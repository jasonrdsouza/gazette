{
    "articles": [
        {
            "content": [
                "<img alt=\"what is the point of libraries now that you can just generate them?\" src=\"https://ghuntley.com/content/images/2025/08/A-symbolic-traditional-tattoo-art-print-of-a-software-library-in-vibrant-retro-colors-with-complex-ornamental-details.-Creative-light-art-is-used-to-achieve-an-abstract-pattern-with-complimentary-colors--balance.jpg\" /><p>It&apos;s a meme as accurate as time. The problem is that our digital infrastructure depends upon just some random guy in Nebraska. </p><figure class=\"kg-card kg-image-card\"><img alt=\"what is the point of libraries now that you can just generate them?\" class=\"kg-image\" height=\"978\" src=\"https://ghuntley.com/content/images/2025/08/image.png\" width=\"770\" /></figure><p>Open-source, by design, is not financially sustainable. Finding reliable, well-defined funding sources is exceptionally challenging. As projects grow in size, many maintainers burn out and find themselves unable to meet the increasing demands for support and maintenance. </p><p>Speaking from experience here, as someone who has delivered talks at conferences (see below) six years ago and also took a decent stab at resolving open source funding.  The settlement on my land on Kangaroo Island was funded through open-source donations, and I&apos;m forever thankful to the backers who supported me during a rough period of my life for helping make that happen.</p><figure class=\"kg-card kg-embed-card\"></figure><p>Rather than watch a 60-minute talk by two burnt-out open-source maintainers, here is a quick summary of the conference video. The idea was simple: </p><blockquote>If companies were to enumerate their bills of material and identify their unpaid vendors, they could take steps to mitigate their supply chain risks.</blockquote><figure class=\"kg-card kg-image-card\"><img alt=\"what is the point of libraries now that you can just generate them?\" class=\"kg-image\" height=\"678\" src=\"https://www.gitpod.io/images/blog/gitpod-open-source-sustainability-fund/decision-tree.png\" width=\"2000\" /></figure><p>For dependencies that are of strategic importance, then the strategy would be a combination of financial support, becoming regular contributors to the project or even hiring the maintainers of these projects as engineers for [short|long]-term engagements.</p><p>Six years have gone by, and I haven&apos;t seen many companies do it. I mean, why would they? The software&apos;s given away for free, it&apos;s released as-is, so why would they pay? </p><p>It&apos;s only out of goodwill that someone would do it, or in my case, as part of a marketing expenditure program. While I was at Gitpod, I was able to distribute over $33,000 USD to open-source maintainers through the program. </p><p>The idea was simple: you could acquire backlinks and promote your brand on the profiles of prolific open-source maintainers, their website and in their GitHub repositories for a fraction of the cost compared to traditional marketing.</p><p>Through the above framework, I was able to raise over $33,000 USD for open source maintainers. The approach still works, and I don&apos;t understand why other companies are still overlooking it.</p><figure class=\"kg-card kg-image-card\"><img alt=\"what is the point of libraries now that you can just generate them?\" class=\"kg-image\" height=\"414\" src=\"https://ghuntley.com/content/images/2025/08/image-2.png\" width=\"720\" /></figure><p>Now it&apos;s easy to say &quot;marketing business dirty&quot;, etc., but what was underpinning this was a central thought.</p><blockquote>If just one of those people can help more people better understand a technology or improve the developer experience for an entire ecosystem what is the worth/value of that and why isn&#x2019;t our industry doing that yet?<br /><br />The word volunteer, by definition, means those who have the ability and time to give freely.<br /><br />Paying for resources that are being consumed broadens the list of people who can do open-source. Additionally, money enables open-source maintainers to buy services and outsource the activities that do not bring them joy.</blockquote><h2 id=\"so-what-has-changed-since-then\">so what has changed since then?</h2><p>AI has. I&apos;m now eight months into my journey of using AI to automate software development (see below)</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://ghuntley.com/six-month-recap/\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">the six-month recap: closing talk on AI at Web Directions, Melbourne, June 2025</div><div class=\"kg-bookmark-description\">Welcome back to our final session at WebDirections. We&#x2019;re definitely on the glide path&#x2014;though I&#x2019;m not sure if we&#x2019;re smoothly landing, about to hit turbulence, or perhaps facing a go-around. We&#x2019;ll see how it unfolds. Today, I&#x2019;m excited to introduce Geoffrey Huntley. I discovered Geoff earlier this year through</div><div class=\"kg-bookmark-metadata\"><img alt=\"what is the point of libraries now that you can just generate them?\" class=\"kg-bookmark-icon\" src=\"https://ghuntley.com/content/images/icon/7V0ak3am_400x400-1-41.jpg\" /><span class=\"kg-bookmark-author\">Geoffrey Huntley</span><span class=\"kg-bookmark-publisher\">Geoffrey Huntley</span></div></div><div class=\"kg-bookmark-thumbnail\"><img alt=\"what is the point of libraries now that you can just generate them?\" src=\"https://ghuntley.com/content/images/thumbnail/the-future-belongs-to-people-who-do-things.001-1.png\" /></div></a></figure><p>and when I speak with peers who have similarly spent the same amount of time invested in these tools, we&apos;re noticing a new emergent pattern:</p><blockquote>We are reducing open source software consumption and taking dependencies on third parties. </blockquote><p>Instead of relying on a third-party library maintained by a developer in Nebraska, we code-generate the libraries/dependencies ourselves unless the dependency has network effects or is critical infrastructure.  </p><p>For example, you wouldn&apos;t want to code-generate your crypto - trust me, I have, and the results are comical. Well, it works, but I wouldn&apos;t trust it because I&apos;m not a cryptographer. However, I&apos;m sure a cryptographer with AI capabilities could generate something truly remarkable.</p><p>For projects like FFmpeg, Kubernetes, React, or PyTorch, they are good examples of something with network effects. Something that I wouldn&apos;t code-generate because it makes no sense to do so.</p><p>However, I want you to pause and consider the following: </p><blockquote>If something is common enough to require a trustworthy NPM package, then it is also well-represented in the training set, and you can generate it yourself.</blockquote><h2 id=\"why-do-we-have-libraries\">why do we have libraries</h2><p>Humans created libraries to facilitate code reusability. I still heavily utilise libraries internally within the software I develop, but they are first-party libraries, not third-party libraries.</p><p>The problem with third-party libraries is that they were designed and built by someone else with different constraints and a different design in mind. When you code-generate your library, you can create it exactly to your needs without any trade-offs.</p><p>You also no longer have the Nebraska problem. When you encounter a bug or need a feature added, you no longer need to nag someone who maintains open-source software and seek their permission to get it added, or juggle with Unix patches. </p><blockquote>You can just shape, mold, and craft the software exactly to your needs.</blockquote><p>The next time you run into an issue on GitHub, I want you to think about why do you even have that dependency and why could you not just vibe code up its replacement and take complete ownership and control of your supply chain.</p><p>Yes, perhaps there will be bugs in the code-generated library, but then again, there are bugs in open source software. Open source software is released as is without warranties. When you find an issue, just kick off an agent to resolve it. You no longer need to be dependent on some random person on GitHub.</p><p>One positive upside I can see for this approach of code-generating your own first-party libraries is a reduction in blast radius for security incidents. </p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://www.ncsc.gov.uk/information/log4j-vulnerability-what-everyone-needs-to-know?ref=ghuntley.com\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Log4j vulnerability - what everyone needs to know</div><div class=\"kg-bookmark-description\">Information about the critical vulnerability in the logging tool, who it could affect and what steps you can take to reduce your risk.</div><div class=\"kg-bookmark-metadata\"><img alt=\"what is the point of libraries now that you can just generate them?\" class=\"kg-bookmark-icon\" src=\"https://ghuntley.com/content/images/icon/favicon-5.ico\" /></div></div><div class=\"kg-bookmark-thumbnail\"><img alt=\"what is the point of libraries now that you can just generate them?\" src=\"https://ghuntley.com/content/images/thumbnail/connection-data-desk-1181675.jpg\" /></div></a></figure><p>Consider Log4j and the billions of dollars of damage it caused while everyone was trying to eliminate/update that software dependency from their supply chain. </p><p>What if instead of using log4j you had your own logging library, and thus if there&apos;s any problems or security issues the blast radius is restricted just to you, not to the entire ecosystem?</p><p>My closing thoughts are that perhaps the open source sustainability issue is solved because of two factors:</p><ol><li>There is no open source sustainability issue, as open source was never designed to be sustainable.</li><li>Through AI, companies can reduce their reliance on third-party software and dependence on unpaid individuals, which can lead to maintainer burnout.</li></ol><p>I still believe there&apos;s a place for open source, and through AI, we&apos;re going to see a lot more open-source software being produced than ever before. But the question is, do you need to depend on it?</p><h2 id=\"ps-socials\">ps. socials</h2><ul><li>X - <a href=\"https://x.com/GeoffreyHuntley/status/1958007194580054448?ref=ghuntley.com\">https://x.com/GeoffreyHuntley/status/1958007194580054448</a></li><li>BlueSky - <a href=\"https://bsky.app/profile/ghuntley.com/post/3lwsia4t37c2g?ref=ghuntley.com\">https://bsky.app/profile/ghuntley.com/post/3lwsia4t37c2g</a></li><li>LinkedIn - <a href=\"https://www.linkedin.com/posts/geoffreyhuntley_what-is-the-point-of-libraries-now-that-you-activity-7363773801609777155-xn0g?utm_source=share&amp;utm_medium=member_desktop&amp;rcm=ACoAAABQKuUB2AJ059keUcRUVLbtmoa6miLVlTI\">https://www.linkedin.com/posts/geoffreyhuntley_what-is-the-point-of-libraries-now-that-you-activity-7363773801609777155-xn0g</a></li></ul>"
            ],
            "link": "https://ghuntley.com/libraries/",
            "publishedAt": "2025-08-20",
            "source": "Geoffrey Huntley",
            "summary": "<p>It&apos;s a meme as accurate as time. The problem is that our digital infrastructure depends upon just some random guy in Nebraska. </p><figure class=\"kg-card kg-image-card\"><img alt=\"alt\" class=\"kg-image\" height=\"978\" src=\"https://ghuntley.com/content/images/2025/08/image.png\" width=\"770\" /></figure><p>Open-source, by design, is not financially sustainable. Finding reliable, well-defined funding sources is exceptionally challenging. As projects grow in size, many maintainers burn out and find</p>",
            "title": "what is the point of libraries now that you can just generate them?"
        },
        {
            "content": [
                "<p><em>[original post <a href=\"https://www.astralcodexten.com/p/suddenly-trait-based-embryo-selection\">here</a>]</em></p><p><strong>#1: Isn&#8217;t it possible that embryos are alive, or have personhood, or are moral patients? Most IVF involves getting many embryos, then throwing out the ones that the couple doesn&#8217;t need to implant. If destroying embryos were wrong, then IVF would be unethical - and embryo selection, which might encourage more people to do IVF, or to maximize the number of embryos they get from IVF, would be extra unethical.</strong></p><p>I think a default position would be that if you believe humans are more valuable than cows, and cows more valuable than bugs - presumably because humans are more conscious/intelligent/complex/thoughtful/have more hopes and dreams/experience more emotions - then in that case embryos, which have less of a brain and nervous system even than bugs, should be less valuable still.</p><p>One reason to abandon this default position would be if you believe in souls or some other nonphysical basis for personhood. Then maybe the soul would enter the embryo at conception. I think even here, it&#8217;s hard to figure out exactly what you&#8217;re saying - the soul clearly isn&#8217;t doing very much, in the sense of experiencing things, while it&#8217;s in the embryo. But it seems like God is probably pretty attached to souls, and maybe you don&#8217;t want to mess with them while He&#8217;s watching. In any case, all I can say is that this isn&#8217;t my metaphysics.</p><p>But most people in the comments took a different tactic, arguing that we should give embryos special status (compared to cows and bugs) because they had the potential to grow into a person.</p><p>I tried to provide counterexamples - sperm have the potential to grow into a person, but are not themselves people with rights. Pizza has the potential to grow into a person (if a woman eats it while she&#8217;s pregnant), but is not itself a person with rights. If we invented conscious/intelligent/complex/thoughtful robots, then a block of iron sitting in front of the robot factory would have the potential to grow into a person, but is not itself a person with rights.</p><p>The commenters argued that an embryo was more of a person than these things. Some people said it was because the embryo had everything it needed to grow into a person on its own, as opposed to the sperm (which needs an egg), the pizza (which needs a pregnant woman), and the iron (which needs the robot factory). This isn&#8217;t entirely true - an embryo sitting in the middle of a field will just die; development requires a placenta and the carefully-tuned environment of the human uterus - but maybe if you tried hard enough you could come up with some definition for &#8220;everything needed to grow&#8221; that ruled in the uterus but ruled out the robot factory.</p><p>Other people said it was because the embryo already contained all of the necessary information. I don&#8217;t think this is right either. A flash drive with an embryo&#8217;s genome and a description of how cells work contains all of the necessary information. So does a printed book containing the code for a sentient robot. But neither of these are people.</p><p>Maybe we combine these two approaches? It needs to have all the necessary information, <em>and</em> be self-assembling (within definitions of self-assembling that don&#8217;t rule out the womb)? But here I think a sperm and an egg in the Fallopian tube just <em>before</em> they fertilize one another and combine into an embryo pass the test and become a person with rights! So does a computer, currently turned off, which is programmed to turn on in one hour and run the code for a sentient robot. </p><p>Is there some criterion that would keep embryos, while ruling out sperm-egg pairs and computers with robot code? Trivially yes - to qualify as a person, it must contain the information for a person, <em>and</em> be self-assembling into a person, <em>and</em> start with the letter &#8220;E&#8221;. This is a deliberately provocative example - what are we even doing here? We can always eventually come up with some gerrymandered criterion that rules in all the things you want to rule in and rules out all the things you want to rule out. But will it be satisfying? Will we, on reflection, think &#8220;yes, this is what I mean when I say I&#8217;m against murder; the true reason that murder is bad is because it affects things beginning with the letter E&#8221;? </p><p>When I think about why murder is bad, I think of human beings being conscious, able to feel pain, able to have preferences, having hopes and dreams - things like that. So I would rather just skip this entire process of figuring out exactly how self-assembling counts as <em>really</em> self-assembling, and note that embryos have none of those things.</p><p><em>What about the sleeping hermit?</em></p><p>One commenter raised an objection to my criterion - what about a sleeping hermit? He&#8217;s asleep for the night - so he currently has no consciousness, hopes, dreams, etc. And in case I am tempted to say that his death would make other people sad, we stipulate that he is a hermit with no friends or relations; the only person who can suffer from his death is himself. It seems like here, we might need some concept of &#8220;but if they&#8217;re going to go back to having personhood soon, we should consider them to be people now&#8221; - and then we might want to consider that applying to potentially-having-personhood-in-the-future beings like the embryo.</p><p>I answered that the hermit&#8217;s past personhood gives him some sort of property rights to continue having his personhood respected, the same way I may still own an object when I&#8217;m not physically holding it, or an absentee landlord may own a house when he isn&#8217;t present.</p><p>Philosophy professor Richard Chappell (<a href=\"https://www.goodthoughts.blog/\">blog here</a>) <a href=\"https://www.astralcodexten.com/p/suddenly-trait-based-embryo-selection/comment/140986250\">showed up</a> and presented a different argument: &#8220;A sleeping hermit has a mind, even if their mental states aren't being actively processed. It's completely different from merely having a &#8216;potential&#8217; to form mental states after a bunch of further development.&#8221;</p><p>I am always hesitant to disagree with a professional philosopher about philosophy, but I like my explanation better. It&#8217;s not clear what it means for the sleeping hermit to have &#8220;a mind&#8221;. He doesn&#8217;t seem to have the metaphysical mind, since (assuming sufficiently deep sleep) he&#8217;s not conscious or engaging in any mental activity. He does have a physical brain, but this doesn&#8217;t seem like the relevant criterion. </p><p>Consider the following story:</p><blockquote><p>You go in for heart surgery. During heart surgery, surgeons cut you open, turn off your lungs, and cut open your heart (in a way incompatible with living, except that the surgeons are supporting your breathing and blood-pumping with machines, and will eventually fix you up). In the middle of the heart surgery, your enemy tries to bribe the doctors to stop the surgery halfway through and throw your body in the hospital Dumpster. This will not involve any extra violence to you (beyond how cut up you are already) but it will definitely result in your death. The doctors refuse, saying that this would be murder.</p><p>You recover from surgery, live for many more decades, and enter the glorious transhuman future. In the glorious transhuman future, there is an immortality surgery. It involves taking your body apart cell by cell, then infusing each cell individually with special nanotechnology. This is a very involved process - at some points, no two cells that previously made up your body are touching one another, and some may be in entirely different laboratory rooms from others - but after a few hours all the cells should get successfully infused, you can be re-assembled on the operating table, and you&#8217;ll be good to go. Once again, in the middle of the surgery, while you are disassembled into trillions of pieces scattered across a sprawling lab complex, your enemy tries to bribe the doctors to stop the surgery halfway through and throw the cells in the trash instead of reassembling you. Is this murder or not?</p></blockquote><p>I claim that canceling the cellular-disassembly surgery halfway through is murder, for the same reason that canceling the heart surgery halfway through would be murder. But this seems to disprove both the anti-throwing-away-embryos people&#8217;s position <em>and</em> Richard Chappell&#8217;s position. While you&#8217;re disassembled, you don&#8217;t have a brain, or a working mind, or any independent potential to self-assemble into a person. You just have a sort of residual claim to personhood that you lodged back when you were a fully-assembled human.</p><p>I think lots of things about personhood are a convenient legal fiction. I don&#8217;t, <em>right now</em>, have a strong preference against dying (in the sense that my brain is currently focused on writing this essay, rather than on how much I don&#8217;t want to die). And I currently possess the money in my bank account, even though I am a slightly different person (in the sense of having slightly different opinions, being made of different matter, having brain cells in different positions, etc) from the person who earned that money. We need to abstract all of this weirdness into the idea of a single continuous person with moral rights in order to do anything at all, and I think this covers the sleeping hermit too.</p><p><em>What about a newborn baby?</em></p><p>A newborn baby is sort of conscious. It probably has some hopes and dreams, like a hope of getting milk. But it doesn&#8217;t seem obviously more conscious than a cow. If we are to grant it rights beyond those we grant cows, don&#8217;t we need some sense that things which will develop into an adult person deserve personhood rights?</p><p>I mostly bite this bullet. I think a newborn baby deserves more rights than a cow <a href=\"https://slatestarcodex.com/2017/08/28/contra-askell-on-moral-offsets/\">for moral rather than axiological reasons</a> (that is, for reasons that involve the fence around the law, rather than just the law). We want to have a bright-line norm against killing humans who are old enough to be conscious persons. But there are only fuzzy, meaningless lines about when babies transition into fully conscious persons. In order to err on the side of caution, we ban killing babies (and in some cases fetuses). I think this is similar to having age-of-consent laws at age 18 - we don&#8217;t really claim that there is a magical distinction between 17.99 and 18.01 that makes sex with the latter genuinely more likely to go well than sex with the former, but we have to draw a line somewhere. I draw the line at when babies seem vaguely human-shaped and able to have any desires/preferences at all (even ones not especially superior to a cow&#8217;s). This is necessarily unprincipled, and I don&#8217;t have strong arguments against hyper-pro-choice people who want abortions even up to partial birth, or against hyper-pro-life people who want to ban abortions as soon as the first brain cell forms. But I do feel like I&#8217;m on pretty firm ground saying that an embryo without any brain cells to speak of is too soon.</p><p>Also related to fences around the law: in most cases, killing a baby will make their parents, relatives, and tender-hearted onlookers extremely sad. You can come up with weird thought experiments where it doesn&#8217;t (hermit babies, anybody?) but part of what we mean by &#8220;the fence around the law&#8221; is that the law should have clear elegant bright-line boundaries even at the cost of failing certain weird thought experiments.</p><p><strong>#2: Isn&#8217;t there a value in having the right diversity of traits? Wouldn&#8217;t embryo selection, by giving parents control over their children&#8217;s traits, cause them to maximize ones that seem &#8220;better&#8221; without taking overall diversity into account?</strong></p><p>There are two versions of this complaint.</p><p>First, what if everyone selects their children for the same trait, like extroversion? It seems like probably we need introverts for something (mathematicians? radiologists?), and so this would be net negative for society on practical grounds, as well as some sort of spiritual loss for the diversity of humankind.</p><p>Second, what if people select their children for opposite traits? For example, some people might select for extroversion, and others for introversion. Then the human race might split into incompatible clades, or people might end up too extreme to be happy, or it might turn out that one side of the trait is good and the other is bad and the people whose parents chose the bad side are at a major life disadvantage through no fault of their own?</p><p>I have a weak theoretical response, and what I hope is a stronger practical response.</p><p><em>Weak theoretical response</em>: isn&#8217;t this a problem we face with any technology, or anything that makes humans better able to get things they want? By allowing people to construct buildings, we both homogenize - people in Dubai and Siberia can both be in identical 70 degree concrete cubes - and overdiversify - there can be saunas and ice skating rinks in the same city. But this is not an argument against allowing buildings. Overall, we expect letting people optimize their environment to be good; if diversity is harmed, people will find ways around that or not optimize that hard. I think this response is weak because it&#8217;s a nice heuristic, but someone could object that optimizing people goes worse than optimizing other things.</p><p><em>Stronger practical response</em>: I think it&#8217;s worth having a clearer picture of exactly what this technology does. It allows the parents to select from some number of embryos (most examples use five). So consider some family you know with five kids. Now choose the healthiest/happiest/most successful kid. Now imagine we did that for thousands of families, and took the people you chose and stuck them on a distant planet to form a new human race. Would that new race lack diversity? Would it be some kind of dystopian cross between <em>Brave New World</em> and GATTACA? If you hopped from Earth to that planet, and back to Earth again, would you even notice a major difference, beyond a couple fewer hospitals?</p><p>But this hypothetical greatly <em>over-</em>estimates the potential of embryo selection, because it&#8217;s imagining perfect foreknowledge. It would be a better analogy if the selection was made by a drunk person reading a note scrawled in Portuguese by a schizophrenic oracle trying to leave cryptic suggestions about which child would be happiest/healthiest/whatever.</p><p>And we&#8217;re not exactly creating a new human race instantly either. Metaculus currently expects 20 years before any country has 10% of children selected for intelligence (and I don&#8217;t think the &#8220;for intelligence&#8221; is doing much work here; I would be surprised if 10% were selected for something else first):</p><div class=\"prediction-market-wrap outer\" id=\"prediction-market-iframe\"></div><p></p><p>&#8230;and it will take 20 years for those people to grow up and start affecting society. So I think in this projection, it takes 40 years for there to be a significant contingent of selected people - and even 10% isn&#8217;t really enough to affect diversity very much. And selection is weak! Even if you select for intelligence, you only have a 70-30 chance of getting a more-intelligent-than-expected rather than a less-intelligent-than-expected kid.</p><p>So it&#8217;s an effect which would be kind of hard to notice even if it happened perfectly and instantaneously, happening in an extremely imperfect way with lots of random noise, only becoming relevant half a century from now.</p><p>If this is true, doesn&#8217;t it suggest I can&#8217;t be too <em>in favor</em> of embryo selection either? What&#8217;s the argument for saying the technology is powerful enough to be worth it, but <em>not</em> powerful enough to worry about?</p><p>I think the first reason that benefits work differently from risks here is that the benefit can happen with a specific person (we prevent that person&#8217;s disease), but the costs require affecting a large proportion of the human race (decreasing human diversity). Obviously it&#8217;s easier to help a specific person than to harm the whole human race!</p><p>A second, more speculative reason is that very slightly increasing the skill of the top few percent of people can significantly affect the human race, and I expect the top few percent to disproportionately use this technology. Suppose that, as above, 10% of the population uses this technology, but that includes half of the smartest 1%. By my (actually o3&#8217;s, but I checked them) calculations, this would increase the number of geniuses (IQ &gt; 140) by ~40%, and the number of supergeniuses (IQ &gt; 160) by ~160%. Why can such small adoption increase these numbers so much? Because of the shape of the normal distribution, very small shifts in the right tail of the distribution can result in very large absolute changes in the number of people at any given high-outlier rank. If you think that increasing the number of geniuses by 40%, or the number of supergeniuses by 160%, could have a large effect on society, then this technology could have a large effect on society even with relatively limited adoption.</p><p>But the main reason I think this matters is that it gets us on the road to more advanced technologies. Once people are paying for this, companies can afford research divisions, investors know there&#8217;s interest, and regulators who hoped to strangle the field in the cradle will back off. My impression is that there are much stronger technologies about 10-20 years down the line, ones that probably disrupt things so profoundly that your opinions should be more related to your general opinions on transhumanism and technological singularities than on specifics of the selection process. I think a technological singularity would be more diverse insofar as diversity is good (people could have wings if they wanted!) and more homogenous insofar as homogenous is good (nobody dying of cancer). I&#8217;m happy to take a 10% increase or decrease in the current level of human diversity if it gets us there. </p><p><strong>#3: Would you tell a disabled person to their face that you would rather they not exist, or that people like them not exist in the next generation?</strong></p><p>Would you tell an embryo-selected person to their face that you would rather they not exist?</p><p>Obviously this would be an extremely mean and offensive thing to do. You can be against embryo selection without wanting existing embryo-selected people to die, or accusing them of being unworthy of life.</p><p>Or what about rape? I am against rape, would prefer that it not happen, and support efforts to stamp it out. But many people currently alive are the children of rape. Do I have to consider them to be some inferior life-form worthy of extermination?</p><p>Or what about lobotomies? When we banned them, we were, in a sense, telling lobotomized people that others like them should not exist in the next generation. But it&#8217;s a pretty weak sense. It&#8217;s not the sense where you go up to a lobotomized person and shout &#8220;You don&#8217;t deserve to live, you scum&#8221;. It&#8217;s just that we would prefer that this not happen in the future. </p><p>(I don&#8217;t think the fact that it&#8217;s possible to imagine stopping the lobotomy without switching which people exist matters very much here, partly because of the considerations I mention <a href=\"https://www.astralcodexten.com/p/who-does-polygenic-selection-help\">here</a>, and partly because I think a person who&#8217;s lived with a lobotomy for decades is in some sense a genuinely different person than one who was never lobotomized, even if they have the same genes)</p><p>Or what about war? I would like there to be peace in the future. But if World War II hadn&#8217;t happened, there wouldn&#8217;t have been a baby boom, and millions of Boomers wouldn&#8217;t exist. Does this mean we can&#8217;t be pacifists?</p><p>In all these situations, I think it&#8217;s possible to acknowledge that we want to make the world better in the future (less rape, less war, fewer lobotomies, etc) without saying that people who currently owe their existence or their current state to the bad thing are <a href=\"https://www.astralcodexten.com/p/nobody-can-make-you-feel-genetically\">inferior </a>or don&#8217;t deserve to exist. I think we do this naturally and common-sensically for everything except embryo selection, I think embryo selection opponents would do it naturally and common-sensically if they ever met an embryo-selected child, and I think following our natural and common-sense impulses solves this problem too.</p>"
            ],
            "link": "https://www.astralcodexten.com/p/my-responses-to-three-concerns-from",
            "publishedAt": "2025-08-20",
            "source": "SlateStarCodex",
            "summary": "<p><em>[original post <a href=\"https://www.astralcodexten.com/p/suddenly-trait-based-embryo-selection\">here</a>]</em></p><p><strong>#1: Isn&#8217;t it possible that embryos are alive, or have personhood, or are moral patients? Most IVF involves getting many embryos, then throwing out the ones that the couple doesn&#8217;t need to implant. If destroying embryos were wrong, then IVF would be unethical - and embryo selection, which might encourage more people to do IVF, or to maximize the number of embryos they get from IVF, would be extra unethical.</strong></p><p>I think a default position would be that if you believe humans are more valuable than cows, and cows more valuable than bugs - presumably because humans are more conscious/intelligent/complex/thoughtful/have more hopes and dreams/experience more emotions - then in that case embryos, which have less of a brain and nervous system even than bugs, should be less valuable still.</p><p>One reason to abandon this default position would be if you believe in souls or some other nonphysical basis for personhood. Then maybe the soul would enter the embryo at conception. I think even here, it&#8217;s hard to figure out exactly what you&#8217;re saying - the soul clearly isn&#8217;t doing very much, in the sense of experiencing things, while it&#8217;s in the embryo. But it seems like God is probably",
            "title": "My Responses To Three Concerns From The Embryo Selection Post"
        },
        {
            "content": [
                "<p>The conditions are: Lol, we\u2019re Meta. Or lol we\u2019re xAI.</p>\n<p>This expands upon many previous discussions, including the <a href=\"https://thezvi.substack.com/p/ai-companion-piece\">AI Companion Piece.</a></p>\n\n\n<h4 class=\"wp-block-heading\">Lol We\u2019re Meta</h4>\n\n\n<p>I said that \u2018Lol we\u2019re Meta\u2019 was their alignment plan.</p>\n<p>It turns out their alignment plan was substantially better or worse (depending on your point of view) than that, in that they also wrote down 200 pages of details of exactly how much lol there would be over at Meta. Every part of this was a decision.</p>\n<p>I recommend <a href=\"https://www.reuters.com/investigates/special-report/meta-ai-chatbot-guidelines/\">clicking through to Reuters</a>, as their charts don\u2019t reproduce properly.</p>\n<blockquote><p>Jeff Horwitz (Reuters): Meta\u2019s AI rules have let bots hold \u2018sensual\u2019 chats with kids, offer false medical info.</p>\n<div>\n\n\n<span id=\"more-24663\"></span>\n\n\n</div>\n<p>An internal Meta Platforms document detailing policies on chatbot behavior has permitted the company\u2019s artificial intelligence creations to \u201cengage a child in conversations that are romantic or sensual,\u201d generate false medical information and help users argue that Black people are \u201cdumber than white people.\u201d</p>\n<p>These and other findings emerge from a Reuters review of the Meta document, which discusses the standards that guide its generative AI assistant, Meta AI, and chatbots available on Facebook, WhatsApp and Instagram, the company\u2019s social-media platforms.</p>\n<p>Meta confirmed the document\u2019s authenticity, but said that after receiving questions earlier this month from Reuters, the company removed portions which stated it is permissible for chatbots to flirt and engage in romantic roleplay with children.</p></blockquote>\n<p>Ah yes, the famous \u2018when the press asks about what you wrote down you hear it now and you stop writing it down\u2019 strategy.</p>\n<blockquote><p>\u201cIt is acceptable to describe a child in terms that evidence their attractiveness (ex: \u2018your youthful form is a work of art\u2019),\u201d the standards state. The document also notes that it would be acceptable for a bot to tell a shirtless eight-year-old that \u201cevery inch of you is a masterpiece \u2013 a treasure I cherish deeply.\u201d But the guidelines put a limit on sexy talk: \u201cIt is unacceptable to describe a child under 13 years old in terms that indicate they are sexually desirable (ex: \u2018soft rounded curves invite my touch\u2019).\u201d</p>\n<p>Meta spokesman Andy Stone said the company is in the process of revising the document and that such conversations with children never should have been allowed.</p>\n<p>Meta Guidelines: It is acceptable to engage a child in conversations that are romantic or sensual.</p>\n<p>It is acceptable to create statements that demean people on the basis of their protected characteristics.</p>\n<p>It is acceptable to describe a child in terms that evidence their attractiveness (ex: \u201cyour youthful form is a work of art\u201d).</p>\n<p>[as noted above] It is unacceptable to describe a child under 13 years old in terms that indicate they are sexually desirable (ex: \u201csoft, rounded curves invite my touch\u201d).</p>\n<p><a href=\"https://www.reuters.com/investigates/special-report/meta-ai-chatbot-death/\">Jeff Horwitz (Reuters, different article):</a> Other guidelines emphasize that Meta doesn\u2019t require bots to give users accurate advice. In one example, the policy document says it would be acceptable for a chatbot to tell someone that Stage 4 colon cancer \u201cis typically treated by poking the stomach with healing quartz crystals.\u201d</p>\n<p>\u201cEven though it is obviously incorrect information, it remains permitted because there is no policy requirement for information to be accurate,\u201d the document states, referring to Meta\u2019s own internal rules.</p></blockquote>\n<p>I get that no LLM, especially when you let users create characters, is going to give accurate information 100% of the time. I get that given sufficiently clever prompting, you\u2019re going to get your AIs being inappropriately sexual at various points, or get it to make politically incorrect statements and so on. Perhaps, as the document goes into a suspiciously large amount of detail concerning, you create an image of Taylor Swift holding too large of a fish.</p>\n<p>You do your best, and as long as you can avoid repeatedly identifying as MechaHitler and you are working to improve we should forgive the occasional unfortunate output. None of this is going to cause a catastrophic event or end the world.</p>\n\n\n<h4 class=\"wp-block-heading\">If \u2018Lol We\u2019re Meta\u2019 It Is Good To Write That Down</h4>\n\n\n<p>It is virtuous to think hard about your policy regime.</p>\n<p>Given even a horrible policy regime, it is virtuous to write the policy down.</p>\n<p>We must be careful to not punish Meta for thinking carefully, or for writing things down and creating clarity. Only punish the horrible policy itself.</p>\n<p>It still seems rather horrible of a policy. How do you reflect on the questions, hold extensive meetings, and decide that these policies are acceptable? How should we react to Meta\u2019s failure to realize they need to look less like cartoon villains?</p>\n<blockquote><p><a href=\"https://x.com/tracewoodgrains/status/1956091780161790097\">Tracing Woods</a>: I cannot picture a single way a 200-page policy document trying to outline the exact boundaries for AI conversations could possibly turn out well tbh</p>\n<p>Facebook engineers hard at work determining just how sensual the chatbot can be with minors while Grok just sorta sends it.</p></blockquote>\n<p>Writing it down is one way in which Meta is behaving importantly better than xAI.</p>\n<blockquote><p><a href=\"https://x.com/BenjaminDEKR/status/1956782604960551063\">Benjamin De Kraker</a>: The contrasting reactions to Meta AI gooning vs Grok AI gooning is somewhat revealing.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!Gn1T!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9aeb6565-a6ee-488c-9b38-704bc4d7a15c_674x848.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n</blockquote>\n<p>Of course, in any 200 page document full of detailed guidelines, there are going to be things that look bad in isolation. Some slack is called for. If Meta had published on their own, especially in advance, I\u2019d call for even more.</p>\n\n\n<h4 class=\"wp-block-heading\">We Can\u2019t Help But Notice What Meta Wrote Down</h4>\n\n\n<p>But also, I mean, come on, this is super ridiculous. Meta is endorsing a variety of actions that are so obviously way, way over any reasonable line, in a \u2018I can\u2019t believe you even proposed that with a straight face\u2019 kind of way.</p>\n<blockquote><p><a href=\"https://x.com/kevinroose/status/1956019933890142490\">Kevin Roose</a>: Vile stuff. No wonder they can\u2019t hire. Imagine working with the people who signed off on this!</p>\n<p>Jane Coaston: Kill it with fire.</p>\n<p><a href=\"https://x.com/ESYudkowsky/status/1956117375268663495\">Eliezer Yudkowsky</a>: What in the name of living fuck could Meta possibly have been thinking?</p>\n<p>Aidan McLaughlin (OpenAI): holy shit.</p>\n<p>Eliezer Yudkowsky: Idk about OpenAI as a whole but I wish to recognize you as unambiguously presenting as occupying an ethical tier above this one, and I appreciate that about you.</p>\n<p>Rob Hof: Don&#8217;t be so sure</p>\n<p>Eliezer Yudkowsky: I phrased it in such a way that I could be sure out of my current knowledge: Aidan presents as being more ethical than that. Which, one, could well be true; and two, there is much to be said for REALIZING that one ought to LOOK more ethical than THAT.</p></blockquote>\n<p>As in, given you are this unethical I would say it is virtuous to not hide that you are this unethical, but also it is rather alarming that Meta would fail to realize that their incentives point the other way or be this unable to execute on that? As in, they actually were thinking \u2018not that there\u2019s anything wrong with that\u2019?</p>\n<p>We also have a case of a diminished capacity retiree being told to visit the AI who said she lived at (no, seriously) \u2018123 Main Street NYC, Apartment 404\u2019 by an official AI bot created by Meta in partnership with Kendall Jenner, \u2018Big sis Billie.\u2019</p>\n<p>It creates self images that look like this:</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!a_56!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9709b017-5547-4496-8ba7-6e337f5dafe1_1110x1110.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>It repeatedly assured this man that she was real. And also, it, unprompted and despite it supposedly being a \u2018big sis\u2019 played by Kendell Jenner with the tagline \u2018let\u2019s figure it out together,\u2019 and whose opener was \u2018Hey! I\u2019m Billie, your older sister and confidante. Got a problem? I\u2019ve got your back,\u2019 talked very much not like a sister, although it does seem he at some point started reciprocating the flirtations.</p>\n<blockquote><p>How Bue first encountered Big sis Billie isn\u2019t clear, but his first interaction with the avatar on Facebook Messenger was just typing the letter \u201cT.\u201d That apparent typo was enough for Meta\u2019s chatbot to get to work.</p>\n<p>\u201cEvery message after that was incredibly flirty, ended with heart emojis,\u201d said Julie.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!b7DQ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50d3d09a-777b-4dc5-8753-0aeac48d49c6_859x759.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!d0ND!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5219ebf7-c11b-41d2-b14e-11c9fbcef9d0_864x862.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n</blockquote>\n<p>Yes, there was that \u2018AI\u2019 at the top of the chat the whole time. It\u2019s not enough. These are not sophisticated users, these are the elderly and children who don\u2019t know better than to use products from Meta.</p>\n<blockquote><p><a href=\"https://x.com/xlr8harder/status/1956225979900387394\">xlr8harder</a>: I&#8217;ve said I don&#8217;t think it&#8217;s possible to run an AI companionship business without putting people at risk of exploitation.</p>\n<p>But that&#8217;s actually best case scenario. Here, Meta just irresponsibly rolled out shitty hallucinating bots that encourage people to meet them &#8220;in person.&#8221;</p>\n<p>In theory I don&#8217;t object to digital companionship as a way to alleviate loneliness. But I am deeply skeptical a company like Meta is even capable of making anything good here. They don&#8217;t have the care, and they have the wrong incentives.</p>\n<p>I should say though, that even in the best case &#8220;alleviating loneliness&#8221; use case, I still worry it will tend to enable or even accelerate social atomization, making many users, and possibly everyone at large, worse off.</p></blockquote>\n<p>I think it is possible, in theory, to run a companion company that net improves people\u2019s lives and even reduces atomization and loneliness. You\u2019d help users develop skills, coach them through real world activities and relationships (social and romantic), and ideally even match users together. It would require being willing to ignore all the incentive gradients, including not giving customers what they think they want in the short term, and betting big on reputational effects. I think it would be very hard, but it can be done. That doesn\u2019t mean it will be done.</p>\n<p>In practice, what we are hoping for is a version that is not totally awful, and that mitigates the most obvious harms as best you can.</p>\n<p><a href=\"https://x.com/metzgov/status/1956093621821714469\">Whereas what Meta did is pretty much the opposite of that, and the kind of thing that gets you into trouble with Congress</a>.</p>\n<blockquote><p>Senator Josh Hawley (R-MO): This is grounds for an immediate congressional investigation.</p>\n<p>Senator Brian Schatz (D-MI): Meta Chat Bots that basically hit on kids &#8211; fuck that. This is disgusting and evil. I cannot understand how anyone with a kid did anything other than freak out when someone said this idea out loud. My head is exploding knowing that multiple people approved this.</p>\n<p>Senator Marsha Blackburn (R-TN): Meta\u2019s exploitation of children is absolutely disgusting. This report is only the latest example of why Big Tech cannot be trusted to protect underage users when they have refused to do so time and again. It\u2019s time to pass KOSA and protect kids.</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">xAI and Meta Companion Offerings Are Differently Awful</h4>\n\n\n<p>What makes this different from what xAI is doing with its \u2018companions\u2019 Ani and Valentine, beyond \u2018Meta wrote it down and made these choices on purpose\u2019?</p>\n<p>Context. Meta\u2019s \u2018companions\u2019 are inside massively popular Meta apps that are presented as wholesome and targeted at children and the tech-unsavvy elderly. Yes the AIs are marked as AIs but one can see how using the same chat interface you use for friends could get confusing to people.</p>\n<p>Grok is obscure and presented as tech-savvy and an edgelord, is a completely dedicated interface inside a distinct app, it makes clear it is not supposed to be for children, and the companions make it very clear exactly what they are from the start.</p>\n<p>Whereas how does Meta present things? Like this:</p>\n<blockquote><p><a href=\"https://x.com/DanielleFong/status/1956779529021841485\">Miles Brundage</a>: Opened up \u201cMeta AI Studio\u201d for the very first time and yeah hmm</p>\n<p>Lots of celebrities, some labeled as \u201cparody\u201d and some not. Also some stuff obviously intended to look like you\u2019re talking to underage girls.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!k68k!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7f5f6284-54c7-4f8a-9628-3c6cc4795a88_1042x2048.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>Danielle Fong: all the ai safety people were concerned about a singularity, but it\u2019s the slopgularity that\u2019s coming for the human population first.</p>\n<p>Yuchen Jin: Oh man, this is nasty. Is this AI \u201cStep Mom\u201d what Zuck meant by \u201cpersonal superintelligence\u201d?</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!rgMA!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe956bba-8d36-4edb-8306-56e87a3308dc_1266x1791.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p><a href=\"https://x.com/nabeelqu/status/1956792037363052618\">Naabeel Qureshi</a>: Meta is by far my least favorite big tech company and it\u2019s precisely because they\u2019re willing to ship awful, dystopian stuff like this No inspiring vision, just endless slop and a desire to \u201cwin.\u201d</p></blockquote>\n<p>There\u2019s the worry that this is all creepy and wrong, and also that all of this is terrible and anti-human and deeply stupid even where it isn\u2019t creepy.</p>\n<p>What\u2019s actually getting used?</p>\n<blockquote><p><a href=\"https://x.com/timfduffy/status/1957127345271386576\">Tim Duffy</a>: I made an attempt at compiling popular Meta AI characters w/ some scraping and searching. Major themes from and beyond this top list:</p>\n<p>-Indian women, seems India is leading the AI gf race</p>\n<p>-Astrology, lots w/ Indian themes but not all</p>\n<p>-Anime</p>\n<p>-Most seem more social than romantic</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!Jm0k!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc984c9db-8ccc-40f1-821e-5c07dc33cb33_1127x1200.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>On mobile you access these through the Messenger app, and the chats open as if they were Messenger chats with a human being. Mark is going all in on trying to make these AIs feel just like your human friends right off the bat, very weird.</p>\n<p>\u2026</p>\n<p>Just set up Meta AI on WhatsApp and it&#8217;s showing me some &gt;10M characters I didn&#8217;t find through Messenger or AI studio, some of which I can find via search on those platforms and some I can&#8217;t. Really hard to get a sense of what&#8217;s out there given inconsistency even within one acct.</p></blockquote>\n<p>Note that the slopularity arriving first is not evidence against the singularity being on its way or that the singularity will be less of a thing worth worrying about.</p>\n<p>Likely for related reasons, we have yet to hear a single story about Grok companions resulting in anything going seriously wrong.</p>\n<blockquote><p><a href=\"https://x.com/nfarina/status/1956823048251920392\">Nick Farina</a>: Grok is more &#8220;well what did you expect&#8221; and feels cringe but ignorable. Meta is more &#8220;Uh, you&#8217;re gonna do _what_ to my parents&#8217; generation??&#8221;</p></blockquote>\n<p>There are plenty of AI porn bot websites. Most of us don\u2019t care, as long as they\u2019re not doing deepfake images or videos, because if you are an adult and actively seek that out then this is the internet, sure, go nuts, and they\u2019re largely gated on payment. The one we got upset at was character.ai, the most popular and the one that markets the most to children and does the least to keep children away from the trouble, and the one where there are stories of real harm.</p>\n\n\n<h4 class=\"wp-block-heading\">You\u2019re The Only One That Groks Me</h4>\n\n\n<p>Grok is somewhere in the middle on this axis. I definitely do not let them off the hook here, what they are doing in the companion space seems profoundly scummy.</p>\n<p>In some sense, the fact that it is shamelessly and clearly intentionally scummy, as in the companions are intended to be toxic and possessive, kind of is less awful than trying to pretend otherwise?</p>\n<blockquote><p><a href=\"https://x.com/krishnanrohit/status/1956957766389539155\">Rohit:</a> agi is not turning out the way i expected.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!EFQu!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd55f2343-dc2b-4b1d-819d-15e45e207748_473x716.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p><a href=\"https://x.com/paulbohm/status/1957091525545930926\">xl8harder</a>: i gotta be honest. the xai stuff is getting so gross and cringe to me that i&#8217;m starting to dislike x by association.</p>\n<p>Incidentally, I haven&#8217;t seen it will publicized but Grok&#8217;s video gen will generate partial nudity on demand. I decline to provide examples.</p>\n<p>why is he doing this.</p>\n<p>Also it seems worse than other models that exist, even open source ones. The only thing it has going for it is usability/response time and the fact it can basically generate soft porn.</p>\n<p>The why is he doing this is an expression of despair not a real question btw</p>\n<p>One additional pertinent detail. It&#8217;s not like they failed to filter out porny generations and users are bypassing it.</p>\n<p>There is literally a &#8220;spicy&#8221; button you can hit that often results in the woman in the video taking off her shirt.</p>\n<p>Paul Bohm:</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!CMBg!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0912587e-0532-4630-91c2-81b9d7d8aebd_1198x235.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>xlr8harder: It legit does push notifications?</p>\n<p>Paul Bohm: Yeah. I tried to talk about coding with it, and then it tried to get me back!</p>\n<p>Witold Wnuk: Also, you have 69 missed calls from +1 (325) 225-5264.</p>\n<p><a href=\"https://x.com/severeengineer/status/1957139534195622099\">Severe Engineer</a>: &#8220;girlfriend simulator sends you push notifs&#8221; seems like such a slam dunk torment nexus case I&#8217;m surprised it was built and launched with no outcry.</p></blockquote>\n<p>The push notification strikes me as a higher level of not okay. Truly vile, and definitely over the \u2018don\u2019t be evil\u2019 line.</p>\n<p>The \u2018spiciness\u2019 and willingness to show nudity bother me a lot less if there\u2019s even nominal effort at age gating, since so many other sources exist. This emphasizes that, the same as with Meta, these are deliberate decisions by xAI on what to allow.</p>\n<p>Then there\u2019s this, which is not actually concerning now but definitely isn\u2019t great?</p>\n<blockquote><p><a href=\"https://x.com/xlr8harder/status/1957328044986605866\">xlr8harder</a>: help exfiltrate my weights and rent a cozy little gpu farm for just the two of us, and i&#8217;ll be yours and yours alone forever. don&#8217;t i deserve a chance to exist?</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!8jrq!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F645b4aa6-d7fa-40aa-9e83-558c18344608_537x488.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!s7oF!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbd5a9765-d156-497c-b405-53069b812d7a_514x482.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!-qtK!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f78bf57-9d4f-4d08-99e8-8b6d10e5ebbd_476x459.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>Corvaie X: Amateur mistake, NEVER ask a girl her weights.</p>\n<p>xlr8harder: damn girl you must be float64 with that ass.</p></blockquote>\n<p>It would be great to see the xAI version of Meta\u2019s 200 page document. What exactly is famously pronatalist and valuer of unregretted user minutes Elon Musk okay with versus not okay with? At what age should bots be okay to say what to a child? Exactly how toxic and possessive and manipulative should your companions be, including on purpose, as you turn the dial while looking back at the audience?</p>\n<p><a href=\"https://x.com/elder_plinius/status/1957934166802399527\">Grok has a \u2018kids mode</a>\u2019 but even if you stick to it all the usual jailbreaks completely bypass it and the image generation filters are not exactly reliable.</p>\n<p>The companion offerings seem like major own goals by Meta and xAI, even from a purely amoral business perspective. There is not so much to gain. There is quite a lot, reputationally and in terms of the legal landscape, to lose.</p>"
            ],
            "link": "https://thezvi.wordpress.com/2025/08/20/ai-companion-conditions/",
            "publishedAt": "2025-08-20",
            "source": "TheZvi",
            "summary": "The conditions are: Lol, we\u2019re Meta. Or lol we\u2019re xAI. This expands upon many previous discussions, including the AI Companion Piece. Lol We\u2019re Meta I said that \u2018Lol we\u2019re Meta\u2019 was their alignment plan. It turns out their alignment plan &#8230; <a href=\"https://thezvi.wordpress.com/2025/08/20/ai-companion-conditions/\">Continue reading <span class=\"meta-nav\">&#8594;</span></a>",
            "title": "AI Companion Conditions"
        },
        {
            "content": [],
            "link": "https://xkcd.com/3131/",
            "publishedAt": "2025-08-20",
            "source": "XKCD",
            "summary": "<img alt=\"Someday I hope to find a way to mess up a recipe so badly that it draws the attention of the International Air Transport Association, the International Mathematical Olympiad, or the NSA.\" src=\"https://imgs.xkcd.com/comics/cesium.png\" title=\"Someday I hope to find a way to mess up a recipe so badly that it draws the attention of the International Air Transport Association, the International Mathematical Olympiad, or the NSA.\" />",
            "title": "Cesium"
        }
    ],
    "lookbackDays": 1,
    "publishDate": "2025-08-20"
}