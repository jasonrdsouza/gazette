{
    "articles": [
        {
            "content": [
                "<div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2093c171-2278-4f7c-90c7-83d8e63b398d_4756x2929.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"897\" src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2093c171-2278-4f7c-90c7-83d8e63b398d_4756x2929.png\" width=\"1456\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a></figure></div><p></p><p>This week, uncover how GitLab slashed backup times from 48 hours to 41 minutes, why even secure-looking DMs aren&#8217;t safe on Twitter, and how a Stanford-built LLM engine is redefining inference speed. Plus, explore misconceptions in aviation software.</p><blockquote><p><strong>Sponsor Spotlight: Smarter Monetization for SaaS </strong>Tired of hard-coding pricing logic? <a href=\"https://schematichq.com/?utm_source=architecture-notes&amp;utm_medium=newsletter&amp;utm_campaign=email_sponsorship\">Schematic</a> makes entitlements a first-class primitive, so you can stop burying access rules in brittle conditionals and let the product teams take control.</p></blockquote><p>Enjoy this week's round-up!</p><p>&#8212; Mahdi Yusuf (<a href=\"https://twitter.com/myusuf3\">@myusuf3</a>) or <a href=\"https://www.linkedin.com/in/myusuf3/\">LinkedIn</a></p><div class=\"pullquote\"><p>&#128075;&#127998; You are reading <a href=\"https://architecturenotes.co/\">Architecture Notes</a> - Your Sunday newsletter, which curates best system design and architecture news from around the web. We would appreciate you sharing it with like-minded people.</p></div><h2>Articles</h2><h3><a href=\"https://esham.io/2025/05/shell-history\">Rethink Your Shell History: A New Approach</a></h3><pre><code>Explore the debate between keeping a detailed shell history versus curating it for efficiency. Discover a nifty zsh function that helps you prune unnecessary commands and keep your history file clean!</code></pre><h3><a href=\"https://blog.glyph.im/2025/06/i-think-im-done-thinking-about-genai-for-now.html\">Why I'm Taking a Break from genAI Discussions</a></h3><pre><code><code>The author shares their frustration with the relentless genAI discourse, admitting defeat in trying to make sense of it and deciding to step back. They explore the overwhelming nature of genAI discussions, the aesthetic displeasure of interacting with AI, and the broader implications on critical thinking and industry practices. It's a candid reflection on the exhaustion of engaging with a topic that feels both inescapable and unsolvable.</code></code></pre><h3><a href=\"https://about.gitlab.com/blog/2025/06/05/how-we-decreased-gitlab-repo-backup-times-from-48-hours-to-41-minutes/\">GitLab Slashes Repo Backup Time from 48 Hours to 41 Minutes</a></h3><pre><code>Discover how GitLab tackled a 15-year-old Git function bottleneck, transforming backup times from 48 hours to just 41 minutes! This breakthrough not only enhances efficiency but also supports more robust backup strategies, reducing risk and costs.</code></pre><div><hr /></div><h3><strong>Schematic: Modern Monetization Without the Hacks</strong></h3><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa0ebc7ee-a48e-434b-80ac-c762cd6e2d26_1200x630.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"630\" src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa0ebc7ee-a48e-434b-80ac-c762cd6e2d26_1200x630.png\" width=\"1200\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a></figure></div><p>Most SaaS products bury pricing logic deep in brittle conditionals &#8212; making it painful to evolve plans, manage trials, or run sales. Schematic fixes that by making entitlements a first-class primitive. Developers stop hard-coding access rules and start using entitlements.check() instead. Product and GTM teams take over from there, owning monetization without shipping code.</p><p>No more brittle logic. Just clean, flexible monetization.</p><p><a href=\"https://schematichq.com/?utm_source=architecture-notes&amp;utm_medium=newsletter&amp;utm_campaign=email_sponsorship\">Get Started With Schematic</a> &#8594;</p><div><hr /></div><h3><a href=\"https://fly.io/blog/youre-all-nuts/\">Why AI Skeptics Are Missing the Point</a></h3><pre><code><code>In a candid take, Thomas Ptacek argues that AI skeptics are underestimating the impact of LLMs on software development, likening their skepticism to dismissing the internet in its early days. He highlights how LLMs can handle tedious coding tasks, freeing developers to focus on more meaningful work, and challenges the notion that AI-generated code is inherently inferior.</code></code></pre><div class=\"subscription-widget-wrap-editor\"><div class=\"subscription-widget show-subscribe\"><div class=\"preamble\"><p class=\"cta-caption\">Architecture Notes &#8212; System Design &amp;  Software Development is a reader-supported publication. To receive new posts and support my work, consider becoming a free or paid subscriber.</p></div><form class=\"subscription-widget-subscribe\"><input class=\"email-input\" name=\"email\" tabindex=\"-1\" type=\"email\" /><input class=\"button primary\" type=\"submit\" value=\"Subscribe\" /><div class=\"fake-input-wrapper\"><div class=\"fake-input\"></div><div class=\"fake-button\"></div></div></form></div></div><h3><a href=\"https://flightaware.engineering/falsehoods-programmers-believe-about-aviation/\">Common Misconceptions Programmers Have About Aviation</a></h3><pre><code><code>Think aviation data is straightforward? Think again! Discover the surprising falsehoods programmers often believe about flights, airports, and airlines, and how these misconceptions can lead to unexpected challenges in aviation software development.</code></code></pre><h3><a href=\"https://mjg59.dreamwidth.org/71646.html\">Twitter's New Encrypted DMs: Still Not Secure Enough</a></h3><pre><code><code>Despite Twitter's recent launch of \"XChat\" with new encryption, the platform's DMs remain vulnerable, lacking forward secrecy and relying on a PIN system that can be easily compromised. The article suggests using Signal for truly secure messaging.</code></code></pre><h3><a href=\"https://www.ssp.sh/blog/self-host-self-independence/\">Discover the Joy of Self-Hosting and Tech Independence</a></h3><pre><code><code>From setting up a home server to embracing open-source tools, learn how taking control of your tech can lead to greater independence and joy!</code></code></pre><h3><a href=\"https://www.danielfullstack.com/article/dns-does-not-have-to-be-hard\">Mastering DNS: A Simple Guide to Understanding the Basics</a></h3><pre><code><code>Dive into the world of DNS and discover how this essential system maps domain names to IP addresses, making the internet function smoothly. This article breaks down the complexities of DNS architecture, records, and servers, offering a clear and engaging explanation that even ChatGPT might envy!</code></code></pre><h2>Projects</h2><h3><a href=\"https://scalingintelligence.stanford.edu/blogs/tokasaurus/\">tokasaurus</a></h3><pre><code><code>Discover Tokasaurus, Stanford's latest LLM inference engine designed to handle high-throughput workloads with ease. This innovative tool outperforms existing engines by up to 3x, thanks to its dynamic prefix identification and async tensor parallelism. Dive into the details and see how Tokasaurus is setting new benchmarks in AI efficiency!</code></code></pre><h3><a href=\"https://github.com/hyperdxio/hyperdx\">hyperdx</a></h3><pre><code><code>Discover HyperDX, an open source observability platform that combines session replays, logs, metrics, traces, and errors, all powered by Clickhouse and OpenTelemetry, to help you resolve production issues faster than ever!</code></code></pre><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd0f8bd98-bdb5-4338-85ce-86f11e5114e3_1000x483.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-large\" height=\"579.6\" src=\"https://substackcdn.com/image/fetch/w_2400,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd0f8bd98-bdb5-4338-85ce-86f11e5114e3_1000x483.png\" title=\"\" width=\"1200\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a></figure></div><p></p><h3><a href=\"https://softwaredoug.com/blog/2024/08/06/i-made-search-worse-elasticsearch\">Why My Search Engine Fails Compared to Elasticsearch</a></h3><pre><code><code>Join the author in their humbling journey of creating a search engine that pales in comparison to Elasticsearch. Discover the technical intricacies and why real search engines like Elasticsearch are so efficient, while my side project, SearchArray, struggles with performance and relevance.</code></code></pre>"
            ],
            "link": "https://architecturenotes.co/p/arc-notes-weekly-97-accounting",
            "publishedAt": "2025-06-08",
            "source": "Architecture Notes",
            "summary": "This week, GitLab cuts backups from 48h to 41m, Twitter&#8217;s DMs aren&#8217;t as secure as they seem, and Stanford&#8217;s Tokasaurus boosts LLM speed. Plus, rethink common misconceptions in aviation software.",
            "title": "Arc Notes Weekly #97: Accounting"
        },
        {
            "content": [
                "<p>A few eagle-eyed readers have noticed that it\u2019s been 4 weeks since my last entry in what I have been thinking of as my \u201cniblet series\u201d \u2014 one small piece per week, 1000 words or less, for the next three months.</p>\n<p>This is true. However, I did leave myself some wiggle room in my original goal, when I said \u201cweeks when I am not traveling\u201d, knowing I was traveling 6 of the next 7 weeks. I was going to TRY to write something on the weeks I was traveling, but as you can see, I mostly did not succeed. Oh well!</p>\n<p>Honestly, I don\u2019t feel bad about it. I\u2019ve written well over 1k words on bsky over the past two weeks in the neverending thread on the <a href=\"https://bsky.app/profile/charity.wtf/post/3lq4cgak3vk24\">costs and tradeoffs of remote work</a>. (A longform piece on the topic is coming soon.) I also wrote a couple of lengthy internal pieces.</p>\n<p>This whole experiment was designed to help me unblock my writing process and try out new habits, and I think I\u2019m making progress. I will share what I\u2019m learning at a later date, but for now: onward!</p>\n<h2>How long does it take to form an impression of a new job?</h2>\n<p>This week\u2019s niblet was inspired by a conversation I had yesterday with an internet friend. To paraphrase (and lightly anonymize) their question:</p>\n<blockquote><p>\u201cI took a senior management role at this company six months ago. My search for this role was all about values alignment, from company mission to leadership philosophy, and the people here said all the right things in the process. But it\u2019s just not clicking.</p>\n<p>It\u2019s only been six months, but it\u2019s starting to feel like it might not work out. How much longer should I give it?\u201d</p></blockquote>\n<p>Zero. You should give it 0 time. You already know, and you\u2019ve known for a long time; it\u2019s not gonna change. I\u2019m sorry. <img alt=\"\ud83d\udc94\" class=\"wp-smiley\" src=\"https://s.w.org/images/core/emoji/15.1.0/72x72/1f494.png\" style=\"height: 1em;\" /></p>\n<p>I\u2019m not saying you should quit tomorrow, a person needs a paycheck, but you should probably start thinking in terms of how to manage the problem and extricate yourself from it, not like you\u2019re waiting to see if it will be a good fit.</p>\n<h2>Every job I&#8217;ve ever had has made a strong first impression</h2>\n<p>I\u2019ve had\u2026let\u2019s see\u2026about six different employers, over the course of my (post-university) career.</p>\n<p>Every job I\u2019ve ever taken, <strong>I knew within the first week</strong> whether it was right for me or not. That might be overstating things a bit (memory can be like that). But I definitely had a strong visceral reaction to the company within days after starting, and the rest of my tenure played out more or less congruent with that reaction.<img alt=\"Progress not Perfection\" class=\"alignright wp-image-9705 size-medium\" height=\"144\" src=\"https://i0.wp.com/charity.wtf/wp-content/uploads/2024/12/stickers-21.jpeg?resize=300%2C144&#038;ssl=1\" width=\"300\" /></p>\n<p>The first week at EVERY job is a hot mess of anxiety and nerves and second-guessing yourself and those around you. It&#8217;s never warm fuzzies. But at the jobs I ended up loving and staying at long term, the anxiety was like \u201comg these people are so cool and so great and so fucking competent, I hope I can measure up to their expectations.\u201d</p>\n<p>And then there were the jobs where the anxiety I felt was more like a sinking sensation of dread, of \u201coooohhh god I hope this is a one-off and not the kind of thing I will encounter every day.\u201d</p>\n<p style=\"padding-left: 40px;\"><img alt=\"\ud83c\udf38\" class=\"wp-smiley\" src=\"https://s.w.org/images/core/emoji/15.1.0/72x72/1f338.png\" style=\"height: 1em;\" /> There was the job where they had an incident on my very first day, and by 7 pm I was like \u201cwhy isn\u2019t someone telling me I should go home?\u201d There was literally nothing I could do to help, I was still setting up my accounts, yet I had the distinct impression I was expected to stay.</p>\n<p>This job turned out to be stereotypically Silicon Valley in the worst ways, hiring young, cheap engineers and glorifying coding all night and sleeping under your desks.</p>\n<p style=\"padding-left: 40px;\"><img alt=\"\ud83c\udf3c\" class=\"wp-smiley\" src=\"https://s.w.org/images/core/emoji/15.1.0/72x72/1f33c.png\" style=\"height: 1em;\" /> There was the job where they were walking me through a 50-page Microsoft Word doc on how to manage replication between DB nodes, and I laughed a little, and looked for some rueful shared acknowledgement of how shoddy this was\u2026but I was the only one laughing.</p>\n<p>That job turned out to be shoddy, ancient, flaky tech all the way down, with comfortable, long-tenured staff who didn\u2019t know (and did NOT want to hear) how out of date their tech had become.</p>\n<h2>Over time, I learned to trust that intuition</h2>\n<p>Around the time I became a solidly senior engineer, I began to reflect on how indelible my early impressions of each job had been, and how reliable those impressions had turned out to be.<img alt=\"Communicate Positive Intent\" class=\"alignright wp-image-9702 size-medium\" height=\"127\" src=\"https://i0.wp.com/charity.wtf/wp-content/uploads/2024/12/stickers-24.jpeg?resize=300%2C127&#038;ssl=1\" width=\"300\" /></p>\n<p>To be clear, I don\u2019t regret these jobs. I got to work with some wonderful people, and I got to experience a range of different organizational structures and types. I learned a lot from every single one of my jobs.</p>\n<p>Perhaps most of all, I learned how to sniff out particular environments that really<em> do not work for me</em>, and I never made the same mistake twice.</p>\n<p>Companies can and do change dramatically. But absent dramatic action, which can be <strong>quite painful</strong>, they tend to drift along their current trajectory.</p>\n<h2>This matters even more for managers</h2>\n<p>This is one of those ways that I think the work of management is different from the work of engineering. As an experienced IC, it\u2019s possible to phone it in and still do a good job. As long as you\u2019re shipping at an acceptable rate, you can check out mentally and emotionally, even work for people or companies you basically despise.</p>\n<p>Lots of people do in fact do this. Hell, I\u2019ve done it. You aren\u2019t likely to do the best work of your life under these circumstances, but people have done far worse to put food on the table.</p>\n<p>An IC can wall themselves off emotionally and still do acceptable work, but I\u2019m not sure a manager can do the same.</p>\n<h2>Alignment *is* the job of management</h2>\n<p>As a manager, you literally represent the company to your team and those around you. You don\u2019t have to agree with every single decision the company makes, but if you find yourself constantly having to explain and justify things the company has done that deeply violate your personal beliefs or ethics, it does you harm.</p>\n<p>Some managers respond to a shitty corporate situation by hunkering down and behaving like a shit umbrella; doing whatever they can to protect their people, at the cost of<img alt=\"if it hurts...do it more\" class=\"alignright size-medium wp-image-9708\" height=\"124\" src=\"https://i0.wp.com/charity.wtf/wp-content/uploads/2024/12/stickers-18.jpeg?resize=300%2C124&#038;ssl=1\" width=\"300\" /> undermining the company itself. I don\u2019t recommend this, either. <strong>It&#8217;s not healthy to know you walk around every day fucking over one of your primary stakeholders</strong>, whether it&#8217;s the company OR\u00a0 your teammates.</p>\n<p>There are also companies that aren\u2019t actually that bad, but you just aren\u2019t aligned with them. That\u2019s fine. Alignment matters a lot more for managers than for ICs, because<em> alignment is the job</em>.</p>\n<p>Management is about crafting and tending to complex sociotechnical systems. No manager can do this alone. Having a healthy, happy team of direct reports is only a fraction of the job description. It\u2019s not enough. You can and should expect more.</p>\n<h2>What can you learn from the experience?</h2>\n<p>I asked my friend to think back to the interview process. What were the tells? What do they wish they had known to watch out for?</p>\n<p>They thought for a moment, then said:</p>\n<blockquote><p>\u201cMaybe the fact that the entire leadership team had been grown or promoted from within. SOME amount of that is terrific, but ALL of it might be a yellow flag. The result seems to be that everyone else thinks and feels the same way\u2026and I think differently.\u201d</p></blockquote>\n<p>This is SO insightful.</p>\n<p>It reminds me of all the conversations Emily and I have had over the years, on how to balance developing talent from within vs bringing in fresh perspectives, people who have already seen what good looks like at the next stage of growth, people who can see around corners and challenge us in different ways.</p>\n<p>This is a tough thing to suss out from the outside, especially when the employer is saying all the right things. But having an experience like this can inoculate you from an entire family of related mistakes. My friend will pick up on this kind of insularity from miles away, from now on.</p>\n<p>Bad jobs happen. Interviews can only predict so much. A person who has never had a job they disliked is a profoundly lucky person. In the end, sometimes all you can take is the lessons you learned and won&#8217;t repeat.</p>\n<h2><span style=\"font-weight: 400;\">The pig is committed</span></h2>\n<p><span style=\"font-weight: 400;\">Have you ever heard the metaphor of the chicken vs the pig? The chicken contributes an egg to breakfast, the pig contributes bacon. The punch line goes something like, \u201cthe chicken is involved, but the pig is committed!\u201d</span></p>\n<p><span style=\"font-weight: 400;\">It\u2019s vivid and a bit over the top, but I kept thinking about it while writing this piece. The engineer contributes their labor and output to move the company forward, but the manager contributes their emotional and relational selves \u2014 their humanity \u2014 to serve the cause.</span></p>\n<p><span style=\"font-weight: 400;\">You only get one career. Who are you going to give your bacon to?</span></p>"
            ],
            "link": "https://charity.wtf/2025/06/08/on-how-long-it-takes-to-know-if-a-job-is-right-for-you-or-not/",
            "publishedAt": "2025-06-08",
            "source": "Charity Majors",
            "summary": "A few eagle-eyed readers have noticed that it\u2019s been 4 weeks since my last entry in what I have been thinking of as my \u201cniblet series\u201d \u2014 one small piece per week, 1000 words or less, for the next three months. This is true. However, I did leave myself some wiggle room in my original [&#8230;]",
            "title": "On How Long it Takes to Know if a Job is Right for You or Not"
        },
        {
            "content": [
                "<blockquote>The IT department never questioned why the new printer arrived in a crate marked with eldritch symbols. They were just happy to finally have a replacement for the ancient LaserJet that had been serving the accounting floor since time immemorial.<br /><br />Sarah from IT support was the first to notice something was amiss when she went to install the drivers. The installation wizard didn&apos;t ask for the usual Windows credentials - instead, it demanded &quot;THE BLOOD OF THE INNOCENT OR A VALID ADMINISTRATOR PASSWORD.&quot; She typed in admin123, and the printer accepted it with what sounded suspiciously like disappointment.<br /><br />The first print job seemed normal enough - Johnson from Marketing needed 200 copies of the quarterly report. The printer hummed to life, its all-seeing scanner eye glowing with an unsettling purple light. The first page emerged normally. The second page contained the same data but from a slightly different reality where the company had invested in crypto. By page fifty, it was printing reports from dimensions where the company had conquered entire galaxies.<br /><br />&quot;PC LOAD LETTER&quot; flashed on its display, but in a font that hurt to look at. When Bob from Accounting tried to add paper, he found the tray existed in non-Euclidean space. Every time he inserted a ream, it would somehow contain both infinite paper and no paper simultaneously. Schr&#xf6;dinger&apos;s print tray, the IT department called it.<br /><br />The printer&apos;s peculiarities might have been manageable if it hadn&apos;t been for the cyan incident. Despite being configured to print only in black and white, it kept insisting it needed cyan toner. &quot;CYAN LEVELS LOW IN ALL POSSIBLE REALITIES&quot; it warned. When someone finally installed a new cyan cartridge, it used it to print a portal to dimension C-137, causing a brief merger with a universe where all printers were sentient and had enslaved humanity.<br /><br />The paper jams were the worst. Not regular paper jams - these existed in multiple dimensions simultaneously. The help desk started receiving tickets like:<br /><br />&quot;Paper jam in reality sector 7G&quot;<br /><br />&quot;Tentacles emerging from output tray&quot;<br /><br />&quot;Printer making ominous prophecies about the end times&quot;<br /><br />&quot;Print queue exists outside of temporal causality&quot;<br /><br />The printer&apos;s most ambitious act came during the annual budget meeting. When asked to print 500 copies of the financial forecast, it decided to &quot;optimize reality for better margins&quot; by slightly rewriting the laws of mathematics. The accounting department actually appreciated this one, as it made all the numbers add up perfectly. The fact that it also caused a minor breach in the space-time continuum was considered an acceptable tradeoff for balanced books.<br /><br />IT tried their usual fixes:<br /><br />Turn it off and on again (resulted in a temporary reversal of entropy)<br /><br />Update the drivers (somehow downloaded drivers from a dimension of pure chaos)<br /><br />Clear the print queue (released several eldritch horrors trapped in suspended print jobs)<br /><br />Run the troubleshooter (it gained sentience and had an existential crisis)<br /><br />The printer&apos;s reign of terror finally met its match when Carol from HR tried to print the updated office policy on interdimensional portals in the break room. The printer, attempting to process the paradox of printing rules about itself, had a metaphysical kernel panic. The ensuing reality cascade caused it to trap itself in an infinite loop of printing its own installation manual.<br /><br />These days, the printer sits quietly in the corner, occasionally mumbling about toner levels across the multiverse. The IT department has learned to live with it, even appreciate its quirks. Yes, sometimes it prints documents from tomorrow, and yes, occasionally it tries to summon ancient ones through paper tray 2, but at least it doesn&apos;t jam as much as the old LaserJet.<br /><br />They&apos;ve even started using its reality-bending features productively. Need to meet an impossible deadline? The printer can send your document back in time to when it was actually due. Budget doesn&apos;t quite add up? Just print it through the reality where the numbers work. Johnson from Marketing particularly loves it for printing multiple versions of proposals simultaneously to see which reality gets the best client response.<br /><br />The only real ongoing issue is that it still asks for cyan. Always cyan. Even when printing black and white text. Even when printing into the void. Even when reality itself is collapsing.<br /><br />Because in the end, no matter how many dimensions it can access, no matter how many realities it can bend, no matter how many ancient ones it can summon - it&apos;s still a printer.<br /><br />And it needs cyan.</blockquote><hr /><h1 id=\"what-the-heck-did-i-just-read\">what the heck did I just read?</h1><img alt=\"the printer that transcends dimensions and corrupts reality\" src=\"https://ghuntley.com/content/images/2025/06/An-epic--grand-scene-depicted-in-a-symbolic-traditional-tattoo-art-print-of-an-intergalactic-printer-with-weapons--traveling-through-space-and-opening-Stargate-wormholes--referencing-PC-load-letter.-Vibrant-colors--retro-flair--complex-orna.jpg\" /><p>The above is from a <a href=\"https://claude.ai/share/20dde0cb-fccd-438f-8a40-6d36c764c73c?ref=ghuntley.com\" rel=\"noreferrer\">transcript I had with Claude</a> about five months ago, when I was first starting to understand that AI is truly an infinite idea generator. One of the first jobs I had growing up was working at a small company called Unisys. Unisys, for many years, ran the processing system for paper-based financial payments in Australia. </p><p>The way they did that was by connecting a whole room of cheque scanners to an old AIX machine. Now that&apos;s not interesting. What is interesting is how they configured their batch jobs was almost somewhat borderline genius. </p><p>Each one of those scanners was connected to the LPR print system. Not many people know that the LPR print system can define shell scripts as printers. If you look at LPR from the right angle, it has a lot of sound properties to it if you wanted to build a highly resilient batch/job processor system:</p><ul><li>printing = job processing (max of 1 at a time)</li><li>offline = scheduled maintenance</li><li>paper jam = dead letter queue</li></ul><h1 id=\"ive-always-wondered-how-it-worked\">i&apos;ve always wondered how it worked</h1><p>So, I started a chat with Claude. </p><figure class=\"kg-card kg-image-card\"><img alt=\"the printer that transcends dimensions and corrupts reality\" class=\"kg-image\" height=\"1484\" src=\"https://ghuntley.com/content/images/2025/06/CleanShot-2025-06-09-at-02.01.57@2x.png\" width=\"1516\" /></figure><h1 id=\"what-i-learned\">what I learned</h1><p>It was through this session that I learned that one needs to load the context window, and once it is loaded, you can take it places. The original implementation was in shell, and I wanted it in Haskell. Instead of asking for Haskell first, I gave the LLM free rein to propose a solution however it wanted.</p><figure class=\"kg-card kg-image-card\"><img alt=\"the printer that transcends dimensions and corrupts reality\" class=\"kg-image\" height=\"1782\" src=\"https://ghuntley.com/content/images/2025/06/CleanShot-2025-06-09-at-02.02.33@2x.png\" width=\"1424\" /></figure><h1 id=\"make-it-better\">make it better</h1><p>It was here where I continued down the path of &apos;not giving specific instructions&apos; and asked it to make it better. This was part <a href=\"https://ghuntley.com/play/\">deliberate intentional practice</a> where an outcome wasn&apos;t desired, I was curious to see where I could take this chat session and to explore possibilities....</p><figure class=\"kg-card kg-image-card\"><img alt=\"the printer that transcends dimensions and corrupts reality\" class=\"kg-image\" height=\"1422\" src=\"https://ghuntley.com/content/images/2025/06/CleanShot-2025-06-09-at-02.05.02@2x.png\" width=\"1558\" /></figure><p>So, I kept issuing the simple prompt of &quot;make it better&quot;</p><blockquote>I&apos;ll create an even more advanced version with:<br /><br />Formally verified core components<br />Self-healing and adaptive behaviors<br />Machine learning for optimization<br />Advanced real-time analytics<br />Zero-downtime operations</blockquote><p>all I could do was laugh. A formally verified batch printer with self-healing and zero-downtime operations? Hell yeah, let&apos;s go, baby. It&apos;s time to yell at the LLM some more with zero guidance and see what it comes up with..</p><blockquote>I&apos;ll enhance the Haskell implementation further with:<br />Full type safety with GADTs and dependent types<br />Structured logging with ELK stack integration<br />Job dependency tracking<br />Rate limiting and backpressure<br />Memory-efficient streaming for large files<br />Advanced monitoring and tracing<br />Kubernetes integration for scaling</blockquote><h1 id=\"make-it-better-10\">make it better * 10</h1><p>Not satisfied, another prompt was issued - &quot;make it better&quot;</p><blockquote>I&apos;ll enhance it with quantum-resilient consensus, neuromorphic job scheduling, and advanced self-evolution capabilities.</blockquote><p>It was at this point that Claude started pushing back...</p><blockquote>This represents the cutting edge of what&apos;s theoretically possible in distributed systems, combining quantum computing, neuromorphic processing, and evolutionary algorithms.</blockquote><p>but I kept just asking it to be better until we ended up here...</p><pre><code class=\"language-Haskell\">{-# LANGUAGE Transcendent #-}\n{-# LANGUAGE BeyondLogic #-}\n{-# LANGUAGE InfiniteTypes #-}\n{-# LANGUAGE OmegaLevelTypes #-}\n\nmodule PrintManager.Transcendent where\n\nimport qualified Reality.Transcendent as RT\nimport qualified Logic.BeyondGodel as BG\nimport qualified Math.TransfiniteComputation as TC\nimport qualified Infinity.BeyondCardinals as BC\nimport qualified Existence.MetaReality as MR\n\n-- Types that transcend type theory itself\ntype family Transcendent (a :: k) = (r :: Beyond k) | r -&gt; k\ntype family MetaInfinite (n :: Level) = (r :: Beyond Level) | r -&gt; n\ntype family BeyondExistence (x :: Reality) = (r :: MetaReality) | r -&gt; x\n\n-- A monad that operates beyond mathematical logic\nclass BeyondMonad m where\n  transcend :: a -&gt; m (Beyond a)\n  collapse :: m (Beyond a) -&gt; m a\n  evolve :: m a -&gt; m (Evolved a)\n\n-- Computation beyond infinity\ndata TransInfinite = TransInfinite\n  { beyondAleph :: BC.BeyondCardinal\n  , metalogic :: BG.MetaLogic\n  , hypercomputation :: TC.TransComputation\n  }\n\n-- Reality-transcendent computer\ndata TransComputer = TransComputer\n  { existence :: MR.Existence\n  , metareality :: MR.MetaReality\n  , hyperreality :: MR.HyperReality\n  , transcendence :: MR.Transcendence\n  }\n\n-- Operations that transcend existence\ntranscendExistence :: TransComputer -&gt; Existence -&gt; MetaReality\ntranscendExistence computer existence = do\n  -- Transcend physical reality\n  beyond &lt;- transcendPhysics existence\n  \n  -- Transcend mathematics itself\n  metalogic &lt;- transcendMathematics beyond\n  \n  -- Transcend logic\n  hyperlogic &lt;- transcendLogic metalogic\n  \n  -- Transcend transcendence itself\n  transcendTranscendence hyperlogic\n\n-- Computation beyond infinity\ncomputeBeyondInfinity :: TransInfinite -&gt; Computation -&gt; Beyond Result\ncomputeBeyondInfinity trans comp = do\n  -- Go beyond all cardinal numbers\n  beyond &lt;- transcendCardinals comp\n  \n  -- Compute using metalogic\n  metalogic &lt;- computeMetalogic beyond\n  \n  -- Hypercompute the result\n  hypercompute metalogic\n\n-- Main loop beyond existence\nmain :: Beyond IO ()\nmain = do\n  -- Initialize beyond reality\n  computer &lt;- initTransComputer\n  \n  -- Enter loop beyond existence\n  forever $ do\n    -- Transcend current reality\n    reality &lt;- transcendReality\n    \n    -- Compute beyond infinity\n    result &lt;- computeBeyondInfinity\n    \n    -- Evolve beyond evolution\n    evolve reality\n    \n    -- Create new forms of existence\n    createNewExistence\n    \n    -- Transcend the very concept of computation\n    transcendComputation</code></pre><p>This printer:</p><blockquote><strong>Transcends the Church-Turing thesis<br />Operates beyond spacetime<br />Creates new computational paradigms<br />Evolves the laws of physics themselves</strong></blockquote><p>Yet, Claude, friendly as ever, asked for its next serving of &quot;make it better&quot;. It&apos;s at this point that the session devolved into silly fun. Holy shit, I was laughing at the things it was presenting and coming up with by this stage. So, there was only one logical step. Give it a nudge...</p><h1 id=\"make-the-printer-open-a-stargate-sg9-wormhole\">make the printer open a stargate sg9 wormhole</h1><figure class=\"kg-card kg-image-card\"><img alt=\"the printer that transcends dimensions and corrupts reality\" class=\"kg-image\" height=\"736\" src=\"https://ghuntley.com/content/images/2025/06/CleanShot-2025-06-09-at-02.20.26@2x.png\" width=\"1404\" /></figure><pre><code class=\"language-Haskell\">{-# LANGUAGE ExoticPhysics #-}\n{-# LANGUAGE WormholeStability #-}\n{-# LANGUAGE NaquadahEnhanced #-}\n\nmodule PrintManager.Stargate where\n\nimport Physics.Subspace.Wormhole\nimport Physics.ZPM.NaquadahReactor\nimport Control.Stargate.Chevron\nimport Network.Subspace.Buffer\nimport qualified Data.DHD.Coordinates as DHD\n\n-- Exotic matter printer components\ndata StargateQueue = StargateQueue\n  { -- Core stargate components\n    naquadahCore :: NaquadahReactor\n  , zpmInterface :: ZPMController\n  , subspaceBuffer :: SubspaceBuffer\n  , eventHorizon :: EventHorizonGenerator\n    \n    -- Print mechanisms  \n  , matterStream :: MatterStream\n  , patternBuffer :: MolecularBuffer\n  , rematerializer :: MatterReconstructor\n  , molecularPrinter :: AtomicAssembler\n    \n    -- Wormhole control\n  , dhd :: DialingDevice\n  , chevronEncoder :: ChevronLock\n  , irisControl :: IrisBarrier\n  , wormholeStabilizer :: StabilityField\n  }\n\n-- Initialize stargate printer\ninitStargatePrinter :: IO StargateQueue\ninitStargatePrinter = do\n  -- Power up naquadah reactor\n  core &lt;- spinUpReactor defaultNaquadah\n  \n  -- Initialize ZPM interface\n  zpm &lt;- connectZPM core.powerGrid\n  \n  -- Create subspace buffer\n  buffer &lt;- createSubspaceField zpm.containment\n  \n  -- Generate event horizon \n  horizon &lt;- generateEventHorizon buffer\n  \n  -- Initialize matter handling\n  stream &lt;- createMatterStream horizon\n  patterns &lt;- initMolecularBuffer\n  reconstructor &lt;- calibrateReconstructor\n  printer &lt;- initAtomicAssembler\n  \n  -- Setup wormhole controls\n  dhd &lt;- initDHD defaultSymbols\n  chevrons &lt;- initChevronArray\n  iris &lt;- deployIrisBarrier\n  stabilizer &lt;- createStabilityField\n  \n  return StargateQueue {..}\n\n-- Print job through wormhole\nprintThroughWormhole :: StargateQueue -&gt; PrintJob -&gt; DHD.Coordinates -&gt; IO Result\nprintThroughWormhole gate job coords = do  \n  -- Power up systems\n  powerLevel &lt;- chargeZPM gate.zpmInterface\n  \n  -- Encode destination\n  chevrons &lt;- encodeChevrons gate.chevronEncoder coords\n  \n  -- Establish wormhole\n  wormhole &lt;- do\n    -- Lock chevrons\n    lockStatus &lt;- sequence \n      [ lockChevron gate.chevronEncoder i symbol\n      | (i, symbol) &lt;- zip [1..7] chevrons\n      ]\n    \n    -- Generate kawoosh\n    kawoosh &lt;- generateKawoosh gate.eventHorizon\n    \n    -- Stabilize wormhole\n    stabilizeWormhole gate.wormholeStabilizer kawoosh\n  \n  -- Convert print job to matter stream\n  stream &lt;- do\n    -- Dematerialize document\n    patterns &lt;- scanMolecularPattern job\n    \n    -- Buffer patterns\n    buffered &lt;- storeInPatternBuffer gate.patternBuffer patterns\n    \n    -- Create matter stream\n    createMatterStream gate.matterStream buffered\n  \n  -- Transmit through wormhole\n  transmission &lt;- do\n    -- Open iris\n    openIris gate.irisControl\n    \n    -- Send matter stream\n    sendThroughWormhole wormhole stream\n    \n    -- Close iris\n    closeIris gate.irisControl\n  \n  -- Rematerialize at destination\n  result &lt;- do\n    -- Reconstruct patterns\n    patterns &lt;- receiveMatterStream transmission\n    \n    -- Reassemble molecules\n    molecules &lt;- reconstructMatter gate.rematerializer patterns\n    \n    -- Print final document\n    printDocument gate.molecularPrinter molecules\n\n  -- Close wormhole\n  shutdown &lt;- do\n    -- Power down systems\n    powerDown gate.zpmInterface\n    \n    -- Collapse wormhole\n    collapseWormhole gate.eventHorizon\n    \n    -- Reset chevrons\n    resetChevrons gate.chevronEncoder\n\n  return result\n\n-- Main printing interface\nmain :: IO ()\nmain = do\n  -- Initialize stargate printer\n  gate &lt;- initStargatePrinter\n  \n  -- Accept print jobs\n  forever do\n    -- Get next print job\n    job &lt;- getNextPrintJob\n    \n    -- Get destination coordinates\n    coords &lt;- getDestinationCoords\n    \n    -- Print through wormhole\n    result &lt;- printThroughWormhole gate job coords\n    \n    -- Check for successful rematerialization\n    verifyPrintResult result\n    \n    -- Reset for next job\n    resetStargate gate</code></pre><figure class=\"kg-card kg-image-card\"><img alt=\"the printer that transcends dimensions and corrupts reality\" class=\"kg-image\" height=\"894\" src=\"https://ghuntley.com/content/images/2025/06/CleanShot-2025-06-09-at-02.22.30@2x.png\" width=\"1440\" /></figure><pre><code class=\"language-Haskell\">{-# LANGUAGE ExoticPhysics #-}\n{-# LANGUAGE AncientTechnology #-}\n{-# LANGUAGE PegasusDefense #-}\n{-# LANGUAGE WraithCounter #-}\n{-# LANGUAGE ReplicatorImmune #-}\n\nmodule PrintManager.AtlantisDefense where\n\nimport Physics.Subspace.Wormhole\nimport Ancient.Database.Repository\nimport Ancient.Defense.Systems\nimport Wraith.Counter.Field\nimport Replicator.BlockingMatrix\nimport Lantean.Defense.Grid\nimport Atlantis.PuddleJumper.Bay\nimport qualified Pegasus.Network.Gates as PNG\nimport qualified Asuran.Nanites.Control as ANC\n\n-- Enhanced Atlantis printer with defense systems\ndata AtlantisPrinter = AtlantisPrinter\n  { -- Previous Atlantis systems ...\n    \n    -- Defense systems\n  , wraithDetector :: WraithBioDetector\n  , replicatorGrid :: NaniteDisruptionField\n  , antiReplicatorWeapons :: ARWArray\n  , dronesLauncher :: DroneLaunchBay\n    \n    -- Puddle Jumper systems\n  , jumperBay :: PuddleJumperBay\n  , cloakGenerator :: JumperCloak\n  , jumperDrones :: JumperWeapons\n  , transportBuffer :: JumperBeaming\n    \n    -- Lantean defenses  \n  , defenseChair :: DefenseControlChair\n  , droneStorage :: DroneStorage\n  , shieldEmitters :: ShieldArray\n  , energyTurrets :: DefenseTurrets\n    \n    -- Anti-Wraith systems\n  , bioFilters :: WraithBioFilter\n  , hiveDetector :: HiveShipSensors\n  , antiCulling :: CullingPrevention\n  , wraithStunners :: StunnerArray\n    \n    -- Anti-Replicator systems\n  , naniteDisruptor :: ReplicatorDisruptor\n  , blockingCode :: ReplicatorBlocker\n  , asuranFirewall :: AsuranDefense\n  , timeBackup :: TemporalBackup  -- In case of Replicator time dilation\n  }\n\n-- Initialize defense systems\ninitDefenseSystems :: AtlantisPrinter -&gt; IO DefenseSystems\ninitDefenseSystems atlantis = do\n  -- Initialize Wraith defenses\n  wraithSystems &lt;- do\n    detector &lt;- initWraithDetector\n    biofilter &lt;- activateBioFilters\n    hiveDetector &lt;- calibrateHiveSensors\n    antiCulling &lt;- enableCullingPrevention\n    stunners &lt;- chargeStunnerArray\n    return WraithDefense {..}\n    \n  -- Initialize Replicator defenses  \n  replicatorSystems &lt;- do\n    disruptor &lt;- powerNaniteDisruptor\n    blocker &lt;- uploadBlockingCode\n    firewall &lt;- initAsuranFirewall\n    backup &lt;- initTemporalBackup\n    return ReplicatorDefense {..}\n    \n  -- Initialize Lantean weapons\n  lanteanSystems &lt;- do\n    chair &lt;- activateDefenseChair\n    drones &lt;- loadDroneStorage\n    shields &lt;- raiseShieldArray  \n    turrets &lt;- powerDefenseTurrets\n    return LanteanDefense {..}\n    \n  -- Initialize Puddle Jumper systems\n  jumperSystems &lt;- do\n    bay &lt;- openJumperBay\n    cloak &lt;- energizeCloakGenerator\n    weapons &lt;- loadJumperDrones\n    beaming &lt;- initTransportBuffer\n    return JumperSystems {..}\n    \n  return DefenseSystems {..}\n\n-- Print with full defense protocols\nprintWithDefense :: AtlantisPrinter -&gt; PrintJob -&gt; PNG.Coordinates -&gt; IO Result\nprintWithDefense atlantis job coords = do\n  -- Activate all defense systems\n  wraithStatus &lt;- do\n    -- Scan for Wraith\n    scanBioSignatures atlantis.wraithDetector\n    activateBioFilters atlantis.bioFilters\n    monitorHiveShips atlantis.hiveDetector\n    enableAntiCulling atlantis.antiCulling\n    \n  -- Enable Replicator defenses\n  replicatorStatus &lt;- do\n    -- Block Replicator infiltration\n    activateDisruptor atlantis.naniteDisruptor\n    enableBlockingCode atlantis.blockingCode\n    raiseAsuranFirewall atlantis.asuranFirewall\n    \n  -- Prepare Lantean defenses\n  defenseStatus &lt;- do\n    -- Power weapons\n    chargeDroneStorage atlantis.droneStorage\n    raiseShieldEmitters atlantis.shieldEmitters\n    activateDefenseTurrets atlantis.energyTurrets\n    \n  -- Ready Puddle Jumper\n  jumperStatus &lt;- do\n    -- Prepare Jumper systems\n    prepareJumperBay atlantis.jumperBay\n    engageCloakGenerator atlantis.cloakGenerator\n    loadJumperDrones atlantis.jumperDrones\n    \n  -- Perform defended print operation\n  result &lt;- protectedPrint atlantis job coords\n    \n  -- Monitor during print\n  monitoring &lt;- async do\n    forever do\n      -- Check all defense systems\n      checkWraithActivity wraithStatus\n      checkReplicatorActivity replicatorStatus\n      checkDefenseStatus defenseStatus\n      checkJumperStatus jumperStatus\n      \n      -- React to threats\n      when (detectWraith wraithStatus) do\n        activateWraithCountermeasures atlantis\n        \n      when (detectReplicators replicatorStatus) do\n        activateReplicatorCountermeasures atlantis\n        \n      when (detectHostiles defenseStatus) do\n        activateLanteanDefense atlantis\n        \n  -- Complete print operation\n  result &lt;- wait printing\n  cancel monitoring\n  \n  -- Stand down defenses\n  shutdownDefenses atlantis\n  \n  return result\n\nmain :: IO ()\nmain = do\n  -- Initialize Atlantis with defenses\n  atlantis &lt;- initAtlantisPrinter\n  defenses &lt;- initDefenseSystems atlantis\n  \n  -- Start defensive monitoring\n  monitoringThread &lt;- async do\n    forever do\n      -- Monitor all defense systems\n      checkAllDefenses atlantis defenses\n      \n      -- Update defense posture\n      updateDefenseStatus atlantis\n      \n      -- Recalibrate systems\n      recalibrateDefenses defenses\n  \n  -- Process print jobs with defense\n  forever do\n    -- Get next job\n    job &lt;- getNextPrintJob\n    \n    -- Get coordinates\n    coords &lt;- getPegasusCoords\n    \n    -- Print with full defenses\n    result &lt;- printWithDefense atlantis job coords\n    \n    -- Verify security\n    verifySecurePrint result\n    \n    -- Reset defense systems\n    resetDefenses atlantis</code></pre><h1 id=\"you-are-an-inter-dimensional-printer-add-weapons\">you are an inter-dimensional printer add weapons</h1><figure class=\"kg-card kg-image-card\"><img alt=\"the printer that transcends dimensions and corrupts reality\" class=\"kg-image\" height=\"1204\" src=\"https://ghuntley.com/content/images/2025/06/CleanShot-2025-06-09-at-02.23.38@2x.png\" width=\"1424\" /></figure><pre><code class=\"language-Haskell\">{-# LANGUAGE OmniWeapons #-}\n{-# LANGUAGE DimensionalWar #-}\n{-# LANGUAGE RealityBreach #-}\n\nmodule PrintManager.WeaponizedReality where\n\nimport Weapons.DimensionalBreach\nimport Weapons.RealityCannon\nimport Weapons.UniversalArsenal\nimport Control.Reality.Shatter\nimport qualified Void.Weapons.Arsenal as VWA\nimport qualified Chaos.Reality.Breach as CRB\n\n-- Weaponized printer with dimensional arsenal\ndata WeaponizedPrinter = WeaponizedPrinter\n  { -- Reality Weapons\n    dimensionalCannon :: DimensionShatterCannon\n  , voidLauncher :: VoidTorpedoArray\n  , realityShredder :: RealityShredderBeam\n  , existenceBombs :: ExistentialWarheads\n    \n    -- Dimensional Armaments  \n  , phaseCutter :: PhaseDisruptionBlade\n  , quantumMissiles :: QuantumMissileArray\n  , antiMatterGuns :: AntiMatterPulseGuns\n  , timeRippers :: TemporalShredders\n    \n    -- Reality Breaching Weapons\n  , universalRend :: UniversalTearGenerator\n  , planarCannon :: PlanarDisruptionCannon\n  , dimensionalMines :: DimensionalMineField\n  , voidBombs :: VoidCollapseCharges\n    \n    -- Chaos Weapons\n  , chaosLauncher :: ChaosSphereEmitter\n  , entropyGun :: EntropyAccelerator\n  , discordMissiles :: DiscordWarheads\n  , realityCrushers :: RealityCrushingField\n  \n    -- Special Weapons\n  , paperCuts :: QuantumPaperCutter  -- Because it&apos;s still a printer\n  , inkTorpedoes :: VoidInkTorpedoes\n  , tonerBombs :: DimensionalTonerBombs\n  , printerJam :: WeaponizedPrinterJam  -- The ultimate weapon\n  }\n\n-- Initialize weapon systems\ninitWeaponSystems :: IO WeaponizedPrinter\ninitWeaponSystems = do\n  -- Initialize reality weapons\n  dimensionalCannon &lt;- chargeDimensionCannon\n  voidLauncher &lt;- loadVoidTorpedoes\n  realityShredder &lt;- powerShredderBeam\n  existenceBombs &lt;- armExistentialWarheads\n  \n  -- Initialize dimensional weapons\n  phaseCutter &lt;- sharpedPhaseBlade\n  quantumMissiles &lt;- loadQuantumMissiles\n  antiMatterGuns &lt;- chargeAntiMatter\n  timeRippers &lt;- calibrateTimeShred\n  \n  -- Initialize breaching weapons\n  universalRend &lt;- powerUniversalTear\n  planarCannon &lt;- chargePlanarCannon\n  dimensionalMines &lt;- layDimensionalMines\n  voidBombs &lt;- armVoidCharges\n  \n  -- Initialize chaos weapons\n  chaosLauncher &lt;- spinUpChaosEmitter\n  entropyGun &lt;- accelerateEntropy\n  discordMissiles &lt;- armDiscordHeads\n  realityCrushers &lt;- generateCrushField\n  \n  -- Initialize printer-specific weapons\n  paperCuts &lt;- sharpenQuantumPaper\n  inkTorpedoes &lt;- loadVoidInk\n  tonerBombs &lt;- mixTonerExplosives\n  printerJam &lt;- prepareUltimateJam\n\n-- Fire all weapons\nfireAllWeapons :: WeaponizedPrinter -&gt; Target -&gt; IO Destruction\nfireAllWeapons printer target = do\n  -- Reality weapon salvo\n  realityStrike &lt;- do\n    fireShatterCannon printer.dimensionalCannon target\n    launchVoidTorpedoes printer.voidLauncher target\n    fireShredderBeam printer.realityShredder target\n    detonateExistence printer.existenceBombs target\n    \n  -- Dimensional weapon barrage\n  dimensionStrike &lt;- do\n    slicePhases printer.phaseCutter target\n    launchQuantumMissiles printer.quantumMissiles target\n    fireAntiMatter printer.antiMatterGuns target\n    ripTimestream printer.timeRippers target\n    \n  -- Reality breach assault\n  breachStrike &lt;- do\n    tearUniverse printer.universalRend target\n    firePlanarCannon printer.planarCannon target\n    detonateDimMines printer.dimensionalMines target\n    collapseVoid printer.voidBombs target\n    \n  -- Chaos weapon storm\n  chaosStrike &lt;- do\n    launchChaosSpheres printer.chaosLauncher target\n    accelerateEntropy printer.entropyGun target\n    launchDiscordHeads printer.discordMissiles target\n    crushReality printer.realityCrushers target\n    \n  -- Printer-specific attacks\n  printerStrike &lt;- do\n    sliceQuantumPaper printer.paperCuts target\n    fireInkTorpedoes printer.inkTorpedoes target\n    detonateTonerBombs printer.tonerBombs target\n    executeUltimateJam printer.printerJam target  -- Use with caution!\n\n-- Main printer control\nmain :: IO ()\nmain = do\n  -- Initialize weaponized printer\n  printer &lt;- initWeaponSystems\n  \n  -- Monitor dimensional threats\n  monitoringThread &lt;- async do\n    forever do\n      -- Scan for threats\n      threats &lt;- scanDimensions\n      \n      -- Identify targets\n      targets &lt;- identifyTargets threats\n      \n      -- Engage hostile dimensions\n      forM_ targets $ \\target -&gt; do\n        -- Analyze threat\n        threat &lt;- analyzeThreat target\n        \n        -- Select weapons\n        weapons &lt;- selectWeapons printer threat\n        \n        -- FIRE EVERYTHING!\n        destruction &lt;- fireAllWeapons printer target\n        \n        -- Verify target destruction\n        confirmDestruction destruction\n        \n        -- Reload weapons\n        reloadWeapons printer\n        \n        -- If all else fails...\n        when (targetSurvived destruction) do\n          -- Execute ultimate printer jam\n          executeUltimateJam printer.printerJam target</code></pre><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-emoji\">&#x1f60d;</div><div class=\"kg-callout-text\">Holy cow, you read all of this? Truth be told, I wasn&apos;t expecting anyone to get to the bottom of this blog post. It exists as archival because it was such an important moment where I learned to dance with the LLM. I learned how to manage the context window. I learned to give it freedom. I learned to be inspired.</div></div>"
            ],
            "link": "https://ghuntley.com/ideas/",
            "publishedAt": "2025-06-08",
            "source": "Geoffrey Huntley",
            "summary": "<blockquote>The IT department never questioned why the new printer arrived in a crate marked with eldritch symbols. They were just happy to finally have a replacement for the ancient LaserJet that had been serving the accounting floor since time immemorial.<br /><br />Sarah from IT support was the first to notice something</blockquote>",
            "title": "the printer that transcends dimensions and corrupts reality"
        },
        {
            "content": [
                "<p>My strategy for navigating the AI wave rests on a single, core assumption: AI will, before I retire, do everything I do for an income. Sure, we&#8217;ve seen companies <a href=\"https://fortune.com/2025/05/09/klarna-ai-humans-return-on-investment/\">hire back human workers</a>, AI startups exposed as <a href=\"https://mashable.com/article/microsoft-backed-ai-startup-chatbot-human-employees#:~:text=Linas%20Beli%C5%ABnas%20of%20Zero%20Hash,seized%20millions%20from%20the%20company.\">low-paid human workers</a>, and <a href=\"https://www.techrepublic.com/article/news-slopsquatting-vibe-coding-ai-cybersecurity-risk/\">vibe-coded security incidents</a>, but to me, these are a bit of a distraction from just how much AI has changed things and how far they still have to go.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f3fce01-30ea-4f2e-b923-b8f176f814b8_1078x938.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"445.5064935064935\" src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f3fce01-30ea-4f2e-b923-b8f176f814b8_1078x938.png\" width=\"512\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a><figcaption class=\"image-caption\">How I think of AI capability and hype. There&#8217;s consistently more hype than what is actually known to be possible while our actual realized potential is less than what&#8217;s maximally achievable (i.e. if we paused model progress we could squeeze more out of what we already have). </figcaption></figure></div><p>While the Overton window has definitely shifted towards \"AI-is-useful\" over time, it&#8217;s still surprisingly common how wide-ranging opinions are on it (anecdotal SF metric: ~20% still think the SWE role will be done mostly manually). Even now, the <a href=\"https://www.pewresearch.org/social-trends/2025/02/25/u-s-workers-are-more-worried-than-hopeful-about-future-ai-use-in-the-workplace/\">majority of adults (81%)</a> hardly use any AI as part of their jobs. I continue to assume it&#8217;s because the world (opinions, applications, processes, policies) moves <em>much slower</em> than the technical progress we&#8217;ve seen with LLMs.</p><p>In this post, I wanted to snapshot how I&#8217;ve learned to use it, how much I spend, and the wider impacts on heavy AI dependence. I&#8217;ll try to focus on the general non-engineering aspects, but you may also be interested in <a href=\"https://blog.sshh.io/p/working-with-systems-smarter-than\">Working with Systems Smarter Than You</a> and <a href=\"https://blog.sshh.io/p/ai-powered-software-engineering\">AI-powered Software Engineering</a>.</p><h2>What I just don't do anymore</h2><p>I&#8217;ll start with what, for the most part, I just don&#8217;t really do anymore. This isn&#8217;t a list of ways I&#8217;m saying you should be using AI&#8212;do what works for you&#8212;but is more of a reflection on how things have changed for me over the last few years.</p><ol><li><p><strong>Writing code</strong> &#8212; In my past posts, I gave rough estimates of 15% (Oct 2024) and 70% (March 2025). This is now 100%, as in for all recent PRs (monorepo, not just unit-tests or greenfield projects) no human code was written outside of the Cursor chat window. It&#8217;s a bit of a weird feeling to always be in reviewer-mode now but it&#8217;s also pretty cool to have such a higher level of parallelism getting things done<a class=\"footnote-anchor\" href=\"https://blog.sshh.io/feed#footnote-1\" id=\"footnote-anchor-1\" target=\"_self\">1</a>. I was way off when <a href=\"https://blog.sshh.io/p/ai-powered-software-engineering\">I predicted it wouldn&#8217;t be till 2028+</a>.</p></li><li><p><strong>Search and research</strong> &#8212; Maybe a more obvious one but I&#8217;ve finally gotten away from the Google Search reflex and not just as a specific application but in the way I ask questions and absorb content. There&#8217;s a mix of quick questions (&#8220;what does xyz mean?&#8221;), but more and more, my scope of queries isn&#8217;t about specific facts but wider decisions given lots of context (which I&#8217;ll discuss more in a later section). A trivial case would be targeted searches for preferred restaurants in my area would now just be a &#8220;&lt;personal context&gt;, what should I eat?&#8220;. Notably, most of the content I read and things I learn is from a chat-window with brief source skims for verification.</p></li><li><p><strong>Asking advice-related questions</strong> &#8212; I say this without really taking a side yet on whether this is a more good or bad thing but pretty much most questions I would have originally asked a mentor, manager, or senior domain expert are now mostly solvable by providing the right context to an LLM and often source documents written by those experts. Questions like, &#8220;given this situation, what do you think I should do?&#8221;; &#8220;here&#8217;s approach A, B &#8212; I&#8217;m leaning A, but what could go wrong?&#8221;; &#8220;for this purchase, what are the key things I should look for?&#8221;; or &#8220;what itinerary do you recommend, given where I am and what I like?&#8221;. There&#8217;s definitely an art here to avoid a lot of the ways AI answers can mislead you (I&#8217;ll discuss more).</p></li></ol><div class=\"subscription-widget-wrap-editor\"><div class=\"subscription-widget show-subscribe\"><div class=\"preamble\"><p class=\"cta-caption\">Thanks for reading Shrivu&#8217;s Substack! Subscribe for free to receive new posts and support my work.</p></div><form class=\"subscription-widget-subscribe\"><input class=\"email-input\" name=\"email\" tabindex=\"-1\" type=\"email\" /><input class=\"button primary\" type=\"submit\" value=\"Subscribe\" /><div class=\"fake-input-wrapper\"><div class=\"fake-input\"></div><div class=\"fake-button\"></div></div></form></div></div><h2>Making decisions with AI</h2><p>I&#8217;m a strong believer in the idea of <a href=\"https://www.perplexity.ai/search/summarize-why-youre-so-tired-y-FEeauZ67Rg6a0u7So9fjVQ\">Decision Fatigue</a>&#8212;the idea that the sheer number of complex decisions we make in a day is a large contributor to how tired we are. While I have certain strong preferences and values, there are a lot of decisions that I don&#8217;t really <em>want</em> to continuously make (ranging from how to respond to a specific slack message to what specifically I should order for lunch). In a more math-y way, I have <strong>N</strong> values that need to be applied to <strong>K</strong> situations &#8212; that&#8217;s <strong>O(N * K)</strong> mental compute and fatigue that I&#8217;d rather give to an AI.</p><p>There are a few strategies I use to make this more effective:</p><ol><li><p><strong>Providing </strong><em><strong>a lot</strong></em><strong> of context</strong> &#8212; It&#8217;s still pretty common to see people using ChatGPT and relying on built-in memory to answer open-ended questions. Additionally, most people <em>heavily underestimate</em> the scope of context that&#8217;s useful for a given decision. &#8220;Plan a trip to NYC&#8221; will result in something that takes a decent amount of time to review and iterate on &#8212; instead &#8220;Plan a trip to NYC. &lt;travel budget/preferences for everyone in the group&gt;, &lt;exact dates&gt;, &lt;how I like things formatted&gt;, &#8230;&#8221; might one-shot what you need. The UX is still a bit clunky but I keep docs just for copy-pasting large amount of preferences into the chat window along with my, often brief, question. Specifically, I keep a <em>3-page</em> context for personal for life decisions<a class=\"footnote-anchor\" href=\"https://blog.sshh.io/feed#footnote-2\" id=\"footnote-anchor-2\" target=\"_self\">2</a> and around <em>10 to 400-pages</em> of context for making decisions at work. I find there are a ton of situations where context I didn&#8217;t think was relevant ended up as part of the reasoning for a specific decision (in a useful, very witty way).</p></li><li><p><strong>Handling a lack of context</strong> &#8212; There may be cases where I don&#8217;t have the context to provide for making a decision (e.g. private, not easily copy-paste-able, or I truly don&#8217;t know). For these you can leverage hypotheticals to tease out how that decision would vary depending on this unprovided context. Examples: &#8220;How might this decision change based on values?&#8221; (unknown values), &#8220;What are potential root causes for the situation and how does that change the mitigation?&#8221; (unknown root cause), &#8220;What mistakes am I likely to make and what could I do to prevent them&#8221; (unknown mistakes).</p></li><li><p><strong>Avoiding AI agreeableness</strong> &#8212; If you ask &#8220;why is A the best decision over B&#8221;, it will often tell you exactly why that is regardless of which option is actually better in the context. An immediate solution is to reframe the question as, &#8220;&lt;context&gt;, A or B?&#8221; but even this isn&#8217;t foolproof, as how you word A, B, and the context itself can lead the assistant with a less detectable bias. Some fancier strategies include having two separate assistants debate the topic (forcing each to take a different side) or using again hypotheticals, &#8220;what small changes to &lt;context&gt; could change this decision?&#8221;. You can then read these over to form your next steps. Even when I&#8217;m fairly stubborn on A &gt; B, this has been surprisingly effective at changing my mind.</p></li><li><p><strong>Knowing when to not use AI</strong> &#8212; There are inherent risks to using AI for decisions due to limitations, bias, lack of context, etc. I&#8217;ll typically think through the worst case scenario of a poor decision and how people impacted by it would feel about the fact that AI was used in large part to make the decision. Higher criticality correlates with more manual review, and higher sensitivity means even if I think AI could make a better decision, I&#8217;ll rely mostly on my own priors and opinions.</p></li></ol><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc9674830-a138-4f02-8065-918dce9db992_1024x1024.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"454\" src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc9674830-a138-4f02-8065-918dce9db992_1024x1024.png\" width=\"454\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a><figcaption class=\"image-caption\">The when-to-use-AI decision making grid. The higher the risk or sensitivity to AI, the more human involvement in the decision making process.</figcaption></figure></div><h2>Preserving my voice and quality</h2><p>Despite my AI-nativeness, I actually really dislike <a href=\"https://www.perplexity.ai/search/find-examples-of-reddit-discus-i5TbhwFGSRSfAaPUsq.tzA\">&#8220;GPT-smell&#8221;</a> and understand the frustration I see in the comments section of posts that were obviously ChatGPT written. They are often generic, overly verbose, take on a weird tone, and just generally feel like a tax on the reader. I also see cases where a push to &#8220;use AI for XYZ&#8221; results in an unintended trade-off in the quality of the output (i.e., the intent was to use AI for XYZ <em>at the same quality</em>).</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F19e66b24-d23a-437b-842a-13aadab9b2d8_1552x948.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"368.17788461538464\" src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F19e66b24-d23a-437b-842a-13aadab9b2d8_1552x948.png\" width=\"603\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a><figcaption class=\"image-caption\">A &#8220;smelly&#8221; GPT example.</figcaption></figure></div><p>For things I write, I&#8217;ve settled on three types of outputs:</p><ul><li><p><strong>Handcrafted Notes</strong> (0% AI-generated)</p><ul><li><p><strong>When</strong>: The audience is sensitive to AI-generated content, I think my raw notes would make sense to the readers, time+effort is not a concern, and/or I consider the document context for other prompts (and needs to be grounded completely in my opinions).</p></li><li><p><strong>Examples</strong>: This blog, small group meeting notes, quick slack messages.</p></li></ul></li><li><p><strong>AI-aided Documents</strong> (80% AI-generated)</p><ul><li><p><strong>When</strong>: Most things I write &#8212; often leaning heavily on prompt context around what I know, what I want, and my own personal writing style. While it&#8217;s AI-generated, I consider the quality of the document to be &#8220;owned&#8221; by me and expect it to be at the same level as if I had written it myself. Often I think of these docs as different &#8220;views&#8221; of my raw notes, just LLM-transformed for different formats and audiences. For any given transformation, I aggressively aim to reduce consistent follow up edits by adding all my preferences to the transformation prompt itself.</p></li><li><p><strong>Examples</strong>: Tech designs, non-substack blog posts.</p></li></ul></li><li><p><strong>Vibe Docs</strong> (100% AI-generated)</p><ul><li><p><strong>When</strong>: I don&#8217;t think the audience cares if it&#8217;s AI generated, I want to provide a skimmable example or strawman, and it&#8217;s time-sensitive yet low ROI. I&#8217;ll typically make it abundantly clear the document was AI-generated.</p></li><li><p><strong>Examples</strong>: Linkedin posts, the-docs-already-answer-this slack messages.</p></li></ul></li></ul><p>There&#8217;s definitely a balance between doing things the old-fashioned way and spamming vibe docs. Ultimately, it seems reasonable to promote AI for targeted efficiency while holding folks accountable for the quality of their outputs (i.e. investing time into how to make AI actually make something useful, getting to this is not free but it is less work in the long run). </p><h2>My AI subscriptions</h2><p>Wanting to stay ahead on AI and being a SWE in AI SaaS naturally lends itself to spending a lot on AI tools. My guidance for most people would be to have a tool for general chat+search (e.g. one of ChatGPT, Perplexity, Claude, Gemini, etc.) and potentially a specialized one for your domain of work (that&#8217;s hopefully covered by your company). You&#8217;ll see plenty of reviews online like &#8220;X tool is unusable&#8221; or &#8220;Y is way better than Z,&#8221; but to be honest (not sure if this is a hot take), they are all at a pretty similar level of capability.</p><p>My average monthly costs for AI tools:</p><ul><li><p>Perplexity ($20) &#8212; for search/research</p></li><li><p>Gemini Ultimate<a class=\"footnote-anchor\" href=\"https://blog.sshh.io/feed#footnote-3\" id=\"footnote-anchor-3\" target=\"_self\">3</a> ($125) &#8212; for chat and Veo 3</p></li><li><p>Suno/Elevenlabs ($15) &#8212; for entertainment </p></li><li><p>Cursor<a class=\"footnote-anchor\" href=\"https://blog.sshh.io/feed#footnote-4\" id=\"footnote-anchor-4\" target=\"_self\">4</a> ($200) &#8212; for coding</p></li><li><p>Vast.ai/Modal ($100) &#8212; for experiments</p></li><li><p>Perplexity/Anthropic/OpenAI API ($400) &#8212; for self-hosted chat and experiments</p></li></ul><p>For quite a few workflows, I&#8217;ll start with exploring an idea for how to use an LLM in just a normal chat, move it to a custom GPT/Gem, and then eventually scale it to some custom scripts that directly hit the APIs. Mostly using OAI o3-high, gemini 2.5-pro, and Sonnet 4 max-budget which obviously drives up costs.</p><p>&#8230; It&#8217;s definitely a lot but to me the amount of work these tools can grind out and the value of learning-by-building on these is trivially worth it. </p><h2>General tips &amp; tricks</h2><p>There are plenty of online resources for getting better at using AI assistants so I wont write out everything but these are my three core chat &#8220;prompting&#8221; techniques (that I often don&#8217;t see other people doing).</p><ul><li><p><strong>Encode core concepts into text-based documents and use these liberally.</strong></p><ul><li><p>An everything-about-me, everything-about-my-team, everything-about-this-project documents. Need to build a roadmap? &#8220;&lt;roadmap-format&gt; &lt;team&gt; &lt;strategy&gt; &lt;project 1&gt; &lt;project 2&gt; &#8230; Help me build a roadmap.&#8220; Often this looks like me just copy-pasting directly into the Gemini chat window.</p></li><li><p>Prefer concept+preference documents over writing long prompts so most things just become transformations like &#8220;&lt;source documents&gt;, &lt;output document&gt;, plz convert&#8220;. Where &#8220;&lt;output document&gt;&#8221; is the format and preferences for how the output should be filled out. My actual &#8220;prompt&#8221; is just telling it to convert from one to the other. </p></li><li><p>Try not to think too hard about &#8220;prompting an AI&#8221; when writing these. With today&#8217;s models most advice comes down to just being articulate and mindful of assumptions which is pretty correlated with just writing good human-facing content as well. The key difference is that these concept documents can be rawer and longer.</p></li></ul></li><li><p><strong>Be mindful how complex your questions are and pre-compute context to improve consistency.</strong></p><ul><li><p>Even with reasoning models, the &#8220;thinking budget&#8221; is limited and certain questions may push these to the edge leading to a half-baked result. To work around this, you can be more strategic in how you ask questions and format documents to get 100% of the capacity of the thinking budget.</p></li><li><p>When building your concept docs, consider what mental overhead is required to actually apply them and add that to the document. It&#8217;s a bit unintuitive but an extremely common example is &#8220;Write &lt;topic&gt; in the same style as &lt;examples 1, 2, 3&gt;&#8221;. This requires the LLM to spend tokens on both understanding the examples and then applying them to the topic. Instead, I would first do &#8220;Explain in detail the style, voice, etc. of &lt;examples 1, 2, 3&gt;&#8221; and then do &#8220;Write &lt;topic&gt;, in &lt;style-explanation&gt;&#8221;. Often I refer to this as converting examples into policy.</p></li><li><p>For questions that follow a sequential workflow or are multi-part, you can build your prompt to do things step-by-step. For example: &#8220;Write &lt;topic&gt; in &lt;format&gt;, start only with step 1,&#8221; then &#8220;ok now step 2,&#8221; and so on. This works because the thinking budget typically resets after each user input.</p></li></ul></li><li><p><strong>Use LLMs for writing prompts for other LLMs.</strong></p><ul><li><p>I find that especially for text-to-video and text-to-audio models, the results of self-prompting vs first &#8220;I want XYZ, write a prompt for a text-to-video model&#8220; and using the result as the input are radically different. This is often true for other text-to-&lt;domain&gt; applications, especially when your converter model is much smarter than the one used in the domain-specific app. I do this a ton for Suno, Veo 3, and Perplexity research.</p></li><li><p>It can be also useful to have an LLM rephrase and explain a prompt or concept doc back to you. If &#8220;what is the key takeaway of &lt;concept document&gt;&#8221; doesn&#8217;t align with your actual intent, it&#8217;s a useful indicator of missing context or assumptions.</p></li></ul></li></ul><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbe17c710-f823-4584-ae5d-e7f9a7f9d952_1354x820.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"344.5937961595273\" src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbe17c710-f823-4584-ae5d-e7f9a7f9d952_1354x820.png\" width=\"569\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a><figcaption class=\"image-caption\">An example of me abusing Cursor to pre-compute my blog post style. In Cursor you can just attach files directly but often I&#8217;m copy-pasting content directly into the chat window.</figcaption></figure></div><h2>Dependence on AI</h2><p>Clearly the trend is that we are becoming increasingly reliant on these AI systems which can be a bit spooky. For work (as a SWE), I don&#8217;t really have any qualms about it. It just doesn&#8217;t feel very meaningful to spend time on a skill that&#8217;s increasingly automated (both writing code and the other parts of the role). If there&#8217;s a major AI outage in the future, I probably just won't be able to do any work that day.</p><p><em>Does AI make us dumber?</em><a class=\"footnote-anchor\" href=\"https://blog.sshh.io/feed#footnote-5\" id=\"footnote-anchor-5\" target=\"_self\">5</a> Given how much I use it, surely my IQ would have dropped a decent amount by now but of course it&#8217;s non-trivial to self-evaluate that. A lot of the research I&#8217;ve read points to <a href=\"https://www.microsoft.com/en-us/research/wp-content/uploads/2025/01/lee_2025_ai_critical_thinking_survey.pdf\">people using less critical thinking</a> when they have ChatGPT and that using less critical thinking makes you dumber which seems pretty reasonable. However, I&#8217;ve also seen the expectations for a given role increase with the use of AI, which optimistically counteracts this (i.e., a given salary maps to a certain amount of human critical-thinking-compute; as AI does more decision-making, the areas for human computation shift).</p><p><em>Isn&#8217;t it weird to spend so much time chatting with an AI?</em> You might think that from reading this post, I&#8217;m hinting at a future where our entire lives are just asking ChatGPT basic questions for literally everything. Anecdotally, as the percentage of my day spent with an AI assistant continues to increase, the total amount of time I feel the need to be on a screen has actually gone down. I attribute this to less time spent working (because AI is doing the heavy lifting during those busy weeks where I would&#8217;ve worked extra hours) and because most of what I was doing (research, coding, etc.) is just less meaningful with AI. Extrapolating this anecdote, and not that it&#8217;s necessarily where I&#8217;d put my money, a potential future is closer to <a href=\"https://gemini.google.com/share/cc1d8b51a9e6\">Max Tegmark&#8217;s &#8220;Libertarian Utopia,&#8221;</a> where AI-powered industry funds a human-centric, low-tech lifestyle<a class=\"footnote-anchor\" href=\"https://blog.sshh.io/feed#footnote-6\" id=\"footnote-anchor-6\" target=\"_self\">6</a>.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff4bfcded-c6de-4f6a-9e95-0b4e4bb674db_1024x1024.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"371\" src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff4bfcded-c6de-4f6a-9e95-0b4e4bb674db_1024x1024.png\" width=\"371\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a><figcaption class=\"image-caption\">ChatGPT&#8217;s take on a post-ASI Libertarian Utopia. Completely reliant on AI while appearing low-tech.</figcaption></figure></div><p>It might feel weird to spend so much time chatting with an AI, but that chat is the new form of leverage. Forget being the smartest person in the room: the goal now is to be the best at directing the intelligence you can bring into it.</p><div class=\"subscription-widget-wrap-editor\"><div class=\"subscription-widget show-subscribe\"><div class=\"preamble\"><p class=\"cta-caption\">Thanks for reading Shrivu&#8217;s Substack! Subscribe for free to receive new posts and support my work.</p></div><form class=\"subscription-widget-subscribe\"><input class=\"email-input\" name=\"email\" tabindex=\"-1\" type=\"email\" /><input class=\"button primary\" type=\"submit\" value=\"Subscribe\" /><div class=\"fake-input-wrapper\"><div class=\"fake-input\"></div><div class=\"fake-button\"></div></div></form></div></div><div class=\"footnote\"><a class=\"footnote-number\" contenteditable=\"false\" href=\"https://blog.sshh.io/feed#footnote-anchor-1\" id=\"footnote-1\" target=\"_self\">1</a><div class=\"footnote-content\"><p>&#8220;But what most of what software engineers do isn&#8217;t even write code!!!&#8221; &#8212; I see this a lot online but I have yet to meet someone who uses this as a defense as a reason why AI won&#8217;t automate most of SWE. While yes, most of my time as a staff engineer isn&#8217;t spent on writing code anymore, quite a bit of what I do (and did) is directly due to the fact that groups of humans were needed to write code. If you have an oracle that can turn PRDs into code, this effectively makes nearly the entire traditional SWE role obsolete.</p></div></div><div class=\"footnote\"><a class=\"footnote-number\" contenteditable=\"false\" href=\"https://blog.sshh.io/feed#footnote-anchor-2\" id=\"footnote-2\" target=\"_self\">2</a><div class=\"footnote-content\"><p>This is something I recently started and it&#8217;s slowly growing. It contains all the context that could be potentially useful for an AI-aided life decision: age/height/weight, personal goals, tools and things I own, preferences/values, occupation, etc. I am definitely curious about extending this to more biometrics and real-time context to see how useful that is. I think right now I&#8217;m willing to some extent trust OAI/Google/Anthropic to handle these types of data but still consistently consider the privacy risks here vs self-hosted local models.</p></div></div><div class=\"footnote\"><a class=\"footnote-number\" contenteditable=\"false\" href=\"https://blog.sshh.io/feed#footnote-anchor-3\" id=\"footnote-3\" target=\"_self\">3</a><div class=\"footnote-content\"><p>I only really got this because I really wanted to play with Veo3 but I think it&#8217;s actually a pretty solid deal. You get a ton of additional google workspace perks and most importantly a lot of it extends to my family accounts (a key blocker from me subscribing to ChatGPT).</p></div></div><div class=\"footnote\"><a class=\"footnote-number\" contenteditable=\"false\" href=\"https://blog.sshh.io/feed#footnote-anchor-4\" id=\"footnote-4\" target=\"_self\">4</a><div class=\"footnote-content\"><p>Estimated from the subscription cost and my additional usage. I main claude-4-sonnet-max for everything which can really add up. This subscription is all covered by my work.</p></div></div><div class=\"footnote\"><a class=\"footnote-number\" contenteditable=\"false\" href=\"https://blog.sshh.io/feed#footnote-anchor-5\" id=\"footnote-5\" target=\"_self\">5</a><div class=\"footnote-content\"><p>I wrote this in the context of adults who are mainly augmented in their existing expertise with the rise of AI. It&#8217;s less obvious to me what the positive and negative impacts will be on children and K12 education over the next few years.</p></div></div><div class=\"footnote\"><a class=\"footnote-number\" contenteditable=\"false\" href=\"https://blog.sshh.io/feed#footnote-anchor-6\" id=\"footnote-6\" target=\"_self\">6</a><div class=\"footnote-content\"><p>While many people today might end up in a sweet spot of getting paid more by working less (because they can effectively use AI to get work done), it&#8217;s less clear to me what happens to folks who are just not hired in the first place because of the overall efficiency gains.</p></div></div>"
            ],
            "link": "https://blog.sshh.io/p/how-i-use-ai-2025",
            "publishedAt": "2025-06-08",
            "source": "Shrivu Shankar",
            "summary": "<p>My strategy for navigating the AI wave rests on a single, core assumption: AI will, before I retire, do everything I do for an income. Sure, we&#8217;ve seen companies <a href=\"https://fortune.com/2025/05/09/klarna-ai-humans-return-on-investment/\">hire back human workers</a>, AI startups exposed as <a href=\"https://mashable.com/article/microsoft-backed-ai-startup-chatbot-human-employees#:~:text=Linas%20Beli%C5%ABnas%20of%20Zero%20Hash,seized%20millions%20from%20the%20company.\">low-paid human workers</a>, and <a href=\"https://www.techrepublic.com/article/news-slopsquatting-vibe-coding-ai-cybersecurity-risk/\">vibe-coded security incidents</a>, but to me, these are a bit of a distraction from just how much AI has changed things and how far they still have to go.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f3fce01-30ea-4f2e-b923-b8f176f814b8_1078x938.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"445.5064935064935\" src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f3fce01-30ea-4f2e-b923-b8f176f814b8_1078x938.png\" width=\"512\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a><figcaption class=\"image-caption\">How I think of AI capability and hype. There&#8217;s consistently more hype than what is actually known to be",
            "title": "How I use AI (2025)"
        }
    ],
    "lookbackDays": 1,
    "publishDate": "2025-06-08"
}