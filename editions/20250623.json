{
    "articles": [
        {
            "content": [
                "<p>A couple of months ago (April 2025), a group of prominent folks released AI 2027, a project that predicted that AGI could plausibly be reached in 2027 and have important consequences. This included a set of <a href=\"https://ai-2027.com/research/\">forecasts</a> and a <a href=\"https://ai-2027.com/\">story</a> for how things might play out. This got a lot of attention. Some was positive, some was negative, but it was almost all very high level.</p>\n\n<p>More recently (June 2025) <a href=\"https://titotal.substack.com/\">titotal</a> released <a href=\"https://titotal.substack.com/p/a-deep-critique-of-ai-2027s-bad-timeline\">a detailed critique</a>, suggesting various flaws in the modeling methodology.</p>\n\n<p>I don\u2019t have much to say about AI 2027 or the critique on a technical level. It would take me at least a couple of weeks to produce an opinion worth caring about, and I haven\u2019t spent the time. But I would like to comment on the discourse. (Because \u201cWhat we need is more commentary on the discourse\u201d, said no one.)</p>\n\n<p>Very roughly speaking, here\u2019s what I remember: First, AI 2027 came out. Everyone cheers. \u201cYay! Amazing!\u201d Then the critique came out. Everyone boos. \u201cTerrible! AI 2027 is not serious! This is why we need peer-review!\u201d</p>\n\n<p>This makes me feel simultaneously optimistic and depressed.</p>\n\n<p>Should AI 2027 have been peer-reviewed? Well, let me tell you a common story:</p>\n\n<ol>\n  <li>\n    <p>Someone decides to write a paper.</p>\n  </li>\n  <li>\n    <p>In the hope of getting it accepted to a journal, they write it in arcane academic language, fawningly cite unrelated papers from everyone who could conceivably be a reviewer, and make every possible effort to hide all flaws.</p>\n  </li>\n  <li>\n    <p>This takes 10\u00d7 longer than it should, results in a paper that\u2019s very boring and dense, and makes all limitations illegible.</p>\n  </li>\n  <li>\n    <p>They submit it to a journal.</p>\n  </li>\n  <li>\n    <p>After a long time, some unpaid and distracted peers give the paper a quick once-over and write down some thoughts.</p>\n  </li>\n  <li>\n    <p>There\u2019s a cycle where the paper is revised to hopefully make those peers happy. Possibly the paper is terrible, the peers see that, and the paper is rejected. No problem! The authors resubmit it to a different journal.</p>\n  </li>\n  <li>\n    <p>Twelve years later, the paper is published. Oh happy day!</p>\n  </li>\n  <li>\n    <p>You decide to read the paper.</p>\n  </li>\n  <li>\n    <p>After fighting your way through the writing, you find something that seems fishy. But you\u2019re not sure, because the paper doesn\u2019t fully explain what they did.</p>\n  </li>\n  <li>\n    <p>The paper cites a bunch of other papers in a way that implies they <em>might</em> resolve your question. So you read those papers, too. It doesn\u2019t help.</p>\n  </li>\n  <li>\n    <p>You look at the supplementary material. It consists of insanely pixelated graphics and tables with labels like <code class=\"language-plaintext highlighter-rouge\">Qetzl_xmpf12</code> that are never explained.</p>\n  </li>\n  <li>\n    <p>In desperation, you email the authors.</p>\n  </li>\n  <li>\n    <p>They never respond.</p>\n  </li>\n  <li>\n    <p>The end.</p>\n  </li>\n</ol>\n\n<p>And remember, peer review is done by <em>peers</em> from the same community who think in similar ways. Different communities settle on somewhat random standards for what\u2019s considered important or what\u2019s considered an error. In much of the social sciences, for example, quick-and-dirty regressions with strongly implied causality are A+ supergood. Outsiders can complain, but they aren\u2019t the ones doing the reviewing.</p>\n\n<p>I wouldn\u2019t say that peer review is worthless. It\u2019s something! Still, call me cynical\u2014you\u2019re not wrong\u2014but I think the number of mistakes in peer-reviewed papers is one to two orders of magnitude higher than generally understood.</p>\n\n<p>Why are there so many mistakes to start with? Well I don\u2019t know if you\u2019ve heard, but humans are fallible creatures. When we build complex things, they tend to be flawed. They <em>particularly</em> tend to be flawed when\u2014for example\u2014people have strong incentives to produce a large volume of \u201csurprising\u201d results, and the process to find flaws isn\u2019t very rigorous.</p>\n\n<p>Aren\u2019t authors motivated by Truth? Otherwise, why choose that life over making lots more money elsewhere? I personally think this is an important factor, and probably the main reason the current system works at all. But still, it\u2019s amazing how indifferent many people are to whether their claims are actually correct. They\u2019ve been in the game so long that all they remember is their <a href=\"https://en.wikipedia.org/wiki/H-index\">h-index</a>.</p>\n\n<p>And what happens if someone spots an error after a paper is published? This happens all the time, but papers are almost never rejected. Nobody wants to make a big deal because, again, <em>peers</em>. Why make enemies? Even when publishing a contradictory result later, people tend to word their criticisms so gently and indirectly that they\u2019re almost invisible.</p>\n\n<p>As far as I can tell, the main way errors spread is: Gossip. This works sorta-OK-ish for academics, because they <em>love</em> gossip and will eagerly spread the flaws of famous papers. But it doesn\u2019t happen for obscure papers, and it\u2019s invisible to outsiders. And, of course, if seeing the flaws requires new ideas, it won\u2019t happen at all.</p>\n\n<p>If peer review is so imperfect, then here\u2019s a little dream. Just imagine:</p>\n\n<ol>\n  <li>\n    <p>Alice develops some ideas and posts them online, quickly and with minimal gatekeeping.</p>\n  </li>\n  <li>\n    <p>Because Alice is a normal human person, there are some mistakes.</p>\n  </li>\n  <li>\n    <p>Bob sees it and thinks something is fishy.</p>\n  </li>\n  <li>\n    <p>Bob asks Alice some questions. Because Alice cares about being right, she\u2019s happy to answer those questions.</p>\n  </li>\n  <li>\n    <p>Bob still thinks something is fishy, so he develops a critique and posts it online, quickly and with minimal gatekeeping.</p>\n  </li>\n  <li>\n    <p>Bob\u2019s critique is friendly and focuses entirely on technical issues, with no implications of bad faith. But at the same time, he pulls no punches.</p>\n  </li>\n  <li>\n    <p>Because Bob is a normal human person, he makes some mistakes, too.</p>\n  </li>\n  <li>\n    <p>Alice accepts some parts of the critique. She rejects other parts and explains why.</p>\n  </li>\n  <li>\n    <p>Carol and Eve and Frank and Grace see all this and jump in with their own thoughts.</p>\n  </li>\n  <li>\n    <p>Slowly, the collective power of many human brains combine to produce better ideas than any single human could.</p>\n  </li>\n</ol>\n\n<p>Wouldn\u2019t that be amazing? And wouldn\u2019t it be amazing if some community developed social norms that encouraged people to behave that way? Because as far as I can tell, that\u2019s approximately what\u2019s happening with AI 2027.</p>\n\n<p>I guess there\u2019s a tradeoff in how much you \u201cpunish\u201d mistakes. Severe punishment makes people defensive and reduces open discussion. But if you\u2019re <em>too</em> casual, then people might get sloppy.</p>\n\n<p>My guess is that different situations call for different tradeoffs. Pure math, for example, might do well to set the \u201cpunishment slider\u201d fairly high, since verifying proofs is easier than creating the proofs.</p>\n\n<p>The best choice also depends on technology. If it\u2019s 1925 and communication is bottlenecked by putting ink on paper, maybe you want to push most of the verification burden onto the original authors. But it\u2019s not 1925 anymore, and surely it\u2019s time to experiment with new models.</p>"
            ],
            "link": "https://dynomight.net/ai2027/",
            "publishedAt": "2025-06-23",
            "source": "Dynomight",
            "summary": "<p>A couple of months ago (April 2025), a group of prominent folks released AI 2027, a project that predicted that AGI could plausibly be reached in 2027 and have important consequences. This included a set of <a href=\"https://ai-2027.com/research/\">forecasts</a> and a <a href=\"https://ai-2027.com/\">story</a> for how things might play out. This got a lot of attention. Some was positive, some was negative, but it was almost all very high level.</p> <p>More recently (June 2025) <a href=\"https://titotal.substack.com/\">titotal</a> released <a href=\"https://titotal.substack.com/p/a-deep-critique-of-ai-2027s-bad-timeline\">a detailed critique</a>, suggesting various flaws in the modeling methodology.</p> <p>I don\u2019t have much to say about AI 2027 or the critique on a technical level. It would take me at least a couple of weeks to produce an opinion worth caring about, and I haven\u2019t spent the time. But I would like to comment on the discourse. (Because \u201cWhat we need is more commentary on the discourse\u201d, said no one.)</p> <p>Very roughly speaking, here\u2019s what I remember: First, AI 2027 came out. Everyone cheers. \u201cYay! Amazing!\u201d Then the critique came out. Everyone boos. \u201cTerrible! AI 2027 is not serious! This is why we need peer-review!\u201d</p> <p>This makes me feel simultaneously optimistic and depressed.</p> <p>Should AI 2027 have been peer-reviewed? Well, let me tell",
            "title": "Thoughts on the AI 2027 discourse"
        },
        {
            "content": [
                "<p>Every few months I put together a guide on which AI system to use. Since I last wrote my guide, however, there has been a subtle but important shift in how the major AI products work. Increasingly, it isn't about the best model, it is about the best overall system for most people. The good news is that picking an AI is easier than ever and you have three excellent choices. The challenge is that these systems are getting really complex to understand. I am going to try and help a bit with both.</p><p>First, the easy stuff.</p><h1>Which AI to Use</h1><p>For most people who want to use AI seriously, you should pick one of three systems: <a href=\"https://claude.ai/\">Claude </a>from Anthropic, Google&#8217;s <a href=\"https://gemini.google.com/\">Gemini</a>, and OpenAI&#8217;s <a href=\"https://chatgpt.com/\">ChatGPT</a>. With all of the options, you get access to both advanced and fast models, a voice mode, the ability to see images and documents, the ability to execute code, good mobile apps, the ability to create images and video (Claude lacks here, however), and the ability to do Deep Research. Some of these features are free, but you are generally going to need to pay $20/month to get access to the full set of features you need. I will try to give you some reasons to pick one model or another as we go along, but you can&#8217;t go wrong with any of them. </p><p>What about everyone else? I am not going to cover specialized AI tools (some people love Perplexity for search, Manus is a great agent, etc.) but there are a few other options for general purpose AI systems: <a href=\"https://x.ai/\">Grok </a>by Elon Musk&#8217;s xAI is good if you are a big X user, though the company has not been very transparent about how its AI operates. Microsoft&#8217;s <a href=\"https://copilot.microsoft.com/\">Copilot </a>offers many of the features of ChatGPT and is accessible to users through Windows, but it can be hard to control what models you are using and when. <a href=\"https://chat.deepseek.com/\">DeepSeek</a> r1, a Chinese model, is very capable and free to use, but is missing a few features from the other companies and it is not clear that they will keep up in the long term. So, for most people, just stick with Gemini, Claude, or ChatGPT</p><p>Great! This was the shortest recommendation post yet! Except&#8230; picking a system is just the beginning. The real challenge is understanding how to use these increasingly complex tools effectively.</p><h1>Now what?</h1><p>I spend a lot of time with people trying to use AI to get stuff done, and that has taught me how incredibly confusing this is. So I wanted to walk everyone through the most important features and choices, as well as some advice on how to actually use AI.</p><h2>Picking a Model</h2><p>ChatGPT, Claude, and Gemini each offer multiple AI models through their interface, and picking the right one is crucial. Think of it like choosing between a sports car and a pickup truck; both are vehicles, but you'd use them for very different tasks. Each system offers three tiers: a fast model for casual chat (Claude Sonnet, GPT-4o, Gemini Flash), a powerful model for serious work (Claude Opus, o3, Gemini Pro), and sometimes an ultra-powerful model for the hardest problems (o3-pro, which can take 20+ minutes to think). The casual models are fine for brainstorming or quick questions. But for anything high stakes (analysis, writing, research, coding) usually switch to the powerful model. </p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!T5FA!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F98abe7ee-3b21-4b00-8fa5-8bfbae9efabb_1157x681.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"681\" src=\"https://substackcdn.com/image/fetch/$s_!T5FA!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F98abe7ee-3b21-4b00-8fa5-8bfbae9efabb_1157x681.png\" width=\"1157\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a></figure></div><p>Most systems default to the fast model to save computing power, so you need to manually switch using the model selector dropdown. (The free versions of these systems do not give you access to the most powerful model, so if you do not see the options I describe, it is because you are using the free version)</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!K27u!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F040a8e71-f90f-40db-ba9a-e871b6cd59fd_1683x511.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"442\" src=\"https://substackcdn.com/image/fetch/$s_!K27u!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F040a8e71-f90f-40db-ba9a-e871b6cd59fd_1683x511.png\" width=\"1456\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a></figure></div><p>I use o3, Claude 4 Opus, and Gemini 2.5 Pro for any serious work that I do. I also have particular favorites based on individual tasks that are outside of these models (GPT-4.5 is a really interesting model for writing, for example), but for most people, stick with the models I suggested most of the time.</p><p>For people concerned about privacy, Claude does not train future AI models on your data, but Gemini and ChatGPT might, if you are not using a corporate or educational version of the system. If you want to make sure your data is never used to train an AI model, you can turn off training features easily for ChatGPT without losing any functionality, and at the cost of some functionality for Gemini. You may also want to turn on or off &#8220;memory&#8221; in ChatGPT&#8217;s personalization option, which lets the AI remember scattered details about you. I find the memory system to be too erratic at this point, but you may have a different experience. </p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!A05d!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F794e8a07-2ad3-43f0-87e3-98a9cca1a3a5_1680x694.jpeg\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"601\" src=\"https://substackcdn.com/image/fetch/$s_!A05d!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F794e8a07-2ad3-43f0-87e3-98a9cca1a3a5_1680x694.jpeg\" width=\"1456\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a></figure></div><p></p><h2>Using Deep Research</h2><p><a href=\"https://www.oneusefulthing.org/p/the-end-of-search-the-beginning-of\">Deep Research is a key AI feature for most people</a>, even if they don&#8217;t know it yet.  Deep Research tools are very useful because they can produce very high-quality reports that often impress information professionals (lawyers, accountants, consultants, market researchers) that I speak to. You should be trying out Deep Research reports in your area of expertise to see what they can do for you, but some other use cases include:</p><ul><li><p>Gift Guides: &#8220;what do I buy for a picky 11-year-old who has read all of Harry Potter, is interested in science museums, and loves chess? Give me options, including where to buy at the best prices.&#8221;</p></li><li><p>Travel Guides &#8220;I am going to Wisconsin on vacation and want to visit unique sites, especially focusing on cheese, produce a guide for me&#8221;</p></li><li><p>Second opinions in law, medicine, and other fields (it should go without saying that you should trust your doctor/lawyer above AI, but research keeps finding that the more advanced AI systems do <a href=\"https://www.medrxiv.org/content/10.1101/2025.06.07.25329176v1\">very well in diagnosis</a> with a <a href=\"https://x.com/emollick/status/1899562684405670394\">surprisingly low hallucination rate</a>, so they can be useful for second opinions).</p></li></ul><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!b1kS!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F65b565b8-8519-4ea8-b1ed-6f76882aadae_1377x641.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"254.63108206245462\" src=\"https://substackcdn.com/image/fetch/$s_!b1kS!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F65b565b8-8519-4ea8-b1ed-6f76882aadae_1377x641.png\" title=\"\" width=\"547\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a><figcaption class=\"image-caption\">Activating Deep Research</figcaption></figure></div><p>Deep Research reports are not error-free but are far more accurate than just asking the AI for something, and the citations tend to actually be correct. Also note that each of the Deep Research tools work a little differently, with different strengths and weaknesses. Turning on the web search option in Claude and o3 will get them to work as mini Deep Research tools, doing some web research, but not as elaborately as a full report. Google has some fun additional options once you have created a report, letting you turn it into an infographic, a quiz or a podcast.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2\" href=\"https://substackcdn.com/image/fetch/$s_!eUJv!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe739fe92-4f1d-4a20-a9dc-c20e01ea54f5_978x408.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"168.95705521472394\" src=\"https://substackcdn.com/image/fetch/$s_!eUJv!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe739fe92-4f1d-4a20-a9dc-c20e01ea54f5_978x408.png\" title=\"\" width=\"405\" /><div></div></div></a></figure></div><h2>An Easy Approach to AI: Voice Mode</h2><p>An easy way to use AI is just to start with voice mode. The two best implementations of voice mode are in the Gemini app and ChatGPT&#8217;s app and website. Claude&#8217;s voice mode is weaker than the other two systems. What makes voice mode great is that you can just have a natural conversation with the app while in the car or on a walk and get quite far in understanding what these models can do. Note the models are optimized for chat (including all of the small pauses and intakes of breath designed to make it feel like you are talking to a person), so you don&#8217;t get access to the more powerful models this way. They also don&#8217;t search the web as often which makes them more likely to hallucinate if you are asking factual questions: if you are using ChatGPT, unless you hear the clicking sound at 44 seconds into this clip, it isn&#8217;t actually searching the web.</p><div class=\"native-video-embed\"></div><p>Voice mode's killer feature isn't the natural conversation, though, it's the ability to share your screen or camera. Point your phone at a broken appliance, a math problem, a recipe you're following, or a sign in a foreign language. The AI sees what you see and responds in real-time. I've used it to identify plants on hikes, solve a problem on my screen, and get cooking tips while my hands were covered in flour. This multimodal capability is genuinely futuristic, yet most people just use voice mode like Siri. You're missing the best part.</p><h2>Making Things for You: Images, Video, Code, and Documents</h2><p>ChatGPT and Gemini will make images for you if you ask (Claude cannot). <a href=\"https://www.oneusefulthing.org/p/no-elephants-breakthroughs-in-image\">ChatGPT offers the most controllable image creation tool,</a> Gemini uses two different image generation tools, Imagen, a very good traditional image generation system, and a multimodal image generation system. Generally, ChatGPT is stronger. On video creation, however, Gemini&#8217;s Veo 3 is very impressive, and you get several free uses a day (but you need to hit the <strong>Video </strong>button in the interface)</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!GHR1!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa2e42cc-677c-4406-8a85-09672c10ab07_1835x1546.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"353.9423076923077\" src=\"https://substackcdn.com/image/fetch/$s_!GHR1!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa2e42cc-677c-4406-8a85-09672c10ab07_1835x1546.png\" width=\"420\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a><figcaption class=\"image-caption\">&#8220;make me a photo of an otter holding a sign saying otters are cool but also accomplished pilots. the otter should also be holding a tiny silver 747 with gold detailing.&#8221;</figcaption></figure></div><p>All three systems can produce a wide variety of other outputs, ranging from documents to statistical analyses to interactive tools to simulations to simple games. To get Gemini or ChatGPT to do this reliably, you need to select the <strong>Canvas</strong> option when you want these systems to run code or produce separate outputs. Claude is good at creating these sorts of outputs on its own. Just ask, you may be surprised what the AI systems can make.</p><h1>Working with an AI</h1><p>Now that you have picked a model, you can start chatting with it. It used to be that the details of your prompts mattered a lot, but the most recent AI models I suggested can often figure out what you want without the need for complex prompts. As a result, many of the tips and tricks you see online for prompting are no longer as important for most people. At the Generative AI Lab at Wharton, we have been trying to examine prompting techniques in a scientific manner, and our research has shown, for example, that <a href=\"https://gail.wharton.upenn.edu/research-and-insights/tech-report-prompt-engineering-is-complicated-and-contingent/\">being polite to AI doesn&#8217;t seem to make a big difference in output quality overall</a><a class=\"footnote-anchor\" href=\"https://www.oneusefulthing.org/feed#footnote-1\" id=\"footnote-anchor-1\" target=\"_self\">1</a>. So just approach the AI conversationally rather than getting too worried about saying exactly the right thing.</p><p>That doesn&#8217;t mean that there is no art to prompting. If you are building a prompt for other people to use, it can take real skill to build something that works repeatedly. But for most people you can get started by keeping just a few things in mind:</p><ul><li><p><strong>Give the AI context to work with</strong>. Most AI models only know basic user information and the information in the current chat, they do not remember or learn about you beyond that. So you need to provide the AI with context: documents, images, PowerPoints, or even just an introductory paragraph about yourself can help - use the file option to upload files and images whenever you need. The AIs can do some of these ChatGPT and Claude can access your files and mailbox if you let them, and Gemini can access your Gmail, so you can ask them to look up relevant context automatically as well, though I prefer to give the context manually.</p></li><li><p><strong>Be really clear about what you want. </strong>Don&#8217;t say &#8220;Write me a marketing email,&#8221; instead go with &#8220;I'm launching a B2B SaaS product for small law firms. Write a cold outreach email that addresses their specific pain points around document management. Here's the details of the product: [paste]&#8221; Or ask the AI to ask you questions to help you clarify what you want.</p></li><li><p><strong>Give it step-by-step directions. </strong><a href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5285532\">Our research found this approach, called Chain-of-Thought prompting, no longer improves answer quality as much as it used to</a>. But even if it doesn&#8217;t help that much, it can make it easier to figure out why the AI came up with a particular answer.</p></li><li><p><strong>Ask for a lot of things.</strong> The AI doesn&#8217;t get tired or resentful. Ask for 50 ideas instead of 10, or thirty options to improve a sentence. Then push the AI to expand on the things you like.</p></li><li><p><strong>Use branching to explore alternatives.</strong> Claude, ChatGPT, and Gemini all let you edit prompts after you have gotten an answer. This creates a new &#8220;branch&#8221; of the conversation. You can move between branches by using the arrows that appear after you have edited an answer. It is a good way to learn how your prompts impact the conversation.</p><div class=\"native-video-embed\"></div></li></ul><h2>Troubleshooting</h2><p>I also have seen some fairly common areas where people get into trouble:</p><ul><li><p><strong>Hallucinations: </strong>In some ways, hallucinations are far less of a concern than they used to be, as AI has improved and newer AI models are better at not hallucinating. However, no matter how good the AI is, it will still make errors and mistakes and still give you confident answers where it is wrong. They also can hallucinate about their own capabilities and actions. Answers are more likely to be right when they come from the bigger, slower models, and if the AI did web searches. The risk of hallucination is why I always recommend using AI for topics you understand until you have a sense for their capabilities and issues.</p></li><li><p><strong>Not Magic: </strong>You should remember that the best AIs can perform at the level of a very smart person on some tasks, but current models cannot provide miraculous insights beyond human understanding. If the AI seems like it did something truly impossible, it is probably not actually doing that thing but pretending it did. Similarly, AI can seem incredibly insightful when asked about personal issues, but you should always take these insights with a grain of salt.</p></li><li><p> <strong>Two Way Conversation: </strong>You want to engage the AI in a back-and-forth interaction. Don&#8217;t just ask for a response, push the AI and question it.</p></li><li><p><strong>Checking for Errors: </strong>The AI doesn&#8217;t know &#8220;why&#8221; it did something, so asking it to explain its logic will not get you anywhere. However, if you find issues, the thinking trace of AI models can be helpful. If you click &#8220;show thinking&#8221; you can find out what the model was doing before giving you an answer. This is not always 100% accurate (you are actually getting a summary of the thinking) but is a good place to start.</p></li></ul><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!ec82!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb53c8df7-d36e-4bd2-839a-4f5f790b7bf1_850x930.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"480.3176470588235\" src=\"https://substackcdn.com/image/fetch/$s_!ec82!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb53c8df7-d36e-4bd2-839a-4f5f790b7bf1_850x930.png\" width=\"439\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a></figure></div><h1>Your Next Hour</h1><p>So now you know where to start. First, pick a system and resign yourself to paying the $20 (the free versions are demos, not tools). Then immediately test three things on real work: First, switch to the powerful model and give it a complex challenge from your actual job with full context and have an interactive back and forth discussion. Ask it for a specific output like a document or program or diagram and ask for changes until you get a result you are happy with. Second, try Deep Research on a question where you need comprehensive information, maybe competitive analysis, gift ideas for someone specific, or a technical deep dive. Third, experiment with voice mode while doing something else &#8212; cooking, walking, commuting &#8212; and see how it changes your ability to think through problems.</p><p>Most people use AI like Google at first: quick questions, no context, default settings. You now know better. Give it documents to analyze, ask for exhaustive options, use branching to explore alternatives, experiment with different outcomes. The difference between casual users and power users isn't prompting skill (that comes with experience); it's knowing these features exist and using them on real work.</p><p class=\"button-wrapper\"><a class=\"button primary\" href=\"https://www.oneusefulthing.org/subscribe\"><span>Subscribe now</span></a></p><p class=\"button-wrapper\"><a class=\"button primary\" href=\"https://www.oneusefulthing.org/p/using-ai-right-now-a-quick-guide?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share\"><span>Share</span></a></p><p></p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!1pxE!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdc7794be-9211-43a4-9b43-eb3db6b05bf3_1376x864.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"258.06976744186045\" src=\"https://substackcdn.com/image/fetch/$s_!1pxE!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdc7794be-9211-43a4-9b43-eb3db6b05bf3_1376x864.png\" width=\"411\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a></figure></div><p></p><div class=\"footnote\"><a class=\"footnote-number\" contenteditable=\"false\" href=\"https://www.oneusefulthing.org/feed#footnote-anchor-1\" id=\"footnote-1\" target=\"_self\">1</a><div class=\"footnote-content\"><p>It is actually weirder than that: on hard math and science questions that we tested, being polite sometimes makes the AI perform much better, sometimes worse, in ways that are impossible to know in advance. So be polite if you want to!</p></div></div>"
            ],
            "link": "https://www.oneusefulthing.org/p/using-ai-right-now-a-quick-guide",
            "publishedAt": "2025-06-23",
            "source": "Ethan Mollick",
            "summary": "<p>Every few months I put together a guide on which AI system to use. Since I last wrote my guide, however, there has been a subtle but important shift in how the major AI products work. Increasingly, it isn't about the best model, it is about the best overall system for most people. The good news is that picking an AI is easier than ever and you have three excellent choices. The challenge is that these systems are getting really complex to understand. I am going to try and help a bit with both.</p><p>First, the easy stuff.</p><h1>Which AI to Use</h1><p>For most people who want to use AI seriously, you should pick one of three systems: <a href=\"https://claude.ai/\">Claude </a>from Anthropic, Google&#8217;s <a href=\"https://gemini.google.com/\">Gemini</a>, and OpenAI&#8217;s <a href=\"https://chatgpt.com/\">ChatGPT</a>. With all of the options, you get access to both advanced and fast models, a voice mode, the ability to see images and documents, the ability to execute code, good mobile apps, the ability to create images and video (Claude lacks here, however), and the ability to do Deep Research. Some of these features are free, but you are generally going to need to pay $20/month to get access to the full set of",
            "title": "Using AI Right Now: A Quick Guide"
        },
        {
            "content": [],
            "link": "https://harper.blog/notes/2025-06-23_4559325cab64_shot-on-shots-on-shots/",
            "publishedAt": "2025-06-23",
            "source": "Harper Reed",
            "summary": "<p>Shot on shots on shots</p> <figure> <img alt=\"image_1.jpg\" height=\"1800\" src=\"https://harper.blog/notes/2025-06-23_4559325cab64_shot-on-shots-on-shots/image_1.jpg\" width=\"1800\" /> </figure> <hr /> <p>Thank you for using RSS. I appreciate you. <a href=\"mailto:harper&#64;modest.com\">Email me</a></p>",
            "title": "Note #264"
        },
        {
            "content": [],
            "link": "https://harper.blog/notes/2025-06-23_e77040c60e13_more-shrine-shots/",
            "publishedAt": "2025-06-23",
            "source": "Harper Reed",
            "summary": "<p>More shrine shots</p> <figure> <img alt=\"image_1.jpg\" height=\"1800\" src=\"https://harper.blog/notes/2025-06-23_e77040c60e13_more-shrine-shots/image_1.jpg\" width=\"1800\" /> </figure> <figure> <img alt=\"image_2.jpg\" height=\"1800\" src=\"https://harper.blog/notes/2025-06-23_e77040c60e13_more-shrine-shots/image_2.jpg\" width=\"1800\" /> </figure> <figure> <img alt=\"image_3.jpg\" height=\"1800\" src=\"https://harper.blog/notes/2025-06-23_e77040c60e13_more-shrine-shots/image_3.jpg\" width=\"1800\" /> </figure> <hr /> <p>Thank you for using RSS. I appreciate you. <a href=\"mailto:harper&#64;modest.com\">Email me</a></p>",
            "title": "Note #263"
        },
        {
            "content": [],
            "link": "https://harper.blog/notes/2025-06-23_e38ba352e72f_the-trees-of-the-shrine/",
            "publishedAt": "2025-06-23",
            "source": "Harper Reed",
            "summary": "<p>The trees of the shrine</p> <figure> <img alt=\"image_1.jpg\" height=\"1440\" src=\"https://harper.blog/notes/2025-06-23_e38ba352e72f_the-trees-of-the-shrine/image_1.jpg\" width=\"1800\" /> </figure> <figure> <img alt=\"image_2.jpg\" height=\"1440\" src=\"https://harper.blog/notes/2025-06-23_e38ba352e72f_the-trees-of-the-shrine/image_2.jpg\" width=\"1800\" /> </figure> <hr /> <p>Thank you for using RSS. I appreciate you. <a href=\"mailto:harper&#64;modest.com\">Email me</a></p>",
            "title": "Note #262"
        },
        {
            "content": [],
            "link": "https://harper.blog/notes/2025-06-23_5484dd899b02_shrine-bells/",
            "publishedAt": "2025-06-23",
            "source": "Harper Reed",
            "summary": "<p>Shrine bells</p> <figure> <img alt=\"image_1.jpg\" height=\"1800\" src=\"https://harper.blog/notes/2025-06-23_5484dd899b02_shrine-bells/image_1.jpg\" width=\"1800\" /> </figure> <figure> <img alt=\"image_2.jpg\" height=\"1800\" src=\"https://harper.blog/notes/2025-06-23_5484dd899b02_shrine-bells/image_2.jpg\" width=\"1800\" /> </figure> <hr /> <p>Thank you for using RSS. I appreciate you. <a href=\"mailto:harper&#64;modest.com\">Email me</a></p>",
            "title": "Note #261"
        },
        {
            "content": [
                "<p>Simple betting markets have long suffered from a <a href=\"https://en.wikipedia.org/wiki/Favourite-longshot_bias\">long-shot bias</a>: long-shots chances are too high, while favorite chances are too low. While many plausible causes <a href=\"https://pubsonline.informs.org/doi/10.1287/mnsc.2023.4684\">of</a> this have been identified, two stand out to me as obvious contributors. First, as favorite bettors have to put up more cash than do long shot bettors, a small fraction of long shot fans can have a disproportionate influence on market odds. Second, as the max possible gain in simple betting markets from betting on favorites is far less than from betting on longshots, favorites bettors are more sensitive to transaction fees, any lack of paying interest on deposits, and the opportunity cost of locking up capital that can&#8217;t be used elsewhere for a while. Let me call this second set problems of &#8220;leverage&#8221;.</p><p>Though I&#8217;ve known it for decades, I&#8217;m not sure if I&#8217;ve ever said this before publicly: combinatorial betting markets greatly cut leverage problems.</p><p>What are combinatorial markets? <a href=\"http://hanson.gmu.edu/combobet.pdf\">You</a> <a href=\"http://hanson.gmu.edu/testcomb.pdf\">can</a> <a href=\"http://hanson.gmu.edu/mktscore.pdf\">take</a> N <a href=\"https://hanson.gmu.edu/~rhanson/mktscore-prototype\">simple</a> <a href=\"https://hanson.gmu.edu/~rhanson/mktscore-prototype-run\">markets</a>, each re a discrete variable with D possible outcomes, all subsidized to the same liquidity level via automated market makers, and combine them into a single combinatorial market where one can trade on all possible combinations of these N variables, all at this same liquidity level, and all for no extra financial cost. A simple dumb implementation takes roughly D^N states to store info, and also about D^N steps to compute changes, making this approach feasible today for up to roughly 30 binary variables. More complex implementations <a href=\"http://hanson.gmu.edu/UAI2012.pdf\">allow</a> thousands <a href=\"http://hanson.gmu.edu/SUM13.pdf\">of</a> variables. And an assumptions interface makes this all understandable to users.</p><p>Imagine you have a combinatorial market, where the market chance of A is 99%. You make a $99 favorite bet on A, matching a contrarian who makes a long-shot $1 bet on not A, say at 99-1 odds. Doing this gives you $100 in assets that pay off if A happens, while it gives the contrarian $100 if not A.</p><p>You could then use your $100 if A assets to bet on another favorite B. You&#8217;ll have to bet on B given A, but as A was at 99% chance, you&#8217;ll have nearly the same effect on the B market as if you made a simple unconditional bet on B. After you bet on B given A at 99-1 odds, you&#8217;ll then have ~$101 if A and B, which you can continue to use to bet on other topics C.</p><p>As you bet in combinatorial markets on new topics using the assets you acquired from prior favorites bets, you&#8217;ll want to ask yourself if these events are correlated, and adjust the odds you&#8217;ll accept to account for that. But in compensation, you get to search for combinations of events where you most disagree with market odds, for max expected trading gains. And the market liquidity will always be high for all these complex combinations, even if no one else ever has or will traded your particular combination.</p><p>If you have many opinions on the topics in this combinatorial market, then risk aversion is likely to be the main limit on your reusing assets from bets on some topics to also bet on other topics. Combine enough bets, even on favorites, and eventually the odds of winning become too low to be tolerable. The same limit applies also to contrarians who bet $1 and acquire $100 if not A, except that their limits come much faster. Combining even two bets at 1-99 odds gives a ~1/10K chance to win bet that is likely too risky for most traders.</p><p>In an ordinary betting markets, 99-1 odds on a claim means that one who backs the favorite has to put up ~100x as much capital to support their bet, and at best only gains 1%, while the contrarian might win 100x their investment. This tends to induce a bias favoring long-shots. But in a combinatorial betting market everyone can bet up to the limits of their risk tolerance, either by combining a few long shot bets or by combining far more favorite bets. Both sides can take as much or little risk as they want, and so there is no longer a leverage problem to bias the prices for long-shots.</p>"
            ],
            "link": "https://www.overcomingbias.com/p/combos-cut-long-shot-bias",
            "publishedAt": "2025-06-23",
            "source": "Robin Hanson",
            "summary": "Simple betting markets have long suffered from a long-shot bias: long-shots chances are too high, while favorite chances are too low.",
            "title": "Combos Cut Long-Shot Bias"
        },
        {
            "content": [],
            "link": "https://simonwillison.net/2025/Jun/23/phoenix-new/#atom-entries",
            "publishedAt": "2025-06-23",
            "source": "Simon Willison",
            "summary": "<p>Here's a fascinating new entrant into the AI-assisted-programming / coding-agents space by <a href=\"https://fly.io/\">Fly.io</a>, introduced on their blog in <a href=\"https://fly.io/blog/phoenix-new-the-remote-ai-runtime/\">Phoenix.new \u2013 The Remote AI Runtime for Phoenix</a>: describe an app in a prompt, get a full Phoenix application, backed by SQLite and running on Fly's hosting platform. The <a href=\"https://www.youtube.com/watch?v=du7GmWGUM5Y\">official Phoenix.new YouTube launch video</a> is a good way to get a sense for what this does.</p> <h4 id=\"background-on-phoenix-and-elixir-and-fly\">Background on Phoenix and Elixir and Fly</h4> <p>First, some background. <a href=\"https://www.phoenixframework.org/\">Phoenix</a> is an open source web framework for Elixir, the Ruby-like language that compiles to Erlang's BEAM bytecode and runs on top of the highly concurrent Erlang runtime. The signature feature of the framework is <a href=\"https://github.com/phoenixframework/phoenix_live_view/blob/main/README.md#feature-highlights\">Phoenix LiveView</a>, a toolkit for building realtime interfaces through streaming diffs to server-side HTML over a WebSocket connection.</p> <p>Phoenix was created by Chris McCord 11 years ago, and Chris joined Fly nearly four years ago. <a href=\"http://phoenix.new/\">Phoenix.new</a> is his latest project.</p> <p>Phoenix LiveView is a really great fit for Fly's geographically distributed application serving infrastructure. Fly co-founder Kurt Mackey <a href=\"https://fly.io/blog/low-latency-liveview/\">wrote about that</a> in April 2021, before they had hired Chris, describing how LiveView benefits from low latency by \"moving app processes close to users\"",
            "title": "Phoenix.new is Fly's entry into the prompt-driven app development space"
        },
        {
            "content": [
                "<p>This is the weekly visible open thread. Post about anything you want, ask random questions, whatever. ACX has an unofficial <a href=\"https://www.reddit.com/r/slatestarcodex/\">subreddit</a>, <a href=\"https://discord.gg/RTKtdut\">Discord</a>, and <a href=\"https://www.datasecretslox.com/index.php\">bulletin board</a>, and <a href=\"https://www.lesswrong.com/community?filters%5B0%5D=SSC\">in-person meetups around the world</a>. Most content is free, some is subscriber only; you can subscribe <strong><a href=\"https://astralcodexten.substack.com/subscribe\">here</a></strong>. Also:</p><p><strong>1: </strong>I&#8217;m looking for a VC/investment/nonprofit lawyer who can answer some questions for ACX Grants, most likely ending in drawing up a contract for something like a grant which is convertible to equity if the grantee becomes a startup (or if this is a bad idea, explaining why). I will pay your normal rate for this service, I&#8217;m just asking here because I trust people in the ACX community more than whoever lands at the top of a Google search. Email scott@slatestarcodex.com if interested.</p><p><strong>2: </strong>New subscribers-only post, <a href=\"https://www.astralcodexten.com/p/make-a-personalized-ai-kids-book\">Make A Personalized AI Kids&#8217; Book</a>. \"AI will probably lead to the end of the world, but in the meantime there will be great [children&#8217;s birthday presents]\"</p><p><strong>3: </strong>Thank you to everyone who voted for finalists in this year&#8217;s Nonbook Review Contest. All entries among the top ten best-ranked reviews became automatic finalists, and I also added two more from the 10-25 tier that voters or I especially liked. Honorable mentions were others from the 10-25 tier that I liked a lot. <strong>Finalists</strong> are Alpha School, Dementia, Islamic Geometric Patterns, Joan of Arc, Mashed Potatoes, Men, Ollantay, Phase I Research, Synaptic Plasticity, The ACX Commentariat, The Internet That Might Have Been, and The Russo-Ukrainian War. <strong>Honorable Mentions</strong> are at least Bishop's Castle, Bukele, Elon Musk's Algorithm, JFK Conspiracies, Martial Arts, Miniatur Wunderland, School (Review 1 by DK), and Watergate. I may promote some honorables to finalists depending on reader tolerance or unexpected opportunities. I will give you finer-grained score information after the contest ends. First finalist post is planned for this Friday.</p>"
            ],
            "link": "https://www.astralcodexten.com/p/open-thread-387",
            "publishedAt": "2025-06-23",
            "source": "SlateStarCodex",
            "summary": "<p>This is the weekly visible open thread. Post about anything you want, ask random questions, whatever. ACX has an unofficial <a href=\"https://www.reddit.com/r/slatestarcodex/\">subreddit</a>, <a href=\"https://discord.gg/RTKtdut\">Discord</a>, and <a href=\"https://www.datasecretslox.com/index.php\">bulletin board</a>, and <a href=\"https://www.lesswrong.com/community?filters%5B0%5D=SSC\">in-person meetups around the world</a>. Most content is free, some is subscriber only; you can subscribe <strong><a href=\"https://astralcodexten.substack.com/subscribe\">here</a></strong>. Also:</p><p><strong>1: </strong>I&#8217;m looking for a VC/investment/nonprofit lawyer who can answer some questions for ACX Grants, most likely ending in drawing up a contract for something like a grant which is convertible to equity if the grantee becomes a startup (or if this is a bad idea, explaining why). I will pay your normal rate for this service, I&#8217;m just asking here because I trust people in the ACX community more than whoever lands at the top of a Google search. Email scott@slatestarcodex.com if interested.</p><p><strong>2: </strong>New subscribers-only post, <a href=\"https://www.astralcodexten.com/p/make-a-personalized-ai-kids-book\">Make A Personalized AI Kids&#8217; Book</a>. \"AI will probably lead to the end of the world, but in the meantime there will be great [children&#8217;s birthday presents]\"</p><p><strong>3: </strong>Thank you to everyone who voted for finalists in this year&#8217;s Nonbook Review Contest. All entries among the top ten best-ranked reviews became automatic finalists, and I also added two more from the 10-25 tier that voters",
            "title": "Open Thread 387"
        }
    ],
    "lookbackDays": 1,
    "publishDate": "2025-06-23"
}