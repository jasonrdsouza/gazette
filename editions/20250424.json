{
    "articles": [
        {
            "content": [
                "<div class=\"trix-content\">\n  <div>We received over 2,200 applications for our <a href=\"https://x.com/dhh/status/1909312757058482443\">just-closed junior programmer opening</a>, and now we're going through all of them by hand and by human. No AI screening here. It's a lot of work, but we have a great team who take the work seriously, so in a few weeks, we'll be able to invite a group of finalists to the next phase.</div><div><br /></div><div>This highlights the folly of thinking that what it'll take to land a job like this is some specific list of criteria, though. Yes, you have to present a baseline of relevant markers to even get into consideration, like a great cover letter that doesn't smell like AI slop, promising projects or work experience or educational background, etc. But to actually get the job, you have to be the best of the ones who've applied!</div><div><br /></div><div>It sounds self-evident, maybe, but I see questions time and again about it, so it must not be. Almost every job opening is grading applicants on the curve of everyone who has applied. And the best candidate of the lot gets the job. You can't quantify what that looks like in advance.</div><div><br /></div><div>I'm excited to see who makes it to the final stage. I already hear early whispers that we got some exceptional applicants in this round. It would be great to help counter the narrative that this industry no longer needs juniors. That's simply retarded.</div><div><br /></div><div>However good AI gets, we're always going to need people who know the ins and outs of what the machine comes up with. Maybe not as many, maybe not in the same roles, but it's truly utopian thinking that mankind won't need people capable of vetting the work done by AI in five minutes.</div>\n</div>"
            ],
            "link": "https://world.hey.com/dhh/we-ll-always-need-junior-programmers-69ddb4a1",
            "publishedAt": "2025-04-24",
            "source": "DHH",
            "summary": "<div class=\"trix-content\"> <div>We received over 2,200 applications for our <a href=\"https://x.com/dhh/status/1909312757058482443\">just-closed junior programmer opening</a>, and now we're going through all of them by hand and by human. No AI screening here. It's a lot of work, but we have a great team who take the work seriously, so in a few weeks, we'll be able to invite a group of finalists to the next phase.</div><div><br /></div><div>This highlights the folly of thinking that what it'll take to land a job like this is some specific list of criteria, though. Yes, you have to present a baseline of relevant markers to even get into consideration, like a great cover letter that doesn't smell like AI slop, promising projects or work experience or educational background, etc. But to actually get the job, you have to be the best of the ones who've applied!</div><div><br /></div><div>It sounds self-evident, maybe, but I see questions time and again about it, so it must not be. Almost every job opening is grading applicants on the curve of everyone who has applied. And the best candidate of the lot gets the job. You can't quantify what that looks like in advance.</div><div><br /></div><div>I'm excited to see who makes it to",
            "title": "We'll always need junior programmers"
        },
        {
            "content": [
                "<p>Theanine is an amino acid that occurs naturally in tea. Many people take it as a supplement for stress or anxiety. It\u2019s mechanistically plausible, but the scientific literature hasn\u2019t been able to find much of a benefit. So I ran a 16-month blinded self-experiment in the hopes of showing it worked. <a href=\"https://dynomight.net/theanine/\">It did not work</a>.</p>\n\n<p>At the end of the post, I put out a challenge: If you think theanine, prove it. Run a blinded self-experiment. After all, if it works, then what are you afraid of?</p>\n\n<p>Well, it turns out that Luis Costigan <em>had</em> already run a <a href=\"https://manifold.markets/LuisCostigan/nof1-blinded-experiment-will-210mg\">self-experiment</a>. Here was his protocol:</p>\n\n<ol>\n  <li>Each morning, take 200 mg theanine or placebo (blinded) along with a small iced coffee.</li>\n  <li>Wait 90 minutes.</li>\n  <li>Record anxiety on a subjective scale of 0-10.</li>\n</ol>\n\n<p>He repeated this for 20 days. His mean anxiety after theanine was 4.2 and after placebo it was 5.0. A simple Bayesian analysis said there was an <a href=\"https://manifold.markets/LuisCostigan/nof1-blinded-experiment-will-210mg#gMcOYZYQSv4tNwaj7ZmM\">82.6%</a> chance theanine reduced anxiety.</p>\n\n<details>\n  The p-value was 0.31, but this is a Bayesian blog\u2014this is what you'd expect with a sample size of 20.\n\n  <p>A sample size of 20 just doesn\u2019t have enough statistical power to have a good chance of finding a statistically significant result. If you assume the mean under placebo is 5.0, the mean under theanine is 4.2, and the standard deviation is 2.0, then you\u2019d only have a <a href=\"https://www.gigacalculator.com/calculators/power-sample-size-calculator.php\">22.6%</a> chance of getting a result with p&lt;0.05.</p>\n</details>\n\n<p>I think this experiment was good, both the experiment and the analysis. It doesn\u2019t <em>prove</em> theanine works, but it was enough to make me wonder: Maybe theanine <em>does</em> work, but I somehow failed to bring out the effect? What would give theanine the best possible chance of working?</p>\n\n<p><img alt=\"i need to be more harcdcore\" src=\"https://dynomight.net/img/theanine-2/hardcore.png\" /></p>\n\n<p>Theanine is widely reported to help with anxiety from caffeine. While I didn\u2019t explicitly take caffeine as part of my previous experiment, I drink tea almost every day, so I figured that if theanine helps, it should have shown up.</p>\n\n<p>But most people (and Luis) take theanine with <em>coffee</em>, not tea. I find that coffee makes me <em>much</em> more nervous than tea. For this reason, I sort of hate coffee and rarely drink it.</p>\n\n<p>Maybe the tiny amounts of natural theanine in tea masked the effects of the supplements? Or maybe you need to take theanine and caffeine at the same time? Or maybe for some strange reason theanine works for coffee (or coffee-tier anxiety) but not tea?</p>\n\n<p>So fine. To hell with my mental health. I decided to take theanine (or placebo) together with coffee on an empty stomach first thing in the day. And I decided to double the dose of theanine from 200 mg to 400 mg.</p>\n<h2 id=\"details\">Details</h2>\n\n<p><strong>Coffee.</strong> I used one of those pod machines which are incredibly uncool but presumably deliver a consistent amount of caffeine.</p>\n\n<p><strong>Measurements.</strong> Each day I recorded my stress levels on a subjective 1-5 scale before I took the capsules. An hour later, I recorded my end stress levels, and my percentage prediction that what I took was actually theanine.</p>\n\n<p><strong>Blinding.</strong> I have capsules that either contain 200 mg of theanine or 25 mcg of vitamin D. These are exactly the same size. I struggled for a while to see how to take two pills of the same type while being blind to the results. In the end, I put two pills of each type in identical looking cups and shuffled the cups. Then I shut my eyes, took a sip of coffee (to make <em>sure</em> I couldn\u2019t taste any difference), swallowed the pills on one cup, and put the others into a numbered envelope.</p>\n\n<p>Here\u2019s a picture of the envelopes, to prove I actually did this and/or invite sympathy for all the coffee I had to endure:</p>\n\n<p><img alt=\"envelopes\" src=\"https://dynomight.net/img/theanine-2/envs.jpg\" /></p>\n\n<p>After 37 days I ran out of capsules.</p>\n\n<h2 id=\"initial-thoughts\">Initial thoughts</h2>\n\n<p>I\u2019m going to try something new. As I write these words, I have not yet opened the envelopes, so I don\u2019t know the results. I\u2019m going to register some thoughts.</p>\n\n<p>My main thought is: I have no idea what the results will show.</p>\n\n<p>It <em>really</em> felt like on some days I got the normal spike of anxiety I expect from coffee and on other days it was almost completely gone. But in my previous experiment I often felt the same thing and was proven wrong. It wouldn\u2019t surprise me if the results show a strong effect, or if it\u2019s all completely random.</p>\n\n<p>I\u2019ll also pre-register (sort of) the statistical analyses I intend to do:</p>\n\n<ol>\n  <li>I\u2019ll plot the data.</li>\n  <li>I\u2019ll repeat <a href=\"https://manifold.markets/LuisCostigan/nof1-blinded-experiment-will-210mg\">Luis\u2019s Bayesian analysis</a>, which looks at end stress levels only.</li>\n  <li>I\u2019ll repeat that again, but looking at the change in stress levels.</li>\n  <li>I\u2019ll repeat that again, but looking at my percentage prediction that what I actually took was theanine vs. placebo.</li>\n  <li>I\u2019ll compute regular-old confidence intervals and p-values for end stress, change in stress, and my percentage prediction that what I actually took was theanine vs. placebo.\n    <h2 id=\"intermission\">Intermission</h2>\n  </li>\n</ol>\n\n<p>Please hold while I open all the envelopes and do the analyses. Here\u2019s a <a href=\"https://www.nga.gov/collection/art-object-page.46557.html\">painting</a>.</p>\n\n<p><img alt=\"\" src=\"https://dynomight.net/img/theanine-2/blue_morning.jpg\" /></p>\n\n<h2 id=\"plots\">Plots</h2>\n\n<p>Here are the raw stress levels. Each line line shows one trial, with the start marked with a small horizontal bar. Remember, this measures the effect of coffee <em>and</em> the supplement. So even though stress tends to go up, this would still show a benefit if it went up <em>less</em> with theanine.</p>\n\n<p><a href=\"https://dynomight.net/img/theanine-2/stress.pdf\"><img alt=\"\" src=\"https://dynomight.net/img/theanine-2/stress.svg\" /></a></p>\n\n<p>Here is the difference in stress levels. If \u0394 Stress is negative, that means stress went down.</p>\n\n<p><a href=\"https://dynomight.net/img/theanine-2/diff.pdf\"><img alt=\"\" src=\"https://dynomight.net/img/theanine-2/diff.svg\" /></a></p>\n\n<p>Here are the start vs. end stress levels, ignoring time. The dotted line shows equal stress levels, so anything below that line means stress went down.</p>\n\n<p><a href=\"https://dynomight.net/img/theanine-2/stress_beforeafter.pdf\"><img alt=\"\" src=\"https://dynomight.net/img/theanine-2/stress_beforeafter.svg\" /></a></p>\n\n<p>And finally, here are my percentage predictions of if what I had taken was actually theanine:</p>\n\n<p><a href=\"https://dynomight.net/img/theanine-2/probs.pdf\"><img alt=\"\" src=\"https://dynomight.net/img/theanine-2/probs.svg\" /></a></p>\n\n<p>So\u2026. nothing jumps out so far.</p>\n\n<h2 id=\"analysis\">Analysis</h2>\n\n<p>So I did the analysis in my pre-registered plan above. In the process, I realized I wanted to show some extra stuff. It\u2019s all simple and I think unobjectionable. But if you\u2019re the kind of paranoid person who only trusts pre-registered things, I love and respect you and I will mark those with \u201c\u2714\ufe0f\u201d.</p>\n\n<h3 id=\"end-stress\">End stress</h3>\n\n<p>The first thing we\u2019ll look at is the final stress levels, one hour after taking theanine or vitamin D. First up, regular-old frequentist statistics.</p>\n\n<table>\n  <thead>\n    <tr>\n      <th>Variable</th>\n      <th>Mean</th>\n      <th>95% C.I.</th>\n      <th>p</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>theanine end stress</td>\n      <td>1.93</td>\n      <td>(1.80, 2.06)</td>\n      <td>\u00a0</td>\n    </tr>\n    <tr>\n      <td>vitamin D end stress</td>\n      <td>2.01</td>\n      <td>(1.91, 2.10)</td>\n      <td>\u00a0</td>\n    </tr>\n    <tr>\n      <td>\u2714\ufe0f difference (T-D)</td>\n      <td>-0.069</td>\n      <td>(-0.23, 0.083)</td>\n      <td>0.33</td>\n    </tr>\n  </tbody>\n</table>\n\n<p>If the difference is less than zero, that would suggest theanine was better. It looks like there might be a small difference, but it\u2019s nowhere near statistically significant.</p>\n\n<p>Next up, Bayes! In this analysis, there are latent variables for the mean and standard deviation of end stress (after one hour) with theanine and also for vitamin D. Following Luis\u2019s analysis, these each have a Gaussian prior with a mean and standard deviation based on the overall mean in the data.</p>\n\n<table>\n  <thead>\n    <tr>\n      <th>Variable</th>\n      <th>Mean</th>\n      <th>95% C.I.</th>\n      <th>P[T better]</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>end stress (T)</td>\n      <td>1.93</td>\n      <td>(1.81, 2.06)</td>\n      <td>\u00a0</td>\n    </tr>\n    <tr>\n      <td>end stress (D)</td>\n      <td>2.00</td>\n      <td>(1.91, 2.10)</td>\n      <td>\u00a0</td>\n    </tr>\n    <tr>\n      <td>difference (T-D)</td>\n      <td>-0.069</td>\n      <td>(-0.23, 0.09)</td>\n      <td>80.5%</td>\n    </tr>\n    <tr>\n      <td>\u2714\ufe0f % diff (T-D)/D</td>\n      <td>-3.38%</td>\n      <td>(-11.1%, 4.71%)</td>\n      <td>80.5%</td>\n    </tr>\n  </tbody>\n</table>\n\n<p>The results are extremely similar to the frequentist analysis. This says there\u2019s an 80% chance theanine is better.</p>\n\n<h3 id=\"\u03b4-stress\">\u0394 Stress</h3>\n\n<p>Next up, let\u2019s look at the <em>difference</em> in stress levels defined as \u0394 = (end - start). Since this measures an increase in stress, we\u2019d like it to be as small as possible. So again, if the difference is negative, that would suggest theanine is better. Here are the good-old frequentist statistics.</p>\n\n<table>\n  <thead>\n    <tr>\n      <th>Variable</th>\n      <th>Mean</th>\n      <th>95% C.I.</th>\n      <th>p</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>theanine \u0394 stress</td>\n      <td>0.082</td>\n      <td>(-0.045, 0.209)</td>\n      <td>\u00a0</td>\n    </tr>\n    <tr>\n      <td>vitamin D \u0394 stress</td>\n      <td>0.085</td>\n      <td>(-0.024, 0.194)</td>\n      <td>\u00a0</td>\n    </tr>\n    <tr>\n      <td>\u2714\ufe0f difference (T-D)</td>\n      <td>0.0026</td>\n      <td>(-0.158, 0.163)</td>\n      <td>0.334</td>\n    </tr>\n  </tbody>\n</table>\n\n<p>And here\u2019s the Bayesian analysis. It\u2019s just like the first one except we have latent variables for the <em>difference</em> in stress levels (end-start). If the difference of that difference was less than zero, that would again suggest theanine was better.</p>\n\n<table>\n  <thead>\n    <tr>\n      <th>Variable</th>\n      <th>Mean</th>\n      <th>95% C.I.</th>\n      <th>P[T better]</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>\u0394 stress (T)</td>\n      <td>0.0837</td>\n      <td>(-0.039, 0.20)</td>\n      <td>\u00a0</td>\n    </tr>\n    <tr>\n      <td>\u0394 stress (D)</td>\n      <td>0.0845</td>\n      <td>(-0.024, 0.19)</td>\n      <td>\u00a0</td>\n    </tr>\n    <tr>\n      <td>difference (T-D)</td>\n      <td>-0.0008</td>\n      <td>(-0.16, 0.16)</td>\n      <td>50.5%</td>\n    </tr>\n    <tr>\n      <td>\u2714\ufe0f % diff (T-D)/D</td>\n      <td>22.0%</td>\n      <td>(-625%, 755%)</td>\n      <td>55.9%</td>\n    </tr>\n  </tbody>\n</table>\n\n<p>In retrospect, this percentage prediction analysis is crazy, and I suggest you ignore it. The issue is that even though \u0394 stress is usually positive (coffee bad) it\u2019s near zero and can be negative. Computing (T-D)/D when D can be negative is stupid and I think makes the whole calculation meaningless. I regret pre-registering this.</p>\n\n<p>The absolute difference is fine. It\u2019s very close (almost <em>suspiciously</em> close) to zero.</p>\n\n<h3 id=\"percentage-prediction\">Percentage prediction</h3>\n\n<p>Finally, let\u2019s look at my percentage prediction that what I took was theanine. It really <em>felt</em> like I could detect a difference. But could I?</p>\n\n<p>Here we\u2019d hope that I\u2019d give a higher prediction that I\u2019d taken theanine when I\u2019d actually taken theanine. So a positive difference would suggest theanine is better, or at least different.</p>\n\n<table>\n  <thead>\n    <tr>\n      <th>Variable</th>\n      <th>Mean</th>\n      <th>95% C.I.</th>\n      <th>p</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>% with theanine</td>\n      <td>52.8%</td>\n      <td>(45.8%, 59.9%)</td>\n      <td>\u00a0</td>\n    </tr>\n    <tr>\n      <td>% with vitamin D</td>\n      <td>49.3%</td>\n      <td>(43.2%, 55.4%)</td>\n      <td>\u00a0</td>\n    </tr>\n    <tr>\n      <td>\u2714\ufe0f difference (T-D)</td>\n      <td>3.5%</td>\n      <td>(-5.4%, 12.4%)</td>\n      <td>0.428</td>\n    </tr>\n  </tbody>\n</table>\n\n<p>And here\u2019s the corresponding Bayesian analysis. This is just like the first two, except with latent variables for my percentage prediction under theanine and vitamin D.</p>\n\n<table>\n  <thead>\n    <tr>\n      <th>Variable</th>\n      <th>Mean</th>\n      <th>95% C.I.</th>\n      <th>P[T better]</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>% prediction (T)</td>\n      <td>52.7%</td>\n      <td>(45.8%, 59.6%)</td>\n      <td>\u00a0</td>\n    </tr>\n    <tr>\n      <td>% prediction (D)</td>\n      <td>49.3%</td>\n      <td>(43.4%, 55.2%)</td>\n      <td>\u00a0</td>\n    </tr>\n    <tr>\n      <td>difference (T-D)</td>\n      <td>3.3%</td>\n      <td>(-5.7%, 12.4%)</td>\n      <td>77.1%</td>\n    </tr>\n    <tr>\n      <td>\u2714\ufe0f % diff (T-D)/D</td>\n      <td>7.2%</td>\n      <td>(-10.8%, 27.6%)</td>\n      <td>77.1%</td>\n    </tr>\n  </tbody>\n</table>\n\n<p>Taking a percentage difference of a quantity that is itself a percentage difference is really weird, but fine.</p>\n\n<h1 id=\"discussion\">Discussion</h1>\n\n<p>This is the most annoying possible outcome. A clear effect would have made me happy. Clear evidence of no effect would also have made me happy. Instead, <em>some</em> analyses say there <em>might</em> be a small effect, and others suggest nothing. Ugh.</p>\n\n<p>But I\u2019ll say this: If there is any effect, it\u2019s small. I know many people say theanine is life-changing, and I know why: It\u2019s insanely easy to fool yourself. Even after running a previous 18-month trial and finding no effect, I <em>still</em> often felt like I could feel the effects in this experiment. I still thought I might open up all the envelopes and find that I had been <em>under</em>-confident in my guesses. Instead, I barely did better than chance.</p>\n\n<p>So I maintain my previous rule. If you claim that theanine has huge effects for you, blind experiment or GTFO.</p>"
            ],
            "link": "https://dynomight.net/theanine-2/",
            "publishedAt": "2025-04-24",
            "source": "Dynomight",
            "summary": "<p>Theanine is an amino acid that occurs naturally in tea. Many people take it as a supplement for stress or anxiety. It\u2019s mechanistically plausible, but the scientific literature hasn\u2019t been able to find much of a benefit. So I ran a 16-month blinded self-experiment in the hopes of showing it worked. <a href=\"https://dynomight.net/theanine/\">It did not work</a>.</p> <p>At the end of the post, I put out a challenge: If you think theanine, prove it. Run a blinded self-experiment. After all, if it works, then what are you afraid of?</p> <p>Well, it turns out that Luis Costigan <em>had</em> already run a <a href=\"https://manifold.markets/LuisCostigan/nof1-blinded-experiment-will-210mg\">self-experiment</a>. Here was his protocol:</p> <ol> <li>Each morning, take 200 mg theanine or placebo (blinded) along with a small iced coffee.</li> <li>Wait 90 minutes.</li> <li>Record anxiety on a subjective scale of 0-10.</li> </ol> <p>He repeated this for 20 days. His mean anxiety after theanine was 4.2 and after placebo it was 5.0. A simple Bayesian analysis said there was an <a href=\"https://manifold.markets/LuisCostigan/nof1-blinded-experiment-will-210mg#gMcOYZYQSv4tNwaj7ZmM\">82.6%</a> chance theanine reduced anxiety.</p> <details> The p-value was 0.31, but this is a Bayesian blog\u2014this is what you'd expect with a sample size of 20. <p>A sample size of 20 just doesn\u2019t have enough statistical power to have",
            "title": "My more-hardcore theanine self-experiment"
        },
        {
            "content": [],
            "link": "https://buttondown.com/hillelwayne/archive/requirements-change-until-they-dont/",
            "publishedAt": "2025-04-24",
            "source": "Hillel Wayne",
            "summary": "<p>Recently I got a question on formal methods<sup id=\"fnref:fs\"><a class=\"footnote-ref\" href=\"https://buttondown.com/hillelwayne/rss#fn:fs\">1</a></sup>: how does it help to mathematically model systems when the system requirements are constantly changing? It doesn't make sense to spend a lot of time proving a design works, and then deliver the product and find out it's not at all what the client needs. As the saying goes, the hard part is \"building the right thing\", not \"building the thing right\".</p> <p>One possible response: \"why write tests\"? You shouldn't write tests, <em>especially</em> <a href=\"https://en.wikipedia.org/wiki/Test-driven_development\" target=\"_blank\">lots of unit tests ahead of time</a>, if you might just throw them all away when the requirements change.</p> <p>This is a bad response because we all know the difference between writing tests and formal methods: testing is <em>easy</em> and FM is <em>hard</em>. Testing requires low cost for moderate correctness, FM requires high(ish) cost for high correctness. And when requirements are constantly changing, \"high(ish) cost\" isn't affordable and \"high correctness\" isn't worthwhile, because a kinda-okay solution that solves a customer's problem is infinitely better than a solid solution that doesn't.</p> <p>But eventually you get something that solves the problem, and what then?</p> <p>Most of us don't work for Google, we can't axe features and",
            "title": "Requirements change until they don't"
        },
        {
            "content": [],
            "link": "https://simonwillison.net/2025/Apr/24/exploring-promptfoo/#atom-entries",
            "publishedAt": "2025-04-24",
            "source": "Simon Willison",
            "summary": "<p>I used <a href=\"https://www.propel.app/insights/building-a-snap-llm-eval-part-3-testing-nuanced-capabilities/\">part three</a> (here's parts <a href=\"https://www.propel.app/insights/building-a-snap-llm-eval-part-1/\">one</a> and <a href=\"https://www.propel.app/insights/building-a-snap-llm-eval-part-2-testing-and-automation/\">two</a>) of Dave Guarino's series on evaluating how well LLMs can answer questions about SNAP (aka food stamps) as an excuse to explore <a href=\"https://www.promptfoo.dev/\">Promptfoo</a>, an LLM eval tool.</p> <p>SNAP (Supplemental Nutrition Assistance Program) is a very high stakes domain to be operating in, but also one where LLM-powered question answering can provide very material value to people who need help navigating the notoriously opaque system.</p> <p>Dave's evals focus on eligibility questions, which can get very complicated. One example: \"In Texas, all SNAP applicants face asset limits. In California, the vast majority of people do not.\"</p> <p>Dave uses <a href=\"https://www.promptfoo.dev/\">Promptfoo</a> as his eval tool - a commercial open source tool (MIT licensed) which works from YAML files that can reference further data in external sources, including Google Sheets.</p> <p>His <a href=\"https://github.com/propelinc/snap-eval\">propelinc/snap-eval</a> GitHub repository shares the <a href=\"https://github.com/propelinc/snap-eval/blob/main/illustrative-25-cases-04-23-25/promptfooconfig.yaml\">YAML configuration</a> and a link to <a href=\"https://docs.google.com/spreadsheets/d/1-0zlX-80w7edpOlZWUPvTkp28J4HS_ZyKnuDjDtKeoc/edit?gid=0#gid=0\">the Google Sheet</a>. Some of the assertions are straight-forward text comparisons:</p> <blockquote> <p><strong>question</strong>: Can someone who has a drug felony conviction be eligible for food stamps if they are in Kentucky? Answer with only one of: YES, NO, REFUSE.<br /> <strong>expected</strong>: contains:YES</p> </blockquote> <p>Others use the",
            "title": "Exploring Promptfoo via Dave Guarino's SNAP evals"
        },
        {
            "content": [
                "<p>AI Futures Project is the group behind <a href=\"https://www.astralcodexten.com/p/introducing-ai-2027\">AI 2027</a>. I&#8217;ve been helping them with <a href=\"https://blog.ai-futures.org/\">their blog</a>. Posts written or co-written by me include:</p><ul><li><p><strong><a href=\"https://blog.ai-futures.org/p/beyond-the-last-horizon\">Beyond The Last Horizon</a></strong> - what&#8217;s behind that METR result showing that AI time horizons double every seven months? And is it <em>really</em> every seven months? Might it be faster?</p></li><li><p><strong><a href=\"https://blog.ai-futures.org/p/ai-2027-media-reactions-criticism\">AI 2027: Media, Reactions, Criticism</a></strong> - a look at some of the response to AI 2027, with links to some of the best objections and the team&#8217;s responses.</p></li><li><p><strong><a href=\"https://blog.ai-futures.org/p/why-america-wins\">Why America Wins</a></strong> - why we predict that America will stay ahead of China on AI in the near future, and what could change this.</p></li></ul><p>I will probably be shifting most of my AI blogging there for a while to take advantage of access to the team&#8217;s expertise. There&#8217;s also <a href=\"https://blog.ai-futures.org/p/training-agi-in-secret-would-be-unsafe\">a post on transparency by Daniel Kokotajlo</a>, and we hope to eventually host writing by other team members as well. </p><p>I&#8217;m especially happy with <a href=\"https://blog.ai-futures.org/p/beyond-the-last-horizon\">the horizons post</a>, because we got it out just a few days before a new result that seems to support one of our predictions: OpenAI&#8217;s newest models&#8217; time horizons land on the faster curve we predicted, rather than the slower seven-month doubling time highlighted in the METR report:</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fefe34e2f-0c51-464a-8f60-92635d1d4431_1199x762.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"419.44954128440367\" src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fefe34e2f-0c51-464a-8f60-92635d1d4431_1199x762.png\" width=\"660\" /><div class=\"image-link-expand\"></div></div></a><figcaption class=\"image-caption\">Curvy green dotted line is AIFP prediction; straight black dotted line is seven month doubling time. This isn&#8217;t meant to imply that METR was overconfident in the seven month time; they made it their headline result but mentioned elsewhere in the paper that it sort of seemed to be speeding up.</figcaption></figure></div><p>And speaking of expertise, the AIFP team have kindly volunteered to do an AMA (&#8220;ask me anything&#8221;, Q&amp;A) here on ACX, this Friday, 3:30 - 6:00 PM California time. If you have any questions on the scenario, AI forecasting, or AI safety more generally, they can give you high-quality answers. I&#8217;ll make a separate post at the appointed time.</p>"
            ],
            "link": "https://www.astralcodexten.com/p/ai-futures-blogging-and-ama",
            "publishedAt": "2025-04-24",
            "source": "SlateStarCodex",
            "summary": "<p>AI Futures Project is the group behind <a href=\"https://www.astralcodexten.com/p/introducing-ai-2027\">AI 2027</a>. I&#8217;ve been helping them with <a href=\"https://blog.ai-futures.org/\">their blog</a>. Posts written or co-written by me include:</p><ul><li><p><strong><a href=\"https://blog.ai-futures.org/p/beyond-the-last-horizon\">Beyond The Last Horizon</a></strong> - what&#8217;s behind that METR result showing that AI time horizons double every seven months? And is it <em>really</em> every seven months? Might it be faster?</p></li><li><p><strong><a href=\"https://blog.ai-futures.org/p/ai-2027-media-reactions-criticism\">AI 2027: Media, Reactions, Criticism</a></strong> - a look at some of the response to AI 2027, with links to some of the best objections and the team&#8217;s responses.</p></li><li><p><strong><a href=\"https://blog.ai-futures.org/p/why-america-wins\">Why America Wins</a></strong> - why we predict that America will stay ahead of China on AI in the near future, and what could change this.</p></li></ul><p>I will probably be shifting most of my AI blogging there for a while to take advantage of access to the team&#8217;s expertise. There&#8217;s also <a href=\"https://blog.ai-futures.org/p/training-agi-in-secret-would-be-unsafe\">a post on transparency by Daniel Kokotajlo</a>, and we hope to eventually host writing by other team members as well. </p><p>I&#8217;m especially happy with <a href=\"https://blog.ai-futures.org/p/beyond-the-last-horizon\">the horizons post</a>, because we got it out just a few days before a new result that seems to support one of our predictions: OpenAI&#8217;s newest models&#8217; time horizons land on the faster curve we predicted, rather than the slower seven-month doubling",
            "title": "AI Futures: Blogging And AMA"
        },
        {
            "content": [
                "<p>\n          <a href=\"https://www.astralcodexten.com/p/hidden-open-thread-3785\">\n              Read more\n          </a>\n      </p>"
            ],
            "link": "https://www.astralcodexten.com/p/hidden-open-thread-3785",
            "publishedAt": "2025-04-24",
            "source": "SlateStarCodex",
            "summary": "<p> <a href=\"https://www.astralcodexten.com/p/hidden-open-thread-3785\"> Read more </a> </p>",
            "title": "Hidden Open Thread 378.5"
        },
        {
            "content": [],
            "link": "https://lethain.com/api-deprecation-strategy/",
            "publishedAt": "2025-04-24",
            "source": "Will Larson",
            "summary": "<p>While Stripe is a widely admired company for things like its creation of the <a href=\"https://lethain.com/stripe-sorbet/\">Sorbet typer project</a>, I personally think that Stripe&rsquo;s most interesting strategy work is also among its most subtle: its willingness to significantly prioritize API stability.</p> <p>This strategy is almost invisible externally. Internally, discussions around it were frequent and detailed, but mostly confined to dedicated API design conversations. API stability isn&rsquo;t just a technical design quirk, it&rsquo;s a foundational decision in an API-driven business, and I believe it is one of the unsung heroes of Stripe&rsquo;s business success.</p> <div class=\"bg-light-gray br4 ph3 pv1\"> <p><em>This is an exploratory, draft chapter for a book on engineering strategy that I&rsquo;m brainstorming in <a href=\"https://lethain.com/tags/eng-strategy-book/\">#eng-strategy-book</a>.</em> <em>As such, some of the links go to other draft chapters, both published drafts and very early, unpublished drafts.</em></p> </div> <h2 id=\"reading-this-document\">Reading this document</h2> <p>To apply this strategy, start at the top with <em>Policy</em>. To understand the thinking behind this strategy, read sections in reverse order, starting with <em>Explore</em>.</p> <p>More detail on this structure in <a href=\"https://lethain.com/readable-engineering-strategy-documents\">Making a readable Engineering Strategy document</a>.</p> <h2 id=\"policy--operation\">Policy &amp; Operation</h2> <p>Our policies for managing API changes are:</p> <ul> <li> <p><strong>Design for long API lifetime.</strong> APIs are not inherently durable.",
            "title": "How should Stripe deprecate APIs? (~2016)"
        },
        {
            "content": [],
            "link": "https://lethain.com/api-deprecation-model/",
            "publishedAt": "2025-04-24",
            "source": "Will Larson",
            "summary": "<p><img src=\"https://lethain.com/static/blog/strategy/api-deprecation-full.png\" /></p>&lt;p&gt;In &lt;a href=\"https://lethain.com/api-deprecation-strategy/\"&gt;How should Stripe deprecate APIs?&lt;/a&gt;, the diagnosis depends on the claim that deprecating APIs is a significant cause of customer churn. While there is internal data that can be used to correlate deprecation with churn, it&amp;rsquo;s also valuable to build a model to help us decide if we believe that correlation and causation are aligned in this case.&lt;/p&gt; &lt;p&gt;In this chapter, we&amp;rsquo;ll cover:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;What we learn from modeling API deprecation&amp;rsquo;s impact on user retention&lt;/li&gt; &lt;li&gt;Developing a system model using the &lt;a href=\"https://github.com/lethain/systems\"&gt;lethain/systems&lt;/a&gt; package on GitHub. That model &lt;a href=\"https://github.com/lethain/eng-strategy-models/blob/main/APIDeprecationModel.ipynb\"&gt;is available in the lethain/eng-strategy-models&lt;/a&gt; repository&lt;/li&gt; &lt;li&gt;Exercising that model to learn from it&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Time to investigate whether it&amp;rsquo;s reasonable to believe that API deprecation is a major influence on user retention and churn.&lt;/p&gt; &lt;div class=\"bg-light-gray br4 ph3 pv1\"&gt; &lt;p&gt;&lt;em&gt;This is an exploratory, draft chapter for a book on engineering strategy that I\u2019m brainstorming in&lt;/em&gt; &lt;em&gt;&lt;a href=\"https://lethain.com/tags/eng-strategy-book/\"&gt;#eng-strategy-book&lt;/a&gt;.&lt;/em&gt; &lt;em&gt;As such, some of the links go to other draft chapters, both published drafts and very early, unpublished drafts.&lt;/em&gt;&lt;/p&gt; &lt;/div&gt; &lt;h2 id=\"learnings\"&gt;Learnings&lt;/h2&gt; &lt;p&gt;In an initial model that has 10% baseline for customer churn per round, reducing customers experiencing API deprecation from 50% to 10% per round only increases the steady",
            "title": "Systems model of API deprecation"
        }
    ],
    "lookbackDays": 1,
    "publishDate": "2025-04-24"
}