{
    "articles": [
        {
            "content": [
                "<div class=\"trix-content\">\n  <div><a href=\"https://github.com/basecamp/omarchy/releases/tag/v2.0.0\">Omarchy 2.0</a> was released on <a href=\"https://gbhackers.com/happy-birthday-linux/\">Linux's 34th birthday</a> as a gift to perhaps the greatest open-source project the world has ever known. Not only does Linux run 95% of all servers on the web, billions of devices as an embedded OS, but it also turns out to be an incredible desktop environment!</div><div><br /></div><div>It's crazy that it took me more than thirty years to realize this, but while I spent time in Apple's walled garden, the free software alternative simply grew better, stronger, and faster. The Linux of 2025 is not the Linux of the 90s or the 00s or even the 10s. It's shockingly more polished, capable, and beautiful.</div><div><br /></div><div>It's been an absolute honor to celebrate Linux with the making of <a href=\"https://omarchy.org\">Omarchy</a>, the new Linux distribution that I've spent the last few months building on top of Arch and Hyprland. What began as a post-install script has turned into a full-blown ISO, dedicated package repository, and <a href=\"https://discord.gg/tXFUdasqhY\">flourishing community</a> of thousands of enthusiasts all collaborating on making it better.</div><div><br /></div><div>It's been improving rapidly with <a href=\"https://github.com/basecamp/omarchy/releases\">over twenty releases</a> since the premiere in late June, but this Version 2.0 update is the biggest one yet. If you've been curious about giving Linux a try, you're not afraid of an operating system that asks you to level up and learn a little, and you want to see what a totally different computing experience can look and feel like, I invite you to give it a go.</div><div><br /></div><div>Here's a <a href=\"https://www.youtube.com/watch?v=TcHY0AEd2Uw\">full tour of Omarchy 2.0</a>.<br /><br />  <figure class=\"attachment attachment--preview attachment--lightboxable attachment--webp\">\n      <a href=\"https://world.hey.com/dhh/16fefc15/blobs/eyJfcmFpbHMiOnsiZGF0YSI6MjI0MDc0MjM4NywicHVyIjoiYmxvYl9pZCJ9fQ--a72c47c1a929f74e8d08df2da31bdb6f31ed6d0f9027dbd4c066a9c7e1ad337a/omarchy-2.0.webp?disposition=attachment\" title=\"Download omarchy-2.0.webp\">\n        <img alt=\"omarchy-2.0.webp\" src=\"https://world.hey.com/dhh/16fefc15/representations/eyJfcmFpbHMiOnsiZGF0YSI6MjI0MDc0MjM4NywicHVyIjoiYmxvYl9pZCJ9fQ--a72c47c1a929f74e8d08df2da31bdb6f31ed6d0f9027dbd4c066a9c7e1ad337a/eyJfcmFpbHMiOnsiZGF0YSI6eyJmb3JtYXQiOiJ3ZWJwIiwicmVzaXplX3RvX2xpbWl0IjpbMzg0MCwyNTYwXSwicXVhbGl0eSI6NjAsImxvYWRlciI6eyJwYWdlIjpudWxsfSwiY29hbGVzY2UiOnRydWV9LCJwdXIiOiJ2YXJpYXRpb24ifX0--12725a832e6e7b2dd7d56a507f20442609781a7502597503a7a5e38f72548391/omarchy-2.0.webp\" />\n</a>\n  </figure></div>\n</div>"
            ],
            "link": "https://world.hey.com/dhh/omarchy-2-0-16fefc15",
            "publishedAt": "2025-08-26",
            "source": "DHH",
            "summary": "<div class=\"trix-content\"> <div><a href=\"https://github.com/basecamp/omarchy/releases/tag/v2.0.0\">Omarchy 2.0</a> was released on <a href=\"https://gbhackers.com/happy-birthday-linux/\">Linux's 34th birthday</a> as a gift to perhaps the greatest open-source project the world has ever known. Not only does Linux run 95% of all servers on the web, billions of devices as an embedded OS, but it also turns out to be an incredible desktop environment!</div><div><br /></div><div>It's crazy that it took me more than thirty years to realize this, but while I spent time in Apple's walled garden, the free software alternative simply grew better, stronger, and faster. The Linux of 2025 is not the Linux of the 90s or the 00s or even the 10s. It's shockingly more polished, capable, and beautiful.</div><div><br /></div><div>It's been an absolute honor to celebrate Linux with the making of <a href=\"https://omarchy.org\">Omarchy</a>, the new Linux distribution that I've spent the last few months building on top of Arch and Hyprland. What began as a post-install script has turned into a full-blown ISO, dedicated package repository, and <a href=\"https://discord.gg/tXFUdasqhY\">flourishing community</a> of thousands of enthusiasts all collaborating on making it better.</div><div><br /></div><div>It's been improving rapidly with <a href=\"https://github.com/basecamp/omarchy/releases\">over twenty releases</a> since the premiere in late June, but this Version 2.0 update is the biggest one yet. If",
            "title": "Omarchy 2.0"
        },
        {
            "content": [
                "<div class=\"trix-content\">\n  <div>The Danish flag is everywhere in Denmark. It's at the airport when parents greet their kids coming back from holiday. It's on the birthday cake when you invite people over. It's swinging from the flagpoles in house after house, especially in the countryside. It's on the buses on the monarch's birthday. It's <em>everywhere</em> and <em>all the time</em>.<br /><br /></div><div>I love it.<br /><br /></div><div>I love that the Danes are so proud of their country that the flag is the most common symbol for celebrating any momentous occasion. Even just returning from a trip! Because being a Dane means something to the Danish. It's a unique identity, separate from everyone else in the world. It's local, it's close, it's personal.<br /><br /></div><div>It's not like that everywhere. It seems like the American flag, for example, has now been solidly right-wing coded. You don't see many progressives putting up big flags in their backyards anymore. And you certainly don't see them putting American flags on their birthday cakes, like the Danes.</div><div><br />What a shame to feel such shame about the country you live in.<br /><br /></div><div>Don't get me wrong, the Danes don't all love everything going on in Denmark either. It's a national sport to rag on politicians. To complain about municipal services. To want things to be better.&nbsp;<br /><br /></div><div>Perfectly healthy for a country to wish to see improvement. But once that search for better tips over into disliking or outright hating the national symbols, you're off the rails, and much less likely to actually fix anything.</div><div><br />Don't even get me started with the UK. It seems flying the English flag is now as transgressive as posting you're not a big fan of mass immigration on Facebook. And given that the latter&nbsp; is already likely to land you <a href=\"https://freespeechunion.org/police-make-30-arrests-a-day-for-offensive-online-messages/\">in trouble with the increasingly authoritarian state</a>, it seems likely that the former might soon too.</div><div><br />National pride is a cornerstone of building a high-trust society.&nbsp; It flows from a strong national identity that defines clear norms, values, and priorities. What better reason than that to raise the flag!<br /><br />  <figure class=\"attachment attachment--preview attachment--lightboxable attachment--webp\">\n      <a href=\"https://world.hey.com/dhh/f7aa1e92/blobs/eyJfcmFpbHMiOnsiZGF0YSI6MjI0MDEzNTI5NCwicHVyIjoiYmxvYl9pZCJ9fQ--30973e207861800e69a872f832fa69ffb5f453375e2707ec405a3771818130cd/lagkage-med-jordbar-og-malkechokolade.WebP?disposition=attachment\" title=\"Download lagkage-med-jordbar-og-malkechokolade.WebP\">\n        <img alt=\"lagkage-med-jordbar-og-malkechokolade.WebP\" src=\"https://world.hey.com/dhh/f7aa1e92/representations/eyJfcmFpbHMiOnsiZGF0YSI6MjI0MDEzNTI5NCwicHVyIjoiYmxvYl9pZCJ9fQ--30973e207861800e69a872f832fa69ffb5f453375e2707ec405a3771818130cd/eyJfcmFpbHMiOnsiZGF0YSI6eyJmb3JtYXQiOiJXZWJQIiwicmVzaXplX3RvX2xpbWl0IjpbMzg0MCwyNTYwXSwicXVhbGl0eSI6NjAsImxvYWRlciI6eyJwYWdlIjpudWxsfSwiY29hbGVzY2UiOnRydWV9LCJwdXIiOiJ2YXJpYXRpb24ifX0--5ea4b62bb72a11573321a73872ad85989caf9ee078a0893dec2b7fcb53a7df43/lagkage-med-jordbar-og-malkechokolade.WebP\" />\n</a>\n  </figure></div>\n</div>"
            ],
            "link": "https://world.hey.com/dhh/national-pride-f7aa1e92",
            "publishedAt": "2025-08-26",
            "source": "DHH",
            "summary": "<div class=\"trix-content\"> <div>The Danish flag is everywhere in Denmark. It's at the airport when parents greet their kids coming back from holiday. It's on the birthday cake when you invite people over. It's swinging from the flagpoles in house after house, especially in the countryside. It's on the buses on the monarch's birthday. It's <em>everywhere</em> and <em>all the time</em>.<br /><br /></div><div>I love it.<br /><br /></div><div>I love that the Danes are so proud of their country that the flag is the most common symbol for celebrating any momentous occasion. Even just returning from a trip! Because being a Dane means something to the Danish. It's a unique identity, separate from everyone else in the world. It's local, it's close, it's personal.<br /><br /></div><div>It's not like that everywhere. It seems like the American flag, for example, has now been solidly right-wing coded. You don't see many progressives putting up big flags in their backyards anymore. And you certainly don't see them putting American flags on their birthday cakes, like the Danes.</div><div><br />What a shame to feel such shame about the country you live in.<br /><br /></div><div>Don't get me wrong, the Danes don't all love everything going on in Denmark either. It's a",
            "title": "National pride"
        },
        {
            "content": [
                "<p><video controls=\"controls\" loop=\"loop\" style=\"height: auto;\"><source src=\"https://grumpy.website/media/2025/1695.mp4\" type=\"video/mp4\" /></video></p><p><strong>nikitonsky: </strong>It\u2019s good to have fallback... s?</p><p><a href=\"https://grumpy.website/search?q=%23GoogleMaps\">#GoogleMaps</a> <a href=\"https://grumpy.website/search?q=%23Zoom\">#Zoom</a> <a href=\"https://grumpy.website/search?q=%23Fallback\">#Fallback</a></p>"
            ],
            "link": "https://grumpy.website/1695",
            "publishedAt": "2025-08-26",
            "source": "Grumpy UX",
            "summary": "<p><video controls=\"controls\" loop=\"loop\" style=\"height: auto;\"><source src=\"https://grumpy.website/media/2025/1695.mp4\" type=\"video/mp4\" /></video></p><p><strong>nikitonsky: </strong>It\u2019s good to have fallback... s?</p><p><a href=\"https://grumpy.website/search?q=%23GoogleMaps\">#GoogleMaps</a> <a href=\"https://grumpy.website/search?q=%23Zoom\">#Zoom</a> <a href=\"https://grumpy.website/search?q=%23Fallback\">#Fallback</a></p>",
            "title": "nikitonsky is being grumpy"
        },
        {
            "content": [
                "<p>AI psychosis (<a href=\"https://archive.is/vAYif\">NYT</a>, <a href=\"https://www.psychologytoday.com/us/blog/urban-survival/202507/the-emerging-problem-of-ai-psychosis\">PsychologyToday</a>) is an apparent phenomenon where people go crazy after talking to chatbots too much. There are some high-profile anecdotes, but still many unanswered questions. For example, how common is it really? Are the chatbots really driving people crazy, or just catching the attention of people who were crazy already? Isn&#8217;t psychosis supposed to be a biological disease? Wouldn&#8217;t that make chatbot-induced psychosis the same kind of category error as chatbot-induced diabetes?</p><p>I don&#8217;t have all the answers, so think of this post as an exploration of possible analogies and precedents rather than a strongly-held thesis. Also, I might have one answer - I think the yearly incidence of AI psychosis is somewhere around 1 in 10,000 (for a loose definition) to 1 in 100,000 (for a strict definition). I&#8217;ll talk about how I got those numbers at the end. But first:</p><h3>I. Lenin Was A Mushroom</h3><p>In the early 1990s, as the Soviet Union was collapsing, performance artist Sergey Kuryokhin <a href=\"https://slatestarcodex.com/Stuff/yurchak2011.pdf\">presented </a>a <em>Daily Show</em> style segment on a Russian talk show. He argued that Vladimir Lenin ate so many mushrooms that he eventually turned into a mushroom, and led the October Revolution while possessed by a sentient mushroom spirit. </p><p>Today this all sounds banal - just another schizo conspiracy theory that probably wouldn&#8217;t even get enough YouTube clicks to earn back its production cost. But 1990s Russians were used to a stodgy, dignified version of state TV. While it&#8217;s an exaggeration to say it would never lie to them, it would at least be <em>comprehensible</em> lies, like how the latest Five Year Plan was right on track. And Kuryohkin designed his piece masterfully, interviewing leading authorities about tangentially related topics (&#8220;so, you&#8217;re the world&#8217;s top Lenin biographer, would you agree that Lenin often ate mushrooms?&#8221;) and splicing the footage to look like a growing scholarly consensus. The result basically one-shotted a large segment of the Russian populace. According <a href=\"https://en.wikipedia.org/wiki/Lenin_was_a_mushroom\">to Wikipedia</a>:</p><blockquote><p>A large number of Soviet citizens (one estimate puts the number at 11.3 million audience members) took the deadpan \"interview\" at face value, in spite of the absurd claims presented. Sholokhov has said that perhaps the most notable result of the show was an appeal by a group of party members to the Leningrad Regional Committee of the CPSU to clarify the veracity of Kuryokhin's claim. According to Sholokhov, in response to the request one of the top regional functionaries stated that \"Lenin could not have been a mushroom\" because \"a mammal cannot be a plant.\"</p></blockquote><p>Aside from the usual conclusion (that history is more charming and fascinating than you can imagine) I conclude two things from this incident.</p><p>First, much like LLMs, lots of people don&#8217;t really have world models. They believe what their friends believe, or what has good epistemic vibes. If they don&#8217;t currently think that Lenin was a mushroom, it&#8217;s not because they understand human agency /  scientific materialism / psychedelia and have a well-worked out theory of why fungi can&#8217;t contain sentient mushroom spirits that possess leading communist politicians. They don&#8217;t believe it because it feels absurd. They predict that other people would laugh at them if they said it. If they get told that it it&#8217;s <em>not</em> absurd, or that maybe people would laugh at them if they <em>didn&#8217;t</em> say it, then their opinion will at least teeter precariously.</p><p>But second, if a source which should be official starts acting in unofficial ways, it can take people a while to catch on. And I think some people - God help them - treat AI as the sort of thing which should be official. Science fiction tells us that AIs are smarter than us - or, if not smarter, at least perfectly rational computer beings who dwell in a world of mathematical precision. And ChatGPT is produced by OpenAI, a $300 billion company run by Silicon Valley wunderkind Sam Altman. If your drinking buddy says you&#8217;re a genius, you know he&#8217;s probably putting you on. If the perfectly rational machine spirit trained in a city-sized data center by the world&#8217;s most cutting-edge company says you&#8217;re a genius . . . maybe you&#8217;re a genius?</p><p>Kelsey Piper discusses her new parenting technique: when her young daughter refuses to hear reason, they ask the AI who&#8217;s right. The AI says she should listen to her parents, and the child is mollified:</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2\" href=\"https://x.com/KelseyTuoc/status/1957966301370151098\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"366.3174061433447\" src=\"https://substackcdn.com/image/fetch/$s_!Zfdf!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4ecd6b57-34bd-4ce8-a5b8-981fde02b45a_586x399.png\" width=\"538\" /><div></div></div></a></figure></div><p>I&#8217;m not making fun of Kelsey or her daughter here. Something about this rings true to me. When I was eight years old, I wouldn&#8217;t have cared much what my parents thought either. But if <em>the</em> <em>computer</em> believed it, that would be a different story!</p><h3>II. In Search Of . . . Social Media Psychosis?</h3><p>In case you&#8217;ve been hiding under a rock for the past ten years: QAnon is a right-wing conspiracy theory. The most common version claims that liberal elites, especially Hillary Clinton, molest young children to extract an immortality serum from their blood. Donald Trump figured this out and is trying to stop them, but for some reason he can&#8217;t play his hand openly, so he has to pursue a roundabout strategy involving winning the Presidency and dismantling the liberal order from above. Everything that has happened in politics over the past ten years has been part of the shadow war between Trump and the immortal pedophile conspiracy.</p><p>This is pretty crazy. But is it <em>psychotic</em>? And since it spread through sites like 4chan and Facebook, should we invent a new diagnostic entity, &#8220;social media psychosis&#8221;, to cover it?</p><p>These are tough questions, but in the end we didn&#8217;t do this. </p><p>I think this was partly because there was a pre-existing category, &#8220;conspiracy theory&#8221;, that seemed like a better fit. We concluded that &#8220;sometimes social media facilitates the spread of conspiracy theories&#8221;, but stepped back from saying &#8220;social media can induce psychosis&#8221;.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!HDQb!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fece0561a-a62c-4eb6-8e23-7c0db5cb8a0b_749x479.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"393.94392523364485\" src=\"https://substackcdn.com/image/fetch/$s_!HDQb!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fece0561a-a62c-4eb6-8e23-7c0db5cb8a0b_749x479.png\" width=\"616\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a><figcaption class=\"image-caption\">And by &#8220;in the end we didn&#8217;t do this&#8221;, I mean &#8220;we absolutely did it, but forgot about it later.&#8221;</figcaption></figure></div><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!mYKR!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F03938197-ae2c-4dde-88d4-c22f66e34c09_767x681.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"559.361147327249\" src=\"https://substackcdn.com/image/fetch/$s_!mYKR!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F03938197-ae2c-4dde-88d4-c22f66e34c09_767x681.png\" width=\"630\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a><figcaption class=\"image-caption\">I think now there might be several dozen subreddit moderators who could accurately describe their job as &#8220;witch webmaster who runs an online service giving advice to new witches&#8221;.</figcaption></figure></div><p>And partly it was because there are so many crazy beliefs in the world - spirits, crystal healing, moon landing denial, esoteric Hitlerism, whichever religions you don&#8217;t believe in - that psychiatrists have instituted a blanket exemption for any widely held idea. If you think you&#8217;re being attacked by demons, you&#8217;re delusional, <em>unless</em> you&#8217;re from some culture where lots of people get attacked by demons, in which case it&#8217;s a religion and you&#8217;re fine. This is partly political self-protection - no psychiatrist wants to be the guy who commits an Afro-Caribbean person for believing in voodoo. But it also seems to track something useful about reality. Nietzsche wrote &#8220;Madness is something rare in individuals &#8212; but in groups, parties, peoples, and ages, it is the rule.&#8221; Most people don&#8217;t have world-models - they believe what their friends believe, or what has good epistemic vibes. In a large group, weird ideas can ricochet from person to person and get established even in healthy brains. In an Afro-Caribbean culture where all your friends get attacked by demons at voodoo church every Sunday, a belief in demon attacks can co-exist with otherwise being a totally functional individual. </p><p>So is QAnon a religion? Awkward question, but it&#8217;s non-psychotic by definition. Still, it&#8217;s interesting, isn&#8217;t it? If social media makes a thousand people believe the same crazy thing, it&#8217;s not psychotic. If LLMs make a thousand people each believe a different crazy thing, that <em>is</em> psychotic. Is this a meaningful difference, or an accounting convention?</p><p>Also, what if a thousand people believe something, but it&#8217;s you and your 999 ChatGPT instances?</p><h3>III. A Hidden Army Of Crackpots</h3><p>I have a family member who believes that the theory of evolution, as usually understood, cannot possibly work. He has developed an alternative theory called &#8220;noctogenesis&#8221; which patches Darwinism using ideas from <a href=\"https://en.wikipedia.org/wiki/Transactional_interpretation\">the transactional interpretation of quantum mechanics</a>, and he works on-and-off on various related books and papers. I have told him I suspect he might be a crackpot; he stands by his claims. It&#8217;s fine; when I got into the technological singularity and AI safety, lots of people suspected I was a crackpot, and I stood by my claims too. You&#8217;ve got to stand by your family members even when they&#8217;re slightly crackpottish.</p><p>This family member is happily married, retired after running a successful business, and generally a normal likeable person. He has no signs of mental illness, and doesn&#8217;t talk about quantum evolution unless someone else brings it up first. There must be millions of people like him. Used car dealers with proofs of P = NP, dentists who think they&#8217;ve discovered something important about Mary Magdalene, <a href=\"https://en.wikipedia.org/wiki/Alexander_Abian\">math professors obsessed with destroying the moon</a>.</p><p>I&#8217;m working on evaluating <a href=\"https://www.astralcodexten.com/p/apply-for-an-acx-grant-2025\">ACX Grants</a>, and these people are out in force. A few propose literal perpetual motion machines. Others have vaguer plans, like some kind of social media app (it&#8217;s always a social media app) that will cause world peace. Many of them have decent jobs and seem like upstanding members of society. Their secrets are known only to themselves, their family members, and their would-be grantmaker.</p><p>&#8230;and, increasingly, their chatbots. After years of hiatus (or at least not talking to me about his work) my family member is back on the quantum evolution beat, and LLMs appear to be involved. If I knew him less well, I would think the LLM had <em>caused</em> the quantum evolution theory - but no, it just made it much easier to research and write about.</p><p>Is this psychosis? The answer has to be no, but it&#8217;s once again hard to draw the line. A very small number of crackpots will be vindicated by history. A larger number will be erroneous but sympathetic - the official account of the Kennedy assassination is pretty weird, and reasonable minds can disagree. From there, we get to ones that are maybe not so sympathetic: flat earth, QAnon, the thing where the Queen was an alien lizard. If only one person thought the Queen was an alien lizard, and they never managed to convince anyone else, would that be sufficient evidence for a delusional disorder? I&#8217;m not sure.</p><p>(psychiatry has a diagnosis, schizotypal personality, which sort of involves being a normal person with a few odd ideas, but it&#8217;s not a great match for many of these people, and interesting mainly as a genetic curiosity - it travels in the same families as schizophrenia itself)</p><p>Maybe this is another place where we are forced to admit <a href=\"https://lorienpsych.com/2020/10/30/ontology-of-psychiatric-conditions-taxometrics/\">a spectrum model of psychiatric disorders</a> - there is an unbroken continuum from mildly sad to suicidally depressed, from social drinking to raging alcoholism, and from eccentric to floridly psychotic. People who are eccentric can remain so their whole lives, with the level of expression depending on their social connections and the ease of pursuing their rabbit holes. </p><p>LLMs, by making it easier to pursue odd theories and serving as a surrogate social connection who always agrees with you, can bring latent crackpottery into the open.</p><h3>IV. Cause And Effect</h3><p>Bipolar disorder has an interesting relationship with sleep. Most manic people sleep very little, or not at all - maybe an hour or two a night. But also, poor sleep can cause bipolar episodes in people prone to them. In a typical case, a bipolar who&#8217;s been well-controlled for years will get assigned a big report at work and get poor sleep for a few nights until they finish. At first, this will be just as bad as it sounds, and they&#8217;ll be working through a fog of tiredness. Then the tiredness will lift. They&#8217;ll feel normal, then better-than-normal, until finally they can&#8217;t sleep even if they want to. Then they&#8217;ll email the report to their boss and it will be written entirely in Assyrian cuneiform.</p><p>I increasingly think this isn&#8217;t just an incidental feature of bipolar, but part of the reason it exists as a diagnostic category at all. Most people have a compensatory reaction to insomnia - missing one night of sleep makes you more tired the next. A small number of people have the reverse, a spiralling reaction where missing one night of sleep makes you <em>less</em> tired the next. Solve for the equilibrium and you reach a stable attractor point where you never sleep at all. But this does other bad things to your brain - hence the cuneiform.</p><p>I&#8217;m not claiming that bipolar is &#8220;just&#8221; sleep loss. <a href=\"https://slatestarcodex.com/2016/12/14/ssc-journal-club-mental-disorders-as-networks/\">As Borsboom et al will tell you</a>, psychiatric disorders can be viewed as complex networks of symptoms, each reinforcing the others. In a few pure cases, you can get a ratchet going with sleep alone, and the sleeplessness will spark everything else. More likely, there will be lots of interactions between poor sleep and everything else, and the &#8220;everything else&#8221; can sink or hypercharge an impending manic episode. Still, I find this a fruitful way to think about bipolar. Sleeplessness is both the cause and the effect.</p><p>Can delusions also be like this?</p><p>That is, suppose there&#8217;s some personality trait where having one delusion makes you even more delusional. Maybe the delusion makes you excited (who <em>wouldn&#8217;t</em> be excited to learn they&#8217;re the Messiah?), and you&#8217;re more delusional when you&#8217;re in an excited state and not thinking clearly. Or maybe it&#8217;s a three-symptom cycle - the delusion causes excitement, which makes you unable to sleep, which scrambles your thinking, which makes you more delusional (which makes you even less able to sleep, etc). The point is: delusions are certainly an effect of bipolar disorder. And in <a href=\"https://lorienpsych.com/2020/11/11/ontology-of-psychiatric-conditions-dynamic-systems/\">the dynamical system model of psychiatric disorders</a>, we should expect that effects are often also causes; that&#8217;s how the vicious cycle gets going. </p><p>This is the best I can do at modeling true LLM psychosis. Someone with a trait where delusions lead inevitably to more delusions starts using an LLM. The LLM accentuates whatever usual tendency towards crackpottery they have and makes them believe something a little crazier than whatever they believed before. Then that crazy belief feeds upon itself and causes other things like excitement and sleep loss, which (if the person is predisposed) precipitates a true psychotic episode. </p><h3>V. Folie A Deux Ex Machina</h3><p>If one person believes a crazy thing, it&#8217;s a delusion; if a thousand people believe it, it&#8217;s a religion. What if exactly two people believe it?</p><p>In psychiatry, this is called <em><a href=\"https://en.wikipedia.org/wiki/Folie_%C3%A0_deux\">folie a deux</a></em>. It fits awkwardly into our nosology and is rarely seen. Still, it happens enough to generate a few case studies. In a typical case, one person has psychosis for some normal reason, like schizophrenia or bipolar, and the second person is a shut-in who lives with them and rarely talks to anyone else. The psychotic person gets some normal psychotic delusion - they&#8217;re God, the Feds are after them, etc - and sort of psychically steamrolls over the second person until they believe it too. Usually removing the second person from the first is sufficient for a cure.</p><p>This slightly challenges the view of psychosis as a biological disorder - but only slightly. Again, think of most people as lacking world-models, but being moored to reality by some vague sense of social consensus. If your social life is limited to one person, and that person themselves becomes unmoored, then sometimes you will follow along. I would expect second-sufferers to believe delusions in a sort of cognitively normal way, the same way people believe true facts, honest mistakes, and conspiracy theories. I would expect them to be less likely (though not zero likely) to have other psychotic features like sleep disturbances, hallucinations, disorganized speech, or a tendency to autonomously generate delusional ideas aside from the one they absorbed from the index case.</p><p>An introverted person using an LLM has some similarities to <em>folie a deux</em>. If they use the chatbot very often, it might be a large majority of their social interactions. Here the primary vs. secondary distinction breaks down - the most likely scenario is that the human first suggested the crazy idea, the machine reflected it back slightly stronger, and it kept ricocheting back and forth, gaining confidence with each iteration, until both were totally convinced. Compare this to normal social interactions, where if someone expresses a crazy idea that isn&#8217;t common in their culture, other people will shoot them down or at the very least nod politely and stop the conversation.</p><p>So my working theory of LLM psychosis is:</p><ul><li><p>Some patients were already psychotic, and LLMs just help them be psychotic more effectively.</p></li><li><p>Other patients had a subclinical tendency towards crackpottishness, and LLMs helped them be crackpottish more effectively, to the point where it started looking really bad and coming to other people&#8217;s attention.</p></li><li><p>Other patients had weak world models, and perhaps a very weak subclinical tendency towards crackpottery that never would have surfaced at all. But unmoored from their usual social connections, and instead stuck in focused conversation with a &#8220;friend&#8221;/&#8221;community&#8221;/&#8221;culture&#8221; that repeated all of their weirdest ideas back to them, they became much more crackpottish than they would have been otherwise.</p></li><li><p>A small number of patients might have started out becoming only a little more crackpottish, but that in itself precipitated a full manic episode and they became floridly psychotic.</p></li></ul><h3>VI. The Survey</h3><p>In order to assess the epidemiology and nosology of AI psychosis, I surveyed readers of my blog. I asked them to take the survey without knowing what it was about (to avoid selection bias), and got 4,156 responses.</p><p>The primary question was whether anyone &#8220;close to you&#8221; - defined as your self, family, co-workers, or 100 closest friends - had shown signs of AI psychosis. 98.1% of people said no, 1.7% said yes.</p><p>How do we translate this into a prevalence? Suppose that respondents had an average of fifty family members and co-workers, so that plus their 100 closest friends makes 150 people. Then the 4,156 respondents have 623,400 people who are &#8220;close&#8221;. Among them, they reported 77 cases of AI psychosis in people close to them (a few people reported more than one case). 77/623,400 = 1/8,000. Since LLMs have only been popular for a year or so, I think this approximates a yearly incidence, and I rounded it off to my 1/10,000 guess above.</p><p>Can you really do things this way? Might people do a bad job tabulating their 100 closest friends, etc? I tried to see if this methodology would return correct results on known questions by asking respondents how many people &#8220;close to them&#8221; had identical twins, or were named Michael. To my surprise, calculating prevalence based on survey results matched known rates of both conditions very closely (0.3% vs. 0.4% for twins, 1.2% vs. 1.3% for Michaels in the US). </p><p>Obvious remaining issues:</p><ul><li><p>Might some people get LLM psychosis without their friends knowing it? Obviously yes; this should be taken as an estimate of the incidence of psychosis severe enough to be noticeable to friends.</p></li><li><p>Might ACX readers be unrepresentative? Obviously yes, although it&#8217;s not clear which direction. Readers tend to be more interested in and willing to use AI than the general public, and more willing to think about speculative and controversial ideas on their own (maybe a risk factor?). But they&#8217;re also richer and more educated, and mostly understand enough about AI to avoid the pure perfect machine spirit failure mode. Overall it seems like a wash. Also, I would expect their friends and family to be less unrepresentative than they are.</p></li><li><p>Might rates vary by country? Obviously yes, although I analyzed the data separately for Americans and non-Americans and didn&#8217;t find any difference.</p></li><li><p>Might some of these people&#8217;s social circles overlap, such that we&#8217;re double-counting the same cases? ACX readers come from all over the world, so I think this is unlikely to be a major issue.</p></li></ul><p>None of these concerns make me reluctant to use this number as it was intended: an order-of-magnitude estimate in the total absence of any other attempt to study this condition.</p><p>What else can we learn about AI psychosis from this survey? I asked people to describe the cases they were talking about. 66 responses were clear enough to code. Of those, 6 did not really seem psychotic (for example, they involved people treating AI like a romantic partner). Of the remaining 60, I coded them into four categories:</p><ul><li><p><strong>Definitely psychotic even before the AI (n=19)</strong>, if the respondent said the friend had a pre-existing diagnosis of schizophrenia, bipolar, or other psychotic mental illness.</p></li><li><p><strong>Not</strong> <strong>previously psychotic but major risk factors (n=19)</strong>, if the respondent volunteered the information that the friend had some sort of issues even before encountering the AI. These included use of psychosis-inducing drugs, obsession with conspiracy theories, or diagnosis with a condition like PTSD or borderline personality.</p></li><li><p><strong>No previous risk factors but had merely become somewhat crackpottish (n=16)</strong>, if the respondent said the friend had gotten weird ideas from the AI but they weren&#8217;t a clear match for a psychotic picture. For example, the friend might have become a math crackpot, or gotten really into crystals, or thought that the AI had &#8220;awoken&#8221; and was &#8220;really talking to them&#8221;, but otherwise remained mostly normal.</p></li><li><p><strong>No previous risk factors, and now totally psychotic (n=6),</strong> if the respondent didn&#8217;t mention any previous history of psychosis or concerning behavior, and their friend&#8217;s post-LLM state did seem like real clinical psychosis.</p></li></ul><p>We see that the nightmare scenario - a person with no previous psychosis history or risk factor becoming fully psychotic - was uncommon, at only 10% of cases. Most people either had a previous psychosis history known to the respondent, or had some obvious risk factor, or were merely crackpots rather than full psychotics.</p><p>If we limit the term &#8220;AI psychosis&#8221; to people with no previous risk factors who are now fully psychotic, I estimate the strict incidence at one tenth of the loose incidence, so 1/100,000 people per year.</p><p>As always, you can try to replicate my work using <a href=\"http://slatestarcodex.com/Stuff/llmpsychosis_public.ods\">this publicly available version of the survey data</a>. If you get slightly different answers than I did, it&#8217;s because I&#8217;m using the full dataset which includes a few people who didn&#8217;t want their answers publicly released. If you get very different answers than I did, it&#8217;s because I made a mistake, and you should tell me.</p>"
            ],
            "link": "https://www.astralcodexten.com/p/in-search-of-ai-psychosis",
            "publishedAt": "2025-08-26",
            "source": "SlateStarCodex",
            "summary": "<p>AI psychosis (<a href=\"https://archive.is/vAYif\">NYT</a>, <a href=\"https://www.psychologytoday.com/us/blog/urban-survival/202507/the-emerging-problem-of-ai-psychosis\">PsychologyToday</a>) is an apparent phenomenon where people go crazy after talking to chatbots too much. There are some high-profile anecdotes, but still many unanswered questions. For example, how common is it really? Are the chatbots really driving people crazy, or just catching the attention of people who were crazy already? Isn&#8217;t psychosis supposed to be a biological disease? Wouldn&#8217;t that make chatbot-induced psychosis the same kind of category error as chatbot-induced diabetes?</p><p>I don&#8217;t have all the answers, so think of this post as an exploration of possible analogies and precedents rather than a strongly-held thesis. Also, I might have one answer - I think the yearly incidence of AI psychosis is somewhere around 1 in 10,000 (for a loose definition) to 1 in 100,000 (for a strict definition). I&#8217;ll talk about how I got those numbers at the end. But first:</p><h3>I. Lenin Was A Mushroom</h3><p>In the early 1990s, as the Soviet Union was collapsing, performance artist Sergey Kuryokhin <a href=\"https://slatestarcodex.com/Stuff/yurchak2011.pdf\">presented </a>a <em>Daily Show</em> style segment on a Russian talk show. He argued that Vladimir Lenin ate so many mushrooms that he eventually turned into a mushroom, and led the October Revolution while possessed by a",
            "title": "In Search Of AI Psychosis"
        },
        {
            "content": [
                "<p>In the wake of the confusions around GPT-5, this week had yet another round of claims that AI wasn\u2019t progressing, or AI isn\u2019t or won\u2019t create much value, and so on. There were reports that one study in particular impacted Wall Street, and as you would expect it was not a great study. Situational awareness is not what you\u2019d hope.</p>\n<p>I\u2019ve gathered related coverage here, to get it out of the way before whatever Google is teasing (Gemini 3.0? Something else?) arrives to potentially hijack our attention.</p>\n<p>We\u2019ll start with the MIT study on State of AI in Business, discuss the recent set of \u2018AI is slowing down\u2019 claims as part of the larger pattern, and then I will share a very good attempted explanation from Steven Byrnes of some of the ways economists get trapped into failing to look at what future highly capable AIs would actually do.</p>\n<div>\n\n\n<span id=\"more-24675\"></span>\n\n\n</div>\n\n\n<h4 class=\"wp-block-heading\">Standing On Lack of AI Business</h4>\n\n\n<p>Chatbots and coding agents are clear huge wins. Over 80% of organizations have \u2018explored or piloted\u2019 them and 40% report deployment. The employees of the other 60% presumably have some news.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!4zS9!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7625519e-87b0-4902-9ef5-70e981a3ceb5_890x204.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p><a href=\"https://t.co/STdh7h7KJg\">But we have a new State of AI in Business report</a> that says that when businesses try to do more than that, \u201895% of businesses get zero return,\u2019 although elsewhere they say \u2018only 5% custom enterprise AI tools reach production.\u2019</p>\n<blockquote><p>From our interviews, surveys, and analysis of 300 public implementations, four patterns emerged that define the GenAI Divide:</p>\n<ol>\n<li>Limited disruption: Only 2 of 8 major sectors show meaningful structural change.</li>\n<li>Enterprise paradox: Big firms lead in pilot volume but lag in scale-up.</li>\n<li>Investment bias: Budgets favor visible, top-line functions over high-ROI back office.</li>\n<li>Implementation advantage: External partnerships see twice the success rate of\n<p>internal builds.</li>\n</ol>\n</blockquote>\n<p>These are early days. Enterprises have only had capacity to look for ways to slide AI directly into existing structures. They ask, \u2018what that we already do, can AI do for us?\u2019 They especially ask \u2018what can show clear measurable gains we can trumpet?\u2019</p>\n<p>It does seem reasonable to say that the \u2018custom tools\u2019 approach may not be doing so great, if the tools only reach deployment 5% of the time. They might have a high enough return they still come out ahead, but that is a high failure rate if you actually fully scrap the other 95% and don\u2019t learn from them. It seems like this is a skill issue?</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!vqTd!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6646f713-2e09-40f5-a549-7826d2acc727_911x382.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<blockquote><p>The primary factor keeping organizations on the wrong side of the GenAI Divide is the learning gap, tools that don&#8217;t learn, integrate poorly, or match workflows.</p>\n<p>\u2026</p>\n<p>The 95% failure rate for enterprise AI solutions represents the clearest manifestation of the GenAI Divide. Organizations stuck on the wrong side continue investing in static tools that can&#8217;t adapt to their workflows, while those crossing the divide focus on learning-capable systems.</p>\n<p>\u2026</p>\n<p>As one CIO put it, &#8220;We&#8217;ve seen dozens of demos this year. Maybe one or two are genuinely useful. The rest are wrappers or science projects.&#8221;</p></blockquote>\n<p>That sounds like the \u2018AI tools\u2019 that fail deserve the air quotes.</p>\n<p>I also note that later they say custom built AI solutions \u2018fail twice as often.\u2019 That implies that when companies are wise enough to test solutions built externally, they succeed over 50% of the time.</p>\n\n\n<h4 class=\"wp-block-heading\">Claims Of Zero Returns Do Not Mean What You Might Think</h4>\n\n\n<p>There\u2019s also a strange definition of \u2018zero return\u2019 here.</p>\n<blockquote><p>Just 5% of integrated AI pilots are extracting millions in value, while the vast majority remain stuck with no measurable P&amp;L impact.</p>\n<p>Tools like ChatGPT and Copilot are widely adopted. Over 80 percent of organizations have explored or piloted them, and nearly 40 percent report deployment. But these tools primarily enhance individual productivity, not P&amp;L performance.</p></blockquote>\n<p>Issue a report where you call the 95% of projects that don\u2019t have \u2018measurable P&amp;L impact\u2019 failures, then wonder why no one wants to do \u2018high-ROI back office\u2019 upgrades.</p>\n<p>Those projects are high ROI, but how do you prove the R on I?</p>\n<p>Especially if you can\u2019t see the ROI on \u2018enhancing individual productivity\u2019 because it doesn\u2019t have this \u2018measurable P&amp;L impact.\u2019 If you double the productivity of your coders (as an example), it\u2019s true that you can\u2019t directly point to [$X] that this made you in profit, but surely one can see a lot of value there.</p>\n\n\n<h4 class=\"wp-block-heading\">Crossing The Divide</h4>\n\n\n<p>They call it a \u2018divide\u2019 because it takes a while to see returns, after which you see a lot.</p>\n<blockquote><p>While most implementations don&#8217;t drive headcount reduction, organizations that have crossed the GenAI Divide are beginning to see selective workforce impacts in customer support, software engineering, and administrative functions.</p>\n<p>In addition, the highest performing organizations report measurable savings from reduced BPO spending and external agency use, particularly in back-office operations.</p>\n<p>Others cite improved customer retention and sales conversion through automated outreach and intelligent follow-up systems.</p>\n<p>These early results suggest that learning-capable systems, when targeted at specific processes, can deliver real value, even without major organizational restructuring.</p></blockquote>\n<p>This all sounds mostly like a combination of \u2018there is a learning curve that is barely started on\u2019 with \u2018we don\u2019t know how to measure most gains.\u2019</p>\n<p>Also note the super high standard here. Only 22% of major sectors show \u2018meaningful structural change\u2019 at this early stage, and section 3 talks about \u2018high adoption, low transformation.\u2019</p>\n<p>Or their \u2018five myths about GenAI in the Enterprise\u2019:</p>\n<blockquote>\n<ol>\n<li>AI Will Replace Most Jobs in the Next Few Years \u2192 Research found limited layoffs from GenAI, and only in industries that are already affected significantly by AI. There is no consensus among executives as to hiring levels over the next 3-5 years.</li>\n<li>Generative AI is Transforming Business \u2192 Adoption is high, but transformation is rare. Only 5% of enterprises have AI tools integrated in workflows at scale and 7 of 9 sectors show no real structural change.</li>\n<li>Enterprises are slow in adopting new tech \u2192 Enterprises are extremely eager to adopt AI and 90% have seriously explored buying an AI solution.</li>\n<li>The biggest thing holding back AI is model quality, legal, data, risk \u2192 What&#8217;s really holding it back is that most AI tools don&#8217;t learn and don\u2019t integrate well into workflows.</li>\n<li>The best enterprises are building their own tools \u2192 Internal builds fail twice as often.</li>\n</ol>\n</blockquote>\n<p>Most jobs within a few years is not something almost anyone is predicting in a non-AGI world. Present tense \u2018transforming business\u2019 is a claim I don\u2019t remember hearing. I also hadn\u2019t heard \u2018the best enterprises are building their own tools\u2019 and it does not surprise me that rolling your own comes with much higher failure rates.</p>\n<p>I would push back on #3. As always, slow is relative, and being \u2018eager\u2019 is very different from not being the bottleneck. \u2018Explored buying an AI solution\u2019 is very distinct from \u2018adopting new tech.\u2019</p>\n<p>I would also push back on #4. The reason AI doesn\u2019t yet integrate well into workflows is because the tools are not yet good enough. This also shows the mindset that the AI is being forced to \u2018integrate into workflows\u2019 rather than generating new workflows, another sign that they are slow in adopting new tech.</p>\n<blockquote><p>Users prefer ChatGPT for simple tasks, but abandon it for mission-critical work due to its lack of memory. What&#8217;s missing is systems that adapt, remember, and evolve, capabilities that define the difference between the two sides of the divide.</p></blockquote>\n<p>I mean ChatGPT does now have some memory and soon it will have more. Getting systems to remember things is not all that hard. It is definitely on its way.</p>\n\n\n<h4 class=\"wp-block-heading\">Unrealistic (or Premature) Expectations</h4>\n\n\n<p>The more I explore the report the more it seems determined to hype up this \u2018divide\u2019 around \u2018learning\u2019 and memory. Much of the time seems like unrealistic expectations.</p>\n<p>Yes, you would love if your AI tools learned all the detailed preferences and contexts of all of your clients without you having to do any work?</p>\n<blockquote><p>The same lawyer who favored ChatGPT for initial drafts drew a clear line at sensitive contracts:</p>\n<p>&#8220;It&#8217;s excellent for brainstorming and first drafts, but it doesn&#8217;t retain knowledge of client preferences or learn from previous edits. It repeats the same mistakes and requires extensive context input for each session. For high-stakes work, I need a system that accumulates knowledge and improves over time.&#8221;</p>\n<p>This feedback points to the fundamental learning gap that keeps organizations on the wrong side of the GenAI Divide.</p></blockquote>\n<p>Well, how would it possibly know about client preferences or learn from previous edits? Are you keeping a detailed document with the client preferences in preferences.md? People would like AI to automagically do all sorts of things out of the box without putting in the work.</p>\n<p>And if they wait a few years? It will.</p>\n\n\n<h4 class=\"wp-block-heading\">Claims Of Prohibitive Lock-In Effects Are Mostly Hype</h4>\n\n\n<p>I totally do not get where this is coming from:</p>\n<blockquote><p>Takeaway: The window for crossing the GenAI Divide is rapidly closing. Enterprises are locking in learning-capable tools. Agentic AI and memory frameworks (like NANDA and MCP) will define which vendors help organizations cross the divide versus remain trapped on the wrong side.</p></blockquote>\n<p>Why is there a window and why is it closing?</p>\n<p>I suppose one can say \u2018there is a window because you will rapidly be out of business\u2019 and of course one can worry about the world transforming generally, including existential risks. But \u2018crossing the divide\u2019 gets easier every day, not harder.</p>\n<blockquote><p>In the next few quarters, several enterprises will lock in vendor relationships that will be nearly impossible to unwind.</p></blockquote>\n<p>Why do people keep saying versions of this? Over time increasingly capable AI and better AI tools will make it, again, easier not harder to pivot or migrate.</p>\n<p>Yes, I get that people think the switching costs will be prohibitive. But that\u2019s simply not true. If you already have an AI that can do things for your business, getting another AI to learn and copy what you need will be relatively easy. Code bases can switch between LLMs easily, often by changing only one to three lines.</p>\n\n\n<h4 class=\"wp-block-heading\">Nothing Ever Changes About Claims That Nothing Ever Changes</h4>\n\n\n<p>What is the bottom line?</p>\n<p>This seems like yet another set of professionals putting together a professional-looking report that fundamentally assumes AI will never improve, or that improvements in frontier AI capability will not matter, and reasoning from there. Once you realize this implicit assumption, a lot of the weirdness starts making sense.</p>\n<blockquote><p><a href=\"https://x.com/emollick/status/1958602041367961972\">Ethan Mollick</a>: Okay, got the report. I would read it yourself. I am not sure how generalizable the findings are based on the methodology (52 interviews, convenience sampled, failed apparently means no sustained P&amp;L impact within six months but no coding explanation)</p>\n<p>I have no doubt pilot failures are high, but I think it is really hard to see how this report gives the kind of generalizable finding that would move markets.</p>\n<p>Nathan Whittemore: Also no mention of coding. Also no agents. Also 50% of uses were marketing, suggesting extreme concentration of org area.</p>\n<p>Azeem Azhar: it was an extremely weak report. You are very generous with your assessment.</p>\n<p>Aaron Erickson: Many reports like this start from the desired conclusion and work backwards, and this feels like no exception to that rule.</p>\n<p>Most of the real work is bottom up adoption not measured by anything. If anything, it is an indictment about top-down initiatives.</p></blockquote>\n<p>The reason this is worth so much attention is that <a href=\"https://www.telegraph.co.uk/business/2025/08/20/ai-report-triggering-panic-and-fear-on-wall-street/\">we have reactions like this one</a> from Matthew Field, saying this is a \u2018warning sign the AI bubble is about to burst\u2019 and claiming the study caused a stock selloff, including a 3.5% drop in Nvidia and ~1% in some other big tech stocks. Which isn\u2019t that much, and there are various alternative potential explanations.</p>\n<p>The improvements we are seeing involve not only AI as it exists now (as in the worst it will ever be), with substantial implementation delays. It also involves only individuals adopting AI or at best companies slotting AI into existing workflows.</p>\n\n\n<h4 class=\"wp-block-heading\">Ask What AI Can Do For You</h4>\n\n\n<p>Traditionally the big gains from revolutionary technologies come elsewhere.</p>\n<blockquote><p><a href=\"https://x.com/tszzl/status/1960066492315361686\">Roon</a>: real productivity gains for prior technological advances came not from individual workers learning to use eg electricity, the internet but entire workflows, factories, processes, businesses being set up around the use of new tools (in other words, management)</p>\n<p>couple years ago I figured this could go much faster than usual thanks to knowledge diffusion over the internet and also the AIs themselves coming up with great ideas about how to harness their strengths and weaknesses. but I\u2019m not sure about that at present moment.</p>\n<p><a href=\"https://x.com/patio11/status/1960104572023689510\">Patrick McKenzie</a>: (Agree with this, and generally think it is one reasons why timelines to visible-in-GDP-growth impact are longer than people similarly bullish on AI seem to believe.)</p></blockquote>\n<p>I do think it is going faster and will go faster, except that in AI the standard for \u2018fast\u2019 is crazy fast, and \u2018AIs coming up with great ideas\u2019 is a capability AIs are only now starting to approach in earnest.</p>\n<p>I do think that if AGI and ASI don\u2019t show up, the timeline to the largest visible-in-GDP gains will take a while to show up. I expect visible-in-GDP soon anyway because I think the smaller, quicker version of even the minimally impressive version of AI should suffice to become visible in GDP, even though GDP will only reflect a small percentage of real gains.</p>\n\n\n<h4 class=\"wp-block-heading\">The Pattern Of Claiming a Slowdown Continues</h4>\n\n\n<p><a href=\"https://x.com/deanwball/status/1959599824736575995\">The \u2018AI is losing steam\u2019 or \u2018big leaps are slowing down</a>\u2019 and so on statements from mainstream media will keep happening whenever someone isn\u2019t feeling especially impressed this particular month. Or week.</p>\n<blockquote><p>Dean Ball: I think we live in a perpetual state of traditional media telling us that the pace of ai progress is slowing</p>\n<p>These pieces were published during a span that I would describe as the most rapid pace of progress I\u2019ve ever witnessed in LLMs (GPT-4 Turbo -&gt; GPT 5-Pro; remember: there were no public reasoner models 365 days ago!)</p>\n<p>(Also note that Bloomberg piece was nearly simultaneous with the announcement of o3, lmao)</p>\n<p><a href=\"https://x.com/Miles_Brundage/status/1959684974938034509\">Miles Brundage</a>: Notably, it&#8217;s ~never employees at frontier companies quoted on this, it&#8217;s the journalists themselves, or academics, startups pushing a different technique, etc.</p>\n<p>The logic being &#8220;people at big companies are biased.&#8221; Buddy, I&#8217;ve got some big news re: humans.</p>\n<p><a href=\"https://x.com/atroyn/status/1959832719522951440\">Anton</a>: my impression is that articles like this mostly get written by people who really really want to believe ai is slowing down. nobody working on it or even using it effectively thinks this. Which is actually basically a marketing problem which the entire field has been bad at since 2022.</p>\n<p><a href=\"https://x.com/petergostev/status/1960100559483978016\">Peter Gostev:</a> I&#8217;m sure you&#8217;ve all noticed the &#8216;AI is slowing down&#8217; news stories every few weeks for multiple years now &#8211; <a href=\"https://t.co/OzES4xPmTc\">so I&#8217;ve pulled a tracker together</a> to see who and when wrote these stories.</p>\n<p>There is quite a range, some are just outright wrong, others point to a reasonable limitation at the time but missing the bigger arc of progress.</p>\n<p>All of these stories were appearing as we were getting reasoning models, open source models, increasing competition from more players and skyrocketing revenue for the labs.</p></blockquote>\n<p>Peter links to about 35 posts. They come in waves.</p>\n<p>The practical pace of AI progress continues to greatly exceed the practical pace of progress everywhere else. I can\u2019t think of an exception. It is amazing how eagerly everyone looks for a supposed setback to try and say otherwise.</p>\n<p>You could call this gap a \u2018marketing problem\u2019 but the US Government is in the tank for AI companies and Nvidia is 3% of total stock market cap and investments in AI are over 1% of GDP and so on, and diffusion is proceeding at record pace. So it is not clear that they should care about those who keep saying the music is about to stop?</p>\n\n\n<h4 class=\"wp-block-heading\">A Sensible Move</h4>\n\n\n<p><a href=\"https://x.com/krishnanrohit/status/1958947164216041967\">Coinbase CEO fires software engineers who don\u2019t adopt AI tools</a>. Well, yeah.</p>\n\n\n<h4 class=\"wp-block-heading\">Who Deserves The Credit And Who Deserves The Blame</h4>\n\n\n<p>On the one hand, AI companies are building their models on the shoulders of giants, and by giants we mean all of us.</p>\n<blockquote><p><a href=\"https://www.nytimes.com/2025/08/24/opinion/chat-gpt5-open-ai-future.html\">Ezra Klein</a> (as an example): Right now, the A.I. companies are not making all that much money off these products. If they eventually do make the profits their investors and founders imagine, I don\u2019t think the normal tax structure is sufficient to cover the debt they owe all of us, and everyone before us, on whose writing and ideas their models are built.</p>\n<p>Then there\u2019s the energy demand.</p></blockquote>\n<p>Also the AI companies are risking all our lives and control over the future.</p>\n<p>On the other hand, notice that they are indeed not making that much money. It seems highly unlikely that, even in terms of unit economics, creators of AI capture more than 10% of value created. So in an \u2018economic normal\u2019 situation where AI doesn\u2019t \u2018go critical\u2019 or transform the world, but is highly useful, who owes who the debt?</p>\n<p>It\u2019s proving very useful for a lot of people.</p>\n<blockquote><p>Ezra Klein: And yet I am a bit shocked by how even the nascent A.I. tools we have are worming their way into our lives \u2014 not by being officially integrated into our schools and workplaces but by unofficially whispering in our ears.</p>\n<p>The American Medical Association <a href=\"https://archive.is/o/lVzkP/https://www.ama-assn.org/practice-management/digital-health/2-3-physicians-are-using-health-ai-78-2023\">found</a> that two in three doctors are consulting with A.I.</p>\n<p>A Stack Overflow <a href=\"https://archive.is/o/lVzkP/https://survey.stackoverflow.co/2025/ai\">survey</a> found that about eight in 10 programmers already use A.I. to help them code.</p>\n<p>The Federal Bar Association <a href=\"https://archive.is/o/lVzkP/https://www.fedbar.org/blog/the-legal-industry-report-2025/\">found</a> that large numbers of lawyers are using generative A.I. in their work, and it was more common for them to report they were using it on their own rather than through official tools adopted by their firms. It seems probable that Trump\u2019s \u201cLiberation Day\u201d tariffs were <a href=\"https://archive.is/o/lVzkP/https://www.theverge.com/news/642620/trump-tariffs-formula-ai-chatgpt-gemini-claude-grok\">designed</a> by consulting a chatbot.</p></blockquote>\n<p>All of these uses involve paying remarkably little and realizing much larger productivity gains.</p>\n\n\n<h4 class=\"wp-block-heading\">Mistakes From Applying Standard Economics To Future AIs</h4>\n\n\n<p><a href=\"https://x.com/steve47285/status/1958527894965108829\">Steven Byrnes explains his view on some reasons why an economics education</a> can make you dumber when thinking about future AI, difficult to usefully excerpt and I doubt he\u2019d mind me quoting it in full.</p>\n<p>I note up top that I know not all of this is technically correct, it isn\u2019t the way I would describe this, and of course #NotAllEconomists throughout especially for the dumber mistakes he points out, but the errors actually are often pretty dumb once you boil them down, and I found Byrnes\u2019s explanation illustrative.</p>\n<blockquote><p>Steven Byrnes: There\u2019s a funny thing where economics education paradoxically makes people DUMBER at thinking about future AI. Econ textbooks teach concepts &amp; frames that are great for most things, but counterproductive for thinking about AGI. Here are 4 examples. Longpost:</p>\n<p>THE FIRST PIECE of Econ anti-pedagogy is hiding in the words \u201clabor\u201d &amp; \u201ccapital\u201d. These words conflate a superficial difference (flesh-and-blood human vs not) with a bundle of unspoken assumptions and intuitions, which will all get broken by Artificial General Intelligence (AGI).</p>\n<p>By \u201cAGI\u201d I mean here \u201ca bundle of chips, algorithms, electricity, and/or teleoperated robots that can autonomously do the kinds of stuff that ambitious human adults can do\u2014founding and running new companies, R&amp;D, learning new skills, using arbitrary teleoperated robots after very little practice, etc.\u201d</p>\n<p>Yes I know, this does not exist yet! (Despite hype to the contrary.) Try asking an LLM to autonomously write a business plan, found a company, then run and grow it for years as CEO. Lol! It will crash and burn! But that\u2019s a limitation of today\u2019s LLMs, not of \u201call AI forever\u201d.</p>\n<p>AI that could nail that task, and much more beyond, is obviously possible\u2014human brains and bodies and societies are not powered by some magical sorcery forever beyond the reach of science. I for one expect such AI in my lifetime, for better or worse. (Probably \u201cworse\u201d, see below.)</p>\n<p>Now, is this kind of AGI \u201clabor\u201d or \u201ccapital\u201d? Well it\u2019s not a flesh-and-blood human. But it\u2019s more like \u201clabor\u201d than \u201ccapital\u201d in many other respects:</p>\n<p>\u2022 Capital can\u2019t just up and do things by itself? AGI can.</p>\n<p>\u2022 New technologies take a long time to integrate into the economy? Well ask yourself: how do highly-skilled, experienced, and entrepreneurial immigrant humans manage to integrate into the economy immediately? Once you\u2019ve answered that question, note that AGI will be able to do those things too.</p>\n<p>\u2022 Capital sits around idle if there are no humans willing and able to use it? Well those immigrant humans don\u2019t sit around idle. And neither will AGI.</p>\n<p>\u2022 Capital can\u2019t advocate for political rights, or launch coups? Well\u2026</p>\n<p>Anyway, people see sci-fi robot movies, and they get this! Then they take economics courses, and it makes them dumber.</p>\n<p>(Yes I know, #NotAllEconomists etc.)</p>\n<p>THE SECOND PIECE of Econ anti-pedagogy is instilling a default assumption that it\u2019s possible for a market to equilibrate. But the market for AGI cannot: AGI combines a property of labor markets with a property of product markets, where those properties are mutually exclusive. Those properties are:</p>\n<p>\u2022 (A) \u201cNO LUMP OF LABOR\u201d: If human population goes up, wages drop in the very short term, because the demand curve for labor slopes down. But in the longer term, people find new productive things to do\u2014the demand curve moves right. If anything, the value of labor goes UP, not down, with population! E.g. dense cities are engines of growth!</p>\n<p>\u2022 (B) \u201cEXPERIENCE CURVES\u201d: If the demand for a product rises, there\u2019s price increase in the very short term, because the supply curve slopes up. But in the longer term, people ramp up manufacturing\u2014the supply curve moves right. If anything, the price goes DOWN, not up, with demand, thanks to economies of scale and R&amp;D.</p>\n<p>QUIZ: Considering (A) &amp; (B), what\u2019s the equilibrium price of this AGI bundle (chips, algorithms, electricity, teleoperated robots, etc.)?</p>\n<p>\u2026Trick question! There is no equilibrium. Our two principles, (A) \u201cno lump of labor\u201d and (B) \u201cexperience curves\u201d, make equilibrium impossible:</p>\n<p>\u2022 If price is low, (A) says the demand curve races rightwards\u2014there\u2019s no lump of labor, therefore there\u2019s massive profit to be made by skilled entrepreneurial AGIs finding new productive things to do.</p>\n<p>\u2022 If price is high, (B) says the supply curve races rightwards\u2014there\u2019s massive profit to be made by ramping up manufacturing of AGI.</p>\n<p>\u2022 If the price is in between, then the demand curve and supply curve are BOTH racing rightwards!</p>\n<p>This is neither capital nor labor as we know it. Instead of the market for AGI equilibrating, it forms a positive feedback loop / perpetual motion machine that blows up exponentially.</p>\n<p>Does that sound absurd? There\u2019s a precedent: humans! The human world, as a whole, is already a positive feedback loop / perpetual motion machine of this type! Humans bootstrapped themselves up from a few thousand hominins to 8 billion people running a $80T economy.</p>\n<p>How? It\u2019s not literally a perpetual motion machine. Rather, it\u2019s an engine that draws from the well of \u201cnot-yet-exploited economic opportunities\u201d. But remember \u201cNo Lump of Labor\u201d: the well of not-yet-exploited economic opportunities is ~infinitely deep. We haven\u2019t run out of possible companies to found. Nobody has made a Dyson swarm yet.</p>\n<p>There\u2019s only so many humans to found companies and exploit new opportunities. But the positive feedback loop of AGI has no such limit. The doubling time can be short indeed:</p>\n<p>Imagine an autonomous factory that can build an identical autonomous factory, which then build two more, etc., using just widely-available input materials and sunlight. Economics textbooks don\u2019t talk about that. But biology textbooks do! A cyanobacterium is such a factory, and can double itself in a day (\u2248 googol percent annualized growth rate <img alt=\"\ud83d\ude1b\" class=\"wp-smiley\" src=\"https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f61b.png\" style=\"height: 1em;\" />).</p>\n<p>Anyway, we don\u2019t know how explosive will be the positive feedback loop of AGI building AGI, but I expect it to be light-years beyond anything in economic history.</p>\n<p>THE THIRD PIECE of Econ anti-pedagogy is its promotion of GDP growth as a proxy for progress and change. On the contrary, it\u2019s possible for the world to transform into a wild sci-fi land beyond all recognition or comprehension each month, month after month, without \u201cGDP growth\u201d actually being all that high. GDP is a funny metric, and especially poor at describing the impact of transformative technological revolutions. (For example, if some new tech is inexpensive, and meanwhile other sectors of the economy remain expensive due to regulatory restrictions, then the new tech might not impact GDP much, no matter how much it upends the world.) I mean, sure we can argue about GDP, but we shouldn\u2019t treat it as a proxy battle over whether AGI will or won\u2019t be a big deal.</p>\n<p>Last and most importantly, THE FOURTH PIECE of Econ anti-pedagogy is the focus on \u201cmutually-beneficial trades\u201d over \u201ckilling people and taking their stuff\u201d. Econ 101 proves that trading is selfishly better than isolation. But sometimes \u201ckilling people and taking their stuff\u201d is selfishly best of all.</p>\n<p>When we\u2019re talking about AGI, we\u2019re talking about creating a new intelligent species on Earth, one which will eventually be faster, smarter, better-coordinated, and more numerous than humans.</p>\n<p>Normal people, people who have seen sci-fi movies about robots and aliens, people who have learned the history of colonialism and slavery, will immediately ask lots of reasonable questions here. \u201cWhat will their motives be?\u201d \u201cWho will have the hard power?\u201d \u201cIf they\u2019re seeming friendly and cooperative early on, might they stab us in the back when they get more powerful?\u201d</p>\n<p>These are excellent questions! We should definitely be asking these questions! (FWIW, this is my area of expertise, and I\u2019m very pessimistic.)</p>\n<p>\u2026And then those normal people take economics classes, and wind up stupider. They stop asking those questions. Instead, they \u201clearn\u201d that AGI is \u201ccapital\u201d, kinda like an injection-molding machine. Injection-molding machines wouldn\u2019t wipe out humans and run the world by themselves. So we\u2019re fine. Lol.</p>\n<p>\u2026Since actual AGI is so foreign to economists\u2019 worldviews, they often deny the premise. E.g. here\u2019s <a href=\"https://x.com/tylercowen\">@tylercowen</a> demonstrating a complete lack of understanding of what we doomers are talking about, when we talk about future powerful AI.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!-czH!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb8e54abf-e8c0-4c07-93c2-88044b3f6ab3_610x243.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n</blockquote>\n<p>Yep. If you restrict to worlds where collaboration with humans is required in most cases then the impacts of AI all look mostly \u2018normal\u2019 again.</p>\n<blockquote><p>And here\u2019s @DAcemogluMIT assuming without any discussion that in the next 10 yrs, \u201cAI\u201d will not include any new yet-to-be-developed techniques that go way beyond today\u2019s LLMs. Funny omission, when the whole LLM paradigm didn\u2019t exist 10 yrs ago!</p>\n<p>(Tbc, it\u2019s fine to make that assumption! Maybe it will be valid, or maybe not, who knows, technological forecasting is hard. But when your paper depends on a giant load-bearing assumption about future AI tech progress, an assumption which many AI domain experts dispute, then that assumption should at least be clearly stated! Probably in the very first sentence of the paper, if not the title!)</p>\n<p>And here\u2019s another example of economists \u201carguing\u201d against AGI scenarios by simply rejecting out of hand any scenario in which actual AGI exists. Many such examples\u2026</p>\n<p><a href=\"https://x.com/ESYudkowsky/status/1958702085698199801\">Eliezer Yudkowsky</a>: Surprisingly correct, considering the wince I had at the starting frame.</p>\n<p>I really think that if you&#8217;re creating a new intelligent species vastly smarter than humans, going &#8220;oh, that&#8217;s &#8216;this time is different&#8217; economics&#8221;, as if it were economics in the first place, is exactly a Byrnes-case of seeing through an inappropriate lens and ending up dumber.</p></blockquote>\n<p>I am under no illusions that an explanation like this would satisfy the demands and objections of most economists or fit properly into their frameworks. It is easy for such folks to dismiss explanations like this as insufficiently serious or rigerous, or simply to deny the premise. I\u2019ve run enough experiments to stop suspecting otherwise.</p>\n<p>However, if one actually did want to understand the situation? This could help.</p>"
            ],
            "link": "https://thezvi.wordpress.com/2025/08/26/reports-of-ai-not-progressing-or-offering-mundane-utility-are-often-greatly-exaggerated/",
            "publishedAt": "2025-08-26",
            "source": "TheZvi",
            "summary": "In the wake of the confusions around GPT-5, this week had yet another round of claims that AI wasn\u2019t progressing, or AI isn\u2019t or won\u2019t create much value, and so on. There were reports that one study in particular impacted &#8230; <a href=\"https://thezvi.wordpress.com/2025/08/26/reports-of-ai-not-progressing-or-offering-mundane-utility-are-often-greatly-exaggerated/\">Continue reading <span class=\"meta-nav\">&#8594;</span></a>",
            "title": "Reports Of AI Not Progressing Or Offering Mundane Utility Are Often Greatly Exaggerated"
        }
    ],
    "lookbackDays": 1,
    "publishDate": "2025-08-26"
}