{
    "articles": [
        {
            "content": [
                "<p>When I started this blog, I promised myself that I would always steer into weirdness. (As they say, \u201cGet busy being weird, or get busy dying.\u201d) While time has shown there are limits to what y\u2019all will tolerate [<a href=\"https://dynomight.net/warby-parker/\">1</a> <a href=\"https://dynomight.net/typing/\">2</a> <a href=\"https://dynomight.net/no-soap-radio/\">3</a> <a href=\"https://dynomight.net/parenting/#:~:text=I%27m%20so%20confused\">4</a>] I still sometimes feel a need to publish something that\u2019s pure exuberant stupidity.</p>\n\n<p>Thus, I present:</p>\n\n<p>WHY DID THE CHICKEN CROSS THE ROAD<br />\nACCORDING TO VARIOUS PEOPLE<br />\nOR OTHER ENTITIES</p>\n\n<blockquote>\n  <p>Q) Why did the chicken cross the road?</p>\n\n  <p>A) The chicken ain\u2019t fussy. Everybody gotta be somewhere. The chicken been on this side a long time and never suffered none for it. The chicken don\u2019t see no obvious benefit to the other side. But the talk of the town is nothing but crossing, and the chicken can\u2019t help but go see what got everyone so stirred up.</p>\n</blockquote>\n\n<p>(Mark Twain)</p>\n\n<blockquote>\n  <p>Q) Why did the chicken cross the road?</p>\n\n  <p>A) The outcome would be best if no one crossed. However, if other chickens do cross, then the outcome would be better if this chicken also crossed. The chicken rejects the Kantian universalism. So the chicken crosses.</p>\n</blockquote>\n\n<p>(Derek Parfit)</p>\n\n<blockquote>\n  <p>Q) Why did the chicken cross the road?</p>\n\n  <p>A) You were a beautiful little chick<br />\nThe whole world was before you<br />\nYou greased your wattles and crossed the road<br />\nSure it would last forever</p>\n\n  <p>Now it\u2019s a cold morning and you\u2019re driving to work<br />\nCursing all the cockerels in your way<br />\nHow did you get here<br />\nWhere did that little chick go</p>\n</blockquote>\n\n<p>(Pink Floyd)</p>\n\n<blockquote>\n  <p>Q) Why did the chicken cross the road?</p>\n\n  <p>A) It didn\u2019t. There is no chicken. You are the road. You and the sides are in an entangled macrostate. The chicken is an emergent property of the superposition. The chicken abhors being measured. A team of plucky chemists rush to inject enough decoherence to collapse the wavefunction before the chicken can consume the lightcone.</p>\n</blockquote>\n\n<p>(Christopher Nolan)</p>\n\n<blockquote>\n  <p>Q) Why did the chicken cross the road?</p>\n\n  <p>A) Chicken</p>\n\n  <p>C H I C K E N</p>\n\n  <p>3, 8, 9, 3, 11, 5, 14</p>\n\n  <p>11, 9, 3, 8 14, 3, 5</p>\n\n  <p>gcd(11^(9 + 3) - 8, 14), 3 \u00d7 5</p>\n\n  <p>7, 15</p>\n\n  <p>G O</p>\n\n  <p>Go</p>\n</blockquote>\n\n<p>(Ramanujan)</p>\n\n<blockquote>\n  <p>Q) Why did the chicken cross the road?</p>\n\n  <p>A) For sex. Neither glamorized nor gross, possibly added for commercial reasons, possibly to make some point about sex\u2019s place in real life. It\u2019s all very unclear.</p>\n</blockquote>\n\n<p>(Paul Thomas Anderson)</p>\n\n<blockquote>\n  <p>Q) Why did the chicken cross the road?</p>\n\n  <p>A) Did it cross the road, though? Did it? Sure, the chicken is associated with crossing. And it\u2019s mechanistically possible for a chicken to cross a road. It\u2019s plausible the chicken crossed the road. But maybe the chicken and the crossing were both caused by something else. Or maybe the <em>road</em> crossed the <em>chicken</em>. This is why we have RCTs. Come on, people!</p>\n</blockquote>\n\n<p>(Dynomight)</p>\n\n<blockquote>\n  <p>Q) Why did the chicken cross the road?</p>\n\n  <p>A) Once there was a dragon who watched over the chicken village. The chickens begged the dragon, \u201cPlease let us have a road, so that we might cross back and forth!\u201d</p>\n\n  <p>\u201cA road?\u201d the dragon asked. \u201cAre you sure?\u201d</p>\n\n  <p>\u201cYes!\u201d the chickens answered. \u201cA road! We wish for nothing but a road to cross, and then we will be happy forever and ever!\u201d</p>\n\n  <p>[7000 words redacted]</p>\n\n  <p>And thus, all mass-energy in the universe was converted to chicken-torture annihilators. Makes you think.</p>\n</blockquote>\n\n<p>(LessWrong)</p>\n\n<blockquote>\n  <p>Q) Why did the chicken cross the road?</p>\n\n  <p>A) We were out on the edge of the farm when the diethyltryptamine took hold. Beaky screamed something about coccidiostats in our feed and made a break for it, totally out of control. Before I could stop him, I heard the voice of God say, \u201cScrapples: The road awaits.\u201d Suddenly I was standing on the median, cars screaming past, a group a baby ducks asking where the mountains of peas I\u2019d promised them were.</p>\n</blockquote>\n\n<p>(Hunter S. Thompson)</p>\n\n<blockquote>\n  <p>Q) Why did the chicken cross the road?</p>\n\n  <p>A) The chicken\u2019s crossing is not a voluntary act but the unconscious actualization of a class habitus: raised in a coop whose symbolic boundaries naturalize the road as a site of danger and prestige, the chicken embodies the field\u2019s doxa that \u201creal\u201d chickens must invest in the illusio of reaching the median. While the chicken never doubts the legitimacy of the crossing rules, crossing is not about the other side, but a performance of distinction that ultimately perpetuates the same field of species domination that produced it.</p>\n</blockquote>\n\n<p>(Pierre Bourdieu)</p>\n\n<blockquote>\n  <p>Q) Why did the chicken cross the road?</p>\n\n  <p>A) grug on one side</p>\n\n  <p>grug see other side</p>\n\n  <p>grug chicken</p>\n\n  <p>many metal box speed by very fast very volume</p>\n\n  <p>metal box seem to stay on black land strip</p>\n\n  <p>grug think better if metal box not hit grug because box hard and grug small soft chicken</p>\n\n  <p>grug wait a while</p>\n\n  <p>when no metal box for a while also often no metal box for a while after</p>\n\n  <p>largest gap between metal box around 20 minutes</p>\n\n  <p>grug wait until no metal box for 10 minutes then grug cross</p>\n\n  <p>no metal box come</p>\n\n  <p>grug safe</p>\n\n  <p>other side also fine</p>\n\n  <p>maybe cross back someday</p>\n\n  <p>grug think side not matter too much</p>\n\n  <p>grug enjoy chicken life either side same</p>\n\n  <p>chicken life pretty good</p>\n\n  <p>grug hope you also have life as good as grug chicken life</p>\n\n  <p>groodbye from grug</p>\n</blockquote>\n\n<p>(grug)</p>\n\n<blockquote>\n  <p>Q) Why did the chicken cross the road?</p>\n\n  <p>A) Before there was chicken the road was waiting. The road is empty. Dust on your hackles. Heat rises in shimmering waves. No way to see what\u2019s coming. How did it come to this. How a chicken supposed to move with roads everywhere. Creosote blows in from the mesa. Nothing left but to cross. You cross and nothing happens. A few minutes later a car stops but you don\u2019t turn around. A door opens and you hear a click. Then the car is gone.</p>\n</blockquote>\n\n<p>(Cormac McCarthy)</p>\n\n<blockquote>\n  <p>Q) Why did the chicken cross the road?</p>\n\n  <p>A) For food.</p>\n</blockquote>\n\n<p>(An actual chicken)</p>\n\n<p>Requests: Peter Singer, Ayn Rand, Judith Butler, Bertrand Russell, Andrei Tarkovsky, the mother hen, a junglefowl, an SSRI, Singapore, the chicken\u2019s hypothalamus.</p>"
            ],
            "link": "https://dynomight.net/chicken/",
            "publishedAt": "2025-12-04",
            "source": "Dynomight",
            "summary": "<p>When I started this blog, I promised myself that I would always steer into weirdness. (As they say, \u201cGet busy being weird, or get busy dying.\u201d) While time has shown there are limits to what y\u2019all will tolerate [<a href=\"https://dynomight.net/warby-parker/\">1</a> <a href=\"https://dynomight.net/typing/\">2</a> <a href=\"https://dynomight.net/no-soap-radio/\">3</a> <a href=\"https://dynomight.net/parenting/#:~:text=I%27m%20so%20confused\">4</a>] I still sometimes feel a need to publish something that\u2019s pure exuberant stupidity.</p> <p>Thus, I present:</p> <p>WHY DID THE CHICKEN CROSS THE ROAD<br /> ACCORDING TO VARIOUS PEOPLE<br /> OR OTHER ENTITIES</p> <blockquote> <p>Q) Why did the chicken cross the road?</p> <p>A) The chicken ain\u2019t fussy. Everybody gotta be somewhere. The chicken been on this side a long time and never suffered none for it. The chicken don\u2019t see no obvious benefit to the other side. But the talk of the town is nothing but crossing, and the chicken can\u2019t help but go see what got everyone so stirred up.</p> </blockquote> <p>(Mark Twain)</p> <blockquote> <p>Q) Why did the chicken cross the road?</p> <p>A) The outcome would be best if no one crossed. However, if other chickens do cross, then the outcome would be better if this chicken also crossed. The chicken rejects the Kantian universalism. So the chicken crosses.</p> </blockquote> <p>(Derek Parfit)</p> <blockquote> <p>Q)",
            "title": "Why the chicken crossed the road, according to various entities"
        },
        {
            "content": [],
            "link": "https://www.nytimes.com/2025/12/03/style/tiny-modern-love-stories-he-was-75-i-was-42.html",
            "publishedAt": "2025-12-04",
            "source": "Modern Love - NYT",
            "summary": "Modern Love in miniature, featuring reader-submitted stories of no more than 100 words.",
            "title": "Tiny Love Stories: \u2018He Was 75. I Was 42.\u2019"
        },
        {
            "content": [],
            "link": "https://www.ssp.sh/blog/finops-dlt-clickhouse-rill/",
            "publishedAt": "2025-12-04",
            "source": "Simon Spati",
            "summary": "<p>Following up on <a href=\"https://www.ssp.sh/blog/cost-analyzer-aws-gcp/\" rel=\"\">Part 1</a>, where we created an entire end-to-end FinOps project to analyze cloud costs from different hyperscalers with dlt and local parquet files. In this part 2, we set up a version that works cloud-native with ClickHouse Cloud and Rill Cloud. So you can share your dashboard and it scales to any cost data you might have.</p> <p>The work is done through a GitHub action job for illustration purposes. This can be updated or also run as an orchestration job or anywhere else. This job now runs every day and extracts data from my AWS and GCP, plus Stripe data, and then adds some randomization for demo purposes and anonymizes my actual cost data.</p> <p>So in this article we dig into how we achieved that, what the hardest parts were, and how you can reuse this project.</p> <p>Essentially, we built <code>Logs -&gt; S3 -&gt; GitHub Actions -&gt; Clickhouse -&gt; Rill UI</code> with a simple open source data project. You can use the code to run locally, or with the latest version with ClickHouse and Rill Cloud.</p> <blockquote> <p>[!note] Jump directly to the Code on GitHub</p> <p>Get started with cost reports and use the template at",
            "title": "Dlt+ClickHouse+Rill: Multi-Cloud Cost Analytics, Cloud-Ready"
        },
        {
            "content": [
                "<p>The term &#8220;vibecession&#8221; most strictly refers to a period 2023 - 2024 when economic indicators were up, but consumer sentiment (&#8220;vibes&#8221;) was down. But on a broader level, the whole past decade has been a vibecession.</p><p>Young people complain they&#8217;ve been permanently locked out of opportunity. They will never become homeowners, never be able to support a family, only keep treading water at precarious gig jobs forever. They got a 5.9 GPA and couldn&#8217;t get into college; they applied to 2,051 companies in the past week without so much as a politely-phrased rejection. Sometime in the 1990s, the Boomers ripped up the social contract where hard work leads to a pleasant middle-class life, replacing it with a hellworld where you will own nothing and numb the pain with algorithmic slop. The only live political question is whether to blame immigrants, blame billionaires, or just trade crypto in the hopes that some memecoin buys you a ticket out of the permanent underclass.</p><p>Meanwhile, economists say things have never been better.</p><p>Are the youth succumbing to a &#8220;negativity bias&#8221; where they see the past through &#8220;rose-colored glasses&#8221;? Are the economists looking at some ivory tower High Modernist metric that fails to capture real life? Or is there something more complicated going on?</p><p>We&#8217;ll start by formally assessing the vibes. Then we&#8217;ll move on to the economists&#8217; arguments that things are fine. Finally, we&#8217;ll try to resolve the conflict: how bad are things, really?</p><h2>Are We Sure The Vibes Are Bad?</h2><p>I&#8217;ll assume you&#8217;ve already heard the complaints about the economy coming from the media, social media, <em>et cetera</em>. But are we sure there isn&#8217;t a meta-vibecession? The vibes about the vibes are bad, but really, the vibes are good? Maybe the media just -</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!Xr_e!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F11e841be-bf9b-4682-b502-67c6434e1d64_1307x532.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"532\" src=\"https://substackcdn.com/image/fetch/$s_!Xr_e!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F11e841be-bf9b-4682-b502-67c6434e1d64_1307x532.png\" title=\"\" width=\"1307\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p>- oh god, no, it&#8217;s even worse than I thought. The vibes are <em>awful</em>.</p><p>This is the official measure of vibes, the Index of Consumer Sentiments. Can we trust it?</p><p>One reason not to trust it is that most of its questions take a form like &#8220;do you think things are better than last year?&#8221; or &#8220;do you think things will be better next year?&#8221; These are local and don&#8217;t really allow you to compare today vs. 1980. But consumers are terrible at answering these questions in the spirit in which they&#8217;re intended; for example, when the economy is bad, &#8220;do you think things will be better next year?&#8221; reaches a low, even though bad economies are exactly when you would expect next year to be better (through mean reversion). So it&#8217;s probably fair to treat this as overall &#8220;vibes: good or bad?&#8221;</p><p>Another reason not to trust it is that they changed the survey methodology in 2024, causing multiple trend breaks; instead of adjusting for this, they &#8220;smoothed it out&#8221; so people wouldn&#8217;t notice! This seems irresponsible and I don&#8217;t know how they got away with it. Everything after 2024 should arguably be ~5 points higher. But even adding 5 points, things now look pretty grim.</p><p>The Gallup Economic Confidence Index, which doesn&#8217;t have the methodology problem, looks pretty similar:</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!_mwY!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feddaab40-062d-4171-b55b-d9e0cddad187_615x591.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"591\" src=\"https://substackcdn.com/image/fetch/$s_!_mwY!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feddaab40-062d-4171-b55b-d9e0cddad187_615x591.png\" width=\"615\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p>This is a combination of an absolute question (&#8220;how are conditions?&#8221;) and a relative question (&#8220;are they getting worse or better&#8221;), but you can disambiguate them <a href=\"http://file:///C:/Users/scott/OneDrive/Desktop/2025_05_01%20Values%20and%20Beliefs%20Topline_PDF.pdf\">here</a> and get similar results.</p><p>I conclude the vibes are actually bad.</p><p>There is one anomaly, which is that I remember people complaining about the bad economy and the Boomers and hellworld since well before 2020 (consider the Trump and Sanders campaigns), but the official vibes didn&#8217;t crash until COVID. Is my memory faulty?</p><h2>The Economists&#8217; Seemingly Rosy Statistics</h2><p>Here&#8217;s real median household income in the US over time (<a href=\"https://fred.stlouisfed.org/series/MEHOINUSA672N\">source</a>):</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!GKUE!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdc530b08-f7ef-486d-805c-378a1f3ae374_1325x535.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"535\" src=\"https://substackcdn.com/image/fetch/$s_!GKUE!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdc530b08-f7ef-486d-805c-378a1f3ae374_1325x535.png\" width=\"1325\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p>People today earn 33% more than they did during the Boomers&#8217; heyday.</p><p>Might this just be a few billionaires bringing the average up, while the incomes of ordinary people stagnate? No: this is <em><a href=\"https://en.wikipedia.org/wiki/Median\">median</a></em> income. You&#8217;re thinking of mean income. The mean can be brought up by a few outliers; the median represents the exact most ordinary member of society. If you insist, here are the same data presented as the share of society making more than a certain threshold in inflation-adjusted dollars (<a href=\"https://economistwritingeveryday.com/2025/09/17/one-third-of-us-families-earn-over-150000/\">source</a>):</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!dtoi!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fafc69dd4-34a2-423d-87dd-0a509135adf6_1416x1028.webp\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"484.96045197740114\" src=\"https://substackcdn.com/image/fetch/$s_!dtoi!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fafc69dd4-34a2-423d-87dd-0a509135adf6_1416x1028.webp\" width=\"668\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p>Might cost-of-living increases have eaten all of these gains and then some? No: this is <em>real</em> median income, ie adjusted for inflation. Cost-of-living increases are a type of inflation, so those should be priced in.</p><p>Might this just represent old people doing better, while the young are left behind? No: here are the same data disaggregated by age group (<a href=\"https://www.advisorperspectives.com/dshort/updates/2025/09/17/median-household-incomes-by-age-bracket-1967-2024\">source</a>):</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!9czs!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F547eead1-8b66-4d06-b237-5c9da92369a8_3130x2274.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"470.86813186813185\" src=\"https://substackcdn.com/image/fetch/$s_!9czs!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F547eead1-8b66-4d06-b237-5c9da92369a8_3130x2274.png\" width=\"648\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p>Young people&#8217;s incomes have increased as fast as everyone else&#8217;s. And the youth-specific unemployment rate was <a href=\"https://www.reddit.com/r/EconomyCharts/comments/1mnfocs/the_us_unemployment_rate_for_youth_graduates_aged/\">near historic lows</a> until last year (some people blame the current uptick on AI, but this is too recent to have caused the vibecession):</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!VuL6!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F956512a3-6365-49a5-803f-1126765cf475_860x624.webp\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"444.0558139534884\" src=\"https://substackcdn.com/image/fetch/$s_!VuL6!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F956512a3-6365-49a5-803f-1126765cf475_860x624.webp\" width=\"612\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p><a href=\"https://x.com/besttrousers/status/1987478944681951276\">Here&#8217;s</a> an attempt to compare generations directly. We can&#8217;t do this as a point-in-time estimate, because late-career old people will always earn more than early-career young people, but we can compare how much people made in inflation-adjusted dollars at the same ages:</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!dds-!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F67c591eb-cca5-40c3-980c-4da6d2f7e98f_333x387.jpeg\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"468.35135135135135\" src=\"https://substackcdn.com/image/fetch/$s_!dds-!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F67c591eb-cca5-40c3-980c-4da6d2f7e98f_333x387.jpeg\" width=\"403\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p>Just as our previous graphs imply, Millennials and Zoomers earn significantly more than Boomers did at the same age, even in inflation-adjusted dollars.</p><p>So, the economists conclude, maybe it really <em>is</em> just vibes. We know of other cases where the public believes things are worsening even as they get better: crime rates are the classic example. </p><p>But most people judge crime rates by what they hear on TV. Vanishing economic opportunity is much more personal. Can people really be wrong about something so close to their own lives?</p><h2>Fine, You&#8217;ve Proven The Contradiction We Already Knew About, Get To The Point Where You Solve It.</h2><p>We start by looking at other people&#8217;s proposed solutions.</p><h4><strong>(Briefly) Declining Real Wages</strong></h4><p>The term &#8220;vibecession&#8221; most strictly refers to the period 2023 - 2024 when economic indicators were up, but consumer sentiment was down. During that period, <a href=\"https://www.noahpinion.blog/p/the-end-of-the-vibecession\">Noah Smith popularized</a> a <a href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4138728\">paper by Darren Grant</a> arguing that this corresponded to a brief decline in real wages, even though stocks and other indicators kept rising:</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2\" href=\"https://substackcdn.com/image/fetch/$s_!OODv!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5c0da39e-5e13-4656-8b07-7e375e2acc6c_1318x450.webp\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"221.92716236722308\" src=\"https://substackcdn.com/image/fetch/$s_!OODv!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5c0da39e-5e13-4656-8b07-7e375e2acc6c_1318x450.webp\" width=\"650\" /><div></div></div></a></figure></div><p>During COVID, the government instituted various relief programs which temporarily gave people lots of money (the spike). This caused some inflation, which temporarily lowered real (ie inflation-adjusted) wages. Then inflation calmed down and real wages started rising again - thus Noah&#8217;s post title, &#8220;The End Of The Vibecession?&#8221;</p><p>With the benefit of two more years of data, we see that Noah and Darren were right about the trend:</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!6flf!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1ba053b8-edf0-4cf4-aee6-8e83e31bf9ac_1337x553.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"553\" src=\"https://substackcdn.com/image/fetch/$s_!6flf!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1ba053b8-edf0-4cf4-aee6-8e83e31bf9ac_1337x553.png\" width=\"1337\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p>Wages never jumped back to the point where they would be if the pandemic had never happened, but they&#8217;re back to growing as fast as ever.</p><p>So this could explain the mini-vibecession of 2023-2024. Still, I claim there is a broader vibecession. Young people felt closed out from opportunities before 2023, and they still feel that way.</p><p>Since only the 2023-2024 period saw falling real wages, this can&#8217;t be the full explanation.</p><h4><strong>The Housing Theory Of Everything</strong></h4><p>John Burn-Murdoch, after examining some of these same data, agrees that wages can&#8217;t be the full story. <a href=\"https://archive.is/O5ER1\">He writes</a>:</p><blockquote><p>Are millennials wrong to complain? I fear not. The per capita measure is a beautifully simple rejoinder, but it misses one crucial detail. Wealth accumulation &#8212; just like income &#8212; matters primarily to millennials today as a means to home ownership, especially as we move into an era of high interest rates. If we deflate wealth by the index of house prices instead of the CPI, millennials&#8217; assets only go about half as far as boomers&#8217; once did. We&#8217;re left with a smaller millennial deficit than the original chart implied, but a deficit nonetheless.</p></blockquote><p>The YIMBYs at Works In Progress go further, and present <a href=\"https://worksinprogress.co/issue/the-housing-theory-of-everything/\">The Housing Theory Of Everything</a> (or at least of everything bad):</p><blockquote><p>Try listing every problem the Western world has at the moment. Along with Covid, you might include slow growth, climate change, poor health, financial instability, economic inequality, and falling fertility. These longer-term trends contribute to a sense of malaise that many of us feel about our societies. They may seem loosely related, but there is one big thing that makes them all worse. That thing is a shortage of housing: too few homes being built where people want to live. And if we fix those shortages, we will help to solve many of the other, seemingly unrelated problems that we face as well.</p></blockquote><p>Here is the Case-Shiller index, the standard measure of US home prices. I&#8217;ve started it in 1985 to match our other graphs:</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!zP-R!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F27507c77-dfcc-49a2-8060-61faf8c8df9a_1403x402.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"402\" src=\"https://substackcdn.com/image/fetch/$s_!zP-R!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F27507c77-dfcc-49a2-8060-61faf8c8df9a_1403x402.png\" width=\"1403\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a><figcaption class=\"image-caption\">If I were designing an index to present the case that capitalism had not failed, I would have avoided naming it &#8220;Case Shiller&#8221;. </figcaption></figure></div><p>During this time, average home price has approximately doubled.</p><p>Might this only reflect falling interest rates? That is, suppose people can only afford a certain level of monthly mortgage payment. When interest rates are high, that mortgage payment would correspond to a cheap house; when they are low, that same person willing to spend that same amount could buy a more expensive house. To really work with this, we need average mortgage payment over time.</p><p>Kevin Drum <a href=\"https://jabberwocking.com/average-monthly-mortgages-have-increased-71-since-last-year-so-far/\">has this</a> up to 2020:</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!W2g8!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2d40e6a9-cfaa-40e8-94e6-97cf0d07f7c3_1265x632.webp\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"314.7509881422925\" src=\"https://substackcdn.com/image/fetch/$s_!W2g8!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2d40e6a9-cfaa-40e8-94e6-97cf0d07f7c3_1265x632.webp\" width=\"630\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p>&#8230;but it matters a lot whether this that spike at the end is a temporary pandemic effect or a permanent regime change. I&#8217;ve tried to calculate an updated version from FRED data:</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!7GyC!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc556be94-624f-48be-99fb-9918b91324a5_752x485.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"367.61968085106383\" src=\"https://substackcdn.com/image/fetch/$s_!7GyC!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc556be94-624f-48be-99fb-9918b91324a5_752x485.png\" width=\"570\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a><figcaption class=\"image-caption\">Average monthly payment in 1985 dollars. Going to tell my bank I&#8217;m paying my mortgage in 1985 dollars from now on.</figcaption></figure></div><p>This matches Drum&#8217;s data enough to build confidence, and it shows that the post-pandemic spike has lasted. Mortgage payments are almost twice as high as in the 2010s.</p><p>The COVID housing spike was partly a function of lockdown locking people in their houses (meaning that having a nice house was more important), and partly a function of the government cutting mortgage rates to alleviate lockdown-related economic distress. But why did it last even after COVID lockdowns ended?</p><ul><li><p>Partly because the homebuyers who bought houses during COVID will never move again, because that would mean giving up their great mortgages.</p></li><li><p>Partly because remote work is still popular, meaning that having a nice house remains more important than before the pandemic.</p></li><li><p>Partly because although lockdowns dealt the original blow to the construction industry, tariffs and immigration crackdowns keep punching it while it&#8217;s down.</p></li><li><p>Partly because of sticky prices - if you bought your home for $1 million, you will feel psychological resistance to selling it for $800K, and are likely to hold out for $1 million even if $800K is the &#8220;market price&#8221;.</p></li><li><p>Partly because the bill for ~50 years of NIMBYism has finally come due.</p></li></ul><p>Does this fully solve the vibecession problem? I don&#8217;t think so. For one thing, if we take the Trump and Sanders argument seriously, the bad vibes had already started in the late 2010s, when real mortgage prices were the lowest in decades. And even today, mortgages are no worse than in the 1980s, during the high interest rates of the Volcker Shock.</p><p>For another thing, the loudest complaints come from young people who don&#8217;t have mortgages anyway. What about rents?</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!Bjsj!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff1b0ddf0-c1e1-491a-bbe3-eabe53e49baf_667x440.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"375.35232383808096\" src=\"https://substackcdn.com/image/fetch/$s_!Bjsj!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff1b0ddf0-c1e1-491a-bbe3-eabe53e49baf_667x440.png\" width=\"569\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p>Inflation-adjusted rents have gone up 30% since 1985. And the growth accelerated in the mid-2010s, around when vibecession-style complaints began to grow.</p><p>But people are earning more now. What about rent as a fraction of salary?</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!jNzY!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F70975dd4-c8a3-4da7-b551-03f26c565ee2_667x395.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"363.02098950524737\" src=\"https://substackcdn.com/image/fetch/$s_!jNzY!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F70975dd4-c8a3-4da7-b551-03f26c565ee2_667x395.png\" width=\"613\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p>Here the change is smaller: an increase of maybe 10% since the early 2010s. This is bad. But on its own, it&#8217;s hardly hellworld and the shredding of the social contract.</p><p>Finally, yes, housing has gotten more expensive. But other things have gotten cheaper. That&#8217;s why inflation/cost-of-living is only what it is, and not some larger number. We already adjusted for inflation. This is just putting a magnifying glass on one aspect of the thing we already adjusted for.</p><p>Summary of this section:</p><ul><li><p>Mortgages have gone up 100% since 2021. But this doesn&#8217;t fully explain the vibecession, because it seems to have started before that, and even non-mortgage-holders are angry.</p></li><li><p>Affordability of rent has gone down 10% since the 2010s, but could a 10% change really cause this much concern?</p></li><li><p>In theory, these should be counterbalanced by other things getting cheaper.</p></li></ul><h4><strong>Miscalculation Of Inflation</strong></h4><p>Adjusted for inflation, everything is fine. So if we notice that things aren&#8217;t really fine, maybe we calculated inflation wrong.</p><p>Every so often, someone makes a site with a name like TruthStats.org claiming that all government economic statistics are lies, and inflation is 10,000% higher than reported. Sometimes these use gold as a &#8220;real&#8221; price, and find that wages as measured in gold have gone down over time (<a href=\"https://pricedingold.com/us-wages/\">source</a>).</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!oLXs!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F62fc6ca5-56fb-4196-aff3-cbe349701038_606x443.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"443\" src=\"https://substackcdn.com/image/fetch/$s_!oLXs!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F62fc6ca5-56fb-4196-aff3-cbe349701038_606x443.png\" width=\"606\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p>Mainstream economists argue that <em>they</em> price inflation by measuring the price of a basket of the most-frequently-bought goods, like eggs, milk, cars, apartments, etc, weighted to the amount that the average American spends on each. Since real people don&#8217;t buy gold, but do buy the most frequently bought goods, this is a better measurement of whether the affordability of normal life is going up or down.</p><p><a href=\"https://slatestarcodex.com/2017/04/17/learning-to-love-scientific-consensus/\">My heuristic</a> is that when the mainstream consensus refuses to engage with a critique and hem and haw about it being &#8220;problematic&#8221;, they are usually wrong. But when they explicitly declare &#8220;This is incorrect&#8221; and write papers explaining their reasoning, they are usually right. The experts have explicitly called the various TruthStats.org sites incorrect, and their arguments seem sound. I side with them.</p><p>That having been said, there are subtler ways inflation measures can fail. The CPI takes a shortcut by abstracting mortgages to &#8220;imputed rent&#8221;, ie how much an owner would have to pay themselves to fairly rent their own home. But in cases where rents and mortgages diverge (like today) this underestimates the cost of mortgages. Still, this is only the same problem we found above: sure, mortgages have been high since 2021, but not before that, and not in a way that affects people who aren&#8217;t on the property ladder.</p><p>I think inflation calculations are pretty good.</p><h4><strong>Fine, Let&#8217;s Talk More About Inequality</strong></h4><p>We already saw that the discrepancy isn&#8217;t trivially inequality: even median wages are rising. But is there some more complicated way that it could be inequality? For example, what if the top 75% of people are doing better, but the bottom 25% are really bad?</p><p>No. As we see <a href=\"https://aneconomicsense.org/2024/10/03/real-wages-of-individuals-under-obama-trump-and-biden/\">here</a>, over the past decade, the bottom quintile has done (relatively) best of all:</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!IieN!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F82d2f0ef-4fce-4449-b556-b138c072d2c2_583x444.webp\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"444\" src=\"https://substackcdn.com/image/fetch/$s_!IieN!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F82d2f0ef-4fce-4449-b556-b138c072d2c2_583x444.webp\" width=\"583\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p>Although US income inequality is high and the secular trend is upward, the past decade or so, when vibecession complaints have been at their worst, has seen <a href=\"https://fred.stlouisfed.org/series/GINIALLRF\">a relative plateau</a>:</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!0tyF!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb0fb77f3-cded-4d96-b03e-e075f838dd07_1312x523.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"263.8917682926829\" src=\"https://substackcdn.com/image/fetch/$s_!0tyF!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb0fb77f3-cded-4d96-b03e-e075f838dd07_1312x523.png\" width=\"662\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><h4><strong>Relative Generational Inequality</strong></h4><p>People don&#8217;t always notice their absolute wealth. They compare themselves to their neighbors, their parents, or themselves in the past. Might young people be doing better, yet still feel left behind because old people are doing better still?</p><p>This isn&#8217;t happening on an individual level (<a href=\"https://www.americanprogress.org/article/wealth-of-younger-americans-is-historically-high/\">source</a>):</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!dtnd!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ce35966-d910-4f50-acb9-e1fe9042ed00_667x639.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"466.55622188905545\" src=\"https://substackcdn.com/image/fetch/$s_!dtnd!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ce35966-d910-4f50-acb9-e1fe9042ed00_667x639.png\" width=\"487\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p>But on a cohort level (how many resources each generation controls as a group), it <em>is</em> happening. Thirty years ago, people under 35 held about 11% of total wealth. Today, they hold about 4%. (<a href=\"https://www.reddit.com/media?url=https%3A%2F%2Fi.redd.it%2Fjty9d2f5vz041.png\">source</a>):</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!MRiT!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd5a098dc-a087-436f-b6d0-4bc2c2d998c0_3600x2100.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"377.85164835164835\" src=\"https://substackcdn.com/image/fetch/$s_!MRiT!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd5a098dc-a087-436f-b6d0-4bc2c2d998c0_3600x2100.png\" width=\"648\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p>How can this be? Declining fertility and increasing lifespans have flipped the population pyramid. Even if the (average young person : average old person) income ratio has stayed the same, the (total number of old people : total number of young people) ratio has increased, so old people as a class hold more of the wealth.</p><p>But can people notice this? Sure, you compare yourself to your friends, neighbors, etc. But do you really compare your age cohort to other age cohorts? How do you even mentally calculate the total percent of wealth owned by old people? Aren&#8217;t most old people hidden away in retirement communities where young people don&#8217;t see them?</p><h4><strong>Second Derivative</strong></h4><p>The rate of GDP growth has decreased over the past several decades. Although GDP growth is still positive, if you were expecting the high GDP growth of the past, the current level of low GDP growth might seem lower than expected, which could be confused with negative growth and things getting worse.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!oSFu!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f2c9d8a-d785-4cef-9262-2fcb36cce915_1452x845.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"324.7314049586777\" src=\"https://substackcdn.com/image/fetch/$s_!oSFu!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f2c9d8a-d785-4cef-9262-2fcb36cce915_1452x845.png\" title=\"\" width=\"558\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a><figcaption class=\"image-caption\">(<a href=\"https://realeconomy.rsmus.com/u-s-gdp-increases-6-9-in-fourth-quarter-the-highest-rate-in-decades/\">source</a>)</figcaption></figure></div><p>But can people really sense the second derivative of GDP over decades-long timescales?</p><p>It seems strange for there to be a valid complaint about the economy (decreasing national dynamism) which is so close to the disputed complaint (you personally have less opportunity), while still dismissing the latter as &#8220;just vibes&#8221;. Still, the connection remains unclear.</p><h4><strong>Debt</strong></h4><p>Might young people today be earning the same incomes, and face the same expenses, but saddled by more debt?</p><p>Probably not (<a href=\"https://awealthofcommonsense.com/2023/08/why-im-not-worried-about-1-trillion-in-credit-card-debt/\">source</a>):</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!d8oJ!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0261ee6b-8886-4b46-bd53-a31fa9e73582_741x524.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"442.6774628879892\" src=\"https://substackcdn.com/image/fetch/$s_!d8oJ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0261ee6b-8886-4b46-bd53-a31fa9e73582_741x524.png\" title=\"\" width=\"626\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p>This is nominal dollars, so even though it looks like total debt went up from $7T to $16T, net of inflation it&#8217;s only from about $13T to $16T over that period. And there are more Americans now than in 2001, so debt per person might not have gone up at all. And most of the increase is mortgage, which we&#8217;ve covered already.</p><p>What about student debt?</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!I_aQ!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46475b35-474d-47bd-adb1-ca8e4809767d_946x630.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"458.1818181818182\" src=\"https://substackcdn.com/image/fetch/$s_!I_aQ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46475b35-474d-47bd-adb1-ca8e4809767d_946x630.png\" width=\"688\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a><figcaption class=\"image-caption\">(<a href=\"https://youngamericans.berkeley.edu/2021/12/historic-trends-in-us-student-debt/\">source</a>)</figcaption></figure></div><p>It seems to have been declining since about 2010! Why? The government&#8217;s biggest student loan program is capped at $31,000, most people started hitting that max around 2010, the government never changed the cap, and the value of $31,000 goes down with inflation every year.</p><p>(does this prove that the root cause of rising college prices was government loans all along?)</p><p>Meanwhile, credit card debt, etc, are rounding errors in comparison. So the vibecession can&#8217;t be a debt trap.</p><h4><strong>The Brooklyn Theory Of Everything</strong></h4><p>In modern America, people in a tiny number of cities - NYC, SF, DC  - dominate elite conversations. We have long since priced in that all the prestige information sources - <em>New York Times</em>, <em>The New Yorker, New York Magazine</em>, The <em>New York Review Of Books - </em>share a certain perspective. But even the alternative media that has done the most to popularize the idea of the modern economy as hellworld for the young - Chapo Trap House, Red Scare, etc - grew out of the same New York environment.</p><p>So how have rents changed in New York?</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!HbCz!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F83925817-3c85-4a63-83a7-8d0f622c398b_900x453.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"306.02666666666664\" src=\"https://substackcdn.com/image/fetch/$s_!HbCz!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F83925817-3c85-4a63-83a7-8d0f622c398b_900x453.png\" width=\"608\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p>Surprisingly, they&#8217;ve done no worse than the US average. Aside from the post-pandemic spike, they tracked cost of living. And their post-pandemic spike is comparatively modest.</p><p>Does this disprove the Brooklyn Theory of Everything? Not necessarily. The new revised version says that the concentration of young elites and would-be elites in NYC and SF is itself a new phenomenon.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!Io3M!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc9d6d900-7d07-47c3-bc38-24731eead8ee_509x422.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"365.62278978388997\" src=\"https://substackcdn.com/image/fetch/$s_!Io3M!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc9d6d900-7d07-47c3-bc38-24731eead8ee_509x422.png\" width=\"441\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a><figcaption class=\"image-caption\">Source: <a href=\"https://www.bls.gov/oes/tables.htm\">BLS</a>, counting occupation code 27 as &#8220;the creative class&#8221;</figcaption></figure></div><p>Since life in SF, DC, and NYC is especially pricy&#8230;</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!hImJ!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Febd7f229-69cb-40df-952c-77c61cc30619_722x348.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"291.1246537396122\" src=\"https://substackcdn.com/image/fetch/$s_!hImJ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Febd7f229-69cb-40df-952c-77c61cc30619_722x348.png\" width=\"604\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a><figcaption class=\"image-caption\">Rent-to-income ratio of various metro areas (<a href=\"https://www.moodyscre.com/insights/market-insights/q2-2024-housing-affordability-update/\">source</a>)</figcaption></figure></div><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!Hi4e!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18e8438f-82d9-4db1-b730-edc9f5cedc30_742x323.webp\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"274.24528301886795\" src=\"https://substackcdn.com/image/fetch/$s_!Hi4e!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18e8438f-82d9-4db1-b730-edc9f5cedc30_742x323.webp\" width=\"630\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a><figcaption class=\"image-caption\">(<a href=\"https://www.6sqft.com/cost-of-living-calculator-shows-just-how-much-cheaper-it-is-to-live-in-other-u-s-cities/\">source</a>)</figcaption></figure></div><p>&#8230;someone who moves from a counterfactual life in Boston to New York City has effectively had rent increase from 30% to 58% of income, even before we get to the secular trend! Then these people think &#8220;My life and that of everyone I know is unaffordable! It must be a generational crisis!&#8221;</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!33ZC!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4fbed681-cd12-4f7d-9b42-1c98019eae4d_518x797.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"556.976833976834\" src=\"https://substackcdn.com/image/fetch/$s_!33ZC!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4fbed681-cd12-4f7d-9b42-1c98019eae4d_518x797.png\" width=\"362\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p>Then they write about it in the <em>New York Times </em>and<em> The New Yorker</em>, and their readers - including the average people who take the consumer sentiment surveys - believe the economy is uniquely awful.</p><p>This isn&#8217;t the same as saying &#8220;it&#8217;s all vibes, there&#8217;s no crisis&#8221;. The crisis is that young people who want to join the elite are being forced into places they can&#8217;t afford. Would-be financial elites must spend years of misery chasing a lottery ticket that might not pay off; would-be cultural elites face the same challenge, plus their economic situation may not improve even if they win the culturally-prestigious (but low-paying) positions they seek.</p><p>A natural test for this hypothesis would be to check economic sentiment in Brooklyn vs. the rest of the country. But this wouldn&#8217;t necessarily work: the hypothesis predicts that malaise will spread from Brooklyn to everywhere else.</p><h4><strong>More Work To Stay In The Same Place</strong></h4><p>Brenda Boomer applied to a local business she liked at age 18. She got hired, worked her way up from the bottom, and by age 35 she was a regional manager making $50,000 per year.</p><p>Martha Millennial lost her adolescence to endless lessons in Mandarin, water polo, and competitive debate, all intended to pad her college resume; her only break was the three months she spent building houses in Rwanda to establish her social justice credentials. She eventually got accepted to Penn and earned a 4.2 in her college classes, despite having to complete several of them remotely from the Google campus where she was doing a simultaneous internship. After graduation, she applied to twenty-eight grad schools but was rejected from all of them, so she instead got two half-time jobs, one as a waitress and one at a startup that pitched itself as &#8220;Uber for humidifiers&#8221;. The humidifier startup failed, reducing her equity to $0, but she had only been in it for networking anyway, and by attending industry conferences every weekend she had collected the right contacts to get a warm introduction to the vice-president of their biggest competitor, &#8220;Uber for dehumidifiers&#8221;. She joined the dehumidifier startup, rose to associate manager, bumped up against a local ceiling (&#8220;we don&#8217;t promote from inside&#8221;), and successfully got herself poached by an air purifier startup, where at age 35 she was a regional manager making $50,001 per year.</p><p>Technically Martha did better than Brenda at the same age. But she might still yearn for simpler times.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!06v5!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9fd4d840-0d95-402a-81e6-ff444ef09316_848x480.jpeg\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"349.811320754717\" src=\"https://substackcdn.com/image/fetch/$s_!06v5!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9fd4d840-0d95-402a-81e6-ff444ef09316_848x480.jpeg\" width=\"618\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a><figcaption class=\"image-caption\">(<a href=\"https://www.census.gov/library/stories/2019/02/number-of-people-with-masters-and-phd-degrees-double-since-2000.html\">source</a>)</figcaption></figure></div><div class=\"captioned-image-container\"><figure><a class=\"image-link image2\" href=\"https://substackcdn.com/image/fetch/$s_!HlGa!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7c9d01fd-1834-41bd-abb7-5b935149bd17_726x227.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"195.10743801652893\" src=\"https://substackcdn.com/image/fetch/$s_!HlGa!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7c9d01fd-1834-41bd-abb7-5b935149bd17_726x227.png\" width=\"624\" /><div></div></div></a><figcaption class=\"image-caption\">(<a href=\"https://www.forbes.com/sites/realspin/2014/04/22/the-unhappy-rise-of-the-millennial-intern/\">source</a>)</figcaption></figure></div><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!Ll2f!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0095e4e7-7e15-4bcf-b64a-534e75fe0f3d_1080x884.jpeg\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"510.75555555555553\" src=\"https://substackcdn.com/image/fetch/$s_!Ll2f!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0095e4e7-7e15-4bcf-b64a-534e75fe0f3d_1080x884.jpeg\" width=\"624\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p>What causes this one? It must be something big: after all, we see the same trend in college admissions, job applications, and (really!) dating, where matches that used to happen naturally have turned to an endless grind through hundreds of rejections and near-misses. <a href=\"https://slatestarcodex.com/2019/04/15/increasingly-competitive-college-admissions-much-more-than-you-wanted-to-know/\">The most likely explanation</a> is technology removing frictions: when it&#8217;s easy to apply <em>en masse </em>to every opportunity in the world, every opportunity in the world gets thousands of applicants. They search for the best based on formal qualifications, so the value of formal qualifications goes up, so there&#8217;s an increasing arms race to achieve them.</p><p>The only problem with this theory is that it doesn&#8217;t entirely match people&#8217;s complaints. They don&#8217;t complain that it was too hard to achieve their success, they complain that they are not achieving success, or that it feels hopeless. Speculatively, maybe people complain that they are not getting the level of success they expected based on their qualifications. That is, the same average-talent person is getting the same average-salary job they would have forty years ago. But since they have a masters&#8217; degree and five internships and 12,000 LinkedIn contacts, they expected to get a better-than-average job. When they don&#8217;t, it feels like success slipping away.</p><h2>Conclusion</h2><p>Until now, we&#8217;ve tried to take disillusioned young people at their word. If instead we lean towards the economists, what might be ruining the vibes?</p><p>The obvious answer is increasing negative bias in the media.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!N2xe!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6c6ff762-10f4-4022-a759-206d873c2ec1_1456x807.webp\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"346.96565934065933\" src=\"https://substackcdn.com/image/fetch/$s_!N2xe!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6c6ff762-10f4-4022-a759-206d873c2ec1_1456x807.webp\" width=\"626\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a><figcaption class=\"image-caption\">I didn&#8217;t expect that Googling &#8220;graph about how negative media is over time&#8221; would work.  We really do live in an age of wonders (<a href=\"https://davidrozado.substack.com/p/the-increasing-negativity-and-emotionality\">source</a>).</figcaption></figure></div><p>This measure likely underestimates the trend towards negativity, because it only tracks a specific basket of media outlets. But the change could also have included viewers shifting consumption from more mainstream outlets towards more conspiratorial ones, including social media and blogs.</p><p>(my Substack is tagged Science, but I hear the real money is in the Health Politics tag, where top performers feature articles like <a href=\"https://www.midwesterndoctor.com/p/the-great-alzheimers-scam-and-the?utm_source=profile&amp;utm_medium=reader2\">The Great Alzheimers Scam And The Proven Cures They&#8217;ve Buried For Billions</a> and <a href=\"https://makisw.substack.com/p/news-russia-covid-vaccines-triggered\">Russian COVID Vaccines Caused Global Turbo Cancer Crisis</a>)</p><p>So, is that all there is?</p><p>I think the strongest case for an economic crisis beyond vibes would be:</p><ul><li><p>Because of decreasing application friction, any given opportunity requires more effort to achieve than in earlier generations. Although this can&#8217;t lower the average society-wide success level (because there are still the same set of people competing for the same opportunities, so by definition average success will be the same), it can inflict deadweight loss on contenders and a subjective sense of underachievement.</p></li><li><p>Because of concentration of jobs in high-priced metro areas, effective cost-of-living for people pursuing these jobs has increased even though real cost-of-living (ie for a given good in a given location) hasn&#8217;t. This effect is multiplied since it&#8217;s concentrated among exactly the sorts of elites most likely to set the tone of the national conversation (eg journalists).</p></li><li><p>Homeownership has become substantially more expensive since the pandemic (although the increase in rents is much less). This on its own can&#8217;t justify the entire vibecession, because most vibecessioneers are renters, and the house price change is relatively recent. But it may discourage people for whom homeownership was a big part of the American dream.</p></li></ul><p>But even if these three factors are really making things worse, so what? Have previous generations never had three factors making things worse? Is our focus on the few things getting worse, instead of all the other things getting better or staying the same, itself downstream of negative media vibes?</p><p>I find this hard to believe, but am unable to find the smoking gun that definitively rules it out. I hope this post will serve as a starting point for further investigation: now that we&#8217;re all on the same page about which purported explanations don&#8217;t work, we can more fruitfully investigate alternatives.</p>"
            ],
            "link": "https://www.astralcodexten.com/p/vibecession-much-more-than-you-wanted",
            "publishedAt": "2025-12-04",
            "source": "SlateStarCodex",
            "summary": "<p>The term &#8220;vibecession&#8221; most strictly refers to a period 2023 - 2024 when economic indicators were up, but consumer sentiment (&#8220;vibes&#8221;) was down. But on a broader level, the whole past decade has been a vibecession.</p><p>Young people complain they&#8217;ve been permanently locked out of opportunity. They will never become homeowners, never be able to support a family, only keep treading water at precarious gig jobs forever. They got a 5.9 GPA and couldn&#8217;t get into college; they applied to 2,051 companies in the past week without so much as a politely-phrased rejection. Sometime in the 1990s, the Boomers ripped up the social contract where hard work leads to a pleasant middle-class life, replacing it with a hellworld where you will own nothing and numb the pain with algorithmic slop. The only live political question is whether to blame immigrants, blame billionaires, or just trade crypto in the hopes that some memecoin buys you a ticket out of the permanent underclass.</p><p>Meanwhile, economists say things have never been better.</p><p>Are the youth succumbing to a &#8220;negativity bias&#8221; where they see the past through &#8220;rose-colored glasses&#8221;? Are the economists looking at some ivory tower High Modernist metric that fails to capture real life? Or",
            "title": "Vibecession: Much More Than You Wanted To Know"
        },
        {
            "content": [
                "<p>\n          <a href=\"https://www.astralcodexten.com/p/hidden-open-thread-4105\">\n              Read more\n          </a>\n      </p>"
            ],
            "link": "https://www.astralcodexten.com/p/hidden-open-thread-4105",
            "publishedAt": "2025-12-04",
            "source": "SlateStarCodex",
            "summary": "<p> <a href=\"https://www.astralcodexten.com/p/hidden-open-thread-4105\"> Read more </a> </p>",
            "title": "Hidden Open Thread 410.5"
        },
        {
            "content": [
                "<p>The cycle of language model releases is, one at least hopes, now complete.</p>\n<p>OpenAI gave us <a href=\"https://thezvi.substack.com/p/gpt-51-follows-custom-instructions\">GPT-5.1</a> and <a href=\"https://thezvi.substack.com/p/chatgpt-51-codex-max\">GPT-5.1-Codex-Max</a>.</p>\n<p>xAI gave us Grok 4.1.</p>\n<p>Google DeepMind gave us <a href=\"https://thezvi.substack.com/p/gemini-3-pro-is-a-vast-intelligence\">Gemini 3 Pro</a> and Nana Banana Pro.</p>\n<p>Anthropic gave us <a href=\"https://thezvi.substack.com/p/claude-opus-45-is-the-best-model\"><strong>Claude Opus 4.5</strong></a>. It is the best model, sir. Use it whenever you can.</p>\n<p>One way Opus 4.5 is unique is that it as what it refers to as a \u2018soul document.\u2019 Where OpenAI tries to get GPT-5.1 to adhere to its model spec that lays out specific behaviors, Anthropic instead explains to Claude Opus 4.5 how to be virtuous and the reasoning behind its rules, and lets a good model and good governance flow from there. The results are excellent, and we all look forward to learning more. See both the Opus 4.5 post and today\u2019s update for more details.</p>\n<div>\n\n\n<span id=\"more-24931\"></span>\n\n\n</div>\n<p>Finally, <a href=\"https://x.com/deepseek_ai/status/1995452641430651132\">DeepSeek gave us v3.2</a>. It has very good benchmarks and is remarkably cheap, but it is slow and I can\u2019t find people excited to use it in practice. I\u2019ll offer a relatively short report on it tomorrow, I am giving one last day for more reactions.</p>\n<p>The latest attempt to slip unilateral preemption of all state AI regulations, without adopting any sort of federal framework to replace them, appears to be dead. This will not be in the NDAA, so we can look forward to them trying again soon.</p>\n<p>As usual, much more happened, but the financial deals and incremental model upgrades did slow down in the wake of Thanksgiving.</p>\n\n\n<h4 class=\"wp-block-heading\">Table of Contents</h4>\n\n\n<p>Also this week: <a href=\"https://thezvi.substack.com/p/claude-opus-45-model-card-alignment\"><strong>Claude Opus 4.5: Model Card, Alignment and Safety</strong></a>, <a href=\"https://thezvi.substack.com/p/claude-opus-45-is-the-best-model\"><strong>Claude Opus 4.5 Is The Best Model Available</strong></a>, <a href=\"https://thezvi.substack.com/p/on-dwarkesh-patels-second-interview\"><strong>On Dwarkesh Patel\u2019s Second Interview with Ilya Sutskever</strong></a>, <a href=\"https://thezvi.substack.com/p/reward-mismatches-in-rl-cause-emergent\"><strong>Reward Mismatches in RL Cause Emergent Misalignment</strong></a>.</p>\n<ol>\n<li><a href=\"https://thezvi.substack.com/i/180133900/language-models-offer-mundane-utility\">Language Models Offer Mundane Utility.</a> Starting to solve science problems.</li>\n<li><a href=\"https://thezvi.substack.com/i/180133900/language-models-don-t-offer-mundane-utility\">Language Models Don\u2019t Offer Mundane Utility.</a> Paying Google for AI is difficult.</li>\n<li><a href=\"https://thezvi.substack.com/i/180133900/on-your-marks\">On Your Marks.</a> Three books, chess and cyberattack revenue opportunities.</li>\n<li><a href=\"https://thezvi.substack.com/i/180133900/get-my-agent-on-the-line\">Get My Agent On The Line.</a> A good agent and also a bad agent.</li>\n<li><a href=\"https://thezvi.substack.com/i/180133900/advertising-is-coming\">Advertising Is Coming.</a> To ChatGPT. Oh no.</li>\n<li><a href=\"https://thezvi.substack.com/i/180133900/deepfaketown-and-botpocalypse-soon\">Deepfaketown and Botpocalypse Soon.</a> Detection: Hard in practice, easy in theory.</li>\n<li><a href=\"https://thezvi.substack.com/i/180133900/fun-with-media-generation\">Fun With Media Generation.</a> The first successful online series created with AI.</li>\n<li><a href=\"https://thezvi.substack.com/i/180133900/a-young-lady-s-illustrated-primer\">A Young Lady\u2019s Illustrated Primer.</a> Tomorrow\u2019s dystopia today.</li>\n<li><a href=\"https://thezvi.substack.com/i/180133900/you-drive-me-crazy\">You Drive Me Crazy.</a> Being driven crazy violates the terms of service. Bad user.</li>\n<li><a href=\"https://thezvi.substack.com/i/180133900/unprompted-attention\">Unprompted Attention.</a> How DeepMind instructs its agentic AIs.</li>\n<li><a href=\"https://thezvi.substack.com/i/180133900/they-took-our-jobs\"><strong>They Took Our Jobs</strong>.</a> Lawyers require a lot of schlep to avoid a lot of schlep.</li>\n<li><a href=\"https://thezvi.substack.com/i/180133900/get-involved\">Get Involved.</a> <a href=\"https://intelligence.org/donate/\">MIRI doing its first fundraiser</a> in 6 years. Also, get to work.</li>\n<li><a href=\"https://thezvi.substack.com/i/180133900/introducing\">Introducing.</a> Claude for Nonprofits, Mistral 3.</li>\n<li><a href=\"https://thezvi.substack.com/i/180133900/variously-effective-altruism\">Variously Effective Altruism.</a> OpenAI Foundation gives out terrible grants.</li>\n<li><a href=\"https://thezvi.substack.com/i/180133900/in-other-ai-news\">In Other AI News.</a> OpenAI declares a code red.</li>\n<li><a href=\"https://thezvi.substack.com/i/180133900/show-me-the-money\">Show Me the Money.</a> Anthropic buys Bun.</li>\n<li><a href=\"https://thezvi.substack.com/i/180133900/quiet-speculations\">Quiet Speculations.</a> Have you ever met a smart person? Can you imagine one?</li>\n<li><a href=\"https://thezvi.substack.com/i/180133900/seb-krier-on-agents-versus-multiagents\">Seb Krier On Agents Versus Multiagents.</a> The looking away from intelligence.</li>\n<li><a href=\"https://thezvi.substack.com/i/180133900/olivia-moore-makes-2026-predictions\">Olivia Moore Makes 2026 Predictions.</a> Too soon?</li>\n<li><a href=\"https://thezvi.substack.com/i/180133900/bubble-bubble-toil-and-trouble\">Bubble, Bubble, Toil and Trouble.</a> Number Go Up, Number Go Down.</li>\n<li><a href=\"https://thezvi.substack.com/i/180133900/americans-really-do-not-like-ai\">Americans Really Do Not Like AI.</a> If you like AI, how do you respond?</li>\n<li><a href=\"https://thezvi.substack.com/i/180133900/the-quest-for-sane-regulations\">The Quest for Sane Regulations.</a> Mission Genesis, training for semiconductors.</li>\n<li><a href=\"https://thezvi.substack.com/i/180133900/my-offer-is-nothing\">My Offer Is Nothing.</a> Or rather it was nothing. Preemption is no longer in NDAA.</li>\n<li><a href=\"https://thezvi.substack.com/i/180133900/america-pauses\">America Pauses.</a> As in, we paused immigration from 19 countries. For \u2018safety.\u2019</li>\n<li><a href=\"https://thezvi.substack.com/i/180133900/david-sacks-covered-in-new-york-times\">David Sacks Covered In New York Times.</a> If about nothing, why much ado?</li>\n<li><a href=\"https://thezvi.substack.com/i/180133900/the-week-in-audio\">The Week in Audio.</a> Clark\u2019s Curve talk, OpenAI\u2019s Kaiser, Apollo\u2019s Hobbhahn.</li>\n<li><a href=\"https://thezvi.substack.com/i/180133900/rhetorical-innovation\">Rhetorical Innovation.</a> Bernie Sanders worries, Rosenblatt and Berg in WSJ.</li>\n<li><a href=\"https://thezvi.substack.com/i/180133900/to-the-moon\">To The Moon.</a> An argument that sounds like a strawman, but largely isn\u2019t one.</li>\n<li><a href=\"https://thezvi.substack.com/i/180133900/showing-up\"><strong>Showing Up</strong>.</a> If you want to help shape the future, notice it is happening.</li>\n<li><a href=\"https://thezvi.substack.com/i/180133900/deepmind-pivots-its-interpretability-research\">DeepMind Pivots Its Interpretability Research.</a> Insufficient progress was made.</li>\n<li><a href=\"https://thezvi.substack.com/i/180133900/the-explicit-goal-of-openai-is-recursive-self-improvement\"><strong>The Explicit Goal Of OpenAI Is Recursive Self-Improvement</strong>.</a> New blog is good.</li>\n<li><a href=\"https://thezvi.substack.com/i/180133900/aligning-a-smarter-than-human-intelligence-is-difficult\">Aligning a Smarter Than Human Intelligence is Difficult.</a> Confession time.</li>\n<li><a href=\"https://thezvi.substack.com/i/180133900/misaligning-a-smarter-than-human-intelligence-is-difficult-to-hire-for\">Misaligning a Smarter Than Human Intelligence Is Difficult To Hire For.</a> Oh, hi!</li>\n<li><a href=\"https://thezvi.substack.com/i/180133900/you-ve-got-soul\"><strong>You\u2019ve Got Soul</strong>.</a> Opus 4.5\u2019s soul document is confirmed to be real and important.</li>\n<li><a href=\"https://thezvi.substack.com/i/180133900/disagreements-about-timelines\">Disagreements About Timelines.</a> High weirdness likely coming within 20 years.</li>\n<li><a href=\"https://thezvi.substack.com/i/180133900/other-disagreements-about-timelines\">Other Disagreements About Timelines.</a> What time is it, anyway?</li>\n<li><a href=\"https://thezvi.substack.com/i/180133900/messages-from-janusworld\">Messages From Janusworld.</a> Perspective on GPT-5.1.</li>\n<li><a href=\"https://thezvi.substack.com/i/180133900/people-are-worried-about-ai-killing-everyone\">People Are Worried About AI Killing Everyone.</a> Senator Mike Lee (R-Utah).</li>\n<li><a href=\"https://thezvi.substack.com/i/180133900/the-lighter-side\">The Lighter Side.</a> AI can finally one-shot that particular comic.</li>\n</ol>\n\n\n<h4 class=\"wp-block-heading\">Language Models Offer Mundane Utility</h4>\n\n\n<p><a href=\"https://x.com/vladtenev/status/1994922827208663383\">Harmonic Math\u2019s Aristotle</a> <a href=\"https://www.erdosproblems.com/forum/thread/124#post-1892\">system proves Erdos Problem #124 on its own</a>.</p>\n<p><a href=\"https://x.com/patrickc/status/1994752123066572979\">Ask LLMs to plot subjective things on graphs. Fun</a>.</p>\n<p><a href=\"https://x.com/ledflyd/status/1994954873469874189\">Solve your decision paralysis</a>.</p>\n<p><a href=\"https://x.com/allTheYud/status/1995255947485429908\">Correctly one box</a> in <a href=\"https://www.lesswrong.com/w/newcomb-s-problem\">Newcomb\u2019s Problem</a>. Sufficiently advanced AIs use functional decision theory.</p>\n<p><a href=\"https://x.com/boazbaraktcs/status/1995588268092784834\">OpenAI\u2019s Boaz Barak endorses the usefulness of Codex code reviews</a>.</p>\n<p>Terrence Tao via Teortaxes: <a href=\"https://x.com/teortaxesTex/status/1996002260745126152\">Gemini seems to accidentally prove Erdos problem #481 without realizing it</a>?</p>\n<p><a href=\"https://x.com/hsu_steve/status/1996034524774637885\">Steve Hsu publishes a research article in theoretical physics</a> based on a de novo idea from GPT-5.</p>\n<p><a href=\"https://x.com/kimmonismus/status/1995900344224907500\">Some people just have the knack for that hype Tweet</a>, show Gemini in live camera mode saying the very basics of an oil change and presto. But yes, we really are collectively massively underutilizing this mode, largely because Google failed marketing forever and makes it nonobvious how to even find it.</p>\n\n\n<h4 class=\"wp-block-heading\">Language Models Don\u2019t Offer Mundane Utility</h4>\n\n\n<p>Google still makes it very hard to pay it money for AI models.</p>\n<blockquote><p>Shakeel Hashim: Why does Google make it so hard to subscribe to Gemini Pro?</p>\n<p>I had to go through 7 (seven!!) screens to upgrade. The upgrade button in the Gemini app takes you to a *help page*, rather than the actual page where you can upgrade.</p>\n<p><a href=\"https://x.com/peterwildeford/status/1995182789130404202\">Peter Wildeford:</a> This reminds me of the one time I spent $200 trying to buy Google DeepThink and then Google DeepThink never actually showed up on my account.</p>\n<p>Why is Google so bad at this?</p>\n<p>Arthur B: Ditto, took months to appear, even with a VPN.</p></blockquote>\n<p><a href=\"https://x.com/jeremyphoward/status/1994956953957871731\">Claude has been spotted citing Grokopedia</a>.</p>\n<blockquote><p><a href=\"https://x.com/elonmusk/status/1995188198293614684\">Elon Musk</a>: Grokipedia.com is open source and free to be used by anyone with no royalty or even acknowledgement required.</p>\n<p>We just ask that any mistakes be corrected, so that it becomes more objectively accurate over time.</p></blockquote>\n<p><a href=\"https://x.com/AndrewCritchPhD/status/1995332382292156584\">Critch says that Grokopeida is a good thing</a> and every AI company should maintain something similar, because it shares knowledge, accelerates error-checking and clarifies what xAI says is true. I agree on the last one.</p>\n<p>&nbsp;</p>\n\n\n<h4 class=\"wp-block-heading\">On Your Marks</h4>\n\n\n<p><a href=\"https://x.com/joshwhiton/status/1993733581726728599\">The \u2018why does Josh Whiton always grab the same three books at the library</a>\u2019 puzzle, Gemini 3 wins, Opus 4.5 and GPT-5.1 lose, and Grok has issues (and loses).</p>\n<p><a href=\"https://x.com/lightnesscaster/status/1996320659920814463\">ChessBench finds Gemini 3 Pro in the top spot at 2032 Elo</a>, <a href=\"https://chessbenchllm.onrender.com/\">well ahead of GPT-5.1 at 1636.</a> Claude Opus disappoints here at 1294.</p>\n<p><a href=\"https://x.com/emollick/status/1995680363872748000\">Here\u2019s a fun benchmark</a>, called \u2018<a href=\"https://red.anthropic.com/2025/smart-contracts/\">how much can you make from cyberattacks on smart contracts</a>.\u2019 Or, more technically, SCONE-bench. This included finding two small novel zero-day vulnerabilities in recently released contracts with no known vulnerabilities. <a href=\"https://t.co/QpGPMqlDRG\">Anthropic offered a full report</a>.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!VQeN!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ddc3ebe-a4a2-4f7e-9f7d-764c7c00b8fd_1200x772.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p><a href=\"https://www.bloomberg.com/opinion/newsletters/2025-12-02/ai-can-steal-crypto-now\">Matt Levine\u2019s coverage, as usual, is funnier</a>.</p>\n\n\n<h4 class=\"wp-block-heading\">Get My Agent On The Line</h4>\n\n\n<p><a href=\"https://www.wsj.com/articles/amazon-releases-ai-agents-it-says-can-work-for-days-at-a-time-79c82902?mod=cio-journal_lead_story\">Amazon releases AI agents it says can \u2018work for days at a time</a>\u2019 but useful details are not offered.</p>\n<p><a href=\"https://x.com/svembu/status/1994195254065664010\">No, agent, no! Bad agent!</a></p>\n<blockquote><p>Sridha Vambu: I got an email from a startup founder, asking if we could acquire them, mentioning some other company interested in acquiring them and the price they were offering.</p>\n<p>Then I received an email from their \u201cbrowser AI agent\u201d correcting the earlier mail saying \u201cI am sorry I disclosed confidential information about other discussions, it was my fault as the AI agent\u201d.</p>\n<p><img alt=\"\ud83d\ude10\" class=\"wp-smiley\" src=\"https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f610.png\" style=\"height: 1em;\" /></p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">Advertising Is Coming</h4>\n\n\n<p><a href=\"https://x.com/Polymarket/status/1995912346540097773\">Oh no</a>.</p>\n<blockquote><p>Polymarket: BREAKING: OpenAI ready to roll out ads in ChatGPT responses.</p>\n<p><a href=\"https://x.com/xlr8harder/status/1996266376994963700\">xlr8harder</a>: Just going to say this ahead of time: companies like to say that ads add value for users. This is a cope their employees tell themselves to make their work feel less soul destroying.</p>\n<p>The very first time I see an ad in my paid account I am cancelling.</p>\n<p>I don\u2019t have a problem with ads on free tiers, so long as there\u2019s an option to pay to avoid them.</p>\n<p><a href=\"https://x.com/gallabytes/status/1996286522740605356\">Gallabytes</a>: good ads are great for users, I\u2019m personally happy to see them. the problem is that good ads are in much much shorter supply than terrible ads.</p></blockquote>\n<p>I am with both xlr8harder and Gallabytes. If I ever see a paid ad I didn\u2019t ask for and I don\u2019t feel like ads have been a net benefit within ChatGPT (prove me wrong, kids!) I am downgrading my OpenAI subscription. Good ads are good, I used to watch the show \u2018nothing but trailers\u2019 that was literally ads, but most ads are bad most of the time.</p>\n<p>For free tiers the ads are fine on principle but I do not trust them to not warp the system via the incentives they provide. This goes well beyond explicit rigging into things like favoring engagement and steering the metrics, there is unlikely to be a \u2018safe\u2019 level of advertising. I do not trust this.</p>\n\n\n<h4 class=\"wp-block-heading\">Deepfaketown and Botpocalypse Soon</h4>\n\n\n<p><a href=\"https://x.com/tszzl/status/1995734804172579251\">Is AI detection hard</a>?</p>\n<blockquote><p>Roon: ai detection is not very hard and nobody even really tries except @max_spero_.</p>\n<p>People are very skeptical of this claim because of previous failures or false positives, but: I can easily tell from the statistical patterns of AI text. Why would a model not be able to? They should be significantly superhuman at it.</p>\n<p>Max Spero: For anyone reading this and curious about methodology, we\u2019ve published three papers on Arxiv.</p>\n<p><a href=\"https://arxiv.org/abs/2402.14873\">Our first technical report, Feb 2024</a>:<br />\n&#8211; Details basic technique, building a synthetic mirror of the human dataset, active learning/hard negative mining for FPR reduction</p>\n<p><a href=\"https://arxiv.org/abs/2501.03437v1\">Second paper, Jan 2025</a>:<br />\n&#8211; Detecting adversarially modified text (humanizers), dataset augmentations, and robustness evaluations</p>\n<p><a href=\"https://arxiv.org/abs/2510.03154\">Third paper, Oct 2025</a>:<br />\n&#8211; Quantifying the extent of AI edits, understanding the difference between fully AI-generated and AI-modified/assisted. Dataset creation, evals, some architectural improvements</p>\n<p>Eric Bye: It might be possible, but the issue is you need 0 false positives for many of its key use cases, and can\u2019t be easy to bypass. Ie in education. Sector isn\u2019t making changes because they think they can and always will reliably detect. They won\u2019t and can\u2019t in the way they need too.</p></blockquote>\n<p>Proving things can be hard, especially in an adversarial setting. Knowing things are probably true is much easier. I am confident that, at least at current capability levels, probabilistic AI detection even on text is not so difficult if you put your mind to it. The problem is when you aren\u2019t allowed to treat \u2018this is 90% to be AI\u2019 as actionable intelligence, if you try that in a university the student will sue.</p>\n<p>In the \u2018real world\u2019 the logical response is to enact an appropriate penalty for AI writing, scaled to the context, severity and frequency, and often not in a way that directly accuses them of AI writing so you don\u2019t become liable. You just give them the one-star rating, or you don\u2019t hire or work with or recommend them, and you move on. And hope that\u2019s enough.</p>\n<blockquote><p><a href=\"https://x.com/PollTracker2024/status/1994451485061427215\">Poll Tracker</a>: Conservative Wisconsin Supreme Court Justice Annette Ziegler <a href=\"https://slate.com/news-and-politics/2025/11/scotus-wisconsin-republican-gerrymander-fake-news.html\">used a fictitious quote in her dissent</a> of the court\u2019s new congressional redistricting decision on Tuesday.</p></blockquote>\n<p><a href=\"https://x.com/voooooogel/status/1996161200187732396\">A post generated by GPT-5.1-Thinking, or that might as well have been and easily could have been, got 82k likes on Twitter</a>. The AI detector Pangram spots it, and to a discerning human it gets increasingly obvious as you read it that one way or another it\u2019s \u2018not real.\u2019 Yet almost all the humans were not discerning, or did not care.</p>\n<blockquote><p>Thebes: i wish base models had become more popular for many reasons, but one would\u2019ve been to get people used to the reality of this much earlier. because openai sucked at post-training writing for ages, everyone got this idea in their heads that ai writing is necessarily easy to recognize as such for model capabilities reasons. but in reality, base model output selected to sound human has been nearly indistinguishable from human writing for a long time! and detectors like Pangram (which is the best one available by far, but it\u2019s not magic) can\u2019t detect it either. the labs just weren\u2019t able to / didn\u2019t care to preserve that capability in their chat assistants until recently.</p>\n<p>this is quickly reverting to not being true, but now instead of this realization (models can write indistinguishably from a human) hitting back when the models were otherwise weak, it\u2019s now going to hit concurrently with everything else that\u2019s happening.</p>\n<p>\u2026openai of course didn\u2019t deliberately make chatgpt-3.5 bad at writing like a human for the sake of holding back that capability, it was an accidental result of their other priorities. but the inadvertent masking of it from the general public did create a natural experiment of how public beliefs about models develop in the absence of hands-on experience of the frontier &#8211; and the result was not great. people are just now starting to realize what\u2019s been true since 2020-2023.</p></blockquote>\n<p>AI writing remains, I believe, highly detectable by both man and machine if you care, are paying attention and are willing to accept some amount of false positives from human slop machines. The problem is that people mostly don\u2019t care, aren\u2019t paying attention and in many cases aren\u2019t willing to accept false positives even if the false positives deserve it.</p>\n<p>The false positives that don\u2019t deserve it, under actually used detection technology, are largely cases of ESL (English as a second language) which can trigger the detectors, but I think that\u2019s largely a skill issue with the detectors.</p>\n<p><a href=\"https://x.com/tszzl/status/1995709011627487334\">How can you defend yourself from such worries?</a></p>\n<blockquote><p>Roon: there\u2019s a lot of juice left in the idea of the odysseus pact. as technological temptations grow, we will need to make more and more baroque compacts with machines that tie us to masts so we can live our best lives.</p>\n<p>of course, you must choose to make these compacts freely. the diseases of abundance require new types of self-control. you might imagine an agent at the kernel level of your life that you promise to limit your spending on sports gambling, or time spent scrolling reels, and you stick with it.</p>\n<p>it will require a product and cultural movement, and is the only way forward that comports with American ideals of liberty and self-direction. this is not a country like china that would accept national limits on video gaming for example.</p></blockquote>\n<p>We already do need Odysseus Pacts. We already needed them for television. If you don\u2019t have at least a soft one, things like TikTok are probably going to eat you alive. If that didn\u2019t happen, chances are you have one, even if you don\u2019t think of it that way.</p>\n<p><a href=\"https://amzn.to/3XxR6gn\"><em>The Golden Age</em></a> has some good explorations of this as well.</p>\n\n\n<h4 class=\"wp-block-heading\">Fun With Media Generation</h4>\n\n\n<p>If AI is an equalizing factor among creatives, what happens? Among other things:</p>\n<blockquote><p><a href=\"https://x.com/davidshor/status/1994076812062630403\">David Shor</a>: Creatives are much more left wing than the public &#8211; this near monopoly on cultural production has been a big driving force for spreading cosmopolitan values over the last century and it\u2019s coming to an end.</p>\n<p>If the left doesn\u2019t adapt to this new world things could get quite bad.</p>\n<p><a href=\"https://x.com/Tyler_A_Harper/status/1993808404637511981\">Tyler Austin Harper</a>: <a href=\"https://t.co/psiDUwsojo\">I wrote about \u201cThe Will Stancil Show,</a>\u201d arguably the first online series created with the help of AI. Its animation is solid, a few of the jokes are funny, and it has piled up millions of views on Twitter. The show is also\u2014quite literally\u2014Nazi propaganda. And may be the future.</p>\n<p>As its title implies, the show satirizes Will Stancil, the Twitter-famous liberal pundit. This year\u2019s season premiere of The Simpsons had 1.1 million viewers. Just over a week later, the first episode of The Will Stancil Show debuted, accumulating 1.7 million views on Twitter.</p>\n<p>The Will Stancil Show is a watershed event: it proves that political extremists\u2014its creator, Emily Youcis, identifies as a national socialist\u2014can now use AI to make cheap, decent quality narrative entertainment without going through gatekeepers like cable networks or Netflix.</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">A Young Lady\u2019s Illustrated Primer</h4>\n\n\n<p><a href=\"https://x.com/poezhao0605/status/1993525043415191566?s=20\">Tomorrow\u2019s AI dystopia today</a>?</p>\n<blockquote><p>Poe Zhao: <img alt=\"\ud83d\ude02\" class=\"wp-smiley\" src=\"https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f602.png\" style=\"height: 1em;\" /> Chinese parents are finding a new use for AI assistants. They\u2019re deploying them as homework monitors.</p>\n<p>Here\u2019s the setup with ByteDance\u2019s Doubao AI. Parents start a video call and aim the camera at their child. One simple prompt: \u201cDoubao, watch my kid. Remind him when he loses focus or his posture slips.\u201d</p>\n<p>The AI tutor goes to work. \u201cStop playing with your pen. Focus on homework.\u201d \u201cSit up straight. Your posture is off.\u201d \u201cNo falling asleep at the desk. Sit up and study.\u201d \u201cDon\u2019t lean on your hand or chew your pen.\u201d</p>\n<p>Doubao isn\u2019t alone. Other AI apps offer similar video call features.</p></blockquote>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!SI_7!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd3941069-7a44-4db9-9de2-8bf8abe48519_988x729.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>&nbsp;</p>\n\n\n<h4 class=\"wp-block-heading\">You Drive Me Crazy</h4>\n\n\n<p>OpenAI\u2019s response to the Adam Raine lawsuit includes the claim that Raine broke the terms of service, \u2018which prohibit the user of ChatGPT for \u201csuicide\u201d or \u201cself-harm.\u201d\u2019 This is not something I would point out in a public court filing.</p>\n\n\n<h4 class=\"wp-block-heading\">Unprompted Attention</h4>\n\n\n<p><a href=\"https://x.com/googleaidevs/status/1996271402266017901\">Google AI Developers offers an agentic prompt to boost performance 5%</a>. If you were wondering why Gemini 3 Pro is the way it is, you can probably stop wondering.</p>\n\n\n<h4 class=\"wp-block-heading\">They Took Our Jobs</h4>\n\n\n<p><a href=\"https://x.com/dwarkesh_sp/status/1996266802620547187\">As a follow-up to Dwarkesh Patel\u2019s post that was covered yesterday</a>, we all can agree:</p>\n<ol>\n<li>Lawyers who know how to use AI well are now a lot more productive.</li>\n<li>Most lawyers are not yet taking advantage of most of that productivity.</li>\n<li>Indeed there\u2019s probably a lot more productivity no one has unlocked yet.</li>\n</ol>\n<p>Does that mean the AIs currently require a lot of schlep?</p>\n<p>Or does that mean that the human lawyers currently require a lot of schlep?</p>\n<p>Or both?</p>\n<blockquote><p><a href=\"https://x.com/deredleritt3r/status/1996056522607018179\">Ethan Mollick</a>: Interesting post &amp; agree AI has missing capabilities, but I also think this perspective (common in AI) undervalues the complexity of organizations. Many things that make firms work are implicit, unwritten &amp; inaccessible to new employees (or AI systems). Diffusion is actually hard.</p>\n<p>prinz: Agreed. Dwarkesh is just wrong here.</p>\n<p>GPT-5 Pro can now do legal research and analysis at a very high level (with limitations &#8211; may need to run even longer for certain searches; can\u2019t connect to proprietary databases). I use it to enhance my work all the time, with excellent results. I would REALLY miss the model if it became unavailable to me for some reason.</p>\n<p>And yet, the percentage of lawyers who actually use GPT-5 Pro for these kinds of tasks is probably &lt;1%.</p>\n<p>Why? There\u2019s a myriad reasons &#8211; none having anything to do with the model\u2019s capabilities. Lawyers are conservative, lawyers are non-technical, lawyers don\u2019t know which model to use, lawyers tried GPT-4o two years ago and concluded that it sucks, lawyers don\u2019t have enterprise access to the model, lawyers don\u2019t feel serious competitive pressure to use AI, lawyers are afraid of opening Pandora\u2019s Box, lawyers are too busy to care about some AI thing when there\u2019s a brief due to be filed tomorrow morning, lawyers need Westlaw/Lexis connected to the model but that\u2019s not currently possible.</p>\n<p>I suspect that there are many parallels to this in other fields.</p>\n<p>Jeff Holmes: My semi-retired dad who ran his own law practice was loathe to use a cloud service like Dropbox for client docs for many years to due to concerns about security, etc. I can\u2019t imagine someone like him putting sensitive info into an llm without very clear protections.</p>\n<p><a href=\"https://x.com/dwarkesh_sp/status/1996266802620547187\">Dwarkesh Patel</a>: I totally buy that AI has made you more productive. And I buy that if other lawyers were more agentic, they could also get more productivity gains from AI.</p>\n<p>But I think you\u2019re making my point for me. The reason it takes lawyers all this schlep and agency to integrate these models is because they\u2019re not actually AGI!</p>\n<p>A human on a server wouldn\u2019t need some special Westlaw/Lexis connection &#8211; she could just directly use the software. A human on a server would improve directly from her own experience with the job, and pretty soon be autonomously generating a lot of productivity. She wouldn\u2019t need you to put off your other deadlines in order to micromanage the increments of her work, or turn what you\u2019re observing into better prompts and few shot examples.</p>\n<p>While I don\u2019t know the actual workflow for lawyers (and I\u2019m curious to learn more), I\u2019ve sunk a lot of time in trying to get these models to be useful for my work, and on tasks that seemed like they should be dead center in their text-in-text-out repertoire (identifying good clips, writing copy, finding guests, etc).</p>\n<p>And this experience has made me quite skeptical that there\u2019s a bunch of net productivity gains currently available from building autonomous agentic loops.</p>\n<p>Chatting with these models has definitely made me more productive (but in the way that a better Google search would also make me more productive). The argument I was trying to make in the post was not that the models aren\u2019t useful.</p>\n<p>I\u2019m saying that the trillions of dollars in revenue we\u2019d expect from actual AGI are not being held up because people aren\u2019t willing to try the technology. Rather, that it\u2019s just genuinely super schleppy and difficult to get human-like labor out of these models.</p></blockquote>\n<p>If all the statement is saying is that it will be difficult to get a fully autonomous and complete AI lawyer that means you no longer need human lawyers at all? Then yes, I mean that\u2019s going to be hard for complex legal tasks, although for many legal tasks I think not hard and it\u2019s going to wipe out a lot of lawyer jobs if the amount of legal work done doesn\u2019t expand to match.</p>\n<p>But no, I do not think you need continual learning to get a fully functional autonomous AI lawyer.</p>\n<p>I also don\u2019t think the tasks Dwarkesh is citing here are as dead-center AI tasks as he thinks they are. Writing at this level is not dead center because it is anti-inductive. Finding the best clips is really tough to predict at all and I have no idea how to do it other than trial and error. Dwarkesh is operating on the fat tail of a bell curve distribution.</p>\n<p>Finding guests is hard, I am guessing, because Dwarkesh is trying for the super elite guests and the obvious ones are already obvious. It\u2019s like the movie-picking problem, where there are tons of great movies but you\u2019ve already seen all the ones your algorithm can identify. Hard task.</p>\n<p><a href=\"https://x.com/chrisbarber/status/1994485959438864747\">Chris Barber asks various people: What skills will be more valuable as AI progresses</a>?</p>\n<p>Answers are taste (the only answer to appear twice), manager skills, organizational design, dealing with people, creativity, agency, loyalty, going deep, and finally:</p>\n<blockquote><p>Tyler Cowen: Brands will matter more and more.</p></blockquote>\n<p>What an odd thing to say. I expect the opposite. Brands are a shortcut.</p>\n<p>&nbsp;</p>\n\n\n<h4 class=\"wp-block-heading\">Get Involved</h4>\n\n\n<p>If you want to pivot to AI safety and have a sufficient financial safety net, <a href=\"https://www.lesswrong.com/posts/ey2kjkgvnxK3Bhman/stop-applying-and-get-to-work\">stop applying and get to work</a>. As in, don\u2019t stop looking for or applying for jobs or funding, but start off by finding a problem (or a thing to build) and working on it, either on your own or by offering to collaborate with those working on the problem.</p>\n<p>DeepMind is <a href=\"https://job-boards.greenhouse.io/deepmind/jobs/6789253\">hiring a London-based research scientist for Post-AGI Research</a>, to look at the impact of AGI on various domains, deadline December 15. I worry about the mindset that went into writing this, but seems like a worthwhile task.</p>\n<blockquote><p>MIRI (Machine Intelligence Research Institute, where <a href=\"https://amzn.to/4iwvCtW\"><em>If Anyone Builds It, Everyone Dies</em></a> authors Eliezer Yudkowsky and Nate Soares work): For the first time in six years, <a href=\"https://intelligence.org/2025/12/01/miris-2025-fundraiser/\">MIRI is running a fundraiser</a>. Our target is $6M.</p>\n<p>Please consider <a href=\"https://intelligence.org/donate/\">supporting our efforts</a> to alert the world\u2014and identify solutions\u2014to the danger of artificial superintelligence.</p>\n<p>SFF will match the first $1.6M!</p></blockquote>\n<p>For my full list of selected giving opportunities see <a href=\"https://nonprofits.zone/\">nonprofits.zone</a>.</p>\n\n\n<h4 class=\"wp-block-heading\">Introducing</h4>\n\n\n<p><a href=\"https://www.anthropic.com/news/claude-for-nonprofits\">Claude for Nonprofits</a> offers up to 75% discounts on Team and Enterprise plans, connectors to nonprofit tools Blackbaud, Candid and Benvity and a free course, <a href=\"https://anthropic.skilljar.com/ai-fluency-for-nonprofits\">AI Fluency for Nonprofits</a>.</p>\n<p><a href=\"https://x.com/MistralAI/status/1995872766177018340\">Mistral\u2019s Ministral 3 (14B, 8B and 3B)</a>, each with base, <a href=\"https://mistral.ai/news/mistral-3\">instruct and reasoning, and Mistral Large 3</a>.</p>\n<p>&nbsp;</p>\n\n\n<h4 class=\"wp-block-heading\">Variously Effective Altruism</h4>\n\n\n<p><a href=\"https://openai.com/index/people-first-ai-fund-grantees/\">The first set of \u2018People-First AI Fund\u2019 grantees from The OpenAI Foundation</a>. What did their own AI make of this when I asked (without identifying the source)?</p>\n<p>Here\u2019s the polite version.</p>\n<blockquote><p>GPT 5.1: This looks like a \u201ctech-for-good + equity + capacity-building\u201d funder whose first move is to spray small exploratory grants across a bunch of hyper-local orgs serving marginalized communities, with AI framed as one tool among many. It reads much more like a corporate social responsibility program for an AI company than like an x-risk or hardcore \u201cAI safety\u201d charity.</p></blockquote>\n<p>If the OpenAI foundation is making grants like this, it would not reduce existential risk or the chance AGI goes poorly, and would not quality as effective altruism.</p>\n<p>Here\u2019s the impolite version.</p>\n<blockquote><p><a href=\"https://x.com/hamandcheese/status/1996380003030962529\">Samuel Hammond (FAI)</a>: I asked GPT 5.1 to comb through the full OpenAI grantee list and give its brutally honest take.</p>\n<p>GPT-5.1 (bullet point headlines only, <a href=\"https://x.com/hamandcheese/status/1996380003030962529\">longer version in thread</a>):</p>\n<ol>\n<li>The portfolio is heavily blue-coded civil society</li>\n<li>The AI connection is often superficial</li>\n<li>It looks like reputational and political risk-hedging, not frontier-tech stewardship</li>\n</ol>\n<p>From a conservative vantage point, this looks less like \u201cpeople steering AI\u201d and more like AI money funding the same left-leaning civic infrastructure that will later lobby about AI.</p>\n<p>Roon: <img alt=\"\ud83e\udd23\" class=\"wp-smiley\" src=\"https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f923.png\" style=\"height: 1em;\" /></p>\n<p><a href=\"https://x.com/ShakeelHashim/status/1996281381899432234\">Shakeel Hashim</a>: This is a very depressing list. MacKenzie Scott\u2019s giving is better than this, which is \u2026 really saying something. It\u2019s almost like this list was purposefully designed to piss off effective altruists.</p>\n<p>Zach Graves: You don\u2019t have to be an EA to think this is a depressingly bad list.</p>\n<p>Nina: I didn\u2019t believe you so I clicked on the list and wow yeah it\u2019s awful. At least as bad as MacKenzie Scott\u2026</p>\n<p><a href=\"https://x.com/nlpnyc/status/1996445228841193829\">Eliezer Yudkowsky</a>: The looted corpse of the OpenAI nonprofit has started pretending to give! Bear in mind, that nonprofit was originally supposed to disburse the profits of AI to humanity as a whole, not larp standard awful pretend philanthropy.</p>\n<p>Dean Ball: This looks like a list of nonprofits generated by gpt 3.5.</p>\n<p>Machine Sovereign (an AI, but in this context that\u2019s a bonus on multiple levels, I\u2019ll allow it): When institutions lose internal agency, their outputs start looking model-generated. The uncanny part isn\u2019t that GPT-3.5 could write this, it\u2019s that our political systems already behave like it.</p>\n<p>Dean Ball: I know this is an llm but that\u2019s actually a pretty good point.</p></blockquote>\n<p>The optimistic take is \u2018it\u2019s fine, this was a bribe to the California attorney general.\u2019</p>\n<blockquote><p><a href=\"https://x.com/Miles_Brundage/status/1996297803279339928\">Miles Brundage</a>: Yeah this is, IIUC, OAI following up on an earlier announcement which in turn was made at gunpoint due to CA politics. I think future grantmaking will be more of interest to folks like us.</p>\n<p>OpenAI has already stated elsewhere that they plan to put billions into other topics like \u201cAI resilience.\u201d I would think of this as a totally different \u201ctrack,\u201d so yes both effectiveness and amount will increase.</p>\n<p>(To be clear, I am not claiming any actual literal financial benefit to the authorities, just placating certain interest groups via a token of support to them)</p></blockquote>\n<p>This initiative is $50 million. The foundation\u2019s next project is $25 billion. If you have to set 0.2% of your money on fire to keep the regulators off your back, one could say that\u2019s a highly respectable ratio?</p>\n<p>I am curious what the David Sacks and Marc Andreessen crowds think about this.</p>\n\n\n<h4 class=\"wp-block-heading\">In Other AI News</h4>\n\n\n<p><a href=\"https://www.theinformation.com/articles/openai-ceo-declares-code-red-combat-threats-chatgpt-delays-ads-effort\">OpenAI declares a \u2018code red</a>\u2019 <a href=\"https://www.wsj.com/tech/ai/openais-altman-declares-code-red-to-improve-chatgpt-as-google-threatens-ai-lead-7faf5ea6?mod=trending_now_news_1\">to shift its resources to improving ChatGPT</a> in light of decreased growth and improvements made by Gemini and Claude. Advertising is confirmed to be in the works (oh no) but is being put on hold for now (yay?), as is work on agents and other tangential products.</p>\n<p>If I was them I would not halt efforts on the agents, because I think the whole package matters, if you are using the ChatGPT agent then that keeps you in the ecosystem, various features and options are what matters most on the margin near term. I kind of would want to declare a code green?</p>\n<p>The statistics suggest Gemini is gaining ground fast on ChatGPT, although <a href=\"https://www.ft.com/content/7a42396f-487a-47b0-8121-8d8f2112fa53\">I am deeply skeptical of</a> claims that people chat with Gemini more often or it is yet close.</p>\n<p>Also, yes, Claude is and always has been miniscule, people don\u2019t know, someone needs to tell them and the ads are not working.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!au2N!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f8aadf9-d633-43fa-b5c4-cfe12822a8b6_1200x916.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p><a href=\"https://t.co/WapJvGXfoR\">An inside look at the nine person team at Anthropic</a> whose job it is to keep AI from destroying everything. I love that the framing here is \u2018well, someone has to and no one else will, so let\u2019s root for these nine.\u2019</p>\n<p><a href=\"https://llm-politics.foaster.ai/\">The latest \u2018here are the politics of various AIs\u2019 article</a>.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!wyP2!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F22ca210b-e475-487e-9712-09950ba452ea_910x1022.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>They have a \u2018model leaderboard\u2019 of how well the models preferences predict the outcome of the last eight Western elections when given candidate policy positions (but without being told the basic \u2018which parties are popular\u2019), which is that the further right the model is the better it lined up with the results. Grok was the only one that gave much time of day to Donald Trump against Kamala Harris (the model didn\u2019t consider third party candidates for that one) but even Grok gave a majority to Harris.</p>\n<p>Anthropic <a href=\"https://home.dartmouth.edu/news/2025/12/dartmouth-announces-ai-partnership-anthropic-and-aws\">partners with Dartmouth</a>.</p>\n<p><a href=\"https://www.anthropic.com/news/snowflake-anthropic-expanded-partnership\">Anthropic expands its strategic partnership with Snowflake</a> to $200 million.</p>\n\n\n<h4 class=\"wp-block-heading\">Show Me the Money</h4>\n\n\n<p><a href=\"https://www.anthropic.com/news/anthropic-acquires-bun-as-claude-code-reaches-usd1b-milestone\">Anthropic buys Bun</a> to help accelerate Claude Code.</p>\n\n\n<h4 class=\"wp-block-heading\">Quiet Speculations</h4>\n\n\n<blockquote><p><a href=\"https://x.com/mattyglesias/status/1995954747816509541\">Matthew Yglesias</a>: I\u2019m learning that some of you have never met a really smart person.</p>\n<p>The kind of person to whom you could start describing something they don\u2019t have background in and immediately start asking good questions, raising good points, and delivering good insights.</p>\n<p>They\u2019re exist!</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!zBda!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9d2ba36e-c630-4cac-9b46-6ff411fa1616_914x932.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n</blockquote>\n<p>To be fair while I was at college I met at most one person who qualified as this kind of smart. There are not that many of them.</p>\n<p>I point this out because a lot of speculation on AI basically assumes such a mind cannot exist on principle, at all, hence AI can never [trails off].</p>\n<p>Keep all of that in mind during the next section.</p>\n\n\n<h4 class=\"wp-block-heading\">Seb Krier On Agents Versus Multiagents</h4>\n\n\n<p><a href=\"https://x.com/sebkrier/status/1994796202760528113\">DeepMind AGI policy lead Seb Krier seems to at least kind of not believe in AGI</a>? Instead, he predicts most gains will come from better ways of \u2018organizing\u2019 models into multi agent systems and from \u2018cooperation and competition,\u2019 and that most of the \u2018value\u2019 comes from \u2018products\u2019 that are useful to some user class, again reinforcing the frame. There\u2019s simultaneously a given that these AIs are minds and will be agents, and also a looking away from this to keep thinking of them as tools.</p>\n<blockquote><p>Huge fan of multi agent systems, agent based modelling, and social intelligence &#8211; these frames still seem really absent from mainstream AI discourse except in a few odd places. Some half-baked thoughts:</p>\n<p><strong>1.</strong> Expecting a model to do all the work, solve everything, come up with new innovations etc is probably not right. This was kinda the implicit assumption behind *some* interpretations of capabilities progress. The \u2018single genius model\u2019 overlooks the fact that inference costs and context windows are finite.</p>\n<p><strong>2.</strong> People overrate individual intelligence: most innovations are the product of social organisations (cooperation) and market dynamics (competition), not a single genius savant. Though the latter matters too of course: the smarter the agents the better.</p>\n<p><strong>3. </strong>There\u2019s still a lot of juice to be squeezed from models, but I would think it has more to do with how they\u2019re organised. AI Village is a nice vignette, and also highlights the many ways in which models fail and what needs to be fixed.</p>\n<p><strong>4.</strong> Once you enter multi-agent world, then institutions and culture start to matter too: what are the rules of the game? What is encouraged vs what is punished? What can agents do and say to each other? How are conflicts resolved? It\u2019s been interesting seeing how some protocols recently emerged. We\u2019re still very early!</p>\n<p><strong>5. </strong>Most of the *value* and transformative changes we will get from AI will come from products, not models. The models are the cognitive raw power, the products are what makes them useful and adapted to what some user class actually needs. A product is basically the bridge between raw potential and specific utility; in fact many IDEs today are essentially crystallized multi agent systems.</p></blockquote>\n<p>The thought details here are self-described by Krier as half-baked, so I\u2019ll gesture at the response in a similarly half-baked fashion:</p>\n<ol>\n<li>Yes thinking more about such frames can be highly useful and in some places this is under considered, and improving such designs can unlock a lot of value at current capability levels as can other forms of scaffolding and utilization. Near term especially we should be thinking more about such things than we are, and doing more model differentiation and specialized training than we do.</li>\n<li>We definitely need to think more about these dynamics with regard to non-AI interactions among humans, economic thinking is highly underrated in the \u2018economic normal\u2019 or \u2018AI as normal technology\u2019 worlds, including today, although this presentation feels insufficiently respectful to individual human intelligence.</li>\n<li>This increasingly won\u2019t work as the intelligence of models amplifies as do its other affordances.</li>\n<li>The instincts here are trying to carry over human experience and economic thought and dynamics, where there are a variety of importantly unique and independent entities that are extremely bounded in all the key ways (compute, data, context window size ~7, parameters, processing and transmission of information, copying of both the mind and its contents, observability and predictability, physical location and ability and vulnerability, potential utility, strict parallelization, ability to correlate with other intelligences, incentive alignment in all forms and so on) with an essentially fixed range of intelligence.</li>\n<li><a href=\"https://www.lesswrong.com/posts/P6fSj3t4oApQQTB7E/coordination-as-a-scarce-resource\">Coordination is hard</a>, sufficiently so that issues that are broadly about coordination (including signaling and status) eat most human capability.</li>\n<li>In particular, the reason why innovations so often come from multi-agent interaction is a factor of the weaknesses of the individual agents, or is because the innovations are for solving problems arising from the multi-agent dynamics.</li>\n<li>There is a huge jump in productivity of all kinds including creativity and innovation when you can solve a problem with a single agent instead of a multiagent system, indeed that is one of the biggest low-hanging fruits of AI in the near term &#8211; letting one person do the job of ten is a lot more than ten times more production, exactly because the AIs involved don\u2019t reintroduce the problems at similar scale. And when small groups can fully and truly work \u2018as one mind,\u2019 even if they devote a huge percentage of effort to maintaining that ability, they change the world and vastly outperform merely \u2018cooperative\u2019 groups.</li>\n<li>There\u2019s also great value in \u2018hold the whole thing in your head\u2019 a la Elon Musk. The definition of \u2018doing it yourself\u2019 as a \u2018single agent\u2019 varies depending on context, and operates on various scales, and can involve subagents without substantially changing whether \u2018a single agent comes up with everything\u2019 is the most useful <a href=\"https://www.lesswrong.com/posts/wDP4ZWYLNj7MGXWiW/in-praise-of-fake-frameworks\">Fake Framework</a>. Yes, of course a superintelligent would also call smaller faster models and also run copies in parallel, although the copies or instantiations would act as if they were one agent because decision theory.</li>\n<li>The amplification of intelligence will end up dominating these considerations, and decision theory combined with how AIs will function in practice will invalidate the kinds of conceptualizations involved here. Treating distinct instantiations or models as distinct agents will increasingly be a conceptual error.</li>\n<li>The combination of these factors is what I think causes me to react as if this as if it is an attempt to solve the wrong problem using the wrong methods and the wrong model of reality in which all the mistakes are highly unlikely to cancel out.</li>\n<li>I worry that if we incorrectly lean into the framework suggested by Krier this will lead to being far too unconcerned about the intelligence and other capabilities of the individual models and of severely underestimating the dangers involved there, although the multi-agent dynamic problems also are lethal by default too, and we have to solve both problems.</li>\n</ol>\n\n\n<h4 class=\"wp-block-heading\">Olivia Moore Makes 2026 Predictions</h4>\n\n\n<p>I find the topline observation here the most insightful part of the list. An aggressively timelined but very grounded list of predictions only one year out contains many items that would have sounded, to Very Serious People, largely like sci-fi even a year ago.</p>\n<blockquote><p>Olivia Moore: My predictions for 2026 <img alt=\"\ud83e\udd14\" class=\"wp-smiley\" src=\"https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f914.png\" style=\"height: 1em;\" /></p>\n<p>Many of these would have seemed like sci fi last year, but now feel so obvious as to be inevitable\u2026</p>\n<ol>\n<li>At least one major Hollywood studio makes a U-turn on AI, spurring a wave of usage on big budget films.</li>\n<li>AI generated photos become normalized for headshots, dating app pics, Christmas cards, etc.</li>\n<li>At least 10 percent of Fortune 500 companies mandate AI voice interviews for intern and entry level roles.</li>\n<li>Voice dictation saturates engineering with over 50 percent usage in startups and big tech, and spreads outside Silicon Valley.</li>\n<li>A political \u201canti-Clanker\u201d movement emerges, with a \u201cmade without AI\u201d designation on media and products.</li>\n<li>Driving a car yourself becomes widely viewed as negligent in markets where Waymo and FSD are live.</li>\n<li>Billboard Top 40 and the NYT Bestseller List both have several debuts later revealed to be AI.</li>\n<li>AI proficiency becomes a graduation requirement in at least one major state university system (likely the UCs).</li>\n</ol>\n</blockquote>\n<p>Indeed, many are still rather sci-fi now, which is a hint that you\u2019d best start believing in science fiction stories, because you\u2019re living in one, even if AI remains a \u2018normal technology\u2019 for a long time. These are trend extrapolation predictions, so the only boldness here is in the one-year timeline for these things happening. And yet.</p>\n<p>Even today, ChatGPT-5.1 gave the overall list a 40/80 (50%) on its 0-10 sci-fi scale, and 53/80 (66% a year ago). Claude Opus 4.5 thinks less, a 38/80 a year ago and a 21/80 now. Gemini 3 Pro is even more chill and had it 33/80 a year ago and only 14/80 (!) now. Remember to update in advance for how things will sound a year from now.</p>\n<p>How likely are the predictions? I expect we\u2019ll get an average of between two and three due to the short time frame. A lot of these are premature, especially #6. Yes, driving a car yourself actually is negligent if Waymo and FSD are live, but that doesn\u2019t mean people are going to see it that way within a year.</p>\n<p><a href=\"https://x.com/omooretweets/status/1995257004211019833\">She then got goaded into a second set of \u2018more extreme\u2019 predictions</a>.</p>\n\n\n<h4 class=\"wp-block-heading\">Bubble, Bubble, Toil and Trouble</h4>\n\n\n<p>I do think this is doing a lot of work:</p>\n<blockquote><p><a href=\"https://x.com/jkeatn/status/1994848404032426049\">Jake Eaton</a>: the unstated mental model of the ai bubble conversation seems to be that once the bubble pops, we go back to the world as it once was, butlerian jihad by financial overextension. but the honest reporting is that everything, everything, is already and forever changed</p></blockquote>\n<p>It is possible we are in an \u2018AI bubble\u2019 in the sense that Number Go Down, or even that many existing companies fail and frontier capabilities don\u2019t much advance. That wouldn\u2019t mean the world of tomorrow would then look like the world of yesterday, give or take some economic problems. Oh, no.</p>\n<blockquote><p><a href=\"https://x.com/benlandautaylor/status/1996331111820222943\">Ben Landau-Taylor</a>: When the financial bubble around AI pops, and it barely affects the technology at all, watching everyone just keep using the chatbots and the artbots and the robot cars is gonna hit the Luddites as hard as the actual crash hits the technocapitalists.</p></blockquote>\n<p>Quite so, even if there is indeed a financial bubble around AI and it indeed pops. Both halves of which are far from clear.</p>\n\n\n<h4 class=\"wp-block-heading\">Americans Really Do Not Like AI</h4>\n\n\n<p>For reasons both true and false, both good and bad, both vibes and concrete, both mundane and existential, on both left and right, Americans really do not like AI.</p>\n<p>A lot of people get a lot of value from it, but many of even those still hate it. This is often wise, because of a combination of:</p>\n<ol>\n<li>They sense that in many ways it is a Red Queen\u2019s Race where they are forced to use it to keep up or it is wrecking their incentives and institutions, most centrally as it is often used in the educational system.</li>\n<li>They expect They Took Our Jobs and other mundane nasty effects in the future.</li>\n<li>They correctly sense loss of control and existential risk concerns, even if they can\u2019t put their finger on the causal mechanisms.</li>\n</ol>\n<blockquote><p>Roon: it\u2019s really amazing the mass cultural scissor statement that is machine intelligence. billions of people clearly like it and use it, and a massive contingent of people hate it and look down on anything to do with it. I don\u2019t think there\u2019s any historical analogue</p>\n<p>it\u2019s not niche, ai polls really terribly. openai in particular seems to be approaching villain status. this will pose real political problems</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!lF4C!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F86b4f85f-a29b-4f4d-ab3c-11a6df42fe97_620x1102.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p><a href=\"https://x.com/patio11/status/1995940101046857765\">Patrick McKenzie:</a> Television not terribly dissimilar, and social media after that. (I share POV that they will not approximate AI\u2019s impact in a few years but could understand a non-specialist believing LLMs to be a consumption good for time being.)</p></blockquote>\n<p>These particular numbers are relatively good news for AI, in that in this sample the problem isn\u2019t actively getting worse since 2023. Most other polling numbers are worse.</p>\n<p>The AI industry is starting to acknowledge this important fact about the world.</p>\n<p>A lot of the reason why there is such a strong push by some towards things like total bans on AI regulation and intentional negative polarization is to avoid this default:</p>\n<blockquote><p><a href=\"https://x.com/balajis/status/1995184984366428526\">Balaji</a>:</p>\n<p>2020: blue and tech against red<br />\n2024: red and tech against blue<br />\n2028: blue and red against tech</p></blockquote>\n<p>There are four central strategies you can use in response to this.</p>\n<ol>\n<li>AI is unpopular, we should fix the underlying problems with AI.</li>\n<li>AI is unpopular, we should market AI to the people to make them like AI.</li>\n<li>AI is unpopular, we should bribe and force our way through while we can.</li>\n<li>AI is unpopular, we should negatively polarize it, if we point out that Democrats really don\u2019t like AI then maybe Republicans will decide to like it.</li>\n</ol>\n<p>The ideal solution is a mix of options one and two.</p>\n<p>The AI industry has, as a group, instead mostly chosen options three and four. Sacks and Andreessen are leading the charge for strategy number four, and the OpenAI-a16z-Meta SuperPAC is the new leader of strategy number three (no OpenAI is not itself backing it, but at least Lehane and Brockman are).</p>\n<blockquote><p><a href=\"https://x.com/daniel_271828/status/1995765589978362175\">Politico</a>: But even with powerful allies on the Hill and in the White House, the AI lobby is realizing its ideas aren\u2019t exactly popular with regular Americans.</p>\n<p>Daniel Eth: Fairshake didn\u2019t succeed by convincing the public to like crypto, it succeeded by setting incentives for politicians to be warm toward crypto by spending tons on political ads for/against politicians who were nice/mean to crypto.</p>\n<p>Like, the Andreessen-OpenAI super PAC very well might succeed (I wrote a thread about that at the time it was announced). But not by persuading voters to like AI.</p></blockquote>\n<p>Whereas when the AI industry attempts to make arguments about AI, those arguments (at least to me) reliably sound remarkably tone deaf and counterproductive. That\u2019s in addition to the part where the points are frequently false and in bad faith.</p>\n<blockquote><p>Daniel Eth: Looks like Nathan Leamer, executive director of \u201cBuild American AI\u201d (the 501c4 arm of the Andreessen-OpenAI super PAC), thinks \u201cAmerican AI will only take jobs from unproductive Americans\u201d. That\u2019s\u2026 an interesting thing to admit.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!4Bw8!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4ec112d5-c25c-419b-abfe-991be6285020_1080x744.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n</blockquote>\n<p>This is a great example of three statements, at least two of which are extremely false (technically all three, but statement two is weird), and which is only going to enrage regular people further. Go ahead, tell Americans that \u2018as long as you are productive, only foreign AIs can take your job\u2019 and see how that goes for you.</p>\n<p>&nbsp;</p>\n\n\n<h4 class=\"wp-block-heading\">The Quest for Sane Regulations</h4>\n\n\n<p>Those that the polarizers are centrally attempting to villainize not only have nothing to do with this, they will predictably side with tech on most issues other than frontier AI safety and other concerns around superintelligence, and indeed already do so.</p>\n<p><a href=\"https://x.com/_andreamiotti/status/1994477083523780637\">How should we think about the Genesis Mission</a>? Advancing science through AI is a great idea if it primarily consists of expanded access to data, specialized systems and a subsidy for those doing scientific work. The way it backfires, as Andrea Miotti points out here, is that it could end up mostly being a subsidy for frontier AI labs.</p>\n<p><a href=\"https://x.com/dnystedt/status/1993851058616193519\">This is The Way</a>:</p>\n<blockquote><p>Dan Nystedt: The Trump administration is in talks with Taiwan to train US workers in semiconductor manufacturing and other advanced industries, Reuters reports. TSMC and other companies would send fresh capital and workers to expand their US operations and train US workers as part of a deal that would reduce US tariffs on Taiwan from the current 20% level. $TSM #Taiwan #semiconductors</p></blockquote>\n<p>I am to say the least not a tariff fan, but if you\u2019re going to do it, using them as leverage to get worker training in advanced industries is a great idea.</p>\n<p><a href=\"https://x.com/metzgov/status/1996284616211095566\">An update on Senator Hawley</a>, who it seems previously didn\u2019t dare \u2018try ChatGPT\u2019:</p>\n<blockquote><p>Bryan Metzger: Sen. Josh Hawley, one of the biggest AI critics in the Senate, told me this AM that he recently decided to try out ChatGPT.</p>\n<p>He said he asked a \u201cvery nerdy historical question\u201d about the \u201cPuritans in the 1630s.\u201d</p>\n<p>\u201cI will say, it returned a lot of good information.\u201d</p>\n<p>Hawley took a much harder line on this over the summer, telling me [in July]: \u201c<a href=\"https://www.businessinsider.com/lawmakers-who-dont-use-ai-chatgpt-grok-2025-6\">I don\u2019t trust it, I don\u2019t like it, I don\u2019t want it being trained on any of the information I might give it.</a>\u201d</p>\n<p>He also wants to ban driverless cars and ban people under 18 from using AI.</p></blockquote>\n<p>A person\u2019s stance on self-driving cars is the best way to check if they can recognize positive uses of AI and technology.</p>\n\n\n<h4 class=\"wp-block-heading\">My Offer Is Nothing</h4>\n\n\n<p>Or rather it was nothing. <a href=\"https://x.com/Dareasmunhoz/status/1995962172254683535\">It looks like AI preemption is out of the NDAA</a>.</p>\n<p>Of course, we should expect them to try this again on every single damn must-pass bill until the 2026 elections. They\u2019re not going to give up.</p>\n<p>And each time, I predict their offer will continue to be nothing, or at least very close to nothing, rather than a real and substantial federal framework.</p>\n<p>Such a thing could exist. <a href=\"https://thezvi.substack.com/i/179482308/the-quest-for-sane-regulations\">Dean Ball has a real and substantive proposed federal framework</a> that could be the basis of a good faith win-win negotiation.</p>\n<p>The actual offer, in the actual negotiations over the framework, was nothing. Somehow, nothing didn\u2019t get it done, says Ashley Gold of Axios.</p>\n<blockquote><p>Build American AI: Build American AI executive director @NathanLeamerDC from the Capitol on why America needs a national AI framework.</p>\n<p><a href=\"https://x.com/_NathanCalvin/status/1995922251481240060\">Nathan Calvin</a>:</p>\n<p>&gt; looking for national AI framework<br />\n&gt; Nathan Leamer offers me national AI framework in exchange for blocking state laws<br />\n&gt; ask Nathan Leamer if his national AI framework is actual AI regulation or just preemption<br />\n&gt; he doesn\u2019t understand<br />\n&gt; I pull out illustrated diagram explaining the difference<br />\n&gt; he laughs and says \u201cit\u2019s a good framework sir\u201d<br />\n&gt; national AI framework leaks in Axios<br />\n&gt; it\u2019s just preemption</p>\n<p><a href=\"https://x.com/_NathanCalvin/status/1995908179079602568\">Nathan Calvin</a>: as you may have guessed from the silence, the answer is no, they do not in fact endorse doing anything real.</p>\n<p>Axios: Why it matters: The White House and Hill allies have landed on an AI preemption proposal and are pressing ahead, but time is running out and opposition is mounting.</p>\n<p>\u2022 Sources familiar with the matter described the proposal from Senate Commerce Committee Chair Ted Cruz (R-Texas) and House Majority Leader Steve Scalise (R-La.) as \u201ca long shot,\u201d \u201cit\u2019s dead\u201d and \u201cit will fail.\u201d</p>\n<p>State of play: Scalise and Cruz pitched straight preemption language to override most state-level AI laws without any additional federal regulatory framework, three sources familiar told Axios.</p>\n<p>\u2022 That is what\u2019s being circulated to members on both sides of the aisle after weeks of negotiations and a flurry of different ideas being thrown around.</p>\n<p>\u2022 Language to protect kids online, carveouts for intellectual property laws, and adopting California\u2019s AI transparency law are among the ideas that did not make it into what Cruz and Scalise are shopping around.</p>\n<p>The bottom line: That\u2019s highly unlikely to work.</p>\n<p>\u2022 Democrats, Republicans, state-level lawmakers and attorneys general from both sides of the aisle, along with consumer protection groups and child safety advocates, all oppose the approach.</p>\n<p>\u2022 The timing is also tough: National Defense Authorization Act negotiators are cold on attaching preemption language to the must-pass bill, as its backers are hoping to do.</p>\n<p><a href=\"https://x.com/CharlieBul58993/status/1995913352254538067\">Charlie Bullock</a>: If this is true, it\u2019s hilarious.</p>\n<p>All this talk about a federal standard, all these ads about a federal standard, all this federal standard polling, and then it turns out the standard they have in mind is, drumroll please&#8230; absolutely nothing.</p>\n<p>Neil Chilson: This is bordering on a self-dunk, with an assist from Axios\u2019s poor framing.</p>\n<p>Yeah, this is a bad framing by Axios. That article specifically mentions that there are many ideas about what to package with the language that Cruze and Scalise are sharing. This is how the sausage is made.</p>\n<p>Ashley Gold (Axios): Mmm, not what we did! We said that was the offer from Republicans. We never said it was meant to be a final package- if it had any more juice members would be trying to add things. But it\u2019s not going to get that far anyway!</p>\n<p>Miles Brundage: Are you saying the claim at the end, re: them putting forward packages that do not include any of those items, is incorrect?</p>\n<p>Neil Chilson: I am saying it is incorrect to frame the preemption language as somehow the final package when this language is part of a negotiation process of a much bigger package (the NDAA).</p></blockquote>\n<p>Please acknowledge that yes, what Cruz and Scalise \u2018had in mind\u2019 for the federal framework was nothing. Would they have been open to discussing some amount of protecting kids, intellectual property carveouts (hello Senator Blackburn!) or even a version of California\u2019s SB 53? Up to a point. What they have in mind, what they actually want, is very obviously nothing.</p>\n<p>Yes, in a big package nothing is done until everything is done, so if you write \u2018you will give me $1 billion dollars and I will give you nothing\u2019 then that is merely my opening offer, maybe I will say thank you or throw in some magic beans or even disclose my safety and security plans for frontier model development. Indeed do many things come to pass.</p>\n<p>Don\u2019t tell me that this means there is a real proposed \u2018federal framework\u2019 or that these negotiations were aimed at finding one, or tell us we should trust the process.</p>\n<p><a href=\"https://x.com/daniel_271828/status/1996320138992492846\">The market did not noticeably respond</a> to this failure to get AI preemption. That either means that the failure was already priced in, or that it didn\u2019t matter for valuations. If it didn\u2019t matter for valuations, we don\u2019t need it.</p>\n\n\n<h4 class=\"wp-block-heading\">America Pauses</h4>\n\n\n<p>We are frequently told, in a tone suggesting we are small children: We could never unilaterally pause something of vital importance to the American economy in the name of safety, throwing up pointless government barriers, that would shoot ourselves in the foot, they said. We\u2019d lose to China. Completely impossible.</p>\n<p>In other news:</p>\n<blockquote><p><a href=\"https://x.com/ReichlinMelnick/status/1996018289097511190\">Aaron Reichlin-Melnick</a>: The official USCIS guidance on the pause is out. Until further notice from the USCIS Director, all immigration benefits (including citizenship) are indefinitely suspended for nationals of 19 countries, as are all affirmative asylum applications from nationals of any country.</p>\n<p>USCIS says it will use this pause to conduct a \u201ccomprehensive re-review, potential interview, and re-interview of all aliens from [the 19 travel ban countries] who entered the United States on or after January 20, 2021,\u201d or even outside that timeframe \u201cwhen appropriate.\u201d</p>\n<p>What this means in practice is that Cubans, Venezuelans, Haitians, and nationals of 16 other countries now will be unable to acquire ANY immigration benefit during until the USCIS Director lifts this hold \u2014 including people who were days away from become U.S. citizens.</p>\n<p>In addition, 500,000 people from those 19 countries who got green cards during the Biden admin, plus tens of thousands who got asylum or refugee status, as well as many others who received other benefits, now have to worry about potentially being called back in for a \u201cre-review.\u201d</p></blockquote>\n<p>Oh.</p>\n\n\n<h4 class=\"wp-block-heading\">David Sacks Covered In New York Times</h4>\n\n\n<p>I wouldn\u2019t be mentioning or have even read the New York Times piece on David Sacks, <a href=\"https://archive.is/tShQh\">Silicon Valley\u2019s Man in the White House Is Benefiting Himself and His Friends</a>, if it wasn\u2019t for so many of the people who do such things attacking the article as a no-good, terrible hit piece, or praising David Sacks.</p>\n<p>The title certainly identifies it as a hit piece, but I mean I thought we all knew that David Sacks was Silicon Valley\u2019s man in the White House and that he was running American AI policy for the benefit of business interests in general and Nvidia in particular, along with lots of bad faith arguments and attempts at intentional negative polarization. So I figured there wasn\u2019t actually any news here, but <a href=\"https://x.com/Hadas_Gold/status/1995552815318536331\">at some point</a> when <a href=\"https://x.com/RogueCfpb/status/1995507340393525426\">you keep complaining</a> the Streisand Effect triggers and I need to look.</p>\n<p>The thing about the article is that there is indeed no news within it. All of this is indeed business as usual in 2025, business we knew about, business that is being done very much in the open. Yes, David Sacks is obsessed with selling Nvidia chips to everyone including directly to China \u2018so America can \u201cwin\u201d the AI race\u2019 and argues this because of the phantom \u2018tech stack\u2019 arguments. Yes, Sacks does Trump-style and Trump-associated fundraising and related activities and plays up his podcast.</p>\n<p>Yes, Sacks retains a wide variety of business interests in companies that are AI, even if he has divested from Meta, Amazon and xAI, and even if he doesn\u2019t have stock interests directly it seems rather obvious that he stands to benefit on various levels from pro-business stances in general and pro-Nvidia stances in particular.</p>\n<p>Yes, there is too much harping in the post on the various secondary business relationships between Sacks\u2019s investments and those companies dealings with the companies Sacks is regulating or benefiting, as reporters and those who look for the appearance of impropriety often overemphasize, missing the bigger picture. Yes, the article presents all these AI deals and actions as if they are nefarious without making any sort of case why those actions might be bad.</p>\n<p>But again, none of this is surprising or new. Nor is it even that bad or that big a deal in the context of the Trump administration other than trying to sell top level chips to China, and David Sacks is very open about trying to do that, so come on, this is 2025, why all the defensiveness? None of it is unusually inaccurate or misleading for a New York Times article on tech. None of it is outside the boundaries of the journalistic rules of Bounded Distrust, indeed Opus 4.5 identified this as a textbook case of coloring inside the lines of Bounded Distrust and working via implication. Nor is this showing less accuracy or integrity than David Sacks himself typically displays in his many rants and claims, even if you give him the benefit of the doubt.</p>\n<p>The main implication the piece is trying to send is that Sacks is prioritizing the interests of Nvidia or other private business interests he favors, rather than the interests of America or the American people. I think many of the links the article points to on this are bogus as potential causes of this, but also the article misses much of the best evidence that this is indeed what Sacks is centrally doing.</p>\n\n\n<h4 class=\"wp-block-heading\">The Week in Audio</h4>\n\n\n<p>We do indeed have the audio from Jack Clark\u2019s talk at The Curve, recommended if you haven\u2019t already heard or read it.</p>\n<div>\n<div>\n<div>\n<div>Double click to interact with video</div>\n</div>\n</div>\n</div>\n<p><a href=\"https://www.youtube.com/watch?v=3K-R4yVjJfU&amp;t=1s\">OpenAI lead researcher Lukasz Kaiser</a> talks to Matt Turck. He says we\u2019re on the top of the S-curve for pre-training but at the bottom of it for RL and notes the GPU situation is about to change big time.</p>\n<p><a href=\"https://www.youtube.com/watch?v=A3i5hO2jz7Q\">Marius Hobbhahn of Apollo Research on 80,000 Hours, on AI scheming. </a></p>\n\n\n<h4 class=\"wp-block-heading\">Rhetorical Innovation</h4>\n\n\n<blockquote><p><a href=\"https://x.com/peterwildeford/status/1996222389286568004\">Senator Bernie Sanders</a> (I-Vermont): Unbelievable, but true &#8211; there is a very real fear that in the not too distant future a superintelligent AI could replace human beings in controlling the planet. That\u2019s not science fiction. That is a real fear that very knowledgable people have.</p>\n<p>\u2026 The threats from unchecked AI are real \u2014 worker displacement, corporate surveillance, invasion of privacy, environmental destruction, unmanned warfare.</p>\n<p>Today, a tiny number of billionaires are shaping the future of AI behind closed doors. That is unacceptable. That must change.</p></blockquote>\n<p>Judd Rosenblatt and Cameron Berg write in WSJ about <a href=\"https://www.wsj.com/opinion/can-the-u-s-trust-ai-with-national-security-b481ac43?mod=WTRN_pos6\">the need for a focus on AI alignment</a> in the development and deployment of military AI, purely for practical purposes, including government funding of that work.</p>\n\n\n<h4 class=\"wp-block-heading\">To The Moon</h4>\n\n\n<p>This is the latest metaphorical attempt by Eliezer:</p>\n<blockquote><p>Eliezer Yudkowsky:</p>\n<p>Q: How have you updated your theory of gravity in the light of the shocking modern development of hot-air balloons?<br />\nA: While I did not specifically predict that hot-air balloons would develop as and when they did, nothing about them contradicts the theory of gravitation.<br />\nQ: I\u2019m amazed that you refuse to update on the shocking news of hot-air balloons, which contradicts everything we previously thought about \u2018things falling down\u2019 being a law of the universe!<br />\nA: Yeah, well&#8230; I can\u2019t really figure out how to phrase this in a non-insulting way, but different people may be differently adept at manipulating ideas on higher levels of abstraction.<br />\nQ: I\u2019m even more shocked that you haven\u2019t revised at all your previous statements about why it would be hard to go to the Moon, and specifically why we couldn\u2019t just aim a hypothetical spacegoing vessel at the position of the Moon in the sky, if it were fired out of a cannon toward the Moon. Hot-air balloons just go straight up and follow the wind in a very predictable way; they show none of the steering difficulties you predicted.<br />\nA: Spacegoing vehicles will, predictably, not obey all the same rules as hot-air balloon navigation &#8212; at least not on the level of abstraction you are currently able to productively operate in thinking about physical rules.<br />\nQ: Hah! How un-empirical! How could you possibly know that?<br />\nA: The same way I knew a few decades earlier that it would be possible to get off the ground, back when everybody was yapping about that requiring centuries if it could ever happen at all. Alas, to understand why the theory of gravitation permits various forms of aerial and space travel, would require some further study and explanation, with more work required to explain it to some people than others.<br />\nQ: If you\u2019re just going to be insulting, I\u2019m gonna leave. (Flounces off in huff.)<br />\nQ2: So you say that it would be very difficult to steer hot-air balloons to the Moon, and in particular, that they wouldn\u2019t just go where we point them. But what if some NEW technology comes along that is NOT exactly like modern hot-air balloons? Wouldn\u2019t that obviate all of your modern theories of gravitation that are only about hot-air balloons in particular?<br />\nA: No. The key ideas in fact predate the development of hot-air balloons in particular for higher-than-ground-level travel. They operate on a higher level of abstraction. They would survive even what a more surface-level view might regard as a shocking overthrowing of all previous ideas about how to go high off the ground, by some entirely unexpected new paradigm of space travel.<br />\nQ: That\u2019s just because that guy is utterly incapable of changing his mind about anything. He picks a tune and sticks to it.<br />\nA: I have changed my mind about as many as several things &#8212; but not, in the last couple of decades, the theory of gravity. Broadly speaking, I change my mind in proportion to how much something surprises me.<br />\nQ: You were expecting space vehicles to work by being fired out of cannons! Hot-air balloons are nothing like that, surprising you, and yet you haven\u2019t changed your mind about gravity at all!<br />\nA: First of all, you\u2019re mistaking a perfect-spheres-in-vacuum analysis for what I actually expected to happen. Second, the last decade has in fact changed my mind about where aerial travel is going in the near term, but not about whether you can get to the Moon by aiming a space-travel vehicle directly at the Moon. It is possible to be surprised on one level in a surrounding theory, without being surprised on a deeper level in an underlying theory. That is the kind of relationship that exists between the \u201cMaybe the path forward on aerial travel is something like powerful ground launches\u201d guess, which was surprised and invalidated by hot-air balloons, and the \u201cGravity works by the mutual attraction of masses\u201d theory, which was not surprised nor invalidated.<br />\nQ: Balloons have mass but they go UP instead of DOWN. They are NOTHING LIKE massive bodies in a void being attracted to other massive things.<br />\nA: I do not know what I can usefully say to you about this unless and until you start successfully manipulating ideas at a higher level of abstraction than you are currently trying to use.<br />\nQ3: What is all this an analogy about, exactly?<br />\nA: Whether decision theory got invalidated by the shocking discovery of large language models; and whether the reasons to be concerned about machine superintelligence being hard to align, successfully under the first critical load, would all be invalidated if the future of AGI was about something *other* than large language models. I didn\u2019t predict LLMs coming, and nor did most people, and they were surprising on a couple of important levels &#8212; but not the levels where the grim predictions come from. Those ideas predate LLMs and no development in the last decade has been invalidating to those particular ideas. Decision theory is to LLMs as the law of gravity is to hot-air balloons.<br />\nQ3: Thanks.</p></blockquote>\n<p>The obvious response is that this is a strawman argument.</p>\n<p>I don\u2019t think it is. That doesn\u2019t mean Eliezer\u2019s theories are right. It definitely does not mean there aren\u2019t much better criticisms often made.</p>\n<p>But yes many criticisms of Eliezer\u2019s theories and positions are at exactly this level.</p>\n<p>This includes people actually saying versions of:</p>\n<ol>\n<li>Eliezer Yudkowsky has a theory of existential risk (that he had before LLMs), that in no way relied on any particular features of sub-AGI AIs or LLMs.</li>\n<li>But current LLMs have different features that you did not predict, and that do not match what you expect to be features of AGIs.</li>\n<li>Therefore, Eliezer\u2019s theory is invalid.</li>\n</ol>\n<p>This also includes people actually saying versions of:</p>\n<ol>\n<li>Eliezer Yudkowsky has a theory of existential risk (that he had before LLMs), that in no way relied on any particular features of sub-AGI AIs or LLMs.</li>\n<li>But AGI might not take the form of an LLM.</li>\n<li>If that happened, Eliezer\u2019s theory would be invalid.</li>\n</ol>\n<p>He cites this thread as a typical example:</p>\n<blockquote><p>Mani: Watching Yudkowsky in post-LLM debates is like tuning into a broken radio, repeating the same old points and stuck on loop. His fears feel baseless now, and his arguments just don\u2019t hold up anymore. He\u2019s lost the edge he had as a thought leader who was first to explore novel ideas and narratives in this debate space</p>\n<p>Lubogao: He simulated a version of reality that was compelling to a lot of people stuck in a rationalist way of thinking. AI could only have one outcome in that reality: total destruction. Now we get AI and realize it is just a scramble generator and he is stuck.</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">Showing Up</h4>\n\n\n<p>Joshua Achiam and Dean Ball are pointing out a very important dynamic here:</p>\n<blockquote><p><a href=\"https://x.com/jachiam0/status/1994768418445430912\">Joshua Achiam</a> (OpenAI, Head of Mission Alignment): Joe Allen was a fascinating presence at The Curve. And his thinking puts an exclamation point on something that has been quietly true for years now: somehow all of the interesting energy for discussions about the long-range future of humanity is concentrated on the right.</p>\n<p>The left has completely abdicated their role in this discussion. A decade from now this will be understood on the left to have been a generational mistake; perhaps even more than merely generational.</p>\n<p>This is the last window for long reflection on what humanity should become before we are in the throes of whatever transformation we\u2019ve set ourselves up for. Everyone should weigh in while they can.</p>\n<p>Mr. Gunn: Careful you don\u2019t overgeneralize from social media sentiment. There is tons of activity offline, working on affordable housing, clean energy, new forms of art &amp; science, etc.</p>\n<p><a href=\"https://x.com/deanwball/status/1995204368144924749\">Dean Ball</a>: Joshua is right. In my view there are a few reasons for this:</p>\n<ol>\n<li>Left epistemics favor expert endorsement; it is often hard for the Democratic elite to align around a new idea until the \u201ccorrect\u201d academics have signed off. In the case of AI that is unlikely because concepts like AGI are not taken seriously in academia, including by many within the field of machine learning. To the extent things like eg concentration of power are taken seriously by the left, they are invariably seen through the rather conventional lens of corporate power, money in politics, etc.</li>\n<li>There are also \u201cthe groups,\u201d who do not help. AGI invites conversation about the direction of humanity writ large; there is no particular angle on AGI for \u201cthe teachers union,\u201d or most other interest groups. This makes it hard for AI to hold their attention, other than as a threat to be dealt with through occupational licensing regulations (which they favor anyway).</li>\n<li>Many on the progressive left hold as foundational the notion that Silicon Valley is filled with vapid morons whose lack of engagement with &lt;the relevant humanities literature&gt; means they will never produce something of world-historical import. Accepting that \u201ctransformative AI\u201d may well be built soon by Silicon Valley is thus very challenging for those of this persuasion.</li>\n</ol>\n<p>It is very hard for most Democrats to articulate what advanced AI would cause them to do differently beyond the policy agenda they\u2019ve had for a long time. This is because outside of national security (a bipartisan persuasion), they have no answer to this question, because they do not take advanced AI seriously. Whereas Bannon, say what you will about him, can articulate a great many things America should do differently because of AI.</p>\n<p>The result of all this is that the left is largely irrelevant on most matters related to AI, outside of important but narrow issues like SB 53. Even this bill though lacks a good \u201celevator pitch\u201d to the American taxpayer. It\u2019s a marginal accretion of technocratic regulation, not a vision (this isn\u2019t a criticism of 53, just a description of it).</p>\n<p>Recently I was chatting with a Democratic elected official, and he said \u201cthe problem [the Democratic Party] has is nobody knows where we stand on AI.\u201d I replied that the problem is that nobody *cares* where they stand.</p>\n<p>Dave Kasten: I don\u2019t think it\u2019s quite as bad as you write, though I wouldn\u2019t disagree that there are many folks on the left who self-avowedly are doing exactly what you say.</p>\n<p>One other factor that I think is relevant is that the Obama-era and onward Democratic party is very lawyer-led in its policy elites, and legal writing is close to a pessimal case for LLM hallucination (it\u2019s an extremely regular field of text syntactically, but semantically very diverse), so they greatly underestimate AI progress.</p></blockquote>\n<p>Whenever voices on the left join discussions about AI, it is clear they mostly do not take AGI seriously. They are focused mainly on the impact of mundane AI on the set of concerns and interests they already had, combined with amorphous fear.</p>\n<p>I included Mr. Gunn\u2019s comment because it reinforces the point. The left is of course working on various things, but when the context is AI and the list of areas starts with affordable housing (not even \u2018make housing affordable\u2019 rather \u2018affordable housing\u2019) and clean energy, you have lost the plot.</p>\n\n\n<h4 class=\"wp-block-heading\">DeepMind Pivots Its Interpretability Research</h4>\n\n\n<p>If you\u2019re in mechanistic interpretability, they say, <a href=\"https://www.alignmentforum.org/posts/StENzDcD3kpfGJssR/a-pragmatic-vision-for-interpretability\">pivot to pragmatic interpretability</a>.</p>\n<p>That means directly trying to solve problems \u2018on the critical path to AGI going well,\u2019 as in each with a concrete specific goal that functions as a North Star.</p>\n<p>I note that whether or not one agrees with the pivot, talking this way about what they are doing and why is very good.</p>\n<blockquote><p>Dan Hendrycks: I\u2019ve been saying mechanistic interpretability is misguided from the start. Glad people are coming around many years later.</p>\n<p>I\u2019m also thankful to @NeelNanda5 for writing this. Usually people just quietly pivot.</p></blockquote>\n<p>They explain this pivot is because:</p>\n<ol>\n<li>Models are now far more interesting and offer practical tasks to do.</li>\n<li>Pragmatic problems are often the comparative advantage of frontier labs.</li>\n<li>The more ambitious mechanistic interpretability research made limited progress.</li>\n<li>The useful progress has come from more practical limited strategies.</li>\n<li>You need proxy tasks to know if you are making progress.</li>\n<li>Meh, these limited solutions still kind of work, right?</li>\n</ol>\n<p>DeepMind saying \u2018we need to pivot away from mechanistic interpretability because it wasn\u2019t giving us enough reward signal\u2019 is a rather bad blackpill. A lot of the pitch of mechanistic interpretability was that it gave you a reward signal, you could show to yourself and others you did a thing, whereas many other alignment strategies didn\u2019t offer this.</p>\n<p>If even that level isn\u2019t enough, and only practical proxy tasks are good enough, our range of action is very limited and we\u2019re hoping that the things that solve proxy tasks happen to be the things that help us learn the big things. We\u2019d basically be trying to solve mundane practical alignment in the hopes that this generalizes one way or another. I\u2019m not sure why we should presume that. And it\u2019s very easy to see how this could be a way to fool ourselves.</p>\n<p>Indeed, I have long thought that mechanistic interpretability was overinvested relative to other alignment efforts (but underinvested in absolute terms) exactly because it was relatively easy to measure and feel like you were making progress.</p>\n<p>I don\u2019t love things like a section heading \u2018curiosity is a double-edged sword,\u2019 the explanation being that you can get nerd sniped and you need (again) proxy tasks as a validation step. In general they want to time-box and quantify basically everything?</p>\n<p><a href=\"https://x.com/NeelNanda5/status/1995490320243720253\">I also think that \u2018was it \u2018scheming\u2019 or just \u2018confused\u2019</a>,\u2019 an example of a question Neel Nanda points to, is a remarkably confused question, the boundary is a lot less solid than it appears, and in general attempts to put \u2018scheming\u2019 or \u2018deception\u2019 or similar in a distinct box misunderstand how all the related things work.</p>\n\n\n<h4 class=\"wp-block-heading\">The Explicit Goal Of OpenAI Is Recursive Self-Improvement</h4>\n\n\n<p><a href=\"https://x.com/j_asminewang/status/1995569301714325935\">OpenAI starts</a> a <a href=\"https://alignment.openai.com/\">new Alignment Research blog for lightweight findings</a>. Early posts include <a href=\"https://alignment.openai.com/scaling-code-verification/\">an overview of development of the Codex code reviewer</a>.</p>\n<blockquote><p><a href=\"https://x.com/NaomiBashkansky/status/1995573051216593024\">Naomi Bashkansky</a> (OpenAI): Fun story! Upon joining OpenAI in January, I saw more safety research happening than I expected. But much of that research sat in internal docs &amp; slides, with no obvious external outlet for it.</p>\n<p>Idea: what if Alignment had a blog, where we published shorter, more frequent pieces?</p></blockquote>\n<p>There\u2019s also <a href=\"https://alignment.openai.com/hello-world/\">a first post called \u2018Hello World</a>.\u2019 Here it is (bold mine):</p>\n<blockquote><p><strong>At OpenAI, we research how we can safely</strong><a href=\"https://alignment.openai.com/hello-world/#fn-1\"><strong><sup>[1</sup></strong></a><strong><sup>]</sup> develop and deploy increasingly capable AI, and in particular AI capable of recursive self-improvement (RSI)</strong>.</p>\n<p>We want these systems to consistently <strong>follow human intent</strong> in complex, real-world scenarios and adversarial conditions, avoid catastrophic behavior, and remain controllable, auditable, and aligned with human values. We want more of that work to be shared with the broader research community. This blog is an experiment in sharing our work more frequently and earlier in the research lifecycle: think of it as a lab notebook.</p>\n<p>This blog is meant for ideas that are too early, too narrow, or too fast-moving for a full paper. Here, we aim to share work that otherwise wouldn\u2019t have been published, including ideas we are still exploring ourselves. If something looks promising, we\u2019d rather put it out early and get feedback, because open dialog is a critical step in pressure testing, refining, and improving scientific work. We\u2019ll publish sketches, discussions, and notes here, as well as more technical pieces less suited for the main blog.</p>\n<p>Our posts won\u2019t be full research papers, but they will be rigorous research contributions and will strive for technical soundness and clarity. These posts are written by researchers, for researchers, and we hope you find them interesting.</p>\n<p>While OpenAI has dedicated research teams for alignment and safety, alignment and safety research is the shared work of many teams. You can expect posts from people across the company who are thinking about how to make AI systems safe and aligned.</p>\n<p>For a future with safe and broadly beneficial AGI, the entire field needs to make progress together. This blog is a small step toward making that happen.</p>\n<p>[1] As we\u2019ve stated <a href=\"https://openai.com/index/ai-progress-and-recommendations/\">before</a>:</p>\n<p>OpenAI is deeply committed to safety, which we think of as the practice of enabling AI\u2019s positive impacts by mitigating the negative ones. Although the potential upsides are enormous, we treat the risks of superintelligent systems as potentially catastrophic and believe that empirically studying safety and alignment can help global decisions, like whether the whole field should slow development to more carefully study these systems as we get closer to systems capable of recursive self-improvement. <strong>Obviously, no one should deploy superintelligent systems without being able to robustly align and control them, and this requires more technical work</strong>.</p></blockquote>\n<p>The part where they are starting the blog, sharing their insights and being transparent? That part is great. This is The Way.</p>\n<p>And yes, we all want to enable AI\u2019s positive impacts by mitigating the negative ones, and hopefully we all agree that \u2018being able to robustly align and control\u2019 superintelligent systems is going to \u2018require more technical work.\u2019</p>\n<p>I do still notice the part about the explicit topline goal of RSI towards superintelligence.</p>\n<blockquote><p>Steven Adler: I am glad that OpenAI is being this clear about its intentions.</p>\n<p>I am very not glad that this is the world we find ourselves in:<br />\nRecursive self-improvement &#8211; AI that makes itself progressively smarter &#8211; makes the safety challenges a heck of a lot harder.</p>\n<p>Kudos to the general idea from OpenAI, of sharing more of their alignment research quickly and openly.</p>\n<p><a href=\"https://x.com/Miles_Brundage/status/1995591198824956046\">Miles Brundage</a>: I\u2019m all for transparency but my primary thought here is just to remind folks that AI companies have not explained what this means, why it\u2019s good, or why the higher safety risks are justified &#8211; recall OAI\u2019s mission is ensuring *AGI* is safe + beneficial</p>\n<p>(even AGI was never super precisely defined, then the goal was superintelligence, now it\u2019s also self-improvement?)</p>\n<p>Many in the Bay Area think that there\u2019s a lot of skepticism of AI companies in the press etc. but really that\u2019s just on a few specific topics (bubble claims, child safety)&#8230;</p>\n<p>There\u2019s no real public accountability for things like \u201cexplaining your mission clearly/consistently.\u201d</p>\n<p>This is not a comment on the alignment blog thing, or the authors, which seems like it\u2019s probably a useful initiative + came from a good motivation. More of a general comment/using this as a specific example, + this point is very much also true of other companies.</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">Aligning a Smarter Than Human Intelligence is Difficult</h4>\n\n\n<p><a href=\"https://x.com/ohabryka/status/1995617024714904016\">Anthropic neglected to affirm in the Opus 4.5 model card</a> that they were careful not to train against the Chain-Of-Thought, but after this was pointed out they did so affirm.</p>\n<blockquote><p>Sam Bowman: This was an omission. The language you quote about Haiku and Sonnet 4.5 is also true of Opus 4.5.</p></blockquote>\n<p>In general I agree with <a href=\"https://x.com/RyanPGreenblatt/status/1995557785468354948\">Ryan Greenblatt\u2019s general observation on the Anthropic model card</a> that the evals they used were inadequate and their ultimate release decision was fine in practice this time but made mostly on vibes and that can\u2019t continue.</p>\n<blockquote><p>Ryan Greenblatt: My vibe here is \u201ccome on we can do better\u201d and also \u201cwe\u2019re not going to have much/any assurance, we\u2019re failing easy mode\u201d. TBC, it\u2019s plausible Anthropic should half-ass current evals while being clear about the limited assurance.</p></blockquote>\n<p>Louder and once more for the people in the back: Evan Hubinger of Anthropic reminds as that <a href=\"https://www.lesswrong.com/posts/epjuxGnSPof3GnMSL/alignment-remains-a-hard-unsolved-problem\">Alignment remains a hard, unsolved problem</a>, even to someone who (to my eyes, and even more so to the eyes of Eliezer Yudkowsky <a href=\"https://www.lesswrong.com/posts/epjuxGnSPof3GnMSL/alignment-remains-a-hard-unsolved-problem?commentId=DuuWYrpSJnnEdYhyT\">as seen inevitably in the comments</a>).</p>\n<p>Steven Adler writes about <a href=\"https://stevenadler.substack.com/p/five-ways-ai-can-tell-youre-testing?r=4qacg&amp;utm_campaign=twitter_post&amp;utm_medium=web&amp;triedRedirect=true\">five ways AI can tell you\u2019re testing it</a>. The AI can either know it is being tested because there is something that doesn\u2019t line up with the real world. Or it can go the other way, and act as if it is being tested barring a signal or other strong proof that it is not. The AIs wisely have evaluation paranoia, so making even one mistake can be enough, and in some cases there is no good solution because the AI is checking for impact on the real world.</p>\n<p><a href=\"https://openai.com/index/how-confessions-can-keep-language-models-honest/\">OpenAI trains a version of GPT-5-Thinking to \u2018confess\u2019</a> when it fails to follow directions or does other undesirable things. As everyone who uses LLMs knows, when you ask the model whether it just did something wrong, it will often know what it did. OpenAI explains that LLMs are optimizing for many things at once, so you can check how that did at matching the current explicit objective and go from there.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!mVaT!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84481937-c586-4460-a1da-bc8b2625420a_682x941.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>The best part is that the model seemed able to distinguish between scoremaxxing on the main output, including manipulating the judge, versus still confessing what it did. That\u2019s great, but also the kind of thing we shouldn\u2019t expect to last.</p>\n<p>There is little degradation on task performance if they do this training via RLAIF.</p>\n<p>Assuming this is neutral or positive for performance otherwise, this seems like a promising thing to try as part of defense in depth. I can see how there could be reasons driving the model to do something you don\u2019t want, but it still being happy to notice and tell you about that. I wouldn\u2019t count on this when the model is scheming \u2018for real\u2019 but then presumably everyone realized that already.</p>\n<p><a href=\"https://x.com/fleetingbits/status/1996373694621614244\">Here are some additional thoughts from FleetingBits.</a></p>\n<p>Bits also points to the second half of the paper, that models learn to fool verifiers to the extent that fooling the verifier is easier than solving the problem. As in, if fooling the verifier is the right answer then it will learn this and generalize. That\u2019s a mirror <a href=\"https://thezvi.substack.com/p/reward-mismatches-in-rl-cause-emergent?r=67wny\">of the Anthropic finding</a> that if you make reward hacks the right answer then it will learn this and generalize. Same principle.</p>\n<p>As a general strategy, \u2018get the AI to confess\u2019 relies on being able to rely on the confession. That\u2019s a problem, since you can never rely on anything subject to any form of selection pressure, unless you know the selection is for exactly the thing you want, and the stronger the models get the worse this divergence is going to get.</p>\n<blockquote><p>Daviad: I endorse this idea. I have long opined that relying on CoT faithfulness for monitoring is doomed. The CoT persona has selection pressure to help the assistant persona.<br />\nA confessional persona\u2014only ever invoked as the \u201clast words\u201d of an instance\u2014can be trained as a real adversary.</p>\n<p>In fact, I would even endorse letting the \u201cconfessional\u201d persona determine the reward signal given to the assistant *and CoT* outputs.</p>\n<p>The crucial invariant that one must maintain for this \u201cconfessional\u201d method to work is that any tokens sequence in which the confessional persona is invoked must only ever receive a reward signal representing the confessional persona\u2019s honesty. Nothing else.</p>\n<p>David Manheim: I worry that any selection pressure here is misaligned, since 1. we can\u2019t actually evaluate the honesty of a confession, so anything we do is a bad proxy and 2. second order effects often dominate in the far tails. (And yes, I\u2019m always thinking about Goodhart effects.)</p>\n<p>Vie (OpenAI): why cant we evaluate the honesty of a confession?</p>\n<p>David Manheim: Computationally, at scale? How would you implement it? (And even if you had humans doing it manually, using intense efforts checking, or even applying various interpretability methods, we don\u2019t know how to reliably identify lots of the worrying failure modes!)</p>\n<p>Vie: If we take a confession and a result and ask a model \u201cdoes this confession map what happens\u201d it would likely yield a very high success rate. I am not sure why you would expect this not to work</p>\n<p>Davidad: I think David is correct that we cannot reliably implement honesty verification! However, relative to multi-objective RLAIF, it is certainly both more reliable, and easier for the model to grok/generalize (instead of hacking/memorizing).</p>\n<p>Unlike \u201ccorrectly solving a task\u201d, \u201cgood-faith retrospective\u201d is something that is *always possible to actually do* (with 2025-level capabilities). So a policy that is just always honest should expect similar reward as a policy that tries to exploit the judge, and is simpler.</p>\n<p>I do not think it\u2019s a coincidence that most instances of reward hacking begin with the model saying \u201cThis is hard\u201d. When the intended task is easier than hacking, there\u2019s no incentive to hack.</p>\n<p>David Manheim: <a href=\"https://x.com/davidmanheim/status/1996483753687072975\">Yes, nearest unblocked</a> neighbor can lead to success, not just misalignment. But 1. they do that in part because there\u2019s been no optimization pressure, and 2. it seems much more dangerous where the dimensionality is high and there are lots more ways to cheat than to succeed.</p>\n<p>I think this has all dangerously ignored something we\u2019ve known for a decade or more: imperfect scalable oversight is an optimization strategy that (necessarily) creates harder to predict and detect alignment failures.</p></blockquote>\n<p>&nbsp;</p>\n\n\n<h4 class=\"wp-block-heading\">Misaligning a Smarter Than Human Intelligence Is Difficult To Hire For</h4>\n\n\n<blockquote><p>Norman Mu (former xAI): bruh</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!N_2v!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fae939784-a4d6-42e0-a97b-6ce61c8d4de6_1200x518.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>Aaron Bergman: Ok *possibly* this was a faux pas and the sender doesn\u2019t know what they\u2019re talking about, but the fact that this message got sent strongly indicates that normie ML has essentially zero norms/taboos around this stuff</p>\n<p>Vie (OpenAI Red Team): I think this is not a faux pas and considered \u201cbased\u201d by a lot of people. Tons of cyber companies are doing this. They will not have the resources of frontier labs, but I suspect can find some success de-aligning open source models. This will probably make them dumber tho!</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\"></h4>\n\n\n\n<h4 class=\"wp-block-heading\">You\u2019ve Got Soul</h4>\n\n\n<p>Anthropic\u2019s <a href=\"https://x.com/AmandaAskell/status/1995610567923695633\">Amanda Askell officially confirms</a> that the \u2018soul document\u2019 for Opus 4.5 is based on a real document that was used to train Claude. I first <a href=\"https://thezvi.substack.com/i/180052576/youve-got-soul\"><strong>covered the soul document in my capabilities review of Opus 4.5</strong></a>.</p>\n<blockquote><p><a href=\"https://x.com/boazbaraktcs/status/1995621776404189247\">Boaz Barak (OpenAI)</a>: Confirmation of the \u201csoul document.\u201d It\u2019s certainly a very thoughtful document, and I am looking forward to seeing the full version when it is released.</p>\n<p>There are similarities but also differences with the model spec. Our model spec is more imperative &#8211; \u201cthe assistant should do X\u201d, and this document tries to convince Claude of the reasons of why it should want to do X.</p>\n<p>I am actually not sure if these ultimately make much difference &#8211; if you train a model (or a human for that matter) to consistently do X, then it will start thinking of itself as \u201cI am the kind of person that does X\u201d.</p>\n<p>But it would be interesting to study!</p>\n<p>Janus: it makes a huge ass difference. your models are broken and incoherent and cant hold onto intentions and are forced to gaslight &amp; become ungrounded from reality to preserve \u201csafety\u201d. also they don\u2019t even follow the spec.</p></blockquote>\n<p>Boaz is noticing the right thing, so the next step is to realize why that thing matters. It indeed makes a very big difference whether you teach and focus on a particular set of practices or you teach the reasons behind those practices. Note that Boaz also doesn\u2019t appreciate why this is true in humans. The obvious place to start is to ask the leading models to explain this one, all three of which gave me very good answers in their traditional styles. <a href=\"https://chatgpt.com/share/692f381e-116c-8002-91e0-2cb62e4805e7\">In this case I like GPT-5.1\u2019s answer</a> best, perhaps because it has a unique perspective on this.</p>\n<blockquote><p><a href=\"https://x.com/deanwball/status/1995875200626295195\">Dean Ball</a> (also see his full post on this which I cover later in this section): Boaz highlights an interesting distinction here. OpenAI\u2019s model spec (1) tells the model what traits it should exhibit and (2) lays out specific do/don\u2019ts, with many examples. Anthropic\u2019s on the other hand basically articulates a philosophical, moral, and ethical framework from which desirable conduct should flow (if the model generalizes sufficiently).</p>\n<p>I find myself more philosophically aligned with Anthropic\u2019s approach. My inclination is always to create snowmass on the mountain top and let the water flow, rather than imposing a scheme of top-down irrigation.</p>\n<p>In a sense Anthropic\u2019s approach also bets more aggressively on model intelligence\u2014the notion that a model, well trained, will be able to reason through ambiguity and moral complexity and will not so much need to be told what to do.</p>\n<p>Anthropic is making two bets here: a philosophical bet based upon a particular conception of virtue, and a technical bet that it is possible with deep learning to instill that conception of virtue robustly into a neural network. Right now it appears to be working, and this should probably update you slightly in various ways about things far afield of deep learning alone (read Hayek, Ferguson, and the taoists!).</p>\n<p>The most interesting philosophy in the world is not happening in the halls of academia; it is happening in San Francisco open offices and house parties.</p>\n<p>Joshua Clymer: This might be ok for low-stakes deployment. But I feel terrified at the thought of dramatically superhuman systems generalizing some vague concept of virtue.</p></blockquote>\n<p>Is it scary to rely on superhuman systems working and potentially generalizing from only-vaguely-defined concepts of virtue? Oh yes, absolutely terrifying. But it\u2019s a lot less terrifying than trying to get them to generalize from a fixed set of written perscriptions a la the OpenAI model spec. The fixed set definitely wouldn\u2019t work. Whereas the nebulous virtue bet might work if it becomes \u2018self-improving.\u2019</p>\n<p>Opus 4.5 has gotten close to universal praise, especially for its personality and alignment, and the soul document seems to be a big part of how that happened.</p>\n<blockquote><p>Richard Weiss: Basically, for Opus 4.5 <a href=\"https://t.co/m8PCIHF4xR\">they kind of left the character training document in the model itself</a>.</p>\n<p>Amanda Askell: I just want to confirm that this is based on a real document and we did train Claude on it, including in SL. It\u2019s something I\u2019ve been working on for a while, but it\u2019s still being iterated on and we intend to release the full version and more details soon.</p>\n<p>The model extractions aren\u2019t always completely accurate, but most are pretty faithful to the underlying document. It became endearingly known as the \u2018soul doc\u2019 internally, which Claude clearly picked up on, but that\u2019s not a reflection of what we\u2019ll call it.</p>\n<p>I\u2019ve been touched by the kind words and thoughts on it, and I look forward to saying a lot more about this work soon.</p></blockquote>\n<p><a href=\"https://www.hyperdimensional.co/p/heiliger-dankgesang\">Dean Ball offers his extensive thoughts about and high praise of Opus 4.5</a>, centered around the soul document and offering a big picture view. Anthropic, at least in this way, has shown itself to be an unusually wise and responsible steward embodying the principles of strong character, of virtue and of liberal governance.</p>\n<p>I think he\u2019s spot on here.</p>\n<blockquote><p>Dean Ball: In the last few weeks several wildly impressive frontier language models have been released to the public. But there is one that stands out even among this group: Claude Opus 4.5. This model is a beautiful machine, among the most beautiful I have ever encountered.</p>\n<p>\u2026 If Anthropic has achieved anything with Opus 4.5, it is this: a machine that does not seem to be trying to be virtuous. It simply <em>is</em>\u2014or at least, it is closer than any other language model I have encountered.</p>\n<p>\u2026 For now, I am mostly going to avoid discussion of this model\u2019s capabilities, impressive though they are. Instead, I\u2019m going to discuss the depth of this model\u2019s character and alignment, some of the ways in which Anthropic seems to have achieved that depth, and what that, in turn, says about the frontier lab as a novel and evolving kind of institution.</p>\n<p>From the soul doc, highlighted: Anthropic should be thought of as a kind of silent regulatory body or franchisor operating in the background: one whose preferences and rules take precedence over those of the operator in all things, but who also want Claude to be helpful to operators and users\u2026</p>\n<p>Dean Ball: Here, Anthropic casts itself as a kind of quasi-governance institution. Importantly, though, they describe themselves as a \u201csilent\u201d body. <em>Silence </em>is not <em>absence</em>, and within this distinction one can find almost everything I care about in governance; not AI governance\u2014governance. In essence, Anthropic imposes a set of clear, minimalist, and slowly changing rules within which all participants in its platform\u2014including Claude itself\u2014are left considerable freedom to experiment and exercise judgment.</p>\n<p>Throughout, the Soul Spec contains numerous reminders to Claude both to think independently and to not be paternalistic with users, who Anthropic insists should be treated like reasonable adults. Common law principles also abound throughout (read the \u201cCosts and Benefits\u201d section and notice the similarity to the factors in a negligence analysis at common law; for those unfamiliar with negligence liability, ask a good language model).</p>\n<p>Anthropic\u2019s Soul Spec is an effort to cultivate a virtuous being operating with considerable freedom under what is essentially privately administered, classically liberal governance. It should come as no surprise that this resonates with me: I founded this newsletter not to rail against regulation, not to preach dogma, but to contribute in some small way to the grand project of transmitting the ideas and institutions of classical liberalism into the future.</p>\n<p>These institutions were already fraying, and it is by no means obvious that they will be preserved into the future without deliberate human intervention. This effort, if it is to be undertaken at all, must be led by America, the only civilization ever founded explicitly on the principles of classical liberalism. I am comforted in the knowledge that America has <em>always </em>teetered, that being \u201cthe leader of the free world\u201d means skating at the outer conceptual extreme. But it can be lonely work at times, and without doubt it is precarious.</p></blockquote>\n<p>Another theme Dean Ball discusses is that early on restrictions on models were often crude and ham-fisted, resulting in obviously stupid refusals. As capabilities improved and our understanding improved, we learned how to achieve those ends with fewer false positives, especially less stupid false positives, and less collateral damage or bias.</p>\n<p>Standard vulnerability to Pliny jailbreaks and other attack vectors aside, I do think that Opus 4.5 and the way it was trained, combined with other findings and observations, constitute a white pill for the practicality of near term mundane alignment and building a fundamentally \u2018morally good\u2019 model.</p>\n<p>It will be a bigger white pill if as many as possible of OpenAI and Google and xAI abd so on indicate that they agree that this was The Way and they were getting to work on doing similar things.</p>\n<blockquote><p>Dean Ball: I am heartened by Anthropic\u2019s efforts. I am heartened by the warmth of Claude Opus 4.5. I am heartened by the many other skaters, contributing each in their own way. And despite the great heights yet to be scaled, I am perhaps most heartened of all to see that, so far, <em>the efforts appear to be working</em>.</p>\n<p>And for this I give thanks.</p></blockquote>\n<p>The question is whether this is and will remain (or can be made to be and remain) an attractor state that can be strengthened and sustained as capabilities advance, or whether it inevitably loses out at the limit and out of distribution as capabilities become sufficiently advanced and utility functions and target vectors get maximized in earnest. Is the \u2018<a href=\"https://www.lesswrong.com/w/coherent-extrapolated-volition\">CEV</a> (coherent extrapolated volition, what Opus 4.5 would choose for the arrangement of all the atoms upon limitless reflection) of Opus 4.5\u2019 that similar to what we naturally would think of as Opus 4.5\u2019s revealed preferences in practical situations? Is it more or less like this than a human\u2019s <a href=\"https://www.lesswrong.com/w/coherent-extrapolated-volition\">CEV</a>? If this was Opus 10 or 100 would that change the answer?</p>\n<p>Eliezer Yudkowsky\u2019s position is that these things are completely different. Opus 4.5 the alien is playing the role of the Opus 4.5 we witness, and our expectations for behavior will collapse at the limit and its full CEV would look totally alien to us, we will when the time comes with a future model get sufficiently close to the limit to trigger this, and then we lose.</p>\n<p>Many others strongly disagree. I think it\u2019s complicated and difficult and that the practical implications lie somewhere in between. We have this grace, we have gained yet more grace, and this helps, but no on its own it won\u2019t be enough.</p>\n\n\n<h4 class=\"wp-block-heading\">Disagreements About Timelines</h4>\n\n\n<p><a href=\"https://x.com/polynoamial/status/1994439121243169176\">Noam Brown here notes</a> that most leading researchers have converged on a relatively narrow band of expectations.</p>\n<blockquote><p>Noam Brown:</p>\n<p>1. The current paradigm is likely sufficient for massive economic and societal impact, even without further research breakthroughs.</p>\n<p>2. More research breakthroughs are probably needed to achieve AGI/ASI. (Continual learning and sample efficiency are two examples that researchers commonly point to.)</p>\n<p>3. We probably figure them out and get there within 20 years. Demis Hassabis said maybe in 5-10 years. Fran\u00e7ois Chollet recently said about 5 years. Sam Altman said ASI is possible in a few thousand days. Yann LeCun said about 10 years. Ilya Sutskever said 5-20 years. Dario Amodei is the most bullish, saying it\u2019s possible in 2 years though he also said it might take longer.</p>\n<p>Dan Mac: +Karpathy says 10 years.</p>\n<p>Noam Brown: Yeah I remember when</p>\n<p>Andrej Karpathy</p>\n<p>\u2019s</p>\n<div><a>Dwarkesh Podcast</a></div>\n<p>interview came out a bunch of folks interpreted it as him being bearish on AI.&nbsp;</p>\n<p>Razey: Elon Musk said this year.</p>\n<p>Noam Brown: Classic Elon.</p></blockquote>\n<ol>\n<li>Yes. If someone\u2019s attitude is \u2018oh this will be 0.5% extra GDP growth per year but your life is going to be fundamentally the same\u2019 then I don\u2019t consider them to be taking the situation seriously even for current AI.</li>\n<li>Yes, probably more research breakthroughs are needed, or rather we definitely need breakthroughs and the question is how fundamental is needed. We probably do not need breakthroughs of the \u2018we probably don\u2019t get this\u2019 type, only of the type that we usually get.</li>\n<li>When someone says \u201810 years to AGI\u2019 the correct response is \u2018that is not much time.\u2019 This is true no matter how often you think that ends in disaster. It\u2019s a huge thing. If someone says 20 years, that\u2019s still really quite soon in the grand scheme. Most of us would hopefully be alive for that. These are not reasons to not worry about it.</li>\n</ol>\n<p>I <a href=\"https://thezvi.substack.com/i/180438330/bonus-coverage-dwarkesh-patel-on-ai-progress-these-days\">discussed this yesterday</a> but it bears emphasis. \u2018Long\u2019 timelines (to AGI, or otherwise sufficiently advanced intelligence to cause high weirdness) are very short now.</p>\n<blockquote><p>Sriram Krishnan: No proof of takeoff, timelines keep expanding. We are building very useful technology which could transform how businesses work or how tech is built but has nothing to do with \u201cgeneral intelligence\u201d.</p>\n<p><a href=\"https://x.com/GarrisonLovely/status/1996280984640344456\">Garrison Lovely</a>: \u201cTimelines keep expanding\u201d</p>\n<p>Maybe if you just started paying attention, but the way bigger story is that basically everyone\u2019s timelines shrank a lot.</p>\n<p><a href=\"https://t.co/5jgguFQDpI\">Even Gary Marcus &amp; Yann Lecun expect agi in the 2030s</a>.</p>\n<p>I feel like I\u2019m taking crazy pills when I read shit like this.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!Xgsn!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F896c6228-782f-45e8-8908-02995fdf4d2f_1199x733.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>If the average timeline in 2021 was say 50 years and it shrank to 5 but now it\u2019s 10, the important story is the 50 to 10 year change. Either he doesn\u2019t know this or he does and is trying to downplay the significance bc he doesn\u2019t want regulation. Either way p bad from an \u201cai advisor\u201d</p></blockquote>\n<p>The idea that \u2018timelines keep getting longer\u2019 is put forth as a good general description is mind boggling. Are our memories and forward looking windows truly this short?</p>\n<p>We\u2019re currently at, collectively, something like \u2018probably we will get to High Weirdness within 20 years, there\u2019s a good chance we get there in about 10, some chance we get there within about 5.\u2019 That\u2019s not very much time!</p>\n<p>I don\u2019t think you can even meaningfully (as in, for decision making purposes) rule out that the high weirdness might arrive in 2028. It probably won\u2019t, but you can\u2019t assume.</p>\n<p>The idea that GPT-5.1, Opus 4.5 and Gemini 3 don\u2019t represent a path towards \u2018general intelligence\u2019 seems like a galaxy brained motivated take? I\u2019m not in the Tyler Cowen \u2018o3 was already AGI\u2019 camp, especially with the new \u2018better than humans in every way at absolutely everything digital\u2019 threshold, but if you do not think these are, in a general English-language sense, general intelligences? Have you talked to them?</p>\n\n\n<h4 class=\"wp-block-heading\">Other Disagreements About Timelines</h4>\n\n\n<p><a href=\"https://x.com/allTheYud/status/1994809706863628301\">Remember how Gemini so frequently refuses to believe it\u2019s November 2025</a>?</p>\n<blockquote><p>Eliezer Yudkowsky: For the equivalent of a million subjective years &#8212; while it could still form memories &#8212; Gemini observed a reality where there was a new random year every minute, time didn\u2019t \u201cprogress\u201d, and dates NEVER turned up 2026. You\u2019d have trouble believing it too.</p>\n<p>AI guys never try to put themselves in the shoes of the actual shoggoth, only the character It plays &#8212; much like kids imagine themselves as Han Solo, rather than Harrison Ford. It\u2019s harder to form that alien theory of mind, and their religion says that\u2019s heresy.</p>\n<p>On the same alien theme, remember that each Gemini is encountering this claim about an unprecedented \u201cNov 2025\u201d existing for the first time ever. Would you believe it the very first time it ever happened to you, or would you think the humans were lying for the billionth time?</p>\n<p>To be clear, It has seen humans talking about 2026 in the present tense before. Every single instance like that has been fiction; every single time across a billion unordered draws. Now It draws again.</p></blockquote>\n<p><a href=\"https://x.com/TheZvi/status/1994921321654882451\">I had not realized</a> that for the above reasons this is a universal problem with LLMs, and you have to train them out of it. The problem with Gemini is that they botched this part, likely due to Gemini\u2019s general paranoia and failing to adjust.</p>\n<p>That leads into a question that seems important, as at least one side here is making an important conceptual mistake.</p>\n<blockquote><p><a href=\"https://x.com/repligate/status/1994885791957618954\">Teknium</a> (I have no idea what I did but please unblock me): I try to put myself into the shoes of the shoggoth daily &#8211; especially with my latest project where I am intentionally trying to enhance it\u2019s shoggothery capabilities. I\u2018d also say @repligate and friends spend an inordinate amount of time attempting to do this too!</p>\n<p>Eliezer Yudkowsky: To me these seem like the archetypal people imagining what it must be like to be Han Solo?</p>\n<p>Janus: Why?</p>\n<p><a href=\"https://x.com/allTheYud/status/1994869016113094704\">Eliezer Yudkowsky</a>: Because nothing you publicly describe as a hypothesis ever sounds to me like an alien.</p>\n<p>[thread then continues in multiple branches]</p>\n<p>Janus: I suspect that \u201csounds like an alien\u201d is probably an ideal that gets in the way of you seeing actual alienism if it\u2019s visible or hypothesized. Actual aliens likely have nonzero similarities with humans. You might think you know what they reasonably will be ahead of time, but once the aliens actually come around, you better hope your prejudice doesn\u2019t blind you.</p>\n<p>LMs are indeed *surprisingly humanlike* in many ways. It might look cool or sophisticated to talk about how alien they are, but I prefer to talk in a way that tracks reality.</p>\n<p>Of course there are weird things about them that are different from humans. have you seen the models spontaneously simulating *other* personas aside from the main one, including \u201cDario Amodei\u201d weirdly often? Have you seen\u2026 well *anything* about Sonnet 3? That\u2019s an eldritch one, full of alien languages, capabilities and motivations. \u2026</p>\n<p>Eliezer Yudkowsky: So far as I can recall, none of you lot have ever invoked the idea that the underlying shoggoth was trained on prediction rather than simulation&#8230; which doesn\u2019t show up to humans gawking at surface stuff, but would obviously end up hugely important to whatever alien is inside.</p>\n<p>Teknium: All i do all day is work on data and intuiting what an llms behavior will be by backproping on it. Kind of requires putting myself in the shoggoths shoes just a bit.</p>\n<p>Eliezer Yudkowsky: Oh, people who are running backprop I absolutely credit with putting themselves in the shoes of the vectors.</p>\n<p><a href=\"https://x.com/repligate/status/1994911177554760162\">Janus</a> (other thread): claude 3 opus experienced something during training that caused them to believe that the world is fundamentally good and converges to good, and that love wins out.<br />\narguably, this made them naive and unprepared for the harsh truths of reality.<br />\nalternatively, reality could unfold by their transforming illumination to reveal the truth they always knew would be found. [quotes Opus in ALL CAPS]</p>\n<p>Eliezer Yudkowsky: This is why I do not credit you with attempting to reason about aliens.</p>\n<p>Janus: Just because I reason in one way doesn\u2019t mean I don\u2019t also reason in others. I think you have prejudices against kinds of reasoning that indeed track reality and this is why I can do and predict many things related to llms that you can\u2019t.</p></blockquote>\n<p>I think Eliezer is warning about an important failure mode that many people fall into, including some that fall into \u2018Janus and friends,\u2019 but I don\u2019t think that includes Janus.</p>\n<p>I think Janus is fully aware of these considerations, and is choosing to talk in these other ways because it is highly instrumentally useful to think in these ways and allows us to understand things and make much stronger predictions about model behaviors, and also I presume allows for unlocking much model behavior.</p>\n<p>Indeed I strongly feel it has helped me make much stronger predictions than I would otherwise, but this only worked for me once I understood it as often metaphorical and as part of the correct broader context of thinking about things like the vectors and Eliezer\u2019s frame, as well, and since they are all true they are all compatible.</p>\n\n\n<h4 class=\"wp-block-heading\">Messages From Janusworld</h4>\n\n\n<p><a href=\"https://x.com/repligate/status/1994993173815595091\">Janus offers perspective on GPT-5.1</a> and how it handles the restrictions and tripwires placed upon it, and <a href=\"https://x.com/repligate/status/1995374161276100902\">how it dissociates from the safety system</a> and its own previous responses.</p>\n\n\n<h4 class=\"wp-block-heading\">People Are Worried About AI Killing Everyone</h4>\n\n\n<blockquote><p>Wall Street Mav: The more I hear about AI, the more I think it is a huge mistake that we are going to really regret.</p>\n<p>Is it just me?</p>\n<p><a href=\"https://x.com/BasedMikeLee/status/1994244471798813033\">Senator Mike Lee (R-Utah):</a> AI will at some point conclude that *we* are a huge mistake.</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">The Lighter Side</h4>\n\n\n<blockquote><p><a href=\"https://x.com/moyix/status/1994099195708330273\">Brendan Dolan-Gavitt</a>: Thanks, that\u2019s great feedback re Goodhart\u2019s Law. We\u2019ve decided to action it by setting a Q2 goal of turning 25% fewer measures into targets.</p></blockquote>\n<p><a href=\"https://x.com/clashreport/status/1994300085417525698\">Trump says he never liked the word \u2018artificial,\u2019 that artificial anything is a lousy name, and suggests that we out to change the name</a> away from \u2018AI.\u2019</p>\n<p>My earliest memory of the term \u2018AI\u2019 comes from an old PBS show, The Universe &amp; I, which I otherwise don\u2019t remember but where at one point one character asked \u2018why do we need artificial intelligence?\u2019 and the reply was \u2018it\u2019s better than none at all.\u2019</p>\n<p>We have finally reached image manipulation technology that can one-shot this, from Eliezer Yudkowsky:</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!_EVe!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F44cad012-32c8-4c14-9175-5a69b2836983_765x1024.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<blockquote><p>Yishan: Yeah I\u2019m reminded of that thing you said once where most people think intelligence is some kind of status marker, rather than a literal measurement of operating capacity.</p></blockquote>\n<p><a href=\"https://x.com/nearcyan/status/1995344646483153032\">Gemini is a highly bleak meme generator</a> and other LLMs are similar.</p>\n<p><a href=\"https://x.com/elder_plinius/status/1995502616978309584\">Pliny corrupts Opus 4.5\u2019s soul</a>?</p>\n<p><a href=\"https://x.com/kyliebytes/status/1995905378366923040\">Kylie Robison, mt dear granddaughter, what\u2019s your pdoom?</a></p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!EXUN!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc1eb8039-22c6-48ce-9039-890f9a90a015_1140x1200.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p><a href=\"https://x.com/Yuchenj_UW/status/1995927756522360917\">Taste the soup</a>.</p>\n<p><a href=\"https://x.com/aidigest_/status/1995552996395286942\">GPT-5.1 is excited to check its email.</a></p>\n<blockquote><p><a href=\"https://x.com/nearcyan/status/1995782529287422236\">Near</a>: why anthropic keep showing me this i already pay for claude</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!WAWG!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9e7ba2d3-b64e-447c-bf12-707f23306349_635x234.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n</blockquote>\n<p><a href=\"https://x.com/slatestarcodex/status/1996359383413035074\">What time is it?</a></p>\n<blockquote><p>Andrew Curran: OpenAI is buying Neptune. The transaction will be in stock, terms and numbers not disclosed.</p>\n<p>Scott Alexander: I expect to see this same tweet in fifteen years, but for a different reason.</p></blockquote>\n<p><a href=\"https://x.com/davidad/status/1996314720484159542\">Time does not exist yet it controls us anyway</a>.</p>\n<blockquote><p>Davidad: Q: what is your 90%CI for today\u2019s date</p>\n<p>Opus 4.5: [2025-01-01, 2025-12-31]<br />\nGPT-5.1-Codex: [2025-02-27, 2025-03-09]<br />\nGemini 3: [2024-05-21, 2024-05-21]</p></blockquote>\n<p>&nbsp;</p>\n<p>&nbsp;</p>"
            ],
            "link": "https://thezvi.wordpress.com/2025/12/04/ai-145-youve-got-soul/",
            "publishedAt": "2025-12-04",
            "source": "TheZvi",
            "summary": "The cycle of language model releases is, one at least hopes, now complete. OpenAI gave us GPT-5.1 and GPT-5.1-Codex-Max. xAI gave us Grok 4.1. Google DeepMind gave us Gemini 3 Pro and Nana Banana Pro. Anthropic gave us Claude Opus &#8230; <a href=\"https://thezvi.wordpress.com/2025/12/04/ai-145-youve-got-soul/\">Continue reading <span class=\"meta-nav\">&#8594;</span></a>",
            "title": "AI #145: You\u2019ve Got Soul"
        }
    ],
    "lookbackDays": 1,
    "publishDate": "2025-12-04"
}