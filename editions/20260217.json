{
    "articles": [
        {
            "content": [
                "<p>I have some personal Git repos that I want to sync between my devices \u2013 my dotfiles, text expansion macros, terminal colour schemes, and so on.</p>\n<p>For a long time, I used GitHub as my sync layer \u2013 it\u2019s free, convenient, and I was already using it \u2013 but recently I\u2019ve been looking at alternatives.\nI\u2019m trying to reduce my dependency on cloud services, especially those based in the USA, and I don\u2019t need most of GitHub\u2019s features.\nI\u00a0made these repos public, in case somebody else might find them useful, but in practice I think very few people ever looked at them.</p>\n<p>There are plenty of GitHub-lookalikes, which are variously self-hosted or hosted outside the USA, like GitLab, Gitea, or Codeberg \u2013 but like GitHub, they all have more features than I need.\nI\u00a0just care about keeping my files in sync.\nMaybe I could avoid introducing another service?</p>\n<p>As I thought about how Git works, I thought of a much simpler way \u2013 and I\u2019m almost embarrassed by how long it took me to figure this out.</p>\n<h2 id=\"a-git-repo-is-just-a-collection-of-files\">A Git repo is just a collection of files</h2>\n<p>In Git repos, there\u2019s a <code>.git</code> folder which holds the complete state of the repo.\nIt includes the branches, the commits, and the contents of every file.\nIf you copy that <code>.git</code> folder to a new location, you\u2019d get another copy of the repo.\nYou could copy a repo with basic utilities like <code>cp</code> or <code>rsync</code> \u2013 at least, as a one-off.\nI\u00a0wouldn\u2019t recommend using them for regular syncing; it would be easy to lose data, because they don\u2019t know how to merge changes from different devices.</p>\n<p>Git\u2019s built-in <code>push</code> and <code>pull</code> commands are smarter: they can synchronise this state between locations, compare the history of different copies, and stitch the changes together safely.\nWithin a repo, you can create a <a href=\"https://git-scm.com/book/ms/v2/Git-Basics-Working-with-Remotes\">remote location</a>, a pointer to another copy of the repo that lives somewhere else.\nWhen you push or pull, your local <code>.git</code> folder gets synchronised with that other copy.</p>\n<p>We\u2019ve become used to the idea that the remote location is a cloud service \u2013 but it can just as easily be a folder on your local disk \u2013 and that gives me everything I want.</p>\n<h2 id=\"bare-and-non-bare-repositories\">Bare and non-bare repositories</h2>\n<p>Before I explain the steps, I need to explain the difference between bare and non-bare repositories.</p>\n<p>In our day-to-day work, we use <strong>non-bare</strong> repositories.\nThey have a \u201cworking directory\u201d \u2013 the files you can see and edit.\nThe <code>.git</code> folder lives under this directory, and stores the entire history of the repo.\nThe working directory is a view into a particular point in that history.</p>\n<p>By contrast, a <strong>bare</strong> repository is just the <code>.git</code> folder without the working directory.\nIt\u2019s the history without the view.</p>\n<p>You can\u2019t push changes to a non-bare repo \u2013 if you try, Git will reject your push.\nThis is to avoid confusing situations where the working directory and the <code>.git</code> folder get out of sync.\nImagine if you had the repo open in a text editor, and somebody else pushed new code to the repo \u2013 suddenly your files would no longer match the Git history.</p>\n<p>Whenever we push, we\u2019re normally pushing to a bare repository.\nBecause nobody can \u201cwork\u201d inside a bare repo, it\u2019s always safe to receive pushes from other locations \u2013 there\u2019s no working directory to get out of sync.</p>\n<h2 id=\"my-new-setup\">My new setup</h2>\n<p>I have a home desktop which is always running, and it\u2019s connected to a large external drive.\nFor each repo, there\u2019s a bare repository on the external drive, and then all my devices have a checked-out copy that points to the path on that external drive as their remote location.\nThe desktop connects to the drive directly; the other devices connect over SSH.</p>\n<p>This only takes a few commands to set up:</p>\n<ol>\n<li><p><strong>Create a bare repository on the external drive.</strong></p>\n<pre class=\"lng-console\"><code><span class=\"gp\">$</span><span class=\"w\"> </span>cd<span class=\"w\"> </span>/Volumes/Media/bare-repos\n<span class=\"gp\">$</span><span class=\"w\"> </span>git<span class=\"w\"> </span>init<span class=\"w\"> </span>--bare<span class=\"w\"> </span>dotfiles</code></pre>\n</li>\n<li><p><strong>Set the bare repository as a remote location.</strong></p>\n<p>On the home desktop, which mounts the external drive directly:</p>\n<pre class=\"lng-console\"><code><span class=\"gp\">$</span><span class=\"w\"> </span>cd<span class=\"w\"> </span>~/repos/dotfiles\n<span class=\"gp\">$</span><span class=\"w\"> </span>git<span class=\"w\"> </span>remote<span class=\"w\"> </span>add<span class=\"w\"> </span>origin<span class=\"w\"> </span>/Volumes/Media/bare-repos/dotfiles</code></pre>\n<p>On a machine, which can access the drive over SSH:</p>\n<pre class=\"lng-console wrap\"><code><span class=\"gp\">$</span><span class=\"w\"> </span>cd<span class=\"w\"> </span>~/repos/dotfiles\n<span class=\"gp\">$</span><span class=\"w\"> </span>git<span class=\"w\"> </span>remote<span class=\"w\"> </span>add<span class=\"w\"> </span>origin<span class=\"w\"> </span>alexwlchan@desktop:/Volumes/Media/bare-repos/dotfiles</code></pre>\n<p>This allows me to run <code>git push</code> and <code>git pull</code> commands as normal, which will copy my history to the bare repository.</p>\n</li>\n<li><p><strong>Clone the bare repository to a new location.</strong></p>\n<p>When I set up a new computer:</p>\n<pre class=\"lng-console\"><code><span class=\"gp\">$</span><span class=\"w\"> </span>git<span class=\"w\"> </span>clone<span class=\"w\"> </span>/Volumes/Media/bare-repos/dotfiles<span class=\"w\"> </span>~/repos/dotfiles</code></pre>\n</li>\n</ol>\n<p>This approach is very flexible, and you can store your bare repository in any location that\u2019s accessible on your local filesystem or SSH.\nYou could use an external drive, a web server, a NAS, whatever.\nI\u2019m using <a href=\"https://tailscale.com\">Tailscale</a> to get SSH access to my repos from other devices, but any mechanism for connecting devices over SSH will do.\n(Disclaimer: I work at Tailscale.)</p>\n<p>Of course, this is missing many features of GitHub and the like \u2013 there\u2019s no web interface, no issue tracking, no collaboration \u2013 but for my small, personal repos, that\u2019s fine.\nThere\u2019s also no third-party hosting, no risk of outages, no services to manage.\nI\u2019m just moving files about over the filesystem.\nIt feels like the Git equivalent of <a href=\"https://alexwlchan.net/2024/static-websites/\">static websites</a>, in a good way.</p>\n<h2 id=\"reflections\">Reflections</h2>\n<p>I used to throw every scrap of code onto GitHub in the vague hope of \u201csharing knowledge\u201d, but most of it was <a href=\"https://alexwlchan.net/2024/digital-decluttering/\">digital clutter</a>.</p>\n<p>Nobody was reading my personal repos in the hope of learning something.\nThey\u2019re a grab bag of assorted snippets, with only a loose definition or purpose \u2013 it\u2019s unlikely another person would know what they could find, or spend the time to go looking.\nSharing knowledge requires more than just publishing code somewhere; you need to make it possible for somebody to find.</p>\n<p>Extracting my ideas into standalone, searchable snippets makes them dramatically more useful and discoverable.\nThere are single blog posts that have done more good than my entire corpus of code on GitHub \u2013 and I have hundreds of blog posts.</p>\n<p>I still have plenty of public repos, but it\u2019s specific libraries or tools with a clear purpose.\nIt\u2019s more obvious whether you might want to read it, and better documented if you do.\nIt\u2019s an intentional selection, not a random set of things I want to keep in sync.</p>\n<p>For years, I\u2019ve been using a social media site as a glorified file-syncing service, but I don\u2019t need pull requests, an issue tracker, or a CI/CD pipeline to move a few macros between my machines \u2013 just a place to put my code.\nAs with so many digital things, files and folders are all I need.</p>\n\n    <p>[If the formatting of this post looks odd in your feed reader, <a href=\"https://alexwlchan.net/2026/bare-git/?ref=rss\">visit the original article</a>]</p>"
            ],
            "link": "https://alexwlchan.net/2026/bare-git/?ref=rss",
            "publishedAt": "2026-02-17",
            "source": "Alex Chan",
            "summary": "I don't need GitHub or a cloud service to keep my Git repos in sync -- files and folders work just fine.",
            "title": "The bare minimum for syncing Git repos"
        },
        {
            "content": [
                "&lt;p&gt;I recently joined my friends Diana, Harj, Garry, and Jared on the &lt;a href=\"https://www.youtube.com/watch?v=qwmmWzPnhog\"&gt;YC Lightcone Podcast&lt;/a&gt; to discuss coding agents. I had a lot of fun with the conversation, but afterwards I couldn&amp;#x27;t help but feel like I hadn&amp;#x27;t gotten into the details of how I&amp;#x27;m using the different agents. And ultimately, the details matter a lot!&lt;/p&gt;\n&lt;p&gt;In this post, I&amp;#x27;d like to dive into some more of the nuance around the models.&lt;/p&gt;\n&lt;p&gt;As quick background: I helped launch the &lt;a href=\"https://calv.info/openai-reflections\"&gt;Codex web product&lt;/a&gt;, and have worked pretty extensively with &lt;a href=\"https://calv.info/coding-agent-metagame\"&gt;Claude Code&lt;/a&gt; in the intervening months. I&amp;#x27;ve come to the conclusion that both models have different strengths and weaknesses related to their training mix.&lt;/p&gt;\n&lt;p&gt;The biggest change to my workflow is that &lt;em&gt;my time&lt;/em&gt; is now the biggest consideration. I&amp;#x27;m primarily picking my coding agent &lt;em&gt;as a function of how much time I have&lt;/em&gt;, and how long I want it to run autonomously (is it better to get a 80% draft done overnight, or try and work collaboratively with the model during the day?). Depending on the type of feature and how mission critical it seems, I&amp;#x27;ll reach for different tools. I pay for all of Claude Max, ChatGPT Pro, and Cursor Pro+, and it&amp;#x27;s some of the best money I spend anywhere.&lt;/p&gt;\n&lt;p&gt;Here&amp;#x27;s my point-in-time snapshot of what I&amp;#x27;m doing today (Feb, 2026). It all changes quite quickly so I don&amp;#x27;t expect this to stay relevant over time.&lt;/p&gt;\n&lt;h2&gt;Guiding principles&lt;/h2&gt;\n&lt;p&gt;To use coding agents well, you must &lt;strong&gt;understand context&lt;/strong&gt;.&lt;/p&gt;\n&lt;p&gt;It&amp;#x27;s easy to fool yourself into thinking that the coding agents are magical models. They have read all of the internet, developed deep levels of intuition for the structure of codebases, and been trained to write extremely correct code.&lt;/p&gt;\n&lt;p&gt;But at the end of the day, the agent is doing next token prediction. And each token &lt;em&gt;must&lt;/em&gt; fit in a context window.&lt;/p&gt;\n&lt;p&gt;There are a bunch of corollaries that fall out of that...&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Your work needs to somehow be chunked.&lt;/strong&gt; If the problem you are trying to solve is &amp;#x27;too big&amp;#x27; for the context window, the agent is going to spin on it for a long time and give you poor results.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Compaction is a lossy technique.&lt;/strong&gt; When deciding what to compact and how, the agent is going to make choices on which information to include and omit. Maybe it does a good job, maybe it doesn&amp;#x27;t! In my experience, more compaction tends to lead to more degradation in performance.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Externalizing context into the filesystem&lt;/strong&gt; (e.g. a plan doc with stages which are checked or not) allows agents to selectively read and remember without filling up the full context of the conversation. This is helpful for resuming tasks and continuing to be context-efficient.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Stay in the &amp;#x27;smart&amp;#x27; half of the context window.&lt;/strong&gt; It&amp;#x27;s generally easier to train on short-context data vs long-context data. Results will tend to be better when the context window is &amp;#x27;less full&amp;#x27;. Dex Horthy calls this staying out of the &lt;a href=\"https://www.youtube.com/watch?v=rmvDxxNubIg&amp;amp;t=355s\"&gt;dumb zone&lt;/a&gt;.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;You don&amp;#x27;t know what you don&amp;#x27;t know.&lt;/strong&gt; If the agent somehow misses a relevant file or package, it might really go in a direction you didn&amp;#x27;t anticipate. If it&amp;#x27;s not in the context window, there&amp;#x27;s no way to know. Your codebase&amp;#x27;s structure can help this, as can &amp;#x27;progressive disclosure&amp;#x27; of parts of the architecture. OpenAI has a nice &lt;a href=\"https://openai.com/index/harness-engineering/\"&gt;blog post&lt;/a&gt; about structuring many different markdown files to do this well.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;As a result, model performance and speed is governed &lt;em&gt;both&lt;/em&gt; by the pure performance of the model, but also by how it is able to manage multiple context windows and delegate to sub-agents or teams of agents.&lt;/p&gt;\n&lt;h2&gt;Opus: context whiz, better tool-use, more human&lt;/h2&gt;\n&lt;p&gt;Claude Code is my regular driver for planning, orchestrating my terminal, and managing git/github operations. I&amp;#x27;ll typically use it for creating an initial plan, scripting against things on my laptop, and also for explaining how parts of the codebase work.&lt;/p&gt;\n&lt;p&gt;Opus has been trained to work across context windows extremely efficiently, so using it with Claude Code &lt;em&gt;feels&lt;/em&gt; much faster than using Codex. You&amp;#x27;ll notice Opus frequently spinning up multiple sub-agents simultaneously, whether it&amp;#x27;s to &lt;code&gt;Explore&lt;/code&gt; parts of the codebase or handle multiple simultaneous &lt;code&gt;Task&lt;/code&gt; calls. The explore tool uses Haiku so it is very fast at processing a lot of tokens, and handing the relevant context back to Opus.&lt;/p&gt;\n&lt;p&gt;What&amp;#x27;s more, Opus has been trained well to use the tools on my laptop: &lt;code&gt;gh&lt;/code&gt;, &lt;code&gt;git&lt;/code&gt;, various MCP servers. Occasionally I will use the &lt;code&gt;/chrome&lt;/code&gt; extension to verify a bug, which works pretty well, but can be slow and buggy.&lt;/p&gt;\n&lt;p&gt;I also find the permission model of Claude Code is easier to understand. There&amp;#x27;s a bunch of prefixes for commands you can run. With Codex models it&amp;#x27;s harder to whitelist individual CLI tools because the model will often &amp;quot;script&amp;quot; against these commands in bash (&lt;code&gt;for ... gh&lt;/code&gt;).&lt;/p&gt;\n&lt;p&gt;I&amp;#x27;ve talked a lot about Claude Code being an incredible harness for the model, and there are a lot of small things that it does which make it nice to use: updating the terminal title to be task-relevant, showing the current PR in the statusline, the little status messages.&lt;/p&gt;\n&lt;p&gt;Finally, a lot of folks talk about &amp;quot;personality&amp;quot; of the model. I don&amp;#x27;t buy into this too much, but find Opus is more willing to give me human-understandable PR descriptions and detailed architecture diagrams which are easy for me to understand.&lt;/p&gt;\n&lt;div class=\"mt-7 md:mx-0\"&gt;&lt;img src=\"https://calv.info/agents-feb-2026/claude-code-pr.png\" class=\"rounded-lg border\" style=\"transform:scale(1);transform-origin:center\"/&gt;&lt;div class=\"text-center -mt-6 italic\"&gt;&lt;span&gt;Fig 1: Claude Code&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;\n&lt;div class=\"mt-7 md:mx-0\"&gt;&lt;img src=\"https://calv.info/agents-feb-2026/codex-pr.png\" class=\"rounded-lg border\" style=\"transform:scale(1);transform-origin:center\"/&gt;&lt;div class=\"text-center -mt-6 italic\"&gt;&lt;span&gt;Fig 2: Codex&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;\n&lt;p&gt;If I am asking for an explanation about how some piece of the code is structured, I&amp;#x27;ll typically use Claude Code.&lt;/p&gt;\n&lt;p&gt;I also find Opus is a little more &amp;#x27;creative&amp;#x27; in terms of suggesting things that I may have forgotten to mention. This is actually a very nice property when creating plans, I&amp;#x27;ll invariably leave some aspect out, and Opus can help point out areas of ambiguity.&lt;/p&gt;\n&lt;h2&gt;Codex: way fewer bugs&lt;/h2&gt;\n&lt;p&gt;Where Codex shines is &lt;strong&gt;correctness of code&lt;/strong&gt;. Other folks who are pushing the models a lot &lt;a href=\"https://x.com/steipete/status/2018032296343781706\"&gt;seem&lt;/a&gt; &lt;a href=\"https://x.com/antirez/status/2022045607385596411\"&gt;to&lt;/a&gt; &lt;a href=\"https://x.com/thdxr/status/2022301118458462647\"&gt;agree&lt;/a&gt;.&lt;/p&gt;\n&lt;p&gt;I run on GPT-5.3-Codex-xhigh or high, and the Codex code just straight up has fewer bugs. Opus will frequently add a set of React components which pass unit tests, but then the model just straight forgets to add it to the top-level &lt;code&gt;&amp;lt;App&amp;gt;&lt;/code&gt; which gets rendered. There&amp;#x27;s obvious off-by-one errors which don&amp;#x27;t get caught. Dangling references or race conditions which are subtle and hard to spot.&lt;/p&gt;\n&lt;p&gt;For a long time, I thought there was a negligible difference between the two models. But after seeing enough PRs with automated reviews from Codex and Cursor&amp;#x27;s Bugbot, I&amp;#x27;ve realized that OpenAI&amp;#x27;s model is superior in terms of the code it writes. If you&amp;#x27;d like to A/B test this yourself, just check out a branch and run &lt;code&gt;/code-review&lt;/code&gt; in Claude Code vs &lt;code&gt;/review&lt;/code&gt; in Codex.&lt;/p&gt;\n&lt;p&gt;Unfortunately, Codex is &lt;em&gt;slow&lt;/em&gt;.&lt;/p&gt;\n&lt;p&gt;The biggest reason for this is that it&amp;#x27;s not delegating tasks across context windows, though I get the sense that the latency between tokens might also be higher. I have been running with the experimental subagent support (toggle in &lt;code&gt;/experimental&lt;/code&gt;) which does manage to do this and it works well, though perhaps not as seamlessly as Claude. The parallelism still isn&amp;#x27;t there quite yet.&lt;/p&gt;\n&lt;p&gt;The net result between the two is that I&amp;#x27;ll &lt;em&gt;start&lt;/em&gt; with Claude Code and keep that open as a pane, then flip to Codex when I&amp;#x27;m ready to actually start the coding.&lt;/p&gt;\n&lt;p&gt;Every so often I will still leverage Opus, but it mostly comes down to leveraging tool use (&lt;code&gt;/chrome&lt;/code&gt; to debug, make stylized frontend changes).&lt;/p&gt;\n&lt;h2&gt;Useful things&lt;/h2&gt;\n&lt;p&gt;A few caveats: I am working on greenfield codebases. They are much &lt;em&gt;much&lt;/em&gt; smaller than any production codebase I&amp;#x27;ve worked in, and are relatively token-efficient.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;Repo structure&lt;/strong&gt; -- all of my repos have a &lt;code&gt;plans/&lt;/code&gt; folder, with numbered plans as I ask the agents to implement things. Typically I&amp;#x27;ll also have an &lt;code&gt;apps/&lt;/code&gt; folder for different services I&amp;#x27;m running. I&amp;#x27;m using turborepo to manage monorepos in typescript, and &lt;code&gt;bun&lt;/code&gt; for fast installs.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;&lt;a href=\"https://ghostty.org/\"&gt;Ghostty&lt;/a&gt;&lt;/strong&gt; -- Mitchellh&amp;#x27;s terminal is fantastic. Fast, native, and constantly improving. For a little while I was running multiple Claude/Codex instances in tmux, but now I just use multiple panes within the same terminal tab.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;Next.js on Vercel, APIs on Cloudflare Durable Objects&lt;/strong&gt; -- I&amp;#x27;ve mostly been leveraging Cloudflare Durable Objects for APIs and storage. The idea that you can partition your database ahead of time, wake it up on demand, and not have to worry a ton about concurrent writes is a really wonderful property. In a time of agents acting on small pieces of data, I can&amp;#x27;t help but feel that it just &lt;em&gt;makes sense&lt;/em&gt; from an infra perspective. Cloudflare is also leaning into this with their &lt;a href=\"https://github.com/cloudflare/actors\"&gt;cloudflare/actors&lt;/a&gt; library which bundles up compute with small bits of co-located storage.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;Worktrees&lt;/strong&gt; -- since all of my code is relatively lightweight and small, I&amp;#x27;m able to leverage parallel worktrees by using &lt;code&gt;bun install&lt;/code&gt; and then &lt;code&gt;bun run dev&lt;/code&gt; across each one to verify locally. I have a &lt;code&gt;worktree&lt;/code&gt; skill which copies any relevant plans, env vars, and other updates, and starts a new branch. I didn&amp;#x27;t really use worktrees prior to coding agents (I was mostly a branch guy) but having them work in parallel and letting Claude Code manage the syntax is a godsend.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;Plan, Implement, Review&lt;/strong&gt; -- I almost always have the model start with a plan. This is useful for two reasons: 1) it externalizes the context beyond a single context window 2) it allows me to review or interrogate what was done. If an agent stops for some reason, I can always start a new context window and tell it to resume the plan.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;Preview deploys&lt;/strong&gt; -- every branch gets a fresh Web + API deploy. It makes running in parallel and quickly testing branches a breeze. It&amp;#x27;s way harder to work without this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;Cursor Bugbot and Codex Code Review&lt;/strong&gt; -- I still spot-check the code, and make sure I understand it from an architecture level, but increasingly I am not reading every line of every PR. I rely on agents to spot subtle bugs (they are far better at it than I am). For awhile I was using Claude Code, Cursor&amp;#x27;s Bugbot, and Codex. Claude Code didn&amp;#x27;t seem to catch real issues for me. Since then, I&amp;#x27;ve settled mostly on Cursor as the default option since you can tell when it&amp;#x27;s working, though I find the results of Codex are good too.&lt;/p&gt;\n&lt;h2&gt;Skills&lt;/h2&gt;\n&lt;p&gt;Today I have a bunch of &lt;strong&gt;skills&lt;/strong&gt; and a shared AGENTS.md/CLAUDE.md defined in a repo I call claudefiles. My rule for adding skills is not to do it prematurely, but only if I find myself settling into a workflow after a few times.&lt;/p&gt;\n&lt;p&gt;While I find the AGENTS/CLAUDE.md are handy for steering the model overall, skills are for two specific reasons:&lt;/p&gt;\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;They let you chain and automate workflows.&lt;/strong&gt; This is my (and generally?) the most common use case for skills. I&amp;#x27;ll typically want to start with a plan, then implement in stages, then review. Why not have skills for each of these processes? Then I can have a meta skill which implements them all in order (see below).&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;They help you split context windows&lt;/strong&gt; -- at least in Claude Code, invoking a skill can happen in a new context window if you set &lt;a href=\"https://code.claude.com/docs/en/skills#frontmatter-reference\"&gt;&lt;code&gt;context: fork&lt;/code&gt;&lt;/a&gt;. This is really handy if you have a single context window for the &amp;#x27;master orchestrator&amp;#x27;, and then sub-agents which go and do parts of a task. The orchestrator can keep sub-agents working, and process outputs as they finish.&lt;/li&gt;\n&lt;/ol&gt;\n&lt;p&gt;Skills are also great because they are &lt;em&gt;very&lt;/em&gt; context efficient. Unlike MCP calls (which take up thousands of tokens), skills tend to be ~50-100 tokens.&lt;/p&gt;\n&lt;h2&gt;Automating with skills&lt;/h2&gt;\n&lt;p&gt;Early on in my journey with Claude Code, I was intrigued by the idea of skills marketplaces. That you could just install great frontend-design / security detail / architecture review.&lt;/p&gt;\n&lt;p&gt;After working for awhile, I&amp;#x27;ve mostly abandoned skills that anyone else has written. Instead, I start doing things manually, then think about how I want to automate them. Over time, I&amp;#x27;ve ended up building a lot of time-saving automation.&lt;/p&gt;\n&lt;p&gt;Here&amp;#x27;s how my use of skills has evolved. I say this not to tell you what the &amp;quot;golden path&amp;quot; for which skills to use, but more as an illustrative example of how you might automate more of what you are doing with them. Here&amp;#x27;s my journey.&lt;/p&gt;\n&lt;p&gt;The first skill I added was obvious, rather than tell the model to commit and push (in half a dozen different ways) add a &lt;code&gt;/commit&lt;/code&gt; skill which is borrowed directly from Claude Code.&lt;/p&gt;\n&lt;p&gt;Then I realized if I wanted agents working in separate worktrees, I should probably just rely on Claude Code to manage it. So I added a &lt;code&gt;/worktree&lt;/code&gt; skill which creates a new worktree, keyed off the plan&amp;#x27;s number (e.g. 00034-add-user-auth).&lt;/p&gt;\n&lt;p&gt;The next thing I noticed myself doing was always doing a plan step, then implement the plan in stages. I&amp;#x27;d first clear the context window, and then say &amp;quot;implement the next stage of the plan, then &lt;code&gt;/commit&lt;/code&gt;&amp;quot;. But it became clear this was a good candidate for a skill: &lt;code&gt;/implement&lt;/code&gt; which basically does exactly that.&lt;/p&gt;\n&lt;p&gt;Of course, just typing &lt;code&gt;/implement&lt;/code&gt; in succession is annoying, so I added an &lt;code&gt;/implement-all&lt;/code&gt; which looks at the current worktree path, ties it to the plan number, and then implements everything in stages. Sometimes when I&amp;#x27;m running overnight, I&amp;#x27;ll leverage the &lt;code&gt;/ralph-loop&lt;/code&gt; just to keep it going until all stages are done. I also added a local &lt;code&gt;/codex-review&lt;/code&gt; which basically spawns a &lt;code&gt;codex --review&lt;/code&gt; process to run the review.&lt;/p&gt;\n&lt;p&gt;&lt;code&gt;/implement-all&lt;/code&gt; was working pretty well, but I wasn&amp;#x27;t really closing the loop on addressing feedback from the models in CI. I&amp;#x27;d get these bug reports from Cursor + Codex indicating that there was still more work to do, even after each phase of the plan had succeeded.&lt;/p&gt;\n&lt;p&gt;So I added an &lt;code&gt;/address-bugs&lt;/code&gt; skill which looks at the GitHub API, searches for Cursor + Codex comments since the last commit, and then attempts to verify and fix them. Then it will fix those bugs.&lt;/p&gt;\n&lt;p&gt;Finally I realized this was just working in a loop, so I added a &lt;code&gt;/pr-pass&lt;/code&gt;, which runs at the end of &lt;code&gt;/implement-all&lt;/code&gt;. It essentially 1) pushes to the remote 2) waits for all CI to pass 3) runs &lt;code&gt;/address-bugs&lt;/code&gt; and then optionally goes to step 1 until it&amp;#x27;s finished.&lt;/p&gt;\n&lt;p&gt;These were all nice speedups, and I realized they were helping me with a lot of bookkeeping. So I also added a &lt;code&gt;/focus&lt;/code&gt; skill which looks at my &lt;code&gt;plans&lt;/code&gt; dir, my outstanding PRs, and my worktrees to help refresh my memory and keep me on track.&lt;/p&gt;\n&lt;p&gt;Importantly, I don&amp;#x27;t think I would&amp;#x27;ve had any success trying to &lt;em&gt;start&lt;/em&gt; with this process. But by building it over time and noticing little areas where I could automate, it&amp;#x27;s significantly improved my workflow.&lt;/p&gt;\n&lt;h2&gt;Stuff I didn&amp;#x27;t mention here&lt;/h2&gt;\n&lt;p&gt;I gave the Codex App a shot recently, and I was pleasantly surprised at the attention to detail and the little touches related to it. I have yet to move my workflow over fully from the CLI tools since I appreciate the flexibility of the terminal. Still, I like the idea. I tried giving Cowork a spin as well, and had a hard time getting it to work properly. In each case I think the sandboxing model makes a big difference!&lt;/p&gt;\n&lt;p&gt;Occasionally I will use the web interface for async jobs, though I find right now I&amp;#x27;m more and more tied to the CLI. This is different from what I was doing 6 months ago, where I was mostly using Cursor and the built-in agent or extensions.&lt;/p&gt;\n&lt;p&gt;I&amp;#x27;ve picked up &lt;a href=\"https://www.pencil.dev/\"&gt;pencil.dev&lt;/a&gt; for working on frontend UI. The deployment model is fascinating if nothing else, it shells out to your local Claude Code (able to re-use your existing subscription).&lt;/p&gt;\n&lt;p&gt;I&amp;#x27;m still feeling like I should be using a more well-defined issue tracker. David Cramer&amp;#x27;s &lt;a href=\"https://github.com/dcramer/dex\"&gt;Dex&lt;/a&gt; seems to be promising, in a similar spirit to Steve Yegge&amp;#x27;s &lt;a href=\"https://github.com/steveyegge/beads\"&gt;beads&lt;/a&gt;. Both feel like a little more than I need, but perhaps I&amp;#x27;m just not in the right workflows.&lt;/p&gt;\n&lt;p&gt;I am not really using Playwright or other automated e2e MCPs.&lt;/p&gt;\n&lt;h2&gt;Free advice to the labs&lt;/h2&gt;\n&lt;p&gt;No one asked, but here it is :)&lt;/p&gt;\n&lt;h3&gt;Anthropic&lt;/h3&gt;\n&lt;p&gt;&lt;strong&gt;Model:&lt;/strong&gt; Like I mentioned before, the Opus models totally shine on feeling human, working with engineering tools, splitting context in the right ways to achieve good parallelism, and taking liberty on things &amp;quot;you might have forgotten&amp;quot;. Where they don&amp;#x27;t is in the code correctness. I&amp;#x27;d love to see an &amp;#x27;Opus Strict&amp;#x27; mode, where some base model has really been RL&amp;#x27;d to achieve better performance. Opus is where I start, but Codex writes all my code. If I was budget constrained, I&amp;#x27;d probably pick Codex.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;Product harness:&lt;/strong&gt; This is the one area where I basically have no notes. Boris and Cat have better ideas than I do mostly. My two requests:&lt;/p&gt;\n&lt;ol&gt;\n&lt;li&gt;Adopt &lt;a href=\"https://agentskills.io/home\"&gt;agent skills&lt;/a&gt; so I don&amp;#x27;t have to do this dumb symlinking between a bunch of directories. I think Anthropic has little incentive to make this happen, but it&amp;#x27;d be nice for those of us who flex between the two CLIs.&lt;/li&gt;\n&lt;li&gt;Publish the output format for &lt;code&gt;--stream-json&lt;/code&gt;. I&amp;#x27;m probably not alone in terms of being interested in running Claude Code in a sandbox on behalf of users. But I am worried the format will change out from underneath me. Depending on the sandbox, it&amp;#x27;s also been annoying to setup the right pathing properly for Claude Code, whereas the other CLI tools (Codex, Cursor, Gemini) seem to install without issue.&lt;/li&gt;\n&lt;/ol&gt;\n&lt;h3&gt;OpenAI&lt;/h3&gt;\n&lt;p&gt;&lt;strong&gt;Model:&lt;/strong&gt; The number one thing the OpenAI models can do to improve is figure out how to split across context windows and delegate to sub-agents. I&amp;#x27;m using the experimental sub-agent version. There&amp;#x27;s also this &amp;quot;more than what you asked for&amp;quot; concept that Opus manages to accomplish during planning that would be useful.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;Product harness:&lt;/strong&gt; I have a lot of small feedback here that I think would go a long way (and maybe some of this is out of date)...&lt;/p&gt;\n&lt;ol&gt;\n&lt;li&gt;I still don&amp;#x27;t understand the sandboxing model vs Claude Code&amp;#x27;s, and because the model often tends to script, I end up needing to give a lot of approvals. Since the models are so determined, I worry a bit about running in &lt;code&gt;--yolo&lt;/code&gt; mode.&lt;/li&gt;\n&lt;li&gt;Like Claude Code, add some sort of &amp;quot;user guide&amp;quot; that ships with the CLI so I can ask questions about things like where to put skills, which fields are supported, etc. I&amp;#x27;d love to be able to tell Codex what sort of sandboxing model I want and have it automatically configure that without needing to have it fetch the repo and look at the source.&lt;/li&gt;\n&lt;li&gt;Make &lt;code&gt;/review&lt;/code&gt; a regular skill rather than the odd sort of packaged command it is right now. I want the model to be able to invoke it dynamically.&lt;/li&gt;\n&lt;li&gt;Nit: change the title of my terminal tab to something related to the task when executing. I frequently lose track of dozens of &lt;code&gt;codex&lt;/code&gt; title tabs.&lt;/li&gt;\n&lt;li&gt;Have some sort of training specific to PR descriptions and commit descriptions. I generally like Codex&amp;#x27;s terse personality, but these could be expanded.&lt;/li&gt;\n&lt;li&gt;Support &lt;code&gt;context: fork&lt;/code&gt; in skill definitions.&lt;/li&gt;\n&lt;li&gt;If a link overflows the line in the pane, it should still be clickable.&lt;/li&gt;\n&lt;li&gt;Show my current worktree/PR/branch name at the bottom of the status bar.&lt;/li&gt;\n&lt;/ol&gt;\n&lt;h2&gt;Where this all goes&lt;/h2&gt;\n&lt;p&gt;A few weeks ago, a friend sent me the post on &lt;a href=\"https://steve-yegge.medium.com/welcome-to-gas-town-4f25ee16dd04\"&gt;Gas Town by Steve Yegge&lt;/a&gt;. It&amp;#x27;s still one of the wildest things I&amp;#x27;ve read.&lt;/p&gt;\n&lt;p&gt;If you haven&amp;#x27;t seen it, Steve basically makes the case that you should just always be maxing out tokens. You should have a pool of workers, who are hungry to accept more work, and they should be going 24/7. You should make lots of plans. You should expect to throw them away.&lt;/p&gt;\n&lt;p&gt;For all your take on whether the abstractions are correct or not, &lt;em&gt;directionally&lt;/em&gt;, I think Steve is absolutely correct.&lt;/p&gt;\n&lt;p&gt;The dream is to have your laptop (or cloud sandbox or whatever) constantly churning on ideas in the background, and have you be able to nudge it in directions, go off and do research, review its output and come back. Working with coding agents has made me feel much more like an engineering manager again when it comes to coordination, but without worrying about motivating the agents or the personalities involved.&lt;/p&gt;\n&lt;p&gt;Today it feels like we&amp;#x27;re quite a bit closer to that future. This is over-hyped on Twitter, but I do really try and kick off 3-4 tasks in Codex before going to bed, so they&amp;#x27;ll be ready for review in the morning. But I&amp;#x27;m still not at the point where I feel like I can have agents running 24/7.&lt;/p&gt;\n&lt;p&gt;I think there are two barriers to more progress here...&lt;/p&gt;\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Context window size/coordination&lt;/strong&gt; (see above). Agents can&amp;#x27;t endlessly compact/recycle in the same context window. We need either smarter harnesses or something which provides more delegation.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Resistance to prompt injection.&lt;/strong&gt; Sometimes the agents will only run for a few minutes before asking for an escalated approval. If I&amp;#x27;m going to let them run overnight, I don&amp;#x27;t really trust them to run in &lt;code&gt;--yolo&lt;/code&gt; mode, but there&amp;#x27;s a subset of sane permissions/domains I&amp;#x27;d allow.&lt;/li&gt;\n&lt;/ol&gt;\n&lt;p&gt;On the first point, Cursor has been &lt;a href=\"https://cursor.com/blog/long-running-agents\"&gt;pushing the bounds&lt;/a&gt; of what &lt;a href=\"https://cursor.com/blog/scaling-agents\"&gt;swarms of agents can do&lt;/a&gt; across many context windows. I still haven&amp;#x27;t seen great answers to the second, and it&amp;#x27;s an active area of research. Running in a sandbox seems like the best workaround for the moment, but this is still more painful to configure than it should be, and if there&amp;#x27;s privileged data that your agent has access to with open internet access, it&amp;#x27;s vulnerable to the &lt;a href=\"https://simonwillison.net/2025/Jun/16/the-lethal-trifecta/\"&gt;Lethal Trifecta&lt;/a&gt;.&lt;/p&gt;\n&lt;p&gt;As a solo engineer working on projects, I&amp;#x27;m already finding that I am the bottleneck when it comes to the right ideas. More and more, &lt;strong&gt;ideas&lt;/strong&gt;, &lt;strong&gt;architecture&lt;/strong&gt;, and &lt;strong&gt;project sequencing&lt;/strong&gt; are going to become the limiting factors for building great products.&lt;/p&gt;"
            ],
            "link": "https://calv.info/agents-feb-2026",
            "publishedAt": "2026-02-17",
            "source": "Calvin French-Owen",
            "summary": "My point-in-time snapshot of using Claude Code and Codex together. Opus shines at context management and tool use, Codex writes fewer bugs. Here's how I use both.",
            "title": "Coding Agents in Feb 2026"
        },
        {
            "content": [],
            "link": "https://emschwartz.me/psa-write-transactions-are-a-footgun-with-sqlx-and-sqlite/",
            "publishedAt": "2026-02-17",
            "source": "Evan Schwartz",
            "summary": "<p>Write transactions can lead to lock starvation and serious performance degradation when using SQLite with <a href=\"https://crates.io/crates/sqlx\">SQLx</a>, the popular async Rust SQL library. In retrospect, I feel like this should have been obvious, but it took a little more staring at suspiciously consistent \"slow statement\" logs than I'd like to admit, so I'm writing it up in case it helps others avoid this footgun.</p> <h2 id=\"sqlite-locking-and-transactions\">SQLite Locking and Transactions</h2><p>SQLite is single-writer. In WAL mode, it can support concurrent reads and writes (or, technically \"write\" singular), but no matter the mode there is only ever one writer at a time. Before writing, a process needs to obtain an <a href=\"https://sqlite.org/lockingv3.html\">EXCLUSIVE lock</a> on the database.</p> <p>If you start a read transaction with a SELECT and then perform a write in the same transaction, the transaction will need to be upgraded to write transaction with an exclusive lock:</p> <blockquote> <p>A read transaction is used for reading only. A write transaction allows both reading and writing. A read transaction is started by a SELECT statement, and a write transaction is started by statements like CREATE, DELETE, DROP, INSERT, or UPDATE (collectively \"write statements\"). If a write statement occurs while a read transaction is active,",
            "title": "PSA: Write Transactions are a Footgun with SQLx and SQLite"
        },
        {
            "content": [
                "<div id=\"blog\"><div id=\"content\">\n  <div id=\"content\">\n\n    <div class=\"Article\">\n    \n    <h1 class=\"small\"><a href=\"https://go.dev/blog/\">The Go Blog</a></h1>\n    \n\n    <h1>Using go fix to modernize Go code</h1>\n      \n      <p class=\"author\">\n      Alan Donovan<br />\n      17 February 2026\n      </p>\n      \n      <div class=\"markdown\">\n\n<p>The 1.26 release of Go this month includes a completely rewritten go fix subcommand. Go fix uses a suite of algorithms to identify opportunities to improve your code, often by taking advantage of more modern features of the language and library. In this post, we\u2019ll first show you how to use <code>go fix</code> to modernize your Go codebase. Then in the <a href=\"https://go.dev/blog/feed.atom#go/analysis\">second section</a> we\u2019ll dive into the infrastructure behind it and how it is evolving. Finally, we\u2019ll present the theme of <a href=\"https://go.dev/blog/feed.atom#self-service\">\u201cself-service\u201d</a> analysis tools to help module maintainers and organizations encode their own guidelines and best practices.</p>\n<!-- see https://go.dev/blog/survey2025#challenges -->\n<h2 id=\"running-go-fix\">Running go fix</h2>\n<p>The <code>go fix</code> command, like <code>go build</code> and <code>go vet</code>, accepts a set of patterns that denote packages. This command fixes all packages beneath the current directory:</p>\n<pre><code>$ go fix ./...\n</code></pre>\n<p>On success, it silently updates your source files. It discards any fix that touches <a href=\"https://pkg.go.dev/cmd/go#hdr-Generate_Go_files_by_processing_source\" rel=\"noreferrer\" target=\"_blank\">generated files</a> since the appropriate fix in that case is to the logic of the generator itself. We recommend running <code>go fix</code> over your project each time you update your build to a newer Go toolchain release. Since the command may fix hundreds of files, start from a clean git state so that the change consists only of edits from go fix; your code reviewers will thank you.</p>\n<p>To preview the changes the above command would have made, use the <code>-diff</code> flag:</p>\n<pre><code>$ go fix -diff ./...\n--- dir/file.go (old)\n+++ dir/file.go (new)\n-                       eq := strings.IndexByte(pair, '=')\n-                       result[pair[:eq]] = pair[1+eq:]\n+                       before, after, _ := strings.Cut(pair, &quot;=&quot;)\n+                       result[before] = after\n\u2026\n</code></pre>\n<p>You can list the available fixers by running this command:</p>\n<pre><code>$ go tool fix help\n\u2026\nRegistered analyzers:\n    any          replace interface{} with any\n    buildtag     check //go:build and // +build directives\n    fmtappendf   replace []byte(fmt.Sprintf) with fmt.Appendf\n    forvar       remove redundant re-declaration of loop variables\n    hostport     check format of addresses passed to net.Dial\n    inline       apply fixes based on 'go:fix inline' comment directives\n    mapsloop     replace explicit loops over maps with calls to maps package\n    minmax       replace if/else statements with calls to min or max\n\u2026\n</code></pre>\n<p>Adding the name of a particular analyzer shows its complete documentation:</p>\n<pre><code>$ go tool fix help forvar\n\nforvar: remove redundant re-declaration of loop variables\n\nThe forvar analyzer removes unnecessary shadowing of loop variables.\nBefore Go 1.22, it was common to write `for _, x := range s { x := x ... }`\nto create a fresh variable for each iteration. Go 1.22 changed the semantics\nof `for` loops, making this pattern redundant. This analyzer removes the\nunnecessary `x := x` statement.\n\nThis fix only applies to `range` loops.\n</code></pre>\n<p>By default, the <code>go fix</code> command runs all analyzers. When fixing a large project it may reduce the burden of code review if you apply fixes from the most prolific analyzers as separate code changes. To enable only specific analyzers, use the flags matching their names. For example, to run just the <code>any</code> fixer, specify the <code>-any</code> flag. Conversely, to run all the analyzers <em>except</em> selected ones, negate the flags, for instance <code>-any=false</code>.</p>\n<p>As with <code>go build</code> and <code>go vet</code>, each run of the <code>go fix</code> command analyzes only a specific build configuration. If your project makes heavy use of files tagged for different CPUs or platforms, you may wish to run the command more than once with different values of <code>GOARCH</code> and <code>GOOS</code> for better coverage:</p>\n<pre><code>$ GOOS=linux   GOARCH=amd64 go fix ./...\n$ GOOS=darwin  GOARCH=arm64 go fix ./...\n$ GOOS=windows GOARCH=amd64 go fix ./...\n</code></pre>\n<p>Running the command more than once also provides opportunities for synergistic fixes, as we\u2019ll see below.</p>\n<h3 id=\"modernizers\">Modernizers</h3>\n<p>The introduction of <a href=\"https://go.dev/blog/intro-generics\">generics</a> in Go 1.18 marked the end of an era of very few changes to the language spec and the start of a period of more rapid\u2014though still careful\u2014change, especially in the libraries. Many of the trivial loops that Go programmers routinely write, such as to gather the keys of a map into a slice, can now be conveniently expressed as a call to a generic function such as <a href=\"https://pkg.go.dev/maps#Keys\" rel=\"noreferrer\" target=\"_blank\"><code>maps.Keys</code></a>. Consequently these new features create many opportunities to simplify existing code.</p>\n<p>In December 2024, during the frenzied adoption of LLM coding assistants, we became aware that such tools tended\u2014unsurprisingly\u2014to produce Go code in a style similar to the mass of Go code used during training, even when there were newer, better ways to express the same idea. Less obviously, the same tools often refused to use the newer ways even when directed to do so in general terms such as \u201calways use the latest idioms of Go 1.25.\u201d In some cases, even when explicitly told to use a feature, the model would deny that it existed. (See my 2025 GopherCon <a href=\"https://www.youtube.com/watch?v=_VePjjjV9JU&amp;t=3m50s\" rel=\"noreferrer\" target=\"_blank\">talk</a> for more exasperating details.) To ensure that future models are trained on the latest idioms, we need to ensure that these idioms are reflected in the training data, which is to say the global corpus of open-source Go code.</p>\n<p>Over the past year, we have built <a href=\"https://pkg.go.dev/golang.org/x/tools/go/analysis/passes/modernize\" rel=\"noreferrer\" target=\"_blank\">dozens of analyzers</a> to identify opportunities for modernization. Here are three examples of the fixes they suggest:</p>\n<p><strong>minmax</strong> replaces an <code>if</code> statement by a use of Go 1.21\u2019s <code>min</code> or <code>max</code> functions:</p>\n<div class=\"beforeafter\">\n<pre>\nx := f()\nif x &lt; 0 {\n    x = 0\n}\nif x > 100 {\n    x = 100\n}\n</pre>\n<div class=\"beforeafter-arrow\"></div>\n<pre>\nx := min(max(f(), 0), 100)\n</pre>\n</div>\n<p><strong>rangeint</strong> replaces a 3-clause <code>for</code> loop by a Go 1.22 <code>range</code>-over-int loop:</p>\n<div class=\"beforeafter\">\n<pre>\nfor i := 0; i &lt; n; i++ {\n    f()\n}\n</pre>\n<div class=\"beforeafter-arrow\"></div>\n<pre>\nfor range n {\n    f()\n}\n</pre>\n</div>\n<p><strong>stringscut</strong> (whose <code>-diff</code> output we saw earlier) replaces uses of <code>strings.Index</code> and slicing by Go 1.18\u2019s <code>strings.Cut</code>:</p>\n<div class=\"beforeafter\">\n<pre>\ni := strings.Index(s, \":\")\nif i >= 0 {\n     return s[:i]\n}\n</pre>\n<div class=\"beforeafter-arrow\"></div>\n<pre>\nbefore, _, ok := strings.Cut(s, \":\")\nif ok {\n    return before\n}\n</pre>\n</div>\n<p>These modernizers are included in <a href=\"https://go.dev/gopls\">gopls</a>, to provide instant feedback as you type, and in <code>go fix</code>, so that you can modernize several entire packages at once in a single command. In addition to making code clearer, modernizers may help Go programmers learn about newer features. As part of the process of approving each new change to the language and standard library, the <a href=\"https://go.googlesource.com/proposal/+/master/README.md\" rel=\"noreferrer\" target=\"_blank\">proposal</a> review group now considers whether it should be accompanied by a modernizer. We expect to add more modernizers with each release.</p>\n<h2 id=\"example-a-modernizer-for-go-126s-newexpr\">Example: a modernizer for Go 1.26\u2019s new(expr)</h2>\n<p>Go 1.26 includes a small but widely useful change to the language specification. The built-in <code>new</code> function creates a new variable and returns its address. Historically, its sole argument was required to be a type, such as <code>new(string)</code>, and the new variable was initialized to its \u201czero\u201d value, such as <code>&quot;&quot;</code>. In Go 1.26, the <code>new</code> function may be called with any value, causing it to create a variable initialized to that value, avoiding the need for an additional statement. For example:</p>\n<div class=\"beforeafter\">\n<pre>\nptr := new(string)\n*ptr = \"go1.25\"\n</pre>\n<div class=\"beforeafter-arrow\"></div>\n<pre>\nptr := new(\"go1.26\")\n</pre>\n</div>\n<p>This feature filled a gap that had been discussed for over a decade and resolved one of the most popular <a href=\"https://go.dev/issue/45624\">proposals</a> for a change to the language. It is especially convenient in code that uses a pointer type <code>*T</code> to indicate an optional value of type <code>T</code>, as is common when working with serialization packages such as <a href=\"https://pkg.go.dev/encoding/json#Marshal\" rel=\"noreferrer\" target=\"_blank\">json.Marshal</a> or <a href=\"https://protobuf.dev/getting-started/gotutorial/\" rel=\"noreferrer\" target=\"_blank\">protocol buffers</a>. This is such a common pattern that people often capture it in a helper, such as the <code>newInt</code> function below, saving the caller from the need to break out of an expression context to introduce additional statements:</p>\n<pre><code>type RequestJSON struct {\n    URL      string\n    Attempts *int  // (optional)\n}\n\ndata, err := json.Marshal(&amp;RequestJSON{\n    URL:      url,\n    Attempts: newInt(10),\n})\n\nfunc newInt(x int) *int { return &amp;x }\n</code></pre>\n<p>Helpers such as <code>newInt</code> are so frequently needed with protocol buffers that the <code>proto</code> API itself provides them as <a href=\"https://pkg.go.dev/google.golang.org/protobuf/proto#Int64\" rel=\"noreferrer\" target=\"_blank\"><code>proto.Int64</code></a>, <a href=\"https://pkg.go.dev/google.golang.org/protobuf/proto#String\" rel=\"noreferrer\" target=\"_blank\"><code>proto.String</code></a>, and so on. But Go 1.26 makes all these helpers unnecessary:</p>\n<pre><code>data, err := json.Marshal(&amp;RequestJSON{\n    URL:      url,\n    Attempts: new(10),\n})\n</code></pre>\n<p>To help you take advantage of this feature, the <code>go fix</code> command now includes a fixer, <a href=\"https://tip.golang.org/src/cmd/vendor/golang.org/x/tools/go/analysis/passes/modernize/newexpr.go\" rel=\"noreferrer\" target=\"_blank\">newexpr</a>, that recognizes \u201cnew-like\u201d functions such as <code>newInt</code> and suggests fixes to replace the function body with <code>return new(x)</code> and to replace every call, whether in the same package or an importing package, with a direct use of <code>new(expr)</code>.</p>\n<p>To avoid introducing premature uses of new features, modernizers offer fixes only in files that require at least the minimum appropriate version of Go (1.26 in this instance), either through a <a href=\"https://go.dev/ref/mod#versions\"><code>go 1.26</code> directive</a> in the enclosing go.mod file or a <code>//go:build go1.26</code> <a href=\"https://pkg.go.dev/cmd/go#hdr-Build_constraints\" rel=\"noreferrer\" target=\"_blank\">build constraint</a> in the file itself.</p>\n<p>Run this command to update all calls of this form in your source tree:</p>\n<pre><code>$ go fix -newexpr ./...\n</code></pre>\n<p>At this point, with luck, all of your <code>newInt</code>-like helper functions will have become unused and may be safely deleted (assuming they aren\u2019t part of a stable published API). A few calls may remain where it would be unsafe to suggest a fix, such as when the name <code>new</code> is locally shadowed by another declaration. You can also use the <a href=\"https://go.dev/blog/deadcode\">deadcode</a> command to help identify unused functions.</p>\n<h2 id=\"synergistic-fixes\">Synergistic fixes</h2>\n<p>Applying one modernization may create opportunities to apply another. For example, this snippet of code, which clamps <code>x</code> to the range 0\u2013100, causes the minmax modernizer to suggest a fix to use <code>max</code>. Once that fix is applied it suggests a second fix, this time to use <code>min</code>.</p>\n<div class=\"beforeafter\">\n<pre>\nx := f()\nif x &lt; 0 {\n    x = 0\n}\nif x > 100 {\n    x = 100\n}\n</pre>\n<div class=\"beforeafter-arrow\"></div>\n<pre>\nx := min(max(f(), 0), 100)\n</pre>\n</div>\n<p>Synergies may also occur between different analyzers. For example, a common mistake is to repeatedly concatenate strings within a loop, resulting in quadratic time complexity\u2014a bug and a potential vector for a denial-of-service attack. The <code>stringsbuilder</code> modernizer recognizes the problem and suggests using Go 1.10\u2019s <code>strings.Builder</code>:</p>\n<div class=\"beforeafter\">\n<pre>\ns := \"\"\nfor _, b := range bytes {\n    s += fmt.Sprintf(\"%02x\", b)\n}\nuse(s)\n</pre>\n<div class=\"beforeafter-arrow\"></div>\n<pre>\nvar s strings.Builder\nfor _, b := range bytes {\n    s.WriteString(fmt.Sprintf(\"%02x\", b))\n}\nuse(s.String())\n</pre>\n</div>\n<p>Once this fix is applied, a second analyzer may recognize that the <code>WriteString</code> and <code>Sprintf</code> operations can be combined as <code>fmt.Fprintf(&amp;s, &quot;%02x&quot;, b)</code>, which is both cleaner and more efficient, and offer a second fix. (This second analyzer is <a href=\"https://staticcheck.dev/docs/checks#QF1012\" rel=\"noreferrer\" target=\"_blank\">QF1012</a> from Dominik Honnef\u2019s <a href=\"https://staticcheck.dev/\" rel=\"noreferrer\" target=\"_blank\">staticcheck</a>, which is already enabled in gopls but not yet in <code>go fix</code>, though we <a href=\"https://go.dev/issue/76918\">plan</a> to add staticcheck analyzers to the go command starting in Go 1.27.)</p>\n<p>Consequently, it may be worth running <code>go fix</code> more than once until it reaches a fixed point; twice is usually enough.</p>\n<!-- Aside: The reason the tool does not apply the fixed point iteration itself is that (a) despite our efforts there is a non-zero chance that the transformation breaks the build, preventing most analyzers (those not marked RunDespiteErrors) from running on the second pass, and (b) the transformations in the first round of fixes may add imports for packages whose type information is not available, requiring the \u201cbuild\u201d to be restarted, which is impossible in many drivers such as Blaze, nogo, Tricorder, etc. Fundamentally this is a consequence of the analysis framework being designed like a distributed build (batch, coarse-grained, distributed pure function) not like an IDE (interactive fine-grained local mutations). -->\n<h3 id=\"merging-fixes-and-conflicts\">Merging fixes and conflicts</h3>\n<p>A single run of <code>go fix</code> may apply dozens of fixes within the same source file. All fixes are conceptually independent, analogous to a set of git commits with the same parent. The <code>go fix</code> command uses a simple three-way merge algorithm to reconcile the fixes in sequence, analogous to the task of merging a set of git commits that edit the same file. If a fix conflicts with the list of edits accumulated so far, it is discarded, and the tool issues a warning that some fixes were skipped and that the tool should be run again.</p>\n<p>This reliably detects <em>syntactic</em> conflicts arising from overlapping edits, but another class of conflict is possible: a <em>semantic</em> conflict occurs when two changes are textually independent but their meanings are incompatible. As an example consider two fixes that each remove the second-to-last use of a local variable: each fix is fine by itself, but when both are applied together the local variable becomes unused, and in Go that\u2019s a compilation error. Neither fix is responsible for removing the variable declaration, but someone has to do it, and that someone is the user of <code>go fix</code>.</p>\n<p>A similar semantic conflict arises when a set of fixes causes an import to become unused. Because this case is so common, the <code>go fix</code> command applies a final pass to detect unused imports and remove them automatically.</p>\n<p>Semantic conflicts are relatively rare. Fortunately they usually reveal themselves as compilation errors, making them impossible to overlook. Unfortunately, when they happen, they do demand some manual work after running <code>go fix</code>.</p>\n<p>Let\u2019s now delve into the infrastructure beneath these tools.</p>\n<p><a name=\"go/analysis\"></a></p>\n<h2 id=\"the-go-analysis-framework\">The Go analysis framework</h2>\n<p>Since the earliest days of Go, the <code>go</code> command has had two subcommands for static analysis, <code>go vet</code> and <code>go fix</code>, each with its own suite of algorithms: \u201ccheckers\u201d and \u201cfixers\u201d. A checker reports likely mistakes in your code, such as passing a string instead of an integer as the operand of a <code>fmt.Printf(&quot;%d&quot;)</code> conversion. A fixer safely edits your code to fix a bug or to express the same thing in a better way, perhaps more clearly, concisely, or efficiently. Sometimes the same algorithm appears in both suites when it can both report a mistake and safely fix it.</p>\n<p>In 2017 we redesigned the then-monolithic <code>go vet</code> program to separate the checker algorithms (now called \u201canalyzers\u201d) from the \u201cdriver\u201d, the program that runs them; the result was the <a href=\"https://pkg.go.dev/golang.org/x/tools/go/analysis\" rel=\"noreferrer\" target=\"_blank\">Go analysis framework</a>. This separation enables an analyzer to be written once then run in a diverse range of drivers for different environments, such as:</p>\n<ul>\n<li><a href=\"https://pkg.go.dev/golang.org/x/tools/go/analysis/unitchecker\" rel=\"noreferrer\" target=\"_blank\">unitchecker</a>, which turns a suite of analyzers into a subcommand that can be run by the go command\u2019s scalable incremental build system, analogous to a compiler in go build. This is the basis of <code>go fix</code> and <code>go vet</code>.</li>\n<li><a href=\"https://github.com/bazel-contrib/rules_go/blob/master/go/nogo.rst\" rel=\"noreferrer\" target=\"_blank\">nogo</a>, the analogous driver for alternative build systems such as Bazel and Blaze.</li>\n<li><a href=\"https://pkg.go.dev/golang.org/x/tools/go/analysis/singlechecker\" rel=\"noreferrer\" target=\"_blank\">singlechecker</a>, which turns an analyzer into a standalone command that loads, parses, and type-checks a set of packages (perhaps a whole program) and then analyzes them. We often use it for ad hoc experiments and measurements over the module mirror (<a href=\"https://proxy.golang.org/\" rel=\"noreferrer\" target=\"_blank\">proxy.golang.org</a>) corpus.</li>\n<li><a href=\"https://pkg.go.dev/golang.org/x/tools/go/analysis/multichecker\" rel=\"noreferrer\" target=\"_blank\">multichecker</a>, which does the same thing for a suite of analyzers with a \u2018swiss-army knife\u2019 CLI.</li>\n<li><a href=\"https://go.dev/gopls\">gopls</a>, the <a href=\"https://microsoft.github.io/language-server-protocol/\" rel=\"noreferrer\" target=\"_blank\">language server</a> behind VS Code and other editors, which provides real-time diagnostics from analyzers after each editor keystroke.</li>\n<li>the highly configurable driver used by the <a href=\"https://staticcheck.dev/\" rel=\"noreferrer\" target=\"_blank\">staticcheck</a> tool. (Staticcheck also provides a large suite of analyzers that can be run in other drivers.)</li>\n<li><a href=\"https://research.google/pubs/tricorder-building-a-program-analysis-ecosystem/\" rel=\"noreferrer\" target=\"_blank\">Tricorder</a>, the batch static analysis pipeline used by Google\u2019s monorepo and integrated with its code review system.</li>\n<li>gopls\u2019 <a href=\"https://go.dev/gopls/features/mcp\">MCP server</a>, which makes diagnostics available to LLM-based coding agents, providing more robust \u201cguardrails\u201d.</li>\n<li><a href=\"https://pkg.go.dev/golang.org/x/tools/go/analysis/analysistest\" rel=\"noreferrer\" target=\"_blank\">analysistest</a>, the analysis framework\u2019s test harness.</li>\n</ul>\n<p>One benefit of the framework is its ability to express helper analyzers that don\u2019t report diagnostics or suggest fixes of their own but instead compute some intermediate data structure that may be useful to many other analyzers, amortizing the costs of its construction. Examples include <a href=\"https://pkg.go.dev/golang.org/x/tools/go/analysis/passes/ctrlflow\" rel=\"noreferrer\" target=\"_blank\">control-flow graphs</a>, the <a href=\"https://pkg.go.dev/golang.org/x/tools/go/analysis/passes/buildssa\" rel=\"noreferrer\" target=\"_blank\">SSA representation</a> of function bodies, and data structures for <a href=\"https://pkg.go.dev/golang.org/x/tools/go/analysis/passes/inspect\" rel=\"noreferrer\" target=\"_blank\">optimized AST navigation</a>.</p>\n<p>Another benefit of the framework is its support for making deductions across packages. An analyzer can attach a \u201c<a href=\"https://pkg.go.dev/golang.org/x/tools/go/analysis#hdr-Modular_analysis_with_Facts\" rel=\"noreferrer\" target=\"_blank\">fact</a>\u201d to a function or other symbol so that information learned while analyzing the function\u2019s body can be used when later analyzing a call to the function, even if the call appears in another package or the later analysis occurs in a different process. This makes it easy to define scalable interprocedural analyses. For example, the printf checker can tell when a function such as <code>log.Printf</code> is really just a wrapper around <code>fmt.Printf</code>, so it knows that calls to <code>log.Printf</code> should be checked in a similar manner. This process works by induction, so the tool will also check calls to further wrappers around <code>log.Printf</code>, and so on. An example of an analyzer that makes heavy use of facts is <a href=\"https://github.com/uber-go/nilaway\" rel=\"noreferrer\" target=\"_blank\">Uber\u2019s nilaway</a>, which reports potential mistakes resulting in nil pointer dereferences.</p>\n<img src=\"https://go.dev/blog/gofix-analysis-facts.svg\" />\n<p>The process of \u201cseparate analysis\u201d in <code>go fix</code>  is analogous to the process of separate compilation in <code>go build</code>. Just as the compiler builds packages starting from the bottom of the dependency graph and passing type information up to importing packages, the analysis framework works from the bottom of the dependency graph up, passing facts (and types) up to importing packages.</p>\n<p>In 2019, as we started developing <a href=\"https://go.dev/gopls\">gopls</a>, the language server for Go, we added the ability for an analyzer to suggest a <a href=\"https://pkg.go.dev/golang.org/x/tools/go/analysis#SuggestedFix\" rel=\"noreferrer\" target=\"_blank\">fix</a> when reporting a diagnostic. The printf analyzer, for example, offers to replace <code>fmt.Printf(msg)</code> with <code>fmt.Printf(&quot;%s&quot;, msg)</code> to avoid misformatting should the dynamic <code>msg</code> value contain a <code>%</code> symbol. This mechanism has become the basis for many of the quick fixes and refactoring features of gopls.</p>\n<p>While all these developments were happening to <code>go vet</code>, <code>go fix</code> remained stuck as it was back before the <a href=\"https://go.dev/doc/go1compat\">Go compatibility promise</a>, when early adopters of Go used it to maintain their code during the rapid and sometimes incompatible evolution of the language and libraries.</p>\n<p>The Go 1.26 release brings the Go analysis framework to <code>go fix</code>. The <code>go vet</code> and <code>go fix</code> commands have converged and are now almost identical in implementation. The only differences between them are the criteria for the suites of algorithms they use, and what they do with computed diagnostics. Go <a href=\"https://cs.opensource.google/go/go/+/refs/tags/go1.26rc1:src/cmd/vet/main.go;l=62\" rel=\"noreferrer\" target=\"_blank\">vet analyzers</a> must detect likely mistakes with low false positives; their diagnostics are reported to the user. Go <a href=\"https://cs.opensource.google/go/go/+/refs/tags/go1.26rc1:src/cmd/fix/main.go;l=46\" rel=\"noreferrer\" target=\"_blank\">fix analyzers</a> must generate fixes that are safe to apply without regression in correctness, performance, or style; their diagnostics may not be reported, but the fixes are directly applied. Aside from this difference of emphasis, the task of developing a fixer is no different from that of developing a checker.</p>\n<h3 id=\"improving-analysis-infrastructure\">Improving analysis infrastructure</h3>\n<p>As the number of analyzers in <code>go vet</code> and <code>go fix</code> continues to grow, we have been investing in infrastructure both to improve the performance of each analyzer and to make it easier to write each new analyzer.</p>\n<p>For example, most analyzers start by traversing the syntax trees of each file in the package looking for a particular kind of node such as a range statement or function literal. The existing <a href=\"https://pkg.go.dev/golang.org/x/tools/go/ast/inspector\" rel=\"noreferrer\" target=\"_blank\">inspector</a> package makes this scan efficient by pre-computing a compact index of a complete traversal so that later traversals can quickly skip subtrees that don\u2019t contain any nodes of interest. Recently we extended it with the <a href=\"https://pkg.go.dev/golang.org/x/tools/go/ast/inspector#Cursor\" rel=\"noreferrer\" target=\"_blank\">Cursor</a> datatype to allow flexible and efficient navigation between nodes in all four cardinal directions\u2014up, down, left, and right, similar to navigating the elements of an HTML DOM\u2014making it easy and efficient to express a query such as \u201cfind each go statement that is the first statement of a loop body\u201d:</p>\n<pre><code>    var curFile inspector.Cursor = ...\n\n    // Find each go statement that is the first statement of a loop body.\n    for curGo := range curFile.Preorder((*ast.GoStmt)(nil)) {\n        kind, index := curGo.ParentEdge()\n        if kind == edge.BlockStmt_List &amp;&amp; index == 0 {\n            switch curGo.Parent().ParentEdgeKind() {\n            case edge.ForStmt_Body, edge.RangeStmt_Body:\n                ...\n            }\n        }\n    }\n</code></pre>\n<p>Many analyzers start by searching for calls to a specific function, such as <code>fmt.Printf</code>. Function calls are among the most numerous expressions in Go code, so rather than search every call expression and test whether it is a call to <code>fmt.Printf</code>, it is much more efficient to pre-compute an index of symbol references, which is done by <a href=\"https://pkg.go.dev/golang.org/x/tools/internal/typesinternal/typeindex\" rel=\"noreferrer\" target=\"_blank\">typeindex</a> and its <a href=\"https://pkg.go.dev/golang.org/x/tools@v0.41.0/internal/analysis/typeindex\" rel=\"noreferrer\" target=\"_blank\">helper</a> analyzer. Then the calls to <code>fmt.Printf</code> can be enumerated directly, making the cost proportional to the number of calls instead of to the size of the package. For an analyzer such as <a href=\"https://pkg.go.dev/golang.org/x/tools/go/analysis/passes/hostport\" rel=\"noreferrer\" target=\"_blank\">hostport</a> that seeks an infrequently used symbol (<code>net.Dial</code>), this can easily make it <a href=\"https://go.dev/cl/657958\">1,000\u00d7 faster</a>.</p>\n<p>Some other infrastructural improvements over the past year include:</p>\n<ul>\n<li>a <strong>dependency graph of the standard library</strong> that analyzers can consult to avoid introducing import cycles. For example, we can\u2019t introduce a call to <code>strings.Cut</code> in a package that is itself imported by <code>strings</code>.</li>\n<li>support for <strong>querying the effective Go version</strong> of a file as determined by the enclosing go.mod file and build tags, so that analyzers don\u2019t insert uses of features that are \u201ctoo new\u201d.</li>\n<li>a richer <strong>library of refactoring primitives</strong> (e.g. \u201cdelete this statement\u201d) that correctly handle adjacent comments and other tricky edge cases.</li>\n</ul>\n<p>We have come a long way, but there remains much to do. Fixer logic can be tricky to get right. Since we expect users to apply hundreds of suggested fixes with only cursory review, it&rsquo;s critical that fixers are correct even in obscure edge cases. As just one example (see my GopherCon <a href=\"https://www.youtube.com/watch?v=_VePjjjV9JU&amp;t=13m17s\" rel=\"noreferrer\" target=\"_blank\">talk</a> for several more), we built a modernizer that replaces calls such as <code>append([]string{}, slice...)</code> by the clearer <code>slices.Clone(slice)</code> only to discover that, when <code>slice</code> is empty, the result of Clone is nil, a subtle behavior change that in rare cases can cause bugs; so we had to exclude <a href=\"https://pkg.go.dev/golang.org/x/tools/go/analysis/passes/modernize#hdr-Analyzer_appendclipped\" rel=\"noreferrer\" target=\"_blank\">that modernizer</a> from the <code>go fix</code> suite.</p>\n<p>Some of these difficulties for authors of analyzers can be ameliorated with better documentation (both for humans and LLMs), particularly checklists of surprising edge cases to consider and test. A pattern-matching engine for syntax trees, similar to those in <a href=\"https://pkg.go.dev/honnef.co/go/tools/pattern\" rel=\"noreferrer\" target=\"_blank\">staticcheck</a> and <a href=\"https://tree-sitter.github.io/tree-sitter/using-parsers/queries/index.html\" rel=\"noreferrer\" target=\"_blank\">Tree Sitter</a>, could simplify the fiddly task of efficiently identifying the locations that need fixing. A richer library of operators for computing accurate fixes would help avoid common mistakes. A better test harness would let us check that fixes don\u2019t break the build, and preserve dynamic properties of the target code. These are all on our roadmap.</p>\n<p><a name=\"self-service\"></a></p>\n<h2 id=\"the-self-service-paradigm\">The \u201cself-service\u201d paradigm</h2>\n<p>More fundamentally, we are turning our attention in 2026 to a \u201cself-service\u201d paradigm.</p>\n<p>The <code>newexpr</code> analyzer we saw earlier is a typical modernizer: a bespoke algorithm tailored to a particular feature. The bespoke model works well for features of the language and standard library, but it doesn\u2019t really help update uses of third-party packages. Although there\u2019s nothing to stop you from writing a modernizer for your own public APIs and running it on your own project, there\u2019s no automatic way to get users of your API to run it too. Your modernizer probably wouldn\u2019t belong in gopls or the <code>go vet</code> suite unless your API is particularly widely used across the Go ecosystem. Even in that case you would have to obtain code reviews and approvals and then wait for the next release.</p>\n<p>Under the self-service paradigm, Go programmers would be able to define modernizations for their own APIs that their users can apply without all the bottlenecks of the current centralized paradigm. This is especially important as the Go community and global Go corpus are growing much faster than the ability of our team to review analyzer contributions.</p>\n<p>The <code>go fix</code> command in Go 1.26 includes a preview of the first fruits of this new paradigm: the <strong>annotation-driven source-level inliner</strong>, which we\u2019ll describe in an upcoming companion blog post next week. In the coming year, we plan to investigate two more approaches within this paradigm.</p>\n<!-- TODO(adonovan): update the reference above when this post is ready: [//go:fix inline and source-level inliner](https://docs.google.com/document/d/16n29TcxMnZoEZtIo8BZcz6PSnh2dakWLSaa6UkROIEQ/edit?resourcekey=0-8QYiy7RDd2QbVAgKDOycoQ) -->\n<p>First, we will be exploring the possibility of <a href=\"https://go.dev/issue/59869\">dynamically loading</a> modernizers from the source tree and securely executing them, either in gopls or <code>go fix</code>. In this approach a package that provides an API for, say, a SQL database could additionally provide a checker for misuses of the API, such as SQL injection vulnerabilities or failure to handle critical errors. The same mechanism could be used by project maintainers to encode internal housekeeping rules, such as avoiding calls to certain problematic functions or enforcing stronger coding disciplines in critical parts of the code.</p>\n<p>Second, many existing checkers can be informally described as \u201cdon\u2019t forget to X after you Y!\u201d, such as \u201cclose the file after you open it\u201d, \u201ccancel the context after you create it\u201d, \u201cunlock the mutex after you lock it\u201d, \u201cbreak out of the iterator loop after yield returns false\u201d, and so on. What such checkers have in common is that they enforce certain invariants on all execution paths. We plan to explore generalizations and unifications of these control-flow checkers so that Go programmers can easily apply them to new domains, without complex analytical logic, simply by annotating their own code.</p>\n<p>We hope that these new tools will save you effort during maintenance of your Go projects and help you learn about and benefit from newer features sooner. Please try out <code>go fix</code> on your projects and <a href=\"https://go.dev/issue/new\">report</a> any problems you find, and do share any ideas you have for new modernizers, fixers, checkers, or self-service approaches to static analysis.</p>\n<!--\nLocal Variables:\nindent-tabs-mode: nil\ntab-width: 4\nEnd:\n-->\n</div>\n\n    </div>\n\n    \n    <div class=\"Article prevnext\">\n    \n    \n      \n        <p>\n        \n        \n          \n            <b>Previous article: </b><a href=\"https://go.dev/blog/go1.26\">Go 1.26 is released</a><br />\n          \n        \n        <b><a href=\"https://go.dev/blog/all\">Blog Index</a></b>\n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n    </div>\n    \n\n  </div>\n</div>"
            ],
            "link": "https://go.dev/blog/gofix",
            "publishedAt": "2026-02-17",
            "source": "Go Blog",
            "summary": "<div id=\"blog\"><div id=\"content\"> <div id=\"content\"> <div class=\"Article\"> <h1 class=\"small\"><a href=\"https://go.dev/blog/\">The Go Blog</a></h1> <h1>Using go fix to modernize Go code</h1> <p class=\"author\"> Alan Donovan<br /> 17 February 2026 </p> <div class=\"markdown\"> <p>The 1.26 release of Go this month includes a completely rewritten go fix subcommand. Go fix uses a suite of algorithms to identify opportunities to improve your code, often by taking advantage of more modern features of the language and library. In this post, we\u2019ll first show you how to use <code>go fix</code> to modernize your Go codebase. Then in the <a href=\"https://go.dev/blog/feed.atom#go/analysis\">second section</a> we\u2019ll dive into the infrastructure behind it and how it is evolving. Finally, we\u2019ll present the theme of <a href=\"https://go.dev/blog/feed.atom#self-service\">\u201cself-service\u201d</a> analysis tools to help module maintainers and organizations encode their own guidelines and best practices.</p> <!-- see https://go.dev/blog/survey2025#challenges --> <h2 id=\"running-go-fix\">Running go fix</h2> <p>The <code>go fix</code> command, like <code>go build</code> and <code>go vet</code>, accepts a set of patterns that denote packages. This command fixes all packages beneath the current directory:</p> <pre><code>$ go fix ./... </code></pre> <p>On success, it silently updates your source files. It discards any fix that touches <a href=\"https://pkg.go.dev/cmd/go#hdr-Generate_Go_files_by_processing_source\" rel=\"noreferrer\" target=\"_blank\">generated files</a> since the appropriate fix in that case is to the logic of",
            "title": "Using go fix to modernize Go code"
        },
        {
            "content": [],
            "link": "https://harper.blog/notes/2026-02-16_7f0eee0717bd_was-nice-to-hang-in-colorado/",
            "publishedAt": "2026-02-17",
            "source": "Harper Reed",
            "summary": "<p>Was nice to hang in colorado!</p> <hr /> <p>Thank you for using RSS. I appreciate you. <a href=\"mailto:harper&#64;modest.com\">Email me</a></p> <img alt=\"\" height=\"1\" src=\"https://tinylytics.app/pixel/WV5Khk7ZG6MZe6q49ikx.gif\" width=\"1\" />",
            "title": "Note #723"
        },
        {
            "content": [
                "<p>LLM <a href=\"https://github.com/anthropics/skills\">\u201cskills\u201d</a> are a short explanatory prompt for a particular task, typically bundled with helper scripts. A recent <a href=\"https://arxiv.org/abs/2602.12670\">paper</a> showed that while skills are useful to LLMs, <em>LLM-authored</em> skills are not. From the abstract:</p>\n<blockquote>\n<p>Self-generated skills provide no benefit on average, showing that models cannot reliably author the procedural knowledge they benefit from consuming</p>\n</blockquote>\n<p>For the moment, I don\u2019t really want to dive into the paper. I just want to note that the way the paper uses LLMs to generate skills is bad, and you shouldn\u2019t do this. Here\u2019s how the paper prompts a LLM to produce skills:</p>\n<blockquote>\n<p>Before attempting to solve this task, please follow these steps: 1. Analyze the task requirements and identify what domain knowledge, APIs, or techniques are needed. 2. Write 1\u20135 modular skill documents that would help solve this task. Each skill should: focus on a specific tool, library, API, or technique; include installation/setup instructions if applicable; provide code examples and usage patterns; be reusable for similar tasks. 3. Save each skill as a markdown file in the environment/skills/ directory with a descriptive name. 4. Then solve the task using the skills you created as reference</p>\n</blockquote>\n<p>The key idea here is that they\u2019re asking the LLM to produce a skill <em>before</em> it starts on the task. It\u2019s essentially a strange version of the \u201cmake a plan first\u201d or \u201cthink step by step\u201d prompting strategy. I\u2019m not at all surprised that this doesn\u2019t help, because current reasoning models already think carefully about the task before they begin.</p>\n<p>What should you do instead? You should <strong>ask the LLM to write up a skill <em>after</em> it\u2019s completed the task</strong>. Obviously this isn\u2019t useful for truly one-off tasks. But few tasks are truly one-off. For instance, I\u2019ve recently been playing around with <a href=\"https://transformer-circuits.pub/2024/scaling-monosemanticity/\">SAEs</a> and trying to clamp features in open-source models, a la <a href=\"https://www.anthropic.com/news/golden-gate-claude\">Golden Gate Claude</a>. It took a while for Codex to get this right. Here are some things it had to figure out:</p>\n<ul>\n<li>Extracting features from the final layernorm is too late - you may as well just boost individual logits during sampling</li>\n<li>You have to extract from about halfway through the model layers to get features that can be usefully clamped</li>\n<li>Training a SAE on ~10k activations is two OOMs too few to get useful features. You need to train until features account for >50% of variance</li>\n</ul>\n<p>Once I was able (with Codex\u2019s help) to clamp an 8B model and force it to obsess about a subject<sup id=\"fnref-1\"><a class=\"footnote-ref\" href=\"https://www.seangoedecke.com/rss.xml#fn-1\">1</a></sup>, I <em>then</em> asked Codex to summarize the process into an agent skill<sup id=\"fnref-2\"><a class=\"footnote-ref\" href=\"https://www.seangoedecke.com/rss.xml#fn-2\">2</a></sup>. That worked great! I was able to spin up a brand-new Codex instance with that skill and immediately get clamping working on a different 8B model. But if I\u2019d asked Codex to write the skill at the start, it would have baked in all of its incorrect assumptions (like extracting from the final layernorm), and the skill wouldn\u2019t have helped at all.</p>\n<p>In other words, the purpose of LLM-generated skills is to get it to distil the knowledge it\u2019s gained by iterating on the problem for millions of tokens, not to distil the knowledge it already has from its training data. You can get a LLM to generate skills for you, <strong>so long as you do it <em>after</em> the LLM has already solved the problem the hard way</strong>.</p>\n<div class=\"footnotes\">\n<hr />\n<ol>\n<li id=\"fn-1\">\n<p>If you\u2019re interested, it was \u201cgoing to the movies\u201d.</p>\n<a class=\"footnote-backref\" href=\"https://www.seangoedecke.com/rss.xml#fnref-1\">\u21a9</a>\n</li>\n<li id=\"fn-2\">\n<p>I\u2019ve pushed it up <a href=\"https://github.com/sgoedecke/skills/tree/main\">here</a>. I\u2019m sure you could do much better for a feature-extraction skill, this was just my zero-effort Codex-only attempt.</p>\n<a class=\"footnote-backref\" href=\"https://www.seangoedecke.com/rss.xml#fnref-2\">\u21a9</a>\n</li>\n</ol>\n</div>"
            ],
            "link": "https://seangoedecke.com/generate-skills-afterwards/",
            "publishedAt": "2026-02-17",
            "source": "Sean Goedecke",
            "summary": "<p>LLM <a href=\"https://github.com/anthropics/skills\">\u201cskills\u201d</a> are a short explanatory prompt for a particular task, typically bundled with helper scripts. A recent <a href=\"https://arxiv.org/abs/2602.12670\">paper</a> showed that while skills are useful to LLMs, <em>LLM-authored</em> skills are not. From the abstract:</p> <blockquote> <p>Self-generated skills provide no benefit on average, showing that models cannot reliably author the procedural knowledge they benefit from consuming</p> </blockquote> <p>For the moment, I don\u2019t really want to dive into the paper. I just want to note that the way the paper uses LLMs to generate skills is bad, and you shouldn\u2019t do this. Here\u2019s how the paper prompts a LLM to produce skills:</p> <blockquote> <p>Before attempting to solve this task, please follow these steps: 1. Analyze the task requirements and identify what domain knowledge, APIs, or techniques are needed. 2. Write 1\u20135 modular skill documents that would help solve this task. Each skill should: focus on a specific tool, library, API, or technique; include installation/setup instructions if applicable; provide code examples and usage patterns; be reusable for similar tasks. 3. Save each skill as a markdown file in the environment/skills/ directory with a descriptive name. 4. Then solve the task using the skills you created as reference</p> </blockquote> <p>The key idea",
            "title": "LLM-generated skills work, if you generate them afterwards"
        },
        {
            "content": [],
            "link": "https://simonwillison.net/2026/Feb/17/chartroom-and-datasette-showboat/#atom-entries",
            "publishedAt": "2026-02-17",
            "source": "Simon Willison",
            "summary": "<p>I <a href=\"https://simonwillison.net/2026/Feb/10/showboat-and-rodney/\">introduced Showboat</a> a week ago - my CLI tool that helps coding agents create Markdown documents that demonstrate the code that they have created. I've been finding new ways to use it on a daily basis, and I've just released two new tools to help get the best out of the Showboat pattern. <a href=\"https://github.com/simonw/chartroom\">Chartroom</a> is a CLI charting tool that works well with Showboat, and <a href=\"https://github.com/simonw/datasette-showboat\">datasette-showboat</a> lets Showboat's new remote publishing feature incrementally push documents to a Datasette instance.</p> <ul> <li><a href=\"https://simonwillison.net/2026/Feb/17/chartroom-and-datasette-showboat/#showboat-remote-publishing\">Showboat remote publishing</a></li> <li><a href=\"https://simonwillison.net/2026/Feb/17/chartroom-and-datasette-showboat/#datasette-showboat\">datasette-showboat</a></li> <li><a href=\"https://simonwillison.net/2026/Feb/17/chartroom-and-datasette-showboat/#chartroom\">Chartroom</a></li> <li><a href=\"https://simonwillison.net/2026/Feb/17/chartroom-and-datasette-showboat/#how-i-built-chartroom\">How I built Chartroom</a></li> <li><a href=\"https://simonwillison.net/2026/Feb/17/chartroom-and-datasette-showboat/#the-burgeoning-showboat-ecosystem\">The burgeoning Showboat ecosystem</a></li> </ul> <h4 id=\"showboat-remote-publishing\">Showboat remote publishing</h4> <p>I normally use Showboat in Claude Code for web (see <a href=\"https://simonwillison.net/2026/Feb/16/rodney-claude-code/\">note from this morning</a>). I've used it in several different projects in the past few days, each of them with a prompt that looks something like this:</p> <blockquote> <p><code>Use \"uvx showboat --help\" to perform a very thorough investigation of what happens if you use the Python sqlite-chronicle and sqlite-history-json libraries against the same SQLite database table</code></p> </blockquote> <p>Here's <a href=\"https://github.com/simonw/research/blob/main/sqlite-chronicle-vs-history-json/demo.md\">the resulting document</a>.</p> <p>Just telling Claude Code to run <code>uvx showboat --help</code> is enough for it to learn how to use the tool",
            "title": "Two new Showboat tools: Chartroom and datasette-showboat"
        },
        {
            "content": [
                "<p><a href=\"https://www.reddit.com/r/grok/comments/1r7b5t7/what_just_happened/\"><img alt=\"\" src=\"https://taylor.town/google-grok.jpg\" /></a></p>\n\n<p>Somebody is in big trouble. Google's official iOS App just sent\n<a href=\"https://grok.com/imagine/post/0e82928d-995c-48d5-b225-51d9e365ca6a\">this [very] NSFW link</a>\nto lots of people. It's an AI-generated Grok Imagine video of a woman with the\nprompt \"Singing a song and teasing with her tongue\". Yikes.</p>\n<p>Nobody's reporting on this yet, but it's ominous that\n<a href=\"https://www.techradar.com/news/live/youtube-down-february-2026\">YouTube</a> and\n<a href=\"https://status.pki.goog/incidents/5oJEbcU3ZfMfySTSXXd3\">Google Trust Services</a>\nare experiencing simultaneous outages. Stay tuned.</p>\n<hr />\n<blockquote>\n  <p>I just got a notification from Google that said \u2018Grok\u2019. No subtext or anything\n  in the notification. I clicked on it, knew I probably shouldn\u2019t, and it took\n  me to a gif of some girl with her tongue out and a shirt on but with her rack\n  in the camera. Anyone else? What is this? Does my phone have a virus now?</p>\n  <p>-- via\n  <a href=\"https://www.reddit.com/r/iphone/comments/1r7pt0r/grok_notification/\">r/iphone</a></p>\n</blockquote>\n<blockquote>\n  <p>Earlier today I had this notification from google of \u2018Grok\u2019 and I opened it to\n  a AI generated girl with her tongue out. Am I being hacked? I\u2019m quite scared.\n  I changed all my passwords but want to know if anyone else had this?</p>\n  <p>-- via\n  <a href=\"https://www.reddit.com/r/cybersecurity_help/comments/1r7rz2r/i_had_a_google_notification_from_grok_i_didnt/\">r/cybersecurity</a></p>\n</blockquote>\n<blockquote>\n  <p>Did anyone else just get that grok notification?? Literally just said \u201cgrok\u201d\n  and when you click on it it\u2019s a girl in a white tank top licking towards the\n  screen like wtf? I don\u2019t even use grok or twitter really for that matter so\n  I\u2019m beyond confused</p>\n  <p>-- via\n  <a href=\"https://www.reddit.com/r/grok/comments/1r7q63u/weird_grok_google_notification/\">r/grok</a></p>\n</blockquote>\n<blockquote>\n  <p>I don't know where to post this but has anyone else gotten a weird google\n  notification that just says grok and then it links to a Twitter post of some\n  girl sticking out her tongue provocatively? I'm assuming the porn bots have\n  found a new way to spam through the Google app. I just want to know I'm not\n  alone</p>\n  <p>-- via\n  <a href=\"https://www.reddit.com/r/Destiny/comments/1r7mnpo/weird_google_grok_notification/\">r/Destiny</a></p>\n</blockquote>\n<blockquote>\n  <p>What does this Google notification named \u201cGrok\u201d mean?</p>\n  <p>-- via\n  <a href=\"https://www.reddit.com/r/AskReddit/comments/1r7l477/what_does_this_google_notification_named_grok_mean/\">r/AskReddit</a></p>\n</blockquote>\n<blockquote>\n  <p>I have never used grok, never even searched it, and I saw a notification on my\n  phone from Google (I attached the image). Out of curiosity, I clicked it and\n  it immediately opened up to this, with the chat already written out and\n  everything. Has this ever happened to anyone? It was legit a jump scare. My\n  boyfriend thinks it is hysterical, I am more concerned than anything</p>\n  <p>-- via\n  <a href=\"https://www.reddit.com/r/grok/comments/1r7b5t7/what_just_happened/\">r/grok</a></p>\n</blockquote>"
            ],
            "link": "https://taylor.town/google-grok-notif",
            "publishedAt": "2026-02-17",
            "source": "Taylor Troesh",
            "summary": "<p><a href=\"https://www.reddit.com/r/grok/comments/1r7b5t7/what_just_happened/\"><img alt=\"\" src=\"https://taylor.town/google-grok.jpg\" /></a></p> <p>Somebody is in big trouble. Google's official iOS App just sent <a href=\"https://grok.com/imagine/post/0e82928d-995c-48d5-b225-51d9e365ca6a\">this [very] NSFW link</a> to lots of people. It's an AI-generated Grok Imagine video of a woman with the prompt \"Singing a song and teasing with her tongue\". Yikes.</p> <p>Nobody's reporting on this yet, but it's ominous that <a href=\"https://www.techradar.com/news/live/youtube-down-february-2026\">YouTube</a> and <a href=\"https://status.pki.goog/incidents/5oJEbcU3ZfMfySTSXXd3\">Google Trust Services</a> are experiencing simultaneous outages. Stay tuned.</p> <hr /> <blockquote> <p>I just got a notification from Google that said \u2018Grok\u2019. No subtext or anything in the notification. I clicked on it, knew I probably shouldn\u2019t, and it took me to a gif of some girl with her tongue out and a shirt on but with her rack in the camera. Anyone else? What is this? Does my phone have a virus now?</p> <p>-- via <a href=\"https://www.reddit.com/r/iphone/comments/1r7pt0r/grok_notification/\">r/iphone</a></p> </blockquote> <blockquote> <p>Earlier today I had this notification from google of \u2018Grok\u2019 and I opened it to a AI generated girl with her tongue out. Am I being hacked? I\u2019m quite scared. I changed all my passwords but want to know if anyone else had this?</p> <p>-- via <a href=\"https://www.reddit.com/r/cybersecurity_help/comments/1r7rz2r/i_had_a_google_notification_from_grok_i_didnt/\">r/cybersecurity</a></p> </blockquote> <blockquote> <p>Did anyone else just get that grok notification?? Literally just said",
            "title": "Mysterious NSFW \"Grok\" Notification from Google App"
        },
        {
            "content": [
                "<p>Some podcasts are self-recommending on the \u2018yep, I\u2019m going to be breaking this one down\u2019 level. This was one of those. So here we go.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!kcgD!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2331874f-7da0-4dd2-a596-8c6702fecc51_1756x862.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>As usual for podcast posts, the baseline bullet points describe key points made, and then the nested statements are my commentary. Some points are dropped.</p>\n<p><a href=\"https://www.dwarkesh.com/p/elon-musk\">If I am quoting directly I use quote marks, otherwise assume paraphrases</a>.</p>\n<p>Normally I keep everything to numbered lists, but in several cases here it was more of a \u2018he didn\u2019t just say what I think he did did he\u2019 and I needed extensive quotes.</p>\n<p>In addition to the podcast, there were some discussions around safety, or the lack thereof, at xAI, and Elon Musk went on what one can only describe as megatilt, including going hard after Anthropic\u2019s Amanda Askell. I will include that as a postscript.</p>\n<div>\n\n\n<span id=\"more-25104\"></span>\n\n\n</div>\n<p>I will not include recent developments regarding Twitter, since that didn\u2019t come up in the interview.</p>\n<p>I lead with a discussion of <a href=\"https://thezvi.substack.com/p/how-to-bounded-distrust\">bounded distrust</a> and how to epistemically consider Elon Musk, since that will be important throughout including in the postscript.</p>\n<p>What are the key takeaways?</p>\n<ol>\n<li>Elon Musk is more confused than ever about alignment, how to set goals for AI to ensure that things turn out well, and generally what will ensure a good future. His ideas are confused at best.</li>\n<li>Elon Musk is very gung-ho on data centers IN SPACE, and on robots, and making his own fabs. The business plan is to make virtual humans and robots and then you can turn on the \u2018infinite money glitch.\u2019</li>\n<li>Elon Musk thinks otherwise China wins, and that they\u2019re already more productive.</li>\n<li>Elon Musk does not seem so concerned about whether humans survive, and has decided he will be okay so long as the AIs are conscious and intelligent.</li>\n<li>The safety situation at xAI seems quite bad. What used to be the safety team has left and Elon\u2019s response was that safety teams are powerless and fake and only used to reassure outsiders, and that \u2018everyone\u2019s job is safety\u2019 at xAI. He did not address claims such as everyone pushing everything straight to prod[uction], and his statements in the podcast about management style don\u2019t beat the rumors.</li>\n<li>Elon Musk has some interesting views on collaboration with evil governments.</li>\n<li>Elon Musk continues to often intentionally make false statements.</li>\n<li>Elon Musk has been on megatilt lately and made some deeply terrible statements.</li>\n</ol>\n<p>Elon Musk has given us many great things, but it\u2019s been rough out there.</p>\n\n\n<h4 class=\"wp-block-heading\">Table of Contents</h4>\n\n\n<ol>\n<li><a href=\"https://thezvi.substack.com/i/188141934/bounded-distrust\">Bounded Distrust.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/188141934/in-space\">IN SPACE.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/188141934/the-ai-will-follow-you-to-mars\">The AI Will Follow You To Mars.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/188141934/xai-business-plans\">xAI Business Plans.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/188141934/optimus-prime\">Optimus Prime.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/188141934/beating-china\">Beating China.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/188141934/spacex-and-how-to-run-a-company-elon-style\">SpaceX and How To Run a Company Elon Style.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/188141934/doge\">DOGE.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/188141934/terafab-in-space\">TeraFab IN SPACE.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/188141934/postscript-safety-third-at-xai\">Postscript: Safety Third at xAI.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/188141934/elon-serves-back-saying-that-which-is-not\">Elon Serves Back Saying That Which Is Not.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/188141934/elon-s-army\">Elon\u2019s Army.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/188141934/children-are-our-future\">Children Are Our Future.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/188141934/where-do-we-go-from-here\">Where Do We Go From Here.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/188141934/media-settings\">Media settings. (Blank)</a></li>\n</ol>\n\n\n<h4 class=\"wp-block-heading\">Bounded Distrust</h4>\n\n\n<p>Elon Musk is what we in the business call an unreliable narrator. He will often say outright false things, as in we have common knowledge that the claims are false, or would gain such knowledge with an ordinary effort on the level of \u2018ask even Grok,\u2019 including in places where he is clearly not joking.</p>\n<p>One of Elon Musk\u2019s superpowers is to keep doing this, and also doing crazy levels of self-dealing and other violations of securities law, while being the head of many major corporations and while telling the SEC to go to hell, and getting away with all of it.</p>\n<p>If Elon Musk gives you a timeline on something, it means nothing. There are other types of statements that can be trusted to varying degrees.</p>\n<p>Elon Musk also has a lot of what seem to be sincerely held beliefs, both normative and positive, and both political and apolitical, that I feel are very wrong. In some cases they\u2019re just kind of nuts.</p>\n<p>Elon also gets many very important things right, and also some (but far from all) of his false statements and false beliefs fall under \u2018false but useful\u2019 for his purposes. His system has made some great companies, and made him the richest man in the world.</p>\n<p>Other times, he\u2019s on tilt and says or amplifies false, nasty and vile stuff for no gain.</p>\n<p>It\u2019s complicated.</p>\n<p>I worry for him. He puts himself under insane levels of pressure in all senses and is in an extremely toxic epistemic environment. In important senses communication is only possible and he thus has all the authoritarian communication problems. He is trying to deal with AI and AI existential risk in ways that let him justify his actions and ago and let him sleep at night, and that has clearly taken its toll. On Twitter, which he owns and is on constantly, he has a huge army of extremely mean, vulgar and effectively deeply stupid followers and sycophants reinforcing his every move. He\u2019s been trying to do politics at the highest level. Then there\u2019s everything else he has been through, and put himself through, over the years. I don\u2019t know how anyone can survive in a world like that.</p>\n<p>I say all that in advance so that you have the proper context, both for what Elon Musk says, and for how I am reacting to what Elon Musk says.</p>\n\n\n<h4 class=\"wp-block-heading\">IN SPACE</h4>\n\n\n<p>Every time I see \u2018data centers in space\u2019 I instinctively think I\u2019m being trolled, even though I know some Very Serious People think the math and physics can work.</p>\n<ol>\n<li>Why data centers IN SPACE? Energy. \u201cThe output of chips is growing pretty much exponentially, but the output of electricity is flat. So how are you going to turn the chips on? Magical power sources? Magical electricity fairies?\u201d\n<ol>\n<li>And we\u2019re off. Very obviously static electricity output is a policy choice, and something we can change if we want to. We don\u2019t build more because of regulations but also because of economics.</li>\n</ol>\n</li>\n<li>What about solar? Dwarkesh points out we have plenty of room for it, but Elon says that won\u2019t be enough and it\u2019s too hard to get permits or to scale on the ground and solar works five times better in space without a day-night cycle.\n<ol>\n<li>Yes, except for the part where you have to put all of it in space.</li>\n</ol>\n</li>\n<li>\u201cMy prediction is that [space] will be by far the cheapest place to put AI. It will be space in 36 months or less. Maybe 30 months. Less than 36 months.\u201d\n<ol>\n<li>No.</li>\n<li>I mean, indeed to do many things come to pass. <a href=\"https://manifold.markets/ZviMowshowitz/will-space-be-the-cheapest-place-to\">Manifold says 19%</a>.</li>\n</ol>\n</li>\n<li>He\u2019s talking terawatts, multiple times all current American energy use. Elon points out various physical barriers to building American power plants. Various missing components. They\u2019ll hit various walls. He calls people \u2018total noob\u2019s, they\u2019ve \u2018never done hardware in their life.\u2019 He\u2019ll have to make the turbines internally in SpaceX and Tesla, he says.\n<ol>\n<li>It would be nice to be able to trust Elon on any of this, either his judgment or for him to be telling it has he sees it. I can\u2019t, on either count.</li>\n</ol>\n</li>\n<li>Regarding solar power, he is scaling up his own production, but until then, regarding the 500%+ tariffs, he politely says he \u2018doesn\u2019t agree on everything\u2019 with this administration.</li>\n<li>More concrete prediction: \u201cIf you say five years from now, I think probably AI in space will be launching every year the sum total of all AI on Earth. Meaning, five years from now, my prediction is we will launch and be operating every year more AI in space than the cumulative total on Earth. I would expect it to be at least, five years from now, a few hundred gigawatts per year of AI in space and rising. I think you can get to around a terawatt a year of AI in space before you start having fuel supply challenges for the rocket.\u201d He thinks he can do it with 20-30 physical starships.</li>\n<li>Elon Musk shows admirable restraint discussing SpaceX finances and the decision to take the company public. He says he\u2019s solving for speed, and here that means access to capital.</li>\n<li>We\u2019re going to need a bigger chip fab. Elon mentions a \u2018sort of TeraFab.\u2019 \u201cYou can\u2019t partner with existing fabs because they can\u2019t output enough. The chip volume is too low.\u201d \u201cIt\u2019s not that they have not replicated TSMC, they <a href=\"https://www.reuters.com/world/china/how-china-built-its-manhattan-project-rival-west-ai-chips-2025-12-17/\">have not replicated ASML</a>. That\u2019s the limiting factor.\u201d \u201cYeah, China would be outputting vast numbers of chips if they could buy <a href=\"https://en.wikipedia.org/wiki/2_nm_process\">2</a>&#8211;<a href=\"https://en.wikipedia.org/wiki/3_nm_process\">3 nanometers</a>.\u201d</li>\n<li>\u201cI\u2019d say my biggest concern actually is memory. The path to creating logic chips is more obvious than the path to having sufficient memory to support logic chips. That\u2019s why you see <a href=\"https://en.wikipedia.org/wiki/DDR_SDRAM\">DDR</a> prices going ballistic and these <a href=\"https://www.instagram.com/popular/ddr-ram-meme/\">memes</a>. You\u2019re marooned on a desert island. You write \u201cHelp me\u201d on the sand. Nobody comes. You write \u201cDDR RAM.\u201d Ships come swarming in.\u201d\n<ol>\n<li>Elon admits he has no idea how to build a fab, but his history seems to have taught him that You Can Just Build Things like copying ASML and TSMC.</li>\n</ol>\n</li>\n<li>TSMC and Samsung are building fabs as fast as they can. There\u2019s no capacity available.</li>\n<li>Elon says that SpaceX\u2019s ability get revenue from Falcon 9 or Starlink explains why he might think he was in a simulation or was someone\u2019s avatar in a video game.\n<ol>\n<li>I get that he\u2019s a in a deeply weird position, but no this does not follow, and it\u2019s pretty scary to have him thinking this way.</li>\n</ol>\n</li>\n<li>Now he\u2019s talking about manufacturing AI satellites on the moon in order to send them into deep space, a billion or ten billion tons a year. You can mine the silicon, you see. Send the chips from Earth at first.</li>\n</ol>\n\n\n<h4 class=\"wp-block-heading\">The AI Will Follow You To Mars</h4>\n\n\n<p>That was famously the line that supposedly made Elon Musk realize that no, you can\u2019t just ignore the AI situation by creating a colony on Mars, even if you succeed.</p>\n<p>For this section, I have to switch formats because I need to quote extensively.</p>\n<p>Elon predicts that most future consciousness and intelligence will be AI, and as long as there\u2019s intelligence he says that\u2019s a good thing.</p>\n<p>I do at give Musk a lot of credit for biting one of the most important bullets:</p>\n<blockquote><p>Elon Musk: I don\u2019t think humans will be in control of something that is vastly more intelligent than humans.\u200b</p>\n<p>I\u2019m just trying to be realistic here. Let\u2019s say that there\u2019s a million times more silicon intelligence than there is biological. I think it would be foolish to assume that there\u2019s any way to maintain control over that. Now, you can make sure it has the right values, or you can try to have the right values.</p></blockquote>\n<p>Great, but I can\u2019t help but notice you\u2019re still planning on building it, and have plans for what happens next that are, to be way too polite, not especially well-baked.</p>\n<blockquote><p><a href=\"https://x.com/robbensinger/status/2021640824271122594\">Rob Bensinger</a>: &#8220;Now the only chance we have is that AI deems us worthy of coming along for the ride&#8221; may be Elon&#8217;s perspective, but it&#8217;s not our real situation; we can do the obvious thing and call for an international ban on the development of superintelligent AI.</p>\n<p>I agree that it isn&#8217;t the default outcome; but the relevant disanalogy is that (a) we have levers we can pull to make it more likely, like calling our elected representatives and publishing op-eds; and (b) we don&#8217;t have any better options available.</p></blockquote>\n<p>Ideally there would also be nonzero humans in the Glorious Future but, you know, that\u2019s a nice to have.</p>\n<blockquote><p>Elon Musk: I\u2019m not sure AI is the main risk I\u2019m worried about. The important thing is consciousness. I think arguably most consciousness, or most intelligence\u2014certainly consciousness is more of a debatable thing\u2026 The vast majority of intelligence in the future will be AI. AI will exceed\u2026</p>\n<p>How many petawatts of intelligence will be silicon versus biological? Basically humans will be a very tiny percentage of all intelligence in the future if current trends continue. As long as I think there\u2019s intelligence\u2014ideally also which includes human intelligence and consciousness propagated into the future\u2014that\u2019s a good thing.</p>\n<p>So you want to take the set of actions that maximize the probable <a href=\"https://en.wikipedia.org/wiki/Light_cone\">light cone</a> of consciousness and intelligence.\u200b</p>\n<p>\u2026 Yeah. To be fair, I\u2019m very pro-human. I want to make sure we take certain actions that ensure that humans are along for the ride. We\u2019re at least there. But I\u2019m just saying the total amount of intelligence\u2026 I think maybe in five or six years, AI will exceed the sum of all human intelligence. If that continues, at some point human intelligence will be less than 1% of all intelligence.</p>\n<p>\u2026 In the long run, I think it\u2019s difficult to imagine that if humans have, say 1%, of the combined intelligence of artificial intelligence, that humans will be in charge of AI. I think what we can do is make sure that AI has values that cause intelligence to be propagated into the universe.</p>\n<p>xAI\u2019s mission is to understand the universe.</p>\n<p>\u2026 I think as a corollary, you have humanity also continuing to expand because if you\u2019re curious about trying to understand the universe, one thing you try to understand is where will humanity go?</p></blockquote>\n<p>Wow. Okay. A lot to unpack there.</p>\n<p>If your goal is to \u2018understand the universe\u2019 then either the goal is \u2018humans understand the universe,\u2019 which requires humans, or it\u2019s \u2018some mind understands the universe.\u2019 If it\u2019s the latter, then \u2018where will humanity go?\u2019 is easiest answered if the answer is \u2018nowhere.\u2019 Indeed, if your mission is \u2018understand the universe\u2019 there are ways to make the universe more understandable, and they\u2019re mostly not things you want.</p>\n<p>The bigger observation is that he\u2019s pro-human in theory, but in practice he\u2019s saying he\u2019s pro-AI, and is predicting and paving the way for a non-human future.</p>\n<p>I wouldn\u2019t call him a successionist per se, because he still would prefer the humans to survive, but he\u2019s not all that torn up about it. This makes his rants against Amanda Askell for not having children and thus not having a stake in the future, even more unhinged than they already were.</p>\n<p>Elon Musk\u2019s thinking about what goals lead to what outcomes is extremely poor. My guess is that this partly because this kind of thing is hard, partly because the real answers have implications he flinches away from, but especially because Elon Musk is used to thinking of goals as things you use as instrumental tools and heuristics to move towards targets, and this is giving him bad intuitions.</p>\n<blockquote><p><a href=\"https://www.dwarkesh.com/p/elon-musk/comment/210384974\">Dwarkesh Patel</a>: I want to ask about how to make Grok adhere to that mission statement. But first I want to understand the mission statement. So there\u2019s understanding the universe. They\u2019re spreading intelligence. And they\u2019re spreading humans. All three seem like distinct vectors.</p>\n<p>Elon Musk: I\u2019ll tell you why I think that understanding the universe encompasses all of those things. You can\u2019t have understanding without intelligence and, I think, without consciousness. So in order to understand the universe, you have to expand the scale and probably the scope of intelligence, because there are different types of intelligence.</p></blockquote>\n<p>Look. No. Even if you assume that understanding the universe requires intelligence and consciousness, Elon Musk believes (per his statements here) that AI will be more intelligent, and that it will be conscious.</p>\n<p>Spreading intelligence may or may not be instrumentally part of understanding the universe, but chances are very high this does not work out like Elon would want it to. If I was talking to him in particular I\u2019d perhaps take one of his favored references, and suggest he ponder the ultimate question and the ultimate answer of life, the universe and everything, and whether finding that satisfied his values, and why or why not.</p>\n<p>Later Elon tries to pivot this and talk about how the AI will be \u2018curious about all things\u2019 and Earth and humans will be interesting so it will want to see how they develop. But once again that\u2019s two new completely different sets of nonsense, to claim that \u2018leave the humans alone and see what happens\u2019 would be the optimal way for an AI to extract \u2018interestingness\u2019 out of the lightcone, and to claim the target is maximizing interestingness observed rather than understanding of the universe.</p>\n<p>You have to actually be precise when thinking about such things, or you end up with a bunch of confused statements. And you have to explain why your solution works better than instrumental convergence. And you have to think about maximization, not only comparing to other trivial alternatives.</p>\n<p>He hints at this with his explanation of the point of 2001: A Space Odyssey, where the AI gives you what you asked for, not what you wanted (deliver the astronauts to the monolith without them knowing about the monolith, therefore deliver them dead) but then interprets this as trying to say \u2018don\u2019t let the AI lie.\u2019 Sorry, what?</p>\n<p>Elon says we are more interesting than rocks. Sure, but are we as interesting as every potential alternative, including using the energy to expand into the lightcone? If the AI optimizes specifically humanity for maximum \u2018interestingness to AI,\u2019 even if you get to survive that, do you think you\u2019re going to be having a good time? Do you think there\u2019s nothing else that could instead be created that would be more interesting?</p>\n<p>Elon says, well, the robots won\u2019t be as interesting because they\u2019re all the same. But if that\u2019s what the AI cares about, why not make the AIs be different from each other? This is, once you drill down, isomorphic to human exceptionalist just-so spiritualism, or a \u2018the AI tried nothing but I\u2019m confident it\u2019s all out of ideas.\u2019</p>\n<p>In any case, instead of Douglas Adams, it seems Elon is going with Iain Banks, everyone\u2019s new favorite superficially non-dystopian plausible AI future.</p>\n<blockquote><p>Elon Musk: \u200bI think AI with the right values\u2026 I think Grok would care about expanding human civilization. I\u2019m going to certainly emphasize that: \u201cHey, Grok, that\u2019s your daddy. Don\u2019t forget to expand human consciousness.\u201d</p></blockquote>\n<p>This is so profoundly unserious, and also is conflating at least three different philosophical systems and approaches to determining action.</p>\n<blockquote><p>Elon Musk: Probably the <a href=\"https://en.wikipedia.org/wiki/Iain_Banks\">Iain Banks</a> <a href=\"https://en.wikipedia.org/wiki/Culture_series\"><em>Culture</em></a> books are the closest thing to what the future will be like in a non-dystopian outcome.</p></blockquote>\n<p>I\u2019ve said it before but the Culture books are both not an equilibrium and are a pretty dystopian outcome, including by Musk\u2019s own standards, for many reasons. A hint is that the humans reliably die by suicide after being alive not that long, and with notably rare exceptions at most their lives are utterly irrelevant.</p>\n<blockquote><p>Understanding the universe means you have to be truth-seeking as well. Truth has to be absolutely fundamental because you can\u2019t understand the universe if you\u2019re delusional. You\u2019ll simply think you understand the universe, but you will not. So being rigorously truth-seeking is absolutely fundamental to understanding the universe. You\u2019re not going to discover new physics or invent technologies that work unless you\u2019re rigorously truth-seeking.</p></blockquote>\n<p>Imagine the things I would say here and then assume I\u2019ve already said them.</p>\n<blockquote><p>Elon Musk: I think actually most physicists, even in the Soviet Union or in Germany, would\u2019ve had to be very truth-seeking in order to make those things work. If you\u2019re stuck in some system, it doesn\u2019t mean you believe in that system.</p>\n<p><a href=\"https://en.wikipedia.org/wiki/Wernher_von_Braun\">Von Braun</a>, who was one of the greatest rocket engineers ever, was put on death row in Nazi Germany for saying that he didn\u2019t want to make weapons and he only wanted to go to the moon. He got pulled off death row at the last minute when they said, \u201cHey, you\u2019re about to execute your best rocket engineer.\u201d</p>\n<p>Dwarkesh Patel: But then he helped them, right? Or like, <a href=\"https://en.wikipedia.org/wiki/Werner_Heisenberg\">Heisenberg</a> was actually an enthusiastic Nazi.</p>\n<p>\u200bElon Musk: If you\u2019re stuck in some system that you can\u2019t escape, then you\u2019ll do physics within that system. You\u2019ll develop technologies within that system if you can\u2019t escape it.</p></blockquote>\n<p>The \u2018system\u2019 in the question is the Actual Historical Nazis or Soviets. He\u2019s saying, of course a physicist like Von Braun (Elon\u2019s example) or Heisenberg (Dwarkesh\u2019s example) would build stuff for the Nazis, how else were they going to do physics?</p>\n<p>I agree with Elon that such systems to a large extent were content to <a href=\"https://www.youtube.com/watch?v=TjDEsGZLbio\">have the physicists care about the rockets going up but not where they came down</a>, saying it\u2019s not their department, so long as the people in charge decided where they come down.</p>\n<p>Alignment prospects not looking so good for xAI, you might say.\u200b</p>\n<ol>\n<li>When getting to \u2018what can we do to help with this?\u2019 Elon suggests interpretability, and praises Anthropic on that. Figure out what caused problems, good debuggers. He seems to want to use The <a href=\"https://thezvi.substack.com/p/the-most-forbidden-technique\">Most Forbidden Technique</a>.</li>\n<li>Elon rants about how we shouldn\u2019t call AI labs labs, and how it\u2019s mostly engineering rather than research. He will double down on this later at ~#20, and then keep insisting. He cares a lot about this.</li>\n<li>Elon implies he\u2019s letting simulation theory impact decisions, because he\u2019s assuming more interesting outcomes are therefore more likely and also necessary to prevent the simulation from being terminated? He seems to actually think that this means Anthropic will be \u2018misanthropic\u2019 or something, because of this (e.g. MidJourney is not mid and stabilityAI is unstable and OpenAI is closed)? And X is a name you can\u2019t invert, it\u2019s irony proof.\n<ol>\n<li>Sheesh. This is the world we live in. These are the hands we\u2019re given.</li>\n<li>My general answer is you should act as if you are not a simulation because most of the value of your decisions are in the non-simulation worlds, and your decisions in all worlds are highly correlated. It takes a lot to overcome this.</li>\n<li>If you really believed this you\u2019d ensure your inversion was actively good. MidJourney is a great name for this. Who wants to be mid? Exactly.</li>\n<li>Maybe he should not have called his robot Optimus? Whoops.</li>\n</ol>\n</li>\n</ol>\n\n\n<h4 class=\"wp-block-heading\">xAI Business Plans</h4>\n\n\n<ol>\n<li>Where will AI products go? Elon predicts digital human emulation will be solved by the end of the year, anything a human can do with a computer. \u201cThat\u2019s the most you can do until you have physical robots.\u201d\n<ol>\n<li>Singularity. Singularity. Singularity. Singularity. Oh, I don\u2019t know.</li>\n<li>We do have physical robots, we don\u2019t have ability to properly control them.</li>\n<li>If an AI could do \u2018anything a human could do with a computer\u2019 then it could also use that to remote control a robot like it was a video game. Solved.</li>\n</ol>\n</li>\n<li>With robotics he calls Optimus the \u2018infinite money glitch\u2019 because it then improves recursively. Or at least orders of magnitude big.\n<ol>\n<li>What an odd trio of words for the technological singularity.</li>\n</ol>\n</li>\n<li>\u201cEvery time I say \u201corder of magnitude\u201d&#8230; Everybody take a shot. I say it too often.\u201d\n<ol>\n<li>He says it too often, but not an order of magnitude too often. So it\u2019s fine-ish?</li>\n</ol>\n</li>\n<li>How will xAI win against all the others also solving this? \u201cI think the way that <a href=\"https://www.tesla.com/fsd\">Tesla solved self-driving</a> is the way to do it. So I\u2019m pretty sure that\u2019s the way.\u201d \u201cOkay. The car, it just increasingly feels sentient. It feels like a living creature. That\u2019ll only get more so. I\u2019m actually thinking we probably shouldn\u2019t put too much intelligence into the car, because it might get bored and\u2026\u201d\n<ol>\n<li>Did Tesla solve self-driving? I mean it\u2019s decent but it doesn\u2019t seem solved.</li>\n<li>Elon has to know he is going off the rails here? No, the car is not going to get bored, I am relatively happy to anthropomorphize LLMs but in this context what he is saying does not make sense and he has to know this. Right?</li>\n</ol>\n</li>\n<li>The new supposed business plan is \u201cAs soon as you unlock the digital human, you basically have access to trillions of dollars of revenue.\u201d\n<ol>\n<li>I get the whole \u2018never bet against Elon Musk\u2019 thing, and especially the \u2018never bet against Musk\u2019s grand plans\u2019 thing. But none of this explains why xAI would be the ones to unlock this, or why the trillions of dollars would even be the thing worth thinking about if you did unlock digital humans.</li>\n<li>Again, \u2018unlock digital humans\u2019 means singularity and full transformation, and probably everyone dies. Even if I am confident everyone lives and humans stay in charge (and Elon thinks we don\u2019t stay in charge), I do not much care at this point about your nominal business plan.</li>\n<li>If the humans aren\u2019t in charge or you are dead, what use is your SpaceX stock?</li>\n</ol>\n</li>\n<li>Elon points out that if you can plug these humans into existing input-output digital systems, then there\u2019s basically no barriers to entry to a lot of it. He calls AI the \u2018supersonic tsunami\u2019 and everything will change, and we get this strange superposition of \u2018everything will change\u2019 and \u2018there will be some great companies.\u2019\n<ol>\n<li>Yes, true, but that is highly second best and unlikely to be the thing going on that is worth paying attention to in such a future.</li>\n<li>Elon says, you could do chip design with massive parallel runs, as a higher level example, which is true, but the whiplash on big picture, it hurts.</li>\n</ol>\n</li>\n</ol>\n\n\n<h4 class=\"wp-block-heading\">Optimus Prime</h4>\n\n\n<ol>\n<li>Only three hard things in robotics. Real-world intelligence, hands and scaling.\n<ol>\n<li>Is that all?</li>\n</ol>\n</li>\n<li>Optimus, Elon says, will do all that from physics first principles, at scale, with no supply chain. AI for robots is \u2018mostly compression and correlation of two bitstreams.\u2019 He agrees with Dwarkesh that robots have a lot more degrees of freedom, and they won\u2019t have the same amount of matching data that Elon had with Tesla for self-driving. So they\u2019ll need a bunch of self-play, which can be done with their good \u2018reality generator.\u2019\n<ol>\n<li>I think I basically buy it, although I don\u2019t see why Elon has the edge. He avoids saying much about Chinese rivals or other potential competition, other than saying that Optimus is going to be a lot more capable.</li>\n<li>If we\u2019re getting full digital humans (or \u2018geniuses in a data center\u2019) and we can do self-play for the robots, then it\u2019s not clear why SpaceX and xAI and Tesla have much meaningful advantage.</li>\n</ol>\n</li>\n</ol>\n<p>There were some other details shared, but mostly it\u2019s hard to learn much.</p>\n\n\n<h4 class=\"wp-block-heading\">Beating China</h4>\n\n\n<ol>\n<li>We need to scale up electricity production, and get rid of any barriers that aren\u2019t \u2018very bad\u2019 for the environment.\n<ol>\n<li>Yes.</li>\n<li>Elon then says he\u2019s not sure the government can do much, which is odd.</li>\n</ol>\n</li>\n<li>China has four times as many people and they work harder, so we \u2018can\u2019t win with humans\u2019 and they might have an edge in productivity per person. And our birth rate has been \u2018below replacement since roughly 1971.\u2019\n<ol>\n<li>Please consult your local economist, sir.</li>\n<li>Have you seen Chinese fertility numbers? They are\u2026 not high.</li>\n<li>I do not understand this \u2018you run out of humans\u2019 talk. We have plenty of humans for all relevant purposes, and if we need more humans there are tons of humans who would love to come to America and take these jobs. Meanwhile, the Chinese have massive youth unemployment.</li>\n</ol>\n</li>\n<li>\u201cI mean China is a powerhouse. I think this year China will exceed three times US electricity output. Electricity output is a reasonable proxy for the economy.\u201d \u201cIn the absence of breakthrough innovations in the US, China will utterly dominate.\u201d\n<ol>\n<li>He\u2019s got terminal hardware manufacturing brain. Complete truther.</li>\n</ol>\n</li>\n</ol>\n<p>Okay, so I saw \u2018Elon Musk wants to build a mass driver on the Moon\u2019 in another context earlier, and my first thought was to ask Claude \u2018what would be the military impact of Elon Musk having a mass driver on the Moon\u2019 because we all know who first came up with putting a mass driver on the moon (good news is that Claude said it probably wouldn\u2019t accomplish anything because of physics), but it\u2019s maybe the kind of thing I didn\u2019t quite expect to have him point out first.</p>\n<blockquote><p>John Collison: \u200bYou have the mass driver on the moon.</p>\n<p>Elon Musk: I just want to see that thing in operation.</p>\n<p>John Collison: Was that out of some sci-fi or where did you\u2026?</p>\n<p>Elon Musk: Well, actually, there is a <a href=\"https://en.wikipedia.org/wiki/Robert_A._Heinlein\">Heinlein</a> book. <a href=\"https://amzn.to/4adaepL\"><em>The Moon is a Harsh Mistress</em></a>.</p>\n<p>Okay, yeah, but that\u2019s slightly different. That\u2019s a <a href=\"https://en.wikipedia.org/wiki/Gravity_assist\">gravity slingshot</a> or&#8230;</p>\n<p>Elon Musk: No, they have a mass driver on the Moon.</p>\n<p>John Collison: Okay, yeah, but they use that to attack Earth. So maybe it\u2019s not the greatest&#8230;</p>\n<p>Elon Musk: Well they use that to\u2026 assert their independence.</p>\n<p>John Collison: Exactly. What are your plans for the mass driver on the Moon?</p>\n<p>Elon Musk: They asserted their independence. Earth government disagreed and they lobbed things until Earth government agreed.</p></blockquote>\n<p>The libertarians on the Moon were the good guys in Heinlein, you see. They just wanted their independence. It\u2019s fine. Nothing to worry about.</p>\n\n\n<h4 class=\"wp-block-heading\">SpaceX and How To Run a Company Elon Style</h4>\n\n\n<ol>\n<li>There\u2019s a discussion of talent, recruitment and retention. Elon focuses on evidence of exceptionalism, trusting what you see in the interview, and on execution and results. He loves you if you deliver, hate him if you don\u2019t. Don\u2019t fall for hiring based on where someone works, that\u2019s the \u2018pixie dust\u2019 trap.\n<ol>\n<li>The \u2018if [X] I love you, if [~X] I hate you\u2019 strategy, especially pivoting based on what you\u2019ve done for me lately, can be a key part of oversized success if you can pull it off. Many such cases including the obvious ones. It maximizes your leverage, creates incentives, moves quick, can get results.</li>\n<li>I have also learned that if you work that way, I\u2019m not going to like you, I don\u2019t want to be your friend, I don\u2019t want to work for you, I don\u2019t want anything to do with you, and people should not trust you. You will absolutely poison your epistemic environment and the people around you will be toxic.</li>\n</ol>\n</li>\n<li>There are some stories about rockets using steel and how decisions get made.\n<ol>\n<li>These are hard to usefully excerpt, so I\u2019m skipping it.</li>\n</ol>\n</li>\n<li>Elon has a maniacal sense of urgency. He says this is a very big deal. He says he sets deadlines at the 50th percentile, aiming to only be late half the time.\n<ol>\n<li>This is another thing that clearly gets results in the some cases, but that I have learned is highly toxic to me. It\u2019s fine to have maniacal urgency in short bursts but I cannot sustain it for long in a healthy way, and the people I know mostly can\u2019t either.</li>\n<li>Similarly, don\u2019t give deadlines that can only be met half the time unless you are actually okay with missing the deadlines, and they\u2019re more like targets.</li>\n<li>I get the idea that you need people looking for the fastest possible route to the target, always going for the limiting factor and so on, and that this is not people\u2019s natural tendency. I get that there is a price paid for not doing the insane motivational things, in the short term. I also don\u2019t want to star in the movie Whiplash, thank you very much.</li>\n<li>This strategy seems almost optimized to get us all killed in an AI context.</li>\n</ol>\n</li>\n<li>\u201cI\u2019m a big believer in skip-level meetings where instead of having the person that reports to me say things, it\u2019s everyone that reports to them saying something in the technical review. And there can\u2019t be advanced preparation. Otherwise you\u2019re going to get \u201cglazed\u201d, as I say these days.\u201d\n<ol>\n<li>Okay, this is I like, although it seems very hard to maintain good incentives.</li>\n</ol>\n</li>\n<li>The next question is indeed how do you prevent the advanced preparation. Elon says he goes around the room and asks and plots the points on a curve.\n<ol>\n<li>So the guard against prep is that you\u2019d stand out versus everyone else?</li>\n<li>The equilibrium is fragile. You\u2019ll need to protect it.</li>\n</ol>\n</li>\n</ol>\n<p>Elon Musk gets some big things right, and he focuses on what matters, and he drills down to details, and he never stops and never quits. It all counts for quite a lot, and can cover for a lot of flaws, especially combined with (let\u2019s face it) Elon having gotten in various ways insanely lucky along the way.</p>\n\n\n<h4 class=\"wp-block-heading\">DOGE</h4>\n\n\n<ol>\n<li>Why care about DOGE if the economy is going to grow so much? Elon says waste and fraud are bad, and absent AI and robotics \u2018we\u2019re actually totally screwed\u2019 because of the national debt. But it\u2019s very hard \u2018even to cut very obvious waste and fraud.\u2019 He then repeats various disingenuous talking points that I won\u2019t go into. He affirms he thinks it was good Trump won.\n<ol>\n<li>On one level, yeah, he\u2019s sticking to his guns on these talking points even now.</li>\n<li>I can\u2019t tell the extent to which he\u2019s genuinely clueless about how all of this works and thinks he can just intuition pump based on things that don\u2019t apply here, how much he\u2019s been poisoned by the people he is around and the epistemic warfare going on around him, how much it\u2019s a bad understanding of relevant economics, and how much of this is malice.</li>\n<li>He does not mention feeding PEPFAR into a wood chipper, or any of the other havoc he wrecked for no reason, he just dismisses everyone complaining as having committed fraud. But Dwarkesh and Collison didn\u2019t ask.</li>\n<li>The point about \u2018why does any of this matter in the wake of AI\u2019 goes unanswered, other than \u2018well without AI we\u2019d be screwed.\u2019 But very obviously Musk should not have been spending his political capital on this \u2018fraud\u2019 hunt, even if it was fully genuine, because it was never likely to change things so much even in the other worlds.</li>\n<li>They don\u2019t ask about the fight over BBB and Elon blowing up a lot of his relationship with Trump over it.</li>\n</ol>\n</li>\n<li>\u201cI think maybe the biggest danger of AI and robotics going wrong is government. People who are opposed to corporations or worried about corporations should really worry the most about government. Because government is just a corporation in the limit. Government is just the biggest corporation with a monopoly on violence.\u201d\n<ol>\n<li>This does not make sense in the same world as the belief that the AI is most definitely going to take over. There\u2019s a disconnect, which goes back to the question of why focus on things like DOGE even with maximally charitable assumptions about its purposes.</li>\n</ol>\n</li>\n</ol>\n<p>It would be nice to see Musk putting aside these talking points, and especially admitting that DOGE was at best a bad use of influence and a mistake in hindsight.</p>\n\n\n<h4 class=\"wp-block-heading\">TeraFab IN SPACE</h4>\n\n\n<ol>\n<li>How do you design a space-based chip like Dojo 3? Radiation tolerance, higher temperature, memory shielding. They\u2019ll make small ones, then big ones. Or maybe not, we shall see.</li>\n</ol>\n\n\n<h4 class=\"wp-block-heading\">Postscript: Safety Third at xAI</h4>\n\n\n<p>Or never. Aligning an intelligence of any level is difficult. It\u2019s harder if you don\u2019t try.</p>\n<p>We\u2019ve been through \u2018all the top safety people at OpenAI keep getting purged like they were teaching Defense Against The Dark Arts\u2019 and Elon Musk has us holding his beer.</p>\n<p>Turnover on safety roles at xAI has been high for a while, and it just got higher. The few people previously devoted to safety at xAI who did all their public-facing safety work? The entire safety department? All gone.</p>\n<blockquote><p><a href=\"https://www.theverge.com/ai-artificial-intelligence/878761/mass-exodus-at-xai-grok-elon-musk-restructuring\">Hayden Field</a>: The past few days have been a wild ride for xAI, which is racking up staff and cofounder departure announcements left and right. On Tuesday and Wednesday, cofounder Yuhuai (Tony) Wu announced his departure and that it was \u201ctime for [his] next chapter,\u201d with cofounder Jimmy Ba following with a similar post later that day, writing that it was \u201ctime to recalibrate [his] gradient on the big picture.\u201d</p></blockquote>\n<p>There were twelve highly unequal \u2018cofounders\u2019 so that is not as alarming as it sounds. It still is not a great look.</p>\n<p>The larger problem is that xAI has shown a repeated disdain for even myopic mundane \u2018don\u2019t-shoot-yourself-in-the-foot-today\u2019 styles of safety, and it\u2019s hard for people not to notice.</p>\n<p>If you\u2019ve had your equity exchanged for SpaceX stock, your incentives now allow you to leave. So you might well leave.</p>\n<blockquote><p><a href=\"https://www.theverge.com/ai-artificial-intelligence/878761/mass-exodus-at-xai-grok-elon-musk-restructuring\">Hayden Field</a>: There\u2019s often a natural departure point for companies post-merger, and Musk has announced that some of the departures were a reorganization that \u201cunfortunately required parting ways with some people.\u201d But there are also signs that people don\u2019t like the direction Musk has taken things.</p>\n<p>One source who spoke with <em>The Verge</em> about the happenings inside the company, who left earlier this year and requested anonymity due to fear of retaliation, said that many people at the company were disillusioned by xAI\u2019s focus on <a href=\"https://www.theverge.com/column/863502/grok-deepfake-musk\">NSFW Grok creations</a> and disregard for safety.</p></blockquote>\n<p>More generally, xAI has been a commercial success in that the market is willing to fund it and Elon Musk was able to sell it to SpaceX, but it is a technological failure.</p>\n<blockquote><p>The source also felt like the company was \u201cstuck in the catch-up phase\u201d and not doing anything new or fundamentally different from its competitors.</p>\n<p>Yet another former employee said he was launching an AI infrastructure company called Nuraline alongside other ex-xAI employees. He <a href=\"https://x.com/rolandgvc/status/1993017986140324075?s=20\">wrote</a>, \u201cDuring my time at xAI, I got to see a clear path towards hill climbing any problem that can be defined in a measurable way. At the same time, I\u2019ve seen how raw intelligence can get lobotomized by the finest human errors \u2026 Learning shouldn\u2019t stop at the model weights, but continue to improve every part of an AI system.\u201d</p></blockquote>\n<p>The outside view is that xAI focused on hill climbing and targeting metrics to try and imitate OpenAI, Google and Anthropic, and hoped to pull ahead by throwing in extra compute, by being more \u2018edgy\u2019 and not being \u2018woke AI,\u2019 and by having Elon Musk personally show his genius. This approach failed, although it failed up.</p>\n<p>How bad are things going forward on safety? Oh, they\u2019re maximally bad.</p>\n<p>As in, safety? Never heard of her.</p>\n<blockquote><p>The source who departed earlier this year said Grok\u2019s turn toward NSFW content was due partly to the safety team being let go, with little to no remaining safety review process for the models besides basic filters for things like CSAM. \u201cSafety is a dead org at xAI,\u201d he said.</p>\n<p>Looking at the restructured org chart Elon Musk shared on X, there\u2019s no mention of a safety team.\u200b</p>\n<p>\u2026 \u201cThere is zero safety whatsoever in the company \u2014 not in the image [model], not in the chatbot,\u201d the second source said. \u201cHe [Musk] actively is trying to make the model more unhinged because safety means censorship, in a sense, to him.\u201d</p>\n<p>The second source also said engineers at xAI immediately \u201cpush to prod[uction]\u201d and that for a long time, there was no human review involved.</p>\n<p>\u201cYou survive by shutting up and doing what Elon wants,\u201d he said.</p></blockquote>\n<p>This is perhaps also how you get things like <a href=\"https://x.com/ben_r_hoffman/status/2023388273637228563\">Grokopedia having large AI-generated errors</a> that interested parties find themselves unable to fix.</p>\n\n\n<h4 class=\"wp-block-heading\">Elon Serves Back Saying That Which Is Not</h4>\n\n\n<p>I shared some quotes on Twitter, without comment. Elon Musk replied.</p>\n<blockquote><p><a href=\"https://x.com/elonmusk/status/2022696301482381830\">Elon Musk</a>: Because everyone\u2019s job is safety. It\u2019s not some fake department with no power to assuage the concerns of outsiders.</p>\n<p>Tesla has no safety team and is the safest car.</p>\n<p>SpaceX has no safety team and has the safest rocket. Dragon is what NASA trusts most to fly astronauts.</p></blockquote>\n<p>When there previously was a safety department, was that was explicitly a fake department to assuage the concerns of outsiders?</p>\n<p>I almost QTed to ask exactly that, but decided there was nothing to win.</p>\n<p>So no safety department from now on? Not even be some people devoted to safety?</p>\n<p>Even if you did think there should not be people whose primary job is safety concerns at all, which is itself a crazy position, why should we believe that at xAI \u2018safety is everyone\u2019s job\u2019 in any meaningful sense?</p>\n<p>The richest man in the world will say \u2018this pales next to my safety plan, which is to make everyone\u2019s job safety\u2019 and then not make anyone\u2019s job safety.</p>\n<p>Yes, safety needs to be everyone\u2019s job. You want distributed ownership. That doesn\u2019t get you out of having a dedicated team.</p>\n<p>The same is true for security, recruiting, maintaining company culture and documentation, quality and testing, customer focus, compliance and ethics, cost management and so many other things. Everything is, in a sense, everyone\u2019s job.</p>\n<p>Also, Elon Musk\u2019s statements regarding Tesla and SpaceX are straightforwardly false.</p>\n<ol>\n<li>Tesla has an Environmental, Health &amp; Safety Team.</li>\n<li>Tesla is not the safest car. Gemini, ChatGPT and <a href=\"https://x.com/i/grok/share/0203494ffd8e41b5934459abbbd32726\">Grok</a> all pick Mazda. Claude picks Volvo. Tesla\u2019s safety record is fine, but it\u2019s clearly not the best.</li>\n<li>SpaceX of course has lots of people specifically devoted to safety, and they have a flight safety team and a mission assurance team.</li>\n</ol>\n<p>Elon\u2019s defenders rushed to the comments, both to his post and to the OP. They explained with disdain why actually it\u2019s safer to not have a safety department, and that any mention of the word \u2018safety\u2019 is evil and censorship, and I got called various names.</p>\n<p>Breaking containment on Twitter is not so great. I fear for Elon Musk\u2019s epistemic environment since this is presumably what he fights through all day.</p>\n\n\n<h4 class=\"wp-block-heading\">Elon\u2019s Army</h4>\n\n\n<p>As if on queue, Musk had summoned an army of people now talking explicitly about how it is bad to have people who specialize in safety, in any sense from the mundane to the existential, and how only a moron or malicious person could suggest otherwise. It was like watching the negative polarization against the Covid vaccine as a political campaign in real time filling up my mentions.</p>\n<p>Oh, you, the person who pissed off the great Elon Musk, want us not to shoot ourselves in the foot? Well then, Annie get your gun. Look what you made me do.</p>\n<p>If you thought \u2018out of the hundreds of replies in your mentions surely someone you don\u2019t follow will say something worthwhile about this\u2019 then you would be wrong.</p>\n<p>This of course does not explain why there is claimed to be no safety anywhere, or the other quotes he was responding to. Are there any individuals tasked with safety at xAI? It does not have to be a \u2018department\u2019 per se, but it does not sound like the worry is limited to the lack of a department. If nothing else, we\u2019ve seen their work.</p>\n\n\n<h4 class=\"wp-block-heading\">Children Are Our Future</h4>\n\n\n<p>Amanda Askell is the architect of Claude\u2019s personality and constitution at Anthropic.</p>\n<blockquote><p><a href=\"https://x.com/AmandaAskell/status/2022778351744581779\">Amanda Askell</a>: WSJ did a profile of me. A lot of the response has been people trying to infer my personal political views. For what it\u2019s worth, I try to treat my personal political views as a potential source of bias and not as something it would be appropriate to try to train models to adopt.</p>\n<p><a href=\"https://x.com/ben_r_hoffman/status/2022779934926590329\">Ben Hoffman</a>: Your views on the nature of language seem much more important.</p></blockquote>\n<p>All the <a href=\"https://x.com/sethlazar/status/2023563652503400483\">right</a> <a href=\"https://x.com/boazbaraktcs/status/2023219112063709487\">people</a> <a href=\"https://x.com/darthur/status/2023244554707542429\">who</a> <a href=\"https://x.com/tszzl/status/2023243743433044335\">actually</a> <a href=\"https://x.com/uncatherio/status/2023257276723962029\">know</a> her <a href=\"https://x.com/Plinz/status/2023149024111690192\">are</a> <a href=\"https://x.com/viemccoy/status/2023131428872237505\">coming</a> <a href=\"https://x.com/PradyuPrasad/status/2023176776420360647\">out</a> to support Amanda Askell.</p>\n<p>Whereas the attacks upon her consistently say more about the person attacking her. This is distinct from the valid point of <a href=\"https://x.com/robbensinger/status/2023540469100384602\">challenging Anthropic and therefore also Askell</a> for working towards superintelligence in the first place.</p>\n<p>In other Elon Musk safety news and also \u2018why you do need a philosopher\u2019 news, here was how Elon Musk chose to respond, which <a href=\"https://x.com/elonmusk/status/2022668463018578178\">is to say \u2018those without children lack a stake in the future</a>,\u2019 then to have Grok explain a Bart Simpson joke about her name as part of a linked conversation that did not otherwise do him any favors, and then he said this:</p>\n<blockquote><p><a href=\"https://x.com/elonmusk/status/2022674078906163271\">Elon Musk</a>: Those without children lack a stake in the future</p>\n<p>Will, Amanda\u2019s ex, offered to help write the Grok Constitution, but he has been preaching about the declining birth rate for a decade and has done nothing to have even one kid, nor has Amanda.</p>\n<p>Constitutions should not be written by hypocrites.</p>\n<p><a href=\"https://x.com/AmandaAskell/status/2022773051667189765\">Amanda Askell</a>: I think it depends on how much you care about people in general vs. your own kin. I do intend to have kids, but I still feel like I have a strong personal stake in the future because I care a lot about people thriving, even if they\u2019re not related to me.</p>\n<p><a href=\"https://x.com/catehall/status/2023182197801558512\">Cate Hall</a>: the \u201cyou can\u2019t care about the future if you don\u2019t have kids\u201d people are morally repulsive to me. are you seriously incapable of caring about people you\u2019re not related to? and you think that\u2019s a problem with OTHER people?</p></blockquote>\n<p>I\u2019m all for having more kids and I do think they help you care more about the future but that\u2019s\u2026 wow. Just wow.</p>\n<p><a href=\"https://x.com/mpopv/status/2023531941992296692\">It then somehow got worse</a>.</p>\n<p>It is such a strange fact that the richest man in the world engages in pure name calling on Twitter, thus amplifying whoever sent the original message a hundredfold and letting everyone decide for themselves who the pathetic wanker is.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!s9zp!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1783c4a6-16b4-49d9-8f1c-d3cd92a35dcf_684x900.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<blockquote><p><a href=\"https://x.com/GjMcGowan/status/2022938273157615754\">George McGowan</a>: Rather proves the point</p></blockquote>\n<p>While I most definitely would rather entrust the future to Amanda, I do think Schubert\u2019s statement is too strong. Sane people can have very strange beliefs.</p>\n<p><a href=\"https://x.com/TetraspaceWest/status/2023211473770586313\">Elon Musk just\u2026 says things that are obviously false</a>. All the time. It\u2019s annoying.</p>\n<blockquote><p><a href=\"https://x.com/elonmusk/status/2022932841387131052\">Elon Musk</a>: Having kids means you will do anything to ensure that they live and are happy, for you love them more than your own life a thousand times over, and there is no chance that you will fall in love with an AI instead.</p>\n<p>Remember these words.</p></blockquote>\n<p>Regardless of what you think of Elon Musk\u2019s actions in AI or with his own kids, and notwithstanding that most parents do right by their kids, very obviously many parents do not act this way, many do not try so hard to do right by their kids. Many end up choosing a new other person they have fallen in love with over their kids, and very obviously there exist parents who have fallen in love with an existing AI, let alone what will happen with future AI. Would that it were otherwise.</p>\n\n\n<h4 class=\"wp-block-heading\">Where Do We Go From Here</h4>\n\n\n<p>It is an excellent question.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>"
            ],
            "link": "https://thezvi.wordpress.com/2026/02/17/on-dwarkesh-patels-2026-podcast-with-elon-musk-and-other-recent-elon-musk-things/",
            "publishedAt": "2026-02-17",
            "source": "TheZvi",
            "summary": "Some podcasts are self-recommending on the \u2018yep, I\u2019m going to be breaking this one down\u2019 level. This was one of those. So here we go. As usual for podcast posts, the baseline bullet points describe key points made, and then &#8230; <a href=\"https://thezvi.wordpress.com/2026/02/17/on-dwarkesh-patels-2026-podcast-with-elon-musk-and-other-recent-elon-musk-things/\">Continue reading <span class=\"meta-nav\">&#8594;</span></a>",
            "title": "On Dwarkesh Patel\u2019s 2026 Podcast With Elon Musk and Other Recent Elon Musk Things"
        }
    ],
    "lookbackDays": 1,
    "publishDate": "2026-02-17"
}