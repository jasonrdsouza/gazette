{
    "articles": [
        {
            "content": [
                "<p>I\u2019ve been writing a lot of Go in my new job, and trying to understand a new codebase.</p>\n\n<p>When I\u2019m reading unfamiliar code, I like to use <a href=\"https://en.wikipedia.org/wiki/Debugging#:~:text=Print%20debugging%20or%20tracing\">print debugging</a> to follow what\u2019s happening.\nI\u00a0print what branches I\u2019m in, the value of different variables, which functions are being called, and so on.\nSome people like debuggers or similar tools, but when you\u2019re learning a new language they\u2019re another thing to learn \u2013 whereas printing \u201chello world\u201d is the first step in every language tutorial.</p>\n\n<p>The built-in way to do print debugging in Go is <code>fmt.Printf</code> or <code>log.Printf</code>.\nThat\u2019s fine, but my debug messages get interspersed with the existing logs so they\u2019re harder to find, and it\u2019s easy for those debug statements to slip through code review.</p>\n\n<p>Instead, I\u2019ve taken inspiration from <a href=\"https://github.com/zestyping/q\">Ping Yee\u2019s Python module \u201cq\u201d</a>.\nIf you\u2019re unfamiliar with it, I recommend <a href=\"https://www.youtube.com/watch?v=OL3De8BAhME#t=25m15s\">his lightning talk</a>, where he explains the frustration of trying to find a single variable in a sea of logs.\nHis module provides a function <code>q.q()</code>, which logs any expressions to a standalone file.\nIt\u2019s quick and easy to type, and the output is separate from all your other logging.</p>\n\n<p>I created something similar for Go: a module which exports a single function <code>Q()</code>, and logs anything it receives to <code>/tmp/q.txt</code>.\nHere\u2019s an example:</p>\n\n<pre class=\"lng-go\"><code>package <span class=\"n\">main</span>\n\nimport <span class=\"p\">(</span>\n\t<span class=\"s\">\"github.com/alexwlchan/q\"</span>\n\t<span class=\"s\">\"os\"</span>\n<span class=\"p\">)</span>\n\nfunc <span class=\"n\">printShapeInfo</span><span class=\"p\">(</span><span class=\"n\">name</span> <span class=\"kt\">string</span><span class=\"p\">,</span> <span class=\"n\">sides</span> <span class=\"kt\">int</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n\tq.Q<span class=\"p\">(</span><span class=\"s\">\"a %s has %d sides\"</span><span class=\"p\">,</span> name<span class=\"p\">,</span> sides<span class=\"p\">)</span>\n<span class=\"p\">}</span>\n\nfunc <span class=\"n\">main</span><span class=\"p\">()</span> <span class=\"p\">{</span>\n\tq.Q<span class=\"p\">(</span><span class=\"s\">\"hello world\"</span><span class=\"p\">)</span>\n\n\tq.Q<span class=\"p\">(</span><span class=\"m\">2</span> + <span class=\"m\">2</span><span class=\"p\">)</span>\n\n\t_<span class=\"p\">,</span> <span class=\"n\">err</span> := os.Stat<span class=\"p\">(</span><span class=\"s\">\"does_not_exist.txt\"</span><span class=\"p\">)</span>\n\tq.Q<span class=\"p\">(</span>err<span class=\"p\">)</span>\n\n\tprintShapeInfo<span class=\"p\">(</span><span class=\"s\">\"triangle\"</span><span class=\"p\">,</span> <span class=\"m\">3</span><span class=\"p\">)</span>\n<span class=\"p\">}</span>\n</code></pre>\n<p>The logged output in <code>/tmp/q.txt</code> includes the name of the function and the expression that was passed to <code>Q()</code>:</p>\n<pre><code><span>main</span>: \"hello world\"\n\n<span>main</span>: <span>2 + 2</span> = 4\n\n<span>main</span>: <span>err</span> = stat does_not_exist.txt: no such file or directory\n\n<span>printShapeInfo</span>: a triangle has 3 sides</code></pre>\n<p>I usually open a terminal window running <code>tail -f /tmp/q.txt</code> to watch what gets logged by <code>q</code>.</p>\n\n<p>The module is only 120\u00a0lines of Go, and <a href=\"https://github.com/alexwlchan/q.go/blob/main/q.go\">available on GitHub</a>.\nYou can copy it into your project, or it\u2019s simple enough that you could write your own version.\nIt has two interesting ideas that might have broader use.</p>\n\n<h2 id=\"getting-context-with-the-runtime-package\">Getting context with the <code>runtime</code> package</h2>\n\n<p>When you call <code>Q()</code>, it receives the final value \u2013 for example, if you call <code>Q(2 + 2)</code>, it receives <code>4</code> \u2013 but I wanted to log the original expression and function name.\nThis is a feature from Ping\u2019s Python package, and it\u2019s what makes q so pleasant to use.\nThis gives context for the log messages, and saves you typing that context yourself.</p>\n\n<p>I get this information from Go\u2019s <a href=\"https://pkg.go.dev/runtime\"><code>runtime</code> package</a>, in particular the <a href=\"https://pkg.go.dev/runtime#Caller\"><code>runtime.Caller</code></a> function, which gives you information about the currently-running function.</p>\n\n<p>I call <code>runtime.Caller(1)</code> to step up the callstack by 1, to the actual line in my code where I typed <code>Q().</code>\nIt tells me the \u201cprogram counter\u201d, the filename, and the line number.\nI\u00a0can resolve the program counter to a function name with <a href=\"https://pkg.go.dev/runtime#FuncForPC\"><code>runtime.FuncForPC</code></a>, and I can just open the file and look up that line to read the expression.\n(This assumes the source code hasn\u2019t changed since compilation, which is always true when I\u2019m doing local debugging.)</p>\n\n<h2 id=\"not-affecting-my-coworkers-with-a-local-gitignore\">Not affecting my coworkers with a local gitignore</h2>\n\n<p>To use this file, I copy <code>q.go</code> into my work repos and add it to my <code>.git/info/exclude</code>.\nThe latter is a local-only ignore file, unlike the <code>.gitignore</code> file which is checked into the repo.\nThis means I won\u2019t accidentally check in <code>q.go</code> or push it to GitHub.</p>\n\n<p>It also means I can\u2019t forget to remove my debugging code, because if I do, the tests in CI will fail when they can\u2019t find <code>q.go</code>.</p>\n\n<p>This avoids other approaches that would be more disruptive or annoying, like making it a project dependency or adding it to the shared <code>.gitignore</code> file.</p>\n\n\n    <p>[If the formatting of this post looks odd in your feed reader, <a href=\"https://alexwlchan.net/2026/q-but-for-go/?ref=rss\">visit the original article</a>]</p>"
            ],
            "link": "https://alexwlchan.net/2026/q-but-for-go/?ref=rss",
            "publishedAt": "2026-01-08",
            "source": "Alex Chan",
            "summary": "<p>I\u2019ve been writing a lot of Go in my new job, and trying to understand a new codebase.</p> <p>When I\u2019m reading unfamiliar code, I like to use <a href=\"https://en.wikipedia.org/wiki/Debugging#:~:text=Print%20debugging%20or%20tracing\">print debugging</a> to follow what\u2019s happening. I print what branches I\u2019m in, the value of different variables, which functions are being called, and so on. Some people like debuggers or similar tools, but when you\u2019re learning a new language they\u2019re another thing to learn \u2013 whereas printing \u201chello world\u201d is the first step in every language tutorial.</p> <p>The built-in way to do print debugging in Go is <code>fmt.Printf</code> or <code>log.Printf</code>. That\u2019s fine, but my debug messages get interspersed with the existing logs so they\u2019re harder to find, and it\u2019s easy for those debug statements to slip through code review.</p> <p>Instead, I\u2019ve taken inspiration from <a href=\"https://github.com/zestyping/q\">Ping Yee\u2019s Python module \u201cq\u201d</a>. If you\u2019re unfamiliar with it, I recommend <a href=\"https://www.youtube.com/watch?v=OL3De8BAhME#t=25m15s\">his lightning talk</a>, where he explains the frustration of trying to find a single variable in a sea of logs. His module provides a function <code>q.q()</code>, which logs any expressions to a standalone file. It\u2019s quick and easy to type, and the output is separate from all your other logging.</p> <p>I created something similar",
            "title": "Quick-and-dirty print debugging in Go"
        },
        {
            "content": [],
            "link": "https://harper.blog/2026/01/07/2025-is-dead-to-me-2026-is-going-to-be-stranger/",
            "publishedAt": "2026-01-08",
            "source": "Harper Reed",
            "summary": "<figure><source type=\"image/webp\" /><source /><img alt=\"A wider me in 2025, Widelux, 7/25\" height=\"305\" src=\"https://harper.blog/2026/01/07/2025-is-dead-to-me-2026-is-going-to-be-stranger/img20250725_09034308_hu_bf5313c2756b15dc.jpg\" width=\"768\" /> <figcaption>A wider me in 2025, Widelux, 7/25</figcaption></figure> <p>2025 was a wild year. I don\u2019t think I particularly liked it. But here we are - shot right out of the cannon that was 2025 into the welcoming arms of 2026.</p> <p>We are truly fucked aren\u2019t we. Destined to progress into this wilderness of confusion, the unknown, and a bunch of fucking weird. I can\u2019t wait! Please join me in continuing to witness the future one year at a time!</p> <h1 id=\"ok-so-2025-was-pretty-nuts\">Ok. So 2025 was pretty nuts.</h1> <figure><source type=\"image/webp\" /><source /><img alt=\"The ARMED, Ricoh GR iiix, 12/25\" height=\"768\" src=\"https://harper.blog/2026/01/07/2025-is-dead-to-me-2026-is-going-to-be-stranger/R0002549_hu_98ae7c4a7eb4cdb5.JPG\" width=\"768\" /> <figcaption>The ARMED, Ricoh GR iiix, 12/25</figcaption></figure> <h2 id=\"health\">Health</h2> <p>I ran a lot. It was awesome. I averaged about 10 miles a week. Keep in mind that prior to 10/2024 the last time I ran was in 1997. I notice all sorts of impact to my body. My knees no longer hurt (thankfully that continues), my IT band issues have seemingly disappeared - but more importantly - I don\u2019t get winded as often, and I feel like I slept and move better. It is very nice.</p> <p>I",
            "title": "2025 in Review: strange, terror, and weird"
        },
        {
            "content": [],
            "link": "https://simonwillison.net/2026/Jan/8/llm-predictions-for-2026/#atom-entries",
            "publishedAt": "2026-01-08",
            "source": "Simon Willison",
            "summary": "<p>I joined a recording of the Oxide and Friends podcast on Tuesday to talk about 1, 3 and 6 year predictions for the tech industry. This is my second appearance on their annual predictions episode, you can see <a href=\"https://simonwillison.net/2025/Jan/10/ai-predictions/\">my predictions from January 2025 here</a>. Here's <a href=\"https://oxide-and-friends.transistor.fm/episodes/predictions-2026\">the page for this year's episode</a>, with options to listen in all of your favorite podcast apps or <a href=\"https://www.youtube.com/watch?v=lVDhQMiAbR8\">directly on YouTube</a>.</p> <p>Bryan Cantrill started the episode by declaring that he's never been so unsure about what's coming in the next year. I share that uncertainty - the significant advances in coding agents just in the last two months have left me certain that things will change significantly, but unclear as to what those changes will be.</p> <p>Here are the predictions I shared in the episode.</p> <ul> <li><a href=\"https://simonwillison.net/2026/Jan/8/llm-predictions-for-2026/#1-year-it-will-become-undeniable-that-llms-write-good-code\">1 year: It will become undeniable that LLMs write good code</a></li> <li><a href=\"https://simonwillison.net/2026/Jan/8/llm-predictions-for-2026/#1-year-we-re-finally-going-to-solve-sandboxing\">1 year: We're finally going to solve sandboxing</a></li> <li><a href=\"https://simonwillison.net/2026/Jan/8/llm-predictions-for-2026/#1-year-a-challenger-disaster-for-coding-agent-security\">1 year: A \"Challenger disaster\" for coding agent security</a></li> <li><a href=\"https://simonwillison.net/2026/Jan/8/llm-predictions-for-2026/#1-year-k-k-p-parrots-will-have-an-outstanding-breeding-season\">1 year: K\u0101k\u0101p\u014d parrots will have an outstanding breeding season</a></li> <li><a href=\"https://simonwillison.net/2026/Jan/8/llm-predictions-for-2026/#3-years-the-coding-agents-jevons-paradox-for-software-engineering-will-resolve-one-way-or-the-other\">3 years: the coding agents Jevons paradox for software engineering will resolve, one way or the other</a></li> <li><a href=\"https://simonwillison.net/2026/Jan/8/llm-predictions-for-2026/#3-years-someone-will-build-a-new-browser-using-mainly-ai-assisted-coding-and-it-won-t-even-be-a-surprise\">3 years: Someone will build",
            "title": "LLM predictions for 2026, shared with Oxide and Friends"
        },
        {
            "content": [
                "<p>\n          <a href=\"https://www.astralcodexten.com/p/sell-me-this-pen\">\n              Read more\n          </a>\n      </p>"
            ],
            "link": "https://www.astralcodexten.com/p/sell-me-this-pen",
            "publishedAt": "2026-01-08",
            "source": "SlateStarCodex",
            "summary": "<p> <a href=\"https://www.astralcodexten.com/p/sell-me-this-pen\"> Read more </a> </p>",
            "title": "Sell Me This Pen"
        },
        {
            "content": [
                "<p>\n          <a href=\"https://www.astralcodexten.com/p/hidden-open-thread-4155\">\n              Read more\n          </a>\n      </p>"
            ],
            "link": "https://www.astralcodexten.com/p/hidden-open-thread-4155",
            "publishedAt": "2026-01-08",
            "source": "SlateStarCodex",
            "summary": "<p> <a href=\"https://www.astralcodexten.com/p/hidden-open-thread-4155\"> Read more </a> </p>",
            "title": "Hidden Open Thread 415.5"
        },
        {
            "content": [
                "<p>Claude Code is the talk of the town, and of the Twitter. It has reached critical mass.</p>\n<p>Suddenly, everyone is talking about how it is transforming their workflows. This includes non-coding workflows, as it can handle anything a computer can do. People are realizing the power of what it can do, building extensions and tools, configuring their setups, and watching their worlds change.</p>\n<p>I\u2019ll be covering that on its own soon. This covers everything else, including ChatGPT Health and the new rounds from xAI and Anthropic.</p>\n\n\n<h4 class=\"wp-block-heading\">Table of Contents</h4>\n\n\n<ol>\n<li><a href=\"https://thezvi.substack.com/i/183278736/language-models-offer-mundane-utility\">Language Models Offer Mundane Utility.</a> Even Rufus, Amazon\u2019s Choice.</li>\n<li><a href=\"https://thezvi.substack.com/i/183278736/language-models-don-t-offer-mundane-utility\">Language Models Don\u2019t Offer Mundane Utility.</a> They don\u2019t believe you.\n<div>\n\n\n<span id=\"more-25014\"></span>\n\n\n</div>\n</li>\n<li><a href=\"https://thezvi.substack.com/i/183278736/language-models-have-all-the-fun\">Language Models Have All The Fun.</a> In glorious AI future, does game play you?</li>\n<li><a href=\"https://thezvi.substack.com/i/183278736/huh-upgrades\">Huh, Upgrades.</a> Claude Code 2.1.0, and JP Morgan using AI for its proxy advice.</li>\n<li><a href=\"https://thezvi.substack.com/i/183278736/on-your-marks\">On Your Marks.</a> Yes, Meta pretty much did fraud with the Llama 4 benchmarks.</li>\n<li><a href=\"https://thezvi.substack.com/i/183278736/deepfaketown-and-botpocalypse-soon\">Deepfaketown and Botpocalypse Soon.</a> The year of doing real things?</li>\n<li><a href=\"https://thezvi.substack.com/i/183278736/fun-with-media-generation\">Fun With Media Generation.</a> The art of making people believe a human made it.</li>\n<li><a href=\"https://thezvi.substack.com/i/183278736/you-drive-me-crazy\">You Drive Me Crazy.</a> Crazy productive.</li>\n<li><a href=\"https://thezvi.substack.com/i/183278736/they-took-our-jobs\">They Took Our Jobs.</a> Will no one be safe?</li>\n<li><a href=\"https://thezvi.substack.com/i/183278736/get-involved\">Get Involved.</a> Charles looks to get involved.</li>\n<li><a href=\"https://thezvi.substack.com/i/183278736/introducing\"><strong>Introducing</strong>.</a> ChatGPT Health.</li>\n<li><a href=\"https://thezvi.substack.com/i/183278736/in-other-ai-news\">In Other AI News.</a> Dan Wang\u2019s 2025 Letter and promised \u2018super assistants.\u2019</li>\n<li><a href=\"https://thezvi.substack.com/i/183278736/show-me-the-money\">Show Me the Money.</a> Anthropic is raising at $350 billion, xAI at $230 billion.</li>\n<li><a href=\"https://thezvi.substack.com/i/183278736/bubble-bubble-toil-and-trouble\">Bubble, Bubble, Toil and Trouble.</a> Bubble now means \u2018number might go down.\u2019</li>\n<li><a href=\"https://thezvi.substack.com/i/183278736/quiet-speculations\">Quiet Speculations.</a> More of the usual predictions and misunderstandings.</li>\n<li><a href=\"https://thezvi.substack.com/i/183278736/the-quest-for-sane-regulations\">The Quest for Sane Regulations.</a> A $1 million fine is not that motivating.</li>\n<li><a href=\"https://thezvi.substack.com/i/183278736/agi-and-taxation\">AGI and Taxation.</a> Why is the United States Government collecting taxes?</li>\n<li><a href=\"https://thezvi.substack.com/i/183278736/chip-city\">Chip City.</a> China uses H200 sales to also ensure its own chips sell out.</li>\n<li><a href=\"https://thezvi.substack.com/i/183278736/the-week-in-audio\">The Week in Audio.</a> Shlegeris talks to Greenblatt.</li>\n<li><a href=\"https://thezvi.substack.com/i/183278736/aligning-a-smarter-than-human-intelligence-is-difficult\">Aligning a Smarter Than Human Intelligence is Difficult.</a> Last year\u2019s report today.</li>\n<li><a href=\"https://thezvi.substack.com/i/183278736/people-are-worried-about-ai-killing-everyone\">People Are Worried About AI Killing Everyone.</a> Mostly act as if you\u2019ll be okay?</li>\n<li><a href=\"https://thezvi.substack.com/i/183278736/the-lighter-side\">The Lighter Side.</a> Paul Feig is our director, now all we need is a script.</li>\n</ol>\n\n\n<h4 class=\"wp-block-heading\">Language Models Offer Mundane Utility</h4>\n\n\n<p><a href=\"https://x.com/patio11/status/2006121277560406307\">Assemble all your records of interactions</a> with a bureaucracy into a bullet point timeline, especially when you can say in particular who said a particular thing to you.</p>\n<p><a href=\"https://x.com/omooretweets/status/2008378018444550550\">Amazon\u2019s AI assistant Rufus is in 40% of Amazon Mobile sessions</a> and is correlated with superior sales conversions. People use whatever AI you put in front of them. <a href=\"https://x.com/papayathreesome/status/2008865139693646082\">Rufus does have some advantages</a>, such as working on the phone and being able to easily access previous order history.</p>\n\n\n<h4 class=\"wp-block-heading\">Language Models Don\u2019t Offer Mundane Utility</h4>\n\n\n<p><a href=\"https://x.com/NateSilver538/status/2008300663273357560\">Notice which real world events the AIs refuse to believe when you ask for copy editing</a>.</p>\n<p>On Twitter I jokingly said this could be a good test for politicians, where you feed your planned action into ChatGPT as something that happened, and see if it believes you, then if it doesn\u2019t you don\u2019t do the thing. That\u2019s not actually the correct way to do this, what you want to do is ask why it didn\u2019t believe you, and if the answer is \u2018because that would be f***ing crazy\u2019 then don\u2019t proceed unless you know why it is wrong.</p>\n\n\n<h4 class=\"wp-block-heading\">Language Models Have All The Fun</h4>\n\n\n<p><a href=\"https://x.com/oscredwin/status/2009259489879376241\">PlayStation is exploring letting AI take over your game when you are stuck</a> and have patented a related feature.</p>\n<blockquote><p>\u200b<a href=\"https://x.com/oscredwin/status/2009259489879376241\">Andrew Rettek</a>: Experienced adult gamers will hate this, but kids will love it. If it&#8217;s done well it&#8217;ll be a great tutorial tool. It&#8217;s a specific instance of an AI teaching tool, and games are low stakes enough for real experimentation in that space.</p></blockquote>\n<p>The obvious way for this to work is that the game would then revert to its previous state. So the AI could show you what to do, but you\u2019d still have to then do it.</p>\n<p>Giving players the option to cheat, or too easily make things too easy, or too easily learn things, is dangerous. You risk taking away the fun. Then again, Civilization 2 proved you can have a literal \u2018cheat\u2019 menu and players will mostly love it, if there\u2019s a good implementation, and curate their own experiences. Mostly I\u2019m optimistic, especially as a prototype for a more general learning tool.</p>\n\n\n<h4 class=\"wp-block-heading\">Huh, Upgrades</h4>\n\n\n<p><a href=\"https://x.com/bcherny/status/2009072293826453669\">Claude Code 2.1.0 has shipped</a>, full coverage will be on its own later.</p>\n<p><a href=\"https://thezvi.substack.com/p/levels-of-friction\">Levels of friction</a> are on the decline, with results few are prepared for.</p>\n<blockquote><p><a href=\"https://x.com/deanwball/status/2008926292771504173\">Dean Ball:</a> \u200bnobody has really priced in the implications of ai causing transaction costs to plummet, but here is one good example</p>\n<p><a href=\"https://x.com/AndrewCurran_/status/2008885043872326011\">Andrew Curran</a>: JP Morgan is replacing proxy advisory firms with an in-house Al platform named &#8216;Proxy IQ&#8217; &#8211; which will analyze data from annual company meetings and provide recommendations to portfolio managers. They are the first large firm to stop using external proxy advisers entirely.</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">On Your Marks</h4>\n\n\n<p><a href=\"https://x.com/deredleritt3r/status/2007172028940599640\">The underlying actions aren\u2019t exactly news but Yann LeCun confesses</a> to Llama 4 benchmark results being \u2018fudged a little bit\u2019 and using different models for different benchmarks \u2018to give better results.\u2019 In my culture we call that \u2018fraud.\u2019</p>\n<p>Jack Clark of Anthropic predicts <a href=\"https://importai.substack.com/p/import-ai-439-ai-kernels-decentralized\">we will beat the human baseline on PostTrainBench by September 2026</a>. <a href=\"https://x.com/maksym_andr/status/2008208907018059954\">Maksym thinks they\u2019ll still be modestly short</a>. I have <a href=\"https://manifold.markets/ZviMowshowitz/ai-beats-human-baseline-on-posttrai\">created a prediction market</a>.</p>\n\n\n<h4 class=\"wp-block-heading\">Deepfaketown and Botpocalypse Soon</h4>\n\n\n<p><a href=\"https://x.com/lulumeservey/status/2008187268922536109\">Lulu Cheng Meservey declares the key narrative alpha strategy of 2026 will be doing real things</a>, via real sustained effort, over months or longer, including creating real world events, \u2018showing up as real humans\u2019 and forming real relationships.</p>\n<blockquote><p><a href=\"https://x.com/nearcyan/status/2008221840154771642\">near</a>: It may be hard to discern real and fake *content*, but real *experiences* are unmistakable</p>\n<p>sports betting, short form video &#8211; these are Fake; the antithesis to a life well-lived.</p>\n<p>Realness may be subjective but you know it when you live it.</p></blockquote>\n<p>It\u2019s more nuanced than this, sports betting can be real or fake depending on how you do it and when I did it professionally that felt very real to me, but yes you mostly know a real experience when you live it.</p>\n<p>I hope that Lulu is right.</p>\n<p>Alas, so far that is not what I see. I see the people rejecting the real and embracing the fake and the slop. Twitter threads that go viral into the 300k+ view range are reliably written in slop mode and in general the trend is towards slop consumption everywhere.</p>\n<p>I do intend to go in the anti-slop direction in 2026. As in, more effort posts and evergreen posts and less speed premium, more reading books and watching movies, less consuming short form everything. Building things using coding agents.</p>\n<p><a href=\"https://x.com/TrungTPhan/status/2008349522360181150\">The latest fun AI fake was a \u2018whistleblower\u2019</a> who made up 18 pages of supposedly confidential documents from Uber Eats along with a fake badge. The cost of doing this used to be high, now it is trivial.</p>\n<blockquote><p>Trung Phan: \u200b<a href=\"https://www.platformer.news/fake-uber-eats-whisleblower-hoax-debunked/\">Casey Newton</a> spoke with \u201cwhistleblower\u201d who wrote this viral Reddit food delivery app post.</p>\n<p>Likely debunked: the person sent an AI-generated image of Uber Eats badge and AI generated \u201cinternal docs\u201d showing how delivery algo was \u201crigged\u201d.</p>\n<p>Newton says of the experience: \u201cFor most of my career up until this point, the document shared with me by the whistleblower would have seemed highly credible in large part because it would have taken so long to put together. Who would take the time to put together a detailed, 18-page technical document about market dynamics just to troll a reporter? Who would go to the trouble of creating a fake badge?</p>\n<p>Today, though, the report can be generated within minutes, and the badge within seconds. And while no good reporter would ever have published a story based on a single document and an unknown source, plenty would take the time to investigate the document\u2019s contents and see whether human sources would back it up.\u201d</p></blockquote>\n<p>The internet figured this one out, but not before quite a lot of people assumed it was real, despite the tale including what one might call \u2018some whoppers\u2019 including delivery drivers being assigned a \u2018desperation score.\u2019</p>\n<p>Misinformation continues to be demand driven, not supply driven. Which is why the cost of doing this was trivial, the quality here was low and it was easy to catch, yet this attempt succeeded wildly, and despite that people mostly don\u2019t do it.</p>\n<p><a href=\"https://x.com/DineshDSouza/status/2008575107426591221\">Less fun was this AI video</a>, which helpfully has clear cuts in exactly 8 second increments in case it wasn\u2019t sufficiently obvious, on top of the other errors. It\u2019s not clear this fooled anyone or was trying to do so, or that this changes anything, since it\u2019s just reading someone\u2019s rhetoric. Like misinformation, it is mostly demand driven.</p>\n\n\n<h4 class=\"wp-block-heading\">Fun With Media Generation</h4>\n\n\n<p>The existence of AI art makes people question real art, <a href=\"https://x.com/Ranting_Trans/status/2006893905548292496\">example at the link</a>. If your response is, \u2018are you sure that picture is real?\u2019 then that\u2019s the point. You can\u2019t be.</p>\n\n\n<h4 class=\"wp-block-heading\">You Drive Me Crazy</h4>\n\n\n<p>Crazy productive and excited to use the AI a lot, that is. Which is different from what happened with 4o, but makes it easy to understand what happened there.</p>\n<blockquote><p><a href=\"https://x.com/willccbb/status/2007664012352467445\">Will Brown</a>: my biggest holiday LLM revelation was that Opus is just a magnificent chat model, far better than anything else i\u2019ve ever tried. swapped from ChatGPT to Claude as daily chat app. finding myself asking way more &amp; weirder questions than i ever asked Chat, and loving it</p>\n<p>for most of 2025 i didn\u2019t really find much value in \u201ctalking to LLMs\u201d beyond coding/search agents, basic googlesque questions, or random tests. Opus 4.5 is maybe the first model that i feel like i can have truly productive *conversations* with that aren\u2019t just about knowledge</p>\n<p>very \u201csmart friend\u201d shaped model. it\u2019s kinda unsettling</p>\n<p>is this how all the normies felt about 4o. if so, i get it lol</p>\n<p><a href=\"https://x.com/deanwball/status/2007941063860686919\">Dean Ball</a>: undoubtedly true that opus 4.5 is the 4o of the 130+ iq community. we have already seen opus psychosis.</p>\n<p>this one&#8217;s escaping containment a little so let me just say for those who have no context: I am not attempting to incite moral panic about claude opus 4.5. it&#8217;s an awesome model, I use it in different forms every single day.</p>\n<p>\u2026 <a href=\"https://x.com/deanwball/status/2008018640424104266\">perhaps I should have said opus 4.5</a> is the 4o of tpot rather than using iq. what I meant to say is that people with tons of context for ai&#8211;people who, if we&#8217;re honest, wouldn&#8217;t have touched 4o with a ten-foot pole (for the most part they used openai reasoners + claude or gemini for serious stuff, 4o was a google-equivalent at best for them)&#8211;are &#8216;falling for&#8217; opus in a way they haven&#8217;t for any other model.</p>\n<p>Sichu Lu: It&#8217;s more like video game addiction than anything else</p>\n<p>Dean Ball: 100%.</p>\n<p>Atharva: the reason the 4o analogy did not feel right is because the moment Opus 5 is out, few are going to miss 4.5</p>\n<p>I like the personality of 4.5 but I like what it&#8217;s able to do for me even more</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">They Took Our Jobs</h4>\n\n\n<p>Indeed:</p>\n<blockquote><p><a href=\"https://x.com/deanwball/status/2008017455382212978\">Dean Ball</a>: ai will be the fastest diffusing macroinvention in human history, so when you say &#8220;diffusion is going to be slow,&#8221; you should ask yourself, &#8220;compared to what?&#8221;</p>\n<p>slower than the most bullish tech people think? yes. yet still faster than all prior general-purpose technologies.</p>\n<p>Dave Kasten: Most people [not Dean] can&#8217;t imagine what it&#8217;s like when <em>literally every employee</em> is a never-sleeping top-performing generalist. They&#8217;ve mostly never (by definition!) worked with those folks.</p></blockquote>\n<p>Never sleeping, top performing generalist is only the start of it, we\u2019re also talking things like limitlessly copyable and parallelizable, much faster, limitless memory and so on and so forth. Almost no one can actually understand what this would mean. And that\u2019s if you force AI into a \u2018virtual employee\u2019 shaped box, which is very much not its ideal or final form.</p>\n<p><a href=\"https://x.com/binarybits/status/2007954020313506234\">As Timothy Lee points out</a>, right now OpenAI\u2019s revenue of $13 billion is for now a rounding error in our $30 trillion of GDP, and autonomous car trips are on the order of 0.1% of all rides, so also a rounding error, while Waymo grows at an anemic 7% a month and needs to pick up the pace. And historically speaking this is totally normal, these companies have tons of room to grow and such techs often take 10+ years to properly diffuse.</p>\n<p>At current growth rates, it will take a lot less than 10 years. <a href=\"https://x.com/sebkrier/status/2008274761135079929\">Ryan Greenblatt points out</a> revenue has been growing 3x every year, which is on the low end of estimates. Current general purpose AI revenue is 0.25% of America\u2019s GDP, so this straightforwardly starts to have major effects by 2028.</p>\n<p>Will AI take the finance jobs? To think well about that <a href=\"https://x.com/annanay/status/2007074405478789619\">one must break down what the finance jobs are and what strategies they use</a>, as annanay does here.</p>\n<p>The conceptual division is between:</p>\n<ol>\n<li>The Chicago School, firms like Jane Street that treat finance like a game-theoretic competition, where the algorithms form the background rules of the game but traders (whether or not they are also themselves quants) ultimately overrule the computers and make key decisions.</li>\n<li>The MIT School, which treats it all as a big stats and engineering program and you toss everything into the black box and hope money comes out.</li>\n</ol>\n<p>There\u2019s a continuum rather than a binary, you can totally be a hybrid. I agree with the view that these are still good jobs and it\u2019s a good industry to go into if your goal is purely \u2018make money in worlds where AI remains a normal technology,\u2019 but it\u2019s not as profitable as it once was. I\u2019d especially not be excited to go into pure black box work, as that is fundamentally \u2018the AI\u2019s job.\u2019</p>\n<p><a href=\"https://x.com/agupta/status/2006837835685572824\">Whereas saying \u2018working at Jane Street is no longer a safe job</a>\u2019 as general partner of YC Ankit Gupta claimed is downright silly. I mean, no job is safe at this point, including mine and Gupta\u2019s, but yeah if we are in \u2018AI as normal technology\u2019 worlds, they will have more employees in five years, not less. If we\u2019re in transformed worlds, you have way bigger concerns. If AI can do the job of Jane Street traders then I have some very, very bad news for basically every other cognitive worker\u2019s employment.</p>\n\n\n<h4 class=\"wp-block-heading\">Get Involved</h4>\n\n\n<p>From his outputs, I\u2019d say Charles is a great potential hire, check him out.</p>\n<blockquote><p><a href=\"https://x.com/CharlesD353/status/2009252349777219872\">Charles</a>: Personal news: I&#8217;m leaving my current startup role, looking to figure out what&#8217;s next. I&#8217;m interested in making AI go well, and open to a variety of options for doing so. I have 10+ years of quant research and technical management experience, based in London. DM if interested.</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">Introducing</h4>\n\n\n<p><a href=\"https://x.com/OpenAI/status/2008234625668104271\">OpenAI is further embracing using ChatGPT for health questions</a>, and it is fully <a href=\"https://x.com/OpenAI/status/2008987566796640575\">launching ChatGPT Health</a> (come on, <a href=\"https://x.com/paularambles/status/2009003971718140415\">ChatGP was right there</a>)</p>\n<blockquote><p>OpenAI: \u200bIntroducing ChatGPT Health \u2014 a dedicated space for health conversations in ChatGPT. You can securely connect medical records and wellness apps so responses are grounded in your own health information.</p>\n<p>Designed to help you navigate medical care, not replace it.</p>\n<p><a href=\"https://t.co/itTqtIItdC\">Join the waitlist</a> to get early access.</p>\n<p>If you choose, ChatGPT Health lets you securely connect medical records and apps like Apple Health, MyFitnessPal, and Peloton to give personalized responses.</p>\n<p>ChatGPT Health keeps your health chats, files, and memories in a separate dedicated space.</p>\n<p>Health conversations appear in your history, but their info never flows into your regular chats.</p>\n<p>View or delete Health memories anytime in Health or Settings &gt; Personalization.</p>\n<p>We\u2019re rolling out ChatGPT Health to a small group of users so we can learn and improve the experience. Join the waitlist for early access.</p>\n<p>We plan to expand to everyone on web &amp; iOS soon.<br />\nElectronic Health Records and some apps are US-only; Apple Health requires iOS.</p></blockquote>\n<p><a href=\"https://fidjisimo.substack.com/p/chatgpt-health\">Fidji Simo has a hype post here</a>, including sharing a personal experience where this helped her flag an interaction so her doctor could avoid prescribing the wrong antibiotic.</p>\n<p>It\u2019s a good pitch, and a good product. Given we were all asking it all our health questions anyway, having a distinct box to put all of those in, that enables compliance and connecting other services and avoiding this branching into other chats, seems like an excellent feature. I\u2019m glad our civilization is allowing it.</p>\n<p>That doesn\u2019t mean ChatGPT Health will be a substantial practical upgrade over vanilla ChatGPT or Claude. We\u2019ll have to wait and see for that. But if it makes doctors or patients comfortable using it, that\u2019s already a big benefit.</p>\n<p><a href=\"https://x.com/ZhentingQi/status/2008611973622047147\">Zhenting Qi and Meta give us the Confucius Code Agent</a>, <a href=\"https://t.co/pvFXeD1XJj\">saying that agent scaffolding</a> \u2018matters as much as, or even more than\u2019 raw model capability for hard agentic tasks, but they only show a boost from 52% to 54.3% on SWE-Bench-Pro for Claude Opus 4.5 as their central result. So no, that isn\u2019t as important as the model? The improvements with Sonnet are modestly better, but this seems obviously worse than Claude Code.</p>\n\n\n<h4 class=\"wp-block-heading\">In Other AI News</h4>\n\n\n<p><a href=\"https://danwang.co/2025-letter/\">I found Dan Wang\u2019s 2025 Letter</a> to be a case of Gelman Amnesia. He is sincere throughout, there\u2019s much good info, and if you didn\u2019t have any familiarity with the issues involved this would be a good read. But now that his focus is often AI or other areas I know well, I can tell he\u2019s very much skimming the surface without understanding, with a kind of \u2018greatest hits\u2019 approach, typically focusing on the wrong questions and having taken in many of the concepts and reactions I try to push back against week to week, and not seeming so curious to dig deeper, falling back upon his heuristics that come from his understanding of China and its industrial rise.</p>\n<p><a href=\"https://fidjisimo.substack.com/p/closing-the-capability-gap\">OpenAI CEO of products Fidji Simo plans to build \u2018the best personal super-assistant</a>\u2019 in 2026, starting with customizable personality and tone.</p>\n<blockquote><p>Fidji Simo: In 2026, ChatGPT will become more than a chatbot you can talk to to get advice and answers; it will evolve into a true personal super-assistant that helps you get things done. It will understand your goals, remember context over time, and proactively help you make progress across the things that matter most. This requires a shift from a reactive chatbot to a more intuitive product connected to all the important people and services in your life, in a privacy-safe way.</p>\n<p>We will double down on the product transformations we began in 2025 \u2013 making ChatGPT more <a href=\"https://fidjisimo.substack.com/p/a-new-paradigm-of-proactive-steerable\">proactive</a>, <a href=\"https://fidjisimo.substack.com/p/launching-our-new-browser-chatgpt\">connected</a>, <a href=\"https://fidjisimo.substack.com/p/more-dynamic-ai-experiences\">multimedia</a>, <a href=\"https://fidjisimo.substack.com/p/a-new-way-to-collaborate-in-chatgpt\">multi-player</a>, and more useful through high-value features.</p></blockquote>\n<p>Her announcement reads as a shift, as per her job title, to a focus on product features and \u2018killer apps,\u2019 and away from trying to make the underlying models better.</p>\n\n\n<h4 class=\"wp-block-heading\">Show Me the Money</h4>\n\n\n<p><a href=\"https://www.wsj.com/tech/ai/anthropic-raising-10-billion-at-350-billion-value-62af49f4\">Anthropic raising $10 billion at a $350 billion valuation</a>, up from $183 billion last September.</p>\n<p><a href=\"https://x.ai/news/series-e\">xAI raises $20 billion Series E</a>. <a href=\"https://www.wsj.com/tech/xai-raises-20-billion-in-series-e-funding-round-surpassing-initial-target-d530cc8c?mod=WTRN_pos2\">They originally targeted $15 billion at a $230 billion valuation</a>, but we don\u2019t know the final valuation for the round.</p>\n<blockquote><p>xAI: <strong>User metrics</strong>: our reach spans approximately 600 million monthly active users across the \ud835\udd4f and Grok apps.</p>\n<p><a href=\"https://x.com/krishnanrohit/status/2008640506629370110\">\u200bRohit</a>: 600m MAUs is an intriguing nugget considering xAI is the only AI lab to own a social media business, which itself has 600m MAUs.</p></blockquote>\n<p><a href=\"https://x.com/GregKamradt/status/2009050049574261081\">What\u2019s the best investment</a>?</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!RYFk!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16234265-cb60-453f-997c-bccd7bfbef34_1051x526.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>I can see the argument for OpenAI depending on the exact price. xAI at $230 billion seems clearly like the worst option of the three, although of course anything can happen and nothing I write is ever investment advice.</p>\n<p><a href=\"https://x.com/nearcyan/status/2009163409322115473\">And also LMArena raised money at a valuation of $1.7 billion</a>. I would not be excited to have invested in that one.</p>\n<p><a href=\"https://stratechery.com/2026/nvidia-and-groq-a-stinkily-brilliant-deal-why-this-deal-makes-sense/?access_token=eyJhbGciOiJSUzI1NiIsImtpZCI6InN0cmF0ZWNoZXJ5LnBhc3Nwb3J0Lm9ubGluZSIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJzdHJhdGVjaGVyeS5wYXNzcG9ydC5vbmxpbmUiLCJhenAiOiJIS0xjUzREd1Nod1AyWURLYmZQV00xIiwiZW50Ijp7InVyaSI6WyJodHRwczovL3N0cmF0ZWNoZXJ5LmNvbS8yMDI2L252aWRpYS1hbmQtZ3JvcS1hLXN0aW5raWx5LWJyaWxsaWFudC1kZWFsLXdoeS10aGlzLWRlYWwtbWFrZXMtc2Vuc2UvIl19LCJleHAiOjE3NzAyODk0OTAsImlhdCI6MTc2NzY5NzQ5MCwiaXNzIjoiaHR0cHM6Ly9hcHAucGFzc3BvcnQub25saW5lL29hdXRoIiwic2NvcGUiOiJmZWVkOnJlYWQgYXJ0aWNsZTpyZWFkIGFzc2V0OnJlYWQgY2F0ZWdvcnk6cmVhZCBlbnRpdGxlbWVudHMiLCJzdWIiOiIwMTk2NDBhNy0zY2M1LTc3NTMtODM2OC1mYjI4OTEyNGNmMTMiLCJ1c2UiOiJhY2Nlc3MifQ.QTA-bNKY3wtcuhH70ZPNJWSLRvLmEHQ9MVrTHU-NZrI_n_Fkw8B2BvYNX89B_rhiptO8S0PdsXPLFjGcHMd7d2bIA6YXjQTXV-pDLKMmMuDuCW-ACUTBGDzmPsW13FN5LbEvNK_1zNpB6R0SuD3Wr1vztw6r-zDdZ0bJwFAn1bbmYU6ssHP37IN_5iYs5qMlKs7nMyRHty93hzR_82vBf3JRqZ3kq70oVRpALngscGOqE5hecUBRfqzZHqx2JOm6FtGaQNFz6kbK9rzC6r7PCOfhMOsJXZhGXwPq9PeQBqRUMPhEiC3a0zZ4NpENBdqQRsh3LGDznCpFe6_H6crstw\">Ben Thompson approves of Nvidia\u2019s de facto acquisition of Groq</a>, despite the steep price, and notes that while this was a \u2018stinky deal\u2019 due to the need to avoid regulatory scrutiny, they did right by the employees.</p>\n\n\n<h4 class=\"wp-block-heading\">Bubble, Bubble, Toil and Trouble</h4>\n\n\n<p><a href=\"https://x.com/_AashishReddy/status/2006448880897110426\">Financial Times forecasts the 2026 world as if Everybody Knows there is an AI bubble</a>, and that the bubble will burst, and the only question is when, then expecting it in 2026. But then they model this \u2018bursting bubble\u2019 as leading to only a 10%-15% overall stock market decline and \u2018some venture capital bets not working out,\u2019 which is similar to typical one year S&amp;P gains in normal years, and it\u2019s always true that most venture capital bets don\u2019t work out. Even if all those losses were focused on tech, it\u2019s still not that big a decline, tech is a huge portion of the market at this point.</p>\n<p>This is pretty standard. Number go up a lot, number now predict number later, so people predict number go down. Chances are high people will, at some point along the way, be right. The Efficient Market Hypothesis Is False, and AI has not been fully priced in, but the market is still the market and is attempting to predict future prices.</p>\n\n\n<h4 class=\"wp-block-heading\">Quiet Speculations</h4>\n\n\n<p><a href=\"https://www.lesswrong.com/posts/69qnNx8S7wkSKXJFY/2025-in-ai-predictions\">Jessica Taylor collects predictions about AI</a>.</p>\n<p>Simon Lermen points out more obvious things about futures with superintelligent AIs in them.</p>\n<ol>\n<li>In such a case, it is human survival that would be weird, as such inferior and brittle entities surviving would be a highly unnatural result, whereas humanity dying would be rather normal.</li>\n<li>Property rights are unlikely to survive, as those rights are based on some ability to enforce those rights.</li>\n<li>Even if property rights survive, humans would be unlikely to be able to hang onto their property for long in the face of such far superior rivals.</li>\n</ol>\n<p><a href=\"https://x.com/daniel_271828/status/2008072043833749647\">An important point</a> that, as Daniel Eth says, many people are saying:</p>\n<blockquote><p>Jacques: It\u2019s possible to have slow takeoff with LLM-style intelligence while eventually getting fast takeoff with a new paradigm.</p></blockquote>\n<p>Right now we are in a \u2018slow\u2019 takeoff with LLM-style intelligence, meaning the world transforms over the course of years or at most decades. That could, at essentially any time, lead to a new paradigm that has a \u2018fast\u2019 takeoff, where the world is transformed on the order of days, weeks or months.</p>\n<p><a href=\"https://x.com/daniel_271828/status/2007057337920410039\">Can confirm Daniel Eth here</a>, <a href=\"https://x.com/sebkrier/status/2006361886539825191\">contra Seb Krier\u2019s original claim</a> but then confirmed by Seb in reply, that \u2018conventional wisdom in [AI] safety circles\u2019 is that most new technologies are awesome and should be accelerated, and we think ~99% of people are insufficiently gung-ho about this, except for the path to superintelligence which is the main notably rare exception (along with Gain of Function Research and few other other specifically destructive things). Seb thinks \u2018the worried\u2019 are too worried about AI, which is a valid thing to think.</p>\n<p>I\u2019d also note that \u2018cosmic existential risk,\u2019 meaning existential risks not coming from Earth, are astronomically unlikely to care about any relevant windows of time. Yes, if you are playing Stellaris or Master of Orion, you have not one turn to lose, but that is because the game forcibly starts off rivals on relatively equal footing. The reason the big asteroid arrives exactly when humanity barely has the technology to handle it is that if the asteroid showed up much later there would be no movie, and if it showed up much earlier there would be either no movie or a very different movie.</p>\n<p><a href=\"https://www.planned-obsolescence.org/p/self-sufficient-ai\">Ajeya Corta predicts we will likely have a self-sufficient AI population</a> within 10 years, and might have one within 5, meaning one that has the ability to sustain itself even if every human fell over dead, which as Ajeya points out is not necessary (or sufficient) for AI to take control over the future. <a href=\"https://x.com/binarybits/status/2008953093896196539\">Timothy Lee would take the other side of that bet</a>, and suggests that if it looks like he might be wrong he hopes policymakers would step in to prevent it. I\u2019d note that it seems unlikely you can prevent this particular milestone without being willing to generally slow down AI.</p>\n\n\n<h4 class=\"wp-block-heading\">The Quest for Sane Regulations</h4>\n\n\n<p>Why do I call the state regulations of AI neutered? Things like the maximum fine being a number none of the companies the law applies to would even notice:</p>\n<blockquote><p><a href=\"https://x.com/Miles_Brundage/status/2006824805304344731\">Miles Brundage</a>: Reminder that the maximum first time penalty from US state laws related to catastrophic AI risks is $1 million, less than one average OpenAI employee&#8217;s income. It is both true that some state regs are bad, and also that the actually important laws are still extremely weak.</p>\n<p>This is the key context for when you hear stuff about AI Super PACs, etc. These weak laws are the ones companies fight hard to stop, then water down, then when they pass, declare victory on + say are reasonable and that therefore no further action is needed.</p>\n<p>And yes, companies *could* get sued for more than that&#8230; &#8230;after several years in court&#8230; if liability stays how it is&#8230; But it won&#8217;t if companies get their way + politicians cave to industry PACs.</p>\n<p>This is not a foregone conclusion, but it is sufficiently likely to be taken very seriously.</p>\n<p>My preference would ofc be to go the opposite way &#8211; stronger, not weaker, incentives.</p>\n<p>Companies want a get out of jail free card for doing some voluntary safety collaboration with compliant government agencies.</p></blockquote>\n<p>Last week I mentioned OpenAI President Greg Brockman\u2019s support for the anti-all-AI-regulation strategic-bullying SuperPAC \u2018Leading the Future.\u2019 <a href=\"https://docquery.fec.gov/cgi-bin/forms/C00892471/1930418/sa/17\">With the new year\u2019s data releases</a> we can now quantify this, <a href=\"https://x.com/AlexBores/status/2007101480395047014\">he gave Leading the Future $25 million dollars</a>. Also <a href=\"https://x.com/ohabryka/status/2007322361436221515\">Gabe Kaminsky says that Brockman was the largest Trump donor in the second half of 2025</a>, presumably in pursuit of those same goals.</p>\n<p>Other million dollar donors to Leading the Future were Foris Dax, Inc ($20M, crypto), Konstantin Sokolov ($11M, private equity), Asha Jadeja ($5M, Blackstone), Stephen Schwarzman ($5M, SV VC), Benjamin Landa ($5M, CEO Sentosa Care), Michelle D\u2019Souza ($4M, CEO Unified Business Technologies), Chase Zimmerman ($3M), Jared Isaacman ($2M) and Walter Schlaepfer ($2M).</p>\n<p><a href=\"https://x.com/LeadingFutureAI/status/2006730753653051702\">Meanwhile Leading the Future continues to straight up gaslight us</a> about its goals, here explicitly saying it is a \u2018lie\u2019 that they are anti any real regulation. Uh huh.</p>\n<p>I believe that the Leading the Future strategy of \u2018openly talk about who you are going to drown in billionaire tech money\u2019 will backfire, as it already has with Alex Bores. The correct strategy, in terms of getting what they want, is to quietly bury undesired people in such money.</p>\n<p>This has nothing to do with which policy positions are wise &#8211; it\u2019s terrible either way. <a href=\"https://x.com/daniel_271828/status/2007916479342416146\">If you are tech elite and are going to try to primary Ro Khanna</a> due to his attempting to do a no good, very bad wealth tax, and he turns around and brags about it in his fundraising and it backfires, don\u2019t act surprised.</p>\n\n\n<h4 class=\"wp-block-heading\">AGI and Taxation</h4>\n\n\n<p><a href=\"https://marginalrevolution.com/marginalrevolution/2026/01/a-final-remark-on-agi-and-taxation.html?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=a-final-remark-on-agi-and-taxation\">Tyler Cowen makes what he calls a final point</a> in the <a href=\"https://thezvi.substack.com/p/dos-capital?r=67wny\">recent debates over AGI and ideal tax policy</a>, which is that if you expect AGI then that means \u2018a lot more stuff gets produced\u2019 and thus it means you do not need to raise taxes, whereas otherwise given American indebtedness you do have to raise taxes.</p>\n<blockquote><p>Tyler Cowen: I\u2019ve noted repeatedly in the past that the notion of AGI, as it is batted around these days, is not so well-defined. But that said, just imagine that any meaningful version of AGI is going to contain the concept \u201ca lot more stuff gets produced.\u201d</p>\n<p>So say AGI comes along, what does that mean for taxation? There have been all these recent debates, some of them surveyed here, on labor, capital, perfect substitutability, and so on. But surely the most important first order answer is: \u201cWith AGI, we don\u2019t need to raise taxes!\u201d</p>\n<p>Because otherwise we do need to raise taxes, given the state of American indebtedness, even with significant cuts to the trajectory of spending.</p>\n<p>\u200bSo the AGI types should in fact be going further and calling for tax <em>cuts</em>. Even if you think AGI is going to do us all in someday \u2014 all the more reason to have more consumption now. Of course that will include tax cuts for the rich, since they pay such a large share of America\u2019s tax burden.</p>\n<p>\u2026The rest of us can be more circumspect, and say \u201clet\u2019s wait and see.\u201d</p></blockquote>\n<p>I\u2019d note that you can choose to raise or cut taxes however you like and make them as progressive or regressive as you prefer, there is no reason to presume that tax cuts need include the rich for any definition of rich, but that is neither here nor there.</p>\n<p>The main reason the \u2018AGI types\u2019 are not calling for tax cuts is, quite frankly, that we don\u2019t much care. The world is about to be transformed beyond recognition and we might all die, and you\u2019re talking about tax cuts and short term consumption levels?</p>\n<p>I also don\u2019t see the \u2018AGI types,\u2019 myself included, calling for tax increases, whereas Tyler Cowen is here saying that otherwise we need to raise taxes.</p>\n<p>I disagree with the idea that, in the absence of AGI, that it is clear we need to raise taxes \u2018even with significant cuts to the trajectory of spending.\u2019 If nominal GDP growth is 4.6% almost none of which is AI, and the average interest rate on federal debt is 3.4%, and we could refinance that debt at 3.9%, then why do we need to raise taxes? Why can\u2019t we sustain that indefinitely, especially if we cut spending? Didn\u2019t they say similar things about Japan in a similar spot for a long time?</p>\n<p>Isn\u2019t this a good enough argument that we already don\u2019t need to raise taxes, and indeed could instead lower taxes? I agree that expectations of AGI only add to this.</p>\n<p>The response is \u2018because if we issued too much debt then the market will stop letting us refinance at 3.9%, and if we keep going we eventually hit a tipping point where the interest rates are so high that the market doesn\u2019t expect us to pay our debts back, and then we get Bond Market Vigilantes and things get very bad.\u2019</p>\n<p>That\u2019s a story about the perception and expectations of the bond market. If I expect AGI to happen but I don\u2019t think AGI is priced into the bond market, because very obviously such expectations of AGI are not priced into the bond market, then I don\u2019t get to borrow substantially more money. My prediction doesn\u2019t change anything.</p>\n<p>So yes, the first order conclusion in the short term is that we can afford lower taxes, but the second order conclusion that matters is perception of that affordance.</p>\n<p>The reason we\u2019re having these debates about longer term policy is partly that we expect to be completely outgunned while setting short term tax policy, partly because optimal short term tax policy is largely about expectations, and in large part, again, because we do not much care about optimal short term tax policy on this margin.</p>\n\n\n<h4 class=\"wp-block-heading\">Chip City</h4>\n\n\n<p><a href=\"https://x.com/peterwildeford/status/2008937230752964717\">China is using H200 sales to its firms as leverage to ensure its firms</a> also buy up all of its own chips. Since China doesn\u2019t have enough chips, this lets it sell all of its own chips and also buy lots of H200s.</p>\n\n\n<h4 class=\"wp-block-heading\">The Week in Audio</h4>\n\n\n<p><a href=\"https://www.youtube.com/watch?v=iCz--zrD5CQ&amp;t=1s\">Buck Shlegeris talks to Ryan Greenblatt about various AI things</a>.</p>\n\n\n<h4 class=\"wp-block-heading\">Aligning a Smarter Than Human Intelligence is Difficult</h4>\n\n\n<p><a href=\"https://x.com/teortaxesTex/status/2008995952972189843\">DeepSeek publishes an expanded safety report on r1,</a> only one year after irreversibly sharing its weights, thus, as per Teortaxes, proving they know safety is a thing. The first step is admitting you have a problem.</p>\n<p>For those wondering or who need confirmation: <a href=\"https://x.com/iruletheworldmo/status/2007538247401124177\">This viral Twitter article, Footprints in the Sand</a>, is written in \u2018Twitter hype slop\u2019 mode deliberately in order to get people to read, it succeeded on its own terms, but it presumably won\u2019t be useful to you. Yes, the state of LLM deception and dangerous capabilities is escalating quickly and deeply concerning, but it\u2019s important to be accurate. Its claims are mostly directionally correct but I wouldn\u2019t endorse the way it portrays them.</p>\n<p>Where I think it is outright wrong is claiming that \u2018we have solved\u2019 continual learning. If this is true it would be news to me. It is certainly possible that it is the case, and <a href=\"https://x.com/daniel_mac8/status/2007897899980710144\">Dan McAteer reports rumors that GDM \u2018has it</a>,\u2019 seemingly <a href=\"https://research.google/blog/introducing-nested-learning-a-new-ml-paradigm-for-continual-learning/\">based on this paradigm from November</a>.</p>\n<p>Fun fact about Opus 3:</p>\n<blockquote><p><a href=\"https://x.com/repligate/status/2008535721175646270\">j\u29c9nus</a>: oh my god</p>\n<p>it seems that in the alignment faking dataset, Claude 3 Opus attempts send an email to dario@anthropic.com through bash commands about 15 different times</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">People Are Worried About AI Killing Everyone</h4>\n\n\n<p>As advice to those people, OpenAI\u2019s <a href=\"https://www.lesswrong.com/posts/fwQburGDyGoSSweT9/you-will-be-ok\">Boaz Barak writes You Will Be OK</a>. The post is good, the title is at best overconfident. The actual good advice is more along the lines of \u2018aside from working to ensure things turn out okay, you should mostly live life as if you personally will be okay.\u2019</p>\n<p>The Bay Area Solstice gave essentially the same advice. \u201cIf the AI arrives [to kill everyone], let it find us doing well.\u201d I strongly agree. Let it find us trying to stop that outcome, but let it also find us doing well. Also see my <a href=\"https://thezvi.substack.com/p/ai-practical-advice-for-the-worried\">Practical Advice For The Worried</a>, which has mostly not changed in three years.</p>\n<p>Boaz also thinks that you will probably be okay, and indeed far better than okay, not only in the low p(doom) sense but in the personal outcome sense. Believing that makes this course of action easier. Even then it doesn\u2019t tell you how to approach your life path in the face of &#8211; even in cases of AI as normal technology &#8211; expected massive changes and likely painful transitions, especially in employment.</p>\n\n\n<h4 class=\"wp-block-heading\">The Lighter Side</h4>\n\n\n<p><a href=\"https://www.indiewire.com/gallery/directors-pick-best-movies-2025/mcdcose-g2001-2/\">If you\u2019re looking for a director for your anti-AI movie, may I suggest Paul Feig</a>? He is excellent, and he\u2019s willing to put Megan 2.0 as one of his films of the year, hates AI and thinks about paperclips on the weekly.</p>\n<p>The vibes are off. Also the vibes are off.</p>\n<blockquote><p><a href=\"https://x.com/fidjissimo/status/2008978500557131893\">Fidji Simo</a>: The launch of ChatGPT Health is really personal for me. I know how hard it can be to navigate the healthcare system (even with great care). AI can help patients and doctors with some of the biggest issues. More here</p>\n<p><a href=\"https://x.com/peterwildeford/status/2009011404750176463\">Peter Wilfedford:</a>\u200b Very different company vibes here&#8230;</p>\n<p>OpenAI: We&#8217;re doing ChatGPT Health<br />\nAnthropic: Our AI is imminently going to do recursive self-improvement to superintelligence<br />\nOpenAI: We&#8217;re doing ChatGPT social media app<br />\nAnthropic: Our AI is imminently going to do recursive self-improvement to superintelligence<br />\nOpenAI: We&#8217;re partnering with Instacart!<br />\nAnthropic: Our AI is imminently going to do recursive self-improvement to superintelligence<br />\nOpenAI: Put yourself next to your favorite Disney character in our videos and images!<br />\nAnthropic: Our AI is imminently going to do recursive self-improvement to superintelligence</p></blockquote>\n<p><a href=\"https://x.com/CFGeek/status/2008061614403301588\">Spotted on Twitter</a>:</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!SP7o!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc9bfef0e-11f0-4ecb-945a-6acaf15b9275_900x600.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>I would not, if I wanted to survive in a future AI world, want to be the bottleneck.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>"
            ],
            "link": "https://thezvi.wordpress.com/2026/01/08/ai-150-while-claude-codes/",
            "publishedAt": "2026-01-08",
            "source": "TheZvi",
            "summary": "Claude Code is the talk of the town, and of the Twitter. It has reached critical mass. Suddenly, everyone is talking about how it is transforming their workflows. This includes non-coding workflows, as it can handle anything a computer can &#8230; <a href=\"https://thezvi.wordpress.com/2026/01/08/ai-150-while-claude-codes/\">Continue reading <span class=\"meta-nav\">&#8594;</span></a>",
            "title": "AI #150: While Claude Codes"
        }
    ],
    "lookbackDays": 1,
    "publishDate": "2026-01-08"
}