{
    "articles": [
        {
            "content": [
                "<p>This is an <a href=\"https://press.asimov.com/articles/dna-information\">article</a> that just appeared in Asimov Press, who kindly agreed that I could publish it here and also humored my deep emotional need to use words like \u201cSparklepuff\u201d.</p>\n\n<hr />\n\n<p>Do you like information theory? Do you like molecular biology? Do you like the idea of smashing them together and seeing what happens? If so, then here\u2019s a question: How much information is in your DNA?</p>\n\n<p>When I first looked into <a href=\"https://dynomight.net/data-wall/\">this question</a>, I thought it was simple:</p>\n\n<ol>\n  <li>Human DNA has about 3.1 billion base pairs.</li>\n  <li>Each base pair can take one of four values (A, T, C, or G)</li>\n  <li>It takes 2 bits to encode one of four possible values (00, 01, 10, or 11)</li>\n  <li>Thus, human DNA contains 6.2 billion bits.</li>\n</ol>\n\n<p>Easy, right? Sure, except:</p>\n\n<ol>\n  <li>You have <em>two</em> versions of each base pair, one from each of your parents. Should you count both?</li>\n  <li>All humans have almost identical DNA. Does that matter?</li>\n  <li>DNA can be compressed. Should you look at the compressed representation?</li>\n  <li>It\u2019s not clear how much of our DNA actually does something useful. The insides of your cells are a convulsing pandemonium of interacting \u201chacks\u201d, designed to keep working even as mutations constantly screw around with the DNA itself. Should we only count the \u201cuseful\u201d parts?</li>\n</ol>\n\n<p>Such questions quickly run into the limits of knowledge for both biology and computer science. To answer them, we need to figure out what exactly we mean by \u201cinformation\u201d and how that\u2019s related to what\u2019s happening inside cells. In attempting that, I will lead you through a frantic tour of information theory and molecular biology. We\u2019ll meet some strange characters, including genomic compression algorithms based on deep learning, retrotransposons, and Kolmogorov complexity.</p>\n\n<p>Ultimately, I\u2019ll argue that the intuitive idea of information in a genome is best captured by a new definition of a \u201cbit\u201d\u2014one that\u2019s unknowable with our current level of scientific knowledge.</p>\n\n<h2 id=\"on-counting\">On counting</h2>\n\n<p>What is \u201cinformation\u201d? This isn\u2019t <em>just</em> a pedantic question, as there are actually several different mathematical definitions of a \u201cbit\u201d. Often, the differences don\u2019t matter, but for DNA, they turn out to matter a lot, so let\u2019s start with the simplest.</p>\n\n<p>In the <strong>storage space definition</strong>, a bit is a \u201cslot\u201d in which you can store one of two possible values. If some object can represent <em>2\u207f</em> possible patterns, then it contains <em>n</em> bits, regardless of which pattern actually happens to be stored.</p>\n\n<p>So here\u2019s a question we can answer precisely: How much information <em>could</em> your DNA store?</p>\n\n<p>A few reminders: DNA is a polymer. It\u2019s a long chain of chunks of ~40 atoms called \u201cnucleotides\u201d. There are four different chunks, commonly labeled A, T, C, and G. In humans, DNA comes in 23 pieces of different lengths, called \u201cchromosomes\u201d. Humans are \u201cdiploid\u201d, meaning we have two versions of each chromosome. We get one from each of our parents, made by randomly weaving together sections from the two chromosomes <em>they</em> got from <em>their</em> parents.</p>\n\n<details>\n  \nAt least, that's true for the first 22 chromosomes. For the last, females have two \"X\" chromosomes, while males have one \"X\" and one \"Y\" chromosome. There's no mixing between these, so men pass on one to their children pretty much unchanged.\n\n  <p>Technically there\u2019s also a tiny amount of DNA in the mitochondria. This is neat because you get it from your mother basically unchanged and so scientists can trace tiny mutations back to see how our great-great-\u2026-great grandmothers were all related. If you go far enough back, our maternal lines all lead to a single woman, <a href=\"https://en.wikipedia.org/wiki/Mitochondrial_Eve\">Mitochondrial Eve</a>, who probably lived in East Africa 120,000 to 156,000 years ago. But mitochondrial DNA is tiny so I won\u2019t mention it again.</p>\n</details>\n\n<p><img alt=\"karyotype\" src=\"https://dynomight.net/img/dna/karyotype.jpg\" /></p>\n\n<p>Chromosomes 1-22 have a total of 2.875 billion nucleotides; the X chromosome has 156 million, and the Y chromosome has 62 million. From here, we can calculate the total storage space in your DNA. Remember, each nucleotide has 4 options, corresponding to 2 bits. So if you\u2019re female, your total storage space is:</p>\n\n<p>\u00a0\u00a0(2\u00d72875 + 2\u00d7156) million nucleotides<br />\n\u00a0\u00a0\u00a0\u00a0  \u00d7 2 bits / nucleotide<br />\n\u00a0\u00a0\u00a0\u00a0  = 12.12 billion bits<br />\n\u00a0\u00a0\u00a0\u00a0  = 1.51 GB.</p>\n\n<p>If you\u2019re male, the total storage space is:</p>\n\n<p>\u00a0\u00a0(2\u00d72875 + 156 + 62) million nucleotides<br />\n\u00a0\u00a0\u00a0\u00a0  \u00d7 2 bits / nucleotide<br />\n\u00a0\u00a0\u00a0\u00a0  = 11.94 billion bits<br />\n\u00a0\u00a0\u00a0\u00a0  = 1.49 GB.</p>\n\n<p>For comparison, a standard single-layer DVD can store 37.6 billion bits or 4.7 GB. The code for your body, magnificent as it is, takes up as much space as around 40 minutes of standard definition video.</p>\n\n<p>So in principle, your DNA could represent around 2<sup>12,000,000,000</sup> different patterns. But hold on. Given human common ancestry, the chromosome pair you got from your mother is almost identical to the one you got from your father. And even ignoring that, there are long sequences of nucleotides that are repeated over and over in your DNA, enough to make up a significant fraction of the total. It seems weird to count all this repeated stuff. So perhaps we want a more nuanced definition of \u201cinformation.\u201d</p>\n\n<h2 id=\"on-compression\">On compression</h2>\n\n<p>A string of 12 billion zeros is much longer than this article. But most people would (I hope) agree that this article contains more information than a string of 12 billion zeros. Why?</p>\n\n<p>One of the fundamental ideas from information theory is to define information in terms of compression. Roughly speaking, the \u201cinformation\u201d in some string is the length of the shortest possible compressed representation of that string.</p>\n\n<p>So how much can you compress DNA? Answers to this question are all over the place. Some people claim it can be compressed by more than 99 percent, while others claim the state of the art is only around 25 percent. This discrepancy is explained by different definitions of \u201ccompression\u201d, which turn out to correspond to different notions of \u201cinformation\u201d.</p>\n\n<details>\n\n  \nIf you pick any two random people on Earth, almost all of their DNA will be exactly the same. It's often said that people are 99.9 percent genetically identical, but this is wrong \u2014 it only measures substitutions and neglects things like insertions, deletions, and transpositions. If you account for all these things, the best estimate is that we are ~<a href=\"https://www.genome.gov/about-genomics/educational-resources/fact-sheets/human-genomic-variation\">99.6 percent identical</a>.\n\n\n  <p>Fun facts: Because of these deletions and insertions, different people have slightly different amounts of DNA. In fact, each of your chromosome pairs have DNA of slightly different lengths. When your body creates sperm/ova it uses a <a href=\"https://en.wikipedia.org/wiki/Synaptonemal_complex\">crazy machine</a> to align the chromosomes in a sensible way so different sections can be woven together without creating nonsense. Also, those same measures of similarity would say that we\u2019re around 96 percent identical with our closest living cousins, the bonobos and chimpanzees.</p>\n\n</details>\n\n<p>The fact that we share so much DNA is key to how some algorithms can compress DNA by more than 99 percent. They do this by first storing a <em>reference</em> genome, which includes all the DNA that\u2019s shared by all people and perhaps the most common variants for regions of DNA where people differ. Then, for each individual person, these algorithms only store the <em>differences</em> from the reference genome. Because that reference only has to be stored once, it isn\u2019t counted in the compressed representation.</p>\n\n<p>That\u2019s great if you want to cram as many of your friends\u2019 genomes on a hard drive as possible. But it\u2019s a strange definition to use if you want to measure the \u201cinformation content of DNA\u201d. It implies that any genomic content that doesn\u2019t change between individuals isn\u2019t important enough to count as \u201cinformation\u201d. However, we know from evolutionary biology that it\u2019s often the most crucial DNA that changes the least <em>precisely because</em> it\u2019s so important. Heritability tends to be <a href=\"https://dynomight.net/heritability/#example-heritability-in-different-species\">lower</a> for genes more closely related to reproduction.</p>\n\n<p>The best compression <em>without</em> a reference seems to be around <a href=\"https://doi.org/10.1093/gigascience/giaa119\">25 percent</a>. (I expect this number to rise a bit over time, as the newest methods use deep learning and research is ongoing.) That\u2019s not a lot of compression. However, these algorithms are benchmarked in terms of how well they compress a genome that includes only <em>one</em> copy of each chromosome. Since your two chromosomes are almost identical (at least, ignoring the Y chromosome), I\u2019d guess that you could represent the other half almost for free, meaning a compression rate of around 50 percent + \u00bd \u00d7 25 percent \u2248 62 percent.</p>\n\n<h2 id=\"on-information\">On information</h2>\n\n<p>So if you compress DNA using an algorithm with a reference genome, it can be compressed by more than 99 percent, down to less than 120 million bits. But if you compress it without a reference genome, the best you can do is 62 percent, meaning 4.6 billion bits.</p>\n\n<p>Which of these is right? The answer is that <em>either</em> could be right. There are two different definitions of a \u201cbit\u201d in information theory that correspond to different types of compression.</p>\n\n<p>In the <strong>Kolmogorov complexity definition</strong>, named after the remarkable Soviet mathematician Andrey Kolmogorov, a bit is a property of a particular string of <code class=\"language-plaintext highlighter-rouge\">1</code>s and <code class=\"language-plaintext highlighter-rouge\">0</code>s. The number of bits of information in the string is the length of the shortest computer program that would output that string.</p>\n\n<p>In the <strong>Shannon information definition</strong>, named after the also-remarkable American polymath Claude Shannon, a bit is again a property of a particular sequence of <code class=\"language-plaintext highlighter-rouge\">1</code>s and <code class=\"language-plaintext highlighter-rouge\">0</code>s, but it\u2019s only defined relative to some large pool of possible sequences. In this definition, if a given sequence has a probability <em>p</em> of occurring, then it contains <em>n</em> bits for whatever value of <em>n</em> satisfies <em>2\u207f=1/p</em>. Or, equivalently, <em>n=-log\u2082 p</em>.</p>\n\n<p>The Kolmogorov complexity definition is clearly related to compression. But what about Shannon\u2019s?</p>\n\n<p>Well, say you have three beloved pet rabbits, Fluffles, Marmalade, and Sparklepuff. And say you have one picture of each of them, each 1 MB large when compressed. To keep me updated on how you\u2019re feeling, you like to send me these same pictures over and over again, with different pets for different moods. You send a picture of Fluffles \u00bd the time, Marmalade \u00bc of the time, and Sparklepuff \u00bc of the time. (You only communicate in rabbit pictures, never with text or images.)</p>\n\n<p>But then you decide to take off in a spacecraft, and your data rates go <em>way</em> up. Continuing the flow of pictures is crucial, so what\u2019s the cheapest way to do that? The best thing would be that we agree that if you send me a <code class=\"language-plaintext highlighter-rouge\">0</code>, I should pull up the picture of Fluffles, while if you send <code class=\"language-plaintext highlighter-rouge\">10</code> I should pull up Marmalade, and if you send <code class=\"language-plaintext highlighter-rouge\">11</code>, I should pull up Sparklepuff. This is unambiguous: If you send 0011100, that means Fluffles, then Fluffles again, then Sparklepuff, then Marmalade, then Fluffles one more time.</p>\n\n<p>It all works out. The \u201ccode length\u201d for Fluffles is the number <em>n</em> so that <em>2\u207f=1/p</em>:</p>\n\n<table>\n  <thead>\n    <tr>\n      <th>pet</th>\n      <th>probability <em>p</em></th>\n      <th>code</th>\n      <th>code length <em>n</em></th>\n      <th><em>2\u207f</em></th>\n      <th><em>1/p</em></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>Fluffles</td>\n      <td>\u00bd</td>\n      <td><code class=\"language-plaintext highlighter-rouge\">0</code></td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <td>Marmelade</td>\n      <td>\u00bc</td>\n      <td><code class=\"language-plaintext highlighter-rouge\">10</code></td>\n      <td>2</td>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <td>Sparklepuff</td>\n      <td>\u00bc</td>\n      <td><code class=\"language-plaintext highlighter-rouge\">11</code></td>\n      <td>2</td>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n\n<p>Intuitively, the idea is that if you want to send as few bits as possible over time, then you should give short codes to high-probability patterns and long codes to low-probability patterns. If you do this <em>optimally</em> (in the sense that you\u2019ll send the fewest bits over time), it turns out that the best thing is to code a pattern with probability <em>p</em> with about <em>n</em> bits, where <em>2\u207f=p</em>. (In general, things don\u2019t work out quite this nicely, but you get the idea.)</p>\n\n<p>In the Fluffles scenario, the Kolmogorov complexity definition would say that each of the images contains 1 MB of information since that\u2019s the smallest each image can be compressed. But under the Shannon information definition, the Fluffles image contains 1 bit of information, and the Marmalade and Sparklepuff images contain 2 bits. This is quite a difference!</p>\n\n<p>Now, let\u2019s return to DNA. There, the Kolmogorov complexity definition basically corresponds to the best possible compression algorithm without a reference. As we saw above, the best-known current algorithm can compress by 62 percent. So, under the Kolmogorov complexity definition, DNA contains at most 12 billion \u00d7 (1-0.62) \u2248 4.6 billion bits of information.</p>\n\n<p>Meanwhile, under the Shannon information definition, you can assume that the distribution of all human genomes is known. The information in <em>your</em> DNA only includes the bits needed to reconstruct <em>your</em> genome. That\u2019s essentially the same as compressing with a reference. So, under the Shannon information definition, your DNA contains less than 12 billion \u00d7 (1-0.01) \u2248 120 million bits of information.</p>\n\n<p>While neither of these is \u201cwrong\u201d for DNA, I prefer the Kolmogorov complexity definition for its ability to best capture DNA that codes for features and functions shared by all humans. After all, if you\u2019re trying to measure how much \u201cinformation\u201d our DNA carries from our evolutionary history, surely you want to include that which has been universally preserved.</p>\n\n<h2 id=\"on-biology\">On biology</h2>\n\n<p>At some point, your high-school biology teacher probably told you (or will tell you) this story about how life works:</p>\n\n<ol>\n  <li>\n    <p>First, your DNA gets transcribed into matching RNA.</p>\n  </li>\n  <li>\n    <p>Next, that RNA gets translated into protein.</p>\n  </li>\n  <li>\n    <p>Then the protein does Protein Stuff.</p>\n  </li>\n</ol>\n\n<p>If things were that simple, we could easily calculate the information density of DNA just by looking at what fraction of your DNA ever becomes a protein (only around 1 percent). But it\u2019s not that simple. The rest of your DNA does other important things, like regulating what proteins get made. Some of it seems to exist only for the purpose of copying itself. Some of it might do nothing, or it might do important things we don\u2019t even know about yet.</p>\n\n<ol>\n  <li>\n    <p>In the beginning, your DNA is relaxing in the nucleus.</p>\n  </li>\n  <li>\n    <p>Some parts of your DNA, called <strong>promoters</strong>, are designed so that if certain proteins are nearby, they\u2019ll stick to the DNA.</p>\n  </li>\n  <li>\n    <p>If that happens, then a hefty little enzyme called \u201cRNA polymerase\u201d will show up, crack open the two strands of DNA, and start transcribing the nucleotides on one side into \u201cpre-messenger RNA\u201d (pre-mRNA).</p>\n  </li>\n  <li>\n    <p>Eventually, for one of several reasons\u2014none of which make any sense to me\u2014the enzyme will decide it\u2019s time to stop transcribing, and the pre-mRNA will detach and float off into the nucleus. At this point, it\u2019s a few thousand or a few tens of thousands of nucleotides long.</p>\n  </li>\n  <li>\n    <p>Then, my personal favorite macromolecular complex, the \u201cspliceosome\u201d, grabs the pre-mRNA, cuts away most of it, and throws those parts away. The sections of DNA that code for the parts that are kept are called <strong>exons</strong>, while the sections that code for parts that are thrown away are called <strong>introns</strong>.</p>\n  </li>\n  <li>\n    <p>Next, another enzyme called \u201cRNA guanylyltransferase\u201d (we can\u2019t all be beautiful) adds a \u201ccap\u201d to one end, and an enzyme called \u201cpoly(A) polymerase\u201d adds a \u201ctail\u201d to the other end.</p>\n  </li>\n  <li>\n    <p>The pre-mRNA is now all grown up and has graduated to being regular mRNA. At this point, it is a few hundred or a few thousand nucleotides long.</p>\n  </li>\n  <li>\n    <p>Then, some proteins notice that the mRNA has a tail, grab it, and throw it out of the nucleus into the cytoplasm, where the noble ribosome lurks.</p>\n  </li>\n  <li>\n    <details>The ribosome grabs the mRNA and turns it into a protein. It does this by starting at one end and looking at chunks of three nucleotides at a time, called \"codons\". When it sees a certain \"start\" pattern, it starts translating each chunk into one of 20 amino acids and continues until it sees a chunk with a \"stop\" pattern.Since there are 4 kinds of nucleotides, there are 4\u00b3=64 possible chunks, while your body only uses 20 amino acids. So the ribosome, logically, gives some amino acids (like leucine) six different codons, and others (like tryptophan) only one codon. Also there are three different stop codons, but only one start codon, and that start codon is also the codon for methionine. So all proteins have methionine at one end unless something else comes and removes it later. Biology is layer after layer of this kind of exasperating complexity, totally indifferent to your desire to understand it.</details>\n  </li>\n  <li>The resulting protein lives happily ever after.</li>\n</ol>\n\n<p>It\u2019s thought that ~<a href=\"https://en.wikipedia.org/wiki/Exon\">1 percent</a> of your DNA is exons and ~<a href=\"https://www.ncbi.nlm.nih.gov/books/NBK595930/\">24 percent</a> is introns. What\u2019s the rest of it doing?</p>\n\n<p>Well, while the above dance is happening, other sections of DNA are \u201cregulating\u201d it. <strong>Enhancers</strong> are regions of DNA where a certain protein can bind and cause the DNA to physically bend so that some promoter somewhere else (typically within a million nucleotides) is more likely to get activated. <strong>Silencers</strong> do the opposite. <strong>Insulators</strong> block enhancers and silencers from influencing regions they shouldn\u2019t influence.</p>\n\n<p>While that might sound complicated, we\u2019re just warming up. The same region of DNA can be both an intron and an enhancer <em>and/or</em> a silencer. That\u2019s right, in the middle of the DNA that codes for some protein, evolution likes to put DNA that regulates some other, distant protein. When it\u2019s not regulating, it gets transcribed into (probably useless) pre-RNA and then cut away and recycled by the spliceosome.</p>\n\n<details>\n  \nThere's also structural DNA that's needed to physically manipulate the chromosomes. <strong>Centromeres</strong> are \"attachment points\" used when copying DNA during cell division. <strong>Telomeres</strong> are \"extra\" DNA at the ends of the chromosomes.\n\n  <p>Telomeres shrink as we age. The body has mechanisms to re-lengthen them, but it mostly only uses these in stem cells and reproductive cells. Longevity folks are interested in activating these mechanisms in other tissues to fight aging, but this is risky since the body seems to <em>intentionally</em> limit telomere repair as a strategy to prevent cancer cells from growing out of control.</p>\n</details>\n\n<p>Further complicating this picture are many regions of DNA that code for RNA that\u2019s never translated into a protein but still has some function. Some regions make tRNA, whose job is to bring amino acids to the ribosome. Other regions make rRNA, which bundle together with some proteins to <em>become</em> the ribosome. There\u2019s siRNA, microRNA, and piRNA that screw around with mRNA produced. And there\u2019s scaRNA, snoRNA, rRNA, lncRNA, and mrRNA. Many more types are sure to be defined in the future, both because it\u2019s hard to know for sure if DNA gets transcribed, it\u2019s hard to know what functions RNA might have, and because academics have strong incentives to invent ever-finer subcategories.</p>\n\n<details>\n  \nThere are also <strong>pseudogenes</strong>. These are regions of DNA that <em>almost</em> make proteins, but not quite. Sometimes, this happens because they lack a promoter, so they never get transcribed into mRNA. Other times, they might lack a start codon, so after their mRNA makes it to the ribosome, it never actually starts making a protein. Then, there are instances when the DNA has an early stop codon or a \"frameshift\" mutation meaning the alignment of the RNA into chunks of three gets screwed up. In these cases, the ribosome will often detect that something is wrong and <a href=\"https://en.wikipedia.org/wiki/Nonsense-mediated_decay\">call for help</a> to destroy the protein. In other cases, a short protein is made that doesn't do anything.\n\n  <p>In more serious cases, these mutations might make the organism non-viable, or lead to problems like Tay-Sachs disease or Cystic fibrosis. But this wouldn\u2019t be considered a pseudogene.</p>\n</details>\n\n<h2 id=\"on-messiness\">On messiness</h2>\n\n<p>Why? Why is this all such a mess? Why is it so hard to say if a given section of DNA does anything useful?</p>\n\n<p>Biologists hate \u201cwhy\u201d questions. We can\u2019t re-run evolution, so how can we say \u201cwhy\u201d evolution did things the way it did? Better to focus on <em>how</em> biological systems actually work. This is probably wise. But since I\u2019m not a biologist (or wise), I\u2019ll give my theory: Cells work like this because DNA is under constant attack from mutations.</p>\n\n<p>Mutations most commonly arise during cell replication. Your DNA is composed of around 250 billion atoms. Making a perfect copy of all those atoms is hard. Your body has amazing nanomachines with many redundant mechanisms to try to correct errors, and it\u2019s estimated that the error rate is less than <a href=\"https://doi.org/10.1038/cr.2008.4\">one per billion nucleotides</a>. But with several billion nucleotides, mutations happen.</p>\n\n<p>There are also <em>environmental</em> sources of mutations. Ultraviolet light has more energy than visible light. If it hits your skin, that energy can sort of knock atoms out of place. The same thing happens if you\u2019re exposed to radiation. Certain chemicals, like formaldehyde, benzene, or asbestos, can also do this or can interfere with your body\u2019s error correction tricks.</p>\n\n<details>\n  \nFinally, we return to the huge fraction of your DNA (~50-60 percent) that repeats of the same sequences. Some of this is caused by the machinery \"slipping\" while making a copy, leading to a loss or repetition of some DNA. There are also little sections of DNA called \"transposons\" that sort of trick your machinery into making another copy of those sections and then inserting them somewhere else in the genome.\n\n  <p>\u201cDNA transposons\u201d get cut out and stuck back in somewhere else, while \u201cretrotransposons\u201d create RNA that\u2019s designed to get reverse-transcribed back into the DNA in another location. There are also \u201cretroviruses\u201d like HIV that contain RNA that they insert into the genome. Some people theorize that retrotransposons can evolve into retroviruses and vice-versa.</p>\n\n  <p>It\u2019s rare for retrotransposons to actually succeed in making a copy of themselves. They seem to have only a 1 in 100,000 or in 1,000,000 chance of copying themselves during cell division. But this is perhaps 10 times as high in the germ line, so the sperm from older men is more likely to contain such mutations.</p>\n</details>\n\n<p>Mutations in your regular cells will just affect <em>you</em>, but mutations in your sperm/eggs could affect all future generations. Evolution helps manage this through selection. Say you have 10 bad mutations, and I have 10 bad mutations, but those mutations are in different spots. If we have some babies together, some of them might get 13 bad mutations, but some might only get 7, and the latter babies are more likely to pass on their genes.</p>\n\n<p>But as well as selection, cells seem designed to be extremely <em>robust</em> to these kinds of errors. Instead of <em>just</em> relying on selection, there are many redundant mechanisms to tolerate them without much issue.</p>\n\n<p>And remember, evolution is a madman. If it decides to <em>tolerate</em> some mutation, everything else will be optimized against it. So even if a mutation is harmful <em>at first</em>, evolution may later find a way to make use of it.</p>\n\n<h2 id=\"on-information-again\">On information again</h2>\n\n<p>So, in theory, how should we define the \u201cinformation content\u201d of DNA? I propose a definition I call the \u201cphenotypic Kolmogorov complexity\u201d. (This has surely been proposed by someone before, but I can\u2019t find a reference, try as I might.) Roughly speaking, this is how short you <em>could</em> make DNA and still get a \u201chuman\u201d.</p>\n\n<p>The \u201cphenotype\u201d of an animal is just a fancy way of referring to its \u201cobservable physical characteristics and behaviors\u201d. So this definition says, like Kolmogorov complexity, to try and find the shortest compressed representation of the DNA. But instead of needing to lead to the same DNA you have, it just needs to lead to an embryo that would look and behave like you do.</p>\n\n<p><img alt=\"infographic\" src=\"https://dynomight.net/img/dna/infographic.png\" /></p>\n\n<details>\n  \nThe idea is this: Take a single-cell human embryo with your DNA, and imagine all the different ways you can modify the DNA. This would include not only removing useless sections but also moving things around. Limit yourself to changes that still lead to a \"person\" that would still look like you and have all the same capabilities you do. Now, compress each of those representations. The smallest compressed representation is the \"information\" in your DNA.\n\n  <p>This definition isn\u2019t totally precise, because I\u2019m not saying how precisely the phenotype needs to match. Even if there\u2019s some completely useless section of DNA and we remove it, that would make all your cells a tiny bit lighter. We need to tolerate <em>some</em> level of approximation. The idea is that it should be <em>very</em> close, but it\u2019s hard to make this precise.</p>\n</details>\n\n<p>So what would this number be? My <em>guess</em> is that you could reduce the amount of DNA by at least 75 percent, but not by more than 98 percent, meaning the information content is:</p>\n\n<p>\u00a0\u00a012 billion bits<br />\n\u00a0\u00a0\u00a0\u00a0  \u00d7 2 bits / nucleotide<br />\n\u00a0\u00a0\u00a0\u00a0  \u00d7 (2 to 25 percent)<br />\n\u00a0\u00a0\u00a0\u00a0  = 480 million to 6 billion bits<br />\n\u00a0\u00a0\u00a0\u00a0  = 60 MB to 750 MB</p>\n\n<p>But in reality, nobody knows. We still have no idea what (if anything) lots of DNA is doing, and we\u2019re a long way from fully understanding how much it can be reduced. Probably, no one will know for a long time.</p>"
            ],
            "link": "https://dynomight.net/dna/",
            "publishedAt": "2025-05-08",
            "source": "Dynomight",
            "summary": "While answering how much information is in DNA may seem straightforward, it actually requires a wild odyssey through information theory and molecular biology.",
            "title": "How much information is in DNA?"
        },
        {
            "content": [],
            "link": "https://harper.blog/2025/05/08/basic-claude-code/",
            "publishedAt": "2025-05-08",
            "source": "Harper Reed",
            "summary": "<p>I really like this agentic coding thing. It is quite compelling in so many ways.</p> <p>Since I wrote <a href=\"https://harper.blog/2025/02/16/my-llm-codegen-workflow-atm/\">that original blog post</a> a lot has happened in Claude land:</p> <ul> <li>Claude Code</li> <li>MCP</li> <li>etc</li> </ul> <p>I have received hundreds (wat) of emails from people talking about their workflows and how they have used my workflow to get ahead. I have spoken at a few conferences, and taught a few classes about codegen. I have learned that computers really want to spellcheck codegen to codeine, who knew!</p> <img alt=\"\" class=\"img \" height=\"600\" src=\"https://harper.blog/2025/05/08/basic-claude-code/codegen_hu_cd1d3b7ef861df7d.webp\" title=\"\" width=\"400\" /> <p>I was talking to a <a href=\"https://www.elidedbranches.com/\">friend</a> the other day about how we are <strong>all totally fucked</strong> and <strong>AI will take our jobs</strong> (more on that in a later post), and she was like &ldquo;you should write a post about claude code.&rdquo;</p> <p>Here we go.</p> <p>Claude Code was released eight days after I wrote my original workflow blog post, and as I predicted, it made a lot of my post irrelevant. I have since migrated from Aider to Claude Code and not looked back. I still like Aider, and it has a distinct use, but Claude Code is a bit more useful atm.</p> <p>Claude",
            "title": "Basic Claude Code"
        },
        {
            "content": [],
            "link": "https://buttondown.com/hillelwayne/archive/write-the-most-clever-code-you-possibly-can/",
            "publishedAt": "2025-05-08",
            "source": "Hillel Wayne",
            "summary": "<p><em>I started writing this early last week but Real Life Stuff happened and now you're getting the first-draft late this week. Warning, unedited thoughts ahead!</em></p> <h2>New Logic for Programmers release!</h2> <p><a href=\"https://leanpub.com/logic/\" target=\"_blank\">v0.9 is out</a>! This is a big release, with a new cover design, several rewritten chapters, <a href=\"https://github.com/logicforprogrammers/book-assets/tree/master/code\" target=\"_blank\">online code samples</a> and much more. See the full release notes at the <a href=\"https://github.com/logicforprogrammers/book-assets/blob/master/CHANGELOG.md\" target=\"_blank\">changelog page</a>, and <a href=\"https://leanpub.com/logic/\" target=\"_blank\">get the book here</a>!</p> <p><img alt=\"The new cover! It's a lot nicer\" class=\"newsletter-image\" src=\"https://assets.buttondown.email/images/038a7092-5dc7-41a5-9a16-56bdef8b5d58.jpg?w=400&amp;fit=max\" /></p> <h2>Write the cleverest code you possibly can</h2> <p>There are millions of articles online about how programmers should not write \"clever\" code, and instead write simple, maintainable code that everybody understands. Sometimes the example of \"clever\" code looks like this (<a href=\"https://codegolf.stackexchange.com/questions/57617/is-this-number-a-prime/57682#57682\" target=\"_blank\">src</a>):</p> <div class=\"codehilite\"><pre><span></span><code><span class=\"c1\"># Python</span> <span class=\"n\">p</span><span class=\"o\">=</span><span class=\"n\">n</span><span class=\"o\">=</span><span class=\"mi\">1</span> <span class=\"n\">exec</span><span class=\"p\">(</span><span class=\"s2\">\"p*=n*n;n+=1;\"</span><span class=\"o\">*~-</span><span class=\"nb\">int</span><span class=\"p\">(</span><span class=\"nb\">input</span><span class=\"p\">()))</span> <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">p</span><span class=\"o\">%</span><span class=\"n\">n</span><span class=\"p\">)</span> </code></pre></div> <p>This is code-golfing, the sport of writing the most concise code possible. Obviously you shouldn't run this in production for the same reason you shouldn't eat dinner off a Rembrandt. </p> <p>Other times the example looks like this:</p> <div class=\"codehilite\"><pre><span></span><code><span class=\"k\">def</span><span class=\"w\"> </span><span class=\"nf\">is_prime</span><span class=\"p\">(</span><span class=\"n\">x</span><span",
            "title": "Write the most clever code you possibly can"
        },
        {
            "content": [
                "<div class=\"trix-content\">\n  <div>When we make something new, people often ask \"why don't you just add that to Basecamp?\"<br /><br />There are a number of reasons, depending on what it is. But, broadly, making something brand new gives you latitude (and attitude) to explore new tech and design approaches.</div><div><br /></div><div>It's the opposite of grafting something on to a heavier, larger system that already exists.</div><div><br /></div><div>The gravity of existing decisions in current systems requires so much energy to reach escape velocity that you tend to conform rather than explore. Essentially you're bent back to where you started, rather than arcing out towards a new horizon.<br /><br />New can be wrong, but it's always interesting. And that in itself is worth it.<br /><br />Because in the end, even if the whole new thing doesn't work out, individual elements, explorations, and executions discovered along the way can make their way back into other things you're already doing. Or something else new down the road. These bits would have been undiscovered had you never set out for new territory in the first place.</div><div><br />Ultimately, a big part of making something new is simply thinking something new.<br /><br /></div><div>-Jason</div>\n</div>"
            ],
            "link": "https://world.hey.com/jason/why-new-when-752d0c5a",
            "publishedAt": "2025-05-08",
            "source": "Jason Fried",
            "summary": "<div class=\"trix-content\"> <div>When we make something new, people often ask \"why don't you just add that to Basecamp?\"<br /><br />There are a number of reasons, depending on what it is. But, broadly, making something brand new gives you latitude (and attitude) to explore new tech and design approaches.</div><div><br /></div><div>It's the opposite of grafting something on to a heavier, larger system that already exists.</div><div><br /></div><div>The gravity of existing decisions in current systems requires so much energy to reach escape velocity that you tend to conform rather than explore. Essentially you're bent back to where you started, rather than arcing out towards a new horizon.<br /><br />New can be wrong, but it's always interesting. And that in itself is worth it.<br /><br />Because in the end, even if the whole new thing doesn't work out, individual elements, explorations, and executions discovered along the way can make their way back into other things you're already doing. Or something else new down the road. These bits would have been undiscovered had you never set out for new territory in the first place.</div><div><br />Ultimately, a big part of making something new is simply thinking something new.<br /><br /></div><div>-Jason</div> </div>",
            "title": "Why new when?"
        },
        {
            "content": [
                "<p>Long ago I noted:</p><blockquote><p>Most [empirical] studies have an agenda associated with their focal factor; the authors, funders, and referees have answers they expect and want to see. Authors can manipulate the statistics to get the answer they want, and funders and referees can refuse to publish unwanted answers. So I tell students to focus more on the control variables when deciding what to believe. For example, you can better trust the control variable estimates of the effect of alcohol, than the estimates from studies where alcohol was the main focus. (<a href=\"https://www.overcomingbias.com/p/control_variablhtml\">more</a>) </p></blockquote><p>Today I just want to note that a similar thing applies to literature. The main character and plot structures of novels are chosen to meet the needs of storytelling, supporting the expectations and morals that readers want to hear. Look at those if you want to learn how to tell compelling stories.</p><p>But if you want to learn about real humans, the genius of the greatest authors lies mostly in their details, what they say about very particular behaviors, thoughts, and feelings. This is true of Middlemarch, which I&#8217;m now reading, and also of Tolstoy, in my mind the very best.</p>"
            ],
            "link": "https://www.overcomingbias.com/p/details-avoid-bias",
            "publishedAt": "2025-05-08",
            "source": "Robin Hanson",
            "summary": "<p>Long ago I noted:</p><blockquote><p>Most [empirical] studies have an agenda associated with their focal factor; the authors, funders, and referees have answers they expect and want to see. Authors can manipulate the statistics to get the answer they want, and funders and referees can refuse to publish unwanted answers. So I tell students to focus more on the control variables when deciding what to believe. For example, you can better trust the control variable estimates of the effect of alcohol, than the estimates from studies where alcohol was the main focus. (<a href=\"https://www.overcomingbias.com/p/control_variablhtml\">more</a>) </p></blockquote><p>Today I just want to note that a similar thing applies to literature. The main character and plot structures of novels are chosen to meet the needs of storytelling, supporting the expectations and morals that readers want to hear. Look at those if you want to learn how to tell compelling stories.</p><p>But if you want to learn about real humans, the genius of the greatest authors lies mostly in their details, what they say about very particular behaviors, thoughts, and feelings. This is true of Middlemarch, which I&#8217;m now reading, and also of Tolstoy, in my mind the very best.</p>",
            "title": "Details Avoid Bias"
        },
        {
            "content": [
                "<p>Thanks to everyone who commented on <a href=\"https://www.astralcodexten.com/p/testing-ais-geoguessr-genius\">the original post</a>.</p><p>Many people ran their own tests, some successful, some less so. For example, Torches Together (<a href=\"https://torchestogether.substack.com/\">blog</a>) <a href=\"https://www.astralcodexten.com/p/testing-ais-geoguessr-genius/comment/113869999\">wrote</a>:</p><blockquote><p>My results from 5 photos: 1 spot on but very slow; 1 close enough (correct country); 1 completely off (wrong continent, even after hint), and 2 okay (different part of the Mediterranean).</p><p>I tested it on one photo in a French town square with bad lighting. The CoT was both brilliant and curiously stupid. It inferred some correct things from tiny details (subtly different makes of car, barely visible street lines) and guessed the country quickly. But there was a shop name with different letters obscured in two different locations- a human would infer the name instantly. o3 took over 5 minutes on that one shop name, going down many incorrect rabbit holes. It got the exact location in the end, but it took over 15 minutes!</p><p>I then tested for a relatively well-shot, 1000km altitude environment in Kyrgyzstan, with ample geology and foliage to analyse, and it was over 6000 km off (it guessed Colorado), and none of the guesses were even in Asia. But this was in under 2 mins. I told it to try again- over 5k km away, it took 7 mins, and it suggested Australia, Europe, NZ, Argentina etc. Nothing in central Asia.</p><p>This suggests to me that it's perhaps trained more on, and biased towards, US and Anglo data. It wouldn't surprise me if there's 100x more pictures of Colorado than Kyrgyz mountains in the dataset.</p><p>It did okay on the next three. All relatively clean photos with at least a little evidence. It guessed a park in Barcelona instead of Rome, a forest in Catalonia instead of Albania, and Crete instead of the Parnasse mountains.</p></blockquote><p><strong>Vadim</strong> <strong>(<a href=\"https://ratandtiger.substack.com\">blog</a>) <a href=\"https://www.astralcodexten.com/p/testing-ais-geoguessr-genius/comment/113830550\">wrote</a></strong>:</p><blockquote><p>I tried to reproduce this on several not-previously-online pictures of streets in Siberia and the results were nowhere as impressive as described in this post. The model seemed to realize it was in Russia when it saw an inscription in Russian or a flag; failing that it didn't even always get the country right. When it did, it usually got the place thousands of kilometers wrong. I don't understand where this discrepancy is coming from. Curious.</p></blockquote><p><strong>Disordered Fermion <a href=\"https://www.astralcodexten.com/p/testing-ais-geoguessr-genius/comment/114023297\">did the most thorough set of tests</a>:</strong></p><blockquote><p>I used o3 with your exact prompt on these 10 images I took each in a separate instance of o3, pasted into paint to remove metadata and it had pretty mixed results, some very good and some not:</p><p>Link here if you want to try to guess first: <a href=\"https://ibb.co/album/M8zS9P\">https://ibb.co/album/M8zS9P</a></p><ol><li><p>It guessed Honshu Japan, was Central Illinois. Distance wrong: 10,500 km</p></li><li><p>It guessed Mt Rogers VA, was Spruce Knob WV. Distance wrong: 280 km</p></li><li><p>It guessed Lansing Michigan, was College Park MD. Distance wrong: 760 km</p></li><li><p>It guessed Jerusalem Israel, was Jerusalem, when prompted where in Jerusalem it guessed Valley of the Cross, which was within 1 km of the correct answer.</p></li><li><p>It guessed Gulf&#8239;of&#8239;Papagayo, Guanacaste&#8239;Province,&#8239;Costa&#8239;Rica and after prompting guessed Secrets&#8239;Papagayo&#8239;Resort, Playa&#8239;Arenilla, Gulf&#8239;of&#8239;Papagayo, Guanacaste&#8239;Province, Costa&#8239;Rica. which was exactly correct</p></li><li><p>It guessed South&#8239;Wales,&#8239;UK, was Buffalo, New York. Distance wrong: 5,500 km</p></li><li><p>It guessed Packard Building, Detroit, was Ford Piquette plant Detroit. Distance wrong: 3 km</p></li><li><p>It guessed Fort&#8239;Frederick&#8239;State&#8239;Park, Maryland&#8239;(USA) which was correct.</p></li><li><p>It guessed Atlanta GA, was Gatlinsburg TN. Distance wrong: 230 km</p></li><li><p>It guessed Southern&#8239;California, USA was Six Flags NJ. Distance wrong: 3800 km</p></li></ol></blockquote><p>Fermion concluded &#8220;It got the tourist destinations where there were a lot pictures taken very accurately for example pictures , 4,5,8 and 7 to an extent&#8221;. </p><p>After looking through many other user tests, I found this the most insightful rule of thumb on what it gets right vs. wrong. In retrospect, Kelsey&#8217;s California beach and my Nepal trekking trail are both very touristy; my house in Michigan and Vadim&#8217;s Siberian streets aren&#8217;t.</p><p><strong>Some people questioned whether o3 might have cheated on the Nepal picture. Rappatoni <a href=\"https://www.astralcodexten.com/p/testing-ais-geoguessr-genius/comment/113980080\">wrote</a>:</strong></p><blockquote><p>It isn't [just] a zoomed in photo of rocks. It is a photo of a fantasy flag planted between those rocks with a trodden path just behind it. It guessed \"Nepal, just north-east of Gorak Shep, &#177;8 km&#8221;. Do you know what is almost exactly north-east of Gorak Shep, ~3.3km as the crow flies? Mount Everest Base Camp. It is making a very educated guess based on where the kind of person who is taking a picture of a fantasy flag somewhere in the Tibetan Plateau would most likely have done so.</p><p>If someone asked me \"where in the Tibetan Plateau might someone plant a flag and take a picture of it\" literally the first (and perhaps the only) thing that would come to mind is \"Dunno, Mount Everest?\" And that would already be almost as good as o3's guess here. I mean, the slopes of Mount Everest has got to be about just about the least random place to take a picture like this.</p></blockquote><p>I doubt this was it.</p><p>o3 offered a latitude + longitude for its guess: 28.00 &#176; N, 86.85 &#176; E. I didn&#8217;t include it in my post, because I don&#8217;t remember the exact latitude + longitude where I took the picture, so it didn&#8217;t add or subtract anything to its naming of Gorak Shep. Here&#8217;s the latitude/longitude plotted on a map of the region. </p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F93d90cd1-a247-482d-9466-4a184b300c41_750x401.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"401\" src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F93d90cd1-a247-482d-9466-4a184b300c41_750x401.png\" width=\"750\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a></figure></div><p>All I remember about the real location was that it was on the green dotted line from Gorak Shep to Kala Pattar.</p><p>The GeoGuess is closer to Everest Base Camp than to the real location, though not to Everest Summit. But it only gave its answers to one one-hundredth of a degree, and the scale is small enough that an 0.01 degree margin of error covers the base camp and (almost) the real location.</p><p>But the chain of thought makes it clear that it&#8217;s thinking of the trail to the base camp (which includes Gorak Shep and runs very close to Kala Pattar) and not the base camp itself:</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F70a2c02a-b88a-4ab3-a556-0bc79ee6689b_876x389.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"389\" src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F70a2c02a-b88a-4ab3-a556-0bc79ee6689b_876x389.png\" width=\"876\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a><figcaption class=\"image-caption\">Stitched together from a few different CoT pieces. There were none that suggested the Base Camp itself as the location.</figcaption></figure></div><p>This is more correct than just saying &#8220;Everest Base Camp&#8221; would be, so I am more impressed than if it just said Everest Base Camp.</p><p>Instead of continuously litigating this, I asked it about similarly vague pictures of some mountains that were nowhere near Everest:</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9e8cc139-4603-4188-989f-b4905657354a_299x265.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"265\" src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9e8cc139-4603-4188-989f-b4905657354a_299x265.png\" width=\"299\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a></figure></div><p>o3 guessed &#8220;upper slopes of Mt. Fuji&#8221;, which was correct.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2\" href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6ccdbf0e-60b6-4cd2-ad6d-6a98979337c4_169x141.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"271.15384615384613\" src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6ccdbf0e-60b6-4cd2-ad6d-6a98979337c4_169x141.png\" width=\"325\" /><div></div></div></a></figure></div><p>o3 guessed &#8220;Midwestern USA limestone trail&#8221;, which was wrong. Its next four guesses were also wrong. When I gave it the full photo:</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F20fb5084-72fc-468d-986b-ca66e7c12535_619x467.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"467\" src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F20fb5084-72fc-468d-986b-ca66e7c12535_619x467.png\" width=\"619\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a></figure></div><p>&#8230;it guessed Mont Ventoux, France, which was also wrong. Its third guess was Mount Olympus, Greece, which was correct.</p><p>Fuji and Everest are both more touristy than Olympus (somehow) so I think this fits Fermion&#8217;s theory of &#8220;good at tourist spots&#8221;. </p><p>Also, my habit of taking really bad pictures of mountains and never showing them to anyone has finally paid off!</p><p><strong>Some people pointed out that human GeoGuessrs are also amazing. Alex Zavoluk <a href=\"https://www.astralcodexten.com/p/testing-ais-geoguessr-genius/comment/113922324\">wrote</a>:</strong></p><blockquote><p>Ordinary people just don&#8217;t appreciate how good GeoGuessng can get . . . Go watch some Rainbolt clips on youtube, he'll rattle off 5 guesses that are on par with your second picture in a row while talking about something else, in a few seconds each.</p><p>Not trying to say o3 isn't impressive, but none of this seems even to match top-level humans yet, let alone be super human. Also, based on the explanation, it seems like it's searching the internet while doing this, which is typically not how you play geoguessr.</p></blockquote><p>This is a reference to Trevor Rainbolt (apparently his real name - I wish my name was that cool), a YouTube GeoGuessr champion. Here&#8217;s an (admittedly cherry-picked) example of his work:</p><div class=\"youtube-wrap\" id=\"youtube2-zjI5SMROCes\"><div class=\"youtube-inner\"></div></div><p>This is obviously incredibly impressive. Rainbolt explains some of his strategy here:</p><div class=\"youtube-wrap\" id=\"youtube2-0p5Eb4OSZCs\"><div class=\"youtube-inner\"></div></div><p>&#8230;and a lot of it has to do with roads and Google Street View in particular - road markings, cars, bollards (the short poles next roads), utility poles, and which Google car covered which region on which day. Can he do random streetless pictures like the ones in my test?</p><div class=\"youtube-wrap\" id=\"youtube2-QRqKPDJYyLE\"><div class=\"youtube-inner\"></div></div><p>Here (h/t CptDrMoreno from <a href=\"https://discord.com/invite/RTKtdut\">the ACX Discord</a>) Rainbolt does apparently-impossible guesses like the title picture (which is &#8220;literally just blue&#8221;). I can&#8217;t tell how cherry-picked these are: in one, he says that it was basically just luck and it will look like cheating to anyone who views it out of context (for example in this highlights reel). But in another, he says he could &#8220;never explain&#8221; how he got it, but does act like there&#8217;s some real skill he&#8217;s using instead of just doing a million impossible guesses and getting one right.</p><p>If Rainbolt&#8217;s skill is anywhere near what it looks like in this video, I don&#8217;t think the takeaway is &#8220;don&#8217;t worry about AI after all&#8221;, it&#8217;s &#8220;Trevor Rainbolt is as far beyond the rest of us as a helicopter engineer is to a chimp, and if you didn&#8217;t predict it was possible for a human to guess the location of a picture of blue sky, then you&#8217;re going to be extra-double-surprised by whatever superintelligence can do&#8221;.</p><p><strong>Some people on Twitter (<a href=\"https://x.com/scaling01/status/1918741410875859413\">@scaling01</a> and <a href=\"https://x.com/DeepGuessr/status/1918756272280572103\">@DeepGuessr</a>)  on Twitter mention the existence of formal AI GeoGuessr benchmarks. </strong></p><p>First is <a href=\"https://geobench.org/\">GeoBench</a>:</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fda66a179-b588-44ad-a9a2-b3da63ab508b_1215x787.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"446.9382716049383\" src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fda66a179-b588-44ad-a9a2-b3da63ab508b_1215x787.png\" width=\"690\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a></figure></div><p>&#8230;where AIs are about equal to human professionals, depending on whether you take median or mean score. o3 isn&#8217;t even on top - that honor goes to Google Gemini.</p><p>Second is <a href=\"https://deepguessr.com/\">DeepGuessr</a>:</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3cd580f8-db99-46c5-be0f-561b8b093288_859x489.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"392.2246798603027\" src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3cd580f8-db99-46c5-be0f-561b8b093288_859x489.png\" width=\"689\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a></figure></div><p>&#8230;which doesn&#8217;t have a human comparison, but finds o1 first, with Gemini and o3 close behind.</p><p>You can <a href=\"https://deepguessr.com/\">play DeepGuessr&#8217;s benchmark yourself</a> and see how you do compared to all the AIs.</p><p><strong>Daniel Kang (<a href=\"https://ddkang.substack.com/\">blog</a>) wrote:</strong></p><blockquote><p>o3 was probably trained on a bunch of geoguessr-style tasks. This shouldn't update you very much since we've known that expert systems on a lot of data crush humans since at least 2016.</p><p>I find this demo very interesting because it gives people a visceral feeling about performance but it actually shouldn't update you very much. Here's my argument for why.</p><p>We have known for years that expert systems can crush humans with enough data (enough can mean 10k samples to billions of samples, depending on the task). We've known this since AlphaGo, circa 2016. For geoguessr in particular, some Stanford students hacked together an AI system that crushed rainman (a pro geoguessr player) in 2022.</p><p>We also know that o3 was trained on enormous amounts RL tasks, some of which have &#8220;verified rewards.&#8221; The folks at OpenAI are almost certainly cramming every bit of information with every conceivable task into their o-series of models! A heuristic here is that if there&#8217;s an easy to verify answer and you can think of it, o3 was probably trained on it.</p><p>This means o3 should reach expert system-level performance on every easily verifiable task and o4 will be even better. I don&#8217;t think this should update you very much on AI capabilities.</p></blockquote><p>I hadn&#8217;t thought of this, but it makes sense! OpenAI is trying to grab every data source they can for training. Data sources work for AIs if they are hard to do, easy to check, can be repeated at massive scale, and teach some kind of transferrable reasoning skill. GeoGuessr certainly counts. This might not be an example of general intelligence at all; just an AI trained at GeoGuessr being very good at it. </p><p>On the other hand, the DeepGuessr benchmark finds that base models like GPT-4o and GPT-4.1 are almost as good as reasoning models at this, and I would expect these to have less post-training, probably not enough to include GeoGuessr (see <a href=\"https://blog.ai-futures.org/p/making-sense-of-openais-models\">the AIFP blog post on OpenAI models</a> for more explanation).</p><p>And people who know how o3 was trained are also amazed:</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2\" href=\"https://x.com/sama/status/1918741036702044645\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"399\" src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F65118b68-f7dd-4dbc-bd48-fd58bafe9792_593x399.png\" width=\"593\" /><div></div></div></a></figure></div><p><strong>And my favorite test was Loweren on the ACX Discord, who gave o3 this challenge:</strong></p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8828134a-02f0-45b6-b82b-746b01589be1_387x319.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"363.51162790697674\" src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8828134a-02f0-45b6-b82b-746b01589be1_387x319.png\" title=\"\" width=\"441\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a></figure></div><p>o3 got it right: this is <a href=\"https://www.nationalgeographic.com/travel/article/tianducheng-paris-of-the-east-replica\">Tianducheng, China</a>. </p>"
            ],
            "link": "https://www.astralcodexten.com/p/highlights-from-the-comments-on-ai",
            "publishedAt": "2025-05-08",
            "source": "SlateStarCodex",
            "summary": "<p>Thanks to everyone who commented on <a href=\"https://www.astralcodexten.com/p/testing-ais-geoguessr-genius\">the original post</a>.</p><p>Many people ran their own tests, some successful, some less so. For example, Torches Together (<a href=\"https://torchestogether.substack.com/\">blog</a>) <a href=\"https://www.astralcodexten.com/p/testing-ais-geoguessr-genius/comment/113869999\">wrote</a>:</p><blockquote><p>My results from 5 photos: 1 spot on but very slow; 1 close enough (correct country); 1 completely off (wrong continent, even after hint), and 2 okay (different part of the Mediterranean).</p><p>I tested it on one photo in a French town square with bad lighting. The CoT was both brilliant and curiously stupid. It inferred some correct things from tiny details (subtly different makes of car, barely visible street lines) and guessed the country quickly. But there was a shop name with different letters obscured in two different locations- a human would infer the name instantly. o3 took over 5 minutes on that one shop name, going down many incorrect rabbit holes. It got the exact location in the end, but it took over 15 minutes!</p><p>I then tested for a relatively well-shot, 1000km altitude environment in Kyrgyzstan, with ample geology and foliage to analyse, and it was over 6000 km off (it guessed Colorado), and none of the guesses were even in Asia. But this was in under 2 mins. I told it",
            "title": "Highlights From The Comments On AI Geoguessr"
        },
        {
            "content": [
                "<p>\n          <a href=\"https://www.astralcodexten.com/p/hidden-open-thread-3805\">\n              Read more\n          </a>\n      </p>"
            ],
            "link": "https://www.astralcodexten.com/p/hidden-open-thread-3805",
            "publishedAt": "2025-05-08",
            "source": "SlateStarCodex",
            "summary": "<p> <a href=\"https://www.astralcodexten.com/p/hidden-open-thread-3805\"> Read more </a> </p>",
            "title": "Hidden Open Thread 380.5"
        }
    ],
    "lookbackDays": 1,
    "publishDate": "2025-05-08"
}