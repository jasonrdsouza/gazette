{
    "articles": [
        {
            "content": [
                "<p>When I embed videos in web pages, I specify an <a href=\"https://developer.mozilla.org/en-US/docs/Web/CSS/Reference/Properties/aspect-ratio\">aspect ratio</a>.\nFor example, if my video is 1920\u202f\u00d7\u202f1080 pixels, I\u2019d write:</p>\n\n<pre class=\"language-html\"><code><span class=\"nt\">&lt;video</span> <span class=\"na\">style=</span><span class=\"s\">\"aspect-ratio: 1920 / 1080\"</span><span class=\"nt\">&gt;</span>\n</code></pre>\n<p>If I also set a width or a height, the browser now knows exactly how much space this video will take up on the page \u2013 even if it hasn\u2019t loaded the video file yet.\nWhen it initially renders the page, it can leave the right gap, so it doesn\u2019t need to rearrange when the video eventually loads.\n(The technical term is \u201creducing <a href=\"https://developer.mozilla.org/en-US/docs/Glossary/CLS\">cumulative layout shift</a>\u201d.)</p>\n\n<p>That\u2019s the idea, anyway.</p>\n\n<p>I noticed that some of my videos weren\u2019t fitting in their allocated boxes.\nWhen the video file loaded, it could be too small and get letterboxed, or be too big and force the page to rearrange to fit.\nClearly there was a bug in my code for computing aspect ratios, but what?</p>\n\n<h2 id=\"three-aspect-ratios-one-video\">Three aspect ratios, one video</h2>\n\n<p>I opened one of the problematic videos in QuickTime Player, and the resolution listed in the Movie Inspector was rather curious: <code>Resolution: 1920\u202f\u00d7\u202f1080 (1350\u202f\u00d7\u202f1080)</code>.</p>\n\n<p>The first resolution is what my code was reporting, but the second resolution is what I actually saw when I played the video.\nWhy are there two?</p>\n\n<p>The <a href=\"https://en.wikipedia.org/wiki/Aspect_ratio_(image)#Distinctions\"><strong>storage aspect ratio (SAR)</strong></a> of a video is the pixel resolution of a raw frame.\nIf you extract a single frame as a still image, that\u2019s the size of the image you\u2019d get.\nThis is the first resolution shown by QuickTime Player, and it\u2019s what I was reading in my code.</p>\n\n<p>I was missing a key value \u2013 the <a href=\"https://en.wikipedia.org/wiki/Pixel_aspect_ratio\"><strong>pixel aspect ratio (PAR)</strong></a>.\nThis describes the shape of each pixel, in particular the width-to-height ratio.\nIt tells a video player how to stretch or squash the stored pixels when it displays them.\nThis can sometimes cause square pixels in the stored image to appear as rectangles.</p>\n\n\n\n<figure id=\"pixel_aspect_ratios\">\n  \n<svg class=\"dark_aware\" height=\"100\" viewBox=\"0 0 95 170\" xmlns=\"http://www.w3.org/2000/svg\">\n  <defs>\n    \n  </defs>\n  \n  <rect height=\"50\" width=\"25\" x=\"0\" y=\"0\"></rect>\n  <rect height=\"50\" width=\"25\" x=\"35\" y=\"0\"></rect>\n  <rect height=\"50\" width=\"25\" x=\"70\" y=\"0\"></rect>\n  \n  <rect height=\"50\" width=\"25\" x=\"0\" y=\"60\"></rect>\n  <rect height=\"50\" width=\"25\" x=\"35\" y=\"60\"></rect>\n  <rect height=\"50\" width=\"25\" x=\"70\" y=\"60\"></rect>\n  \n  <rect height=\"50\" width=\"25\" x=\"0\" y=\"120\"></rect>\n  <rect height=\"50\" width=\"25\" x=\"35\" y=\"120\"></rect>\n  <rect height=\"50\" width=\"25\" x=\"70\" y=\"120\"></rect>\n<title id=\"svg_pixel_aspect_ratio_lt\">A 3\u00d73 grid of pixels, where each pixel is a rectangle that's taller than it is wide.</title></svg>\n\n  \n<svg class=\"dark_aware\" height=\"100\" viewBox=\"0 0 170 170\" xmlns=\"http://www.w3.org/2000/svg\">\n  <defs>\n    \n  </defs>\n  \n  <rect height=\"50\" width=\"50\" x=\"0\" y=\"0\"></rect>\n  <rect height=\"50\" width=\"50\" x=\"60\" y=\"0\"></rect>\n  <rect height=\"50\" width=\"50\" x=\"120\" y=\"0\"></rect>\n  \n  <rect height=\"50\" width=\"50\" x=\"0\" y=\"60\"></rect>\n  <rect height=\"50\" width=\"50\" x=\"60\" y=\"60\"></rect>\n  <rect height=\"50\" width=\"50\" x=\"120\" y=\"60\"></rect>\n  \n  <rect height=\"50\" width=\"50\" x=\"0\" y=\"120\"></rect>\n  <rect height=\"50\" width=\"50\" x=\"60\" y=\"120\"></rect>\n  <rect height=\"50\" width=\"50\" x=\"120\" y=\"120\"></rect>\n<title id=\"svg_pixel_aspect_ratio_eq\">A 3\u00d73 grid of pixels, where each pixel is a square.</title></svg>\n\n  \n<svg class=\"dark_aware\" height=\"100\" viewBox=\"0 0 320 170\" xmlns=\"http://www.w3.org/2000/svg\">\n  <defs>\n    \n  </defs>\n  \n  <rect height=\"50\" width=\"100\" x=\"0\" y=\"0\"></rect>\n  <rect height=\"50\" width=\"100\" x=\"110\" y=\"0\"></rect>\n  <rect height=\"50\" width=\"100\" x=\"220\" y=\"0\"></rect>\n  \n  <rect height=\"50\" width=\"100\" x=\"0\" y=\"60\"></rect>\n  <rect height=\"50\" width=\"100\" x=\"110\" y=\"60\"></rect>\n  <rect height=\"50\" width=\"100\" x=\"220\" y=\"60\"></rect>\n  \n  <rect height=\"50\" width=\"100\" x=\"0\" y=\"120\"></rect>\n  <rect height=\"50\" width=\"100\" x=\"110\" y=\"120\"></rect>\n  <rect height=\"50\" width=\"100\" x=\"220\" y=\"120\"></rect>\n<title id=\"svg_pixel_aspect_ratio_gt\">A 3\u00d73 grid of pixels, where each pixel is a rectangle that's wider than it is tall.</title></svg>\n\n  <figcaption>\n    PAR &lt; 1<br />\n    portrait pixels\n  </figcaption>\n  <figcaption>\n    PAR = 1<br />\n    square pixels\n  </figcaption>\n  <figcaption>\n    PAR &gt; 1<br />\n    landscape pixels\n  </figcaption>\n</figure>\n\n<p>This reminds me of <a href=\"https://alexwlchan.net/2025/create-thumbnail-is-exif-aware/\">EXIF orientation</a> for still images \u2013 a transformation that the viewer applies to the stored data.\nIf you don\u2019t apply this transformation properly, your media will look wrong when you view it.\nI wasn\u2019t accounting for the pixel aspect ratio in my code.</p>\n\n<p>According to Google, the primary use case for non-square pixels is standard-definition televisions which predate digital video.\nHowever, I\u2019ve encountered several videos with an unusual PAR that were made long into the era of digital video, when that seems unlikely to be a consideration.\nIt\u2019s especially common in vertical videos like YouTube Shorts, where the stored resolution is a square 1080\u202f\u00d7\u202f1080, and the aspect ratio makes it a portrait.</p>\n\n<p>I wonder if it\u2019s being introduced by a processing step somewhere?\nI don\u2019t understand why, but I don\u2019t have to \u2013 I\u2019m only displaying videos, not producing them.</p>\n\n<p>The <a href=\"https://en.wikipedia.org/wiki/Display_aspect_ratio\"><strong>display aspect ratio (DAR)</strong></a> is the size of the video as viewed \u2013 what happens when you apply the pixel aspect ratio to the stored frames.\nThis is the second resolution shown by QuickTime Player, and it\u2019s the aspect ratio I should be using to preallocate space in my video player.</p>\n\n<p>These three values are linked by a simple formula:</p>\n\n<p>DAR = SAR\u2009\u00d7\u2009PAR</p>\n\n<p>The size of the viewed video is the stored resolution times the shape of each pixel.</p>\n\n<h2 id=\"the-stored-frame-may-not-be-what-you-see\">The stored frame may not be what you see</h2>\n\n<p>One video with a non-unit pixel aspect ratio is my download of <a href=\"https://www.youtube.com/watch?v=HHhyznZ2u4E\">Mars EDL 2020 Remastered</a>.\nThis video by Simeon Schmau\u00df tries to match what the human eye would have seen during the landing of NASA\u2019s <a href=\"https://en.wikipedia.org/wiki/Perseverance_rover\"><em>Perseverance</em> rover</a> in 2021.</p>\n\n<p>We can get the width, height, and <strong>sample aspect ratio</strong> (which is another name for pixel aspect ratio) using ffprobe:</p>\n\n<pre class=\"language-console\"><code><span class=\"gp\">$</span><span class=\"w\"> </span>ffprobe -v error <span class=\"p\">\\</span>\n      -select_streams v:0 <span class=\"p\">\\</span>\n      -show_entries stream=width,height,sample_aspect_ratio <span class=\"p\">\\</span>\n      <span class=\"s2\">\"Mars 2020 EDL Remastered [HHhyznZ2u4E].mp4\"</span>\n<span class=\"go\">[STREAM]\nwidth=1920\nheight=1080\nsample_aspect_ratio=45:64\n[/STREAM]\n</span></code></pre>\n<p>Here <code>1920</code> is the stored width, and <code>45:64</code> is the pixel aspect ratio.\nWe can multiply them together to get the display width: <code>1920\u202f\u00d7\u202f45\u2009/\u200964 = 1350</code>.\nThis matches what I saw in QuickTime Player.</p>\n\n<p>Let\u2019s extract a single frame using <a href=\"https://ffmpeg.org/ffmpeg.html\">ffmpeg</a>, to get the stored pixels.\nThis command saves the 5000th frame as a PNG image:</p>\n\n<pre class=\"language-console\"><code><span class=\"gp\">$</span><span class=\"w\"> </span>ffmpeg <span class=\"nt\">-i</span> <span class=\"s2\">\"Mars 2020 EDL Remastered [HHhyznZ2u4E].mp4\"</span> <span class=\"se\">\\</span>\n    <span class=\"nt\">-filter</span>:v <span class=\"s2\">\"select=eq(n</span><span class=\"se\">\\,</span><span class=\"s2\">5000)\"</span> <span class=\"se\">\\</span>\n    <span class=\"nt\">-frames</span>:v 1 <span class=\"se\">\\</span>\n    frame.png\n</code></pre>\n<p>The image is 1920\u202f\u00d7\u202f1080 pixels, and it looks wrong: the circular parachute is visibly stretched.</p>\n\n<source type=\"image/avif\" /><source type=\"image/webp\" /><source type=\"image/png\" /><img alt=\"Photo looking up towards a parachute against a dark brown sky. The parachute is made of white-and-orange segments, and is stretched horizontally. The circle is wider than it is tall.\" src=\"https://alexwlchan.net/images/2025/mars_edl_frame_raw_1x.png\" width=\"750\" />\n\n\n<p>Suppose we take that same image, but now apply the pixel aspect ratio.\nThis is what the image is meant to look like, and it\u2019s not a small difference \u2013 now the parachute actually looks like a circle.</p>\n\n<figure>\n  \n\n<source type=\"image/avif\" /><source type=\"image/webp\" /><source type=\"image/png\" /><img alt=\"The same photo as before, but now the parachute is a circle.\" src=\"https://alexwlchan.net/images/2025/mars_edl_frame_fixed_1x.png\" width=\"750\" />\n\n\n</figure>\n\n<p>Seeing both versions side-by-side makes the problem obvious: the stored frame isn\u2019t how the video is displayed.\nThe video player in my browser will play it correctly using the pixel aspect ratio, but my layout code wasn\u2019t doing that.\nI was telling the browser the wrong aspect ratio, and the browser had to update the page when it loaded the video file.</p>\n\n<h2 id=\"getting-the-correct-display-dimensions-in-python\">Getting the correct display dimensions in Python</h2>\n\n<p>This is my old function for getting the dimensions of a video file, which uses a <a href=\"https://pypi.org/project/MediaInfo/\">Python wrapper around MediaInfo</a> to extract the width and height fields.\nI now realise that this only gives me the storage aspect ratio, and may be misleading for some videos.</p>\n<pre><code>from <span class=\"n\">pathlib</span> import <span class=\"n\">Path</span>\n\nfrom <span class=\"n\">pymediainfo</span> import <span class=\"n\">MediaInfo</span>\n\n\ndef <span class=\"n\">get_storage_aspect_ratio</span><span class=\"p\">(</span><span class=\"n\">video_path</span><span class=\"p\">:</span> Path<span class=\"p\">)</span> -&gt; tuple<span class=\"p\">[</span>int<span class=\"p\">,</span> int<span class=\"p\">]:</span>\n    <span class=\"sh\">\"\"\"</span><span class=\"s\">\n    Returns the storage aspect ratio of a video, as a width/height ratio.\n    </span><span class=\"sh\">\"\"\"</span>\n    <span class=\"n\">media_info</span> = MediaInfo<span class=\"p\">.</span>parse<span class=\"p\">(</span>video_path<span class=\"p\">)</span>\n    \n    try<span class=\"p\">:</span>\n        <span class=\"n\">video_track</span> = next<span class=\"p\">(</span>\n            tr\n            for tr <span class=\"ow\">in</span> media_info<span class=\"p\">.</span>tracks\n            if tr<span class=\"p\">.</span>track_type == <span class=\"sh\">\"</span><span class=\"s\">Video</span><span class=\"sh\">\"</span>\n        <span class=\"p\">)</span>\n    except StopIteration<span class=\"p\">:</span>\n        raise ValueError<span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"sh\">\"</span><span class=\"s\">No video track found in </span><span class=\"si\">{</span>video_path<span class=\"si\">}</span><span class=\"sh\">\"</span><span class=\"p\">)</span>\n    \n    return video_track<span class=\"p\">.</span>width<span class=\"p\">,</span> video_track<span class=\"p\">.</span>height\n</code></pre>\n<p>I can\u2019t find an easy way to extract the pixel aspect ratio using pymediainfo.\nIt does expose a <code>Track.aspect_ratio</code> property, but that\u2019s a string which has a rounded value \u2013 for example, <code>45:64</code> becomes <code>0.703</code>.\nThat\u2019s close, but the rounding introduces a small inaccuracy.\nSince I can get the complete value from ffprobe, that\u2019s what I\u2019m doing in my revised function.</p>\n\n<p>The new function is longer, but it\u2019s more accurate:</p>\n<pre><code>from <span class=\"n\">fractions</span> import <span class=\"n\">Fraction</span>\nimport <span class=\"n\">json</span>\nfrom <span class=\"n\">pathlib</span> import <span class=\"n\">Path</span>\nimport <span class=\"n\">subprocess</span>\n\n\ndef <span class=\"n\">get_display_aspect_ratio</span><span class=\"p\">(</span><span class=\"n\">video_path</span><span class=\"p\">:</span> Path<span class=\"p\">)</span> -&gt; tuple<span class=\"p\">[</span>int<span class=\"p\">,</span> int<span class=\"p\">]:</span>\n    <span class=\"sh\">\"\"\"</span><span class=\"s\">\n    Returns the display aspect ratio of a video, as a width/height fraction.\n    </span><span class=\"sh\">\"\"\"</span>\n    <span class=\"n\">cmd</span> = <span class=\"p\">[</span>\n        <span class=\"sh\">\"</span><span class=\"s\">ffprobe</span><span class=\"sh\">\"</span><span class=\"p\">,</span>\n        <span class=\"c1\">#\n</span>        <span class=\"c1\"># verbosity level = error\n</span>        <span class=\"sh\">\"</span><span class=\"s\">-v</span><span class=\"sh\">\"</span><span class=\"p\">,</span> <span class=\"sh\">\"</span><span class=\"s\">error</span><span class=\"sh\">\"</span><span class=\"p\">,</span>\n        <span class=\"c1\">#\n</span>        <span class=\"c1\"># only get information about the first video stream\n</span>        <span class=\"sh\">\"</span><span class=\"s\">-select_streams</span><span class=\"sh\">\"</span><span class=\"p\">,</span> <span class=\"sh\">\"</span><span class=\"s\">v:0</span><span class=\"sh\">\"</span><span class=\"p\">,</span>\n        <span class=\"c1\">#\n</span>        <span class=\"c1\"># only gather the entries I'm interested in\n</span>        <span class=\"sh\">\"</span><span class=\"s\">-show_entries</span><span class=\"sh\">\"</span><span class=\"p\">,</span> <span class=\"sh\">\"</span><span class=\"s\">stream=width,height,sample_aspect_ratio</span><span class=\"sh\">\"</span><span class=\"p\">,</span>\n        <span class=\"c1\">#\n</span>        <span class=\"c1\"># print output in JSON, which is easier to parse\n</span>        <span class=\"sh\">\"</span><span class=\"s\">-print_format</span><span class=\"sh\">\"</span><span class=\"p\">,</span> <span class=\"sh\">\"</span><span class=\"s\">json</span><span class=\"sh\">\"</span><span class=\"p\">,</span>\n        <span class=\"c1\">#\n</span>        <span class=\"c1\"># input file\n</span>        str<span class=\"p\">(</span>video_path<span class=\"p\">)</span>\n    <span class=\"p\">]</span>\n    \n    <span class=\"n\">output</span> = subprocess<span class=\"p\">.</span>check_output<span class=\"p\">(</span>cmd<span class=\"p\">)</span>\n    <span class=\"n\">ffprobe_resp</span> = json<span class=\"p\">.</span>loads<span class=\"p\">(</span>output<span class=\"p\">)</span>\n    \n    <span class=\"c1\"># The output will be structured something like:\n</span>    <span class=\"c1\">#\n</span>    <span class=\"c1\">#   {\n</span>    <span class=\"c1\">#       \"streams\": [\n</span>    <span class=\"c1\">#           {\n</span>    <span class=\"c1\">#               \"width\": 1920,\n</span>    <span class=\"c1\">#               \"height\": 1080,\n</span>    <span class=\"c1\">#               \"sample_aspect_ratio\": \"45:64\"\n</span>    <span class=\"c1\">#           }\n</span>    <span class=\"c1\">#       ],\n</span>    <span class=\"c1\">#       \u2026\n</span>    <span class=\"c1\">#   }\n</span>    <span class=\"c1\">#\n</span>    <span class=\"c1\"># If the video doesn't specify a pixel aspect ratio, then it won't\n</span>    <span class=\"c1\"># have a `sample_aspect_ratio` key.\n</span>    <span class=\"n\">video_stream</span> = ffprobe_resp<span class=\"p\">[</span><span class=\"sh\">\"</span><span class=\"s\">streams</span><span class=\"sh\">\"</span><span class=\"p\">][</span><span class=\"mi\">0</span><span class=\"p\">]</span>\n    \n    try<span class=\"p\">:</span>\n        <span class=\"n\">pixel_aspect_ratio</span> = Fraction<span class=\"p\">(</span>\n            video_stream<span class=\"p\">[</span><span class=\"sh\">\"</span><span class=\"s\">sample_aspect_ratio</span><span class=\"sh\">\"</span><span class=\"p\">].</span>replace<span class=\"p\">(</span><span class=\"sh\">\"</span><span class=\"s\">:</span><span class=\"sh\">\"</span><span class=\"p\">,</span> <span class=\"sh\">\"</span><span class=\"s\">/</span><span class=\"sh\">\"</span><span class=\"p\">)</span>\n        <span class=\"p\">)</span>\n    except KeyError<span class=\"p\">:</span>\n        <span class=\"n\">pixel_aspect_ratio</span> = <span class=\"mi\">1</span>\n    \n    <span class=\"n\">width</span> = round<span class=\"p\">(</span>video_stream<span class=\"p\">[</span><span class=\"sh\">\"</span><span class=\"s\">width</span><span class=\"sh\">\"</span><span class=\"p\">]</span> * pixel_aspect_ratio<span class=\"p\">)</span>\n    <span class=\"n\">height</span> = video_stream<span class=\"p\">[</span><span class=\"sh\">\"</span><span class=\"s\">height</span><span class=\"sh\">\"</span><span class=\"p\">]</span>\n    \n    return width<span class=\"p\">,</span> height\n</code></pre>\n<p>This is calling the <code>ffprobe</code> command I showed above, plus <code>-print_format json</code> to print the data in JSON, which is easier for Python to parse.</p>\n\n<p>I have to account for the case where a video doesn\u2019t set a sample aspect ratio \u2013 in that case, the displayed video just uses square pixels.</p>\n\n<p>Since the aspect ratio is expressed as a ratio of two integers, this felt like a good chance to try the <a href=\"https://docs.python.org/3.13/library/fractions.html\"><code>fractions</code> module</a>.\nThat avoids converting the ratio to a floating-point number, which potentially introduces inaccuracies.\nIt doesn\u2019t make a big difference, but in my video collection treating the aspect ratio as a <code>float</code> produces results that are 1 or 2 pixels different from QuickTime Player.</p>\n\n<p>When I multiply the stored width and aspect ratio, I\u2019m using the <a href=\"https://docs.python.org/3.13/library/functions.html#round\"><code>round()</code> function</a> to round the final width to the nearest integer.\nThat\u2019s more accurate than <code>int()</code>, which always rounds down.</p>\n\n<h2 id=\"conclusion-use-display-aspect-ratio\">Conclusion: use display aspect ratio</h2>\n\n<p>When you want to know how much space a video will take up on a web page, look at the display aspect ratio, not the stored pixel dimensions.\nPixels can be squashed or stretched before display, and the stored width/height won\u2019t tell you that.</p>\n\n<p>Videos with non-square pixels are pretty rare, which is why I ignored this for so long.\nI\u2019m glad I finally understand what\u2019s going on.</p>\n\n<p>After switching to ffprobe and using the display aspect ratio, my pre-allocated video boxes now match what the browser eventually renders \u2013 no more letterboxing, no more layout jumps.</p>\n\n\n    <p>[If the formatting of this post looks odd in your feed reader, <a href=\"https://alexwlchan.net/2025/square-pixels/?ref=rss\">visit the original article</a>]</p>"
            ],
            "link": "https://alexwlchan.net/2025/square-pixels/?ref=rss",
            "publishedAt": "2025-12-05",
            "source": "Alex Chan",
            "summary": "When you want to get the dimensions of a video file, you probably want the display aspect ratio. Using the dimensions of a stored frame may result in a stretched or squashed video.",
            "title": "When square pixels aren\u2019t square"
        },
        {
            "content": [
                "<img alt=\"Perpetual futures, explained\" src=\"https://www.bitsaboutmoney.com/content/images/2025/12/Roulette-in-the-Cosmos.png\" /><p><em>Programming note</em>: <em>Bits about Money is </em><a href=\"https://www.bitsaboutmoney.com/memberships/\" rel=\"noreferrer\"><em>supported by our readers</em></a><em>. I generally forecast about one issue a month, and haven&apos;t kept that pace that this year. As a result, I&apos;m working on about 3-4 for December.</em></p><p>Much financial innovation is in the ultimate service of the real economy. Then, we have our friends in crypto, who occasionally do intellectually interesting things which do not have a locus in the real economy. One of those things is perpetual futures (hereafter, perps), which I find fascinating and worthy of study, the same way that a virologist just loves geeking out about furin cleavage sites.</p><p>You may have read a lot about stablecoins recently. I may write about them (again; see <a href=\"https://www.bitsaboutmoney.com/archive/stablecoin-mechanisms-and-use-cases/\">past BAM issue</a>) in the future, as there has in recent years been <a href=\"https://www.stablecoin.fyi/\">some uptake</a> of them for payments. But it is useful to understand that a plurality of stablecoins collateralize perps. Some observers are occasionally <em>strategic </em>in whether they acknowledge this, but for payments use cases, it does not require a lot of stock to facilitate massive flows. And so of the <a href=\"https://defillama.com/stablecoins\">$300 billion or so in stablecoins presently outstanding</a>, <a href=\"https://cryptoquant.com/asset/stablecoin/chart/exchange-flows/exchange-reserve?exchange=all_exchange&amp;window=DAY&amp;sma=0&amp;ema=0&amp;priceScale=log&amp;metricScale=linear&amp;chartStyle=line\">about a quarter</a> sit on exchanges. The majority of that is collateralizing perp positions.</p><p>Perps are the dominant way crypto trades, in terms of volume. (It bounces around but is typically <a href=\"https://cryptoquant.com/insights/quicktake/691f2c39e69e12693d3aa0bf-Spot-vs-Derivative-Volume-Ratio-Are-Real-Buyers-Taking-Control\">6-8 times larger than spot</a>.) This is similar to most traditional markets: where derivatives are available, derivative volume swamps spot volume. The degree to which depends on the market, Schelling points, user culture, and similar. For example, in India, most retail investing in equity is actually through derivatives; this is not true of the U.S. In the U.S., most retail equity exposure is through the spot market, directly holding stocks or indirectly through ETFs or mutual funds. Most <em>trading volume of the stock indexes</em>, however, is via derivatives.&#xa0;</p><h2 id=\"beginning-with-the-problem\">Beginning with the problem</h2><p>The large crypto exchanges are primarily casinos, who use the crypto markets as a source of numbers, in the same way a traditional casino might use a roulette wheel or set of dice. The function of a casino is for a patron to enter it with money and, statistically speaking, exit it with less. Physical casinos are often huge capital investments with large ongoing costs, including the return on that speculative capital. If they could choose to be less capital intensive, they would do so, but they are partially constrained by market forces and partially by regulation.</p><p>A crypto exchange is also capital intensive, not because the website or API took much investment (relatively low, by the standards of financial software) and not because they have a physical plant, but because trust is expensive. Bettors, and the more sophisticated market makers, who are the primary source of action for bettors, need to trust that the casino will actually be able to pay out winnings. That means the casino needs to keep assets (generally, mostly crypto, but including a smattering of cash for those casinos which are anomalously well-regarded by the financial industry) on hand exceeding customer account balances.</p><p>Those assets are&#x2026; sitting there, doing nothing productive. And there is an implicit cost of capital associated with them, whether nominal (and borne by a gambler) or material (and borne by a sophisticated market making firm, crypto exchange, or the crypto exchange&#x2019;s affiliate which trades against customers [0]).</p><p>Perpetual futures exist to provide the risk gamblers seek while decreasing the total capital requirement (shared by the exchange and market makers) to profitably run the enterprise.</p><h2 id=\"perps-predate-crypto-but-found-a-home-there\">Perps predate crypto but found a home there</h2><p>In the commodities futures markets, you can contract to either buy or sell some standardized, valuable thing at a defined time in the future. The overwhelming majority of contracts do not result in taking delivery; they&#x2019;re cancelled by an offsetting contract before that specified date.</p><p>Given that speculation and hedging are such core use cases for futures, the financial industry introduced a refinement: cash-settled futures. Now there is a reference price for the valuable thing, with a great deal of intellectual effort put into making that reference price robust and fair (not always successfully). Instead of someone notionally taking physical delivery of pork bellies or barrels of oil, people who are net short the future pay people who are net long the future on delivery day. (The mechanisms of this clearing are fascinating but outside today&#x2019;s scope.)</p><p>Back in the early nineties economist Robert Shiller <a href=\"https://ideas.repec.org/a/bla/jfinan/v48y1993i3p911-31.html\">proposed a refinement</a> to cash settled futures: if you don&#x2019;t actually want pork bellies or oil barrels for consumption in April, and we accept that almost no futures participants actually do, why bother closing out the contracts in April? Why fragment the liquidity for contracts between April, May, June, etc? Just keep the market going <em>perpetually</em>.</p><p>This achieved its first widespread popular use in crypto (Bitmex is generally credited as being the popularizer), and hereafter we&#x2019;ll describe the standard crypto implementation. There are, of course, variations available.</p><h2 id=\"multiple-settlements-a-day\">Multiple settlements a day</h2><p>Instead of all of a particular futures vintage settling on the same day, perps settle multiple times a day for a particular market on a particular exchange. The mechanism for this is the <em>funding rate</em>. At a high level: winners get paid by losers every e.g. 4 hours and then the game continues, unless you&#x2019;ve been blown out due to becoming overleveraged or for other reasons (discussed in a moment).</p><p>Consider a toy example: a retail user buys 0.1 Bitcoin via a perp. The price on their screen, which they understand to be for Bitcoin, might be $86,000 each, and so they might pay $8,600 cash. Should the price rise to $90,000 before the next settlement, they will get +/- $400 of winnings credited to their account, and their account will continue to reflect exposure to 0.1 units of Bitcoin via the perp. They might choose to sell their future at this point (or any other). They&#x2019;ll have paid one commission (and a spread) to buy, one (of each) to sell, and perhaps they&#x2019;ll leave the casino with their winnings, or perhaps they&#x2019;ll play another game.</p><p>Where did the money come from? Someone else was symmetrically short exposure to Bitcoin via a perp. It is, with some very important caveats incoming, a closed system: since no good or service is being produced except the speculation, winning money means someone else lost.</p><p>One fun wrinkle for funding rates: some exchanges cap the amount the rate can be for a single settlement period. This is similar in intent to traditional markets&#x2019; usage of <a href=\"https://www.nyse.com/publicdocs/nyse/NYSE_MWCB_FAQ.pdf\">circuit breakers</a>: designed to automatically blunt out-of-control feedback loops. It is dissimilar in that it cannot actually break circuits: changes to funding rate can delay realization of losses but can&#x2019;t prevent them, since they don&#x2019;t prevent the realization of symmetrical gains.</p><p>Perp funding rates also embed an interest rate component. This might get quoted as 3 bps a day, or 1 bps every eight hours, or similar. However, because of the impact of leverage, gamblers are paying more than you might expect: at 10X leverage that&#x2019;s 30 bps a day. Consumer finance legislation standardizes borrowing costs as APR rather than basis points per day so that an unscrupulous lender can&#x2019;t bury a 200% APR in the fine print.</p><h2 id=\"convergence-in-prices-via-the-basis-trade\">Convergence in prices via the basis trade</h2><p>Prices for perps do not, as a fact of nature, exactly match the underlying. That is a <em>feature</em> for some users.</p><p>In general, when the market is exuberant, the perp will trade above spot (the underlying market). To close the gap, a sophisticated market participant should do the <em>basis trade</em>: make offsetting trades in perps and spot (short the perp and buy spot, here, in equal size). Because the funding rate is set against a reference price for the underlying, longs will be paying shorts more (as a percentage of the perp&#x2019;s current market price). For some of them, that&#x2019;s fine: the price of gambling went up, oh well. For others, that&#x2019;s a market incentive to close out the long position, which involves selling it, which will decrease the price at the margin (in the direction of spot).</p><p>The market maker can wait for price convergence; if it happens, they can close the trade at a profit, while having been paid to maintain the trade. If the perp continues to trade rich, they can just continue getting the increased funding cost. To the extent this is higher than <em>their own</em> cost of capital, this can be extremely lucrative.</p><p>Flip the polarities of these to understand the other direction.</p><p>The basis trade, classically executed, is delta neutral: one isn&#x2019;t exposed to the underlying itself. You don&#x2019;t need any belief in Bitcoin&#x2019;s future adoption story, fundamentals, market sentiment, halvings, none of that. You&#x2019;re getting paid to provide the gambling environment, including a really important feature: the perp price needs to stay <em>reasonably</em> close to the spot price, close enough to continue attracting people who want to gamble. You are also renting access to your capital for leverage.</p><p>You are also underwriting the exchange: if they blow up, your collateral becoming a claim against the bankruptcy estate is <em>the happy</em> scenario. (As one motivating example: Galois Capital, a crypto hedge fund doing basis trades, had ~40% of its assets on FTX when it went down. They then wound down the fund, selling the bankruptcy claim for <a href=\"https://www.ft.com/content/a06b77bc-52ac-4901-98d7-8c567449262e\">16 cents on the dollar</a>.)</p><p>Recall that the market can&#x2019;t function without a system of trust saying that someone is good for it if a bettor wins. Here, the market maker is good for it, via the collateral it kept on the exchange.</p><p>Many market makers function across many different crypto exchanges. This is one reason they&#x2019;re so interested in capital efficiency: fully collateralizing all <em>potential</em> positions they could take across the universe of venues they trade on would be prohibitively capital intensive, and if they do not pre-deploy capital, they miss profitable trading opportunities. [1]</p><h2 id=\"leverage-and-liquidations\">Leverage and liquidations</h2><p>Gamblers like risk; it amps up the fun. Since one has many casinos to choose from in crypto, the ones which only &#x201c;regular&#x201d; exposure to Bitcoin (via spot or perps) would be offering a less-fun product for many users than the ones which offer leverage. How much leverage? <em>More leverage</em> is always the answer to that question, until predictable consequences start happening.</p><p>In a standard U.S. brokerage account, <a href=\"https://www.ecfr.gov/current/title-12/chapter-II/subchapter-A/part-220?toc=1\">Regulation T</a> has, for almost 100 years now, set maximum leverage limits (by setting minimums for margins). These are 2X at position opening time and 4X &#x201c;maintenance&#x201d; (before one closes out the position). Your brokerage would be obligated to forcibly close your position if volatility causes you to exceed those limits.</p><p>As a simplified example, if you have $50k of cash, you&#x2019;d be allowed to buy $100k of stock. You now have $50k of equity and a $50k loan: 2x leverage. Should the value of that stock decline to about $67k, you still owe the $50k loan, and so only have $17k remaining equity. You&#x2019;re now on the precipice of being 4X leveraged, and should expect a margin call very soon, if your broker hasn&#x2019;t &#x201c;blown you out of the trade&#x201d; already.</p><p>What part of that is relevant to crypto? For the moment, just focus on that number: 4X.</p><p>Perps are offered at 1X (non-levered exposure). But they&#x2019;re <a href=\"https://www.binance.com/en/square/post/24757521817370\">routinely offered</a> at 20X, 50X, and 100X. SBF, during his press tour / regulatory blitz about being a responsible financial magnate fleecing the customers <em>in an orderly fashion</em>, voluntarily <a href=\"https://www.coindesk.com/markets/2021/07/25/ftx-cuts-leverage-limit-to-20x-from-100x-as-criticism-of-margin-trading-in-crypto-grows\">self-limited FTX to 20X</a>.</p><p>One reason perps are structurally better for exchanges and market makers is that they simplify the business of blowing out leveraged traders. The exact mechanics depend on the exchange, the amount, etc, but generally speaking you can either force the customer to enter a closing trade or you can assign their position to someone willing to bear the risk in return for a discount.</p><p>Blowing out losing traders is lucrative for exchanges except when it catastrophically isn&#x2019;t. It is a priced service in many places. The price is quoted to be low (<a href=\"https://www.binance.com/en/square/post/26755786144026\">&#x201c;a nominal fee of 0.5%</a>&#x201d; is one way Binance describes it) but, since it is calculated from the amount at risk, it can be a large portion of the money lost. If the account&#x2019;s negative balance is less than the liquidation fee, wonderful, thanks for playing and the exchange / &#x201c;the insurance fund&#x201d; keeps the rest, as a tip.</p><p>In the case where the amount an account is negative by is more than the fee, that &#x201c;insurance fund&#x201d; can choose to pay the winners on behalf of the liquidated user, at management&#x2019;s discretion. Management will <em>usually</em> decide to do this, because a casino with a reputation for not paying winners will not long remain a casino.</p><p>But tail risk is a real thing. The capital efficiency <em>has a price</em>: there physically does not exist enough money in the system to pay all winners given sufficiently dramatic price moves. Forced liquidations happen. Sophisticated participants withdraw liquidity (for reasons we&#x2019;ll soon discuss) or the exchange becomes overwhelmed technically / operationally. The forced liquidations eat through the diminished / unreplenished liquidity in the book, and the magnitude of the move increases.</p><p>Then crypto <a href=\"https://unchainedcrypto.com/the-chopping-block-inside-the-19b-perp-crash-adl-explained-binances-usde-staked-token-depeg-and-the-hyperliquid-whale-debate/\">gets reminded</a> about automatic deleveraging (ADL), a detail to perp contracts that few participants understand.</p><h2 id=\"we-have-altered-the-terms-of-your-unregulated-futures-investment-contract\">We have altered the terms of your unregulated futures investment contract.</h2><p>(<a href=\"https://www.youtube.com/watch?v=3D8TEJtQRhw\">Pray we do not alter them further.</a>)</p><p>Risk in perps has to be symmetric: if (accounting for leverage) there are 100,000 units of Somecoin exposure long, then there are 100,000 units of Somecoin exposure short. This does not imply that the shorts or longs are sufficiently capitalized to <em>actually pay</em> for all the exposure in all instances.</p><p>In cases where management deems paying winners from the insurance fund would be too costly and/or impossible, they automatically deleverage some winners. In theory, there is a published process for doing this, because it would be confidence-costing to ADL non-affiliated accounts but pay out affiliated accounts, one&#x2019;s friends or particularly important counterparties, etc. In theory.</p><p>In theory, one likely ADLs accounts which were quite levered before ones which were less levered, and one ADLs accounts which had high profits before ones with lower profits. In theory. [2]</p><p>So perhaps you understood, prior to a 20% move, that you were 4X leveraged. You just earned 80%, right? Ah, except you were only 2X leveraged, so you earned 40%. Why were you <em>retroactively</em> only 2X? That&#x2019;s what automatic deleveraging means. Why couldn&#x2019;t you get the other 40% you feel entitled to? Because the collective group of losers doesn&#x2019;t have enough to pay you your winnings and the insurance fund was insufficient or deemed insufficient by management.</p><p>ADL is particularly painful for sophisticated market participants doing e.g. a basis trade, because they thought e.g. they were 100 units short via perps and 100 units long <em>somewhere else</em> via spot. If it turns out they were actually 50 units short via perps, but 100 units long, their net exposure is +50 units, and they have very possibly just gotten absolutely shellacked.</p><p>In theory, this can happen to the upside or the downside. <em>In practice</em> in crypto, this seems to usually happen after sharp decreases in prices, not sharp increases. For example, October 2025 saw widespread ADLing as (more than) <a href=\"https://www.bloomberg.com/news/articles/2025-11-22/crypto-s-brutal-month-triggers-a-stress-test-for-wall-street\">$19 billion of liquidations</a> happened, across a variety of assets. Alameda&#x2019;s CEO Caroline Ellison <a href=\"https://www.wsj.com/livecoverage/sam-bankman-fried-trial-ftx-caroline-ellison/card/alameda-research-lost-100-million-on-terrausd-uhsJkMxHAu4TU4PJV9Kd?gaa_at=eafs&amp;gaa_n=AWEtsqcUTBS1ClKudIOSulhPczCueQrmHacrKc48MbNkyWvrvttdiJEOV6gGYvaIfpg%3D&amp;gaa_ts=692e37a5&amp;gaa_sig=OrKMG6Tx7IV1mr9NebTACUXOFFABpI3lO-JBghpvChgBNyGFFAN1xPsB-zf6tnqA0JoIWdfvQPbD7ne_aFDiVQ%3D%3D\">testified</a> that they lost over $100 million during the collapse of Terra&#x2019;s stablecoin in 2022, but since FTX&#x2019;s insurance fund <a href=\"https://www.theblock.co/post/255352/ftx-used-random-numbers-to-generate-the-size-of-its-insurance-fund\">was made up</a>; when leveraged traders lost money, their positions were frequently taken up by Alameda. That was quite lucrative much of the time, but catastrophically expensive during e.g. the Terra blowup. Alameda was a good loser and paid the winners, though: with other customers&#x2019; assets that they &#x201c;borrowed.&#x201d;</p><h2 id=\"an-aside-about-liquidations\">An aside about liquidations</h2><p>In the traditional markets, if one&#x2019;s brokerage deems one&#x2019;s assets are unlikely to be able to cover the margin loan from the brokerage one has used, one&#x2019;s brokerage will issue a margin call. Historically that gave one a relatively short period (typically, a few days) to post additional collateral, either by moving in cash, by transferring assets from another brokerage, or by experiencing appreciation in the value of one&#x2019;s assets. Brokerages have the option, and in some cases the requirement, to manage risk after or during a margin call by forcing trades on behalf of the customer to close positions.</p><p>It sometimes surprises crypto natives that, in the case where one&#x2019;s brokerage account goes negative and all assets are sold, with a negative remaining balance, the traditional markets largely <em>still expect you to pay that balance</em>. This contrasts with crypto, where the market expectation for many years was that the customer was Daffy Duck with a gmail address and a pseudonymous set of numbered accounts recorded on a blockchain, and dunning them was a waste of time. Crypto exchanges have mostly, in the intervening years, either stepped up their game regarding <a href=\"https://www.bitsaboutmoney.com/archive/kyc-and-aml-beyond-the-acronyms/\">KYC</a> or pretended to do so, but the market expectation is still that a defaulting user will basically never successfully recover. (Note that the legal obligation to pay is not coextensive with users actually paying. The retail speculators with $25,000 of capital that the pattern day trade rules are worried about will often not have $5,000 to cover a deficiency. On the other end of the scale, when a hedge fund blows up, the fund entity is wiped out, but its limited partners&#x2014;pension funds, endowments, family offices&#x2014;are not on the hook to the prime broker, and nobody expects the general partner to start selling their house to make up the difference.)&#xa0;</p><p>So who bears the loss when the customer doesn&#x2019;t, can&#x2019;t, or won&#x2019;t? The waterfall depends on market, product type, and geography, but as a sketch: brokerages bear the loss first, out of their own capital. They&#x2019;re generally required to keep a reserve for this purpose.&#xa0;</p><p>A brokerage will, in the ordinary course of business, have obligations to other parties which would be endangered if they were catastrophically mismanaged and could not successfully manage risk during a downturn. (It&#x2019;s been known to happen, and even can be associated with <a href=\"https://www.nytimes.com/2007/11/30/business/30citadel.html\">assets rather than liabilities</a>.) In this case, most of those counterparties are partially insulated by structures designed to insure the peer group. These include e.g. clearing pools, guaranty funds capitalized by the member firms of a clearinghouse, the clearinghouse&#x2019;s own capital, and perhaps mutualized insurance pools. That is the rough ordering of the waterfall, which varies depending geography/product/market.</p><p>One can imagine a true catastrophe which burns through each of those layers of protection, and in that case, the clearinghouse might be forced to assess members or allocate losses across survivors. That would be a very, very bad day, but contracts exist to be followed on very bad days.</p><p>One commonality with crypto, though: this system is also not fully capitalized against all possible events at all times. Unlike crypto, which for contingent reasons pays some lip service to being averse to credit even as it embraces leveraged trading, the traditional industry relies <em>extensively</em> on underwriting risk of various participants.</p><h2 id=\"will-crypto-successfully-%E2%80%9Cexport%E2%80%9D-perps\">Will crypto successfully &#x201c;export&#x201d; perps?</h2><p>Many crypto advocates believe that they have something which the traditional finance industry desperately needs. Perps are crypto&#x2019;s most popular and lucrative product, but they probably won&#x2019;t be adopted materially in traditional markets.</p><p>Existing derivatives products already work reasonably well at solving the cost of capital issue. Liquidations are not the business model of traditional brokerages. And learning, on a day when markets are 20% down, that you might be hedged or you might be bankrupt, is not a prospect which fills traditional finance professionals with the warm fuzzies.</p><p>And now you understand the crypto markets a bit better.</p><p>[0] Brokers trading with their own customers can happen in the ordinary course of business, but has been progressively discouraged in traditional finance, as it enables frontrunning.&#xa0;</p><p>Frontrunning, while it is understood in the popular parlance to mean &#x201c;trading before someone else can trade&#x201d; and often brought up in discussions of high frequency trading using very fast computers, does not historically mean that. It historically describes a single abusive practice: a broker could basically use <em>the slowness</em> of traditional financial IT systems to give conditional post-facto treatment to customer orders, taking the other side of them (if profitable) or not (if not). Frontrunning basically disappeared because customers now get order confirms almost instantly by computer not at end of day via a phone call. The confirm has the price the trade executed at on it.&#xa0;</p><p>In classic frontrunning, you sent the customer&#x2019;s order to the market (at some price X), waited a bit, and then observed a later price Y. If Y was worse for the customer than X, well, them&#x2019;s the breaks on Wall Street. If Y was better, you congratulated the customer on their investing acumen, and informed them that they had successfully transacted at Z, a price of your choosing between X and Y. You then fraudulently inserted a recorded transaction between the customer and yourself earlier in the day, at price Z, and assigned the transaction which happened at X to your own account, not to the customer&#x2019;s account.</p><p>Frontrunning was a lucrative scam while it lasted, because (effectively) the customer takes 100% of the risk of the trade but the broker gets any percentage they want of the first day&#x2019;s profits. This is potentially <em>so</em> lucrative that smart money (and some investors in his funds!) thought Madoff was doing it, thus generating the better-than-market stable returns for over a decade through malfeasance. Of frontrunning Madoff was entirely innocent.</p><p>Some more principled crypto participants have attempted to discourage exchanges from trading with their own customers. They have mostly been unsuccessful: Merit Peak Limited is Binance&#x2019;s captive entity which does this. It also is occasionally described by U.S. federal agencies as running a sideline in money laundering, Alameda Research was FTX&#x2019;s affiliated trading fund. Their management was criminally convicted of money laundering. etc, etc.</p><p>One of the reasons this behavior is so adaptive is because the billions of dollars sloshing around can be described to banks as &#x201c;proprietary trading&#x201d; and &#x201c;running an OTC desk&#x201d;, and an inattentive bank (like, say, Silvergate, as <a href=\"https://www.bitsaboutmoney.com/archive/debanking-and-debunking/\">recounted here</a>) might miss the customer fund flows they would have been formally unwilling to facilitate. This is a useful feature for sophisticated crypto participants, and so some of them do not draw attention to the elephant in the room, even though it is averse to their interests.</p><p>[1] Not <em>all</em> crypto trades are pre-funded. Crypto OTC transactions sometimes settle on T+1, with the OTC desk essentially extending credit in the fashion that a prime broker would in traditional markets. But most transactions on exchanges have to be paid immediately in cash already at the venue. This is very different from traditional equity market structure, where venues don&#x2019;t typically receive funds flow at all, and settling/clearing happens after the fact, generally by a day or two.</p><p>[2] I note, for the benefit of readers of footnote 0, that there is often a substantial gap between the time when market dislocation happens and when a trader is informed they were ADLed. The implications of this are left as an exercise to the reader.</p>"
            ],
            "link": "https://www.bitsaboutmoney.com/archive/perpetual-futures-explained/",
            "publishedAt": "2025-12-05",
            "source": "Bits About Money",
            "summary": "Crypto\u2019s most popular product offers capital efficiency for professionals, leveraged exposure for the masses, rich yields for market makers \u2014 and a poorly understood failure mode.",
            "title": "Perpetual futures, explained"
        },
        {
            "content": [],
            "link": "https://interconnected.org/home/2025/12/05/training",
            "publishedAt": "2025-12-05",
            "source": "Matt Webb",
            "summary": "<div> <p>I left a loose end the other day when I said that <a href=\"https://interconnected.org/home/2025/11/28/plumbing\">AI is about intent and context</a>.</p> <p>That was when I said <em>\"what\u2019s context at inference time is valuable training data if it\u2019s recorded.\"</em></p> <p>But I left it at that, and didn\u2019t really get into why training data is valuable.</p> <p>I think we often just draw a straight arrow from <em>\u201ccollect training data,\u201d</em> like ingest pages from Wikipedia or see what people are saying to the chatbot, to <em>\u201cnow the AI model is better and therefore it wins.\u201d</em></p> <p>But I think it\u2019s worth thinking about what that arrow actually means. Like, what is the mechanism here?</p> <p>Now all of this is just my mental model for what\u2019s going on.</p> <p>With that caveat:</p> <p>To my mind, the era-defining AI company is the one that is the first to close two self-accelerating loops.</p> <p>Both are to do with training data. The first is the general theory; the second is specific.</p> <hr /> <h3>Training data for platform capitalism</h3> <p>When I say era-defining companies, to me there\u2019s an era-defining idea, or at least era-<em>describing,</em> and that\u2019s Nick Srnicek\u2019s concept of <a href=\"https://www.amazon.co.uk/Platform-Capitalism-Theory-Redux-Srnicek/dp/1509504877\">Platform Capitalism</a> <em>(Amazon).</em></p> <p>It is the logic that underpins the",
            "title": "My mental model of the AI race"
        },
        {
            "content": [],
            "link": "https://www.nytimes.com/2025/12/05/style/modern-love-ai-divorce-rebound-with-robot.html",
            "publishedAt": "2025-12-05",
            "source": "Modern Love - NYT",
            "summary": "Raised on a commune, I resisted technology at every step. Until it saved me.",
            "title": "Healing My Heart for 20 Dollars a Month"
        },
        {
            "content": [],
            "link": "https://www.nytimes.com/2025/12/03/style/tiny-modern-love-stories-he-was-75-i-was-42.html",
            "publishedAt": "2025-12-05",
            "source": "Modern Love - NYT",
            "summary": "Modern Love in miniature, featuring reader-submitted stories of no more than 100 words.",
            "title": "Tiny Love Stories: \u2018He Was 75. I Was 42.\u2019"
        },
        {
            "content": [],
            "link": "https://www.robinsloan.com/lab/releasebot/",
            "publishedAt": "2025-12-05",
            "source": "Robin Sloan",
            "summary": "<p>A cool new service. <a href=\"https://www.robinsloan.com/lab/releasebot/\">Read here.</a></p>",
            "title": "Releasebot!"
        },
        {
            "content": [
                "<p>DeepSeek v3.2 is DeepSeek\u2019s latest open model release with strong bencharks. Its paper contains some technical innovations that drive down cost.</p>\n<p>It\u2019s a good model by the standards of open models, and very good if you care a lot about price and openness, and if you care less about speed or whether the model is Chinese. It is strongest in mathematics.</p>\n<p>What it does not appear to be is frontier. It is definitely not having a moment. In practice all signs are that it underperforms its benchmarks.</p>\n<p>When I asked for practical experiences and reactions, I got almost no responses.</p>\n<div>\n\n\n<span id=\"more-24934\"></span>\n\n\n</div>\n\n\n<h4 class=\"wp-block-heading\">A Brief History of DeepSeek</h4>\n\n\n<p>DeepSeek is a cracked Chinese AI lab that has produced some very good open models, done some excellent research, and given us strong innovations in terms of training techniques and especially training efficiency.</p>\n<p>They also, back at the start of the year, scared the hell out of pretty much everyone.</p>\n<p>A few months after OpenAI released o1, and shortly after DeepSeek released the impressive v3 that was misleadingly known as the \u2018six million dollar model,\u2019 DeepSeek came out with a slick app and with r1, a strong open reasoning model based on v3 that showed its chain of thought. With reasoning models not yet scaled up, it was the perfect time for a fast follow, and DeepSeek executed that very well.</p>\n<p>Due to a strong viral marketing campaign and confluence of events, including that DeepSeek\u2019s app shot to #1 on the app store, and conflating the six million in cost to train v3 with OpenAI\u2019s entire budget of billions, and contrasting r1\u2019s strengths with o1\u2019s weaknesses, events briefly (and wrongly) convinced a lot of people that China or DeepSeek had \u2018caught up\u2019 or was close behind American labs, as opposed to being many months behind.</p>\n<p>There was even talk that American AI labs or all closed models were \u2018doomed\u2019 and so on. Tech stocks were down a lot and people attributed that to DeepSeek, in ways that reflected a stock market highly lacking in situational awareness and responding irrationally, even if other factors were also driving a lot of the move.</p>\n<p>Politicians claimed this meant we had to \u2018race\u2019 or else we would \u2018lose to China,\u2019 thus all other considerations must be sacrificed, and to this day the idea of a phantom DeepSeek-Huawei \u2018tech stack\u2019 is used to scare us.</p>\n<p>This is collectively known as The DeepSeek Moment.</p>\n<p>Slowly, in hindsight, <a href=\"https://thezvi.substack.com/i/165339410/we-had-a-moment\"><strong>the confluence of factors that caused this moment became clear</strong></a>. DeepSeek had always been behind by many months, likely about eight. Which was a lot shorter than previous estimates, but a lot more than people were saying.</p>\n<p>Later releases bore this out. DeepSeek\u2019s r1-0528 and v3.1 did not \u2018have a moment,\u2019 ad neither did v3.2-exp or now v3.2. The releases disappointed.</p>\n<p>DeepSeek remains a national champion and source of pride in China, and is a cracked research lab that innovates for real. Its models are indeed being pushed by the PRC, especially in the global south.</p>\n<p>For my coverage of this, see:</p>\n<ol>\n<li><a href=\"https://thezvi.substack.com/p/deekseek-v3-the-six-million-dollar?utm_source=chatgpt.com\">DeepSeek v3: The Six Million Dollar Model</a>.</li>\n<li><a href=\"https://thezvi.substack.com/p/on-deepseeks-r1?utm_source=chatgpt.com\">On DeepSeek\u2019s r1</a>.</li>\n<li><a href=\"https://thezvi.substack.com/p/deepseek-panic-at-the-app-store?utm_source=chatgpt.com\">DeepSeek: Panic at the App Store</a>.</li>\n<li><a href=\"https://thezvi.substack.com/p/deepseek-lemon-its-wednesday?utm_source=chatgpt.com\">DeepSeek: Lemon, It\u2019s Wednesday</a>.</li>\n<li><a href=\"https://thezvi.substack.com/p/deepseek-dont-panic?utm_source=chatgpt.com\">DeepSeek: Don\u2019t Panic.</a></li>\n<li><a href=\"https://thezvi.substack.com/p/deepseek-r1-0528-did-not-have-a-moment?utm_source=publication-search\">DeepSeek-r1-0528 Did Not Have a Moment.</a></li>\n<li><a href=\"https://thezvi.substack.com/p/deepseek-v31-is-not-having-a-moment?utm_source=chatgpt.com\">DeepSeek v3.1 Is Not Having a Moment</a>.</li>\n</ol>\n\n\n<h4 class=\"wp-block-heading\">Once More, With Feeling</h4>\n\n\n<p>I\u2019d just been through a few weeks in which we got GPT-5.1, Grok 4.1, Gemini 3 Pro, GPT-5.1-Codex-Max and then finally Claude Opus 4.5. Mistral, listed above, doesn\u2019t count. Which means we\u2019re done and can have a nice holiday season, asks Padme?</p>\n<p>No, Anakin said. There is another.</p>\n<blockquote><p><a href=\"https://x.com/deepseek_ai/status/1995452641430651132\">DeepSeek</a>: <img alt=\"\ud83d\ude80\" class=\"wp-smiley\" src=\"https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f680.png\" style=\"height: 1em;\" /> Launching DeepSeek-V3.2 &amp; DeepSeek-V3.2-Speciale \u2014 Reasoning-first models built for agents!</p>\n<p><img alt=\"\ud83d\udd39\" class=\"wp-smiley\" src=\"https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f539.png\" style=\"height: 1em;\" /> DeepSeek-V3.2: Official successor to V3.2-Exp. Now live on App, Web &amp; API.</p>\n<p><img alt=\"\ud83d\udd39\" class=\"wp-smiley\" src=\"https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f539.png\" style=\"height: 1em;\" /> DeepSeek-V3.2-Speciale: Pushing the boundaries of reasoning capabilities. API-only for now.</p>\n<p><a href=\"https://t.co/7EyydyNuG0\">Tech report [here]</a>,<a href=\"https://t.co/Kh8HzHl3uX\"> v3.2 model,</a> <a href=\"https://t.co/ZKUg5IC0AJ\">v3.2-speciale model</a>.</p>\n<p><img alt=\"\ud83c\udfc6\" class=\"wp-smiley\" src=\"https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f3c6.png\" style=\"height: 1em;\" /> World-Leading Reasoning</p>\n<p><img alt=\"\ud83d\udd39\" class=\"wp-smiley\" src=\"https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f539.png\" style=\"height: 1em;\" /> V3.2: Balanced inference vs. length. Your daily driver at GPT-5 level performance.</p>\n<p><img alt=\"\ud83d\udd39\" class=\"wp-smiley\" src=\"https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f539.png\" style=\"height: 1em;\" /> V3.2-Speciale: Maxed-out reasoning capabilities. Rivals Gemini-3.0-Pro.</p>\n<p><img alt=\"\ud83e\udd47\" class=\"wp-smiley\" src=\"https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f947.png\" style=\"height: 1em;\" /> Gold-Medal Performance: V3.2-Speciale attains gold-level results in IMO, CMO, ICPC World Finals &amp; IOI 2025.</p>\n<p><img alt=\"\ud83d\udcdd\" class=\"wp-smiley\" src=\"https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f4dd.png\" style=\"height: 1em;\" /> Note: V3.2-Speciale dominates complex tasks but requires higher token usage. Currently API-only (no tool-use) to support community evaluation &amp; research.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!yXRK!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdaf1f98a-389c-4c18-b855-7a129b784b46_1200x723.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p><img alt=\"\ud83e\udd16\" class=\"wp-smiley\" src=\"https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f916.png\" style=\"height: 1em;\" /> Thinking in Tool-Use</p>\n<p><img alt=\"\ud83d\udd39\" class=\"wp-smiley\" src=\"https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f539.png\" style=\"height: 1em;\" /> Introduces a new massive agent training data synthesis method covering 1,800+ environments &amp; 85k+ complex instructions.</p>\n<p><img alt=\"\ud83d\udd39\" class=\"wp-smiley\" src=\"https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f539.png\" style=\"height: 1em;\" /> DeepSeek-V3.2 is our first model to integrate thinking directly into tool-use, and also supports tool-use in both thinking and non-thinking modes.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!pr6B!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3e091b11-1df2-4721-ac06-fdae1dd86427_1200x254.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n</blockquote>\n\n\n<h4 class=\"wp-block-heading\">Reading The Paper</h4>\n\n\n<p>Teortaxes threatened to bully me if I did not <a href=\"https://arxiv.org/html/2512.02556v1\">read the v3.2 paper</a>. I did read it. The main innovation appears to be a new attention mechanism, which improves training efficiency and also greatly reduces compute cost to scaling the context window, resulting in v3.2 being relatively cheap without being relatively fast. Unfortunately I lack the expertise to appreciate the interesting technical aspects. Should I try and fix this in general? My gut says no.</p>\n<p>What the paper did not include was <a href=\"https://x.com/davidmanheim/status/1995489124611235855\">any form of safety testing or information of any kind</a> for this irreversible open release. There was not, that I could see, even a sentence that said \u2018we did safety testing and are confident in this release\u2019 or even one that said \u2018we do not see any need to do any safety testing.\u2019 It\u2019s purely and silently ignored.</p>\n<blockquote><p>David Manheim: They announce the new DeepSeek.</p>\n<p>\u201cDid it get any safety testing, or is it recklessly advancing open-source misuse capability?\u201d</p>\n<p>They look confused.</p>\n<p>\u201cDid it get any safety testing?\u201d</p>\n<p>\u201cIt is good model, sir!\u201d</p>\n<p>I check the model card.</p>\n<p>There\u2019s absolutely no mention of misuse or safety.</p></blockquote>\n<p>Frankly, this is deeply irresponsible and completely unacceptable.</p>\n<p><a href=\"https://x.com/georgejrjrjr/status/1995770539755868371\">DeepSeek did by some accounts become somewhat censorious back in May</a>, but that doesn\u2019t seem to apply to, as George puts it, plans for &lt;bad_device&gt;.</p>\n<p>DeepSeek claims to be \u2018pushing the boundaries of reasoning capabilities\u2019 and to be giving a GPT-5 level of performance. Their benchmarks match this story.</p>\n<p>And they can\u2019t even give us an explanation of why they don\u2019t believe they owe us any sort of explanation? Not even a single sentence?</p>\n<p>I knew DeepSeek was an irresponsible lab. I didn\u2019t know they were this irresponsible.</p>\n\n\n<h4 class=\"wp-block-heading\">Open Language Model Offers Mundane Utility</h4>\n\n\n<p>The short version of my overall take seems to be that DeepSeek v3.2 is excellent for its price point, and its best area is mathematics, but while it is cheap it is reported to be remarkably slow, and for most practical purposes it is not frontier.</p>\n<p>Which means you only would use it either if you are doing relatively advanced math, or if all four of the following are true:</p>\n<ol>\n<li>You don\u2019t need the frontier capabilities</li>\n<li>You don\u2019t mind the lack of speed.</li>\n<li>You benefit a lot from decreased cost or it being an open model or both.</li>\n<li>You don\u2019t mind the security concerns.</li>\n</ol>\n<p>The only strong praise I found in practice was <a href=\"https://x.com/jd_pressman/status/1996562133782581643\">this exchange from perennial whale (DeepSeek) advocate Teortaxes, Vinicius and John Pressman</a>:</p>\n<blockquote><p>Teortaxes: Strange feeling, talking to Opus 4.5 and V3.2 and objectively\u2026 Opus is not worth it. Not just for the price; its responses are often less sharp, less interesting. But I\u2019m still burning tokens.<br />\nAnthropic can coast far on \u201cpersonality\u201d, enterprise coding aside.</p>\n<p>John Pressman: Opus told me I was absolutely right when I wasn\u2019t, V3.2 told me I was full of shit and my idea wouldn\u2019t work when it sort of would, but it was right in spirit and I know which behavior I would rather have.</p>\n<p>I\u2019ve never understood this phenomenon because if I was tuning a model and it ever told me I was \u201cabsolutely right\u201d about some schizo and I wasn\u2019t I would throw the checkpoint out.</p>\n<p>Vinicius: Have you been using Speciale?</p>\n<p>Teortaxes: yes but it\u2019s not really as good as 3.2<br />\nit\u2019s sometimes great (when it doesn\u2019t doomloop) for zero-shotting a giant context</p>\n<p>Vinicius: I\u2019ve been using 3.2-thinking to handle input from social media/web; it\u2019s insanely good for research, but I haven\u2019t found a real use case for Speciale in my workflows.</p></blockquote>\n<p>Notice the background agreement that the \u2018model to beat\u2019 for most purposes is Opus 4.5, not Gemini 3 or GPT-5.1. I strongly agree with this, although Gemini 3 still impresses on \u2018just the facts\u2019 or \u2018raw G\u2019 tasks.</p>\n<p>Some people really want a combative, abrasive sparring partner that will err on the side of skepticism and minimize false positives. Teortaxes and Pressman definitely fit that bill. That\u2019s not what most people want. You can get Opus to behave a lot more in that direction if you really want that, but not easily get it to go all the way.</p>\n<p>Is v3.2 a good model that has its uses? My guess is that it is. But if it was an exciting model in general, we would have heard a lot more.</p>\n\n\n<h4 class=\"wp-block-heading\">Those Benchmarks</h4>\n\n\n<p>They are very good benchmarks, and a few independent benchmarks also gave v3.2 high scores, but what\u2019s the right bench to be maxing?</p>\n<blockquote><p><a href=\"https://x.com/teortaxesTex/status/1995448208709890187\">Teortaxes:</a> V3.2 is here, it\u2019s no longer \u201cexp\u201d. It\u2019s frontier. Except coding/agentic things that are being neurotically benchmaxxed by the big 3. That\u2019ll take one more update.<br />\n\u201cSpeciale\u201d is a high compute variant that\u2019s between Gemini and GPT-5 and can score gold on IMO-2025.<br />\nThank you guys.</p>\n<p>hallerite: hmm, I wonder if the proprietary models are indeed being benchmaxxed. DeepSeek was always a bit worse at the agentic stuff, but I guess we could find out as soon as another big agentic eval drops</p>\n<p>Teortaxes: I\u2019m using the term loosely. They\u2019re \u201cbenchmaxxed\u201d for use cases, not for benchmarks. Usemaxxed. But it\u2019s a somewhat trivial issue of compute and maybe environment curation (also overwhelmingly a function of compute).</p></blockquote>\n<p>This confuses different maxings of things but I love the idea of \u2018usemaxxed.\u2019</p>\n<blockquote><p><a href=\"https://x.com/teortaxesTex/status/1995906126018187481\">Teortaxes</a> (responding to my asking): Nah. Nothing happened. Sleep well, Zvi\u2026<br />\n(nothing new happened. \u00abA factor of two\u00bb price reduction\u2026 some more post-training\u2026 this was, of course, all baked in. If V3.2-exp didn\u2019t pass the triage, why would 3.2?)</p></blockquote>\n<p>That\u2019s a highly fair thing to say about the big three, that they\u2019ve given a lot of focus to making them actually useful in practice for common use cases. So one could argue that by skipping all that you could get a model that was fundamentally as smart or frontier as the big three, it just would take more work to get it to do the most common use cases. It\u2019s plausible.</p>\n<blockquote><p><a href=\"https://x.com/teortaxesTex/status/1995933395025870938\">Teortaxes</a>: I think Speciale\u2019s peak performance suggests a big qualitative shift. Their details on post-training methodology align with how I thought the frontier works now. This is the realm you can\u2019t touch with distillation.</p>\n<p>Lisan al Gaib: LisanBench results for DeepSeek-V3.2</p>\n<p>DeepSeek-V3.2 and V3.2 Speciale are affordable frontier models*</p>\n<p>*the caveat is that they are pretty slow at ~30-40tks/s and produce by far the longest reasoning chains at 20k and 47k average output tokens (incl. reasoning) &#8211; which results in extremely long waiting times per request.</p>\n<p>but pricing is incredible<br />\nfor example, Sonnet 4.5 Thinking costs 10x ($35) as much and scores much lower than DeepSeek-V3.2 Speciale ($3)</p>\n<p>DeepSeek V3.2 Speciale also scored 13 new high scores</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!qyAj!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F71643d3a-b1bb-4e1f-8fee-18b2c7cd0daa_1200x622.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p><a href=\"https://x.com/ChaseBrowe32432/status/1995552995724153266\">Chase Brower</a>: DSV3.2-Speciale scores 30 on @AcerFur \u2018s IUMB math benchmark, tying with the existing top performer Gemini 3 Pro Preview.</p>\n<p>Token usage/cost isn\u2019t up yet, but it cost $1.07 to run Speciale with 2546096 total tokens, vs $20.64 for gpt-5 <img alt=\"\ud83d\udc40\" class=\"wp-smiley\" src=\"https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f440.png\" style=\"height: 1em;\" /><img alt=\"\ud83d\udc40\" class=\"wp-smiley\" src=\"https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f440.png\" style=\"height: 1em;\" /></p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!yQaW!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9f9a98c0-6251-466e-8deb-27b07aa959f9_1200x611.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n</blockquote>\n<p>Those are presumably non-targeted benchmark that give sensible ratings elsewhere, <a href=\"https://x.com/Hangsiin/status/1995899545339990042\">as is this one from NomoreID</a> on a Korean test, so it confirms that the \u2018good on benchmarks\u2019 thing is probably generally real especially on math.</p>\n\n\n<h4 class=\"wp-block-heading\">Open Language Model Doesn\u2019t Offer Mundane Utility</h4>\n\n\n<p>In practice, it seems less useful, whether or not that is because less usemaxxed.</p>\n<p>I want my models to be usemaxxed, because the whole point is to use them.</p>\n<p>Also our standards are very high.</p>\n<blockquote><p><a href=\"https://x.com/ChaseBrowe32432/status/1995910694215320000\">Chase Brower</a>: The big things you\u2019ll see on tpot are:<br />\n&#8211; vibecoding (V3.2 is still a bit behind in performance + really slow inference)<br />\n&#8211; conversation (again, slow)</p>\n<p>Since it\u2019s not very good for these, you won\u2019t hear much from tpot</p>\n<p>I feel like it\u2019ll be a go-to for math/proving assistance, tho</p>\n<p>Clay Schubiner: It\u2019s weak but is technically on the Pareto frontier by being cheap &#8211; at least on my benchmark</p>\n<p>Jake Halloran: spent like 10 minutes testing it and its cheap and ~fine~</p>\n<p>its not frontier but not bad either (gpt 5ish)</p></blockquote>\n<p>The counterargument is that if you are \u2018gpt 5ish\u2019 then the core capabilities pre-usemaxxing are perhaps only a few months behind now? Which is very different from being overall only a few months behind in a practical way, or in a way that would let one lead.</p>\n<p><a href=\"https://x.com/elder_plinius/status/1995514604001308941\">The Pliny jailbreak is here, if you\u2019re curious</a>.</p>\n<p><a href=\"https://x.com/gallabytes/status/1995529866595500071\">Gallabytes was unimpressed</a>, as were those responding if your standard is the frontier. There were reports of it failing <a href=\"https://x.com/SteveStricklan6/status/1995670216840544566\">various gotcha questions</a> and no reports of it passing.</p>\n\n\n<h4 class=\"wp-block-heading\">Open Language Model Does Do The Math</h4>\n\n\n<p>In other DeepSeek news, <a href=\"https://x.com/novasarc01/status/1994057920544469399\">DeepSeekMath-v2 used a prover-verifier loop that calls out the model\u2019s own mistakes</a> for training purposes, the same way you\u2019d do it if you were learning real math.</p>\n<blockquote><p><a href=\"https://x.com/teortaxesTex/status/1994092229288497581\">Teortaxes</a>: There is a uniquely Promethean vibe in Wenfeng\u2019s project.</p>\n<p>Before DS-MoE, only frontier could do efficiency.</p>\n<p>Before DS-Math/Prover, only frontier could do Real math.</p>\n<p>Before DS-Prover V2, only frontier could do Putnam level.</p>\n<p>Before DS-Math V2, only frontier could do IMO Gold\u2026</p>\n<p>This is why I don\u2019t think they\u2019ll be the first to \u201cAGI\u201d, but they will likely be the first to make it open source. They can replicate anything on a shoestring budget, given some time. Stealing fire from definitely-not-gods will continue until human autonomy improves.</p></blockquote>\n<p>So far, the reported actual breakthroughs have all been from American closed source frontier models. Let\u2019s see if that changes.</p>\n<p>I am down with the recent direction of DeepSeek releases towards specialized worthwhile math topics. That seems great. I do not want them trying to cook an overall frontier model, especially given their deep level of irresponsibility.</p>\n\n\n<h4 class=\"wp-block-heading\">I\u2019ll Get You Next Time, Gadget</h4>\n\n\n<p>Making things cheaper can still be highly valuable, even with other issues. By all accounts this model has real things to offer, the first noteworthy DeepSeek offering since r1. What it is not, regardless of their claims, is a frontier model.</p>\n<p>This is unsurprising. You don\u2019t go from v3.2-exp to v3.2 in your naming schema while suddenly jumping to the frontier. You don\u2019t actually go on the frontier, I would hope, with a fully open release, while saying actual zero words about safety concerns.</p>\n<p>DeepSeek are still doing interesting and innovative things, and this buys some amount of clock in terms of keeping them on the map.</p>\n<p>As DeepSeek says in their v3.2 paper, open models have since r1 been steadily falling further behind closed models rather than catching up. v3.2 appears to close some of that additional gap.</p>\n<p>The question is, will they be cooking a worthy v4 any time soon?</p>\n<p>The clock is ticking.</p>\n<p>&nbsp;</p>"
            ],
            "link": "https://thezvi.wordpress.com/2025/12/05/deepseek-v3-2-is-okay-and-cheap-but-slow/",
            "publishedAt": "2025-12-05",
            "source": "TheZvi",
            "summary": "DeepSeek v3.2 is DeepSeek\u2019s latest open model release with strong bencharks. Its paper contains some technical innovations that drive down cost. It\u2019s a good model by the standards of open models, and very good if you care a lot about &#8230; <a href=\"https://thezvi.wordpress.com/2025/12/05/deepseek-v3-2-is-okay-and-cheap-but-slow/\">Continue reading <span class=\"meta-nav\">&#8594;</span></a>",
            "title": "DeepSeek v3.2 Is Okay And Cheap But Slow"
        },
        {
            "content": [],
            "link": "https://xkcd.com/3177/",
            "publishedAt": "2025-12-05",
            "source": "XKCD",
            "summary": "<img alt=\"Luckily, the range is limited by the fact that the square boundary lines follow great circles.\" src=\"https://imgs.xkcd.com/comics/chessboard_alignment.png\" title=\"Luckily, the range is limited by the fact that the square boundary lines follow great circles.\" />",
            "title": "Chessboard Alignment"
        }
    ],
    "lookbackDays": 1,
    "publishDate": "2025-12-05"
}