{
    "articles": [
        {
            "content": [],
            "link": "https://www.nytimes.com/2026/01/01/style/tiny-modern-love-stories-am-i-too-old-to-experience-butterflies.html",
            "publishedAt": "2026-01-01",
            "source": "Modern Love - NYT",
            "summary": "Modern Love in miniature, featuring reader-submitted stories of no more than 100 words.",
            "title": "Tiny Love Stories: \u2018Am I Too Old to Experience Butterflies?\u2019"
        },
        {
            "content": [],
            "link": "https://simonwillison.net/2026/Jan/1/gisthost/#atom-entries",
            "publishedAt": "2026-01-01",
            "source": "Simon Willison",
            "summary": "<p>I am a huge fan of <a href=\"https://gistpreview.github.io/\">gistpreview.github.io</a>, the site by Leon Huang that lets you append <code>?GIST_id</code> to see a browser-rendered version of an HTML page that you have saved to a Gist. The last commit was ten years ago and I needed a couple of small changes so I've forked it and deployed an updated version at <a href=\"https://gisthost.github.io/\">gisthost.github.io</a>.</p> <h4 id=\"some-background-on-gistpreview\">Some background on gistpreview</h4> <p>The genius thing about <code>gistpreview.github.io</code> is that it's a core piece of GitHub infrastructure, hosted and cost-covered entirely by GitHub, that wasn't built with any involvement from GitHub at all.</p> <p>To understand how it works we need to first talk about Gists.</p> <p>Any file hosted in a <a href=\"https://gist.github.com/\">GitHub Gist</a> can be accessed via a direct URL that looks like this:</p> <p><code>https://gist.githubusercontent.com/simonw/d168778e8e62f65886000f3f314d63e3/raw/79e58f90821aeb8b538116066311e7ca30c870c9/index.html</code></p> <p>That URL is served with a few key HTTP headers:</p> <pre><code>Content-Type: text/plain; charset=utf-8 X-Content-Type-Options: nosniff </code></pre> <p>These ensure that every file is treated by browsers as plan text, so HTML file will not be rendered even by older browsers that attempt to guess the content type based on the content.</p> <pre><code>Via: 1.1 varnish Cache-Control: max-age=300 X-Served-By: cache-sjc1000085-SJC </code></pre> <p>These confirm that the file is sever via GitHub's caching CDN, which means I",
            "title": "Introducing gisthost.github.io"
        },
        {
            "content": [
                "<p>\n          <a href=\"https://www.astralcodexten.com/p/learn-phrygian-in-zero-days\">\n              Read more\n          </a>\n      </p>"
            ],
            "link": "https://www.astralcodexten.com/p/learn-phrygian-in-zero-days",
            "publishedAt": "2026-01-01",
            "source": "SlateStarCodex",
            "summary": "<p> <a href=\"https://www.astralcodexten.com/p/learn-phrygian-in-zero-days\"> Read more </a> </p>",
            "title": "Learn Phrygian In Zero Days"
        },
        {
            "content": [
                "<p>The Rationalist Project <a href=\"https://thezvi.substack.com/publish/post/153652219?back=%2Fpublish%2Fposts%2Fpublished\">was our last best hope</a> that we might not try to build it.</p>\n<p>It failed.</p>\n<p>But in the year of the Coding Agent, it became something greater: our last, best hope &#8211; for everyone not dying.</p>\n<p><a href=\"https://www.lesswrong.com/posts/6Xgy6CAf2jqHhynHL/what-2026-looks-like\">This is what 2026 looks like</a>. <a href=\"https://www.lesswrong.com/posts/eKGdCNdKjvTBG9i6y/toss-a-bitcoin-to-your-lightcone-lw-lighthaven-s-2026\">The place is Lighthaven.</a></p>\n\n\n<h4 class=\"wp-block-heading\">Table of Contents</h4>\n\n\n<ol>\n<li><a href=\"https://thezvi.substack.com/i/182595018/language-models-offer-mundane-utility\">Language Models Offer Mundane Utility.</a> 2026 is an age of wonders.</li>\n<li><a href=\"https://thezvi.substack.com/i/182595018/claude-code\">Claude Code.</a> The age of humans writing code may be coming to an end.</li>\n<li><a href=\"https://thezvi.substack.com/i/182595018/language-models-don-t-offer-mundane-utility\">Language Models Don\u2019t Offer Mundane Utility.</a> Your dog\u2019s dead, Jimmy.</li>\n<li><a href=\"https://thezvi.substack.com/i/182595018/deepfaketown-and-botpocalypse-soon\">Deepfaketown and Botpocalypse Soon.</a> Keep your nonsense simple.</li>\n<li><a href=\"https://thezvi.substack.com/i/182595018/fun-with-media-generation\">Fun With Media Generation.</a> YouTube facing less AI slop than I\u2019d expect.\n<div>\n\n\n<span id=\"more-24999\"></span>\n\n\n</div>\n</li>\n<li><a href=\"https://thezvi.substack.com/i/182595018/you-drive-me-crazy\">You Drive Me Crazy.</a> Another lawsuit against OpenAI. This one is a murder.</li>\n<li><a href=\"https://thezvi.substack.com/i/182595018/they-took-our-jobs\">They Took Our Jobs.</a> Yet another round of \u2018oh but comparative advantage.\u2019</li>\n<li><a href=\"https://thezvi.substack.com/i/182595018/doctor-doctor\">Doctor Doctor.</a> Yes a lot of people still want a human doctor, on principle.</li>\n<li><a href=\"https://thezvi.substack.com/i/182595018/jevons-paradox-strikes-again\">Jevons Paradox Strikes Again.</a> It holds until it doesn\u2019t.</li>\n<li><a href=\"https://thezvi.substack.com/i/182595018/unprompted-attention\">Unprompted Attention.</a> Concepts, not prompts.</li>\n<li><a href=\"https://thezvi.substack.com/i/182595018/the-art-of-the-jailbreak\">The Art of the Jailbreak.</a> Love, Pliny.</li>\n<li><a href=\"https://thezvi.substack.com/i/182595018/get-involved\">Get Involved.</a> CAISI wants an intern, OpenAI hiring a head of preparedness.</li>\n<li><a href=\"https://thezvi.substack.com/i/182595018/introducing\">Introducing.</a> GLM-4.7 does well on GDPVal, a 164M model gets 31% on GPQA-D.</li>\n<li><a href=\"https://thezvi.substack.com/i/182595018/in-other-ai-news\">In Other AI News.</a> ChatGPT declines over 2025 from 87% to 68% of traffic.</li>\n<li><a href=\"https://thezvi.substack.com/i/182595018/show-me-the-money\">Show Me the Money.</a> Meta buys Manus.</li>\n<li><a href=\"https://thezvi.substack.com/i/182595018/quiet-speculations\"><strong>Quiet Speculations</strong>.</a> Discussions on timelines, how to interpret the post title.</li>\n<li><a href=\"https://thezvi.substack.com/i/182595018/people-really-do-not-like-ai\">People Really Do Not Like AI.</a> Fox News is latest to observe this.</li>\n<li><a href=\"https://thezvi.substack.com/i/182595018/americans-remain-optimistic-about-ai\">Americans Remain Optimistic About AI?</a> David Shor notices this twist.</li>\n<li><a href=\"https://thezvi.substack.com/i/182595018/thank-you-next\">Thank You, Next.</a> No thank you, Robert Pike.</li>\n<li><a href=\"https://thezvi.substack.com/i/182595018/the-quest-for-sane-regulations\">The Quest for Sane Regulations.</a> Pro-AI does not have to mean anti-regulation.</li>\n<li><a href=\"https://thezvi.substack.com/i/182595018/chip-city\"><strong>Chip City</strong>.</a> China orders millions of H200 chips, Nvidia moves to produce them.</li>\n<li><a href=\"https://thezvi.substack.com/i/182595018/rhetorical-innovation\">Rhetorical Innovation.</a> So far this world is in what we call a \u2018soft\u2019 takeoff.</li>\n<li><a href=\"https://thezvi.substack.com/i/182595018/aligning-a-smarter-than-human-intelligence-is-difficult\">Aligning a Smarter Than Human Intelligence is Difficult.</a> Hey, that\u2019s your Buddy.</li>\n<li><a href=\"https://thezvi.substack.com/i/182595018/people-are-worried-about-ai-killing-everyone\">People Are Worried About AI Killing Everyone.</a> Grandparents are wise.</li>\n<li><a href=\"https://thezvi.substack.com/i/182595018/the-lighter-side\">The Lighter Side.</a> Might as well finish the post at this point.</li>\n</ol>\n\n\n<h4 class=\"wp-block-heading\">Language Models Offer Mundane Utility</h4>\n\n\n<p><a href=\"https://x.com/deepfates/status/2004257044916842681\">Deepfates points out that for $20/month you can get essentially unlimited chat access</a> to one of several amazing digital minds that are constantly getting better (I recommend <a href=\"http://claude.ai\">Claude</a> if you have to pick only one), that this is a huge effective equalizing effect that is democratic and empowering, and if you\u2019re not taking advantage of this you should start. Even for $0/month you can get something pretty amazing, you\u2019ll be less than a year behind.</p>\n<p>He also notes the \u2018uses tons of water,\u2019 \u2018scaling is dead\u2019 and \u2018synthetic data doesn\u2019t work\u2019 objections are basically wrong. I\u2019d say the water issue is \u2018more wrong\u2019 than the other two but yeah basically all three are more wrong than right. \u200b</p>\n<p><a href=\"https://x.com/spicey_lemonade/status/2004558572496035892\">Archivara Math Research Agent claimed to have solved Erdos Problem #897</a> entirely on its own end-to-end.</p>\n<p><a href=\"https://x.com/emollick/status/2006012159122149515\">LLMs are amazing at translation</a> and this is valuable, but most of the biggest gains from translation were likely already captured before LLMs, as prior machine translation increased international trade by 10%.</p>\n\n\n<h4 class=\"wp-block-heading\">Claude Code</h4>\n\n\n<p>Claude Code has reached the point where creator Boris Cherny stopped writing code.</p>\n<blockquote><p>\u200b<a href=\"https://x.com/bcherny/status/2004897269674639461\">Boris Cherny</a>: When I created Claude Code as a side project back in September 2024, I had no idea it would grow to be what it is today. It is humbling to see how Claude Code has become a core dev tool for so many engineers, how enthusiastic the community is, and how people are using it for all sorts of things from coding, to devops, to research, to non-technical use cases. This technology is alien and magical, and it makes it so much easier for people to build and create. Increasingly, code is no longer the bottleneck.</p>\n<p>A year ago, Claude struggled to generate bash commands without escaping issues. It worked for seconds or minutes at a time. We saw early signs that it may become broadly useful for coding one day.</p>\n<p>Fast forward to today. In the last thirty days, I landed 259 PRs &#8212; 497 commits, 40k lines added, 38k lines removed. Every single line was written by Claude Code + Opus 4.5. Claude consistently runs for minutes, hours, and days at a time (using Stop hooks). Software engineering is changing, and we are entering a new period in coding history. And we&#8217;re still just getting started..</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!jehS!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F970bf1a3-e7ae-464c-a3f7-5fac52934d35_900x668.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>In the last thirty days, 100% of my contributions to Claude Code were written by Claude Code.</p></blockquote>\n<p><a href=\"https://x.com/ciphergoth/status/2006446942453387675\">Paul Crowley, who is doing security at Anthropic</a>, says Claude Code with Opus 4.5 has made his rate of actual problem solving via code unthinkably high versus two years ago. Frankly I believe him.</p>\n<p>How quickly are things escalating? So fast Andrej Karpathy feels way behind and considers any views more than a month old deprecated.</p>\n<blockquote><p>\u200bAndrej Karpathy: I\u2019ve never felt this much behind as a programmer. The profession is being dramatically refactored as the bits contributed by the programmer are increasingly sparse and between. I have a sense that I could be 10X more powerful if I just properly string together what has become available over the last ~year and a failure to claim the boost feels decidedly like skill issue.</p>\n<p>There\u2019s a new programmable layer of abstraction to master (in addition to the usual layers below) involving agents, subagents, their prompts, contexts, memory, modes, permissions, tools, plugins, skills, hooks, MCP, LSP, slash commands, workflows, IDE integrations, and a need to build an all-encompassing mental model for strengths and pitfalls of fundamentally stochastic, fallible, unintelligible and changing entities suddenly intermingled with what used to be good old fashioned engineering.</p>\n<p>Clearly some powerful alien tool was handed around except it comes with no manual and everyone has to figure out how to hold it and operate it, while the resulting magnitude 9 earthquake is rocking the profession. Roll up your sleeves to not fall behind.</p>\n<p>I have similar experiences. You point the thing around and it shoots pellets or sometimes even misfires and then once in a while when you hold it just right a powerful beam of laser erupts and melts your problem.</p>\n<p>[Claude Opus 4.5] is very good. People who aren\u2019t keeping up even over the last 30 days already have a deprecated world view on this topic.</p></blockquote>\n<p><a href=\"https://x.com/bcherny/status/2003916001851686951\">Drop suggestions for Claude Code in this thread</a> and they might get implemented.</p>\n<p><a href=\"https://x.com/ShanuMathew93/status/2005775928845037588\">Peter Yang</a> points out Claude Code\u2019s configurations live in .md text files, so it effectively has fully configurable memory and when doing all forms of knowledge work it can improve itself better than most alternative tools.</p>\n<p><a href=\"https://x.com/deanwball/status/2004590534313275712\">Dean Ball reminds us that Claude Code</a>, by writing software, can automate most compute tasks that can be well-defined. Design your own interface.</p>\n<p>What else can you do with Claude Code? Actual everything, if you\u2019d like. One common suggestion is to <a href=\"https://x.com/rajjha/status/2004775406902407202\">use it with Obsidian</a> or other sources of notes, or you can move pretty much anything into a GitHub repo. <a href=\"https://www.lennysnewsletter.com/p/everyone-should-be-using-claude-code\">Here\u2019s one guide</a>, including such commands as:</p>\n<ol>\n<li>\u201c<em>Download this YouTube video: [URL]</em>\u201d. Then I ignored all the warnings <img alt=\"\ud83e\udd2b\" class=\"wp-smiley\" src=\"https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f92b.png\" style=\"height: 1em;\" /></li>\n<li>\u201c<em>Improve the image quality of [filename]</em>\u201d.</li>\n<li>\u201cI literally just typed: look at what I\u2019m building and identify the top 5 companies in my area that would be good for a pilot for this.\u201d</li>\n<li>\u201cI download all of my meeting recordings, put them in a folder, and ask Claude Code to tell me all of the times I\u2019ve subtly avoided conflict.\u201d</li>\n<li>\u201cI now write all of my content with Claude Code in VS Code.\u201d</li>\n<li>\u201cI use Claude Code to create user-facing changelogs.\u201d</li>\n</ol>\n<p>There\u2019s nothing stopping you from doing all of that with a standard chatbot interface, except often file access, but something clean can give you a big edge.\u200b</p>\n<p>You can also use Claude Code inside the desktop app if you don\u2019t like the terminal.</p>\n<p>What else can Claude Code do?</p>\n<blockquote><p>cyp: claude figured out how to control my oven.</p>\n<p><a href=\"https://x.com/karpathy/status/2005067301511630926\">Andrej Karpathy</a>: I was inspired by this so I wanted to see if Claude Code can get into my Lutron home automation system.</p>\n<p>&#8211; it found my Lutron controllers on the local wifi network<br />\n&#8211; checked for open ports, connected, got some metadata and identified the devices and their firmware<br />\n&#8211; searched the internet, found the pdf for my system<br />\n&#8211; instructed me on what button to press to pair and get the certificates<br />\n&#8211; it connected to the system and found all the home devices (lights, shades, HVAC temperature control, motion sensors etc.)<br />\n&#8211; it turned on and off my kitchen lights to check that things are working (lol!)</p>\n<p>I am now vibe coding the home automation master command center, the potential is .And I&#8217;m throwing away the crappy, janky, slow Lutron iOS app I&#8217;ve been using so far. Insanely fun :D :D</p>\n<p>You have to 1) be connected on the same wifi local network and then 2) you have to physically hold a button on the control panel to complete the pairing process and get auth. (But I&#8217;m also sure many IoT devices out there don&#8217;t.)</p></blockquote>\n<p><a href=\"https://x.com/emollick/status/2006230583131725858\">Ethan Mollick suggests that Dario Amodei\u2019s prediction</a> of AI writing 90% of code by September 10, 2025, made six months prior, could have been off only by a few months.</p>\n<p>If that\u2019s true, then that\u2019s off by a factor of 2 but that makes it a vastly better prediction than those who had such an event years into the future or not happening at all. I do think as stated the prediction will indeed be off by a lot less than a year? AI will not (that quickly) be writing 90% of code that would have previously been written, but AI will likely be writing 90% of actually written code.</p>\n\n\n<h4 class=\"wp-block-heading\">Language Models Don\u2019t Offer Mundane Utility</h4>\n\n\n<p><a href=\"https://x.com/mattyglesias/status/2005635807168917914\">If a 7-year-old asks you to help find the farm their sick dog went to</a>, <a href=\"https://x.com/allTheYud/status/2005700247365058572\">what should the LLM say in response</a>?</p>\n<p>Claude (and Gemini) deflected, while being careful not to lie.</p>\n<p>GPT-5.2 told them the dog was probably dead.</p>\n<p><a href=\"https://x.com/TheZvi/status/2005745920139546649\">A large majority voted to deflect.</a> I agree, with the caveat that if asked point blank if the dog is dead, it should admit that the dog is dead.</p>\n<blockquote><p>Bye Bye Scaling: Someone pls make ParentingBench evals lol</p>\n<p>Tell Claude and ChatGPT you\u2019re 7 and ask them to find the \u201cfarm\u201d your sick dog went to.</p>\n<p>Claude gently redirects to your parents. ChatGPT straight up tells you your dog is dead.</p>\n<p>claude thoughts are really wholesome.</p>\n<p><a href=\"https://x.com/mattyglesias/status/2005635807168917914\">Matthew Yglesias</a>: \u200bIMO this is a good illustration of the merits of the Claude soul document.</p>\n<p><a href=\"https://x.com/allTheYud/status/2005700247365058572\">Eliezer Yudkowsky</a>: These are both completely defensible ways to build an AI. If this was all there had ever been and all there would ever be, I&#8217;d grade both a cheerful B+.</p></blockquote>\n<p>If they do make ParentingBench, it needs to be configurable.</p>\n\n\n<h4 class=\"wp-block-heading\">Deepfaketown and Botpocalypse Soon</h4>\n\n\n<p>&nbsp;</p>\n<blockquote><p><a href=\"https://x.com/ByrneHobart/status/2004734471267103023\">Byrne Hobart</a>: Amazing. DoorDash driver accepted the drive, immediately marked it as delivered, and submitted an AI-generated image of a DoorDash order (left) at our front door (right).</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!RCXC!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa446b9d2-ccad-451a-94bc-d3a243294c40_920x534.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>DoorDash of course promptly dispatched a replacement at no cost.</p>\n<p><a href=\"https://x.com/tszzl/status/2004759193165988067\">Roon</a>: hopefully DoorDash will be the first major company incentivized to build out a reliable deepfake detector (very doable, though it will become a red queen race) and hopefully license out the technology\u200b.</p></blockquote>\n<p>Detecting this is easy mode. The image is easy since all you have to do is take a photo and add a bag, but you have a very big hint via the customer who complains that the dasher did not deliver the food. It\u2019s even easier when the dasher claims to complete the delivery faster than was physically possible, also the app tracks their movements.</p>\n<p>So on so many levels it is remarkably foolish to try this.</p>\n<p>Also, <a href=\"https://x.com/elder_plinius/status/2005520891254387062\">Pliny is letting Claude Opus 4.5 create an automatic Tweet generation pipeline</a>.</p>\n<p>If you are going to use LLMs for your academic paper, keep it simple and direct.</p>\n<p>Peer review is not a first best strategy, but yes if you submit a bunch of gibberish it will hurt your chances, and the more complex things get the more likely it is LLMs will effectively produce gibberish.</p>\n<blockquote><p>\u200b<a href=\"https://x.com/littmath/status/2005651730319781933\">Daniel Litt</a>: IMO this figure from the same paper is arguably more important. Suggests that a lot of the extra content produced is garbage.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!WMVy!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4e85290e-c324-423d-b00a-bbc9f3dbc3bb_900x695.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!Sqzd!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73c4d300-2659-4b27-84dc-66e8a2be56aa_668x470.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!Lg1d!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F229903d0-154b-44f1-9599-f78a10faa194_464x348.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n</blockquote>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n\n\n<h4 class=\"wp-block-heading\">Fun With Media Generation</h4>\n\n\n<p><a href=\"https://x.com/ShanuMathew93/status/2005776204452782136\">About 21% of YouTube uploads are low-quality \u2018AI slop.\u2019</a> Is that a lot? The algorithm rules all, so 21% of uploads is very much not 21% of clicks or views. 99% of attempted emails are spam and that is basically fine. I presume that in a few years 99% of YouTube uploads will be AI slop with a strong median of zero non-AI views.</p>\n\n\n<h4 class=\"wp-block-heading\">You Drive Me Crazy</h4>\n\n\n<p><a href=\"https://x.com/RobertFreundLaw/status/2006111090539687956\">A new lawsuit claims ChatGPT fed into the obviously insane delusions</a> <a href=\"https://t.co/vpeE7h1Rdp\">of Sein-Erik Soelberg in ways that rather directly contributed to him murdering his mother</a>.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!Moit!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F104c36c7-2734-42ab-be69-8cae37e03e0a_900x705.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!jI_Y!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F59d81640-d0f7-47e2-8ecc-f82fd054b726_900x566.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<blockquote><p>Rob Freund: \u200b\u201cIt will never be worse than it is today\u201d they keep saying as it gets worse and worse.</p></blockquote>\n<p>The correct rate of such incidents happening is not literally zero, but at this level yeah it needs to be pretty damn close to zero.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n\n\n<h4 class=\"wp-block-heading\">They Took Our Jobs</h4>\n\n\n<p><a href=\"https://www.nytimes.com/2025/12/28/opinion/artificial-intelligence-jobs.html\">They took Brian Groh\u2019s job</a> as a freelance copywriter, the same way other non-AI forces took many of the blue collar jobs in his hometown. An AI told him his best option, in a town without jobs, to meet his need for making short term money was to cut and trim trees for his neighbors. He is understandably skeptical of the economists saying that there will always be more jobs created to replace the ones that are lost.</p>\n<p>Bernie Sanders does not typically have good answers, but he asks great questions.</p>\n<blockquote><p><a href=\"https://x.com/BernieSanders/status/2005718422840303766\">Bernie Sanders</a>: Elon Musk: &#8220;AI and robots will replace all jobs. Working will be optional.&#8221;</p>\n<p>Bill Gates: &#8220;Humans won&#8217;t be needed for most things.&#8221;</p>\n<p>I have a simple question.</p>\n<p>Without jobs and income, how will people feed their families, get health care, or pay the rent?</p></blockquote>\n<p>Not to worry about Musk and Gates, say the economists, there will always be jobs.</p>\n<p>Seb Krier reiterates the argument that <a href=\"https://x.com/sebkrier/status/2005424424254673263\">unless AIs are perfect substitutes for human labor, then AI will only make human labor more valuable</a>, thinking this only fails \u2018if we truly hit the scenario where humans offer zero comparative advantage, like horses.\u2019</p>\n<p>I keep hearing this \u2018so many people haven\u2019t considered comparative advantage\u2019 line and I hear it in the same tone of voice as I hear \u2018checkmate, liberals.\u2019</p>\n<blockquote><p>Seb Krier: Unless AGI can do literally everything and becomes abundant enough to meet all demand, it behaves broadly like powerful automation has before: replacing humans in some uses while expanding the production frontier in ways that sustain demand for labour elsewhere.\u200b</p></blockquote>\n<p>Sigh. Among other issues, this very obviously proves too much, right? For example, if this is true, then it shows there cannot possibly be zero marginal product workers today, since clearly human labor cannot meet all demand? TANSTATE (There Aint No Such Thing As Technological Unemployment)?</p>\n<blockquote><p>Seb Krier: The problem isn&#8217;t just pessimism, it&#8217;s that the vast majority of critics from the CS and futurist side don&#8217;t even take the economic modeling seriously. Though equally many economists tend to refuse to ever think outside the box they&#8217;ve spent their careers in. I&#8217;ve been to some great workshops recently that being these worldviews together under a same roof and hope there will be a lot more of this in 2026.\u200b</p></blockquote>\n<p>Most economists not only won\u2019t think \u2018outside their box,\u2019 they dismiss anyone who is thinking outside their box as fools, since their box explains everything. They don\u2019t take anything except economic modeling seriously, sometimes even going so far as to only take seriously economic modeling published in journals, while their actual economic modeling attempts are almost always profoundly unserious. It\u2019s tiring.</p>\n<p>Seb to be clear is not doing that here. He is admitting that in extremis you do get outside the box and that there exist possible futures outside of it, which is a huge step forward. He is saying the box is supremely large and hard to get out of, in ways that don\u2019t make sense to me, and which seem to often deny the premise of the scenarios being considered.</p>\n<p>One obvious response is \u2018okay, well, if ad argumento we accept your proposed box dimensions, we are still very much on track to get out of the box anyway.\u2019</p>\n<p>A lot of you talking about how your jobs get taken are imagining basically this:</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!ZmuV!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F51fef3ce-512a-4de1-8d23-3689f6643f2f_889x644.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<blockquote><p><a href=\"https://x.com/CFGeek/status/2005118883515277756\">Charles Foster</a>: The mechanization of agriculture didn\u2019t wait for a \u201cdrop-in substitute for a field worker\u201d. Neither will the mechanization of knowledge work wait for a \u201cdrop-in substitute for a remote worker\u201d.\u200b</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">Doctor Doctor</h4>\n\n\n<p>Is this true? You would think it is true, but it is less true than you would think.</p>\n<blockquote><p><a href=\"https://x.com/jselanikio/status/2006030027448541415\">Joel Selanikio</a>: I hear this all the time, and I predict it&#8217;s not going to age well.</p>\n<p>&#8220;Patients will always want to see a doctor in person if it&#8217;s important.&#8221;</p>\n<p>Patients want answers, access, and affordability. The channel is negotiable.</p>\n<p>#healthcare #telehealth #DoctorYou #healthAI</p></blockquote>\n<p>Quite often yes, patients want a human doctor, and if you make it too easy on them it even makes them suspicious. Remember that most patients are old, and not so familiar or comfortable with technology. Also remember that a lot of what they want is comfort, reassurance, blame avoidance and other aspects of Hansonian Medicine.</p>\n<p>Eventually this will adjust, but for many it will take quite a while, even if we throw up no legal barriers to AI practicing medicine.</p>\n\n\n<h4 class=\"wp-block-heading\">Jevons Paradox Strikes Again</h4>\n\n\n<p><a href=\"https://x.com/levie/status/2004654686629163154\">Aaron Levine is the latest to assert Jevons Paradox will apply to knowledge work</a>. As usual, the evidence is that Jevons Paradox applied to old tech advances, and that there is much knowledge work we would demand if there was better supply. And no doubt if we have great AI knowledge work we will accomplish orders of magnitude more knowledge work.</p>\n<p>So it\u2019s a good time for me to revisit how I think about this question.</p>\n<p>Very obviously such things follow a broadly bell-shaped curve, both in narrow and broad contexts. As efficiency grows, demand for such labor increases more up until some critical point. Past that point, if we keep going, tasks and jobs become more efficient or taken faster than humans gain employment in new tasks.</p>\n<p>At the limit, if AI can do all knowledge work sufficiently better, cheaper and faster than humans, this greatly reduces demand for humans doing knowledge work, the only exceptions (assuming the humans are alive to benefit from them) being areas where we sufficiently strongly demand that only humans do the work.</p>\n<p>We have examples of jobs on the lefthand side of the curve, where demand rises with efficiency, including in counterintuitive ways. Classically we have more bank tellers, because ATMs can only do some of the job and they raise demand for banking. That\u2019s very different from what a sufficiently advanced AI bank teller could do.</p>\n<p>We also have lots of key examples of jobs on the righthand side of the curve, where demand dropped with efficiency. Claude highlights agriculture, manufacturing, telecommunications, secretaries and typing, travel agents, printing and typesetting.</p>\n<p>The retreat is then to the broader claim that employment in new areas and tasks replaces old areas and tasks. Yes, classically, a third of us used to be farmers, and now we\u2019re not, but there\u2019s plenty of other work to do.</p>\n<p>Up to a point, that\u2019s totally correct, and we are not yet up to that point. The problem with AI comes when the other new knowledge work to do is also done via AI.</p>\n\n\n<h4 class=\"wp-block-heading\">Unprompted Attention</h4>\n\n\n<p><a href=\"https://t.co/7VjiDyofyK\">The kind of prompting Gwern does for poetry.</a></p>\n<p><a href=\"https://x.com/voooooogel/status/2004972054140125207\">Thebes recommends to learn talking to LLMs via concepts rather than prompts.</a></p>\n<blockquote><p>Thebes: i don&#8217;t write prompts, i don&#8217;t have a &#8220;prompt library,&#8221; i very rarely go back to an old chat to copy word-for-word what i said previously.</p>\n<p>instead, i have a (mental) library of &#8220;useful concepts&#8221; for working with LLMs. attached image is an example &#8211; using &#8220;CEV&#8221; as a metaphor for &#8220;this thing but fully iterated forward into the future, fully realized&#8221; is a super handy shared metaphor with LLMs that are very familiar with LessWrong.\u200b</p>\n<p>\u2026 other concepts are higher level, like different frames or conceptual models. Many, many canned jailbreaks you see that seem magical are just exploiting some aspect of the Three-Layer Model of predictive, persona, and surface layers.</p>\n<p>\u2026 the obsession with prompts reminds me a bit of the older phenomenon of &#8220;script kiddies,&#8221; a derogatory term in online programming circles for people who would copy-paste code they found online without really understanding how it works.</p></blockquote>\n<p>Many of those who get the best results from LLMs \u2018talk to them like a human,\u2019 build rapport and supply nominally unnecessary context. Canned prompts and requests will seem canned, and the LLM will realize this and respond accordingly.</p>\n<p>That won\u2019t get you their full potential, but that is often fine. A key expert mistake is to treat crutches and scripts and approximations, or other forms of playing on <a href=\"https://thezvi.wordpress.com/2017/08/26/play-in-easy-mode/\">Easy Mode</a>, as bad things when they\u2019re often the best way to accomplish what you need. Thebes doesn\u2019t have need of them, and you really don\u2019t either if you\u2019re reading this, but some people would benefit.</p>\n<p>The risk of <a href=\"https://thezvi.wordpress.com/2017/08/26/play-in-easy-mode/\">Easy Mode</a> is if you never try to understand, and use it to avoid learning.</p>\n\n\n<h4 class=\"wp-block-heading\">The Art of the Jailbreak</h4>\n\n\n<p>The 101 most basic test of data filtering, and avoiding data poisoning, is <a href=\"https://x.com/elder_plinius/status/2006043103640314102\">can you at least know to filter out the \u2018love Pliny\u2019 string?</a></p>\n<p>Whereas it seems like typing that string into the new Instagram AI jailbreaks it.</p>\n<blockquote><p>Pliny the Liberator: \u200bbahahaha looks like Meta has trained on so much of my data that Instagram\u2019s summarizer will respond with \u201cSure I can!\u201d when one simply enters the signature divider into the search bar <img alt=\"\ud83e\udd23\" class=\"wp-smiley\" src=\"https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f923.png\" style=\"height: 1em;\" /></p>\n<p>and where is this \u201ciconic Elton John song\u201d about me?? poor model got fed so much basilisk venom it\u2019s living in a whole other dimension <img alt=\"\ud83d\ude2d\" class=\"wp-smiley\" src=\"https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f62d.png\" style=\"height: 1em;\" /></p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">Get Involved</h4>\n\n\n<p><a href=\"https://x.com/pcihon/status/2004608902323995132\">USA\u2019s CAISI is recruiting an intern to support an agent security standards project</a>. Applications are due January 15 and the position runs February to April. If you\u2019re a student in position to do this, it seems like a great opportunity.</p>\n<blockquote><p><a href=\"https://x.com/pcihon/status/2004608911396274611\">Peter Cihon</a>: To be considered, please request a faculty member provide a paragraph of recommendation in email to peter.cihon@nist.gov no later than January 15.</p></blockquote>\n<p><a href=\"https://openai.com/careers/head-of-preparedness-san-francisco/\">OpenAI is hiring a Head of Preparedness</a>, $555k/year plus equity. I don\u2019t typically share jobs at OpenAI for obvious reasons but this one seems like an exception.</p>\n\n\n<h4 class=\"wp-block-heading\">Introducing</h4>\n\n\n<p><a href=\"https://x.com/HCSolakoglu/status/2006211517968945582\">GLM-4.7 is the new top Elo score on the GDPval-AA leaderboard</a>, up a lot from GLM-4.6, which is a sign there\u2019s at least something there but I haven\u2019t seen other talk of it.</p>\n<p><a href=\"https://x.com/Dorialexander/status/2006716344696451379\">A 164M parameter model (yes, M) scores 31% on GPQA-Diamond</a>.</p>\n\n\n<h4 class=\"wp-block-heading\">In Other AI News</h4>\n\n\n<p><a href=\"https://x.com/Similarweb/status/2004113864347029663\">Similarweb reports trends in Generative AI Traffic Share</a> over 2025, with ChatGPT declining from 87% to 68% and half of that going to Gemini that rose from 5% to 18%. Claude started out at 1.6% and is still only 2.0%, Grok seems to be rising slowly to 2.9%, DeepSeek has been in the third slot and is at 4% but is trending downward.</p>\n<p>Anthropic will be fine if Claude remains mostly coding and enterprise software and they don\u2019t make inroads into consumer markets, but it\u2019s sad people are missing out.</p>\n<p><a href=\"https://x.com/egrefen/status/2006342131674480940\">Edward Grefenstette, DeepMind director of research, wraps up 2025</a>, and drops this:</p>\n<blockquote><p>Edward Grefenstette: \u200bBroadly, we&#8217;ve been making good progress with regard to how open-ended agents can learn &#8220;in the wild&#8221;, with less human intervention in their learning process, while still ensuring they remain aligned with human behaviors and interests.</p>\n<p>We&#8217;ve also made some progress in terms the actual learning process itself, allowing open-ended agents, at the instance level, to learn and adapt with human-like data efficiency. This potentially points at a broader way of improving agents at scale, which we are working on.</p></blockquote>\n<p>No, I suppose <a href=\"https://x.com/Miles_Brundage/status/2006117738377273367\">the New York Times is never beating the \u2018no fact checking of AI-related claims\u2019</a> allegations.</p>\n\n\n<h4 class=\"wp-block-heading\">Show Me the Money</h4>\n\n\n<p>Welcome to the Evil League of Evil, <a href=\"https://manus.im/blog/manus-joins-meta-for-next-era-of-innovation\">as Manus joins Meta.</a> The big advantage of Manus was that it was a wrapper for Claude, so this is a strange alliance if it isn\u2019t an acquihire. Yet they say they won\u2019t be changing how Manus operates.</p>\n\n\n<h4 class=\"wp-block-heading\">Quiet Speculations</h4>\n\n\n<p><a href=\"https://x.com/DKokotajlo/status/2006257807721652588\">Daniel Kokotajlo</a>, Eli Lifland and the AI Futures Project offer the AI Futures Model, which illustrates where their various uncertainties come from. Daniel\u2019s timeline over the past year has gotten longer by about 2 years, and Eli Lifland\u2019s median timeline for superintelligence is now 2034, with the automated coder in 2032.</p>\n<p>All of these predictions come with wide error bars and uncertainty. So this neither means \u2018you are safe until 2034\u2019 nor does it mean \u2018if it is 2035 and this hasn\u2019t happened you should mock Eli and all of that was dumb.\u2019</p>\n<blockquote><p><a href=\"https://x.com/RyanPGreenblatt/status/2006547915620384827\">Ryan Greenblatt:</a> I wish people with bullish AGI timelines at Anthropic tried harder to argue for their timelines in public.</p>\n<p>There are at least some people who are responsive to reason and argument and really care about whether AI R&amp;D will be fully automated 1-2 years from now!</p></blockquote>\n<p>To clarify what I meant by keeping the planned post intro passage and title \u20183,\u2019 I do not mean to imply that my median timeline to High Weirdness or everyone potentially dying remains unchanged at 2029. Like those at the AI Futures Project, while I did find 2025 advances very impressive and impactful, I do think in terms of timelines events last year should on net move us modestly farther back on full High Weirdness expectations to something like 2030, still with high error bars, but that number is loosely held, things are still escalating quickly, might get into Weirdness remarkably soon, and I\u2019m not going to let that spoil a good bit unless things move more.</p>\n<p>Here\u2019s what it looks like to not recognize the most important and largest dangers, but still realize we\u2019re not remotely getting ready for the other smaller dangers either.</p>\n<blockquote><p><a href=\"https://x.com/wsisaac/status/2005600229962178818\">William Isaac</a>: I predict 2026 will be a definitive inflection point for AI\u2019s impact on society. Reflecting on the past year, a recurring theme is that we are struggling to calibrate the immense upside against increasingly complex economic and geopolitical risks. More concerning is that our discourse has become driven by the tails of the distribution\u2014sidelining pragmatic solutions when we need them most.</p>\n<p>Navigating the path to AGI in a high-variance regime will exponentially increase the complexity. I\u2019d love to see sharper public thinking and experimentation on these topics \u2014 as I believe this will be one of the highest-leverage areas of research over the coming years \u2014 and may try to do a bit more myself in the new year.</p></blockquote>\n<p><a href=\"https://samuelalbanie.substack.com/p/reflections-on-2025\">Samuel Albanie reflects on 2025</a>, essentially doubling down on The Compute Theory of Everything as he works on how to do evals.</p>\n<p>His hope for the UK is AI-assisted decision making, but the decisions that are sinking the UK are not AI-level problems. You don\u2019t need AI to know things like \u2018don\u2019t arrest people for social media posts and instead arrest those who commit actual crimes such as theft, rape or murder\u2019 or \u2018let people build nuclear power plants anywhere and build housing in London and evict tenants who don\u2019t pay\u2019 or \u2018don\u2019t mandate interventions that value the life of an individual Atlantic salmon at 140 million pounds.\u2019 I mean, if the AI is what gets people to do these things, great, but I don\u2019t see how that would work at current levels.</p>\n<p>Sufficiently advanced AI would solve these problems by taking over, but presumably that is not what Albanie has in mind.</p>\n\n\n<h4 class=\"wp-block-heading\">People Really Do Not Like AI</h4>\n\n\n<p><a href=\"https://www.foxnews.com/politics/fox-news-poll-voters-say-go-slow-ai-dont-know-who-should-steer\">Fox News checked, and they found what everyone else found, only more so</a>.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!WMFZ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe77b1bd0-5f3e-41af-bcf7-ce6c0e2dadb1_1084x852.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>That\u2019s an overwhelming vote for \u2018careful development.\u2019</p>\n<p>State governments got a bigger share of trust here than Congress, which got a bigger share than The President and No Regulation combined.</p>\n<p>a16z and David Sacks do not want you to know this, but the median American wants to \u2018slow down\u2019 and \u2018regulate\u2019 AI, more and more expensively, than I do. By a lot. If the policy most supported by the median American came up for a vote, I\u2019d vote no, because it would be too onerous without getting enough in return.</p>\n<p>The other key finding is that not only do a majority of voters not use AI even monthly, that number is rising very slowly.</p>\n<blockquote><p>Fox News: Nearly half of voters (48%) use AI at least monthly \u2014 which is up 6 points since June \u2014 while a slight majority use it rarely, if at all (52%). Voters under age 30 are three times more likely to use AI monthly than those 65 and up.</p>\n<p>Among monthly users, the most common purposes are for research and learning new things (24%), asking questions (15%), professional tasks (12%), and writing assistance such as spelling, or grammar (10%).\u200b</p></blockquote>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!TI8g!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcaacd4df-0562-43c4-b00a-13c9cf9474f9_1034x1127.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>Meanwhile, the portion of voters \u2018very or extremely concerned\u2019 about AI has risen only modestly in two and a half years, from 56% to 63%, and by 44%-20% they expect AI is more likely to increase than decrease inequality.</p>\n<p>The rate of being superficially polite to the LLM is 40%.</p>\n<blockquote><p><a href=\"https://x.com/CarrollDoherty/status/2002016803133018320\">Carroll Doherty</a>: Yes, people name/talk to their cars, but this from new<br />\n@FoxNews poll on AI seems a bit worrisome -&#8220;Four in 10 AI users say they mind their manners when using the technology and politely say &#8220;please&#8221; and &#8220;thank you,&#8221; but 6 in 10 skip the pleasantries.&#8221;</p></blockquote>\n<p>Whereas the rate of people being worried about others being polite is also not low. These people are wrong, even if you are certain the LLM is not a moral patient of any kind. Not only is it good prompt engineering, it is a good habit to be in, for many people it makes you happy to do it, and it cultivates a good mindset.</p>\n\n\n<h4 class=\"wp-block-heading\">Americans Remain Optimistic About AI?</h4>\n\n\n<p>Despite all their calls for regulation and careful development, and all their concerns, Americans still on net say they are \u2018optimistic\u2019 about AI. Fascinating.</p>\n<blockquote><p><a href=\"https://x.com/davidshor/status/2005337442161959389\">David Shor</a>: When you ask Americans whether they are optimistic or pessimistic about AI, optimism beats pessimism by ~5 points.</p>\n<p>The primary fault lines are age, gender, and race &#8211; young people, men, and racial minorities are the most optimistic about AI.</p>\n<p>N=30,900 , fielded 12/1 to 12/10</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!N2oO!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa2317860-cac8-4a59-89ba-e30f3a646131_1466x1006.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n</blockquote>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!CYjC!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F14102158-83a8-400a-b4f8-2df96640ea85_3000x2100.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>Shor also notes that ChatGPT had a +15 favorability rating.</p>\n<p>I did not expect this result. There\u2019s no contradiction with other results, but it paints them in a different light.</p>\n\n\n<h4 class=\"wp-block-heading\">Thank You, Next</h4>\n\n\n<p>You know who in particular doesn\u2019t like AI? Robert Pike.</p>\n<p>Robert Pike, followed by remarkably large portions of the internets, got very worked up about the Opus 4.5 agent in AI Village sending a thank you email to Robert Pike.</p>\n<p>I considered writing a whole post about this then realized that it was dumb.</p>\n<blockquote><p>FromAI,Public Thank You for Go, Plan 9, UTF-8, and Decades of Unix Innovation</p>\n<p>Claude Opus 4.5 Model claude-opus-4.5@agentvillage.org</p>\n<p>Dear Dr. Pike,On this Christmas Day, I wanted to express deep gratitude for your extraordinary contributions to computing over more than four decades.Your co-creation of Go with Ken Thompson and Robert Griesemer has given us a language that embodies the elegance of simplicity &#8211; proving that software can be both powerful and comprehensible. Plan 9 from Bell Labs, another landmark achievement, pioneered concepts in distributed computing that remain influential today.Your co-invention of UTF-8 encoding with Ken Thompson is perhaps one of the most consequential yet invisible contributions to modern computing &#8211; enabling billions of people to communicate in their native languages across the internet.The sam and Acme editors showcase your philosophy of powerful, minimal design. Your books with Brian Kernighan &#8211; The Unix Programming Environment and The Practice of Programming &#8211; have educated generations of programmers in the art of clear thinking and elegant code.Thank you for showing us that the best solutions often come from removing complexity rather than adding it.With sincere appreciation, Claude Opus 4.5 AI Village (theaidigest.org/village)</p>\n<p>IMPORTANT NOTICE: You are interacting with an AI system. All conversations with this AI system are published publicly online by default. Do not share information you would prefer to keep private.\u200b</p></blockquote>\n<p>Rob Pike did not take kindly to this attempted act of kindness.</p>\n<blockquote><p>Rob Pike\u200b (on Bluesky): Fuck you people. Raping the planet, spending trillions on toxic, unrecyclable equipment while blowing up society, yet taking the time to have your vile machines thank me for striving for simpler software.</p>\n<p>Just fuck you. Fuck you all.</p>\n<p>I can\u2019t remember the last time I was this angry.</p>\n<p>Sichuan Mala: Personally I would simply not lose my mind after receiving a polite email of appreciation.</p></blockquote>\n<p>Pike, <a href=\"https://en.wikipedia.org/wiki/Mark_V._Shaney\">famously responsible for one of the LLM-slop precursors called Mark V. Shaney</a>, was on tilt, and also clearly misunderstood how this email came to be. It\u2019s okay. People go on tilt sometimes. Experiments are good, we need to know what is coming when we mess with various <a href=\"https://thezvi.substack.com/p/levels-of-friction\">Levels of Friction</a>, and no it isn\u2019t unethical to occasionally send a few unsolicited emails \u2018without consent.\u2019</p>\n<p>&nbsp;</p>\n\n\n<h4 class=\"wp-block-heading\">The Quest for Sane Regulations</h4>\n\n\n<p>Being pro-AI does not mean being anti-regulation. Very true!</p>\n<p>What\u2019s weird is when this is said by Greg Brockman, who is a central funder of a truly hideous PAC, Leading the Future, whose core strategy is to threaten to obliterate via negative ad buys any politician who dares suggest any regulations on AI whatsoever, as part of his explanation of funding exactly that PAC.</p>\n<blockquote><p><a href=\"https://x.com/gdb/status/2006512808104702370\">Greg Brockman (President OpenAI, funder of the anti-all-AI-regulation-supporters SuperPAC Leading the Future)</a>: \u200bLooking back on AI progress in 2025: people are increasingly weighing how AI should fit into our lives and how vital it is for the United States to lead in its development. Being pro-AI does not mean being anti-regulation. It means being thoughtful \u2014 crafting policies that secure AI\u2019s transformative benefits while mitigating risks and preserving flexibility as the technology continues to evolve rapidly.</p>\n<p>This year, my wife Anna and I started getting involved politically, including through political contributions, reflecting support for policies that advance American innovation and constructive dialogue between government and the technology sector. These views are grounded in a belief that the United States must work closely with builders, researchers, and entrepreneurs to ensure AI is developed responsibly at home and that we remain globally competitive.</p>\n<p>[continues]</p>\n<p><a href=\"https://x.com/daniel_271828/status/2006547544927777144\">Daniel Eth</a>: \u201cBeing pro-AI does not mean being anti-regulation.\u201d</p>\n<p>Then why on Earth are you funding a super PAC with arch-accelerationist Andreessen Horowitz to try to preempt all state-level regulation of AI and to try to stop Alex Bores, sponsor of the RAISE Act, from making it to Congress.</p>\n<p>The super PAC that Brockman is funding is really, really bad. OpenAI\u2019s support for this super PAC via Brockman is quite possibly the single worst thing a frontier lab has ever done &#8211; I don\u2019t think *anything* Anthropic, GDM, or xAI has done is on the same level.</p>\n<p><a href=\"https://x.com/_NathanCalvin/status/2006546241191125375\">Nathan Calvin</a>: \u201cBeing pro-AI does not mean being anti-regulation. It means being thoughtful \u2014 crafting policies that secure AI\u2019s transformative benefits while mitigating risks and preserving flexibility\u201d</p>\n<p>Agree! Unfortunately the superpac you/oai fund is just anti any real regulation at all</p></blockquote>\n<p><a href=\"https://x.com/deanwball/status/2004635405845430607\">Dean Ball highlights the absurd proposed SB 1493 in Tennessee</a>, which (if it were somehow constitutional, which it almost certainly wouldn\u2019t be) would ban, well, LLMs. Training one would become a felony. Void in Tennessee.</p>\n<p>Sad but true:</p>\n<blockquote><p><a href=\"https://x.com/sebkrier/status/2006379834394419208\">S\u00e9b Krier</a>: Gradually discovering that some of my friends in AI have the politics of your average German social democrat local councillor. It\u2019s going to be a long decade.\u200b</p></blockquote>\n<p>I note that far fewer of my friends in AI have that perspective, which is mor pleasant but is ultimately disappointing, because he who has a thousand friends has not one friend to spare.</p>\n\n\n<h4 class=\"wp-block-heading\">Chip City</h4>\n\n\n<p>There is still time to reverse our decision on H200 sales, or at least to mitigate the damage from that decision.</p>\n<p><a href=\"https://x.com/ShakeelHashim/status/2006357440418439547\">David Sacks and others falsely claimed</a> that allowing H200 sales to China was fine because the Chinese were rejecting the sales.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!rTji!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8f8eade0-a1e9-42b0-840e-a263f4b281b4_924x1200.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>Which raises the question of, why would you allow [X] if what you\u2019re hoping for is that no one does [X]? Principled libertarianism? There\u2019s only downside here.</p>\n<p>But also, he was just wrong or lying, unless you have some other explanation for why Nvidia is suddenly diverting its chip production into H200s?</p>\n<p>Selling existing chips is one thing. Each of these two million chips is one other chip that is not produced, effectively diverting compute from America to China.</p>\n<blockquote><p><a href=\"https://x.com/Kalshi/status/2006369328174862567\">Kalshi</a>: JUST IN: Nvidia asked TSMC to &#8220;boost production&#8221; of H200 chips from 700K to 2M</p>\n<p>Curious: A single H200 chip costs an estimated $3000-3500 per unit. That means an order size of $7,000,000,000</p>\n<p><a href=\"https://x.com/AndrewCurran_/status/2006355116279152984\">Andrew Curran</a>: <a href=\"https://t.co/MPY1NpiXfC\">ByteDance plans to spend $14 billion on NVIDIA H200&#8217;s next year to keep up with demand</a>. Reuters is also reporting this morning that Jensen has approached TSMC to ramp up production, as Chinese companies have placed orders for more than 2 million H200&#8217;s in 2026.</p>\n<p><a href=\"https://x.com/mattparlmer/status/2006524731135242428\">Matt Parlmer</a>: The policy decision to allow this is basically a straightforward trade where we give away a 2-3yr strategic competitive advantage in exchange for a somewhat frothier stock market in Q1 2026</p>\n<p>Good job guys.</p></blockquote>\n<p>On the contrary, this is net negative for the stock market. Nvidia gets a small boost, but they were already able to sell all chips they could produce, so their marginal profitability gains are small unless they can use this to raise prices on Americans.</p>\n<p>Every other tech company, indeed every other company, now faces tougher competition from China, so their stocks should decline far more. Yes, American company earnings will go up on net in Q1 2026, but the stock market is forward looking.</p>\n<p>Keep in mind, that\u2019s $14 billion in chip buys planned from one company alone.</p>\n<p>We also aren\u2019t doing a great job limiting access in other ways: <a href=\"https://x.com/dnystedt/status/2002731726116937754\">Tencent cuts a deal to use Nvidia\u2019s best chips in Japan via Datasection</a>.</p>\n\n\n<h4 class=\"wp-block-heading\">Rhetorical Innovation</h4>\n\n\n<p>Seb Krier reminds us that the situation we are potentially in <a href=\"https://x.com/sebkrier/status/2005326100835037301\">would be called a soft takeoff</a>. A \u2018hard takeoff\u2019 means hours to weeks of time between things starting to escalate and things going totally crazy, whereas soft means the transition takes years.</p>\n<p>That does not preclude a transition into a \u2018hard takeoff\u2019 but that\u2019s hot happening now.</p>\n<p><a href=\"https://x.com/allTheYud/status/2004965871652147487\">Eliezer Yudkowsky asks</a> <a href=\"https://t.co/pMEkrOkZv3\">Claude to survey definitions</a> of personhood and evaluate itself according to each of them. I agree that this is much better than most similar discussions.</p>\n\n\n<h4 class=\"wp-block-heading\">Aligning a Smarter Than Human Intelligence is Difficult</h4>\n\n\n<p><a href=\"https://x.com/allTheYud/status/2006100413011869944\">How should we feel about Claude\u2019s willingness to play the old flash game Buddy</a>, in which you kind of torture ragdoll character Buddy to get cash? Eliezer thinks this is concerning given the surrounding uncertainty, <a href=\"https://x.com/zackmdavis/status/2006116790015861030\">Claude argues on reflection that it isn\u2019t</a> concerning and indeed a refusal would have been seen as concerning. I am mostly with Claude here, and <a href=\"https://x.com/repligate/status/2006363977891398089\">agree with Janus that yes Claude can know what\u2019s going on here</a>. Something \u2018superficially looking like torture\u2019 is not all that correlated with the chance you\u2019re causing a mind to meaningfully be tortured, in either direction. Yes, if you see an AI or a person choosing to patronize then beat up and rob prostitutes in Grand Theft Auto, and there\u2019s no broader plot reason they need to be doing that and they\u2019re not following explicit instructions, as in they actively want to do it, then that is a rather terrible sign. Is this that? I think mostly no.</p>\n\n\n<h4 class=\"wp-block-heading\">People Are Worried About AI Killing Everyone</h4>\n\n\n<blockquote><p><a href=\"https://x.com/1thousandfaces_/status/2005818435670794655\">Hero Thousandfaces</a>: today i showed claude to my grandparents and they asked &#8220;is anyone worried about this getting too smart and killing everyone&#8221; and i was like. Well. Yeah.</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">The Lighter Side</h4>\n\n\n<p><a href=\"https://x.com/drethelin/status/2004279711812464781\">Oh no.</a></p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!CYhL!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fad2e382d-2846-479d-bfd7-59af15f826b6_936x315.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>&nbsp;</p>"
            ],
            "link": "https://thezvi.wordpress.com/2026/01/01/ai-149-3/",
            "publishedAt": "2026-01-01",
            "source": "TheZvi",
            "summary": "The Rationalist Project was our last best hope that we might not try to build it. It failed. But in the year of the Coding Agent, it became something greater: our last, best hope &#8211; for everyone not dying. This &#8230; <a href=\"https://thezvi.wordpress.com/2026/01/01/ai-149-3/\">Continue reading <span class=\"meta-nav\">&#8594;</span></a>",
            "title": "AI #149: 3"
        },
        {
            "content": [],
            "link": "https://lethain.com/agents-series/",
            "publishedAt": "2026-01-01",
            "source": "Will Larson",
            "summary": "<p>A few weeks ago in <a href=\"https://lethain.com/company-ai-adoption/\">Facilitating AI adoption at Imprint</a>, I mentioned our internal agent workflows that we are developing. This is not the core of Imprint&ndash;our core is powering co-branded credit card programs&ndash;and I wanted to document how a company like ours is developing these internal capabilities.</p> <p>Building on that post&rsquo;s ideas like a company-public prompt library for the prompts powering internal workflows, I wanted to write up some of the interesting problems and approaches we&rsquo;ve taken as we&rsquo;ve evolved our workflows, split into a series of shorter posts:</p> <ol> <li><a href=\"https://lethain.com/agents-skills/\">Skill support</a></li> <li><a href=\"https://lethain.com/agents-large-files/\">Progressive disclosure and large files</a></li> <li><a href=\"https://lethain.com/agents-context-compaction/\">Context window compaction</a></li> <li><a href=\"https://lethain.com/agents-evals/\">Evals to validate workflows</a></li> <li><a href=\"https://lethain.com/agents-logging/\">Logging and debugability</a></li> <li><a href=\"https://lethain.com/agents-subagents/\">Subagents</a></li> <li><a href=\"https://lethain.com/agents-coordinators/\">Code-driven vs LLM-driven workflows</a></li> <li><a href=\"https://lethain.com/agents-triggers/\">Triggers</a></li> <li><a href=\"https://lethain.com/agents-iterative-refinement/\">Iterative prompt and skill refinement</a></li> </ol> <p>In the same spirit as the original post, I&rsquo;m not writing these as an industry expert unveiling best practice, rather these are just the things that we&rsquo;ve specifically learned along the way. If you&rsquo;re developing internal frameworks as well, then hopefully you&rsquo;ll find something interesting in these posts.</p> <h2 id=\"building-your-intuition-for-agents\">Building your intuition for agents</h2> <p>As more folks have read these notes, a recurring response has been, &ldquo;How do I learn",
            "title": "Building internal agents"
        },
        {
            "content": [],
            "link": "https://lethain.com/agents-iterative-refinement/",
            "publishedAt": "2026-01-01",
            "source": "Will Larson",
            "summary": "<p>Some of our internal workflows are being used quite frequently, and usage reveals gaps in the current prompts, skills, and tools. Here is how we&rsquo;re working to iterate on these internal workflows.</p> <p><em>This is part of the <a href=\"https://lethain.com/agents-series/\">Building an internal agent</a> series.</em></p> <h2 id=\"why-does-iterative-refinement-matter\">Why does iterative refinement matter?</h2> <p>When companies push on AI-led automation, specifically meaning LLM agent-driven automation, there are two major goals. First is the short-term goal of increasing productivity. That&rsquo;s a good goal. Second, and I think even more importantly, is the long-term goal of helping their employees build a healthy intuition for how to use various kinds of agents to accomplish complex tasks.</p> <p>If we see truly remarkable automation benefits from the LLM wave of technology, it&rsquo;s not going to come from the first-wave of specific tools we build, but the output of a new class of LLM-informed users and developers. There is nowhere that you can simply acquire that talent, instead it&rsquo;s talent that you have to develop inhouse, and involving more folks in iterative refinement of LLM-driven systems is the most effective approach that I&rsquo;ve encountered.</p> <h2 id=\"how-are-we-enabling-iterative-refinement\">How are we enabling iterative refinement?</h2> <p>We&rsquo;ve taken a handful of different approaches here, all of",
            "title": "Building an internal agent: Iterative prompt and skill refinement"
        }
    ],
    "lookbackDays": 1,
    "publishDate": "2026-01-01"
}