{
    "articles": [
        {
            "content": [],
            "link": "https://simonwillison.net/2026/Jan/11/answers/#atom-entries",
            "publishedAt": "2026-01-11",
            "source": "Simon Willison",
            "summary": "<p>Last month I <a href=\"https://simonwillison.net/2025/Dec/15/porting-justhtml/\">wrote about porting JustHTML from Python to JavaScript</a> using Codex CLI and GPT-5.2 in a few hours while also buying a Christmas tree and watching Knives Out 3. I ended that post with a series of open questions about the ethics and legality of this style of work. Alexander Petros on <a href=\"https://lobste.rs/\">lobste.rs</a> just <a href=\"https://lobste.rs/s/cmsfbu/don_t_fall_into_anti_ai_hype#c_cqkdve\">challenged me to answer them</a>, which is fair enough! Here's my attempt at that.</p> <p>You can read <a href=\"https://simonwillison.net/2025/Dec/15/porting-justhtml/\">the original post</a> for background, but the short version is that it's now possible to point a coding agent at some other open source project and effectively tell it \"port this to language X and make sure the tests still pass\" and have it do exactly that.</p> <p>Here are the questions I posed along with my answers based on my current thinking. Extra context is that I've since tried variations on a similar theme a few more times using Claude Code and Opus 4.5 and found it to be <em>astonishingly</em> effective.</p> <h4 id=\"does-this-library-represent-a-legal-violation-of-copyright-of-either-the-rust-library-or-the-python-one\">Does this library represent a legal violation of copyright of either the Rust library or the Python one?</h4> <p>I decided that the right thing to do here was to <a href=\"https://github.com/simonw/justjshtml/commit/a415d0af40c34bf9a856e956d841513f482867e3\">keep",
            "title": "My answers to the questions I posed about porting open source code with LLMs"
        },
        {
            "content": [
                "<p>I&#8217;m building <strong><a href=\"https://newsletter.squishy.computer/p/deep-future\">Deep Future</a></strong>, an AI that stress-tests strategies against thousands of possible futures via a realtime scenario generation engine. Think of it as Deep Research but for strategic foresight.</p><p>The research methods that ground <a href=\"https://newsletter.squishy.computer/p/deep-future\">Deep Future</a> have roots in the Cold War, when RAND began adapting ideas from game theory and systems theory toward military strategy. By mapping the systemic forces driving change we can trace the outlines of futures that may emerge as forces collide. It&#8217;s a bit like forecasting, except instead of making specific predictions, we hold multiple scenarios in superposition, and use the contrasts like a wind tunnel.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!USFb!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b58eb53-df3b-4603-b5c8-6636d32b18d0_1275x1018.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"1018\" src=\"https://substackcdn.com/image/fetch/$s_!USFb!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b58eb53-df3b-4603-b5c8-6636d32b18d0_1275x1018.png\" width=\"1275\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a><figcaption class=\"image-caption\">Julie Mehretu, 2003. &#8220;Looking Back to a Bright New Future&#8221;</figcaption></figure></div><p>Why map multiple futures instead of making particular predictions? The answer boils down to <em>uncertainty</em>. When uncertainty is within bounds, we can deploy the tools of risk management; things like portfolio theory, forecasts, and <a href=\"https://en.wikipedia.org/wiki/Decision_theory\">classical decision theory</a>. However, extreme uncertainty fundamentally changes the strategic terrain. The heavy machinery of classical decision theory gets bogged down in <a href=\"https://en.wikipedia.org/wiki/VUCA\">the mud</a>. Scenario planning, developed to help navigate the extreme uncertainty of conflict, can offer some traction.</p><h3>Risk and uncertainty are two different things</h3><p>The first thing to recognize is the distinction between uncertainty and risk. <em>Risk</em> is when you know the possible outcomes, and can assign probabilities to those outcomes. <em>Uncertainty</em> is when you don&#8217;t know the possible outcomes. These are two very different kinds of strategic situation.</p><blockquote><p>Uncertainty must be taken in a sense radically distinct from the familiar notion of Risk, from which it has never been properly separated.... The essential fact is that &#8216;risk&#8217; means in some cases a quantity susceptible of measurement, while at other times it is something distinctly not of this character; and there are far-reaching and crucial differences in the bearings of the phenomena depending on which of the two is really present and operating.... It will appear that a measurable uncertainty, or &#8216;risk&#8217; proper, as we shall use the term, is so far different from an unmeasurable one that it is not in effect an uncertainty at all.<br /><em>(Frank Knight, <a href=\"https://fraser.stlouisfed.org/files/docs/publications/books/risk/riskuncertaintyprofit.pdf\">Risk, Uncertainty and Profit</a>)</em></p></blockquote><p>Rolling a six on a die is a <em>risk</em>. All of the possible outcomes are known and quantifiable. Aligning AGI is an <em>uncertainty</em>. The possible outcomes are unknown, and unquantifiable. We&#8217;re not sure what the space of possible intelligences looks like. We don&#8217;t know which paths through that space lead to alignment. We don&#8217;t even know if our concepts of <em>alignment</em> and <em>intelligence</em> are well-posed.</p><p>A pivotal question here is if we can identify the set of all outcomes. If we can, we&#8217;re dealing with risk. We can calculate <a href=\"https://en.wikipedia.org/wiki/Expected_utility_hypothesis\">expected utility</a> and use <a href=\"https://en.wikipedia.org/wiki/Decision_theory\">classical decision theory</a>. If we can&#8217;t, we&#8217;re dealing with <em><a href=\"https://en.wikipedia.org/wiki/Knightian_uncertainty\">Knightian uncertainty</a></em>.</p><p>When we don&#8217;t know the possible outcomes, it is difficult to assign them meaningful probabilities. We have to grapple with uncertainty on its own terms. If we treat it like risk, it becomes too easy to assign <a href=\"https://en.wikipedia.org/wiki/False_precision\">false precision</a> to unknowns, or just <a href=\"https://en.wikipedia.org/wiki/McNamara_fallacy\">ignore the things we can&#8217;t quantify</a>.</p><h3>Uncertainty defines the strategic environment</h3><p>If we can&#8217;t quantify uncertainty, we can at least classify it. One useful heuristic is to divide uncertainty into four levels:</p><ul><li><p><strong>Clear</strong> environments are defined by known-knowns. The relationship between cause and effect is obvious.</p></li><li><p><strong>Complicated</strong> environments hinge on known-unknowns. The important factors are knowable. There are direct relationships between cause and effect, but they might require expert knowledge and analysis to understand.</p></li><li><p><strong>Complex</strong> environments are full of unknown-unknowns. The behavior of the environment is nonlinear. The relationship between cause and effect is indirect. The set of all possible outcomes is unknown, and often <a href=\"https://mathworld.wolfram.com/ComputationalIrreducibility.html#:~:text=Computations%20that%20cannot%20be%20sped,%2C%20or%20simulate%2C%20the%20computation.\">computationally irreducible</a>.</p></li><li><p><strong>Chaotic</strong> environments are structureless. The relationship between cause and effect is untraceable. Future states are unknowable and <a href=\"https://en.wikipedia.org/wiki/Uncertainty#Radical_uncertainty\">radically uncertain</a>.</p></li></ul><p>Production lines are clear, rocket science is complicated, climate change is complex, stampeding crowds are chaotic. If you don&#8217;t know which one you&#8217;re dealing with, you&#8217;re confused.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!s2zt!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe67393c0-a1db-47ea-8b3f-48aeaba54766_2224x1668.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"1092\" src=\"https://substackcdn.com/image/fetch/$s_!s2zt!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe67393c0-a1db-47ea-8b3f-48aeaba54766_2224x1668.png\" title=\"\" width=\"1456\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a><figcaption class=\"image-caption\"><a href=\"https://en.wikipedia.org/wiki/Cynefin_framework\">Cynefin Framework</a>. Diagram <a href=\"https://www.vige.se/blog/2020/6/20/cynefinvige\">by Vige</a>. </figcaption></figure></div><p>These quadrants correspond to distinct <a href=\"https://gordonbrander.com/notes/punctuated-equilibrium/\">phase transitions we can observe in ecosystems</a>. We could say <em>clear</em>, <em>complicated</em>, <em>complex</em>, and <em>chaotic</em> are archetypal patterns of behavior that emerge in ecosystems as they <a href=\"https://newsletter.squishy.computer/p/coevolution-creates-living-complexity\">spiral upward in complexity</a>. The increasing structure generates repeated patterns. More structure, more pattern, less uncertainty. Less structure, less pattern, more uncertainty.</p><h3>Different environments require different strategies</h3><p>Clear environments are dominated by risks. Complicated, complex, and chaotic environments are dominated by varying degrees of uncertainty.</p><p>A clear environment is basically a closed system. The rigid structure of clear environments generates very predictable patterns of behavior. The relationship between cause and effect is well-known. Decision theory is a no-brainer here. The important system states are all known and quantified, and we can easily calculate the expected utility of various strategies. At the extreme, we might even be able to apply automated optimization strategies.</p><p>Complicated space involves moderate amounts of uncertainty. The critical unknowns are mostly knowable in principle. However, putting bounds around these unknowns usually requires expert analysis.</p><p>An important quality of complicated and clear environments is that they tend to be <a href=\"https://en.wikipedia.org/wiki/Ergodic_process\">ergodic</a>, in the sense that we can poke the system without causing any fundamental changes to its structure or behavior. The relationships between cause and effect are linear. We can probe, measure results, and put bounds around key uncertainties. This allows us to apply optimization strategies, such as <a href=\"https://en.wikipedia.org/wiki/Hill_climbing\">hill-climbing</a>.</p><p><a href=\"https://en.wikipedia.org/wiki/Superforecaster\">Superforecasting</a> is highly effective in complicated environments. Detailed analysis of what is known allows a superforecaster to make highly educated guesses about what is not. The ergodic nature of complicated systems also means that we can often probe the system, identify possible outcomes, assign them probabilities, and practice <a href=\"https://pascalbugnion.net/notes/bayesian-statistics-explained\">Bayesian updating</a>, without blowing anything up.</p><p>Things start to get muddier in complex and chaotic environments.</p><p>In chaos, all bets are off. Chaotic systems have no discernible structure, so prediction becomes almost useless. What we need are fast reflexes. Keep your eyes peeled, your ears open, and stay on your toes. This means expanding the <em>Observe</em> phase of <a href=\"https://newsletter.squishy.computer/p/tools-for-thought-in-your-ooda-loop\">the OODA loop</a>, keeping <em>Orientation</em> simple, and <em>Deciding</em> and <em>Acting</em> as quickly as possible. The only success metric here is survival.</p><p>Complex environments are also dominated by uncertainty. However, unlike chaotic systems, there are patterns here. These patterns are driven by interacting <a href=\"https://newsletter.squishy.computer/p/effort-is-evidence-of-broken-feedback\">feedback loops</a>.</p><p>Because complex systems are driven by feedback, linear strategies that work in simple or complicated environments can generate unintended consequences in complex ones. To give a particularly stark example from The Great Leap Forward, when grain harvests didn&#8217;t meet expectations, sparrows were blamed for eating seeds and causing the shortfall. Therefore, the Party decided to <a href=\"https://en.wikipedia.org/wiki/Eliminate_Sparrows_campaign#Ecological_disaster\">eliminate the sparrows</a>. Citizens were encouraged to kill sparrows by any means: shooting them down, throwing rocks, destroying nests. Hundreds of millions of sparrows were wiped out. A Soviet scientist present at the time recounts,</p><blockquote><p>The results of this extermination drive were felt soon enough. The whole campaign had been initiated in the first place by some bigwig of the Party who had decided that the sparrows were devouring too large a part of the harvests&#8230; Soon enough, however, it was realized that although the sparrows did consume grain, they also destroyed many harmful insects which, left alive, inflicted far worse damage on the crops than did the birds. So the sparrows were rehabilitated. Rehabilitation, however, did not return them to life any more than it had the victims of Stalin&#8217;s bloody purges, and the insects continued to feast on China&#8217;s crops.<br /><em>(Mikhail Antonovich Klochko, 1961. Translation by Andrew MacAndrew)</em></p></blockquote><p>This man-made plague of locusts reduced harvests by 20%, leading to the deaths of <a href=\"https://www.economist.com/science-and-technology/2025/10/22/how-the-persecution-of-sparrows-killed-2m-people\">two million people</a>.</p><p>It is an extreme example, but characteristic of the disasters that happen when linear optimizers plow headlong into complex situations. Complex systems do not react to linear force in linear ways. This is because feedback loops make the relationship between cause and effect circular. The harder we try to optimize toward the goal, the more energy we pump into feedback loops. Eventually, some loop spins out of control, and the system kicks back.</p><blockquote><p>&#8220;You see, when you get circular trains of causation, as you always do in the living world, the use of logic will make you walk into paradoxes. Just take the thermostat, a simple sense organ, yes? If it&#8217;s on, it&#8217;s off; if it&#8217;s off, it&#8217;s on. If yes, then no; if no, then yes.&#8221;</p><p>With that he stopped to let me puzzle about what he had said. His last sentence reminded me of the classical paradoxes of Aristotelian logic, which was, of course, intended. So I risked a jump.</p><p>&#8220;You mean, do thermostats lie?&#8221;</p><p>Bateson&#8217;s eyes lit up: &#8220;Yes-no-yes-no-yes-no. You see, the cybernetic equivalent of logic is oscillation.&#8221;</p><p><em>(<a href=\"https://shrinkrants.tumblr.com/post/32396927568/gregory-bateson-and-fritjof-capra-discuss-mind\">Interview with Gregory Bateson</a>)</em></p></blockquote><p>And it&#8217;s never just one loop. Imagine how multiple loops might feed into each other, damping or amplifying each other. You can see how the relationship between cause and effect becomes very complex indeed. Even small actions can produce big effects. The right move can generate exponential returns, or exponential collapse. The stakes are high.</p><div class=\"youtube-wrap\" id=\"youtube2--Y9I06Pvnws\"><div class=\"youtube-inner\"></div></div><p>There is no way to be a passive observer in such a complex system, since probing the network can alter its patterns of behavior in dramatic and irreversible ways. Complexity is <a href=\"https://taylorpearson.me/ergodicity/\">non-ergodic</a>, not a marble in a bowl that will roll back into equilibrium, but a <a href=\"https://newsletter.squishy.computer/p/fragments-attractors?utm_source=publication-search#:~:text=Something%20interesting%20begins%20to%20happen%20when%20variables%20interact.%20As%20one%20variable%20influences%20the%20value%20of%20the%20other%2C%20the%20landscape%20begins%20to%20dance.%20The%20more%20interacting%20variables%2C%20the%20more%20the%20landscape%20dances.\">dancing landscape, with multiple attractors</a>, constantly changing, and being changed by our actions. It is difficult to assign probabilities to a fixed set of outcomes, when, in trying to discover the set of possible outcomes, we change the set of possible outcomes.</p><h3>Scenario planning is for navigating complexity</h3><blockquote><p>THOMASINA: Do we believe nature is written in numbers?<br />SEPTIMUS: We do.<br />THOMASINA: Then why do your shapes describe only the shapes of manufacture?<br />SEPTIMUS: I do not know.<br />THOMASINA: Armed thus, God could only make a cabinet.</p><p><em>(Tom Stoppard, 1993. Arcadia)</em></p></blockquote><p>To survive complexity, we need to accept a bit of uncertainty. This means letting go of the optimal outcomes promised by expected utility. Instead of an <em>optimal</em> strategy, we want a <em>robust</em> strategy. We want to become <a href=\"https://en.wikipedia.org/wiki/Antifragile_(book)\">antifragile</a> to a wide range of possible plot twists.</p><p>This is where scenario methods come in. The first thing scenario planning helps us with is <strong>identifying major drivers</strong> and ballparking their <strong>level of uncertainty </strong>and<strong> potential for impact</strong>. During scenario research, we systematically catalog the forces driving change, tracking trends across social, technological, environmental, economic, political, and other categories. Maybe we can&#8217;t pin exact numbers to everything, but we can spot many of the unknowns and put bounds around them. Systematically cataloging and grading forces like this often surfaces important strategic factors that would otherwise be missed. We especially want to keep an eye on weak signals that could have high potential impact. Using superforecasting techniques can be very high-leverage here, and in fact, the kind of cataloging and grading we do in this phase looks a lot like the detailed estimation that a superforecaster does before making a forecast.</p><p>Another thing that scenario planning helps with is <strong>mapping connections</strong> between forces and between actors in the environment. This surfaces many of the<strong> feedback loops</strong> that can generate nonlinear behavior in a complex environment. Spotting these feedback loops can give us a good sense of what might spin out of control, or, taking another perspective, where the systemic leverage points are.</p><p>Using this map of our strategic environment, we can also <strong>generate numerous research-grounded scenarios</strong>. These scenarios emerge from the intersection of trends that we can point to in our environment today. Rather than attempting to predict one or the other future, we use these scenarios&#8212;particularly the divergent scenarios&#8212;to <strong>wind-tunnel strategies</strong>. This helps us develop strategies that are robust across many possible futures. We can even develop multiple contingency plans to deploy in one scenario or another.</p><p>Most interesting to me, scenario planning can help us <strong>shape the future</strong> by articulating a range of possible futures we can aim for. Used in this way, a scenario is prescriptive rather than descriptive. Instead of <a href=\"https://aiprospects.substack.com/p/ai-options-not-optimism\">debating the odds of a scenario like a spectator</a>, we can use scenario planning to tilt the odds in our favor. The best way to predict the future is to create it, after all. In this view, scenario planning is more like map of leverage points that we can push on, to try to bring about particular futures.</p><h3>Reality is bigger than any one model</h3><p>These are all just heuristics. Reality is never just one thing. Real strategic challenges involve a wide range of problems and sub-problems, some clear, others complicated, complex, chaotic, or in-between.</p><p>I was chatting with <a href=\"https://substack.com/@forecasting\">Nu&#241;o Sempere</a> about all of this recently. Nu&#241;o is an advisor to Deep Future and a superforecaster who&#8217;s team won the CSET-Foretell forecasting competition by a surprising margin&#8212;<a href=\"https://samotsvety.org/\">&#8220;around twice as good as the next-best team in terms of the relative Brier score&#8221;</a>. So Nu&#241;o is someone you want to listen to when it comes to the future. Anyway, he described the experience of trading between foresight and forecasting techniques as almost a yin-yang kind of thing. The skilled strategist freely borrows from a wide repertoire of strategic tools, including forecasting, scenario planning, decision theory and everything else. This instinct is a kind of tacit knowledge learned in the trenches. Can we infuse some of it into an AI agent? I&#8217;m optimistic.</p><div><hr /></div><p><em>We&#8217;re developing Deep Future alongside a limited number of exclusive founding partners. Interested? Reply to this email, or <strong><a href=\"http://forms.gle/h7m4ZgSu7hD3hXZk8\">join the waitlist</a></strong>.</em></p>"
            ],
            "link": "https://newsletter.squishy.computer/p/strategy-in-four-worlds",
            "publishedAt": "2026-01-11",
            "source": "Squishy Computer",
            "summary": "<p>I&#8217;m building <strong><a href=\"https://newsletter.squishy.computer/p/deep-future\">Deep Future</a></strong>, an AI that stress-tests strategies against thousands of possible futures via a realtime scenario generation engine. Think of it as Deep Research but for strategic foresight.</p><p>The research methods that ground <a href=\"https://newsletter.squishy.computer/p/deep-future\">Deep Future</a> have roots in the Cold War, when RAND began adapting ideas from game theory and systems theory toward military strategy. By mapping the systemic forces driving change we can trace the outlines of futures that may emerge as forces collide. It&#8217;s a bit like forecasting, except instead of making specific predictions, we hold multiple scenarios in superposition, and use the contrasts like a wind tunnel.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!USFb!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b58eb53-df3b-4603-b5c8-6636d32b18d0_1275x1018.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"1018\" src=\"https://substackcdn.com/image/fetch/$s_!USFb!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b58eb53-df3b-4603-b5c8-6636d32b18d0_1275x1018.png\" width=\"1275\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21",
            "title": "Strategy in four worlds"
        },
        {
            "content": [
                "<p>My coworkers really like AI-powered code review tools and it seems that every time I make a pull request in one of their repos I learn about yet another AI code review SaaS product. Given that there are so many of them, I decided to see how easy it would be to develop my own AI-powered code review bot that targets GitHub repositories. I managed to hack out the core of it in a single afternoon using a model that runs on my desk. I've ended up with a little tool I call <a href=\"https://github.com/Xe/x/tree/master/cmd/reviewbot\">reviewbot</a> that takes GitHub pull request information and submits code reviews in response.</p>\n        <p>reviewbot is powered by a <a href=\"https://xeiaso.net/blog/2025/dgx-spark-first-look/\">DGX Spark</a>, <a href=\"https://github.com/ggml-org/llama.cpp\">llama.cpp</a>, and OpenAI's <a href=\"https://openai.com/index/introducing-gpt-oss/\">GPT-OSS 120b</a>. The AI model runs on my desk with a machine that pulls less power doing AI inference than my gaming tower pulls running fairly lightweight 3D games. In testing I've found that nearly all runs of reviewbot take less than two minutes, even at a rate of only 60 tokens per second generated by the DGX Spark.</p>\n        <p>reviewbot is about 350 lines of Go that just feeds pull request information into the context window of the model and provides a few tools for actions like &quot;leave pull request review&quot; and &quot;read contents of file&quot;. I'm considering adding other actions like &quot;read messages in thread&quot; or &quot;read contents of issue&quot;, but I haven't needed them yet.</p>\n        <p>To make my life easier, I distribute it as <a href=\"https://github.com/Xe/x/pkgs/container/x%2Freviewbot\">a Docker image</a> that <a href=\"https://github.com/Xe/x/blob/master/cmd/reviewbot/actions/reviewbot-manually-invoked.yaml\">gets run in GitHub Actions</a> whenever a pull review comment includes the magic phrase <code>/reviewbot</code>.</p>\n        <p>The main reason I made reviewbot is that I couldn't find anything like it that let you specify the combination of:</p>\n        <ul>\n        <li>Your own AI model name</li>\n        <li>Your own AI model provider URL</li>\n        <li>Your own AI model provider API token</li>\n        </ul>\n        <p>I'm fairly sure that there are thousands of similar AI-powered tools on the market that I can't find because Google is a broken tool, but this one is mine.</p>\n        <h2>How it works</h2>\n        <p>When reviewbot reviews a pull request, it assembles an AI model prompt like this:</p>\n        <pre class=\"language-text\"><code class=\"language-text code-highlight\"><span class=\"code-line\">Pull request info:\n        </span><span class=\"code-line\">\n        </span><span class=\"code-line\">&lt;pr>\n        </span><span class=\"code-line\">&lt;title>Pull request title&lt;/title>\n        </span><span class=\"code-line\">&lt;author>GitHub username of pull request author&lt;/author>\n        </span><span class=\"code-line\">&lt;body>\n        </span><span class=\"code-line\">Text body of the pull request\n        </span><span class=\"code-line\">&lt;/body>\n        </span><span class=\"code-line\">&lt;/pr>\n        </span><span class=\"code-line\">\n        </span><span class=\"code-line\">Commits:\n        </span><span class=\"code-line\">\n        </span><span class=\"code-line\">&lt;commits>\n        </span><span class=\"code-line\">&lt;commit>\n        </span><span class=\"code-line\">&lt;author>Xe&lt;/author>\n        </span><span class=\"code-line\">&lt;message>\n        </span><span class=\"code-line\">chore: minor formatting and cleanup fixes\n        </span><span class=\"code-line\">\n        </span><span class=\"code-line\">- Format .mcp.json with prettier\n        </span><span class=\"code-line\">- Minor whitespace cleanup\n        </span><span class=\"code-line\">\n        </span><span class=\"code-line\">Assisted-by: GLM 4.7 via Claude Code\n        </span><span class=\"code-line\">Reviewbot-request: yes\n        </span><span class=\"code-line\">Signed-off-by: Xe Iaso &lt;me@xeiaso.net>\n        </span><span class=\"code-line\">&lt;/message>\n        </span><span class=\"code-line\">&lt;/commit>\n        </span><span class=\"code-line\">&lt;/commits>\n        </span><span class=\"code-line\">\n        </span><span class=\"code-line\">Files changed:\n        </span><span class=\"code-line\">\n        </span><span class=\"code-line\">&lt;files>\n        </span><span class=\"code-line\">&lt;file>\n        </span><span class=\"code-line\">&lt;name>.mcp.json&lt;/name>\n        </span><span class=\"code-line\">&lt;status>modified&lt;/status>\n        </span><span class=\"code-line\">&lt;patch>\n        </span><span class=\"code-line\">@@ -3,11 +3,8 @@\n        </span><span class=\"code-line\">     &quot;python&quot;: {\n        </span><span class=\"code-line\">       &quot;type&quot;: &quot;stdio&quot;,\n        </span><span class=\"code-line\">       &quot;command&quot;: &quot;go&quot;,\n        </span><span class=\"code-line\">-      &quot;args&quot;: [\n        </span><span class=\"code-line\">-        &quot;run&quot;,\n        </span><span class=\"code-line\">-        &quot;./cmd/python-wasm-mcp&quot;\n        </span><span class=\"code-line\">-      ],\n        </span><span class=\"code-line\">+      &quot;args&quot;: [&quot;run&quot;, &quot;./cmd/python-wasm-mcp&quot;],\n        </span><span class=\"code-line\">       &quot;env&quot;: {}\n        </span><span class=\"code-line\">     }\n        </span><span class=\"code-line\">   }\n        </span><span class=\"code-line\">-}\n        </span><span class=\"code-line\">\\ No newline at end of file\n        </span><span class=\"code-line\">+}\n        </span><span class=\"code-line\">&lt;/patch>\n        </span><span class=\"code-line\">&lt;/file>\n        </span><span class=\"code-line\">&lt;/files>\n        </span><span class=\"code-line\">\n        </span><span class=\"code-line\">Agent information:\n        </span><span class=\"code-line\">\n        </span><span class=\"code-line\">&lt;agentInfo>\n        </span><span class=\"code-line\">[contents of AGENTS.d in the repository]\n        </span><span class=\"code-line\">&lt;/agentInfo>\n        </span></code></pre>\n        <p>The AI model can return one of three results:</p>\n        <ul>\n        <li>Definite approval via the <code>submit_review</code> tool that approves the changes with a summary of the changes made to the code.</li>\n        <li>Definite rejection via the <code>submit_review</code> tool that rejects the changes with a summary of the reason why they're being rejected.</li>\n        <li>Comments without approving or rejecting the code.</li>\n        </ul>\n        <p>The core of reviewbot is the &quot;AI agent loop&quot;, or a loop that works like this:</p>\n        <ul>\n        <li>Collect information to feed into the AI model</li>\n        <li>Submit information to AI model</li>\n        <li>If the AI model runs the <code>submit_review</code> tool, publish the results and exit.</li>\n        <li>If the AI model runs any other tool, collect the information it's requesting and add it to the list of things to submit to the AI model in the next loop.</li>\n        <li>If the AI model just returns text at any point, treat that as a noncommittal comment about the changes.</li>\n        </ul>\n        <h2>Don't use reviewbot</h2>\n        <p>reviewbot is a hack that probably works well enough for me. It has a number of limitations including but not limited to:</p>\n        <ul>\n        <li>It does not work with closed source repositories due to the <a href=\"https://pkg.go.dev/rsc.io/gitfs\">gitfs</a> library not supporting cloning repositories that require authentication. Could probably fix that with some elbow grease if I'm paid enough to do so.</li>\n        <li>A fair number of test invocations had the agent rely on unpopulated fields from the GitHub API, which caused crashes. I am certain that I will only find more such examples and need to issue patches for them.</li>\n        <li>reviewbot is like 300 lines of Go hacked up by hand in an afternoon. If you really need something like this, you can likely write one yourself with little effort.</li>\n        </ul>\n        <h2>Frequently asked questions</h2>\n        <p>When such an innovation as reviewbot comes to pass, people naturally have questions. In order to give you the best reading experience, I asked my friends, patrons, and loved ones for their questions about reviewbot. Here are some answers that may or may not help:</p>\n        <h3>Does the world really need another AI agent?</h3>\n        <p>Probably not! This is something I made out of curiosity, not something I made for you to actually use. It was a lot easier to make than I expected and is surprisingly useful for how little effort was put into it.</p>\n        <h3>Is there a theme of FAQ questions that you're looking for?</h3>\n        <p>Nope. Pure chaos. Let it all happen in a glorious way.</p>\n        <h3>Where do we go when we die?</h3>\n        <p>How the fuck should I know? I don't even know if chairs exist.</p>\n        <h3>Has anyone ever really been far even as decided to use even go want to do look more like?</h3>\n        <p>At least half as much I have wanted to use go wish for that. It's just common sense, really.</p>\n        <h3>If you have a pile of sand and take away one grain at a time, when does it stop being a pile?</h3>\n        <p>When the wind can blow all the sand away.</p>\n        <h3>How often does it require oatmeal?</h3>\n        <p>Three times daily or the netherbeast will emerge and doom all of society. We don't really want that to happen so we make sure to feed reviewbot its oatmeal.</p>\n        <h3>How many pancakes does it take to shingle a dog house?</h3>\n        <p>At least twelve. Not sure because I ran out of pancakes.</p>\n        <h3>Will this crush my enemies, have them fall at my feet, their horses and goods taken?</h3>\n        <p>Only if you add that functionality in a pull request. reviewbot can do anything as long as its code is extended to do that thing.</p>\n        <h3>Why should I use reviewbot?</h3>\n        <p>Frankly, you shouldn't.</p>"
            ],
            "link": "https://xeiaso.net/blog/2026/reviewbot/",
            "publishedAt": "2026-01-11",
            "source": "Xe Iaso",
            "summary": "<p>My coworkers really like AI-powered code review tools and it seems that every time I make a pull request in one of their repos I learn about yet another AI code review SaaS product. Given that there are so many of them, I decided to see how easy it would be to develop my own AI-powered code review bot that targets GitHub repositories. I managed to hack out the core of it in a single afternoon using a model that runs on my desk. I've ended up with a little tool I call <a href=\"https://github.com/Xe/x/tree/master/cmd/reviewbot\">reviewbot</a> that takes GitHub pull request information and submits code reviews in response.</p> <p>reviewbot is powered by a <a href=\"https://xeiaso.net/blog/2025/dgx-spark-first-look/\">DGX Spark</a>, <a href=\"https://github.com/ggml-org/llama.cpp\">llama.cpp</a>, and OpenAI's <a href=\"https://openai.com/index/introducing-gpt-oss/\">GPT-OSS 120b</a>. The AI model runs on my desk with a machine that pulls less power doing AI inference than my gaming tower pulls running fairly lightweight 3D games. In testing I've found that nearly all runs of reviewbot take less than two minutes, even at a rate of only 60 tokens per second generated by the DGX Spark.</p> <p>reviewbot is about 350 lines of Go that just feeds pull request information into the context window of the model and",
            "title": "I made a simple agent for PR reviews. Don't use it."
        }
    ],
    "lookbackDays": 1,
    "publishDate": "2026-01-11"
}