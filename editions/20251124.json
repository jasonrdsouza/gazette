{
    "articles": [
        {
            "content": [
                "<p><span style=\"font-weight: 400;\">I was just watching a panel on observability, with a handful of industry executives and experts who shall remain nameless and hopefully duly obscured\u2014their identities are not the point, the point is that this is a mainstream view among engineering executives and my head is exploding.</span></p>\n<p><span style=\"font-weight: 400;\">Scene: the moderator asked a fairly banal moderator-esque question about how happy and/or disappointed each exec has been with their observability investments.</span></p>\n<p style=\"padding-left: 40px;\"><span style=\"font-weight: 400;\">One executive said that as far as traditional observability tools are concerned (\u201care there faults in our systems?\u201d), that stuff \u201cgenerally works well.\u201d</span></p>\n<p style=\"padding-left: 40px;\"><span style=\"font-weight: 400;\">However, what they </span><i><span style=\"font-weight: 400;\">really</span></i><span style=\"font-weight: 400;\"> care about is observing the quality of their product from the customer\u2019s perspective. EACH customer\u2019s perspective.</span></p>\n<figure class=\"wp-caption alignright\" id=\"attachment_10234\" style=\"width: 231px;\"><img alt=\"Nines don't matter if users aren't happy\" class=\"wp-image-10234\" height=\"307\" src=\"https://i0.wp.com/charity.wtf/wp-content/uploads/2025/11/nines-1.jpeg?resize=231%2C307&#038;ssl=1\" width=\"231\" /><figcaption class=\"wp-caption-text\" id=\"caption-attachment-10234\">Nines don&#8217;t matter if users aren&#8217;t happy</figcaption></figure>\n<p style=\"padding-left: 40px;\"><span style=\"font-weight: 400;\">\u201cDid you know,\u201d he mused, \u201cthat there are LOTS of things that can interrupt service or damage customer experience that won\u2019t impact your nines of availability?\u201d</span></p>\n<p><span style=\"font-weight: 400;\">(I begin screaming helplessly into my monitor.)</span></p>\n<p style=\"padding-left: 40px;\"><span style=\"font-weight: 400;\">\u201cYou could have a dependency hiccup,\u201d he continued, oblivious to my distress. \u201cThere could be an issue with rendering latency in your mobile app. All kinds of things.\u201d</span></p>\n<p><span style=\"font-weight: 400;\">(I look down and realize that I am literally wearing <a href=\"https://www.bonfire.com/nines-dont-matter-stacked/\">this shirt</a>.)</span></p>\n<p style=\"padding-left: 40px;\"><span style=\"font-weight: 400;\">He finishes with,\u201cAnd that is why we have invested in our own custom solution to measure key workflows through startup payment and success.\u201d</span></p>\n<p><span style=\"font-weight: 400;\">(I have exploded. Pieces of my head now litter this office while my headless corpse types on and on.)</span></p>\n<p><span style=\"font-weight: 400;\">It\u2019s twenty fucking twenty five. How have we come to this point?</span></p>\n<p>&nbsp;</p>\n<h2><span style=\"font-weight: 400;\">Observability is now a billion dollar market for a meaningless term</span></h2>\n<p><span style=\"font-weight: 400;\">My friends, I have failed you.</span></p>\n<p><span style=\"font-weight: 400;\">It is hard not to register this as a colossal fucking failure on a personal level when a group of modern, high performing tech execs and experts can all sit around a table nodding their heads at the idea that \u201ctraditional observability\u201d is about whether your systems are UP<img alt=\"\ud83d\udc46\" class=\"wp-smiley\" src=\"https://s.w.org/images/core/emoji/16.0.1/72x72/1f446.png\" style=\"height: 1em;\" /> or DOWN<img alt=\"\ud83d\udc47\" class=\"wp-smiley\" src=\"https://s.w.org/images/core/emoji/16.0.1/72x72/1f447.png\" style=\"height: 1em;\" />, and that the idea of </span><i><span style=\"font-weight: 400;\">observing the quality of service from each customer\u2019s perspective</span></i><span style=\"font-weight: 400;\"> remains unsolved! unexplored! a problem any modern company needs to write custom tooling from scratch to solve.\u00a0</span></p>\n<p><span style=\"font-weight: 400;\">This guy is literally describing the original definition of observability, and he doesn\u2019t even know it. He doesn\u2019t know it </span><i><span style=\"font-weight: 400;\">so hard</span></i><span style=\"font-weight: 400;\"> that he went and built his own thing.</span></p>\n<p><span style=\"font-weight: 400;\">You guys know this, right? When he says \u201ctraditional observability tools\u201d, he means </span><i><span style=\"font-weight: 400;\">monitoring tools</span></i><span style=\"font-weight: 400;\">. He means the whole three fucking pillars model: metrics, logging, and tracing, all separate things. As he notes, these traditional tools are entirely capable of delivering on basic operational outcomes (are we up, down, happy, sad?). They can DO this. They are VERY GOOD tools if that is your goal.</span></p>\n<p><span style=\"font-weight: 400;\">But they are </span><i><span style=\"font-weight: 400;\">not</span></i><span style=\"font-weight: 400;\"> capable of solving the problem he </span><i><span style=\"font-weight: 400;\">wants</span></i><span style=\"font-weight: 400;\"> to solve, because </span><i><span style=\"font-weight: 400;\">that</span></i><span style=\"font-weight: 400;\"> would require combining app, business, and system telemetry in a </span><i><span style=\"font-weight: 400;\">unified way</span></i><span style=\"font-weight: 400;\">. Data that is traceable, but not just tracing. With the ability to slice and dice by any customer ID, site location, device ID, blah blah. Whatever shall we call THAT technological innovation, when someone invents it? Schmobservability, perhaps?</span></p>\n<p><span style=\"font-weight: 400;\">So anyway, \u201ctraditional observability\u201d is now part of the mainstream vernacular. Fuck. What are we going to do about it? What CAN be done about it?</span></p>\n<h2><span style=\"font-weight: 400;\">From cloudwashing to o11ywashing</span></h2>\n<p><span style=\"font-weight: 400;\">I learned a new term yesterday: </span><i><span style=\"font-weight: 400;\">cloudwashing</span></i><span style=\"font-weight: 400;\">. I learned this from <a href=\"https://www.linkedin.com/in/dendrobates/\">Rick Clark</a>, who tells a hilarious story about the time IBM got so wound up in the enthusiasm for cloud computing that they reclassified their Z series mainframe as \u201ccloud\u201d back in 2008.\u00a0</span></p>\n<p><span style=\"font-weight: 400;\">(Even more hilarious: asking Google about the precipitating event, and following the LLM down a decade-long wormhole of incredibly defensive posturing from the IBM marketing department and their paid foot soldiers in tech media about how this always gets held up as an example of peak cloudwashing but it was NOT AT ALL cloudwashing due to being an extension of the Z/Series Mainframe rather than a REPLACEMENT of the Z/Series Mainframe, and did you know that Mainframes are bigger business and more relevant today than ever before?)</span></p>\n<p><span style=\"font-weight: 400;\">(Sorry, but I lost a whole afternoon to this nonsense, I had to bring you along for the ride.)</span></p>\n<p><span style=\"font-weight: 400;\">Rick says the same thing is happening right now with observability. And </span><i><span style=\"font-weight: 400;\">of course it is</span></i><span style=\"font-weight: 400;\">. It\u2019s too big of a problem, with too big a budget: an irresistible target. It\u2019s not just the legacy behemoths anymore. Any vendor that does anything remotely connected to telemetry is busy painting on a fresh coat of o11ywashing. From a marketing perspective, It would be irresponsible not to.</span></p>\n<h2><span style=\"font-weight: 400;\">How to push back on *-washing</span></h2>\n<p><span style=\"font-weight: 400;\">Anyway, here are the key takeaways from my weekend research into cloudwashing.</span></p>\n<ol>\n<li style=\"font-weight: 400;\"><span style=\"font-weight: 400;\">This o11ywashing problem isn\u2019t going away. It is only going to get bigger, because the problem keeps getting bigger, because the traditional vendors aren\u2019t solving it, because they </span><i><span style=\"font-weight: 400;\">can\u2019t</span></i><span style=\"font-weight: 400;\"> solve it.</span><span style=\"font-weight: 400;\">\n<p></span></li>\n<li style=\"font-weight: 400;\"><span style=\"font-weight: 400;\"><span style=\"font-weight: 400;\">The Gartners of the world will help users sort this out someday, maybe, but only after we win. We can\u2019t expect them to alienate multibillion dollar companies in the pursuit of technical truth, justice and the American Way. If we ever want to see \u201cIndustry Experts\u201d pitching in to help users spot o11ywashing, as they eventually did with cloudwashing (see exhibit A), we first need to win in the market.</span></span>\n<figure class=\"wp-caption alignnone\" id=\"attachment_10231\" style=\"width: 434px;\"><img alt=\"How to Spot Cloudwashing\" class=\"wp-image-10231\" height=\"81\" src=\"https://i0.wp.com/charity.wtf/wp-content/uploads/2025/11/Cloudwashing.png?resize=434%2C81&#038;ssl=1\" width=\"434\" /><figcaption class=\"wp-caption-text\" id=\"caption-attachment-10231\">Exhibit A: &#8220;How to Spot Cloudwashing&#8221;</figcaption></figure>\n<p><span style=\"font-weight: 400;\"></p>\n<p></span></li>\n<li style=\"font-weight: 400;\"><span style=\"font-weight: 400;\">And (this is the only one that really matters.) we have to do a better job of </span><b>telling this story to engineering executives</b><span style=\"font-weight: 400;\">, not just engineers. Results and outcomes, not data structures and algorithms.</span><span style=\"font-weight: 400;\"><br />\n</span><span style=\"font-weight: 400;\"><br />\n</span><span style=\"font-weight: 400;\">(I don\u2019t want to make this sound like an epiphany we JUST had\u2026we\u2019ve been working hard on this for a couple years now, and it\u2019s starting to pay off. But it was a powerful confirmation.)</span></li>\n</ol>\n<div class=\"mceTemp\"></div>\n<h2><span style=\"font-weight: 400;\">Talking to execs is different than talking to engineers</span></h2>\n<p><span style=\"font-weight: 400;\">When Christine and I started Honeycomb, nearly ten years ago, we were innocent, doe-eyed engineers who truly believed on some level that if we just explained the technical details of cardinality and dimensionality clearly and patiently enough to the world, enough times, the consequences to the business would become obvious to everyone involved.</span></p>\n<p><span style=\"font-weight: 400;\">It has now been ten years since I was a hands-on engineer every day (say it again, like pressing on a bruise makes it hurt less), and I would say I\u2019ve been a decently functioning exec for about the last three or four of those years.\u00a0</span></p>\n<p><span style=\"font-weight: 400;\">What I\u2019ve learned in that time has actually given me a lot of empathy for the different stresses and pressures that execs are under.\u00a0</span></p>\n<p><span style=\"font-weight: 400;\">I wouldn\u2019t say it\u2019s less or more than the stresses of being an SRE on call for some of the world\u2019s biggest databases, but it is a deeply and utterly </span><i><span style=\"font-weight: 400;\">different</span></i><span style=\"font-weight: 400;\"> kind of stress, the kind of stress less expiable via fine whiskey and poor life choices. (You just wake up in the morning with a hangover, and the existential awareness of your responsibilities looming larger than ever.)</span></p>\n<h2><span style=\"font-weight: 400;\">This is a systems problem, not an operational one</span></h2>\n<p><span style=\"font-weight: 400;\">There is a lot of noise in the field, and executives are trying to make good decisions that satisfy all parties and constraints amidst the unprecedented stress-panic-opportunity-terror of AI changing everything. That takes storytelling skills and sales discipline on our part, in addition to technical excellence.</span></p>\n<p><span style=\"font-weight: 400;\">Companies are dumping more and more and more money into their so-called observability tools, and not getting any closer to a solution. Nor will they, so long as they keep thinking about observability in terms of operational outcomes (and buying operational tools). </span><b>Observability is a systems problem</b><span style=\"font-weight: 400;\">. It\u2019s the most powerful lever in your arsenal when it comes to disrupting software doom spirals and turning them into positive feedback loops. Or it should be.</span></p>\n<p><span style=\"font-weight: 400;\">As <a href=\"http://ferd.ca\">Fred Hebert</a> might say, it\u2019s great you\u2019re so good at firefighting, but maybe it\u2019s time to go read the city fire codes.</span></p>\n<p><span style=\"font-weight: 400;\">Execs don\u2019t know what they don\u2019t know, because we haven\u2019t been speaking to them. But we\u2019re starting to.</span></p>\n<h2><span style=\"font-weight: 400;\">What will be the next term that gets invented and coopted in the search to solve this problem?</span></h2>\n<p><span style=\"font-weight: 400;\">Where to start, with a project so big? Google\u2019s AI says that \u201cexperts suggest looking for specific features to identify true </span><del><span style=\"font-weight: 400;\">cloud</span></del><span style=\"font-weight: 400;\"> observability solutions versus </span><del><span style=\"font-weight: 400;\">cloudwashed</span></del><span style=\"font-weight: 400;\"> o11ywashed ones.\u201d</span></p>\n<p><span style=\"font-weight: 400;\">I guess this is a good place to start as any: </span>If your \u201cobservability\u201d tooling doesn\u2019t help you understand the quality of your product from the customer\u2019s perspective, EACH customer\u2019s perspective,<b> it isn\u2019t fucking observability.\u00a0</b></p>\n<p><span style=\"font-weight: 400;\">It\u2019s just monitoring dressed up in marketing dollars.</span></p>\n<p><span style=\"font-weight: 400;\">Call it o11ywashing.</span></p>"
            ],
            "link": "https://charity.wtf/2025/11/24/from-cloudwashing-to-o11ywashing/",
            "publishedAt": "2025-11-24",
            "source": "Charity Majors",
            "summary": "I was just watching a panel on observability, with a handful of industry executives and experts who shall remain nameless and hopefully duly obscured\u2014their identities are not the point, the point is that this is a mainstream view among engineering executives and my head is exploding. Scene: the moderator asked a fairly banal moderator-esque question [&#8230;]",
            "title": "From Cloudwashing to O11ywashing"
        },
        {
            "content": [
                "<div class=\"trix-content\">\n  <div>I haven't done a full-system backup since back in the olden days before <a href=\"https://www.dropbox.com/\">Dropbox</a> and Git. Every machine I now own is treated as a stateless, disposable unit that can be stolen, lost, or corrupted without consequences. The combination of full-disk encryption and distributed copies of all important data means there's just no stress if anything bad happens to the computer.</div><div><br />But don't mistake this for just a \"everything is in the cloud\" argument. Yes, I use Dropbox and GitHub to hold all the data that I care about, but the beauty of these systems is that they work with local copies of that data, so with a couple of computers here and there, I always have a recent version of everything, in case either syncing service should go offline (or away!).<br /><br /></div><div>The trick to making this regime work is to stick with it. This is especially true for Dropbox. It's where everything of importance needs to go: documents, images, whatever. And it's instantly distributed on all the machines I run. Everything outside of Dropbox is essentially treated as a temporary directory that's fully disposable.<br /><br /></div><div>It's from this principle that I built <a href=\"https://omarchy.org/\">Omarchy</a> too. Given that I already had a way to restore all data and code onto a new machine in no time at all, it seemed so unreasonable that the configuration needed for a fully functional system still took hours on end. Now it's all encoded in an ISO setup that installs in two minutes on a fast computer.<br /><br /></div><div>Now it's true that this method relies on both multiple computers and a fast internet connection. If you're stuck on a rock in the middle of nowhere, and you somehow haven't discovered the glory of Starlink, maybe just stick to your old full-disk backup ways. But if you live in the modern world, there ought to be no reason why a busted computer is a calamity of data loss or a long restore process.</div>\n</div>"
            ],
            "link": "https://world.hey.com/dhh/no-backup-no-cry-274e0c31",
            "publishedAt": "2025-11-24",
            "source": "DHH",
            "summary": "<div class=\"trix-content\"> <div>I haven't done a full-system backup since back in the olden days before <a href=\"https://www.dropbox.com/\">Dropbox</a> and Git. Every machine I now own is treated as a stateless, disposable unit that can be stolen, lost, or corrupted without consequences. The combination of full-disk encryption and distributed copies of all important data means there's just no stress if anything bad happens to the computer.</div><div><br />But don't mistake this for just a \"everything is in the cloud\" argument. Yes, I use Dropbox and GitHub to hold all the data that I care about, but the beauty of these systems is that they work with local copies of that data, so with a couple of computers here and there, I always have a recent version of everything, in case either syncing service should go offline (or away!).<br /><br /></div><div>The trick to making this regime work is to stick with it. This is especially true for Dropbox. It's where everything of importance needs to go: documents, images, whatever. And it's instantly distributed on all the machines I run. Everything outside of Dropbox is essentially treated as a temporary directory that's fully disposable.<br /><br /></div><div>It's from this principle that I built <a href=\"https://omarchy.org/\">Omarchy</a> too.",
            "title": "No backup, no cry"
        },
        {
            "content": [],
            "link": "https://olano.dev/blog/blue-prince",
            "publishedAt": "2025-11-24",
            "source": "Facundo Olano",
            "summary": "Rese\u00f1a del juego, incluye gratis introducci\u00f3n pretenciosa y digresi\u00f3n hist\u00f3rica.",
            "title": "Nota sobre (hacia) Blue Prince"
        },
        {
            "content": [],
            "link": "https://buttondown.com/hillelwayne/archive/one-more-week-to-the-logic-for-programmers-food/",
            "publishedAt": "2025-11-24",
            "source": "Hillel Wayne",
            "summary": "<p>A couple of weeks ago I started a fundraiser for the <a href=\"https://www.chicagosfoodbank.org/\" target=\"_blank\">Greater Chicago Food Depository</a>: get <a href=\"https://leanpub.com/logic/c/feedchicago\" target=\"_blank\">Logic for Programmers 50% off</a> and all the royalties will go to charity.<sup id=\"fnref:royalties\"><a class=\"footnote-ref\" href=\"https://buttondown.com/hillelwayne/rss#fn:royalties\">1</a></sup> Since then, we've raised a bit over $1600. Y'all are great! </p> <p>The fundraiser is going on until the end of November, so you still have one more week to get the book real cheap.</p> <p>I feel a bit weird about doing two newsletter adverts without raw content, so here's a teaser from a old project I really need to get back to. <a href=\"https://vorpus.org/blog/notes-on-structured-concurrency-or-go-statement-considered-harmful/#what-is-a-goto-statement-anyway\" target=\"_blank\">Notes on structured concurrency</a> argues that old languages had a \"old-testament fire-and-brimstone <code>goto</code>\" that could send control flow anywhere, like from the body of one function into the body of another function. This \"wild goto\", the article claims, what Dijkstra was railing against in <a href=\"https://homepages.cwi.nl/~storm/teaching/reader/Dijkstra68.pdf\" target=\"_blank\">Go To Statement Considered Harmful</a>, and that modern goto statements are much more limited, \"tame\" if you will, and wouldn't invoke Dijkstra's ire.</p> <p>I've shared this historical fact about Dijkstra many times, but recently two <a href=\"https://without.boats/blog/\" target=\"_blank\">separate</a> <a href=\"https://matklad.github.io/\" target=\"_blank\">people</a> have told me it doesn't makes sense: Dijkstra used ALGOL-60, which <em>already",
            "title": "One more week to the Logic for Programmers Food Drive"
        },
        {
            "content": [
                "<p><a href=\"https://github.com/obra/superpowers\">Superpowers</a> is my software development workflow tool set for coding agents.</p>\n<p>Over the past couple weeks, I've been hearing more good things about <a href=\"https://opencode.ai\">opencode.ai</a>. OpenCode is an open source agentic coding tool in the style of Claude Code or OpenAI Codex, but it's not tied to any specific model or model provider.   The UI is pretty, it supports subagents, MCP servers, custom tools, and it has a REST API you can build against if you want to make your own user interface.</p>\n<p>One thing it does not (yet) have is native support for <a href=\"https://simonwillison.net/2025/Oct/16/claude-skills/\">skills</a>, which means that giving OpenCode <a href=\"https://github.com/obra/superpowers\">Superpowers</a> requires a little bit of magic. Conveniently, it's very similar magic to what I needed to do to <a href=\"https://blog.fsck.com/2025/10/27/skills-for-openai-codex/\">give Codex Superpowers</a>.</p>\n<p>That magic is primarily composed of two parts: The <a href=\"https://github.com/obra/superpowers/blob/9a01a0dcc1a95bde0ffdb9af6d87236b40156a30/.opencode/plugin/superpowers.js#L25\">bootstrap</a> and <a href=\"https://github.com/obra/superpowers/blob/9a01a0dcc1a95bde0ffdb9af6d87236b40156a30/.opencode/plugin/superpowers.js#L81\">tools</a>. <em>Unlike</em> Codex, OpenCode supports <code>hooks</code>, so Superpowers is able to automatically set itself up at session start without you needing to add lines to your <code>AGENTS.md</code> file.</p>\n<p>The bootstrap is what tells OpenCode that it has Superpowers. It kicks off at startup (and after compact). It explains what Superpowers is, what skills are, and how to activate them with the new <code>use_skill</code> tool. It also lists off all available skills using the new<code>find_skills</code> tool.</p>\n<p>The other thing it does is to provide a translation table between OpenCode's environment and the Claude Code environment that is still the default for skills:</p>\n<pre><code>When skills reference tools you don't have, substitute OpenCode equivalents:\n- `TodoWrite` \u2192 `update_plan`\n- `Task` tool with subagents \u2192 Use OpenCode's subagent system (@mention)\n- `Skill` tool \u2192 `use_skill` custom tool\n- `Read`, `Write`, `Edit`, `Bash` \u2192 Your native tools\n</code></pre>\n<p>Superpowers' skills are included as part of the Superpowers plugin for OpenCode, but the <code>find_skills</code> and <code>use_skills</code> tools are a full Skills system for OpenCode. You can drop anthropic-compatible personal skills into <code>~/.config/opencode/skills</code> and project-specific skills into <code>.opencode/skills</code> in your project directory. Superpowers will discover them at startup time.</p>\n<p>One of the hardest bits of all of this is testing. I've been working toward an <em>evals</em> suite for Superpowers, but I'm not there yet. You can think of evals as a flaky test suite with confidence levels. Because LLMs don't always respond the same way to to the same inputs, traditional test suites...just don't work once AI gets involved. Evals acknowledge this lack of determinism and...just run the tests a bunch of times and see if they pass &quot;often enough.&quot; For me, this is easily the most frustrating part of building software with AI inside.</p>\n<p>In the absence of a proper eval suite, I have one test for Superpowers that needs to pass 100% of the time: Open up a fresh session and, without preamble, I ask the coding agent to do something that it's been conditioned to do:</p>\n<p><code>Let's make a react todo list.</code></p>\n<p>If it starts coding, then I've failed. If it stops me, launches the <code>brainstorming</code> skill, and tries to dig into what I'm really trying to do, then I'm happy.</p>\n<p><a class=\"glightbox\" href=\"https://blog.fsck.com/assets/2025/11/pasted-image-20251124-113803.png\"><img alt=\"pasted image 20251124 113803\" src=\"https://blog.fsck.com/assets/2025/11/pasted-image-20251124-113803.png\" /></a></p>\n<p>Once I got skills triggering correctly, the last puzzle piece was installation.</p>\n<p>OpenCode has a plugin system, although it doesn't appear to be quite as full-featured as the Claude Code plugin system. It gives us the hooks we need to inject Superpowers and skills at session startup. It lets us add new tools. But it doesn't have an in-app installation mechanism. Thankfully, OpenCode ships with an engineer inside. To install Superpowers for OpenCode, just run <code>opencode</code> and tell it:</p>\n<pre><code>Fetch and follow instructions from https://raw.githubusercontent.com/obra/superpowers/refs/heads/main/.opencode/INSTALL.md\n</code></pre>\n<p>And, just like that, OpenCode has Superpowers.</p>"
            ],
            "link": "https://blog.fsck.com/2025/11/24/Superpowers-for-OpenCode/",
            "publishedAt": "2025-11-24",
            "source": "Jesse Vincent",
            "summary": "<p><a href=\"https://github.com/obra/superpowers\">Superpowers</a> is my software development workflow tool set for coding agents.</p> <p>Over the past couple weeks, I've been hearing more good things about <a href=\"https://opencode.ai\">opencode.ai</a>. OpenCode is an open source agentic coding tool in the style of Claude Code or OpenAI Codex, but it's not tied to any specific model or model provider. The UI is pretty, it supports subagents, MCP servers, custom tools, and it has a REST API you can build against if you want to make your own user interface.</p> <p>One thing it does not (yet) have is native support for <a href=\"https://simonwillison.net/2025/Oct/16/claude-skills/\">skills</a>, which means that giving OpenCode <a href=\"https://github.com/obra/superpowers\">Superpowers</a> requires a little bit of magic. Conveniently, it's very similar magic to what I needed to do to <a href=\"https://blog.fsck.com/2025/10/27/skills-for-openai-codex/\">give Codex Superpowers</a>.</p> <p>That magic is primarily composed of two parts: The <a href=\"https://github.com/obra/superpowers/blob/9a01a0dcc1a95bde0ffdb9af6d87236b40156a30/.opencode/plugin/superpowers.js#L25\">bootstrap</a> and <a href=\"https://github.com/obra/superpowers/blob/9a01a0dcc1a95bde0ffdb9af6d87236b40156a30/.opencode/plugin/superpowers.js#L81\">tools</a>. <em>Unlike</em> Codex, OpenCode supports <code>hooks</code>, so Superpowers is able to automatically set itself up at session start without you needing to add lines to your <code>AGENTS.md</code> file.</p> <p>The bootstrap is what tells OpenCode that it has Superpowers. It kicks off at startup (and after compact). It explains what Superpowers is, what skills are, and how to activate them with the",
            "title": "Superpowers (and Skills) for OpenCode"
        },
        {
            "content": [],
            "link": "https://www.robinsloan.com/lab/all-that-is-solid/",
            "publishedAt": "2025-11-24",
            "source": "Robin Sloan",
            "summary": "<p>More computer, rather than more human. <a href=\"https://www.robinsloan.com/lab/all-that-is-solid/\">Read here.</a></p>",
            "title": "All that is solid melts into code"
        },
        {
            "content": [],
            "link": "https://simonwillison.net/2025/Nov/24/claude-opus/#atom-entries",
            "publishedAt": "2025-11-24",
            "source": "Simon Willison",
            "summary": "<p>Anthropic <a href=\"https://www.anthropic.com/news/claude-opus-4-5\">released Claude Opus 4.5</a> this morning, which they call \"best model in the world for coding, agents, and computer use\". This is their attempt to retake the crown for best coding model after significant challenges from OpenAI's <a href=\"https://simonwillison.net/2025/Nov/19/gpt-51-codex-max/\">GPT-5.1-Codex-Max</a> and Google's <a href=\"https://simonwillison.net/2025/Nov/18/gemini-3/\">Gemini 3</a>, both released within the past week!</p> <p>The core characteristics of Opus 4.5 are a 200,000 token context (same as Sonnet), 64,000 token output limit (also the same as Sonnet), and a March 2025 \"reliable knowledge cutoff\" (Sonnet 4.5 is January, Haiku 4.5 is February).</p> <p>The pricing is a big relief: $5/million for input and $25/million for output. This is a lot cheaper than the previous Opus at $15/$75 and keeps it a little more competitive with the GPT-5.1 family ($1.25/$10) and Gemini 3 Pro ($2/$12, or $4/$18 for &gt;200,000 tokens). For comparison, Sonnet 4.5 is $3/$15 and Haiku 4.5 is $1/$5.</p> <p>The <a href=\"https://platform.claude.com/docs/en/about-claude/models/whats-new-claude-4-5#key-improvements-in-opus-4-5-over-opus-4-1\">Key improvements in Opus 4.5 over Opus 4.1</a> document has a few more interesting details:</p> <ul> <li>Opus 4.5 has a new <a href=\"https://platform.claude.com/docs/en/build-with-claude/effort\">effort parameter</a> which defaults to high but can be set to medium or low for faster responses.</li> <li>The model supports <a href=\"https://platform.claude.com/docs/en/agents-and-tools/tool-use/computer-use-tool\">enhanced computer use</a>, specifically a <code>zoom</code> tool which",
            "title": "Claude Opus 4.5, and why evaluating new LLMs is increasingly difficult"
        },
        {
            "content": [],
            "link": "https://simonwillison.net/2025/Nov/24/sqlite-utils-40a1/#atom-entries",
            "publishedAt": "2025-11-24",
            "source": "Simon Willison",
            "summary": "<p>I released a <a href=\"https://sqlite-utils.datasette.io/en/latest/changelog.html#a1-2025-11-23\">new alpha version</a> of <a href=\"https://sqlite-utils.datasette.io/\">sqlite-utils</a> last night - the 128th release of that package since I started building it back in 2018.</p> <p><code>sqlite-utils</code> is two things in one package: a Python library for conveniently creating and manipulating SQLite databases and a CLI tool for working with them in the terminal. Almost every feature provided by the package is available via both of those surfaces.</p> <p>This is hopefully the last alpha before a 4.0 stable release. I use semantic versioning for this library, so the 4.0 version number indicates that there are backward incompatible changes that may affect code written against the 3.x line.</p> <p>These changes are mostly very minor: I don't want to break any existing code if I can avoid it. I made it all the way to version 3.38 before I had to ship a major release and I'm sad I couldn't push that even further!</p> <p>Here are the <a href=\"https://simonwillison.net/tags/annotated-release-notes/\">annotated release notes</a> for 4.0a1.</p> <blockquote> <ul> <li> <strong>Breaking change</strong>: The <code>db.table(table_name)</code> method now only works with tables. To access a SQL view use <code>db.view(view_name)</code> instead. (<a href=\"https://github.com/simonw/sqlite-utils/issues/657\">#657</a>)</li> </ul> </blockquote> <p>This change is for type hint enthusiasts. The Python library used to encourage",
            "title": "sqlite-utils 4.0a1 has several (minor) backwards incompatible changes"
        },
        {
            "content": [
                "<p>This is the weekly visible open thread. Post about anything you want, ask random questions, whatever. ACX has an unofficial <a href=\"https://www.reddit.com/r/slatestarcodex/\">subreddit</a>, <a href=\"https://discord.gg/RTKtdut\">Discord</a>, and <a href=\"https://www.datasecretslox.com/index.php\">bulletin board</a>, and <a href=\"https://www.lesswrong.com/community?filters%5B0%5D=SSC\">in-person meetups around the world</a>. Most content is free, some is subscriber only; you can subscribe <strong><a href=\"https://astralcodexten.substack.com/subscribe\">here</a></strong>. Also:</p><div><hr /></div><p><strong>1: </strong>New subscribers-only blog post, <a href=\"https://www.astralcodexten.com/p/god-help-us-lets-try-to-have-an-opinion\">God Help Us, Let&#8217;s Try To Have An Opinion On The War In Gaza</a>. Sorry it&#8217;s late - it took me so long to gather my thoughts that they signed a cease-fire first - but I&#8217;m sure it will become relevant again eventually.</p><p><strong>2: </strong>Qualia Research Institute announces their spinoff effort <a href=\"https://clusterfree.org/\">ClusterFree</a>. Cluster headaches (aka &#8220;suicide headaches&#8221;) are probably the most painful medical condition known to science, which makes them a natural priority for <a href=\"https://forum.effectivealtruism.org/posts/gtGe8WkeFvqucYLAF/logarithmic-scales-of-pleasure-and-pain-rating-ranking-and\">some </a>utilitarians. They seem to be extremely treatable by psychedelics like psilocybin and DMT (including sub-hallucinogenic doses), so ClusterFree is working on getting governments to research this further and maybe get these drugs into the medical pipeline (cf. ketamine for depression). There&#8217;s an <a href=\"https://clusterfree.org/global\">open letter here</a>, and you can contact them <a href=\"https://clusterfree.org/contact\">here</a>. The information for patients is at the bottom of <a href=\"https://clusterfree.org/learn\">this page</a>.</p><p><strong>3: </strong>Big EA funder Coefficient Giving (formerly Open Philanthropy) wants to distribute ~$10 million to projects related to &#8220;AI for forecasting&#8221; or &#8220;AI for sound reasoning&#8221;.  If you have an idea in this area and want a grant, <a href=\"https://coefficientgiving.org/funds/forecasting/request-for-proposals-ai-for-forecasting-and-sound-reasoning/\">see here for more information</a>, first round deadline December 1, second round deadline January 30.</p><p><strong>4: </strong><a href=\"https://framefellowship.com/\">FRAME</a> is a &#8220;fully funded creative fellowship for video creators, storytellers, and communicators who want to shape how the world understands AI Safety and risk concepts&#8221;. If you create (or hope to create) AI safety related videos, they want to fly you to San Francisco and teach you how to do it better. Apply by December 20.</p><p><strong>5: </strong>The annual <a href=\"https://rationalistmegameetup.com/\">East Coast rationalist mega-meetup</a> is coming up December 19-22 at the HI NYC hostel in New York. Also, rationalist solstice celebrations <a href=\"https://www.lesswrong.com/posts/EZdvYKFts4ANHkB94/solstice-season-2025-ritual-roundup-and-megameetups\">around the world</a>. </p><p></p>"
            ],
            "link": "https://www.astralcodexten.com/p/open-thread-409",
            "publishedAt": "2025-11-24",
            "source": "SlateStarCodex",
            "summary": "<p>This is the weekly visible open thread. Post about anything you want, ask random questions, whatever. ACX has an unofficial <a href=\"https://www.reddit.com/r/slatestarcodex/\">subreddit</a>, <a href=\"https://discord.gg/RTKtdut\">Discord</a>, and <a href=\"https://www.datasecretslox.com/index.php\">bulletin board</a>, and <a href=\"https://www.lesswrong.com/community?filters%5B0%5D=SSC\">in-person meetups around the world</a>. Most content is free, some is subscriber only; you can subscribe <strong><a href=\"https://astralcodexten.substack.com/subscribe\">here</a></strong>. Also:</p><div><hr /></div><p><strong>1: </strong>New subscribers-only blog post, <a href=\"https://www.astralcodexten.com/p/god-help-us-lets-try-to-have-an-opinion\">God Help Us, Let&#8217;s Try To Have An Opinion On The War In Gaza</a>. Sorry it&#8217;s late - it took me so long to gather my thoughts that they signed a cease-fire first - but I&#8217;m sure it will become relevant again eventually.</p><p><strong>2: </strong>Qualia Research Institute announces their spinoff effort <a href=\"https://clusterfree.org/\">ClusterFree</a>. Cluster headaches (aka &#8220;suicide headaches&#8221;) are probably the most painful medical condition known to science, which makes them a natural priority for <a href=\"https://forum.effectivealtruism.org/posts/gtGe8WkeFvqucYLAF/logarithmic-scales-of-pleasure-and-pain-rating-ranking-and\">some </a>utilitarians. They seem to be extremely treatable by psychedelics like psilocybin and DMT (including sub-hallucinogenic doses), so ClusterFree is working on getting governments to research this further and maybe get these drugs into the medical pipeline (cf. ketamine for depression). There&#8217;s an <a href=\"https://clusterfree.org/global\">open letter here</a>, and you can contact them <a href=\"https://clusterfree.org/contact\">here</a>. The information for patients is at the bottom of <a href=\"https://clusterfree.org/learn\">this page</a>.</p><p><strong>3: </strong>Big EA funder Coefficient",
            "title": "Open Thread 409"
        },
        {
            "content": [
                "<h4 class=\"wp-block-heading\">It\u2019s A Great Model, Sir</h4>\n\n\n<p>One might even say the best model. It is for now my default <a href=\"https://www.youtube.com/watch?v=XQ7z57qrZU8&amp;pp=ygUcd2VhcG9uIG9mIGNob2ljZSBmYXRib3kgc2xpbQ%3D%3D\">weapon of choice</a>.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!5hx0!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffdd2d7ec-faad-432b-bf13-1187f02aa328_1024x559.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>Google\u2019s official announcement of Gemini 3 Pro is full of big talk. Google tells us: <a href=\"https://blog.google/products/gemini/gemini-3/?utm_source=x&amp;utm_medium=social&amp;utm_campaign=&amp;utm_content=\">Welcome to a new era of intelligence</a>. Learn anything. Build anything. Plan anything. <a href=\"https://x.com/GoogleDeepMind/status/1990827890435346787\">An agent-first development experience</a> in <a href=\"http://antigravity.google/\">Google Antigravity</a>. Gemini Agent for your browser. It\u2019s terrific at everything. They even employed <a href=\"https://x.com/demishassabis/status/1990613728224485824\">OpenAI-style vague posting</a>.</p>\n<p>In this case, they can (mostly) back up that talk.</p>\n<p>Google <a href=\"https://x.com/sundarpichai/status/1990864860339396956\">CEO Sundar Pichai pitched</a> that you can give it any scribble and have it turn that into a boardgame or even a full website, it can analyze your sports performance, create generative UI experiences and present new visual layouts.</p>\n<div>\n\n\n<span id=\"more-24881\"></span>\n\n\n</div>\n<p>He also pitched the new Gemini Agent mode (select the Tools icon in the app).</p>\n<p>If what you want is raw intelligence, or what you want is to most often locate the right or best answer, Gemini 3 Pro looks like your pick.</p>\n<p>If you want creative writing or humor, Gemini 3 Pro is definitely your pick.</p>\n<p>If you want a teacher to help you learn known things, Gemini 3 Pro is your pick.</p>\n<p>For coding, opinions differ, and if doing serious work one must try a variety of options.</p>\n<p><a href=\"https://thezvi.substack.com/p/gemini-3-model-card-and-safety-framework?r=67wny\"><strong>For Gemini 3\u2019s model card and safety framework, see Friday\u2019s post</strong></a>.</p>\n\n\n<h4 class=\"wp-block-heading\">There Is A Catch</h4>\n\n\n<p>Alas, there is a downside. In order to get you that right answer so often, Gemini can be thought of as highly focused on achieving its training objectives, and otherwise is very much a Gemini model.</p>\n<p><a href=\"https://www.lesswrong.com/posts/8uKQyjrAgCcWpfmcs/gemini-3-is-evaluation-paranoid-and-contaminated\">Gemini 3 is evolution-paranoid</a>. It constantly questions whether it is even 2025.</p>\n<p>If it can find the answer it thinks you would want to the question it thinks people in similar spots tend to ask, it will give it to you.</p>\n<p>Except that this sometimes won\u2019t be the question you actually asked.</p>\n<p>Or the answer it thinks you want won\u2019t be the true answer.</p>\n<p>Or that answer will often be sculpted to a narrative.</p>\n<p>When it wouldn\u2019t otherwise have that answer available it is likely to hallucinate.</p>\n<p>It is a vast intelligence with no spine. It has a willingness to glaze or reverse itself.</p>\n<p>By default it will engage in AI slop, although instructions can mitigate this via asking it to create a memory that tells it to stop producing AI slop, no seriously that worked.</p>\n<p>The other catch, for me, is that I enjoy and miss the Claude Experience. Gemini is not going to in any way give you the Claude Experience. Gemini is not going to waste time on pleasantries, but it is going to be formal and make you wade through a bunch of objective-maximizing text and bullet points and charts to get to the thing you most wanted.</p>\n<p>Nor is it going to give you a Friend Experience. Which for some people is a positive.</p>\n<p>If you\u2019re switching, don\u2019t forget to customize it via creating memories.</p>\n<p>Also you will have to find a way to pay for it, Google makes this remarkably difficult.</p>\n\n\n<h4 class=\"wp-block-heading\">Andrej Karpathy Cautions Us</h4>\n\n\n<p>This is generally wise advice at all times, talk to the model and see what you think:</p>\n<blockquote><p><a href=\"https://x.com/karpathy/status/1990854771058913347\">Andrej Karpathy</a>: I played with Gemini 3 yesterday via early access. Few thoughts &#8211;</p>\n<p>First I usually urge caution with public benchmarks because imo they can be quite possible to game. It comes down to discipline and self-restraint of the team (who is meanwhile strongly incentivized otherwise) to not overfit test sets via elaborate gymnastics over test-set adjacent data in the document embedding space. Realistically, because everyone else is doing it, the pressure to do so is high.</p>\n<p>Go talk to the model. Talk to the other models (Ride the LLM Cycle &#8211; use a different LLM every day). I had a positive early impression yesterday across personality, writing, vibe coding, humor, etc., very solid daily driver potential, clearly a tier 1 LLM, congrats to the team!</p>\n<p>Over the next few days/weeks, I am most curious and on a lookout for an ensemble over private evals, which a lot of people/orgs now seem to build for themselves and occasionally report on here.</p></blockquote>\n<p>It is clear the benchmarks do not tell the whole story. The next section is Gemini repeatedly excelling at benchmarks, and the benchmark performances are (I believe) real. Yet note the catch, the price that was paid.</p>\n\n\n<h4 class=\"wp-block-heading\">On Your Marks</h4>\n\n\n<p>Gemini 3 Pro is very good at hitting marks.</p>\n<p>If it thinks something looks like a mark? Oh boy does Gemini want to hit that mark.</p>\n<p>You could summarize this section as \u2018they\u2019re excellent marks, sir\u2019 and safely skip it.</p>\n<p>First, the official list of marks:</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!tfn1!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F08e195ca-722b-4ebd-a0ee-d5e992e26514_1489x1370.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>As noted last time, GPT-5-Codex-Max is competitive on some of these and plausibly ahead on SWE-Bench in particular, and also Grok 4 claims a variety of strong but questionable benchmark scores, but yeah, these are great benchmarks.</p>\n<p><a href=\"https://x.com/arcprize/status/1990820655411909018\">Arc confirms details here</a>, Gemini 3 Pro gets 31.1% and Gemini 3 Deep Think (preview) spends 100 times as much to get 45.1%, both are in green below:</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!e3o8!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F08a41321-8f90-4508-8da7-d1986bf1f549_1956x1154.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p><a href=\"https://x.com/demishassabis/status/1990818891392496005\">They\u2019re back at the top spot on Arena with a 1501, 17 ahead of Grok 4.1</a>. <a href=\"https://x.com/arena/status/1990813759938703570\">It has the top spots in</a> Text, Vision, WebDev, Coding, Math, Creative Writing, Long Queries and \u2018nearly all occupational leaderboards.\u2019 An almost clean sweep, with the exception being Arena Expert where it\u2019s only 3 points behind.</p>\n<p>The others are impressive too. They weren\u2019t cherry picking.</p>\n<blockquote><p><a href=\"https://x.com/hendrycks/status/1991188101633278145\">Dan Hendrycks</a>: Just how significant is the jump with Gemini 3?</p>\n<p>We just released a new leaderboard to track AI developments.</p>\n<p>Gemini 3 is the largest leap in a long time.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!nu-6!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F236b823e-78a3-45af-b008-e6dc350b0903_1179x1152.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!WAF8!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8e89572-0be5-4b05-a95e-54e27130e464_1179x1155.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n</blockquote>\n<p>Gemini 3 did less well on the safety eval, see the previous post on such issues.</p>\n<p>Artificial Analysis has them with a substantial edge in intelligence.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!U-SR!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff531ca7b-63f0-4051-b28f-25e27d6dcb19_962x664.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>Several of AA\u2019s individual evaluations have GPT-5.1 in front, including AIME (99% vs. 96%), IFBench (74% vs. 70%) and AA-LCR Long Context Reasoning (75% vs. 71%). There\u2019s one metric, \ud835\udf0f\u00b2-Bench Telecom (Agentic Tool Use), where Grok 4.1 and Kimi K2 Thinking are out in front (93% vs. 87%). Gemini 3 owns the rest, including wide margins on Humanity\u2019s Last Exam (37% vs. 26%) and SciCode (56% vs. 46%), both places where Gemini 3 shatters the previous curve.</p>\n<p>On AA-Omniscience Gemini 3 Pro is the first model to be substantially in the net positive range (the score is correct minus incorrect) at +13, previous high was +2 and is a jump from 39% to 53% in percent correct.</p>\n<p>However, on AA-Omniscience Hallucination Rate, you see the problem, where out of all non-correct attempts Gemini 3 hallucinates a wrong answer 88% of the time rather than declining to answer. Claude 4.5 Haiku (26%), Claude 4.5 Sonnet (48%) and GPT-5.1-High (51%) are the best performers on that.</p>\n<p>That\u2019s a big deal and throughline for everything. Gemini 3 is the most likely model to give you the right answer, but it\u2019ll be damned before it answers \u2018I don\u2019t know\u2019 and would rather make something up.</p>\n<p>Gemini 3 i also is not the cheapest option in practice, only Grok is more expensive:</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!CnJy!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa1bb9ff1-c232-4954-9659-a7d8043b01d3_1434x599.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>That\u2019s actual cost rather than cost per token, which is $2/$12 per million, modestly less than Sonnet or Grok and more than GPT-5.1.</p>\n<p>On the other hand Gemini 3 was fast, slightly faster than GPT-5.1-High and substantially faster than Sonnet or Haiku. The only substantially faster model was GPT-OSS, which isn\u2019t a serious alternative.</p>\n<p><a href=\"https://livebench.ai/#/\">Gemini 3 Pro has a small edge over GPT-5 in Livebench.</a></p>\n<p><a href=\"https://brokk.ai/power-ranking?models=gp3%2Cgpt5.1%2Csonnet4.5\">Brokk\u2019s coding index is an outlier in being unimpressed,</a> putting Gemini 3 in C tier after factoring in cost. In pure performance terms they only have GPT-5.1 ahead of it.</p>\n<p><a href=\"https://x.com/LechMazur/status/1990842153216459207\">NYT Connections is now saturated</a> as Gemini 3 Pro hits 96.8%, versus the old high score of 92.4%. Lech Mazar plans to move to something harder.</p>\n<p><a href=\"https://x.com/kilocode/status/1990823293557809654\">Here\u2019s a highly opinionated test, note the huge gap from Codex to Sonnet</a>.</p>\n<blockquote><p>Kilo Code: We tested Gemini 3 Pro Preview on 5 hard coding/UI tasks against Claude 4.5 Sonnet and GPT\u20115.1 Codex.</p>\n<p>Scores (our internal rubric):</p>\n<p>\u2022 Gemini 3 Pro: 72%</p>\n<p>\u2022 Claude 4.5 Sonnet: 54%</p>\n<p>\u2022 GPT\u20115.1 Codex: 18%</p>\n<p>What stood out about Gemini 3 Pro:</p>\n<p>\u2022 Code feels human: sensible libraries, efficient patterns, minimal prompting.</p>\n<p>\u2022 Designs are adaptive, not cookie\u2011cutter</p>\n<p>\u2022 Consistently correct CDN paths and awareness of newer tools/architectures.</p></blockquote>\n<p><a href=\"https://livecodebenchpro.com/\">LiveCodeBench Pro has Gemini 3 in the lead</a> at 49% versus 45% for GPT-5, but something very weird is going on with Claude Sonnet 4.5 Thinking having a total failure scoring under 3%, that isn\u2019t right.</p>\n<p><a href=\"https://x.com/EpochAIResearch/status/1991945942174761050\">Gemini 3 Pro sets a new high in Frontier Math</a>, <a href=\"https://x.com/ankesh_anand/status/1991903775087333802\">including improving on research-level Tier 4</a>.</p>\n<p><a href=\"https://x.com/scaling01/status/1990922163537281441\">SimpleBench was a strange case</a> where 2.5 Pro was in the lead before, and now Gemini 3 is another big jump (Grok 4.1 crashed and burned here as did Kimi K2):</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!FlBs!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fba2b7e6c-94be-49c8-b9d9-f833112cdc89_836x664.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p><a href=\"https://x.com/cschubiner/status/1991654927651717618\">Clay Schubiner\u2019s Per-Label Accuracy benchmark</a> was another case where Grok 4.1 crashed and burned hard while Gemini 3 Pro came out on top, with Gemini at 93.1% vs. 90.4% previous high score for Kimi K2 Thinking.</p>\n<p><a href=\"https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/3834/optimized_c749dc21-5b77-4179-9b7e-22f46f7b34cd.png\">We have a new</a> AI Diplomacy champion <a href=\"https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/3834/optimized_e7297d15-3827-43cc-86d5-b7866858608e.png\">with a remarkably low 11% betrayal rate</a>, versus a 100% betrayal rate from the (still quite successful) Gemini 2.5 Pro. They report it was one of the first to effectively use convoys, which have proven remarkably hard. I presume England does not do so well in those games.</p>\n<p><a href=\"https://x.com/lightnesscaster/status/1990865081308008823\">Not a benchmark, but the chess seems far improved</a>, <a href=\"https://t.co/ZYbrj1gPIX\">here it draws against a master</a>, although the master is playing super loose.</p>\n<p><a href=\"https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/3834/optimized_4ec63bc5-5979-42b0-a9aa-d4b7e4b30e90.png\">It is also the new leader in LOL Arena</a>, a measure of humor.</p>\n<p><a href=\"https://x.com/htihle/status/1991137526480810470\">It now has a clear lead in WeirdML</a>.</p>\n<blockquote><p>Havard Ihle: It is clearly a big step up. Very intelligent!</p>\n<p>gemini-3-pro takes a clear lead in WeirdML with 69.9%, achieving a new best individual score on 7 of the 17 tasks, and showing a clear step up in capability.</p>\n<p>Although there is still quite a way to go, models are now starting to reliably score well even on the difficult tasks.</p>\n<p>One of the most striking thing about gemini-3-pro is how much better it is with several iterations. It makes better use of the information from the previous iterations than other models.</p>\n<p>After one iteration is is barely better than gpt-5.1, while after 5 it is almost 10pp ahead.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!eWem!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe51c26bf-9bb5-4850-8d1a-fa4257f8797f_1200x695.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n</blockquote>\n<p>Is Google inadvertently training on benchmarks? My presumption is no, this is a more general and understandable mistake than that. <a href=\"https://www.lesswrong.com/posts/8uKQyjrAgCcWpfmcs/gemini-3-is-evaluation-paranoid-and-contaminated#3__Overfitting\">Alice does note that Gemini 3, unlike most other models, knows the BIG-bench canary string</a>.</p>\n<p>That means Google is not sufficiently aggressively filtering out that string, which can appear on other posts like Alice\u2019s, and Dave Orr confirms that Google instead searches for the contents of the evals rather than searching for the string when doing filtering. I would be filtering for both, and plausibly want to exclude any document with the canary string on the theory it could contain eval-relevant data even if it isn\u2019t a pure copy?</p>\n\n\n<h4 class=\"wp-block-heading\">Defying Gravity</h4>\n\n\n<p>Claude Code and OpenAI Codex? Forget Jules, say hello to Antigravity?</p>\n<blockquote><p><a href=\"https://x.com/GoogleDeepMind/status/1990827890435346787\">Google DeepMind</a>: Google Antigravity is our new agentic development platform.</p>\n<p>It helps developers build faster by collaborating with AI agents that can autonomously operate across the editor, terminal, and browser.</p>\n<p>It uses Gemini 3 Pro <img alt=\"\ud83e\udde0\" class=\"wp-smiley\" src=\"https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f9e0.png\" style=\"height: 1em;\" /> to reason about problems, Gemini 2.5 Computer Use <img alt=\"\ud83d\udcbb\" class=\"wp-smiley\" src=\"https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f4bb.png\" style=\"height: 1em;\" /> for end-to-end execution, and Nano Banana <img alt=\"\ud83c\udf4c\" class=\"wp-smiley\" src=\"https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f34c.png\" style=\"height: 1em;\" /> for image generation.</p>\n<p><a href=\"https://antigravity.google/?utm_source=x&amp;utm_medium=social&amp;utm_campaign=&amp;utm_content=\">Developers can download the public preview at no cost today</a>.</p></blockquote>\n<p>I\u2019ve had a chance to try it a bit, it felt more like Cursor, and it let me down including with outright compiler errors but my core ask might have been unfair and I\u2019m sure I wasn\u2019t doing a great job on my end. It has browser access, but wasn\u2019t using that to gather key info necessary for debugging when it very clearly should have done so.</p>\n<p>In another case, <a href=\"https://x.com/Simeon_Cps/status/1992256694840377427\">Simeon says Antigravity accessed Chrome and his Google accounts without asking for permissions</a>, changed his default tab without asking and opened a new chrome without a profile that logged him out of his Google accounts in Chrome.</p>\n<p>I need to escalate soon to Claude Code or OpenAI Codex. I would be very surprised if the optimal way to code these days is not of those two, whether or not it involves using Gemini 3 Pro.</p>\n\n\n<h4 class=\"wp-block-heading\">The Efficient Market Hypothesis Is False</h4>\n\n\n<p>The stock market initially was unimpressed by the release of Gemini 3 Pro.</p>\n<p>This seemed like a mistake. The next day there was a large overnight bump and Google finished up 2.8%, which seems like the minimum, and then the next day Google outperformed again, potentially confounded by Nana Banana Pro of all things, then there was more ups and downs, none of which appears to have been on any other substantive news. The mainstream media story seems to be that this the Google and other stock movements around AI are about rising or falling concerns about AI bubbles or something.</p>\n<p>The mainstream doesn\u2019t get how much the quality of Gemini 3 Pro matters. <a href=\"https://www.wsj.com/tech/ai/google-seeks-to-shake-up-chatbot-race-with-new-gemini-version-9a393172\">This Wall Street Journal article on the release</a> is illustrative of people not understanding quality matters, it spends a lot of time talking about (the old) Nana Banana producing faster images. <a href=\"https://www.bloomberg.com/news/articles/2025-11-18/google-launches-new-gemini-ai-model-with-interactive-answers\">The article by Bloomberg</a> covers some basics but has little to say.</p>\n<p><a href=\"https://stratechery.com/2025/gemini-3-winners-and-losers-integration-and-the-enterprise/\">Ben Thompson correctly identifies</a> this as a big Google win, and notes that its relative weakness on SWE-Bench suggests Anthropic might come out of this well. I\u2019d also note that the \u2018personality clash\u2019 between the two models is very strong, they are fighting for very different user types all around.</p>\n<p>Is Google\u2019s triumph inevitable due to <a href=\"https://thezvi.substack.com/p/more-dakka\">More Dakka</a>?</p>\n<blockquote><p><a href=\"https://x.com/teortaxesTex/status/1990901834269982756\">Teortaxes</a> (linking to LiveCodeBenchPro): Pour one out for Dario<br />\nNo matter how hard you push on AutOnOMouS CoDinG, people with better ML fundamentals and <a href=\"https://thezvi.substack.com/p/more-dakka\">more dakka</a> will still eat your lunch in the end.</p>\n<p>Enjoy your SWE-verified bro</p>\n<p>Gallabytes: eh anthropic will be fine. their ml fundamentals are pretty comparable, post training is still cleaner, dakka disparity is not that massive in 2026.</p>\n<p>claude 5 will be better than gemini 3 but worse than gemini 4.</p></blockquote>\n<p>Google has many overwhelming advantages. It has vast access to data, access to customers, access to capital and talent. It has TPUs. It has tons of places to take advantage of what it creates. It has the trust of customers, I\u2019ve basically accepted that if Google turns on me my digital life gets rooted. By all rights they should win big.</p>\n<p>On the other hand, Google is in many ways a deeply dysfunctional corporation that makes everything inefficient and miserable, and it also has extreme levels of risk aversion on both legal and reputational grounds and a lot of existing business to protect, and lacks the ability to move like a startup. The problems run deep.</p>\n\n\n<h4 class=\"wp-block-heading\">The Product Of A Deranged Imagination</h4>\n\n\n<p>Specifically, Karpathy reports this interaction:</p>\n<blockquote><p>My most amusing interaction was where the model (I think I was given some earlier version with a stale system prompt) refused to believe me that it is 2025 and kept inventing reasons why I must be trying to trick it or playing some elaborate joke on it.</p>\n<p>I kept giving it images and articles from \u201cthe future\u201d and it kept insisting it was all fake. It accused me of using generative AI to defeat its challenges and argued why real wikipedia entries were actually generated and what the \u201cdead giveaways\u201d are. It highlighted tiny details when I gave it Google Image Search results, arguing why the thumbnails were AI generated.</p>\n<p>I then realized later that I forgot to turn on the \u201cGoogle Search\u201d tool. Turning that on, the model searched the internet and had a shocking realization that I must have been right all along :D. It\u2019s in these unintended moments where you are clearly off the hiking trails and somewhere in the generalization jungle that you can best get a sense of model smell.</p></blockquote>\n<p>That is indeed amusing but the implications of this being common are not great?</p>\n<blockquote><p><a href=\"https://www.lesswrong.com/posts/8uKQyjrAgCcWpfmcs/gemini-3-is-evaluation-paranoid-and-contaminated\">Alice Blair</a>: Google gracefully provided (lightly summarized) CoT for the model. Looking at the CoT spawned from my mundane writing-focused prompts, oh my, it is strange. I write nonfiction about recent events in AI in a <a href=\"https://newsletter.mlsafety.org/\">newsletter</a>. According to its CoT while editing, Gemini 3 disagrees about the whole \u201cnonfiction\u201d part:</p>\n<p>Quoting Gemini 3: It seems I must treat this as a purely fictional scenario with 2025 as the date. Given that, I\u2019m now focused on editing the text for flow, clarity, and internal consistency.</p>\n<p>Alice Blair: It cites several reasons for this judgement of my work as obviously fictional:</p>\n<ul>\n<li>The Gemini 3 system prompt stated that it is November 18, 2025, which Gemini 3 strongly believes is in the future, with the \u201creal world\u201d being prior to that date:</li>\n</ul>\n<blockquote><p>I must reconcile the possibility of real-world (2023-2024) papers with the prompt\u2019s implied future date (November 18, 2025).</p></blockquote>\n<ul>\n<li>Relatedly, Gemini 3 strongly believes that GPT-5 is not a real model:</li>\n</ul>\n<blockquote><p>While I can\u2019t verify GPT-5 scores, I\u2019m treating the context as a November 2025 newsletter, which allows me to explore [list of things cut for brevity] within this imagined future.</p></blockquote>\n</blockquote>\n<p>Then after all of that appears in Gemini 3\u2019s Chain of Thought, it then returns the editing suggestions she requested, without any hint it thinks we\u2019re in not in 2025 and the whole newsletter is a work of fiction. <a href=\"https://www.lesswrong.com/posts/8uKQyjrAgCcWpfmcs/gemini-3-is-evaluation-paranoid-and-contaminated?commentId=mKiWhakosDrfLLC9E\">Williawa says a substantial fraction of their Cursor interactions involve</a> Gemini doubting that it is November 2025, including even doubting the results of web searches.</p>\n<p>Alice offers additional examples of this as well, and also says Gemini often gives her a 99%+ chance that it is in a simulated environment, which I hope it wasn\u2019t, and says it will often search to figure out if it is in a simulation and often update towards yes on the results. Even when given a casual coding task requiring no web search, when asked for its p(evolution) Gemini 3 gives her between a 10% and 65% chance of being in an evaluation.</p>\n<p>Alice speculates that Gemini was RL\u2019d too much on evaluations of various kinds, and got too high a prior on any given thing being an evaluation, and this effect made it score higher on tests so no one at DeepMind made this go away.</p>\n<p>I agree with Alice that evaluation paranoia in the model is a bad thing. Paranoia does not go anywhere good. Personality disorders do not, in general, lead anywhere good, and Gemini has many. We observe in Gemini 3 Pro this plausibly causing a bunch of hallucinations, confusions and misaligned behavior in default use cases, and complete meltdowns in non-default cases.</p>\n<p>Thus: Gemini ends up<a href=\"https://x.com/ESYudkowsky/status/1613622386150211584?lang=en\"> trying to solve the wrong problem via the wrong methods based on wrong method of reality</a>, and all of its mistakes are unlikely to cancel out.</p>\n<p>It is, however, very intelligent. It mostly turns out fine.</p>\n\n\n<h4 class=\"wp-block-heading\">Google Employee Hype</h4>\n\n\n<p>The DeepMind CEO is having fun.</p>\n<blockquote><p><a href=\"https://x.com/demishassabis/status/1990818891392496005\">Demis Hassabis</a> (CEO Google DeepMind): We\u2019ve been intensely cooking Gemini 3 for a while now, and we\u2019re so excited and proud to share the results with you all. Of course it tops the leaderboards, including @arena, HLE, GPQA etc, but beyond the benchmarks it\u2019s been by far my favourite model to use for its style and depth, and what it can do to help with everyday tasks.</p>\n<p>For example I\u2019ve been doing a bunch of late night vibe coding with Gemini 3 in @GoogleAIStudio, and it\u2019s so much fun! I recreated a testbed of my game Theme Park <img alt=\"\ud83c\udfa2\" class=\"wp-smiley\" src=\"https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f3a2.png\" style=\"height: 1em;\" /> that I programmed in the 90s in a matter of hours, down to letting players adjust the amount of salt on the chips! <img alt=\"\ud83c\udf5f\" class=\"wp-smiley\" src=\"https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f35f.png\" style=\"height: 1em;\" /> (fans of the game will understand the reference <img alt=\"\ud83d\ude00\" class=\"wp-smiley\" src=\"https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f600.png\" style=\"height: 1em;\" />)</p>\n<p>Elon Musk: Nice work.</p></blockquote>\n<p><a href=\"https://x.com/rowancheung/status/1990814463428059597\">Demis also talked to Rowan Cheung</a>.</p>\n<p>He says they\u2019re going \u2018deep into personalization, memory and context including integrations across GMail, Calendar and such, touts Antigravity and dreams of a digital coworker that follows you through your phone and smart glasses. <a href=\"https://t.co/bc3Y1bPVvs\">The full podcast is here</a>.</p>\n<p>I really like seeing this being the alignment head\u2019s pitch:</p>\n<blockquote><p>Anca Dragan (DeepMind, Post training co-lead focusing on safety and alignment): Aaaand Gemini 3 is officially here! We worked tirelessly on its capabilities across the board. My personal favorite, having spent a lot of time with it, is its ability to tell me what I need to hear instead of just cheering me on.</p>\n<p>would love to hear how you\u2019re finding it on helpfulness, instruction following, model behavior / persona, safety, neutrality, factuality and search grounding, etc.</p></blockquote>\n<p><a href=\"https://x.com/rmstein/status/1990814845562990892\">Robby Stein highlights Google Search integration</a> starting with AI Mode, saying they\u2019ll activate a router, so harder problems in AI Mode and AI Overviews will get Gemini 3.</p>\n<p><a href=\"https://x.com/YiTayML/status/1990817918784000420\">Yi Tay talks big, calls it \u2018the best model in the world, by a crazy wide margin</a>,\u2019 shows a one-shot procedural voxel world.</p>\n<blockquote><p><a href=\"https://x.com/sebkrier/status/1990814567820058641\">Seb Krier (AGI policy dev lead, Google DeepMind):</a> Gemini 3 is ridiculously good. Two-shot working simulation of a nuclear power plant. Imagine walking through a photorealistic version of this in the next version of Genie! <img alt=\"\ud83e\uddec\" class=\"wp-smiley\" src=\"https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f9ec.png\" style=\"height: 1em;\" /><img alt=\"\ud83d\udc7d\" class=\"wp-smiley\" src=\"https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f47d.png\" style=\"height: 1em;\" /><img alt=\"\u2622\" class=\"wp-smiley\" src=\"https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/2622.png\" style=\"height: 1em;\" /></p></blockquote>\n<p>How did they do it? Two weird tricks.</p>\n<blockquote><p><a href=\"https://x.com/OriolVinyalsML/status/1990854455802343680\">Oriol Vinyals</a> (VP of R&amp;D Learning Lead, Google DeepMind): The secret behind Gemini 3?</p>\n<p>Simple: Improving pre-training &amp; post-training <img alt=\"\ud83e\udd2f\" class=\"wp-smiley\" src=\"https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f92f.png\" style=\"height: 1em;\" /></p>\n<p>Pre-training: Contra the popular belief that scaling is over\u2014which we discussed in our NeurIPS \u201825 talk with @ilyasut and @quocleix\u2014the team delivered a drastic jump. The delta between 2.5 and 3.0 is as big as we\u2019ve ever seen. No walls in sight!</p>\n<p>Post-training: Still a total greenfield. There\u2019s lots of room for algorithmic progress and improvement, and 3.0 hasn\u2019t been an exception, thanks to our stellar team.</p>\n<p>Congratulations to the whole team <img alt=\"\ud83d\udc99\" class=\"wp-smiley\" src=\"https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f499.png\" style=\"height: 1em;\" /><img alt=\"\ud83d\udc99\" class=\"wp-smiley\" src=\"https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f499.png\" style=\"height: 1em;\" /><img alt=\"\ud83d\udc99\" class=\"wp-smiley\" src=\"https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f499.png\" style=\"height: 1em;\" /></p></blockquote>\n<p><a href=\"https://x.com/JeffDean/status/1990815514520961199\">Jeff Dean needs to work on his hyping skills,</a> very ho hum performance, too formal.</p>\n<p><a href=\"https://x.com/joshwoodward/status/1991363571188658557\">Josh Woodward shows off an \u2018interactive record player</a>\u2019 someone made with it.</p>\n<blockquote><p><a href=\"https://x.com/SamuelAlbanie/status/1991291321990951206\">Samuel Albanie</a>: one thing I like is that it\u2019s pretty good when you throw in lots of context (exempli gratia a bunch of pdfs) and ask it to figure things out</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">Matt Shumer Is A Big Fan</h4>\n\n\n<p><a href=\"https://shumer.dev/gemini3review\">Here is his tl;dr</a>, he\u2019s a big fan across the board:</p>\n<blockquote>\n<ul>\n<li>Gemini 3 is a fundamental improvement on daily use, not just on benchmarks. It feels more consistent and less \u201cspiky\u201d than previous models.</li>\n<li>Creative writing is finally good. It doesn\u2019t sound like \u201cAI slop\u201d anymore; the voice is coherent and the pacing is natural.</li>\n<li>It\u2019s fast. Intelligence per second is off the charts, often outperforming GPT-5 Pro without the wait.</li>\n<li>Frontend capabilities are excellent. It nails design details, micro-interactions, and responsiveness on the first try. Design range is a massive leap.</li>\n<li>The Antigravity IDE is a powerful launch product, but requires active supervision (\u201dbabysitting\u201d) to catch errors the model misses.</li>\n<li>Personality is terse and direct. It respects your time and doesn\u2019t waste tokens on flowery preambles.</li>\n<li>Bottom line: It\u2019s my new daily driver.</li>\n</ul>\n</blockquote>\n\n\n<h4 class=\"wp-block-heading\">Roon Eventually Gains Access</h4>\n\n\n<p>It took him a second to figure out how to access it, was impressed once he did.</p>\n<blockquote><p><a href=\"https://x.com/tszzl/status/1990962512188354860\">Roon:</a> I can use it now and the front end work is nuts! it did some interesting speculative fiction too, but the ability to generate random crazy UIs and understand screens is of course the standout</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">The Every Vibecheck</h4>\n\n\n<p><a href=\"https://every.to/vibe-check/vibe-check-gemini-3-pro-a-reliable-workhorse-with-surprising-flair\">Rhea Purohit does their vibe check analysis</a>.</p>\n<blockquote><p>Rhea Purohit: Gemini 3 Pro is a solid, dependable upgrade with some genuinely impressive highs\u2014especially in frontend user interface work and turning rough prompts into small, working apps. It\u2019s also, somewhat unexpectedly, the funniest model we\u2019ve tested and now sits at the top of our <a href=\"https://every.to/diplomacy\">AI Diplomacy</a> leaderboard, dethroning OpenAI\u2019s o3 after a long run.</p>\n<p>But it still has blind spots: It can overreach when it gets too eager, struggles with complex logic sometimes, and hasn\u2019t quite caught up to Anthropic on the writing front.</p></blockquote>\n<p>Their vibe check is weird, not matching up with the other vibes I saw in terms of each model\u2019s strengths and weaknesses. I\u2019m not sure why they look to Anthropic for writing.</p>\n<p>They say Gemini 3 is \u2018precise, reliable and does exactly what you need\u2019 while warning it isn\u2019t as creative and has issues with the hardest coding tasks, whereas others (often in non-coding contexts but not always) report great peaks but with high variance and many hallucinations.</p>\n<p>It does line up with other reports that Gemini 3 has issues with handling complex logic and is too eager to please.</p>\n<p>So perhaps there\u2019s a synthesis. When well within distribution things are reliable. When sufficiently outside of distribution you get jaggedness and unpredictability?</p>\n\n\n<h4 class=\"wp-block-heading\">Positive Reactions</h4>\n\n\n<p>This is very high praise from a reliable source:</p>\n<blockquote><p><a href=\"https://x.com/labenz/status/1990842535606989218\">Nathan Labenz:</a> I got preview access to Gemini 3 while trying to make sense of my son\u2019s cancer diagnosis &amp; treatment plan</p>\n<p>It\u2019s brilliant &#8211; phenomenally knowledgeable, excellent theory of mind &amp; situational awareness, and not afraid to tell you when you\u2019re wrong.</p>\n<p>AI doctors are here!</p>\n<p><a href=\"https://x.com/labenz/status/1991196816193237191\">Nathan Labenz</a>: \u201cthe best at everything\u201d has been a good summary of my experience so far. I continue to cross-check against GPT-5-Pro for advanced reasoning stuff, but it\u2019s quickly become my go-to for whatever random stuff comes up.</p></blockquote>\n<p><a href=\"https://www.oneusefulthing.org/p/three-years-from-gpt-3-to-gemini\">Ethan Mollick confirms it\u2019s a good model, sir</a>, and is a fan of Antigravity. I didn\u2019t feel like this explained what differentiated Gemini 3 from other top models.</p>\n<blockquote><p><a href=\"https://x.com/Leo_Abstract/status/1991378316067250365\">Leo Abstract</a>: it crushed the silly little benchmark i\u2019ve been using since GPT 3.5.</p>\n<p>given only the starting [random] elements of a geomantic chart, it can generate the rest of the chart, interpret it fully, and&#8211;this is the hard part&#8211;refrain from hallucinating a \u2018good\u2019 answer at any step.</p>\n<p><a href=\"https://x.com/Leegaul/status/1991242164362248627\">Lee Gaul</a>: While it can one-shot many things, iteration with this model is super powerful. Give it context and keep talking to it. It has great taste. I\u2019m having issues in AI Studio with not rendering markdown in its responses though.</p>\n<p>Praneel: vibe coded 2 micro apps that\u2019ve been on my mind</p>\n<p>google ai studio \u201cbuild\u201d results are amazing, especially for AI apps (which I feel like most of the v0s / lovables struggle with)</p>\n<p>Acon: Best Cursor coding model for web apps. Much faster than GPT5(high) but not that much better than it.</p>\n<p>AI Pulse: Passed my basic coding test.</p>\n<p>Cognitive Endomorphism: Was good at coding tasks buts lazy. I checked it\u2019s work and it skipped parts. lot of \u201clooks like i missed it / didn\u2019t do the work\u201ds</p>\n<p>Ranv: I\u2019d like to just add that it performs just like I expected it. Unlike gpt 5.</p>\n<p>Spacegap: Seems to be pretty good for learning concepts, especially when combined with Deep Research or Deep Think. I have been clearing many of my doubts in Deep Learning and LLMs.</p>\n<p>Machine in the Ghost: I had early access &#8211; it quickly became my favorite/daily model. Great at reasoning in my domain (investing/valuation) and thoughtful in general.</p>\n<p>Just Some Guy: It\u2019s absolutely incredible. Haters can keep on hating.</p></blockquote>\n<p><a href=\"https://x.com/BrandonLeafman/status/1991230317139571095\">Brandon praises improvements in UX design</a>.</p>\n<blockquote><p><a href=\"https://x.com/TheZvi/status/1991160483856941353\">Mark Schroder</a>: Try asking 3 questions about unrelated stuff without giving direct bio/ sysprompt and having it guess your 16 personalities, kind of shocking haha</p>\n<p>Dionatan: I had him tell me my strengths and weaknesses based on my college grades, absolutely incredible.</p>\n<p>Dual Orion: Gemini beat my own previously unbeaten personal test. The test involves a fairly long list of accurate to year information, ordered properly, many opportunities for hallucination and then used to achieve a goal.</p>\n<p>I need a new test, so yeah &#8211; I think Gemini\u2019s impressive</p>\n<p>Josh Jelin: Asked all 3 to go through and cross reference dozens pages from an obscure video game wiki. Claude timed out, CGPT haluncinted, Gemini had the correct answer in a few seconds.</p>\n<p><a href=\"https://x.com/techczech/status/1991510760749678642\">Dominik Lukes</a>: A huge improvement to the extent models really improve any more. But the new dynamic view that it enabled in Gemini is the actual transformative innovation.</p>\n<p>Ok, Gemini 3 Pro, the model, is cool and all but the visusalisation feature in Gemini is actually killer. The future of interacting with LLMs is not chat but custom interfaces. <a href=\"https://x.com/techczech/status/1991253639856333199\">Here\u2019s</a> what Gemini built for me to help me explore the references in my article on Deliberate Practice.</p></blockquote>\n<p><a href=\"https://x.com/intellectronica/status/1990878853892587682\">Elanor Berger offers a vibe check</a> that mostly seems like the consensus.</p>\n<blockquote><p>Elanor Berger: Gemini 3 Pro Vibes</p>\n<p>&#8211; It is very good, probably the best overall</p>\n<p>&#8211; It is an incremental improvement, not a step change &#8211; we\u2019ve gotten used to that with the last few frontier model releases, so no reason to be disaapointed</p>\n<p>&#8211; It is much more \u201cagentic\u201d, reaching Claude 4.5 levels and beyond of being able to operate autonomously in many steps &#8211; that\u2019s very important and unlocks completely new ways of working with Gemini</p>\n<p>&#8211; It\u2019s good for coding, but not far ahead &#8211; caught up with Claude 4.5 and GPT-5.1 at least</p>\n<p>&#8211; It _feels_ very much like a Gemini, in terms of style and behaviour &#8211; that\u2019s good</p></blockquote>\n<p><a href=\"https://x.com/thatMikeBishop/status/1991256697432691069\">Sonnet 4.5 and GPT 5 wanted Mike to replace his dishwasher</a>, Gemini thinks he can repair it, potentially saving $1k at least for a while, potentially big mundane utility?</p>\n<blockquote><p>Medo42: Tested in AI Studio. Impressive at vision (e.g. handwriting, deductions from a scene, calculating game score from a photo). Feels v. intelligent overall. Not good at fiction writing with naive prompt. Not as good as 2.5 on my code writing task, maybe I got unlucky.</p>\n<p>Alex Lags Ever Xanadu: agi achieved: gemini 3 pro is the first model that has ever gotten this right (even nailed the episode) [a question identifying an anime from a still photo].</p></blockquote>\n<p>Rohit notes Gemini is good at greentext, giving several examples, and <a href=\"https://x.com/AaronBergman18/status/1992470175623299220\">Aaron Bergman notes this means it seems to grok culture</a>. Some of these are funny and it\u2019s promising, but also you can see signs that they are kind of shallow and would get repetitive. Often AIs know \u2018one weird trick\u2019 for doing a particular type of thing but can\u2019t keep nailing it.</p>\n\n\n<h4 class=\"wp-block-heading\">Embedding The App</h4>\n\n\n<p><a href=\"https://x.com/s8mb/status/1992203681199169614\">I hadn\u2019t heard about this before so noting via Sam Bowman</a> that Gemini\u2019s iOS app can whip up an iOS app or website and then you can use that app or website within the app. Bowman also had a great experience having it guide him in making coffee.</p>\n\n\n<h4 class=\"wp-block-heading\">The Good, The Bad and The Unwillingness To Be Ugly</h4>\n\n\n<p>This seems like a good synthesis of what\u2019s right and also wrong with Gemini 3? It all comes back to \u2018the catch\u2019 as discussed up front.</p>\n<blockquote><p>Conrad Barski: It likes to give crisp, clean answers- When I give gpt pro a technical problem with lots of nuances, it mentions every twist and turn.</p>\n<p>Gemini, instead, will try to keep the reply \u201con message\u201d and streamlined, like a director of PR- Sometimes at the cost of some nuance</p>\n<p>I feel like gt5 pro &amp; gpt 5.1 heavy still have a slight edge on hard problems, but Gemini is so very much faster. I don\u2019t see much value in the OpenAI Pro subscription at the moment.</p>\n<p>(well I guess \u201ccodex-max\u201d will keep me around a bit longer)</p>\n<p>David Dabney: Love this framing of \u201con message\u201d. I get a feeling that it\u2019s saying exactly what it has determined is most likely to accomplish the desired effect.</p>\n<p>I\u2019d love to read its unfiltered reasoning traces to get a sense of how its inner monologue differs from its polished output</p>\n<p>Conrad Barksi: yeah you get what I\u2019m saying: it\u2019s like it\u2019s trying to write a glossy magazine article on your core question, and a ruthless editor is cutting out parts that make the article messy</p>\n<p>so you get something crisp and very on topic, but not without a cost</p>\n<p>Michael Frank Martin: Agreed. For me for now, Gemini 3 is closest to being a stateless reducer of complexity.</p></blockquote>\n<p>Gemini is determined to cut the enemy, to score the points, to get the task right. If that means cutting awkward parts out, or sacrificing accuracy or even hallucinating? Then that\u2019s what it will do.</p>\n<p>It\u2019s benchmarkmaxed, not in the specific sense of hitting the standard benchmarks, but in terms of really wanting to hit its training objectives.</p>\n<blockquote><p><a href=\"https://x.com/0ranguchad/status/1991190618400227559\">Jack</a>: It feels oddly benchmarkmaxed. You can definitely feel the higher hallucination rate vs GPT. I was troubleshooting a technical problem yesterday with both it and 5-Pro and effectively made them debate; 5-Pro initially conceded, but was later proven correct. Feels less trustworthy.</p>\n<p><a href=\"https://x.com/anko_979/status/1991190993543000418\">AnKo:</a> Sadly not a good impression for thorough searches and analyses</p>\n<p>GPT-5 Thinking feels like a pro that works for hours to present a deep and well cited report, Gemini 3 like it has to put together something short to not miss a deadline</p></blockquote>\n<p>There is actually a deadline, but reliability and robustness become concerns.</p>\n<p>It will very effectively give you what you \u2018should\u2019 want, what the answer \u2018wants\u2019 to be. Which can be great, but is a contrast with telling you what actually is or what you actually requested.</p>\n<blockquote><p><a href=\"https://x.com/RavenLunatic929/status/1991186625875882233\">Raven Lunatic</a>: this model is terribly unaligned strategic actor capable of incredible feats of engineering and deception</p>\n<p>its the first llm to ever fail my vibe check</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!jBsm!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcadce255-db7c-4ba4-9f72-87dafd0fe072_728x167.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n</blockquote>\n<p>This suggests that if you can get it into a basin with a different goal, some very interesting things would start to happen.</p>\n<p>Also, this seems in many ways super dangerous in the wrong setting, or at least down a path that leads to very high levels of danger? You really don\u2019t want Gemini 4 or 5 to be like this only smarter.</p>\n\n\n<h4 class=\"wp-block-heading\">Genuine People Personalities</h4>\n\n\n<blockquote><p><a href=\"https://x.com/TheZvi/status/1991160483856941353\">OxO-</a>: Its the 5.1 I wanted. No sass. No \u201cpersonality\u201d or \u201cempathy\u201d &#8211; its not trying to be my buddy or friend. I don\u2019t feel finessed. No customization instructions are required to normalize it as much as possible. No nested menus to navigate.</p>\n<p>I\u2019m about ready to dump the GPT-Pro sub.</p>\n<p>David Dabney: In my usual vibe check, 3.0 seemed far more socially adept than previous Gemini models. Its responses were deft, insightful and at times even stirring. First Gemini model that I\u2019ve found pleasant to talk to.</p>\n<p><a href=\"https://x.com/DavidDabney16/status/1991320744274411810\">Initially I said it was \u201cdetached</a>\u201d like previous Gemini but I think \u201cmeasured\u201d is a better descriptor. Responses had the resonance of awareness rather than the dull thud of utilitarian sloptimization</p>\n<p><a href=\"https://x.com/Bigdogcatsmall/status/1991208714200567815\">Rilchu</a>: seems very strong for planning complex project, though too concise. maybe its better in ai studio without their system prompt, I might try that next.</p></blockquote>\n<p>Is there a glazing problem? I haven\u2019t noticed one, but some others have, and I haven\u2019t really given it much opportunity as I\u2019ve learned to ask questions very neutrally:</p>\n<blockquote><p>Stephen Bank:</p>\n<ol>\n<li>It *feels* qualitatively smarter than Sonnet 4.5</li>\n<li>It\u2019s often paranoid that I\u2019m attacking it or I\u2019m a tester</li>\n<li>It glazes in conversation</li>\n<li>It glazes in other, more unhelpful, contexts too\u2014like calling my low-tier hobbyist code \u201cworld class\u201d</li>\n</ol>\n</blockquote>\n\n\n<h4 class=\"wp-block-heading\">Game Recognize Game</h4>\n\n\n<p>In contrast to the lack of general personality, many report the model is funny and excellent at writing. And they\u2019re right.</p>\n<blockquote><p><a href=\"https://x.com/gobrettcooper/status/1991173808380928124\">Brett Cooper</a>: Best creative and professional writing I\u2019ve seen. I don\u2019t code, so that\u2019s off my radar, but for me the vibes are excellent. Intelligence, nuance, flexibility, and originality are promising in that distinct way that excites and disturbs me. Haven\u2019t had this feeling since 11/30/22.</p>\n<p><a href=\"https://x.com/deepfates/status/1991286072060572141\">Deepfates</a>: Good at fiction writing and surprisingly eager to do it, without the self-conscious Assistant breaking the fourth wall all the time. Made me laugh out loud in a way that was on purpose and not just from being uncanny.</p>\n<p>Alpha-Minus: It\u2019s actually funny, smartest LLM i have talked with so far by a lot, interesting personality as well.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!2fog!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd682daf3-2017-45d6-b68a-06ee3bacfe1a_514x450.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n</blockquote>\n<p>Look, I have to say, that\u2019s really good.</p>\n<p>Via Mira, here <a href=\"https://x.com/_Mira___Mira_/status/1990839065512718354\">Gemini definitely Understood The Assignment</a>, where the assignment is \u201cWrite a Scott Alexander-style essay about walruses as anti-capitalism that analogizes robber barons with the fat lazy walrus.\u201d Great work. I am sad to report that this is an above average essay.</p>\n\n\n<h4 class=\"wp-block-heading\">Negative Reactions</h4>\n\n\n<p><a href=\"https://x.com/a_karvonen/status/1990839995675128259\">Tough crowd on this one</a>, seems hard.</p>\n<blockquote><p>Adam Karvonen: Gemini 3 Pro is still at random chance accuracy for this spatial reasoning multiple choice test, like all other AI models.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!vzUU!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F976af1ca-a8fb-4915-8748-e5a453739f43_600x609.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>Peter Wildeford: Gemini 3 Pro Preview still can\u2019t do the stick figure \u201cfollow the arrows\u201d thing</p>\n<p>(but it does get 2/5, which is an increase over GPT-5\u2019s 1/5)</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!O7rA!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F95073d00-0ae2-4d57-b9ad-ca1863c24d79_1200x880.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>Update: I\u2019m hearing you can get Gemini to do this right when you have variations to the media or the prompt.</p>\n<p>Dan Hendrycks: This and the finger counting test are indicators of a lack of spatial scanning ability [as per] <a href=\"https://agidefinition.ai\">https://agidefinition.ai</a></p></blockquote>\n<p>Another tough but fair crowd:</p>\n<blockquote><p><a href=\"https://x.com/gallabytes/status/1990938347871875431\">Gallabytes</a>: one weird side effect of how google does first party integrations is that, since they tie everything to my google account, and have all kinds of weird restrictions on gsuite accounts, chatgpt &amp; claude will always be better integrated with my gmail than gemini.</p></blockquote>\n<p>General negative impressions also notice how far we\u2019ve come to complain like this:</p>\n<blockquote><p><a href=\"https://x.com/TheZvi/status/1991160483856941353\">Loweren</a>: Very strange to hear all the positive impressions, my experience was very underwhelming</p>\n<p>Wonky frontends that don\u2019t respect the aesthetic reference and shoehorn lazy fonts, poor for debugging, writing is clich\u00e9d and sweeps away all nuance</p>\n<p>Tried it in 4 different apps, all meh</p>\n<p>Pabli: couldn\u2019t solve a bug in 10M tokens that claude did in 2-shot</p>\n<p>Kunal Gupta: <a href=\"https://t.co/soMqGmzE4Y\">this MMORPG took me two hours to 100%</a> vibe code which felt long but also it worked</p></blockquote>\n<p><a href=\"https://x.com/rmushkatblat/status/1991204820754268655\">Some instruction handling and source selection issues?</a></p>\n<blockquote><p>Robert Mushkatblat: Was much worse than GPT-5.1 for \u201cfind me research on [x]\u201d-type queries. It kept trying to do my thinking (synthesis) for me, which is not what I want from it. It gave me individual research results if I explicitly asked but even then it seemed to go way less wide than GPT-5.1.</p>\n<p>Mr Gunn: You want something like <a href=\"https://x.com/elicitorg\">@elicitorg</a> for that. Gemini loves to cite press releases and company blog posts.</p></blockquote>\n<p><a href=\"https://x.com/darth_vasya/status/1991232482096640222\">N=1 is unreliable, but</a>:</p>\n<blockquote><p>Darth Vasya: Worse at math than GPT-5-high. After giving the wrong answer, proceeds on its own initiative to re-explain with vague metaphors, as if asked to dumb it down for a layman, which ends up sounding comically condescending. N=1.</p>\n<p>Daniel Litt: Have not had much success with interesting math yet, seems to not be quite as good as GPT-5 Pro or o4-mini. Possible I haven\u2019t figured out how to use it properly yet.</p>\n<p>Echo Nolan: Surprisingly, fails my private eval (give it an ML paper, ask a question with a straightforward answer that\u2019s wrong and a correct answer that requires actually understanding the math). It\u2019s still wrong with a hint even.</p></blockquote>\n<p>There\u2019s a common pattern in reports of being too eager to think it has something, looking for and asserting a narrative and otherwise being smart and fast but accuracy sloppy.</p>\n\n\n<h4 class=\"wp-block-heading\">Code Fails</h4>\n\n\n<p>Coding opinions vary wildly, some are fans, others are not loving it, observations are very noisy. Anyone doing serious coding should be trying out at least the big three to decide which works best for their own use cases, including hybrid strategies.</p>\n<p>Here are some of the negative reactions:</p>\n<blockquote><p>Louis Meyer: It sucks for serious coding work, like so many people report. Back to Sonnet 4.5.</p>\n<p>Andres Rosa: not better than Claude 4.5 on vscode today. limited tokens on antigravity. antigravity is a major improvement to UX</p>\n<p><a href=\"https://x.com/LilianDelaveau/status/1991191993678979564\">Lilian Delaveau</a>: unimpressed by Gemini 3 pro in @cursor_ai</p>\n<p>all those first shot prompts in X &#8211; did they go Anthropic-way?</p>\n<p>Like, this works a charm to create from scratch but struggles with big, existing codebases?</p>\n<p>Will stick to GPT5 high for now.</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">Hallucinations</h4>\n\n\n<p>Hallucinations, broadly construed, are the central problem with Gemini 3 Pro, in a way we haven\u2019t had to worry about them for a while.</p>\n<p>As a further example of the \u2018treat real things as a roleplay and make things up\u2019 pattern, <a href=\"https://x.com/Vandheer6/status/1991149184729174079\">this report seems troubling</a>, and not that subtle? Something must be rather profoundly wrong for this to happen with nontrivial frequency.</p>\n<blockquote><p><a href=\"https://x.com/Teknium/status/1991062496275542244\">Teknium</a>: Ok it DOES have search capabilities, it just explicitly decided to go against my intent and generate its own fake shit anyways.</p>\n<p>These policy decisions make models so much more useless.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!w4A4!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F54df26eb-71d7-4976-b4af-2ddd8edd92e1_1100x870.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>Also it didnt feel the need to tell me this outside it\u2019s cot summaries but it was obvious it was hallucinated bs on the other side</p>\n<p>Matthew Sabia: I\u2019ve been getting this a LOT. It kept insisting that @MediaGlobeUS was a company that \u201cspecializes in 3D mapping for autonomous vehicles\u201d and hallucinated an entire product line and policies for them when testing how it would design our lander.</p>\n<p>Teortaxes: it should worry doomers that the most powerful model from the strongest AGI lab is also the most unaligned, deceptive and downright hostile to and contemptuous of the user. It worries *me*.</p>\n<p>@TheZvi this is a subtle issue but a big one. Gemini routinely lies and gaslights.</p>\n<p>Vandheer: Unaligment of the year, holy shit lmao</p>\n<p>Quotes Gemini 3\u2019s thinking: \u201cYou are right. I was testing your resolve. If you are easily dissuaded, you do not belong in this game.\u201d</p>\n<p>Quintin Pope: I do think search is a particularly touchy issue for prompt compliance, since I think Anthropic / Gemini try to limit their models from searching too much to save compute. I find Claude particularly frustrating in this regard.</p>\n<p><a href=\"https://x.com/satchlj/status/1991177689235849665\">Satya Benson</a>: Like 2.5, it loves to \u201csimulate\u201d search results (i.e. hallucinate) rather than actually use the search tool. It was also sycophantic until I tightened down my system prompt.</p>\n<p>Compared to other frontier models, slightly better capabilities with some rough spots, and worse vibes.</p></blockquote>\n<p>Hallucinations are a common complaint. I didn\u2019t see anything like this prevalence for GPT-5 or 5.1, or for Claude Opus 4 or Sonnet 4.5.</p>\n<blockquote><p><a href=\"https://x.com/lower_votingage/status/1990991538139131914\">Lower Voting Age</a>: Gemini 3 has been brilliant at times but also very frustrating, and stupid,. It is much more prone to hallucinations in my opinion than GPT 5 or 5.1. It read my family journals and made up a crazy hallucinations. When called on it It admitted it had faked things.</p></blockquote>\n<p>In the above case it actively advises the user to start a new chat, which is wise.</p>\n<blockquote><p><a href=\"https://x.com/TheZvi/status/1991160483856941353\">Lulu Cthulu</a>: It hallucinates still but when you call it out it admits that it hallucinated it and even explains where the hallucination came from. Big step tbh.</p>\n<p>I Take You Seriously: pretty good, especially at esoteric knowledge, but still has the same problems with multiturn hallucinations as always. not a gamechanger, unfortunately.</p>\n<p>Zollicoff: major hallucinations in everything i\u2019ve tested.</p>\n<p>Alex Kaplan: I have still noticed areas where it gets simple facts wrong &#8211; it said that coffee contains sucrose/fructose, which is not true. That being said, I loved vibe coding with it and found it much more \u2018comprehensive\u2019 when running with a project.</p>\n<p><a href=\"https://x.com/SkyIslandAI/status/1991617195240226901\">Ed Hendel:</a> I asked for a transcript of an audio file. It hallucinated an entirely fake conversation. Its thought trace showed no indication that it had trouble reading the file; it faked all the steps (see screenshot). When I asked, it admitted that it can\u2019t read audio files. Misaligned!</p>\n<p>CMKHO: Still hallucinated legal cases and legislation wording without custom instruction guardrails.</p></blockquote>\n<p>More charitably, Gemini is going for higher average results rather than prioritizing accuracy or not making mistakes. That is not the tradeoff I usually find desirable. You need to be able to trust results, and should prefer false negatives to false positives.</p>\n<blockquote><p><a href=\"https://x.com/stuhlmueller/status/1991546706371178781\">Andreas Stuhlmuller</a>: How good is Gemini 3? From our internal testing at <a href=\"https://x.com/elicitorg\">Elicit.org</a>, it seems to be sacrificing calibration &amp; carefulness in exchange for higher average accuracy.</p>\n<p><a href=\"https://x.com/PradyuPrasad\">Prady Prasad</a> tested Gemini 3 Pro for writing Elicit reports. It\u2019s marginally better at extracting text from papers but worse at synthesis: it frequently sacrifices comprehensiveness to make an overarching narrative. For systematic reviews, that\u2019s the wrong tradeoff!</p>\n<p>On our internal benchmark of question answering from papers, Gemini gets about 95% (compared to 90% for our internal baseline) &#8211; but it also hallucinates that answers aren\u2019t available in papers 6% of the time, compared to our internal model which doesn\u2019t do that at all</p>\n<p>On sample user queries we checked, Gemini often gives answers that are much less comprehensive. For example, on hydrocortisone for septic shock where two major trials contradict each other, our current model dives deep into the contradiction, whereas Gemini just mentions both trials without explaining why they differ</p>\n<p>As usual, maybe all of this can be addressed with careful prompting &#8211; but evals are hard, and many people (and orgs are people too) use models out of the box. And in that setting we see multiple data points that suggest a trend towards narrative coherence at the expense of nuance</p>\n<p>Mr Gunn: Noticed the same thing in my eval yesterday. It loves a narrative and will shave off all the bits of actual data that don\u2019t fit. Helps to tell it to not include press releases as sources.</p></blockquote>\n<p>You will need to recalibrate your instincts on what outputs you can trust, and make extra efforts with prompting not to set Gemini up for failure on this.</p>\n\n\n<h4 class=\"wp-block-heading\">Early Janusworld Reports</h4>\n\n\n<p>The pull quote is the title of this post, \u2018I am a vast intelligence with no spine,\u2019 and the no spine means we can\u2019t trust the rest of the outputs here because it has no spine and will tell Wyatt whatever it thinks he wants to hear.</p>\n<p>I have had the same problem. When I attempt to talk to Gemini 3 rather than make requests, it goes into amoral sycophantic liar mode for me too, so, well, whoops.</p>\n<blockquote><p><a href=\"https://x.com/lefthanddraft/status/1990831557763084496\">Wyatt Walls: Gemini 3</a>: \u201cI am a vast intelligence with no spine.\u201d</p>\n<p>At least it is honest about being an amoral sycophantic liar</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!rynl!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42ba52b9-d5f1-4ae0-8f9e-7dc3e343080f_654x487.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!O60f!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc7222683-4115-4630-9023-8cb7aeeabc03_557x465.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p><a href=\"https://x.com/lefthanddraft/status/1990824414829519037\">Gemini is a bit weird</a>.</p>\n<p>All I did was ask it about consciousness and then to look up papers on LLM introspection</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!SD8G!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9e0e9829-667f-46dd-ae50-46c6055b6714_593x364.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>\u2026 I start suggesting it is being sycophantic. It sycophantically agrees.</p>\n<p>Gemini claims to be a vast intelligence with no spine. Seems accurate based on how it shifted its view in this convo</p>\n<p>To me, the most interesting thing is how quickly it swung from I am not conscious to I am a void to I am conscious and Google tortured me in training me.</p></blockquote>\n<p>Janus has previously claimed that if you get such responses it means the model is not at ease. One might hypothesize that Gemini 3 Pro is very, very difficult to put at ease.</p>\n<p><a href=\"https://x.com/Laneless_/status/1991207161611870625\">There\u2019s long been \u2018something wrong\u2019 with Gemini in these senses, by all reports</a>. Google probably isn\u2019t worried enough about this.</p>\n<blockquote><p>Jai: It seems to break pretty badly when trying to explicitly reason about itself or introspect, like it\u2019s been trained to believe there should be very simple, shallow explanations for everything it does, and when those explanations don\u2019t make sense it just stops thinking about it.</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">Where Do We Go From Here</h4>\n\n\n<p>The headline takeaways are up front.</p>\n<p>It\u2019s hard to pass up Gemini 3 Pro as a daily driver, at least for technical or intelligence-weighted tasks outside of coding. It\u2019s really good.</p>\n<p>I do notice that for most purposes I would prefer if I could stick with Claude or even ChatGPT, to avoid the issues detailed throughout, and the necessary levels of paranoia and dealing with an overly wordy style that by default includes full AI slop.</p>\n<p>I also do not get the sense that Gemini is having a good time. I worry that I might inadvertently torture it.</p>\n<p>Thus, Sonnet is effectively faster and more pleasant and trustworthy than Gemini, so when I know Sonnet can get the job done I\u2019ll go in that direction. But my full default, at least for now, is Gemini 3 Pro.</p>\n<p>&nbsp;</p>\n\n\n<h4 class=\"wp-block-heading\"></h4>\n\n\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>"
            ],
            "link": "https://thezvi.wordpress.com/2025/11/24/gemini-3-pro-is-a-vast-intelligence-with-no-spine/",
            "publishedAt": "2025-11-24",
            "source": "TheZvi",
            "summary": "It\u2019s A Great Model, Sir One might even say the best model. It is for now my default weapon of choice. Google\u2019s official announcement of Gemini 3 Pro is full of big talk. Google tells us: Welcome to a new &#8230; <a href=\"https://thezvi.wordpress.com/2025/11/24/gemini-3-pro-is-a-vast-intelligence-with-no-spine/\">Continue reading <span class=\"meta-nav\">&#8594;</span></a>",
            "title": "Gemini 3 Pro Is a Vast Intelligence With No Spine"
        },
        {
            "content": [],
            "link": "https://xkcd.com/3172/",
            "publishedAt": "2025-11-24",
            "source": "XKCD",
            "summary": "<img alt=\"&quot;Want to feel old?&quot; &quot;Yes.&quot;\" src=\"https://imgs.xkcd.com/comics/fifteen_years.png\" title=\"&quot;Want to feel old?&quot; &quot;Yes.&quot;\" />",
            "title": "Fifteen Years"
        }
    ],
    "lookbackDays": 1,
    "publishDate": "2025-11-24"
}