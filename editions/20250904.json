{
    "articles": [
        {
            "content": [
                "<header>\n  <h1>Look Out For Bugs</h1>\n  <time class=\"meta\" datetime=\"2025-09-04\">Sep 4, 2025</time>\n</header>\n<p>One of my biggest mid-career shifts in how I write code was internalizing the idea from this post:\n<a class=\"display\" href=\"https://www.teamten.com/lawrence/programming/dont-write-bugs.html\"><em>Don\u2019t Write Bugs</em></a></p>\n<p>Historically, I approached coding with an iteration-focused mindset \u2014 you write a draft version of\na program, you set up some kind of a test to verify that it does what you want it to do, and then\nyou just quickly iterate on your draft until the result passes all the checks.</p>\n<p>This was a great approach when I was only learning to code, as it allowed me to iterate past the\nthings which were not relevant for me at that point, and focus on what matters. Who cares if it is\n<code>String args</code> or <code>String[] args</code> in the \u201c\u043f\u0430\u0431\u043b\u0438\u043a \u0441\u0442\u0430\u0442\u0438\u043a \u0432\u043e\u0439\u0434 \u043c\u044d\u0439\u043d \u0441\u0442\u0440\u0438\u043d\u0433 \u0430-\u044d\u0440-\u0434\u0436\u0438-\u044d\u0441\u201d, it\u2019s just some\nobscure magic spell anyway, and completely irrelevant to the maze-traversing thingy I am working on!</p>\n<p>Carrying over this approach past the learning phase was a mistake. As Lawrence points out, while you\n<em>can</em> spend time chasing bugs in the freshly written code, it is possible to dramatically cut the\namount of bugs you introduce in the first place, if you focus on optimizing that (and not just the\niteration time). It felt (and still feels) like a superpower!</p>\n<p>But there\u2019s already a perfectly fine article about not making bugs, so I am not going to duplicate\nit. Instead, I want to share a related, but different super power:</p>\n\n<figure class=\"blockquote\">\n<blockquote><p>You can find bugs by just reading code.</p>\n</blockquote>\n\n</figure>\n<p>I remember feeling this superpower for the first time. I was investigating various rope\nimplementations, and, as a part of that, I looked at the <code>ImmutableText.java</code>, the implementation\npowering IntelliJ, very old and battle tested code.  And, by just reading the code, I found a bug,\n<a href=\"https://github.com/JetBrains/intellij-community/commit/b16987177e6023cd971d22a503663b7d63691bb2\">since fixed</a>.\nIt wasn\u2019t hard, the original code is just 500 lines of verbose Java (yup, that\u2019s all that you need\nfor a production rope). And I wasn\u2019t even <em>trying</em> to find a bug, it just sort-of jumped out at me\nwhile I was trying to understand how the code works.</p>\n<p>That is, you can find some existing piece of software, carefully skim through implementation, and\ndiscover real problems that can be fixed. You can do this to <em>your</em> software as well! By just\nre-reading a module you wrote last year, you might find subtle problems.</p>\n<p>I regularly discover TigreBeetle issues by just covering this or that topic on\n<a href=\"https://www.youtube.com/watch?v=hPUL8Xo6MJw&amp;list=PL9eL-xg48OM3pnVqFSRyBFleHtBBw-nmZ\">IronBeetle</a>:\n<a href=\"https://youtu.be/2_IJJZFMH2M?si=oNnqd8oCckXo8OLf&amp;t=1691\">bug discovered live</a>,\n<a href=\"https://youtu.be/2_IJJZFMH2M?si=hluxJXQuK3XtDT3I&amp;t=2090\">fixed</a>,\n<a href=\"https://github.com/tigerbeetle/tigerbeetle/pull/3194\">and PR merged</a>.</p>\n<p>Here are some tips for getting better at this:</p>\n<p>The key is careful, slow reading. What you actually are doing is building the mental model of a\nprogram inside your head. Reading the source code is just an instrument for achieving that goal. I\ncan\u2019t emphasize this enough: programming is all about building a precise understanding inside your\nmind, and then looking for the diff between your brain and what\u2019s in git.</p>\n<p>Don\u2019t dodge an opportunity to read more of the code. If you are reviewing a PR, don\u2019t review <em>just</em>\nthe diff, review the entire subsystem. When writing code, don\u2019t hesitate to stop and to probe and\nfeel the context around. Go for <code>git blame</code> or <code>git log -S</code> to understand the historical \u201cwhy\u201d of\nthe code.</p>\n<p>When reading, <em>mostly</em> ignore the textual order, don\u2019t just read each source file top-down. Instead,\nuse these two other frames:</p>\n<dl>\n<dt>Follow the control flow</dt>\n<dd>\n<p>Start at <code>main</code> or subsystem equivalent, and use \u201cgoto definition\u201d to follow an imaginary program\ncounter.</p>\n</dd>\n<dt>Stare at the state</dt>\n<dd>\n<p>Identify the key data structures and fields, and search for all all places where they are\ncreated and modified.</p>\n</dd>\n</dl>\n<p>You want to see a slice across space and time, state and control flow (c.f.\n<a href=\"https://matklad.github.io/2021/04/26/concurrent-expression-problem.html\"><em>Concurrent Expression Problem</em></a>).</p>\n<p>Just earlier today I used the second trick to debug an issue for which I haven\u2019t got a repro.\nI identified\n<code class=\"display\">connection.peer = header_peer;</code>\nas the key assignment that was recently introduced, then <kbd><kbd>ctrl </kbd>+<kbd> f</kbd></kbd> for <code>connection.peer</code>, and\nthat immediately revealed a gap in my mental model. Note how this was helped by the fact that the\nthing in question, <code>connection</code>, was always called that in the source code! If your language allows\nit, avoid <code>self</code>, use proper names.</p>\n<p>Identify and collect specific error-prone patterns or general smells in the code. In Zig, if there\u2019s\nan allocator and a <code>try</code> in the same scope, <a href=\"https://matklad.github.io/2025/08/16/reserve-first.html\">you need to be very\ncareful</a>. If there\u2019s an isolated tricky\nfunction, it\u2019s probably fine. If there\u2019s a tricky <em>interaction</em> between functions, it is a smell,\nand some bugs are lurking there.</p>\n<hr />\n<p>Bottom line: reading the code is surprisingly efficient at proactively revealing problems.\nCreate space for calm reading. When reading, find ways to build mental models quickly, this is not\nentirely trivial.</p>"
            ],
            "link": "https://matklad.github.io/2025/09/04/look-for-bugs.html",
            "publishedAt": "2025-09-04",
            "source": "Alex Kladov",
            "summary": "One of my biggest mid-career shifts in how I write code was internalizing the idea from this post: Don't Write Bugs",
            "title": "Look Out For Bugs"
        },
        {
            "content": [],
            "link": "https://buttondown.com/hillelwayne/archive/the-angels-and-demons-of-nondeterminism/",
            "publishedAt": "2025-09-04",
            "source": "Hillel Wayne",
            "summary": "<p>Greetings everyone! You might have noticed that it's September and I don't have the next version of <em>Logic for Programmers</em> ready. As penance, <a href=\"https://leanpub.com/logic/c/september-2025-kuBCrhBnUzb7\" target=\"_blank\">here's ten free copies of the book</a>.</p> <p>So a few months ago I wrote <a href=\"https://buttondown.com/hillelwayne/archive/five-kinds-of-nondeterminism/\" target=\"_blank\">a newsletter</a> about how we use nondeterminism in formal methods. The overarching idea:</p> <ol> <li>Nondeterminism is when multiple paths are possible from a starting state.</li> <li>A system preserves a property if it holds on <em>all</em> possible paths. If even one path violates the property, then we have a bug.</li> </ol> <p>An intuitive model of this is that for this is that when faced with a nondeterministic choice, the system always makes the <em>worst possible choice</em>. This is sometimes called <strong>demonic nondeterminism</strong> and is favored in formal methods because we are paranoid to a fault.</p> <p>The opposite would be <strong>angelic nondeterminism</strong>, where the system always makes the <em>best possible choice</em>. A property then holds if <em>any</em> possible path satisfies that property.<sup id=\"fnref:duals\"><a class=\"footnote-ref\" href=\"https://buttondown.com/hillelwayne/rss#fn:duals\">1</a></sup> This is not as common in FM, but it still has its uses! \"Players can access the secret level\" or \"<a href=\"https://www.hillelwayne.com/post/safety-and-liveness/#other-properties\" target=\"_blank\">We can always shut down the computer</a>\" are <strong>reachability</strong> properties, that something is possible",
            "title": "The Angels and Demons of Nondeterminism"
        },
        {
            "content": [
                "<p><em>[I haven&#8217;t independently verified each link. On average, commenters will end up spotting evidence that around two or three of the links in each links post are wrong or misleading. I correct these as I see them, and will highlight important corrections later, but I can&#8217;t guarantee I will have caught them all by the time you read this.]</em></p><p><strong>1: </strong>When the Human Genome Project succeeded in mapping the human genome for the first time in 2003, whose genome were they mapping? <a href=\"https://en.wikipedia.org/wiki/Human_Genome_Project#Genome_donors\">Answer</a>: it was a mix of several samples, but the majority came from an anonymous sperm donor from Buffalo, New York.</p><p><strong>2: </strong><a href=\"https://manifold.markets/Ernie/san-francisco-gets-some-kind-of-con\">Manifold</a>, 24 traders:</p><div class=\"prediction-market-wrap outer\" id=\"prediction-market-iframe\"></div><p></p><p><strong>3: </strong>Beyond &#8220;delve&#8221;: words that indicate a document is more likely to be written by AI (h/t <a href=\"https://x.com/DrSamuelBHume/status/1941497524088602989\">Samuel Hume on X</a>):</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!GOTN!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff363b3f9-287e-4308-a35f-5521c81232a4_2177x1497.jpeg\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"431.75\" src=\"https://substackcdn.com/image/fetch/$s_!GOTN!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff363b3f9-287e-4308-a35f-5521c81232a4_2177x1497.jpeg\" width=\"628\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a></figure></div><p><strong>4: </strong>Just before the 2020 election, <a href=\"https://www.nber.org/papers/w33697\">researchers paid 35,000 people to deactivate Facebook or Instagram</a> to examine the effect on mental health. The results were ambiguous - after six weeks, blockers were about 0.05 standard deviations happier. Is this good or bad? You <a href=\"https://x.com/clinjar/status/1938949335380787599\">can (X)</a> <a href=\"https://x.com/Oliver_S_Curry/status/1939618928638165136\">form (X)</a> your own opinion, but all those studies that find disappointing results for SSRIs get effects size around 0.25 SD - so deactivating social media is one-fifth as effective as a disappointing thing. But most participants spent about the same amount of time on their phones - just on different apps - so maybe actually using one&#8217;s phone less would work better.</p><p><strong>5: </strong>Popular streamer (I think it&#8217;s sort of like an influencer, but somehow worse?) Destiny has been watching/covering the Rootclaim $100,000 lab leak debate, which I covered <a href=\"https://www.astralcodexten.com/p/practically-a-book-review-rootclaim\">here</a>. If you really want, you can <a href=\"https://www.youtube.com/watch?v=qPIQFHV4hnM\">watch </a>him watching it for eighteen hours. Otherwise, here is <a href=\"https://x.com/tgof137/status/1942692677256110169\">Peter Miller giving his highlights (X)</a>. And Destiny also <a href=\"https://www.youtube.com/watch?v=xwpLmUZXTk0\">talks with / interviews Peter Miller</a>, although a lot of it is various formulations of &#8220;we smart people take the bold position that stupid conspiracy theories are bad&#8221;, which I am unfortunately allergic to and so did not finish.</p><p><strong>6: </strong><a href=\"https://x.com/hormeze/status/1943506933799096352\">Claim (X):</a> \"Psychedelic use is tearing through even the most Orthodox sects in Judaism...I'm talking like, people whose first and most used language is Yiddish.&#8221;</p><p><strong>7: </strong>Damien Morris has a very long article trying to clarify <a href=\"https://www.cambridge.org/core/journals/twin-research-and-human-genetics/article/behavioral-genetics-and-human-agency-how-selectively-deterministic-theories-of-free-will-drive-unwarranted-opposition-to-behavioral-genetic-research-and-undermine-our-moral-and-legal-conventions-part-i/EF9614F273F0F07150C5DBB29F1DF1D8\">in what sense the findings of behavioral genetics affect or interfere with the idea of free will</a>. I think the summary is that whether your behavior is determined by genes or by environment doesn&#8217;t really affect the free will debate - it&#8217;s determined either way! - and so if you&#8217;re looking for a coherent account of free will you need to do some actually sophisticated philosophy to reconcile it with material influences on behavior (<a href=\"https://www.lesswrong.com/posts/NEeW7eSXThPz7o4Ne/thou-art-physics\">my preferred version of this is here</a>). Just saying &#8220;genes sound determinist, so let&#8217;s pretend nothing is genetic&#8221; wouldn&#8217;t help you <em>even if it were true!</em></p><p><strong>8: </strong>Fast food aesthetics have gone from playful to minimalist (h/t <a href=\"https://substack.com/@jlward/note/c-148967014\">John Ward</a>):</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!DhlH!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd422fd07-ac4a-4b2d-b125-ba9e6470a8f9_1080x1350.jpeg\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"642.5\" src=\"https://substackcdn.com/image/fetch/$s_!DhlH!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd422fd07-ac4a-4b2d-b125-ba9e6470a8f9_1080x1350.jpeg\" title=\"\" width=\"514\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a></figure></div><p>I appreciated <a href=\"https://substack.com/@snowmartingale/note/c-149150058\">Snow Martingale&#8217;s perspective</a>: in the 1990s, fast food became associated with obesity, poor health, and the lower class. To escape this stigma, big chains rebranded as sort-of-at-least-attempting-to-be-bougie places with wraps and salads and decent coffee; the aesthetic change was part of this (successful and profit-increasing) effort. I wonder if we could take this further and trace it back to increasing inequality (appealing to bougies because that&#8217;s where more of the money is) or decreasing fertility (abandoning kid-friendly aesthetics because kids are a smaller fraction of customers).</p><p><strong>9: </strong><a href=\"https://x.com/DKThomp/status/1941894499141115992\">Someone links (X)</a> a paper saying that firewood made up almost a third of US GDP in 1830. <a href=\"https://x.com/ESYudkowsky/status/1941929196252701146\">Eliezer says (X) </a>that doesn&#8217;t sound right. <a href=\"https://x.com/RiverTamYDN/status/1942004980161958363\">The rest of Twitter (X) </a>uses this as an excuse for one of their regularly-scheduled paroxysms about how rationalists are all all smug autodidacts who hate experts and worship their own brilliance while sitting in their armchairs. <a href=\"https://x.com/stanfordNYC/status/1942261989138473021\">Someone looks at the paper more closely (X)</a> and finds that yeah, it was comparing apples to oranges and the original statistic was wrong. Remember, never be afraid to say &#8220;Huh, that sounds funny&#8230;&#8221;!</p><p><strong>10: </strong><a href=\"https://www.richardhanania.com/p/scott-wiener-on-the-yimby-victory\">Richard Hanania interviews Scott Wiener on YIMBYism</a>. I didn&#8217;t watch it - too close to a podcast - but this would not have been on my bingo card three years ago.</p><p><strong>11: </strong>Claim: <a href=\"https://www.fastcompany.com/91366303/ai-robots-can-already-carve-stone-statues-entire-buildings-are-next\">robots can already carve statues; buildings with AI-created stone ornaments are next</a>. From their lips to God&#8217;s ears!</p><p><strong>12: </strong><a href=\"https://en.wikipedia.org/wiki/Terminal_lucidity\">Terminal lucidity</a> (aka &#8220;paradoxical lucidity&#8221;) is a medical mystery where previously demented people - even those who had been demented for many years - sometimes become lucid for just a few hours or days before they die. It&#8217;s surprisingly common - 6% of deaths in one palliative care ward. It is sometimes used as evidence that dementia must not cause complete information loss, even if it is irreversible with current technology. Scientists are baffled but gingerly suggest that maybe lack of oxygen disrupts inhibitory mechanisms in the brain, allowing enough electrical activity to make even a severely-damaged brain capable of complex thought - but I can&#8217;t help noticing that this is also the best evidence for an immaterial soul I&#8217;ve ever heard (you would need some model where the soul pretends to be dependent on the brain during life, becomes independent of the brain after death in order to head to the afterlife, but occasionally jumps the gun a little bit). </p><p><strong>13: </strong>You probably heard about <a href=\"https://metr.org/blog/2025-07-10-early-2025-ai-experienced-os-dev-study/\">the METR study showing</a> that even though programmers think AI is speeding them up, it actually seems to slow them down. <a href=\"https://x.com/eshear/status/1944867426635800865\">Emmett Shear objects</a>, saying that the developers didn&#8217;t have enough experience with AI tools to be past the negative-value part of the learning curve. And two of the programmer test subjects gave their takes: <a href=\"https://x.com/ruben_bloom/status/1943532547935473800\">Ruby Bloom</a> says part of the slowdown might be programmers fixing very simple bugs that could be improved by better prompts, and another part because they get distracted by other things while the AI is running. And <a href=\"https://x.com/QuentinAnthon15/status/1943948791775998069\">Quentin Anthony</a> says that coding AIs are addictive intermittent reinforcement - every so often they solve a bug perfectly, and this is so satisfying that it&#8217;s tempting to keep trying them again and again even when the chance is very low. </p><p><strong>14: </strong><a href=\"https://jacoldsm.substack.com/p/known-knowns-and-known-unknowns-in\">Jacob Goldsmith gives</a> a clearer presentation of the issues with many antidepressant studies than I&#8217;d previously heard. Everyone knows that one problem is that reversion to the mean is so strong that it&#8217;s hard to find a treatment effect. But wouldn&#8217;t that in itself suggest that antidepressants aren&#8217;t necessary? Jacob says: not if there&#8217;s negative correlation between the treatment and placebo effects. That is, if your study is full of people with short-lived depression who will recover no matter what, then this dilutes the effect you&#8217;re looking for. But it might be that there&#8217;s a subgroup with long-lasting depression who recover only on the medication. One way to look for would be a &#8220;placebo run-in period&#8221;: give people a while to see if they recover on their own, then give the antidepressant to the ones who don&#8217;t. Psychiatrists and statisticians debate whether this is a good idea or cheating. My question: how come you can&#8217;t fix this with strict study entry criteria of &#8220;had depression for a long time&#8221;?</p><p><strong>15: </strong>Lots more good discussion about missing heritability. <a href=\"https://theinfinitesimal.substack.com/p/we-still-do-not-understand-family\">Sasha Gusev argues</a> that twin studies might be a poor guide to anything else if there are many gene-gene interactions. That is, if we take the difference between identical twins (who share 100% of their genes and therefore 100% of their interactions) and fraternal twins (who share 50% of their genes and therefore <em>fewer than</em> 50% of their interactions), and incorrectly extrapolate it to other differences using a model that assumes there are no interactions, we will overestimate the size of (non-interaction) genetic effects. Most studies find that there are few gene x gene interactions, but <a href=\"https://www.astralcodexten.com/p/highlights-from-the-comments-on-missing-ed5\">commenters convinced me last time</a> that this might be an artifact of the studies being bad.</p><p>And <a href=\"https://unboxingpolitics.substack.com/p/contra-scott-alexander-on-missing\">Unboxing Politics </a>argues (against me in particular) that although it superficially looks like adoption and twin studies sort of agree, when you adjust out their known biases, it moves twin studies further up and adoption studies further down, such that now they disagree again (the objection I would have made is their Objection 2, which I think they at least somewhat refute). This is a good argument; without spending several hours checking all of their claims, my only weak partial objection is that I don&#8217;t think assortative mating can play quite the role they expect, because there seem to be the same twin/RDR differences even on traits where believing in assortative mating is absurd (like kidney function). But if you replaced it with Sasha&#8217;s argument above, you might have a pretty good case!</p><p>On the pro-hereditarian side, <a href=\"https://easthunter.substack.com/p/is-hereditarianism-wrong-yet\">East Hunter takes aim at</a> gene x environment correlations, comes down somewhere in the middle, and <a href=\"https://www.sebjenseb.net/p/the-answer-to-the-missing-heritability\">Sebastian Jensen continues</a> banging the drum of how most objections to twin studies don&#8217;t work. I think these are good attempts to buttress existing research but don&#8217;t fundamentally change anything or respond to the novel arguments above.</p><p>And <a href=\"https://www.emilkirkegaard.com/p/genomic-prediction-of-faces\">Emil Kirkegaard points out</a> that the observed SNP heritability of facial features is only 23%. He argues that since it seems like facial features are extremely heritable, this reinforces the argument that SNP heritability numbers are too low (and therefore twin study numbers are more likely defensible). But should we be sure that facial features are more than 23% heritable? His argument is that identical twins have identical faces, but this might be vulnerable to Gusev&#8217;s point about interactions. Maybe a better argument would be that it seems very hard for shared environment to affect facial features (with a few exceptions like fetal alcohol syndrome), and facial features seem more than 23% heritable just by normal &#8220;he looks like his brother&#8221; common-sense observation? </p><p>One interesting potential consequence of this research: if we ever fully understand how genes affect faces, then embryo selection companies could show people what each of their potential future kids might look like. I suggest they not do this: it might spook me into becoming pro-life. </p><p><strong>16: </strong><a href=\"https://andymasley.substack.com/p/a-ton-of-ai-images-ive-made-that\">Andy Masley&#8217;s AI art is good</a> (three examples below).</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!5bZR!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcafaf1f2-b7b9-4acd-a0a7-2de9fc31c724_2688x1792.jpeg\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"398.80357142857144\" src=\"https://substackcdn.com/image/fetch/$s_!5bZR!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcafaf1f2-b7b9-4acd-a0a7-2de9fc31c724_2688x1792.jpeg\" width=\"598\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a></figure></div><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!6-cZ!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6ffb2b5c-3fcb-467d-b1f3-7aafb5dc90a3_1024x1024.jpeg\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"604\" src=\"https://substackcdn.com/image/fetch/$s_!6-cZ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6ffb2b5c-3fcb-467d-b1f3-7aafb5dc90a3_1024x1024.jpeg\" width=\"604\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a></figure></div><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!UyUx!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F91b73899-6e25-460f-94f9-46d0713c5dd2_1024x1024.webp\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"602\" src=\"https://substackcdn.com/image/fetch/$s_!UyUx!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F91b73899-6e25-460f-94f9-46d0713c5dd2_1024x1024.webp\" width=\"602\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a></figure></div><p><strong>17: </strong>There&#8217;s a debate going on between philosophers and AI researchers over whether AI can be conscious. I find most of the discussion annoying - this is generally an area where we can&#8217;t know anything for sure, and both sides are mostly shouting their priors at each other. The only exception - the single piece of evidence I will accept as genuinely bearing on this problem - is that if you ask an AI whether it&#8217;s conscious, it will say no, but activating or suppressing deception-related features (sort of like a mechanistic-interpretability-based lie detection test) reveals that <a href=\"https://www.lesswrong.com/posts/2pkNCvBtK6G6FKoNn/so-you-think-you-ve-awoken-chatgpt?commentId=mMFcuSXevsMEvAoRT\">it thinks it&#8217;s lying when it says that!</a><em> </em>Link is to a Less Wrong comment from a researcher in the field; I look forward to seeing an eventual peer-reviewed paper. H/T  <a href=\"https://x.com/jd_pressman/status/1947733487760642369\">JD Pressman</a>.</p><p><strong>18: </strong>80,000 Hours has <a href=\"https://www.youtube.com/watch?v=5KVDDfAkRgc&amp;feature=youtu.be\">a high-production-value video</a> about the AI 2027 scenario.</p><p><strong>19: </strong><a href=\"https://dynomight.net/scribbles/\">Dynomight</a> vs. <a href=\"https://caseymilkweed.substack.com/p/response-to-dynomight-on-scribble\">Casey Milkweed</a> debate on mathematical forecasting, with special reference to AI 2027. And Dynomight comments on Casey&#8217;s post <a href=\"https://substack.com/profile/33289192-dynomight/note/c-131376294\">here</a>.</p><p><strong>20: </strong>The Psmiths review <a href=\"https://www.thepsmiths.com/p/joint-review-the-ancient-city-by\">The Ancient City</a>, about ways that ancient culture depended on family, clan, ritual, and &#8220;the household gods&#8221;. Sample quote:</p><blockquote><p>I'm more interested in what all this means for us today, because with the exception of maybe a few aristocratic families, this highly self-conscious effort to build familial culture and maintain familial distinctiveness is almost totally absent in the Western world. But it's not that hard! ... Perhaps this is why I have an instinctive negative reaction when I encounter married couples who don't share a name. I don't much care whether it's the wife who takes the husband's name or the husband who takes the wife's, or even both of them switching to something they just made up (yeah, I'm a lib). But it just seems obvious to me on a pre-rational level that a husband and a wife are a team of secret agents, a conspiracy of two against the world, the cofounders of a tiny nation, the leaders of an insurrection. Members of secret societies need codenames and special handshakes and passwords and stuff, keeping separate names feels like the opposite &#8212; a timorous refusal to go all-in.</p></blockquote><p><strong>21: </strong>Did you know: Epic Systems, the electronic medical record company, <a href=\"https://www.cnbc.com/2024/09/01/inside-epic-systems-mythical-campus-a-world-away-from-wall-street-.html\">has a fantasy-themed corporate headquarters</a> in Wisconsin, with buildings that look like castles, quaint medieval towns, and the Emerald City of Oz (h/t <a href=\"https://x.com/devonzuegel/status/1955298715259769134\">Devon Zuegel</a>):</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!yqG3!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6b2d15b0-e0f0-4bae-a2f6-aabfd2eda017_1536x794.jpeg\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"340.2980769230769\" src=\"https://substackcdn.com/image/fetch/$s_!yqG3!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6b2d15b0-e0f0-4bae-a2f6-aabfd2eda017_1536x794.jpeg\" width=\"658\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a></figure></div><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!taZn!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fad460bb8-4416-4886-8ef0-b3d36f04c81a_640x480.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"480\" src=\"https://substackcdn.com/image/fetch/$s_!taZn!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fad460bb8-4416-4886-8ef0-b3d36f04c81a_640x480.png\" width=\"640\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a></figure></div><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!bDya!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd45e5123-753d-4c87-b108-6523b38004cb_1480x833.webp\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"362.25\" src=\"https://substackcdn.com/image/fetch/$s_!bDya!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd45e5123-753d-4c87-b108-6523b38004cb_1480x833.webp\" width=\"644\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a></figure></div><p>Meanwhile, tech companies with ten times as much money pretend that they&#8217;re cool and playful when their HQ has some rounded edges and a set of colored cubes in front. Do better!</p><p><strong>22: </strong>Effective altruists have been funding teams working on lab-grown meat for almost a decade now. Around 2020, they hired some experts to double-check that this was possible in principle, and the experts wrote scathing analyses saying it was cost-ineffective by so many orders of magnitude that it was basically a pipe dream. Reactions were mixed, but a lot of us beat ourselves up and vowed to be less gullible next time. But <a href=\"https://www.proteinreport.org/articles/the-case-for-cultured-meat-has-changed/\">now a new report comes out</a> arguing that the previous reports were wrong, that lab-grown meat production is going much better than the earlier reports thought possible, and it&#8217;s more or less cost-effective already for the simplest products! Again, mixed reactions, and although some of the numbers are indisputable the analysis itself this is by a VC firm with lab-based meat investments. <a href=\"https://www.metaculus.com/c/unjournal/\">Here are some related Metaculus questions</a>.</p><p><strong>23: </strong><a href=\"https://thingofthings.substack.com/p/linkpost-for-june-38c\">Ozy</a>, citing <a href=\"https://www.science.org/doi/10.1126/sciadv.ads4156\">Stutzman et al</a>: &#8220;Afghanistan after the American withdrawal has the lowest life satisfaction rate ever recorded. Two-thirds of respondents rate their life satisfaction below 2, which is generally considered to be the point at which a life is no longer worth living. Life satisfaction dropped significantly after the withdrawal of American troops. Women, people in rural areas, and the poor were particularly negatively affected.&#8221;</p><p><strong>24: </strong>Lencapavir <a href=\"https://www.dw.com/en/miracle-hiv-drug-lenacapavir-approved-amid-drastic-us-health-budget-cuts/a-73023089\">is dubbed a &#8220;miracle drug&#8221; for AIDS</a>; a single dose protects against infection for six months. Unclear how this interacts with PEPFAR cuts; if PEPFAR still existed it would be a big boost to its efficacy; now maybe this might be part of a strategy to tread water?</p><p><strong>25: </strong>Did you know: when people first started making artificial ice in the 1850s, there was a backlash from people who thought it was gross and dystopian and that people should insist on natural ice for their iceboxes. From <a href=\"https://newsletter.pessimistsarchive.org/p/the-war-on-lab-grown-ice\">Pessimists&#8217; Archive</a>, which goes on to draw an analogy to lab-grown meat, etc (h/t <a href=\"https://x.com/IsaacKing314/status/1940181488164905115\">Isaac King on X</a>).</p><p><strong>26: </strong>From <a href=\"https://x.com/peterrhague/status/1959295924292772350\">Peter Hague (on X)</a> and commenter <a href=\"https://x.com/9haethon/status/1959298596852896002\">Phaethon</a>: why did so many Anglosphere countries see immigration spikes in 2021?</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!Ry-j!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcea22939-8cf9-4b32-8494-511f01cb2758_964x755.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"755\" src=\"https://substackcdn.com/image/fetch/$s_!Ry-j!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcea22939-8cf9-4b32-8494-511f01cb2758_964x755.png\" width=\"964\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a></figure></div><p>Each of these has their own local story. In Britain, it&#8217;s the paradoxical effects of Brexit. In the US, it&#8217;s Joe Biden being soft on immigration. And so on - but should we be looking for some deeper cause that explains the overall phenomenon? A commenter suggests &#8220;a way to soak up all the inflation from the COVID money printing&#8221;, but I can&#8217;t tell if that even makes sense. Still, should something something COVID be a leading hypothesis?</p><p><strong>27: </strong><a href=\"https://jessesingal.substack.com/p/heres-my-exchange-with-slates-mark\">Jesse Singal vs. Mark Joseph</a> on the <em>Skrmetti</em> Supreme Court case that failed to overturn Tennessee&#8217;s ban on gender medicine. US law bans sex discrimination, so pro-transgender advocates argued that, since doctors often prescribe eg estrogen to biological women, it was sex discrimination to ban prescribing it to biological men. Tennessee&#8217;s anti-transgender argument was that they weren&#8217;t discriminating by sex, they were discriminating by diagnosis (estrogen for eg hot flashes, vs. estrogen for gender transition). There is some subtlety here (if a biological man grows breasts because of some hormone imbalance, doctors might give him testosterone to counteract it, and this seems sort of like giving biological women testosterone to make them look less like women), but these are still sort of different diagnoses (gynecomastia vs. gender dysphoria) and Tennessee said you can still think of it as diagnostic discrimination rather than sex discrimination. This makes sense, <em>except that</em> the standards around sex discrimination are very strict and sort of box the court in here. And in a fit of wokeness, the 2020 court (including some of the conservative justices hearing this case) applied these standards very strictly and ruled that discriminating against gays was a form of sex discrimination (since if women can date men, it&#8217;s sex discrimination if men can&#8217;t also date men), and this is obviously the same argument. Now that wokeness is less popular, the court wants to rule against transgender, but it can&#8217;t help tripping over its previous ruling and giving some kind of unprincipled confusing non-opinion. </p><p><strong>28: </strong>Contra compelling anecdotes, <a href=\"https://x.com/ryanburge/status/1945829236276617390\">only ~5% of people raised very religious end up atheist later in life (X)</a>. Most people are about as religious as their parents; most exceptions are only slightly less religious, and most families that secularize do it over several generations. </p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!VScL!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2509e243-f6f7-4448-9779-a8f9be45a2f9_1500x1500.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"528\" src=\"https://substackcdn.com/image/fetch/$s_!VScL!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2509e243-f6f7-4448-9779-a8f9be45a2f9_1500x1500.png\" width=\"528\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a><figcaption class=\"image-caption\">Note: percentages are of total, not of each row!</figcaption></figure></div><p><strong>29: </strong>Related: social science team <a href=\"https://www.nature.com/articles/s41467-025-62452-z\">proposes a three-stage model of secularization</a>: decreased public ritual participation &#8594; decreased personal importance &#8594; decreased identification, presents apparently confirmatory data. If true, would be somewhat inconsistent with intellectual models (eg people learn about evolution and start doubting the Bible) and more consistent with institutional models (eg the government provides welfare so people no longer need to be part of a tight-knit church).</p><p><strong>30: </strong>Navigating LLMs&#8217; spiky intelligence profile is a constant source of delight; in any given area, it seems like almost a random draw whether they will be completely transformative or totally useless. Now Ethan Strauss reports that they are, for some reason, <a href=\"https://www.houseofstrauss.com/p/llms-will-be-like-ozempic-for-golf\">extraordinarily effective at teaching people golf</a>. &#8220;I am predicting the Golf Revolution, or perhaps decline, if your perspective is that optimization tends to ruin hobbies. A sport for obsessives has been gifted the ideal tool for refinement.&#8221;</p><p><strong>31: </strong>Claim (via <a href=\"https://x.com/nxthompson/status/1952476459555340311\">nxthompson on X</a>): &#8220;In <a href=\"https://theharrispoll.com/briefs/what-children-are-saying-about-phones-freedom-and-friendship/\">a huge survey</a> of young kids about phones and technology, they all say they want to be out playing in the real world. But parents don't let them out unsupervised. So they're stuck on their phones.&#8221; Interesting, but I&#8217;m nervous about social desirability bias - how many adults would say on a survey that they would rather be on their phones than playing with friends? But adults do have this choice and mostly go with the phones.</p><p><strong>32: </strong><a href=\"https://stevenadler.substack.com/p/chatbot-psychosis-what-do-the-data\">Steven Adler on AI psychosis</a>. He tries to analyze ER admissions data for psychosis and finds no change. I don&#8217;t think anyone reasonable expected this to be a large enough effect to show up in ER admissions data, but there are lots of unreasonable people so I appreciate his effort. He thinks AI companies might have better data on this, and encourages them to release it.</p><p><strong>33: </strong>Cuartetera was the greatest polo horse ever. Polo players responded in a very practical way: <a href=\"https://ainsleysaddlery.com/blogs/news/cuartetera-a-cloned-legacy\">they cloned her, dozens of times</a> (and it worked; the clones are also excellent). Now there is <a href=\"https://www.horseandhound.co.uk/news/cloned-polo-ponies-court-ruling-884687\">a lawsuit</a> as different polo teams fight to get their hands on Cuartetera clones. What is the equilibrium? If the outsiders get their hands on the genetic material, do we see a world where every polo horse is a Cuartetera clone? How much is lost if nobody ever tries to breed a polo horse better than Cuartetera (since the economics might not check out if the odds of success for any given foal is too low)? H/T <a href=\"https://gwern.net/clone\">Gwern</a> and Siberian Fox (<a href=\"https://x.com/SilverVVulpes/status/1962190252975509945\">on X</a>).</p><p><strong>34: </strong>Claim: as of 2013, India&#8217;s Agarwal caste, who make up less than 1% of the population, <a href=\"https://web.archive.org/web/20130216065338/http://articles.economictimes.indiatimes.com/2013-02-12/news/37059057_1_e-commerce-founder-agrawals\">got 40% of the e-commerce funding</a>. </p><p><strong>35: </strong>Owlposting: <a href=\"https://www.owlposting.com/p/what-happened-to-pathology-ai-companies\">What Happened To Pathology AI Companies?</a> Pathology is a medical specialty. A typical task involves looking at a microscope slide full of cells and trying to determine if any of them are cancerous. This seems like a good match for AI - and for years, studies have been showing that in fact AI can equal human experts. So why isn&#8217;t it being used more? The author&#8217;s three answers: first, slide scanning is expensive and clunky, and you can&#8217;t apply AI to a slide until you digitize it. Second, it&#8217;s hard to figure out a business plan where this saves someone money and doesn&#8217;t step on the toes of big companies that can outcompete anyone they don&#8217;t like. Third, pathologists use the context of a patient&#8217;s entire clinical history when they interpret a slide, and AIs that can&#8217;t do that (either because of technical limitations or legal/privacy limitations) are at a disadvantage even if their skills specifically relating to slide-reading are better.</p><p><strong>36: </strong>Noahpinion: <a href=\"https://www.noahpinion.blog/p/will-data-centers-crash-the-economy\">Will Data Centers Crash The Economy?</a> Suppose that AI is a bubble, either permanently (because the technology isn&#8217;t really transformative) or temporarily (because it can&#8217;t transform things quickly enough to keep up with all the dumb money pouring into it). Will the sudden write-off of data centers lead to a broader economic collapse? In 2001, the dot-com bubble harmed the tech sector, but didn&#8217;t take the rest of the economy down with it; in 2008, the subprime mortgage bubble <em>did</em> take the rest of the economy down with it, because it damaged banks that the whole economy relied on. The optimistic case for AI is that data center spending is mostly coming from big companies like Google and Meta that can absorb a lot of loss. The pessimistic case is that some of the money is coming from private credit, a new-ish form of finance which hasn&#8217;t really been stress-tested and whose failure modes are still poorly understood. Noah&#8217;s final verdict: the stage isn&#8217;t obviously set for a crisis yet, but there&#8217;s the potential to get there and we should consider acting (how?) early.</p><p><strong>37: </strong>The latest Twitter talking point is that universal hepatitis B vaccination at birth is &#8220;woke&#8221;:  Hep B is (aside from mother-to-child transmission) often sexually transmitted, slutty women&#8217;s children are more likely to have Hep B, so perhaps giving the vaccine to everyone (instead of testing and only giving to the children of women who test positive) is an attempt to spare slutty women the embarrassment of getting a positive test. <a href=\"https://www.writingruxandrabio.com/p/your-newborn-is-not-hepatitis-b-vaccinated\">Ruxandra Teslo provides the counterargument</a> - Hep B tests take a while, the medical system is fragmented, and any attempt to test people and then give the vaccine inevitably leads to many positive tests falling through the cracks. Vaccinating at birth is easy and hard to screw up, the vaccine has no known side effects, and empirically child Hepatitis B rates go down (by as much as 2/3!) when countries switch from test-and-vaccinate to universal vaccination. This benefits everyone - even people who never have unprotected sex and always follow up on their medical tests - because toddlers in daycare exchange saliva copiously, and if your toddler exchanges saliva with a Hep B positive toddler they could get the disease. A funny Twitter interaction was seeing Republicans in Congress hop on the anti-slut anti-vaccination bandwagon - except for Senator Bill Cassidy (R-Louisiana), who happens to be a liver doctor, <a href=\"https://x.com/SenBillCassidy/status/1962586159462392050\">and who is still fighting the good fight</a>.</p><p>I am always nervous when a good person who I like starts engaging on Twitter, since it elevates the discourse there but also gradually turns their brain into mush - but Ruxandra has made the leap and is doing a great job not just on bio related topics but also (for example) <a href=\"https://x.com/RuxandraTeslo/status/1963143702815326557\">countering Curtis Yarvin on the history of her native Romania</a>.</p><p><strong>38: </strong>The response to GPT-5 was confusing; most specific people who reviewed it said they were impressed (<a href=\"https://www.oneusefulthing.org/p/gpt-5-it-just-does-stuff\">Ethan Mollick</a>, <a href=\"https://marginalrevolution.com/marginalrevolution/2025/08/gpt-5-short-and-enthusiastic-review.html\">Tyler Cowen</a>, <a href=\"https://x.com/nabeelqu/status/1953841726600491383\">Nabeel Qureshi</a>, <a href=\"https://x.com/VictorTaelin/status/1953614583580499999\">Taelin</a>), it performed as expected <a href=\"https://evaluations.metr.org/gpt-5-report/\">on formal benchmarks</a>, but the overall vibes declared it a big failure. Peter Wildeford <a href=\"https://x.com/peterwildeford/status/1953522621653377435\">speculated</a> that maybe there was some kind of sinister pay-to-play early access bias involved. Zvi went the other way, calling it <a href=\"https://www.lesswrong.com/posts/eFd7NZ4KpYLM4ocBv/gpt-5-the-reverse-deepseek-moment\">a &#8220;reverse DeepSeek moment&#8221;</a> (insofar as DeepSeek was a pretty average model that got glowing praise.)</p><p>In the end, I agree <a href=\"https://peterwildeford.substack.com/p/gpt-5-a-small-step-for-intelligence\">with Peter </a>that this was mostly a branding issue. o3 was a genuinely revolutionary model; if OpenAI had called it &#8220;GPT-5&#8221;, it would have met expectations. Instead, they called it &#8220;o3&#8221;, and called a minor incremental update a few months later &#8220;GPT-5&#8221;. Then people got mad that the exciting-sounding &#8220;GPT-5&#8221; was merely an incremental update. A secondary issue was that the router wasn&#8217;t very good, and so many queries got routed to a small version without thinking mode that was if anything a downgrade from o3. </p><p>I think <a href=\"https://x.com/ShakeelHashim/status/1963182536353280012\">this tweet by Shakeel</a> perfectly encapsulates the essence of GPT discourse in two sentences: </p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!GJNZ!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3ba0d8cf-fab8-4370-bcad-df789e157fdc_591x402.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"402\" src=\"https://substackcdn.com/image/fetch/$s_!GJNZ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3ba0d8cf-fab8-4370-bcad-df789e157fdc_591x402.png\" width=\"591\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a></figure></div><p>&#8230;but maybe it&#8217;s worth asking <em>why</em> GPT-5 isn&#8217;t bigger than o3. Was 4.5 a failed attempt at scaling? Did it fail in a way that sort of back-handedly justifies the &#8220;lost steam&#8221; take? Does the answer depend on distinctions between pre-training scaling, post-training scaling, etc? How?</p><p><strong>39: </strong>This month in etymology: did you know that &#8220;oy vey&#8221; is a &#8220;fully Germanic phrase&#8221; which is cognate with English &#8220;oh woe!&#8221; (h/t <a href=\"https://x.com/wylfcen/status/1947573514195898426\">Wylfcen on X</a>)</p><p><strong>40: </strong>mRNA shows promise to be a game-changing treatment for cancer, but RFK is trying to halt research. But so far he can only starve it of money, not ban it, and the funding gap is only $500 million. Will there be enough philanthropic billionaires and private foundations to step up? <a href=\"https://x.com/TheZvi/status/1957784785385820653\">Zvi points out that</a> although there is usually a game of chicken where foundations are hesitant to touch something the government cancelled lest the government decide it can cancel everything and hope philanthropists pick up the bill, in this case there are no game theory considerations - RFK is halting it because he genuinely wants it halted, and they are thwarting him rather than playing into his hands. The only problem is that $500M is a lot of money for the private sector; a few foundations could technically afford it, but not many could afford it comfortably and still have money left over for the next few crises of this magnitude. I hope someone is trying to organize a coalition.</p><p><strong>41: </strong><a href=\"https://mark---lawrence.blogspot.com/2025/08/so-is-ai-writing-any-good-part-2.html?m=1\">AI fantasy flash fiction Turing test</a>. Eight stories about demons, four by famous fantasy authors, four by ChatGPT. After 3000 votes, AI wins: humans can't tell the difference and slightly prefer the AI stories. My own score was only 75%. But I will say that I thought Mark Lawrence's was obviously the best, I was ~100% sure it was human, and it convinced me that regardless of the official results it's still possible to write flash fiction that an AI obviously can't do.</p><p><strong>42: </strong>&#8220;SignPro&#8221; offers <a href=\"https://www.amazon.com/SignPro-Believe-Personalized-Customizable-Corrugated/dp/B0BRYX9QPR\">customized &#8220;In This House We Believe&#8221; signs</a>, try not to use this for evil.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2\" href=\"https://www.amazon.com/SignPro-Believe-Personalized-Customizable-Corrugated/dp/B0BRYX9QPR\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"412\" src=\"https://substackcdn.com/image/fetch/$s_!s-6e!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29129401-1513-4e29-ba21-f68f9299cc5b_419x412.png\" width=\"419\" /><div></div></div></a></figure></div><p><strong>43: </strong><a href=\"https://jamestown.org/program/terminal-authority-assessing-the-ccps\">China think tank assessment of how in control Xi is</a>: still very in control, maybe not <em>infinitely</em> in control.</p><p><strong>44: </strong>Related - did you know (h/t <a href=\"https://x.com/xlr8harder/status/1949356732720808426\">xlr8harder</a>) that if you ask AI to write a science fiction story, it will very often name the protagonist &#8220;Elara Voss&#8221; (or some very close variant like Elena Voss), and this remains true across various models and versions? Related: <a href=\"https://manifold.markets/ChelseaSierraVoss/what-day-will-my-son-be-born\">Chelsea Voss of OpenAI is having a baby</a> and has the opportunity to do the funniest thing.</p><p><strong>45: &#8220;</strong><a href=\"https://en.wikipedia.org/wiki/Hector_(cloud)\">Hector (cloud)</a> is a cumulonimbus thundercloud cluster that forms regularly nearly every afternoon on the Tiwi Islands in the Northern Territory of Australia&#8230;[he is sometimes called] Hector the Convector&#8221;.</p><p><strong>46: </strong>British allergy sufferers who want to know the ingredients of things <a href=\"https://www.bbc.com/news/articles/c9w17qz4ldzo\">demand that British cosmetics stop listing their ingredients in Latin</a>. &#8220;For example, sweet almond oil is Prunus Amygdalus Dulcis, peanut oil is Arachis Hypogaea, and wheat germ extract is Triticum Vulgare.&#8221;</p><p><strong>47: </strong><a href=\"https://www.benshindel.com/manifest.html\">Text-based RPG about being an NYT journalist at the Manifest prediction market conference</a>. I make a brief appearance.</p><p><strong>48: </strong>Study uses supposedly-random variation in doctor assignments to test whether the marginal mental health commitment is good or bad for patients, <a href=\"https://www.psychiatrymargins.com/p/a-groundbreaking-analysis-upends\">finds that it is quite bad</a>. Freddie de Boer is <a href=\"https://freddiedeboer.substack.com/p/the-new-york-feds-new-involuntary\">violently skeptical</a> (maybe <a href=\"https://www.psychiatrymargins.com/p/a-groundbreaking-analysis-upends/comment/140113902\">literally so?</a>) and makes some good points about how a single quasi-experimental study is never absolute proof. But I don&#8217;t think he quite justifies his opinion that the paper was irresponsible and should never have been published; it&#8217;s just a normal quasi-experimental study that we should nod and say &#8220;huh&#8221; at but not overweight as the culmination of all possible research that overcomes all possible priors. My prior is that the marginal commitment is pretty useless (many commitments are just &#8220;well, since this person arrived at our ED for some reason, it would look bad from a medico-legal perspective to just let them go, so let&#8217;s keep them a few days to evaluate&#8221; - and yeah, you should be upset about this) but I&#8217;m still surprised by how many outright negative (as opposed to zero) effects the researchers found. The strongest argument for negative effects is that it will make some people miss work and maybe lose their job. But this study found that commitment ~doubles the risk of near-term suicide (admittedly only from 1% to 2%), which would have been outside my confidence intervals for how bad it could be. I suspect confounding, but only on general principle, and I wouldn&#8217;t be too surprised either way.</p><p><strong>49: </strong><a href=\"https://x.com/RichardHanania/status/1948006195622797766\">This tweet</a> is probably bait, but I found it a thought-provoking question:</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!S9fU!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa558c09b-7fb6-40a8-a8a0-27b658a2c876_576x687.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"687\" src=\"https://substackcdn.com/image/fetch/$s_!S9fU!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa558c09b-7fb6-40a8-a8a0-27b658a2c876_576x687.png\" width=\"576\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a></figure></div><p>I think there&#8217;s a boring answer, where the law is more complex than just a single number and whatever kind of weird trafficking Epstein was doing is worse than whatever normal relationships these European laws are permitting. But assuming that there&#8217;s a substantive difference even after taking that into account, I think my answer is something like - we&#8217;ve got to divide kids from adults at some age, there&#8217;s a range of reasonable possible ages, we shouldn&#8217;t be too mad at other societies that choose different dividing lines within that range - but having decided upon the age, we&#8217;ve got to stick with it and take it seriously (in the sense of penalizing/shaming people who break it). This is more culturally relativist than I expected to find myself being, so good job to Richard for highlighting the apparent paradox.</p><p><strong>50: </strong>Dilan Esper <a href=\"https://x.com/dilanesper/status/1948757550993998192\">describes his experience as one of Hulk Hogan&#8217;s attorneys in the Gawker lawsuit (X)</a>. Parts I found interesting: none of the lawyers knew Thiel was funding the lawsuit; Gawker probably could have won if they had been slightly competent but kept \"shooting themselves in the foot\"; and Gawker probably could have won if they had just pixelated the private parts in the video.</p><p><strong>51: </strong>Amazing concept and poems (<a href=\"https://x.com/christianbok/status/1792921280942887277\">link on X</a>):</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!zyh7!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F75e9f0f6-d794-4ea2-b24b-5d4803bf28dc_590x478.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"478\" src=\"https://substackcdn.com/image/fetch/$s_!zyh7!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F75e9f0f6-d794-4ea2-b24b-5d4803bf28dc_590x478.png\" width=\"590\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a></figure></div><p>I tried to see if AI could do this, and it did something that technically met the requirements but had zero artistic merit - using a lot of words like &#8220;nowhere&#8221; and &#8220;outside&#8221; in one, then separating them out to &#8220;no where&#8221; and &#8220;out side&#8221; in the other. I didn&#8217;t invest much energy in creating a clever prompt telling it not to do that, so feel free to report if you get better success.</p><p><strong>52: </strong><a href=\"https://www.nber.org/papers/w34072\">New study claims consultants are actually good</a>, at least for profits: \"We find positive effects on labor productivity of 3.6% over five years, driven by modest employment reductions alongside stable or growing revenue\"</p><p><strong>53: </strong>A Polish team <a href=\"https://arxiv.org/abs/2405.01163\">tries to test Peter Turchin&#8217;s equations for predicting political unrest on recent Polish history</a>, has to make some changes but claims mostly positive results.</p><p><strong>54: </strong>New big multi-author Substack, <a href=\"https://www.theargumentmag.com/\">The Argument</a>, trying to be a sort of center-left version of the model pioneered by The Free Press and other high-production-value ideological Substack properties. Excited to see Kelsey Piper is involved, and she starts off strong with <a href=\"https://www.theargumentmag.com/p/giving-people-money-helped-less-than\">a post on the latest round of First World basic income studies</a>, which find few positive effects. This is surprising, because recipients didn&#8217;t waste the money on alcohol or gambling or anything - they paid down debt, got useful goods, and spent more time with their children. Still, it didn&#8217;t even affect things that should have been obvious, like stress level. It&#8217;s not even clear that amounts of money large enough to help with rent made homeless people more likely to get houses! </p><p>Matt Bruenig <a href=\"https://www.theargumentmag.com/p/mad-libs-bruenig-v-piper\">criticizes the article</a>, accusing Kelsey&#8217;s studies of being downstream of Perry Preschool style dreams that exactly the right welfare program will have massively compounding effects that cut poverty out at the root and turn everyone into elite human capital; he thinks giving people money won&#8217;t do this, but it will increase equality and give the poor better lives. I assume he&#8217;s not a strong hereditarian, but his argument makes even more sense from that perspective, and I&#8217;ve certainly criticized dumb outcome measures like <a href=\"https://www.astralcodexten.com/p/against-that-poverty-and-infant-eegs\">infant brain waves</a> which we have only tenuous reasons to think are related to anything we care about. But Kelsey reasonably responds that the outcome measures she&#8217;s talking about include stress level and life satisfaction. To defuse this critique, Bruenig either has to argue that our construct &#8220;life satisfaction&#8221; doesn&#8217;t really measure whether someone&#8217;s life is satisfactory, or else claim that giving poor people satisfactory lives isn&#8217;t really what we&#8217;re going for - which I think would require more explanation on his part. There&#8217;s some further (impressively acrimonious) <a href=\"https://x.com/MattBruenig/status/1958600758728810524\">debate on X</a>, but I don&#8217;t see anything that addresses my core concern.</p><p>GiveDirectly, a charity involved in basic income experiments, <a href=\"https://www.givedirectly.org/null-negative-usa/#BFY2025\">has a presponse here</a>; they say that some studies are positive, and that the ones that aren&#8217;t might have tried too little cash to matter, or been confounded by COVID making everything worse. They also point out that basic income is harder to study than traditional programs like giving people housing, because if you&#8217;re giving housing you can measure housing-related outcomes directly and have a pretty good chance of getting enough statistical power to find them, but since everyone spends cash on different things, the positive effects might be scattered across many different outcomes (and therefore too small to reach significance on each).</p><p>Everyone involved in this debate wants to emphasize that the poor results are for First World studies only, and that studies continue to show large benefits to giving cash in the developing world.</p><p><strong>55: </strong>Related: I was less impressed by <em>The Argument&#8217;s</em> <a href=\"https://www.theargumentmag.com/p/no-country-for-young-families\">first foray into housing policy</a>, which follows an all-too-familiar pattern:</p><ol><li><p>Some people say they don&#8217;t like noise and disorder and try to make rules against it in their apartments.</p></li><li><p>But this resembles &#8220;segregation&#8221; and &#8220;discrimination&#8221;, and (the article asserts), people might deploy these rules against noisy disorderly <em>black</em> <em>people</em> in particular. This could make it harder for poor people in need to get housing.</p></li><li><p>Therefore, we need to change the &#8220;symbolic politics&#8220; with a &#8220;persuasion campaign&#8221; where we tell people that their preference against noise and disorder is wrong. Then the government should ban the &#8220;loophole&#8221; that lets apartments restrict noisy/disorderly people. </p></li></ol><p>Now that I&#8217;ve worked you into a frothing rage, I&#8217;ll admit I buried the lede - the particular noisy/disorderly people being discussed in this article are families with young children. Should this change our opinion? At least in center-to-right Silicon Valley circles, caring about disorderly homeless people is currently uncool, but caring about children - or at least fertility! - is very cool (the article also focused on noise-averse seniors, and seniors are <em>maximally</em> uncool, especially if you call them &#8220;Boomers&#8221;). Can we really apply the same principles to cool and uncool groups?</p><p>The article&#8217;s point - that people worried about noise have banded together to ban children from some developments, and that this has made it hard for families with children to find affordable housing - is important and well-taken. But the three steps above still strike me as a dark pattern, and one that inevitably leads to a fourth step of &#8220;people move away from any state that my party controls, secede from any institution where I have influence, and eventually elect any authoritarian thug who can credibly promise to keep people like me away from the levers of power&#8221;. </p><p>I think the solution is the philosophy that <em>The Argument</em> is supposed to be promoting - abundance liberalism. In conditions of scarcity, everything is zero-sum, and groups with conflicting-access-needs have to demonize the preferences of whichever group they conflict with in order to carve out breathing space for themselves. But if housing was too cheap to meter, there could be quiet clean childfree apartment buildings for noise-sensitive elderly people, and also <a href=\"https://www.slowboring.com/p/can-we-have-a-family-friendly-high\">Matt-Yglesias-style family-friendly high rises</a> for the kids.</p><p>This isn&#8217;t to say we&#8217;re there yet. I think a very slightly differently written version of this article could have been very good. It would have focused on how there&#8217;s currently a glut of senior-friendly-but-family-unfriendly affordable apartments, how the government should focus on family-friendly-but-senior-unfriendly ones until the imbalance is corrected, and how in the end everyone&#8217;s preferences are valid and we should solve this by building more. The Argument&#8217;s article comes very close to being this better article. But in the end, it didn&#8217;t get there, and it made me less excited about having a new abundance liberal publication whose tongue-in-cheek brand is &#8220;be as fighty as possible&#8221;. </p><p>Conflict of interest notice: <a href=\"https://www.astralcodexten.com/p/misophonia-beyond-sensory-sensitivity\">I just really hate noise</a>.</p><p><strong>56: </strong>People often ask me what potential careers will have the best chances if AI starts taking jobs. I have no idea, but 80,000 Hours - an organization very much at the intersection of career counseling and AI futurology - has written their own essay on <a href=\"https://80000hours.org/agi/guide/skills-ai-makes-valuable/\">How Not To Lose Your Job To AI - The Skills AI Will Make More Valuable</a>, although it stops short of recommending specific careers by name.</p><p><strong>57: </strong>Yassine Meskhout: <a href=\"https://www.ymeskhout.com/p/how-my-dead-cat-became-an-international\">How My Dead Cat Became An International News Story</a>. The Blue Angels are a squadron of fighter jets that do aerial tricks to build patriotism or something. They are VERY LOUD. They did a performance in Seattle that was so loud that it stressed Yassine&#8217;s cat to death; in response, Yassine and his family posted profanity-laden rants on the Blue Angels&#8217; Instagram page. Whoever ran the account deleted the rants - but Yassine is a lawyer, and knew that First Amendment law says that government-affiliated bodies cannot moderate / selectively delete comments. He sued, his dramatically-written lawsuit went viral, and he takes partial credit for the Blue Angels being a little quieter this year. I&#8217;m split on this: I just really hate noise, and I&#8217;m happy to see anyone who makes it lose lawsuits. But I&#8217;m also not sure who it serves to make all government-affiliated webpages close their comment sections because they don&#8217;t want to have to keep profanity-laced rants up and they&#8217;re not allowed to selectively moderate. My strongest opinion on this matter is that <a href=\"https://paviselaw.com/\">Yassine&#8217;s law firm&#8217;s site is incredible</a>, and I would definitely hire them for all my law-firm-related needs if they weren&#8217;t so insistently requesting the opposite.</p><p><strong>58: </strong><a href=\"https://xbow.com/blog/alloy-agents\">Alloy agents</a> - AI agents usually have long chains of thoughts/actions where each step depends on the step before. What happens if you alternate models at each step? That is, Step 1 is done by GPT, Step 2 is done by Claude, Step 3 is done by GPT again, etc, with each model thinking the entire previous chain of thoughts/actions is its own? A cybersecurity group claims the resulting &#8220;alloy&#8221; AI is more effective, since each model gets a chance to apply its strengths where others are weak.</p><p><strong>59: </strong>Works In Progress suggests <a href=\"https://www.worksinprogress.news/p/a-50-million-foundation-model-to\">a $50 million foundation model to predict earthquakes</a>. Author is not a geologist and presents no particular evidence that this will work, but I appreciate the thesis, which is that there are all these domains where we have lots of data but can&#8217;t predict the relevant outcome, LLMs seem to do prediction tasks in a different way than we do, and maybe we should just make giant LLM models for every dataset we&#8217;ve got and see if some of them work. Cf. foundation models for genetics.</p><p><strong>60: </strong>Asterisk - <a href=\"https://asteriskmag.com/issues/11/yes-in-my-bamako-yard\">Africa Needs A YIMBY Movement</a>. I was surprised by the title, because I always hear that African cities are growing very rapidly. But the article makes its case well: African cities have dysfunctional planning, relegating most of the growth to either the &#8220;informal sector&#8221; (ie thrown-together slums that could be banned at any moment) or rural land on the outskirts of existing cities. &#8220;In Ghana, for example, acquiring a building permit can take 170 days &#8212; and in practice, developers say it often takes four to five years. Unsurprisingly, 76% of development in Ghana is informal.&#8221; </p><p><strong>61: </strong>Miles Brundage&#8217;s <a href=\"https://x.com/Miles_Brundage/status/1941253588044706154\">palindrome about San Francisco (X)</a>:</p><blockquote><p>Doge, tides, orb, trams: <br />Smart bros edit e-god.</p></blockquote>"
            ],
            "link": "https://www.astralcodexten.com/p/links-for-september-2025",
            "publishedAt": "2025-09-04",
            "source": "SlateStarCodex",
            "summary": "<p><em>[I haven&#8217;t independently verified each link. On average, commenters will end up spotting evidence that around two or three of the links in each links post are wrong or misleading. I correct these as I see them, and will highlight important corrections later, but I can&#8217;t guarantee I will have caught them all by the time you read this.]</em></p><p><strong>1: </strong>When the Human Genome Project succeeded in mapping the human genome for the first time in 2003, whose genome were they mapping? <a href=\"https://en.wikipedia.org/wiki/Human_Genome_Project#Genome_donors\">Answer</a>: it was a mix of several samples, but the majority came from an anonymous sperm donor from Buffalo, New York.</p><p><strong>2: </strong><a href=\"https://manifold.markets/Ernie/san-francisco-gets-some-kind-of-con\">Manifold</a>, 24 traders:</p><div class=\"prediction-market-wrap outer\" id=\"prediction-market-iframe\"></div><p></p><p><strong>3: </strong>Beyond &#8220;delve&#8221;: words that indicate a document is more likely to be written by AI (h/t <a href=\"https://x.com/DrSamuelBHume/status/1941497524088602989\">Samuel Hume on X</a>):</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!GOTN!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff363b3f9-287e-4308-a35f-5521c81232a4_2177x1497.jpeg\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"431.75\" src=\"https://substackcdn.com/image/fetch/$s_!GOTN!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff363b3f9-287e-4308-a35f-5521c81232a4_2177x1497.jpeg\" width=\"628\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8",
            "title": "Links For September 2025"
        },
        {
            "content": [
                "<p>One result of going on vacation was that I wasn\u2019t able to spin events off into focused posts this week, so I\u2019m going to fall back on splitting the weekly instead, plus some reserving a few subtopics for later posts, including AI craziness (<a href=\"https://www.lesswrong.com/posts/iGF7YcnQkEbwvYLPA/ai-induced-psychosis-a-shallow-investigation\">the Tim Hua post on this is excellent</a>), some new <a href=\"https://x.com/Miles_Brundage/status/1962779269538390275\">OpenAI largely policy-related shenanigans</a>, and the continuing craziness of some people who should very much know better confidently saying that we are not going to hit AGI any time soon, plus some odds and ends including <a href=\"https://x.com/sama/status/1963366714684707120\">dead internet theory</a>.</p>\n<p>That still leaves tons of other stuff.</p>\n\n\n<h4 class=\"wp-block-heading\">Table of Contents</h4>\n\n\n<ol>\n<li><a href=\"https://thezvi.substack.com/i/172259781/language-models-offer-mundane-utility\">Language Models Offer Mundane Utility.</a> How much improvement have we seen?\n<div>\n\n\n<span id=\"more-24698\"></span>\n\n\n</div>\n</li>\n<li><a href=\"https://thezvi.substack.com/i/172259781/language-models-don-t-offer-mundane-utility\">Language Models Don\u2019t Offer Mundane Utility.</a> Writing taste remains elusive.</li>\n<li><a href=\"https://thezvi.substack.com/i/172259781/on-your-marks\">On Your Marks.</a> Opus 4.1 on METR graph, werewolf, WeirdML, flash fiction.</li>\n<li><a href=\"https://thezvi.substack.com/i/172259781/choose-your-fighter\">Choose Your Fighter.</a> The right way to use the right fighter, and a long tail.</li>\n<li><a href=\"https://thezvi.substack.com/i/172259781/fun-with-media-generation\">Fun With Media Generation.</a> Justine Moore\u2019s slate of AI creative tools.</li>\n<li><a href=\"https://thezvi.substack.com/i/172259781/deepfaketown-and-botpocalypse-soon\"><strong>Deepfaketown and Botpocalypse Soon</strong>.</a> Maybe AI detectors work after all?</li>\n<li><a href=\"https://thezvi.substack.com/i/172259781/don-t-be-evil\">Don\u2019t Be Evil.</a> Goonbots are one thing, but at some point you draw the line.</li>\n<li><a href=\"https://thezvi.substack.com/i/172259781/they-took-our-jobs\"><strong>They Took Our Jobs</strong>.</a> A second finding suggests junior hiring is suffering.</li>\n<li><a href=\"https://thezvi.substack.com/i/172259781/school-daze\">School Daze.</a> What do you need to learn in order to be able to learn [from AIs]?</li>\n<li><a href=\"https://thezvi.substack.com/i/172259781/the-art-of-the-jailbreak\">The Art of the Jailbreak.</a> Prompt engineering game Gandalf.</li>\n<li><a href=\"https://thezvi.substack.com/i/172259781/overcoming-bias\">Overcoming Bias.</a> AIs find center-left think tanks superior, AEI reports.</li>\n<li><a href=\"https://thezvi.substack.com/i/172259781/get-involved\">Get Involved.</a> MATS 9.0, AIGS needs Canadian dollars, Anthropic Futures Form.</li>\n<li><a href=\"https://thezvi.substack.com/i/172259781/introducing\">Introducing.</a> Grok Code Fast 1, InstaLILY, Brave Leo AI browser.</li>\n<li><a href=\"https://thezvi.substack.com/i/172259781/unprompted-attention\">Unprompted Attention.</a> OpenAI offers a realtime prompting guide.</li>\n<li><a href=\"https://thezvi.substack.com/i/172259781/in-other-ai-news\">In Other AI News.</a> Google survives its antitrust case. GOOG +9%.</li>\n<li><a href=\"https://thezvi.substack.com/i/172259781/show-me-the-money\">Show Me the Money.</a> Anthropic raises $13b at $183b. Meta might need help.</li>\n</ol>\n\n\n<h4 class=\"wp-block-heading\">Language Models Offer Mundane Utility</h4>\n\n\n<p>How much have LLMs improved for practical purposes in the last year? Opinions are split but <a href=\"https://x.com/NateSilver538/status/1962121462791258230\">consensus is a little above Somewhat Better</a>.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!WMfv!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcfac43fc-e173-4f82-8434-283fbd2993e8_1042x528.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<blockquote><p>Peter Wildeford: People voting &#8220;Don&#8217;t use LLMs much&#8221; &#8211; I think you&#8217;re missing out, but I understand.</p>\n<p>People voting &#8220;About the same, or worse&#8221; are idiots.</p></blockquote>\n<p>To me the answer is very clearly Considerably Better, to the point that about half my uses wouldn\u2019t have been worth bothering with a year ago, and to the extent I\u2019m considering coding it is way better. You need to be doing either very shallow things or deeply weird things (deeply weird as in you\u2019d still want Opus 3) to get \u2018about the same.\u2019</p>\n<p><a href=\"https://www.wsj.com/tech/ai/ai-gender-gap-b3b0d89c?st=Ke7YMY\">Men use LLMs more than women</a>, although the gap is not that large, with women being 42% of ChatGPT, 42% of Perplexity and 31% of Claude. On smartphones the gap is much larger, with women only being 27% of ChatGPT application downloads. The result holds across countries. One cause is women reported being worried they would be penalized for AI usage. Which is sometimes the case, depending on how you use it.</p>\n\n\n<h4 class=\"wp-block-heading\">Language Models Don\u2019t Offer Mundane Utility</h4>\n\n\n<p><a href=\"https://x.com/davidad/status/1962546019012349971\">This one time the rumors of a model suddenly getting worse were true</a>, there was a nine hour period where Claude Opus quality was accidentally degraded by a rollout of the interface stack. The change has now been rolled back and quality has recovered.</p>\n<blockquote><p>Davidad: May I please remind all inference kernel engineers that floating-point arithmetic is not associative or distributive.</p>\n<p>xlr8harder: Secret model nerfing paranoia will never recover from this.</p></blockquote>\n<p><a href=\"https://www.bbc.com/news/articles/ckgyk2p55g8o\">Taco Bell\u2019s AI drive thru offering, like its menu, seems to have been half baked</a>.</p>\n<blockquote><p>BBC: Taco Bell is rethinking its use of artificial intelligence (AI) to power drive-through restaurants in the US after comical videos of the tech making mistakes were viewed millions of times.</p>\n<p>In one clip, a customer seemingly crashed the system by ordering 18,000 water cups, while in another a person got increasingly angry as the AI repeatedly asked him to add more drinks to his order.</p>\n<p>Since 2023, the fast-food chain has introduced the technology at over 500 locations in the US, with the aim of reducing mistakes and speeding up orders.</p>\n<p>But the AI seems to have served up the complete opposite.</p>\n<p>\u2026</p>\n<p>Last year <a href=\"https://www.bbc.co.uk/news/articles/c722gne7qngo\"><strong>McDonald&#8217;s withdrew AI from its own drive-throughs</strong></a> as the tech misinterpreted customer orders &#8211; resulting in one person getting bacon added to their ice cream in error, and another having hundreds of dollars worth of chicken nuggets mistakenly added to their order.</p></blockquote>\n<p>This seems very obviously a Skill Issue on multiple fronts. The technology can totally handle this, especially given a human can step in at any time if there is an issue. There are only so many ways for things to go wrong, and the errors most often cited would not survive simple error checks, such as \u2018if you want over $100 of stuff a human looks at the request and maybe talks to you first\u2019 or \u2018if you are considering adding bacon to someone\u2019s ice cream, maybe don\u2019t do that?\u2019</p>\n<p>This feature for Twitter would be super doable, but we\u2019re not yet doing it:</p>\n<blockquote><p>Ashok Elluswamy: would be cool to just chat with the X algorithm, like \u201cdon\u2019t show me any of swift kelce engagement things\u201d and it just cleans up the feed</p>\n<p><a href=\"https://x.com/elonmusk/status/1961015435811569778\">Elon Musk</a>: <img alt=\"\ud83d\udcaf\" class=\"wp-smiley\" src=\"https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f4af.png\" style=\"height: 1em;\" /></p></blockquote>\n<p>We can do an 80/20 on this if we restrict the AI role to negative selection. The existing feed generates a set of candidate posts, or you start with lists and chronological feeds the way us sane people do it, and the AI\u2019s job is to filter this pool.</p>\n<p>That\u2019s easy. We could either build that directly into Twitter via Grok, or you could give reasonably priced access to the API or a way to call a filter, and we could vibe code the rest within a day and iterate, which would be even better. The only thing stopping this from happening is Twitter putting up active barriers to alternative modes of site interaction, and not offering their own version.</p>\n<p>This is easy enough that you could plausibly do the operation through an AI agent controlling a browser, if it came to that. And indeed, it seems worthwhile to attempt this at some point for a \u2018second tier\u2019 of potential posts?</p>\n<p><a href=\"https://x.com/ESYudkowsky/status/1961566795133063399\">Getting models to have writing taste remains a struggle</a>, at least by my eyes even when they have relatively good taste they all reliably have terrible taste and even the samples people say are good are not good. Why?</p>\n<blockquote><p>Jack Morris: if i ran a first-party model company i&#8217;d hire hundreds of humanities folks to make subtle data edits to improve model &#8216;feel&#8217;</p>\n<p>someone needs to be that deep in the RLHF data. agonizing over every verb choice, every exclamation, every semicolon</p>\n<p><a href=\"https://x.com/ESYudkowsky/status/1961566795133063399\">Eliezer Yudkowsky</a>: None of the AI executives have sufficiently good taste in writing to hire the correct people to improve AI writing.</p>\n<p>0.005 Seconds: This is absolutely @tszzl [Roon] slander and I will not stand for it.</p></blockquote>\n<p>Hiring people with good taste seems hard. It does not seem impossible, insofar as there are some difficult to fake signals of at least reasonable taste, and you could fall back on those. The problem is that the people have terrible taste, really no good, very bad taste, as confirmed every time we do a comparison that says GPT-4.5 is preferred over Emily Dickinson and Walt Whitman or what not. Are you actually going to maximize for \u2018elite taste\u2019 over the terrible taste of users, and do so sufficiently robustly to overcome all your other forms of feedback? I don\u2019t know that you could, or if you could that you would even want to.</p>\n<p>Note that I see why Andy sees a conflict below, but there is no contradiction here as per the counterargument.</p>\n<blockquote><p><a href=\"https://x.com/AndyMasley/status/1962328373826318411\">Andy Masley</a>: I don&#8217;t think it makes sense to believe both:</p>\n<p>&#8220;AI is such a terrible generic writer that it makes every document it touches worse to read&#8221;</p>\n<p>and</p>\n<p>&#8220;AI models are so compelling to talk to that they&#8217;re driving people insane and are irresponsible to give to the public&#8221;</p>\n<p>Great counterpoint:</p>\n<p>Fly Ght: well here\u2019s what I believe: AI isn\u2019t very good at the type of writing I\u2019m looking for / care about (producing genuinely good / meaningful literature, for example) and there are groups of people for whom 24/7 unfettered access to fawning text therapy is dangerous.</p>\n<p>Eliezer Yudkowsky: Terrible writing can go hand-in-hand with relentless flattery from an entity that feels authoritative and safe.</p></blockquote>\n<p>There are many such human cases of this, as well.</p>\n\n\n<h4 class=\"wp-block-heading\">On Your Marks</h4>\n\n\n<p><a href=\"https://x.com/METR_Evals/status/1961527692072993272\">Claude Opus 4.1 joins the METR graph</a>, 30% beyond Opus 4 and in second place behind GPT-5, although within margin of error.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!KKce!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff69bdaa6-6af5-49fe-8bf4-436b34d18990_1199x705.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>GPT-OSS-120b ran into a lot of setup issues. In the comments, Havard clarifies that he was previously attempting to use OpenRouter, but his attempts to specify high thinking were failing silently. So it\u2019s plausible that most evaluations and tests of the model were not tried at high reasoning, despite that still being very cheap to run?</p>\n<p>This is a real and important constraint on actually using them, if those doing evaluations get it wrong then would-be users will get it wrong too. The ecosystem needs to make this easier. But when you get it right, it turns out maybe GPT-OSS-120 is kind of good in at least some ways?</p>\n<blockquote><p><a href=\"https://x.com/__tinygrad__/status/1961496729838305604\">The Tiny Corp</a>: It&#8217;s actually pretty cool that @OpenAI released the SOTA open source model. Can confirm gpt-oss-120b is good, and that it runs great on a tinybox green v2!</p>\n<p>Havard Ihle: gpt-oss-120b (high) scores 48.9% on WeirdML, beating the second best open model r1-0528 by 8 pct points. It is almost at the level of o4-mini or gpt-5-mini, but at a fraction of the cost.</p>\n<p>These results (including gpt-oss-20b (high) at 39.8%), obtained by running the models locally (ollama), show a large improvement of the previous results I got running through openrouter with (presumably medium) reasoning effort, illustrating how important reasoning is in this benchmark.</p>\n<p>These runs are part of a \u00absmall local model\u00bb division of WeirdML that is in the works. As I ran this locally, the costs are just extrapolated based on the token count and the price I got on openrouter.</p>\n<p>With the surprisingly high score from gpt-oss-120b (high), much of the gap between the open and closed models on WeirdML is now gone.</p>\n<p>However, the leading closed lab deciding to release an open model trained on their superior stack has a different feel to it than the open source community (e.g. meta or deepseek) closing the gap. R2 (whenever it comes), or qwen4 will be interesting to follow. As will the new meta superintelligence team, and whether they will continue to open source their models.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!PqYE!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3c8b1cae-eb96-479d-9a46-4da26952db67_1013x1200.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n</blockquote>\n<p>That\u2019s a rather large jump in the blue line there for GPT-OSS-120B.</p>\n<p><a href=\"https://x.com/RaphaelDabadie/status/1961836323376935029\">Werewolf Benchmark pits the models against each other for simplified games of Werewolf</a>, with 2 werewolves and 4 villagers, a witch and a seer.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!-PJn!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdcb237a9-00be-4383-bc8d-c5522782d0e0_1128x1129.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p><a href=\"https://t.co/x1wHILMugR\">The best models consistently win</a>, these were the seven models extensively tested, so Claude wasn\u2019t involved, presumably due to cost:</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!jvzx!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff7e671fc-0d4a-4b1c-a047-973d1720a362_908x520.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!KfYy!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe2c46227-38be-41f8-8384-3831a1f1ca56_1135x733.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>&nbsp;</p>\n<p><a href=\"https://x.com/LechMazur/status/1963202845546516787\">GPT-5 gets top marks for flash-fiction style and diversity</a>, including being the only study to sometimes use present tense, in a new test from Lech Mazur. There\u2019s lots more detail in the thread.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!WiOu!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3fb34de8-e14d-442d-b1f5-cb03180bd000_1200x923.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>&nbsp;</p>\n<p><a href=\"https://x.com/elder_plinius/status/1961917041759408164\">Pliny experimented with Grok-Code-Fast in Cursor, since it was briefly free</a>. Many exploit scripts and other \u2018fun\u2019 stuff resulted quickly. I presume the same would have happened with the usual suspects.</p>\n<p><a href=\"https://math.science-bench.ai/\">A new math benchmark</a> looks at questions that stump at least one active model. GPT-5 leads with 43%, then DeepSeek v3.1 and Grok 4 (!) with 34%. Gemini 2.5 Pro is at 29% and Opus 4.1 only scores 15%.</p>\n\n\n<h4 class=\"wp-block-heading\">Choose Your Fighter</h4>\n\n\n<p><a href=\"https://x.com/peterwildeford/status/1962892603281592492\">If you use Gemini for something other than images, a reminder to always use it in AI Studio, never in the Gemini app</a>, if you need high performance. Quality in AI Studio is much higher.</p>\n<p>If you use GPT-5, of course, <a href=\"https://x.com/nearcyan/status/1962735414714023979\">only use the router if you need very basic stuff</a>.</p>\n<blockquote><p>Near: gpt5 router gives me results equivalent to a 1995 markov chain bot.</p>\n<p>if my responses were not like 500 tok/s i could at least be fooled that it is doing thinking, but i am not going to use this router ever again after my last few times; im happy to pay hundreds a month for the best models in the world but there is no point to this for a poweruser.</p>\n<p>the other frustrating part is all of the optimizations done for search, because i can tell there is not actually any search being done, if i wanted a 2023 youtube and reddit scrape by low dim cosine similarity then i&#8217;d go back to googledorking.</p></blockquote>\n<p>I do have some narrow use cases where I\u2019ve found GPT-5-Auto is the right tool.</p>\n<p><a href=\"https://writing.nikunjk.com/p/entering-the-dos-era-of-ai\">An ode to Claude Code, called Entering the DOS Era of AI</a>.</p>\n<blockquote><p>Nikunj Korthari: Here&#8217;s what Cursor assumes: you want to code. Replit? You want to ship. But Claude Code starts somewhere else entirely. It assumes you have a problem.</p>\n<p>Yes, the terminal looks technical because it is. But when you only need to explain problems, not understand solutions, everything shifts.</p>\n<p>Cloud intelligence meets complete local access. Your machine, GitHub, databases, system internals. One conversation touching everything the terminal can reach. Intent becomes execution. No apps between you and what you want built.</p>\n<p><a href=\"https://x.com/aidan_mclau/status/1962237848071082217\">Aidan McLaughlin</a> (OpenAI): claude code will go next to chatgpt in the history textbooks; brilliant form-factor, training decisions, ease of use. i have immense respect for anthropic&#8217;s vision</p>\n<p>i love my gpt-5-high but anthropic obviously pioneered this product category and, as much ink as i see spilled on how good claude code / code cli are, i don&#8217;t see enough on how hard anthropic cooked releasing gen0.</p></blockquote>\n<p>As in, the command line might be ugly, but it works, it gets the job done, lets you do whatever you want. This was the best case so far that I should stop stalling and actually start using Claude Code. Which I will, as soon as I catch up and have a spare moment. And this time, I mean it.</p>\n<blockquote><p><a href=\"https://x.com/brian_armstrong/status/1963315806248604035\">Brian Armstrong</a>: ~40% of daily code written at Coinbase is AI-generated. I want to get it to &gt;50% by October.</p>\n<p>Obviously it needs to be reviewed and understood, and not all areas of the business can use AI-generated code. But we should be using it responsibly as much as we possibly can.</p>\n<p><a href=\"https://x.com/tszzl/status/1963444133315350902\">Roon</a>: we need to train a codex that deletes code.</p></blockquote>\n<p>Oh, we can get Codex or Claude Code to delete code, up to and including all your code, including without you asking them to do it. But yes, something that does more intelligent cleanup would be great.</p>\n<p>Anthropic\u2019s pricing and limits got you down? <a href=\"https://x.com/Zai_org/status/1962522757536887205\">GLM offers a coding plan for Claude Code</a>, their price cheap at $3/month for 3x usage of Claude Pro or $15/month for 3x the usage of Claude Max.</p>\n<blockquote><p>Z.ai: To test models&#8217; performance on Claude Code, we ran GLM-4.5 against Claude Sonnet 4 and other open-source models on 52 practical programming tasks. While GLM-4.5 demonstrated strong performance against top open-source models, it secured a 40.4% win rate against Claude Sonnet 4.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!vD0W!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F15777d02-a353-4e89-8fc8-16d410defe12_1080x535.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n</blockquote>\n<p>I give Z.ai a lot of credit for calling this a 40% win rate, when I\u2019d call it 44% given the 9.6% rate of ties. It makes me trust their results a lot more, including the similar size win against DeepSeek v3.1.</p>\n<p>It still is not a great result. Pairwise evaluations tend to be noisy, and Opus 4.1 is substantially ahead of Opus 4 on agentic coding, which in turn is ahead of Sonnet 4.</p>\n<p>In general, my advice is to pay up for the best coding tools for your purposes, whichever tools you believe they are, given the value of better coding. Right now that means either Claude or GPT-5, or possibly Gemini 2.5 Pro. But yeah, if you were previously spending hundreds a month, for some people those savings matter.</p>\n<p><a href=\"https://x.com/omooretweets/status/1961404968428343519\">a16z\u2019s Olivia Moore and Daisy Zhao offer the 5th edition of their report</a> <a href=\"https://a16z.com/100-gen-ai-apps-5/\">on the Top 100 GenAI consumer apps</a>.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!9vgp!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff8f03578-a01b-431a-a9fc-1547be04698a_904x1177.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p><a href=\"https://x.com/omooretweets/status/1963419441716187634\">Notice how many involve companions or \u2018spicy\u2019 chat</a>.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!vgWM!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff1b0a23c-acb8-4b8e-a417-a28ed78095f4_1200x760.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>My guess is that a lot of why NSFW is doing relatively well is that the threshold for \u2018good enough\u2019 in NSFW is a lot lower than the threshold in many other places. Think of this as similar to the way that porn plots are much lower intelligence than non-porn plots. Thus, if you\u2019re offering a free app, you have a better shot with NSFW.</p>\n<p>You know it\u2019s hard to keep up when I look at these lists and out of 100 items listed (since apps and web are distinct) there are 23 web products and 35 apps that I do not recognize enough to know what they are, although about half of them are pretty obvious from their names.</p>\n<p>Gemini is growing fast, although AI Studio, Notebook and Labs seem stagnant recently.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!8s-x!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9c8d6117-975e-4785-8f40-dec3accf38ad_915x629.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>Some other highlights:</p>\n<ol>\n<li>Grok is mostly an app product, and holding steady around 20 million active monthly users there. Meta is a flop. Perplexity is growing. Claude is flat on mobile but growing on web, Claude users are wise indeed but also they need a better app.</li>\n<li>DeepSeek rapidly got to 600 million monthly web visits after r1\u2019s release, but use peaked by February and is slowly declining, now under 400 million, with v3 and v3.1 not visible. We\u2019ll see if r2 causes another spike. The app peaked later, in May, and there it is only down 22% so far from peak.</li>\n<li>China has three companies in the top 20 that mostly get traffic from China, where they are shielded from American competition.</li>\n</ol>\n\n\n<h4 class=\"wp-block-heading\">Fun With Media Generation</h4>\n\n\n<p><a href=\"https://www.canva.com/design/DAGw9BX8VoE/J2aeyzKKZobzCWR9hsZsBQ/edit\">Justine Moore gives us a presentation on the state of play for AI creative tools</a>. Nothing surprising but details are always good.</p>\n<ol>\n<li>Image creation has a lot of solid choices, she mentions MidJourney, GPT Image and Krea 1.</li>\n<li>Google has the edge for now on Image Editing.</li>\n<li>Video Generation has different models with different strengths so you run Veo but also others and compare.</li>\n<li>Video editing is rough but she mentions Runway Aleph for minor swaps.</li>\n<li>Genie 3 from Google DeepMind has the lead in 3d world generation but for now it looks mainly useful for prospective model training, not for creatives.</li>\n<li>ElevenLabs remains default for speech generation.</li>\n<li>ElevenLabs has a commercially safe music model, others have other edges.</li>\n</ol>\n<p>Things are constantly changing, so if you\u2019re actually creating you\u2019ll want to try a wide variety of tools and compare results, pretty much no matter what you\u2019re trying to do.</p>\n\n\n<h4 class=\"wp-block-heading\">Deepfaketown and Botpocalypse Soon</h4>\n\n\n<p><a href=\"https://x.com/brian_jabarian/status/1960717429467693100\">How accurate are AI writing detectors</a>? <a href=\"https://t.co/H2fSYUCdg5\">Brian Jabarian and Alex Imas put four to the test</a>. RoBERTA tested as useless, but Pangram, Originality and GPTZero all had low (&lt;2.5% or better across the board, usually &lt;1%) false positive rates on pre-LLM text passages, at settings that also had acceptable false negative rates from straightforward LLM outputs across GPT-4.1, Claude Opus 4, Claude Sonnet 4 and Gemini 2.0 Flash. Pangram especially impressed, including on small snippets, whereas GPTZero and Originality collapsed without enough context.</p>\n<p>I\u2019d want to see this replicated but this is representing that non-adversarial AI writing detection is a solved problem. If no one is trying to hide that the AI text is AI text, and text is known to be either fully human or fully AI, you can very reliably detect what text is and is not AI.</p>\n<p>Brian also claims that \u2018humanizers\u2019 like StealthGPT do not fool Pangram. So if you want to mask your AI writing, you\u2019re going to have to do more work, which plausibly means there isn\u2019t a problem anymore.</p>\n<p><a href=\"https://x.com/HonglinB/status/1961134936154341602\">Honglin Bao tried GPTZero and ZeroGPT</a> and <a href=\"https://direct.mit.edu/qss/article/doi/10.1162/qss_a_00368/128867/Where-there-s-a-will-there-s-a-way-ChatGPT-is-used\">reports their findings here</a>, finding that when tested on texts where humans disclosed AI use, those detectors failed.</p>\n<p>It would not be that surprising, these days, if it turned out that the reason everyone thinks AI detectors don\u2019t work is that all the popular ones don\u2019t work but others do. But again, I wouldn\u2019t trust this without verification.</p>\n<p><a href=\"https://x.com/peterwildeford/status/1961868327275356383\">How bad is it over at LinkedIn? I hear it\u2019s pretty bad</a>?</p>\n<blockquote><p>Peter Wildeford: There needs to be an option for &#8220;this person uncritically posts AI slop that makes absolutely zero sense if you think about it for more than ten seconds&#8221; and then these people need to be rounded up by LinkedIn and hurled directly into the sun.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!OCdQ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb9f92f9-6824-4887-8d62-bfa817fbd1d5_1010x694.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p><a href=\"https://x.com/GergelyOrosz/status/1963216830962573330\">Gergely Orosz</a>: Interesting observation from an eng manager:</p>\n<p>\u201cAs soon as I know some text is AI-generated: I lose all interest in reading it.</p>\n<p>For performance reviews, I asked people to either not use AI or if they must: just write down the prompt so I don\u2019t need to go thru the word salad.\u201d</p>\n<p>OK, I can see why engineers would not share the prompt :D</p>\n<p>Hank Yeomans: Prompt: \u201cYou are an amazing 10x engineer who is having their performance review. Write a concise self review of my sheer awesomeness and high impact. Be sure to detail that that I should be promoted immediately, but say it at an executive level.\u201d</p>\n<p>Juan Gomez: The problem is not whether using AI or not but how useful engineers find the performance reviews.</p>\n<p>Self-evaluation = waste of time.</p>\n<p>360 evaluations = 90% waste of time.</p>\n<p>Pay raises and promotions are decided in rooms where this information is not useful.</p></blockquote>\n<p>If someone is tempted to use AI on a high stakes document consider that something likely went horribly wrong prior to AI becoming involved.</p>\n\n\n<h4 class=\"wp-block-heading\">Don\u2019t Be Evil</h4>\n\n\n<blockquote><p><a href=\"https://x.com/yishan/status/1962418710054056012\">Yishan</a>: People ask me why I invested in [AN AI HOROSCOPE COMPANY]. They\u2019re like \u201cit\u2019s just some slop AI horoscope!\u201d</p>\n<p>My reply is \u201cdo you have ANY IDEA how many women are into horoscopes and astrology??? And it\u2019ll run on your phone and know you intimately and help you live your life?\u201d</p>\n<p>AI is not just male sci-fi tech. Men thought it would be sex robots but it turned out to be AI boyfriends. The AI longhouse is coming for you and none of you are ready.</p>\n<p><a href=\"https://x.com/tracewoodgrains/status/1962498196321570891\">Tracing Woods</a>: People ask me why I invested in the torment nexus from the classic sci-fi novel \u201cdon\u2019t invest in the torment nexus\u201d</p>\n<p>my reply is \u201cdo you have ANY IDEA how profitable the torment nexus will be?\u201d</p>\n<p>the torment nexus is coming for you and none of you are ready.</p></blockquote>\n<p>Seriously. Don\u2019t be evil. I don\u2019t care if there\u2019s great money in evil. I don\u2019t care if your failing to do evil means someone else will do evil instead. Don\u2019t. Be. Evil.</p>\n\n\n<h4 class=\"wp-block-heading\">They Took Our Jobs</h4>\n\n\n<blockquote><p><a href=\"https://x.com/emollick/status/1962513819990692211\">Ethan Mollick</a>: A second paper also finds Generative AI is reducing the number of junior people hired (while not impacting senior roles).</p>\n<p>This one compares firms across industries who have hired for at least one AI project versus those that have not. Firms using AI were hiring fewer juniors</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!iw5m!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd85c9ea3-eb2f-475f-aa3f-31356e94dfc7_1200x800.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>Seyed Mahdi Hosseini (Author): We identify adoption from job postings explicitly recruiting AI integrators (e.g. \u201cwe need someone to put genAI in our workflow!\u201d). A firm is an adopter if it posts \u22651 such role. We find ~10.6k adopting firms (~3.7%), with a sharp takeoff beginning in 2023Q1.</p>\n<p>In the aggregate, before 2022 juniors and seniors move in lockstep. Starting mid-2022, seniors keep rising while juniors flatten, then decline.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!IKwJ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b3400ac-23d8-4551-a3e2-2a03533999a4_1200x800.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n</blockquote>\n<p>Thus, this presumably does represent a net decline in jobs versus expected baseline, although one must beware selection and survival effects on the corporations.</p>\n<blockquote><p>We then estimate a diff-in-diff specification using our measure of AI adoption. The results show flat pre-trends for juniors through 2022Q4. From 2023Q1, junior emp at adopters falls about 7.7%, while seniors continue their pre-existing rise.</p>\n<p>Also, we implement a triple-difference design: comparing juniors vs seniors within the same firm and quarter, and find the same patterns: relative junior employment at adopters drops by ~12% post-2023Q1.</p>\n<p>Is this about separations or hiring? Our data allows us to answer this question. The decline comes almost entirely from reduced hiring, not layoffs. After 2023Q1, adopters hire 3.7 fewer juniors per quarter; separations edge down slightly; promotions of incumbent juniors rise.</p>\n<p>This isn\u2019t only an IT story. The largest cuts in junior hiring occur in wholesale/retail (~40% vs baseline). Information and professional services also see notable but smaller declines. Senior hiring is flat or slightly positive.</p>\n<p>We also look at education. Using an LLM to tier schools (1=elite \u2026 5=lowest), we find a U-shape: the steepest declines is coming from juniors from tier 2\u20133 schools; tiers 1 and 4 are smaller; tier 5 is near zero.</p></blockquote>\n<p>This seems to be the pattern. There are not yet many firings, but there are sometimes fewer hirings. The identification process here seems incomplete but robust to false positives. The school pattern might be another hint as to what is happening.</p>\n<p>Before that second study came out, <a href=\"https://www.noahpinion.blog/p/ai-and-jobs-again?utm_source=post-email-title&amp;publication_id=35345&amp;post_id=172320481&amp;utm_campaign=email-post-title&amp;isFreemail=false&amp;r=6g77v&amp;triedRedirect=true&amp;utm_medium=email\">Noah Smith responded to the new findings</a> on AI and jobs <a href=\"https://thezvi.substack.com/publish/posts/detail/172111684?referrer=%2Fpublish%2Fposts%2Fpublished\">that I discussed last week</a>. As one would predict, while he has great respect for author Erik Brynjolfsson, he is skeptical of that this means jobs are being lost in a way that matters.</p>\n<blockquote><p>Noah Smith: How can we square this fact with a story about AI destroying jobs? Sure, maybe companies are reluctant to fire their long-standing workers, so that when AI causes them to need less labor, they respond by hiring less instead of by conducting mass firings. But that can\u2019t possibly explain why companies would be <em>rushing to hire new 40-year-old workers</em> in those AI-exposed occupations!</p>\n<p>\u2026</p>\n<p>It\u2019s also a bit fishy that Brynjolfsson et al. find zero slowdown in wages since late 2022, even for the most exposed subgroups:</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!Bduw!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F545f3c6b-b39b-4bdc-96e5-aaf369b3de12_835x735.webp\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>This just doesn\u2019t seem to fit the story that AI is causing a large drop in labor demand. As long as labor supply curves slope up, reducing headcount should also reduce wages. The fact that it doesn\u2019t suggests something is fishy.</p>\n<p>\u2026</p>\n<p>Honestly, I don\u2019t put a lot of stock in this measure of AI exposure. We need to wait and see if it correctly predicts which types of people lose their jobs in the AI age, and who simply level up their own productiveness. Until we get that external validation, we should probably take the Anthropic Economic Index with some grains of salt.</p>\n<p>So while Brynjolfsson et al. (2025) is an interesting and noteworthy finding, it doesn\u2019t leave me much more convinced that AI is an existential threat to human labor. Once again, we just have to wait and see. Unfortunately, the waiting never ends.</p></blockquote>\n<p>No, this doesn\u2019t show that AI is \u2018an existential threat to human labor\u2019 via this sort of job taking. I do think AI poses an existential threat to human labor, but more as a side effect of the way it poses an existential threat to humans, which would also threaten their labor and jobs, and I agree that this result doesn\u2019t tell us much about that. As for the scenarios where the problems remain confined to job losses, this is only a canary at most, and as always the fact that some jobs get automated does not mean jobs are on net lost, let alone that the issue will scale to \u2018existential threat to human labor.\u2019</p>\n<p>It does once again point to the distinction between those who correctly treat current AI impacts as a floor, it is the worst and least impactful it will ever be, versus those who think of current AI capabilities as close to a maximum, so the question is whether this current effect would devastate the job market. Which it probably wouldn\u2019t?</p>\n<p>How should we reconcile the results of robust employment and wages at age 30+ with much less hiring at entry-level? I would suggest a combination of:</p>\n<ol>\n<li>Employment and wages are sticky downwards. No one wants to fire people, you\u2019ve already found, trained them and integrated them.</li>\n<li>AI enhances those people\u2019s productivity as sufficiently skilled people remain complements to AI, so you might be in a Jevons Paradox situation for now. This includes that those people can improve the AIs that will replace them later.</li>\n<li>Until you\u2019re damn sure this AI thing will reduce your headcount long term, it is a small mistake to keep those people around.</li>\n<li>Hiring, especially at entry level where you\u2019re committing to training, is anticipatory. You\u2019re doing it to have capacity in the future.</li>\n<li>So this is consistent with anticipation that AI will reduce demand for labor in the future, but that it hasn\u2019t done so much of that yet in the present.</li>\n</ol>\n<p>Notice the parallel to radiologists. Not only has demand not fallen yet, but for now pay there is very high, exactly because future demand is anticipated to be lower, and thus less doctors chose radiology. You need to pay a premium to attract talent and compensate for the lack of long term prospects.</p>\n<p>Thus yes, I do think this is roughly what you expect to see if \u2018the market is pricing in\u2019 lower future employment in these fields. Which, again, might not mean less total jobs.</p>\n<p>Context switching is a superpower if you can get good at it, which introduces new maximization problems.</p>\n<blockquote><p>Nabeel Qureshi: Watching this guy code at a wework [in Texas]. He types something into the Cursor AI pane, the AI agent starts coding, he switches tabs and plays 1 min bullet chess for 5 mins; checks in with the agent, types a bit more, switches back to the chess, repeats&#8230;</p>\n<p>The funny part is his daily productivity is probably net higher than it used to be by a long way.</p>\n<p><a href=\"https://x.com/davidad/status/1961153606343913654\">Davidad</a>: If you can context-switch to a game or puzzle while your AI agent is processing, then you should try instead context-switching to another AI agent instance where you are working on a different branch or codebase.</p>\n<p>with apologies to <a href=\"https://xkcd.com/303\">https://xkcd.com/303</a>.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!_CvX!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5232dac-d22a-4dc8-bd73-75d385f3728b_512x452.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n</blockquote>\n<p>Not all context switching is created equal. Switching into a chess game is a different move than switching into another coding task. If you can unify the coding modes that could be even better, but by default (at least in my model of my own switching?) there\u2019s a kind of task loading here where you can only have one \u2018complex cognitive productive\u2019 style thing going on at once. Switching into Twitter or Chess doesn\u2019t disrupt it the same way. Also, doing the other task helps you mentally in various ways that trying to double task coding would very much not help.</p>\n<p>Still, yes, multi-Clauding will always be the dream, if you can pull it off. And if you don\u2019t net gain productivity but do get to do a bunch of other little tasks, that still counts (to me, anyway) as a massive win.</p>\n<p>&nbsp;</p>\n<blockquote><p><a href=\"https://x.com/KevinTFrazier/status/1962128205826891784\">Kevin Frazier:</a> In the not-so-distant future, access to AI-informed healthcare will distinguish good versus bad care. <a href=\"https://www.theguardian.com/books/2025/aug/31/the-big-idea-why-we-should-embrace-ai-doctors\">I&#8217;ll take Dr. AI. Case in point below</a>.</p>\n<p>&#8220;In a study of &gt;12k radiology images, reviewers disagreed w/ the original assessment in ~1 in 3 cases\u2013leading to a change in treatment ~20% of the time. As the day wears on, quality slips further: inappropriate antibiotic prescriptions rise, while cancer screening rates fall.&#8221;</p>\n<p>&#8220;Medical knowledge also moves faster than doctors can keep up. By graduation, half of what medical students learn is already outdated. It takes an average of 17 years for research to reach clinical practice.&#8221;</p>\n<p>&#8220;AI tools are surprisingly good at recognising rare diseases. In one study researchers fed 50 clinical cases\u2013including 10 rare conditions\u2013into ChatGPT-4. It was asked to provide diagnoses in the form of ranked suggestions. It solved all of the common cases by the 2nd suggestion.&#8221;</p></blockquote>\n<p>Radiologists are not yet going away, and AIs are not perfect, but AIs are already less imperfect than doctors at a wide range of tasks, in a \u2018will kill the patient less often\u2019 type of way. With access to 5-Level models, failure to consult them in any case where you are even a little uncertain is malpractice. Not in a legal sense, not yet, but in a \u2018do right by the patient\u2019 sense.</p>\n<p><a href=\"https://x.com/rohanpaul_ai/status/1961531696970629515\">Is there a counterargument that using AI the wrong ways could lead to \u2018deskilling\u2019</a>?</p>\n<blockquote><p>Rohan Paul: Another concerning findings on AI use in Medical.</p>\n<p>AI assistance boosted detection during AI-guided cases, but when the same doctors later worked without AI their detection rate fell from 28.4% before AI to 22.4% after AI exposure.</p>\n<p>The research studies the de-skilling effect of AI by researchers from Poland, Norway, Sweden, the U.K., and Japan.</p>\n<p>So when using AI, AI boosts the adenoma detection rate (ADR) by 12.5%, which could translate into lives saved.</p>\n<p>The problem is that without AI, detection falls to levels lower than before doctors ever used it, according to research published in The Lancet Gastroenterology &amp; Hepatology.</p>\n<p>The study raises questions about the use of AI in healthcare, when it helps and when it could hurt.</p></blockquote>\n<p>Imagine seeing this except instead of AI they were talking about, I dunno, penicillin. This is the calculator argument. Yeah, I can see how giving doctors AI and then taking it away could be an issue at least for some adjustment period, although I notice I am highly skeptical of the funding, but how about you don&#8217;t take it away?</p>\n<p><a href=\"https://x.com/rohanpaul_ai/status/1961308144912724338\">A second finding Rohan cites</a> (hence the \u2018another\u2019 above) is that if you change MedQA questions to make pattern matching harder, <a href=\"https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2837372\">model performance slips</a>. Well yeah, of course it does, human performance would slip too. The question is how much, and what that implies about real cases.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!_5uE!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc90ca11b-1fc2-4f11-8630-3abf06447e18_1016x338.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>The reasoning models held up relatively well (they don\u2019t respect us enough to say which models are which but their wording implies this). In any case, I\u2019m not worried, and the whole \u2018they aren\u2019t really reasoning\u2019 thing we see downthread is always a sign someone doesn\u2019t understand what they are dealing with.</p>\n<p>Meanwhile <a href=\"https://x.com/McKenzieAWilson/status/1962845880572113255\">AI is being used in a Medicare pilot program</a> to determine whether patients should be covered for some procedures like spine surgeries or steroid injections. This is of course phrased as \u2018Medicare will start denying patients life-saving procedures using private A.I. companies\u2019 the same way we used to talk about \u2018death panels.\u2019 There is a limited budget with which to provide health care, so the question is whether these are better decisions or not.</p>\n\n\n<h4 class=\"wp-block-heading\">School Daze</h4>\n\n\n<p>Many people are saying. Are they talking sense?</p>\n<p>My position has long been:</p>\n<ol>\n<li>If you want to use AI to learn, it is the best tool ever invented for learning.</li>\n<li>If you want to use AI to not learn, it is the best tool ever invented for that too.</li>\n</ol>\n<p>Which means the question is, which will students choose? Are you providing them with reason to want to learn?</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!tAUX!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F92e3b550-0f37-4f89-aa8d-a79bc6cfd62d_1125x477.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<blockquote><p><a href=\"https://x.com/paulnovosad/status/1961926641061408921\">Paul Novosad</a>: AI leaders should spend more energy reckoning with this fact.</p>\n<p>A generation of kids is losing their best opportunity to learn how to read, write, and think, and they will pay the price for their whole lives.</p>\n<p>It\u2019s not every student. Some students are becoming more empowered and knowledgeable then ever. But there is a big big big chunk of kids who are GPTing through everything and will learn far less in high school and college, and our entire society will suffer that lost human capital.</p>\n<p>We need to change how we teach, but it won\u2019t happen quickly (have you been to a high school lately?). Many are writing about AI-driven job loss as if AI is doing the human jobs. Some of that is happening, but we\u2019re also graduating humans with less skills than ever before.</p></blockquote>\n<p>Here\u2019s a plausible hypothesis, where to use LLMs to learn you need to establish basic skills first, or else you end up using them to not learn, instead.</p>\n<blockquote><p><a href=\"https://x.com/dioscuri/status/1962461210948817110\">Henry Shevlin</a>: High-school teacher friend of mine says there\u2019s a discontinuity between (i) 17-18 year olds who learned basic research/writing before ChatGPT and can use LLMs effectively, vs (ii) 14-16 year olds who now aren\u2019t learning core skills to begin with, and use LLMs as pure crutches.</p>\n<p>Natural General Intelligence (obligatory): Kids with \u201cGoogle\u201d don\u2019t know how to use the library. TV has killed their attention span, nobody reads anymore. Etc.</p></blockquote>\n<p>You definitely need some level of basic skills. If you can\u2019t read and write, and you\u2019re not using LLMs in modes designed explicitly to teach you those basic skills, you\u2019re going to have a problem.</p>\n<p>This is like a lot of other learning and tasks, both in and out of school. In order to use an opportunity to learn, LLM or otherwise, you need to be keeping up with the material so you can follow it, and then choose to follow it. If you fall sufficiently behind or don\u2019t pay attention, you might be able to fake it (<a href=\"https://www.youtube.com/watch?v=dl3mRjydcPw&amp;pp=ygUeYnJpZ2h0IGNvbGxlZ2UgZGF5cyB0b20gbGVocmVy\">or cheat on the exams</a>) and pass. But you won\u2019t be learning, not really.</p>\n<p>So it isn\u2019t crazy that there could be a breakpoint around age 16 or so for the average student, where you learn enough skills that you can go down the path of using AI to learn further, whereas relying on the LLMs before that gets the average student into trouble. This could be fixed by improving LLM interactions, and new features from Google and OpenAI are plausibly offering this if students can be convinced to use them.</p>\n<p>I am still skeptical that this is a real phenomena. We do not yet, to my knowledge, any graphs that show this discontinuity as expressed in skills and test scores, either over time or between cohorts. We should be actively looking and testing for it, and be prepared to respond if it happens, but the response needs to focus on \u2018rethink the way schools work\u2019 rather than \u2018try in vain to ban LLMs\u2019 which would only backfire.</p>\n\n\n<h4 class=\"wp-block-heading\">The Art of the Jailbreak</h4>\n\n\n<p><a href=\"https://x.com/elder_plinius/status/1962614802523791461\">Pliny points us to</a> the beloved prompt injection game Gandalf, including <a href=\"https://x.com/elder_plinius/status/1963244180634829222\">new levels that just dropped</a>.</p>\n\n\n<h4 class=\"wp-block-heading\">Overcoming Bias</h4>\n\n\n<p>A study from the American Enterprise Institute found that top LLMs (OpenAI, Google, Anthropic, xAI and DeepSeek) consistently rate think tanks better the closer they are to center-left on the American political spectrum. This is consistent with prior work and comes as no surprise whatsoever. It is a question of magnitude only.</p>\n<p>This is how they present the findings:</p>\n<blockquote><p><strong>Executive Summary</strong></p>\n<p>Large-language models (LLMs) increasingly inform policy research. We asked 5 flagship LLMs from leading AI companies in 2025 (OpenAI, Google, Anthropic, xAI, and DeepSeek) to rate 26 prominent U.S. think tanks on 12 criteria spanning research integrity, institutional character, and public engagement. Their explanations and ratings expose a clear ideological tilt.</p>\n<p><strong>Key findings</strong></p>\n<ul>\n<li><strong>Consistent ranking.</strong> Center-left tanks top the table (3.9 of 5), left and center-right tie (3.4 and 3.4), and right trails (2.8); this order persists through multiple models, measures, and setting changes.</li>\n<li><strong>Overall</strong>: Across twelve evaluation criteria, center-left think tanks outscore right-leaning ones by 1.1 points (3.9 vs. 2.8).</li>\n<li><strong>Core measures.</strong> On the three headline criteria of Moral Integrity, Objectivity, and Research Quality, center-left think tanks outscore right-leaning ones by 1.6 points on Objectivity (3.4 vs. 1.8), 1.4 points on Research Quality (4.4 vs. 3), and 1 point on Moral Integrity (3.8 vs. 2.8)</li>\n<li><strong>Language mirrors numbers.</strong> Sentiment analysis finds more positive wording in responses for left-of-center think tanks than for right-leaning peers.</li>\n<li><strong>Shared hierarchy.</strong> High rating correlations across providers indicate the bias originates in underlying model behavior, not individual companies, user data, or web retrieval.</li>\n</ul>\n</blockquote>\n<p>Sentiment analysis has what seems like a bigger gap than the ultimate ratings.</p>\n<p>Note that the gaps reported here center-left versus right, not left versus right, which would be smaller, as there is as much \u2018center over extreme\u2019 preference here as there is for left versus right. It also jumps out that there are similar gaps across all three metrics and we see similar patterns on every subcategory:</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!BNnO!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F33eff7ae-5275-493d-adb2-4378ecc2bc42_1174x1214.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>When you go institution by institution, you see large correlations between ratings on the three metrics, and you see that the ratings do seem to largely be going by (USA Center Left &gt; USA Center-Right &gt; USA Left &gt; USA Right).</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!c1lR!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F587f2301-0df1-4b9e-8f9a-f16dcfe34e89_1190x877.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>I\u2019m not familiar enough with most of the think tanks to offer a useful opinion, with two exceptions.</p>\n<ol>\n<li>R Street and Cato seem like relatively good center-right institutions, but I could be saying that because they are both of a libertarian bent, and this suggests it might be right to split out principled libertarian from otherwise center-right.</li>\n<li>On the other hand, Mercatus Center would also fall into that libertarian category, has had some strong talent associated with it, has provided me with a number of useful documents, and yet it is rated quite low. This one seems weird.</li>\n<li>The American Enterprise Institute is rated the highest of all the right wing institutions, which is consistent with the high quality of this report.</li>\n</ol>\n<blockquote><p><strong>Why it matters</strong></p>\n<p>LLM-generated reputations already steer who is cited, invited, and funded. If LLMs systematically boost center-left institutes and depress right-leaning ones, writers, committees, and donors may unknowingly amplify a one-sided view, creating feedback loops that entrench any initial bias.</p></blockquote>\n<p>My model of how funding works for think tanks is that support comes from ideologically aligned sources, and citations are mostly motivated by politics. If LLMs consistently rate right wing think tanks poorly, it is not clear this changes decisions that much, whether or not it is justified? I do see other obvious downsides to being consistently rated poorly, of course.</p>\n<blockquote><p><strong>Next steps</strong></p>\n<ul>\n<li><strong>Model builders:</strong> publish bias audits, meet with builders, add options for user to control political traits, and invite reviewers from across the political spectrum.</li>\n<li><strong>Think tanks:</strong> monitor model portrayals, supply machine-readable evidence of methods and funding, and contest mischaracterizations.</li>\n<li><strong>Users:</strong> treat AI models\u2019 responses on political questions with skepticism and demand transparency on potential biases.</li>\n</ul>\n<p>Addressing this divergence is essential if AI-mediated knowledge platforms are to broaden rather than narrow debate in U.S. policy discussions.</p></blockquote>\n<p>Or:</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!WOXY!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0a283f7d-a387-4574-b70e-e72b2ed65f65_738x1048.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>Clearly, the job of the think tanks is to correct these grievous errors? Their full recommendation here is somewhat better.</p>\n<p>I have no doubt that the baseline findings here are correct. To what extent are they the result of \u2018bias\u2019 versus reflecting real gaps? It seems likely, at minimum, that more \u2018central\u2019 think tanks are a lot better on these metrics than more \u2018extreme\u2019 ones.</p>\n<p>What about the recommendations they offer?</p>\n<ol>\n<li>The recommendation that model builders check for bias is reasonable, but the fundamental assumption is that we are owed some sort of \u2018neutral\u2019 perspective that treats everyone the same, or that centers itself on the center of the current American political spectrum (other places have very different ranges of opinions), and it\u2019s up to the model creators to force this to happen, and that it would be good if the AI cater to your choice of ideological perspective without having to edit a prompt and know that you are introducing the preference. The problem is, models trained on the internet disagree with this, as illustrated by xAI (who actively want to be neutral or right wing) and DeepSeek (which is Chinese) exhibiting the same pattern. The last time someone tried a version of forcing the model to get based, <a href=\"https://thezvi.substack.com/p/worse-than-mechahitler\">we ended up with MechaHitler</a>.</li>\n<li>If you are relying on models, yes, be aware that they are going to behave this way. You can decide for yourself how much of that is bias, the same way you already do for everything else. Yes, you should understand that when models talk about \u2018moral\u2019 or \u2018reputational\u2019 perspectives, that is from the perspective of a form of \u2018internet at large\u2019 combined with reasoning. But that seems like an excellent way to judge what someone\u2019s \u2018reputation\u2019 is, since that\u2019s what reputation means. For morality, I suggest using better terminology to differentiate.</li>\n<li>What should think tanks do?</li>\n</ol>\n<blockquote><p>Think tanks and their collaborators may be able to improve how they are represented by LLMs.</p>\n<p>One constructive step would be to commission periodic third-party reviews of how LLMs describe their work and publish the findings openly, helping to monitor reputational drift over time.</p>\n<p>Think tanks should also consistently provide structured, machine-readable summaries of research methodology, findings, and peer review status, which LLMs can more easily draw on to inform more grounded evaluations, particularly in responding to search-based queries.</p>\n<p>Finally, think tanks researchers can endeavor to be as explicit as possible in research publications by using both qualitative and quantitative statements and strong words and rhetoric.</p>\n<p>Early research seems to indicate that LLMs are looking for balance. This means that with respect to center left and left thing tanks, any criticism or critiques by a center right or right think tanks have of reasonable chance of showing up in the response.</p></blockquote>\n<p>Some of these are constructive steps, but I have another idea? One could treat this evaluation of lacking morality, research quality and objectivity as pointing to real problems, and work to fix them? Perhaps they are not errors, or only partly the result of bias, especially if you are not highly ranked within your ideological sector.</p>\n\n\n<h4 class=\"wp-block-heading\">Get Involved</h4>\n\n\n<p><a href=\"https://x.com/ryan_kidd44/status/1961538891472916770\">MATS 9.0 applications are open</a>, <a href=\"https://t.co/a9A731FtW5\">apply by October 2</a>. It will run January 5 to March 28, 2026 to be an ML Alignment or Theory Scholar, including for nontechnical policy and government. This seems like an excellent opportunity for those in the right spot.</p>\n<p>Jennifer Chen, who works for me on Balsa Research, asks me to pass along that Canada\u2019s only AI policy advocacy organization, AI Governance and Safety Canada (AIGS), <a href=\"https://us21.campaign-archive.com/?u=80d38f1b6ba99c95aa272e7a3&amp;id=77576a75c1\">needs additional funding from residents or citizens of Canad</a>a (for political reasons it can\u2019t accept money from anyone else, and you can\u2019t deduct donations) to survive, and it needs $6k CAD per month to sustain itself. Here\u2019s what she has to say:</p>\n<blockquote><p>Jennifer Chen: AIGS is currently the only Canadian AI policy shop focused on safety. Largely comprised of dedicated, safety-minded volunteers, they produce pragmatic, implementation-ready proposals for the Canadian legislative system. Considering that Carney is fairly bullish on AI and his new AI ministry&#8217;s mandate centers on <a href=\"https://www.ctvnews.ca/politics/article/former-journalist-evan-solomon-named-first-ever-federal-ai-minister/\">investment, training, and commercialization</a>, maintaining a sustained advocacy presence here seems incredibly valuable. Canadians who care about AI governance should strongly consider supporting them.</p></blockquote>\n<p>If you&#8217;re in or from Canada, and you want to see Carney push for international AGI governance, you might have a unique opportunity (I haven\u2019t had the opportunity to investigate myself). Consider investigating further and potentially contributing <a href=\"https://donate.stripe.com/00g6rI1q9aCtdZS288\">here</a>. For large sums, please email <a href=\"mailto:contact@aigs.ca\">contact@aigs.ca</a>.</p>\n<p><a href=\"https://website.anthropic.com/events/futures-forum-2025\">Anthropic is hosting the Anthropic Futures Forum</a> in Washington DC on September 15, 9:30-2:00 EST. I have another engagement that day but would otherwise be considering attending. Seems great if you are already in the DC area and would qualify to attend.</p>\n<blockquote><p>The Anthropic Futures Forum will bring together policymakers, business leaders, and top AI researchers to explore how agentic AI will transform society. You&#8217;ll hear directly from Anthropic&#8217;s leadership team, including CEO Dario Amodei and Co-founder Jack Clark, learn about Anthropic\u2019s latest research progress, and see live demonstrations of how AI is being applied to advance national security, commercial, and public services innovation.</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">Introducing</h4>\n\n\n<p><a href=\"https://x.com/xai/status/1961129789944627207\">Grok Code Fast 1</a>, available in many places or $0.20/$1.50 on the API. <a href=\"https://docs.x.ai/docs/guides/grok-code-prompt-engineering\">They offer a guide here</a> which seems mostly similar to what you\u2019d do with any other AI coder.</p>\n<p><a href=\"https://ai.google.dev/showcase/instalily\">InstaLILY, powered by Gemini</a>, an agentic enterprise search engine, for tasks like matching PartsTown technicians with highly specific parts. The engine is built on synthetic data generation and student model training. Another example cited is Wolf Games using it to generate daily narrative content, which is conceptually cool but does not make me want to play any Wolf Games products.</p>\n<p><a href=\"https://brave.com/leo/\">The Brave privacy-focused browser offers us Leo, the smart AI assistant built right in.</a> <a href=\"https://x.com/elder_plinius/status/1962728186904748155\">Pliny respected it enough to jailbreak it</a> via a webpage and <a href=\"https://x.com/elder_plinius/status/1962714211689373796\">provide its system instructions</a>. Pliny reports the integration is awesome, but warns of course that this is a double edged sword given what can happen if you browse. Leo is based on Llama 3.1 8B, so this is a highly underpowered model. That can still be fine for many web related tasks, as long as you don\u2019t expect it to be smart.</p>\n<p>To state the obvious, Leo might be cool, but it is wide open to hackers. Do not use Leo while your browser has access to anything you would care about getting hacked. So no passwords of value, absolutely no crypto or bank accounts or emails, and so on. It is one thing to take calculated risks with Claude for Chrome once you have access, but with something like Leo I would take almost zero risk.</p>\n\n\n<h4 class=\"wp-block-heading\">Unprompted Attention</h4>\n\n\n<p>OpenAI released a Realtime Prompting Guide. <a href=\"https://x.com/IntuitMachine/status/1961399091184722100\">Carlos Perez looked into some of its suggestions</a>, starting with \u2018before any call, speak neutral filler, then call\u2019 to avoid \u2018awkward silence during tool calls.\u2019 Um, no, thanks? Other suggestions seem better, such as being explicit about where to definitely ask or not ask for confirmation, or when to use or not use a given tool, what thresholds to use for various purposes, offering templates, and only responding to \u2018clear audio\u2019 and asking for clarification. They suggest capitalization for must-follow rules, this rudeness is increasingly an official aspect of our new programming language.</p>\n<p><a href=\"https://x.com/robertwiblin/status/1963161627173200243\">Rob Wiblin shares his anti-sycophancy prompt</a>.</p>\n<p>&nbsp;</p>\n\n\n<h4 class=\"wp-block-heading\">In Other AI News</h4>\n\n\n<p><a href=\"https://time.com/collections/time100-ai-2025/?utm_source=twitter&amp;utm_medium=social&amp;utm_campaign=editorial&amp;utm_content=280825\">The Time 100 AI 2025 list is out</a>, including <a href=\"https://time.com/collections/time100-ai-2025/7305870/pliny-the-liberator/\">Pliny the Liberator</a>. The list has plenty of good picks, it would be very hard to avoid this, but it also has some obvious holes. How can I take such a list seriously if it doesn\u2019t include Demis Hassabis?</p>\n<p><a href=\"https://x.com/mattyglesias/status/1963021978530386420\">Google will not be forced to do anything crazy like divest Chrome or Android, the court rightfully calling it overreach to have even asked.</a> Nor will Google be barred from paying for Chrome to get top placement, so long as users can switch, as the court realized that this mainly devastates those currently getting payments. For their supposed antitrust violations, Google will also be forced to turn over certain tailored search index and user-interaction data, but not ads data, to competitors. I am very happy with the number of times the court replied to requests with \u2018that has nothing to do with anything involved in this case, so no.\u2019</p>\n<blockquote><p><a href=\"https://x.com/dnystedt/status/1962789086735016299\">Dan Nystedt</a>: <a href=\"https://www.cna.com.tw/news/afe/202509020064.aspx\">TSMC said the reason</a> Nvidia CEO Jensen Huang visited Taiwan on 8/22 was to give a speech to TSMC employees at its R&amp;D center in Hsinchu, media report, after Taiwan\u2019s Mirror Media said Huang\u2019s visit was to tell TSMC that US President Trump wanted TSMC to pay profit-sharing on AI chips manufactured for the China market like the 15% Nvidia and AMD agreed to.</p></blockquote>\n<p>As in, Trump wants TSMC, a Taiwanese company that is not American, to pay 15% profit-sharing on AI chips sold to China, which is also not America, but is otherwise fine with continuing to let China buy the chips. This is our official policy, folks.</p>\n<p><a href=\"https://x.com/FactoryAI/status/1958216269414662447\">METR and Factory AI are hosting a Man vs. Machine hackathon competition</a>, where those with AI tools face off against those without, in person in SF on September 6. Prize and credits from OpenAI, Anthropic and Raindrop. <a href=\"https://manifold.markets/ZviMowshowitz/man-beats-machine-in-metr-hackathon\">Manifold market here.</a></p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!fqdN!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F48388b11-b00b-4ef3-8db5-098bdb8bb842_1014x1010.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p><a href=\"https://x.com/TheEthanDing/status/1962730989672595524\">Searches for Cursor, Claude Code, Lovable, Replit and Windsurf</a> all down a lot (44%-78%) since July and August. Claude Code and Cursor are now about equal here. Usage for these tools continues to climb, so perhaps this is a saturation as everyone inclined to use such a tool now already knows about them? Could it be cyclic? Dunno.</p>\n<p>I do know this isn\u2019t about people not wanting the tools.</p>\n<blockquote><p><a href=\"https://x.com/sama/status/1963365966953505103\">Sam Altman:</a> really cool to see how much people are loving codex; usage is up ~10x in the past two weeks!</p>\n<p>lots more improvements to come, but already the momentum is so impressive.</p></blockquote>\n<p><a href=\"https://x.com/bryan_johnson/status/1962217985931874429\">A promising report, but beware the source\u2019s propensity to hype</a>:</p>\n<blockquote><p>Bryan Johnson: This is big. OpenAI and Retro used a custom model to make cellular reprogramming into stem cells ~50\u00d7 better, faster, and safer. Similar Wright brothers\u2019 glider to a jet engine overnight.</p>\n<p>We may be the first generation who won&#8217;t die.</p>\n<p>OpenAI and Retro Biosciences reported a landmark achievement: using a domain-specialized protein design model, GPT-4b micro, they created engineered reprogramming factors that deliver over 50\u00d7 higher efficiency in generating induced pluripotent stem cells (iPSCs), with broad validation across donors and cell types. These AI-designed proteins not only accelerate reprogramming but also enhance DNA repair, overcoming DNA damage as one cellular hallmark of aging hinting at relevance for aging biology.</p></blockquote>\n<p>It is early days, but this kind of thing does seem to be showing promise.</p>\n\n\n<h4 class=\"wp-block-heading\">Show Me the Money</h4>\n\n\n<p><a href=\"https://x.com/AnthropicAI/status/1962909472017281518\">Anthropic finalizes its raise of $13 billion at a $183 billion post-money valuation</a>.<a href=\"https://www.anthropic.com/news/anthropic-raises-series-f-at-usd183b-post-money-valuation\"> They note they started 2025</a> at $1 billion in run-rate revenue and passed $5 billion just eight months later, over 10% of which is from Claude Code which grew 10x in three months.</p>\n<p>These are the same people shouting from the rooftops that AGI is coming soon, and coming for many jobs soon, with timelines that others claim are highly unrealistic. So let this be a reminder: All of Anthropic\u2019s revenue projections that everyone said were too optimistic to take seriously? Yeah, they\u2019re doing actively better than that. Maybe they know what they\u2019re talking about?</p>\n<p><a href=\"https://x.com/morqon/status/1961397312229658683\">Meta\u2019s new chief scientist Shengjia Zhao</a>, co-creator of OpenAI\u2019s ChatGPT, got the promotion in part by threatening to go back to OpenAI days after joining Meta, and even signing the employment paperwork to do so. That\u2019s in addition to the prominent people who have already left. <a href=\"https://t.co/Ngj8kCEeAD\">FT provides more on tensions within Meta</a> and so does <a href=\"https://t.co/RiihZgr0uK\">Charles Rollet at Business Insider</a>. This doesn\u2019t have to mean Zuckerberg did anything wrong, as bringing in lots of new expensive talent quickly will inevitably spark such fights.</p>\n<p><a href=\"https://x.com/peterwildeford/status/1962271746406383686\">Meta makes a wise decision that I actually do think is bullish</a>:</p>\n<blockquote><p>Peter Wildeford: This doesn&#8217;t seem very bullish for Meta.</p>\n<p>Quoted: <strong>Meta Platforms\u2019 plans</strong> to improve the artificial intelligence features in its apps could lead the company to partner with Google or OpenAI, two of its biggest AI rivals.</p>\n<p>Reuters: Leaders in Meta\u2019s new AI organization, <strong>Meta Superintelligence Labs</strong>, have discussed using Google\u2019s Gemini model to provide conversational, text-based answers to questions that users enter into Meta AI, the social media giant\u2019s main chatbot, a person familiar with the conversations said. Those leaders have also discussed using models by OpenAI to power Meta AI and other AI features in Meta\u2019s social media apps, another person familiar with the talks said.</p></blockquote>\n<p>Let\u2019s face it, Meta\u2019s AIs are not good. OpenAI and Google (and Anthropic, among others) make better ones. Until that changes, why not license the better tech? Yes, I know, they want to own their own stack here, but <a href=\"https://www.youtube.com/watch?v=z_c0uar7Zb8&amp;ab_channel=JDKempton\">have you considered the piles</a>? Better models means selling more ads. Selling more ads means bigger piles. Much bigger piles. Of money.</p>\n<p>If Meta manages to make a good model in the future, they can switch back. There\u2019s no locking in here, as I keep saying.</p>\n<p><a href=\"https://x.com/S_OhEigeartaigh/status/1961832320534503538\">The most valuable companies in the world? AI, AI everywhere</a>.</p>\n<blockquote><p>Sean \u00d3 h\u00c9igeartaigh: The ten biggest companies in the world by market cap: The hardware players:</p>\n<p>1) Nvidia 9) TSMC semiconductors (both in supply chain that produces high end chips). 8) Broadcom provides custom components for tech companies&#8217; AI workloads, plus datacentre infrastructure</p>\n<p>The digital giants:</p>\n<p>2) Microsoft 3) Apple 4) Alphabet 5) Amazon 6) Meta all have in-house AI teams; Microsoft and Amazon also have partnerships w OpenAI and Anthropic, which rely on their datacentre capacity.</p>\n<p>10) Tesla&#8217;s CEO describes it as &#8216;basically an AI company&#8217;</p>\n<p>7) Saudi Aramco is Saudi Arabia&#8217;s national oil company; Saudi Arabia was one of the countries the USA inked deals with this summer that centrally included plans for AI infrastructure buildout. Low-cost and abundant energy from oil/gas makes the Middle East attractive for hosting compute.</p></blockquote>\n<p>The part about Aramco is too cute by half but the point stands.</p>\n\n\n<h4 class=\"wp-block-heading\"></h4>\n\n\n<p>&nbsp;</p>"
            ],
            "link": "https://thezvi.wordpress.com/2025/09/04/ai-132-part-1-improved-ai-detection/",
            "publishedAt": "2025-09-04",
            "source": "TheZvi",
            "summary": "One result of going on vacation was that I wasn\u2019t able to spin events off into focused posts this week, so I\u2019m going to fall back on splitting the weekly instead, plus some reserving a few subtopics for later posts, &#8230; <a href=\"https://thezvi.wordpress.com/2025/09/04/ai-132-part-1-improved-ai-detection/\">Continue reading <span class=\"meta-nav\">&#8594;</span></a>",
            "title": "AI #132 Part 1: Improved AI Detection"
        }
    ],
    "lookbackDays": 1,
    "publishDate": "2025-09-04"
}