{
    "articles": [
        {
            "content": [
                "<div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!TIDP!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3da51221-8a5a-4720-a29d-a9ebd50dcedc_2000x1260.jpeg\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"917\" src=\"https://substackcdn.com/image/fetch/$s_!TIDP!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3da51221-8a5a-4720-a29d-a9ebd50dcedc_2000x1260.jpeg\" width=\"1456\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p>During a <a href=\"https://www.youtube.com/watch?v=n1E9IZfvGMA\">recent interview</a>, Dwarkesh Patel and the CEO of Anthropic, Dario Amodei, discussed whether clinical trials will remain a meaningful bottleneck for drug development in the age of AI. Patel said that &#8220;most clinical trials fail because the drug does not work.&#8221; In response, Amodei speculated that as AI models get better at designing drugs, &#8220;clinical trials will be much faster &#8230; let&#8217;s say, they will take one year.&#8221;</p><p>This is a commonly voiced sentiment, but flawed. The truth is that the most significant barriers to progress today are rarely a lack of intelligence. London has a housing crisis even though the technology to design and construct homes has existed for centuries. The bottleneck in housing is not a lack of knowhow, but rather the weaponization of environmental regulations, planning, and NIMBYism. Much the same is true for clinical trials.</p><p>AI models can help design more elegant molecules, in the same way an architect can use AI to design more efficient floor plans, but neither intervention guarantees an efficient use of institutional machinery to make that design in the real world. Even the most promising drug candidates must be tested in human bodies which, in turn, need time to metabolize those drugs and develop side effects. Patients must be recruited and followed over time, and regulators must be satisfied. None of this is easily accelerated with AI.</p><p>Although I&#8217;m optimistic that AI will design better drug candidates, this alone cannot ensure &#8220;therapeutic abundance,&#8221; for a few reasons. First, because the history of drug development shows that even when strong preclinical models exist for a condition, like osteoporosis, the high costs needed to move a drug through trials deters investment &#8212; especially for chronic diseases requiring large cohorts. And second, because there is a feedback problem between drug development and clinical trials. In order for AI to generate high-quality drug candidates, it must first be trained on rich, human data; especially from early, small-n studies.</p><div class=\"subscription-widget-wrap-editor\"><div class=\"subscription-widget show-subscribe\"><div class=\"preamble\"><p class=\"cta-caption\">Deep writing about biology, delivered to your inbox.</p></div><form class=\"subscription-widget-subscribe\"><input class=\"email-input\" name=\"email\" tabindex=\"-1\" type=\"email\" /><input class=\"button primary\" type=\"submit\" value=\"Subscribe\" /><div class=\"fake-input-wrapper\"><div class=\"fake-input\"></div><div class=\"fake-button\"></div></div></form></div></div><h2><strong>Clinical Variables</strong></h2><p>The Amodei interview conflates two distinct variables: the success rate of a trial (based on the quality of a drug), and the speed of that trial, understood as an operational process.</p><p>The first variable &#8212; the success rate of a trial &#8212; is the probability that a drug candidate will be both efficacious and safe in humans. The current success rate for a drug entering clinical trials is only about ten percent, meaning <a href=\"https://pmc.ncbi.nlm.nih.gov/articles/PMC9293739/\">90 percent</a> of all drugs <em>fail</em>. Most AI efforts in biology aim to boost this success rate.</p><p>The second variable is the speed of data generation &#8212; the calendar time required to run an experiment after it has started. A clinical trial is just an experiment in human subjects, and the duration of that experiment is determined by both operational and biological constraints that are largely independent of how confident we are in the drug itself. Recruiting 1000 patients across 10 sites takes time; understanding and satisfying unclear regulatory requirements is onerous and often frustrating; and shipping temperature-sensitive vials to research hospitals across multiple states takes both time and money.</p><p>Amodei&#8217;s prediction that clinical trials could be done in a single year seems to assume that improving the first variable will also compress the second; but this is not so. Even if AI can help design more effective drugs, timelines will not compress until we solve the operational and regulatory bottlenecks of trials.</p><p>Admittedly, there is a tempting counter-argument: If AI <em>does </em>generate better drug candidates, then perhaps clinical trials will cease to be a meaningful bottleneck. If a drug is almost certainly going to work, then trials may become a &#8220;formality,&#8221; even if, in general, they remain unnecessarily costly and long.<a class=\"footnote-anchor\" href=\"https://www.asimov.press/feed#footnote-1\" id=\"footnote-anchor-1\" target=\"_self\">1</a> This argument is also wrong, but understanding <em>why </em>requires being clear about what clinical trials are actually for.</p><p>Trials serve two distinct functions: validation &#8212; confirming whether a drug works and is safe &#8212; and learning, or generating biological data to refine our understanding of a disease, a compound, and the relationship between the two.</p><p>Validation is the primary goal of large-scale Phase III trials, which come later in the process and are typically designed to support regulatory approval. While data from these studies can deepen our understanding of drugs, their main goal is to figure out whether a treatment works under defined conditions. Learning, by contrast, is the dominant aim of early-stage trials. Conducted in smaller patient populations and often using exploratory designs, these studies are not limited to simple &#8220;yes or no&#8221; outcomes. Instead, they are experiments in the fullest scientific sense: they seek to uncover how a drug behaves in the human body, and how the disease itself responds. As argued in my earlier essay, <a href=\"https://www.asimov.press/p/clinic-loop\">Clinic-in-the-Loop</a>, this makes these early stage trials active engines of discovery that close the feedback loop between hypothesis and human biology.</p><p>For large &#8220;validation&#8221; trials, is it plausible that their cost will simply cease to matter in a (theoretical) world where AI makes drugs with a high probability of success? I think the answer is no, for a couple reasons.</p><p>First, unless we increase the pace and volume of the early-stage &#8220;learning trials,&#8221; it is unlikely that we will ever approach such a level of certainty in drug discovery. Today, most AI systems in drug development are trained predominantly on <em>in vitro</em> data and animal models. While valuable, these sources only imperfectly capture the complexity of human biology. Without large amounts of high-quality data from actual humans, we should not expect AI to generate predictions that approach near-certainty about trial outcomes.</p><p>Second, even if improved modeling could compress early-stage development timelines, every successful drug must still demonstrate benefit on an endpoint; either a clinical endpoint or a surrogate endpoint.</p><p>For many diseases, however, the relevant endpoints take a very long time to observe. This is especially true for chronic conditions, which develop and progress over years or decades. The outcomes that matter most &#8212; such as disability, organ failure, or death &#8212; take a long time to measure in clinical trials. Aging represents the most extreme case. Demonstrating an effect on mortality or durable healthspan would require following large numbers of patients for decades. The resulting trial sizes and durations are enormous, making studies extraordinarily expensive. This scale has been a major deterrent to investment in therapies that target aging directly.</p><p>Lastly, the duration of a clinical trial does not merely determine how fast an individual therapy reaches patients. It also shapes which diseases attract serious investment and which do not. In a scenario where AI produces better drug candidates, yet trials remain slow, medicines will become unevenly deployed. In that scenario, capital and innovation will flow toward indications with clear, rapidly measurable endpoints &#8212; such as oncology &#8212; where trials can be completed relatively quickly. By contrast, fields like aging, where meaningful outcomes take years or decades to observe, will continue to lag unless there is genuine innovation in endpoint development.</p><p>Osteoporosis, a progressive bone disease that primarily affects post-menopausal women, illustrates these dynamics well. Firstly, it benefits from an unusually strong preclinical model in the ovariectomized rat (OvX model). Unlike many other chronic diseases, where animal models have poor predictive validity, the OvX model reliably <a href=\"https://pmc.ncbi.nlm.nih.gov/articles/PMC2707131/\">recapitulates post-menopausal bone loss</a> and predicts drug response. This rat model is so good, in fact, that Phase III trials for osteoporosis succeed <a href=\"https://www.pharmaceutical-technology.com/data-insights/denosumab-biosimilar-lupin-post-menopausal-osteoporosis-likelihood-of-approval/\">83.7 percent</a> of the time, substantially higher than the cross-indication average of roughly <a href=\"https://go.bio.org/rs/490-EHZ-999/images/ClinicalDevelopmentSuccessRates2011_2020.pd\">57.8 percent</a> at the same stage.</p><p>Given the existence of a good pre-clinical model that allows us to select higher quality candidates and the scale of unmet need in osteoporosis, one might expect it to attract sustained and substantial investment. But instead, the opposite has occurred. Today, only two drug candidates remain in late-stage clinical development for osteoporosis.</p><p>The primary reason is that Phase III osteoporosis trials are <a href=\"https://ifp.org/proxy-praxis-why-validating-an-endpoint-took-twelve-years/\">exceptionally large, long, and expensive</a> to run. The core challenge lies in the endpoint: fracture reduction. Fractures are relatively infrequent events, even in high-risk populations, and they happen unpredictably. To demonstrate that a new therapy meaningfully lowers fracture rates compared with standard of care, trials must wait for enough fracture events to accumulate to produce statistical confidence.</p><p>Because the event rate is low and influenced by many factors beyond bone strength &#8212; such as fall risk, age, and comorbidities &#8212; the signal-to-noise ratio is modest. As a result, Phase III osteoporosis trials typically enroll <a href=\"https://ifp.org/proxy-praxis-why-validating-an-endpoint-took-twelve-years/\">10,000&#8211;16,000 participants</a> and follow them for three to five years. The sheer scale and duration of these trials push costs to between $500 million and $1 billion. Thus, investment into osteoporosis drugs slowed not because the biology failed or drug candidates lacked promise, but because the cost of <em>proving benefit</em> became prohibitively high.</p><p>Osteoporosis is just one example where trial size and costs deter investment. But there is <a href=\"https://pubs.aeaweb.org/doi/pdfplus/10.1257/aer.20131176\">broader empirical evidence</a> in this direction. A 2015 study examining oncology R&amp;D found that hematological cancers &#8212; where the FDA accepts short-term surrogate endpoints in roughly 92 percent of approvals, allowing for shorter trials &#8212; attracted 112 percent more private R&amp;D investment than solid tumors, where surrogate endpoints are used in only about half of cases. The authors traced this disparity to commercialization timelines. The shorter trials used for the former preserve more of a drug&#8217;s effective patent life, improving expected returns and drawing capital. Each one-year reduction in bringing a new therapy to market was estimated to increase R&amp;D investment by between 7 and 23 percent.</p><p>If we want AI models to actually accelerate &#8220;therapeutic abundance,&#8221; then, we must first find ways to speed up these large validation trials. And to design better drugs in the first place, we must find ways to collect in-human data in early-stage &#8220;learning&#8221; trials much faster, too.</p><h2>Regulatory Friction</h2><p>The best way forward is to reduce operational and regulatory friction. AI tools can already help at the margins by automating submission drafting, improving site selection, matching patients more efficiently, and streamlining data workflows. But without deep regulatory reform, this is unlikely to shrink trial timelines or costs at scale.</p><p>One regulatory lever we could pull is to implement more <a href=\"https://ifp.org/proxy-praxis-how-surrogate-endpoints-can-speed-drug-development/\">high-quality surrogate endpoints.</a> A clinical endpoint directly measures how a patient feels, functions, or survives &#8212; such as prevention of stroke or a reduction in fractures. A surrogate endpoint, by contrast, is a measurable biological marker or intermediate outcome that reliably predicts such clinical benefit. Instead of waiting years to observe clinical outcomes, trials that rely on surrogate endpoints can measure signals much earlier.</p><p>AI tools can contribute to the development of better surrogate endpoints, such as by identifying promising biomarkers, analyzing cross-trial datasets, and modeling causal relationships between intermediate signals and clinical outcomes. But here, too, technical capability is only part of the story. Institutional reform is likely to be the binding constraint. As my <a href=\"https://ifp.org/proxy-praxis-why-validating-an-endpoint-took-twelve-years/\">case study</a> of the 12-year effort to qualify bone mineral density (BMD) as an endpoint for osteoporosis trials illustrates, the bottleneck was not scientific capability. Instead, the core barriers to faster progress were fragmented trial data scattered across sponsors, weak funding incentives for what is effectively a public good, and an unnecessarily lengthy and opaque regulatory pathway.<a class=\"footnote-anchor\" href=\"https://www.asimov.press/feed#footnote-2\" id=\"footnote-anchor-2\" target=\"_self\">2</a></p><p>For AI to generate high-quality candidates &#8212; the kind that might, one day, push success rates of drug candidates so high that trials become more of a formality &#8212; it also needs rich, dynamic data as input. But remember that such data can <em>only </em>come from trials in people (mice are nice, but most animal results simply do not translate.) This, in turn, creates a feedback loop: better AI models require better trial data, and better trial data requires running trials. The loop is only as fast as its slowest component, the trial itself.</p><p>A regulatory structure modeled after <a href=\"https://www.tga.gov.au/products/unapproved-therapeutic-goods/access-pathways/clinical-trials/clinical-trial-notification-ctn-scheme\">Australia&#8217;s Clinical Trial Notification</a> (CTN) framework &#8212; administered by the Therapeutic Goods Administration &#8212; offers a concrete example of the kind of policy push that could speed up these types of trials. There, most early-phase trials proceed after approval by a Human Research Ethics Committee (HREC), with notification rather than pre-approval by the regulator. The regulator retains inspection powers and the authority to halt unsafe studies, but does not duplicate the scientific review already conducted by the clinician-scientists and toxicologists embedded in HRECs. The result is that clinical trial sites can begin giving drugs to patients much sooner (about two times faster than in the United States, according to informal interviews with industry leaders).</p><p>In the United States, by contrast, Phase I trials typically require submission of an Investigational New Drug (IND) application to the U.S. Food and Drug Administration before initiation. This dual review &#8212; by both an IRB and the federal regulator &#8212; creates redundancy that lengthens the feedback loop. A CTN-like model for Phase I trials could preserve safety oversight while shifting scientific and toxicological reviews to accredited, transparently governed IRBs with expanded expertise. The FDA would retain the power to inspect, impose clinical holds, and intervene in high-risk cases, such as for novel gene therapies. But for the majority of small-molecule first-in-human studies, the default could be notification rather than permission.</p><p>My criticisms are not meant to imply that AI is irrelevant to trials; that&#8217;s certainly not the case. But many of the bottlenecks that determine trial speed and cost are coordination, institutional and regulatory problems, and they cannot be solved by technology alone.</p><div><hr /></div><p><strong>Ruxandra Teslo </strong>is a fellow at Renaissance Philanthropy and co-founder of the Clinical Trial Abundance project. She writes about the intersection of science, culture and policy at her Substack. She holds a PhD in Genomics from Cambridge University.</p><p>Header image by Ella Watkins-Dulaney.</p><p><strong>Cite: </strong>Teslo, R. &#8220;AI Will Not Solve Clinical Trials.&#8221; <em>Asimov Press </em>(2026). DOI: 10.62211/92wj-65fn</p><div class=\"footnote\"><a class=\"footnote-number\" contenteditable=\"false\" href=\"https://www.asimov.press/feed#footnote-anchor-1\" id=\"footnote-1\" target=\"_self\">1</a><div class=\"footnote-content\"><p>Clinical trials can be stopped early for overwhelming efficacy if interim analyses show a treatment effect so large and statistically robust that continuing would be unnecessary or unethical. In such cases, sponsors may also qualify for expedited FDA pathways &#8212; such as Fast Track, Breakthrough Therapy, or Priority Review &#8212; which can shorten regulatory timelines.But this is not a general solution for long development cycles.</p></div></div><div class=\"footnote\"><a class=\"footnote-number\" contenteditable=\"false\" href=\"https://www.asimov.press/feed#footnote-anchor-2\" id=\"footnote-2\" target=\"_self\">2</a><div class=\"footnote-content\"><p>Surrogate endpoints function as a public good because once validated, any sponsor in a therapeutic area can use them, regardless of who funded the underlying research.</p><p></p></div></div>"
            ],
            "link": "https://www.asimov.press/p/ai-clinical-trials",
            "publishedAt": "2026-02-27",
            "source": "Asimov Press",
            "summary": "<div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!TIDP!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3da51221-8a5a-4720-a29d-a9ebd50dcedc_2000x1260.jpeg\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"917\" src=\"https://substackcdn.com/image/fetch/$s_!TIDP!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3da51221-8a5a-4720-a29d-a9ebd50dcedc_2000x1260.jpeg\" width=\"1456\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p>During a <a href=\"https://www.youtube.com/watch?v=n1E9IZfvGMA\">recent interview</a>, Dwarkesh Patel and the CEO of Anthropic, Dario Amodei, discussed whether clinical trials will remain a meaningful bottleneck for drug development in the age of AI. Patel said that &#8220;most clinical trials fail because the drug does not work.&#8221; In response, Amodei speculated that as AI models get better at designing drugs, &#8220;clinical trials will be much faster &#8230; let&#8217;s say, they will take one year.&#8221;</p><p>This is a commonly voiced sentiment, but flawed. The truth is that the most significant barriers",
            "title": "AI Won't Automatically Accelerate Clinical Trials"
        },
        {
            "content": [
                "<img alt=\"Software development now costs less than than the wage of a minimum wage worker\" src=\"https://ghuntley.com/content/images/2026/01/Symbolic-traditional-tattoo-art-print-of-the-invention-of-the-shipping-container--presented-with-an-ethereal-spiritual-vibe-in-an-intense-jet-black-wet-rainy-scene--adorned-with-vibrant-rose-tattoo-colors--retro.jpg\" /><p>Hey folks, the last year I&apos;ve been pondering about this and doing game theory around the discovery of Ralph, how good the models are getting and how that&apos;s going to intersect with society. What follows is a cold, stark write-up of how I think it&apos;s going to go down.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img alt=\"Software development now costs less than than the wage of a minimum wage worker\" class=\"kg-image\" height=\"1536\" src=\"https://media.licdn.com/dms/image/v2/D5622AQGnCxyMPX9LiA/feedshare-shrink_2048_1536/B56ZyXExzEJQAk-/0/1772061138793?e=1773878400&amp;v=beta&amp;t=UxYi116WBNSlQmhRcCNYnxw61oee738_AN_3Ee7zQOQ\" width=\"2048\" /><figcaption><a href=\"https://www.theregister.com/2026/01/27/ralph_wiggum_claude_loops/?ref=ghuntley.com\"><span style=\"white-space: pre-wrap;\">https://www.theregister.com/2026/01/27/ralph_wiggum_claude_loops/</span></a></figcaption></figure><p>The financial impacts are already unfolding. Back when Ralph started to go really viral, there was a private equity firm that was previously long on Atlassian and went deliberately short on Atlassian because of Ralph. In the last couple of days, they released their new investor report, and they made absolute bank.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img alt=\"Software development now costs less than than the wage of a minimum wage worker\" class=\"kg-image\" height=\"2318\" src=\"https://ghuntley.com/content/images/2026/02/CleanShot-2026-02-27-at-19.43.48@2x.png\" width=\"1932\" /><figcaption><span style=\"white-space: pre-wrap;\">Dec 2025 - </span><a href=\"https://www.minotaurcapital.com/reports/quarterly/2025-12?ref=ghuntley.com\"><span style=\"white-space: pre-wrap;\">https://www.minotaurcapital.com/reports/quarterly/2025-12</span></a></figcaption></figure><p>I discovered Ralph almost a year ago today, and when I made that discovery, I sat on it for a while and focused on education and teaching juniors to pay attention and just writing prolifically, just writing and doing <a href=\"https://ghuntley.com/six-month-recap\" rel=\"noreferrer\">keynotes internationally</a>,  pleading with people to pay attention and to invest in themselves.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://ghuntley.com/screwed\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Dear Student: Yes, AI is here, you&#x2019;re screwed unless you take action...</div><div class=\"kg-bookmark-description\">Two weeks ago a student anonymously emailed me asking for advice. This is the reply and if I was in your shoes this is what I&#x2019;d do. So, I read your blog post &#x201c;An oh f*** moment in time&#x201d; alongside &#x201c;The future belongs to idea guys that can just do</div><div class=\"kg-bookmark-metadata\"><img alt=\"Software development now costs less than than the wage of a minimum wage worker\" class=\"kg-bookmark-icon\" src=\"https://ghuntley.com/content/images/icon/A-black-and-white--low-angle-digital-illustration-in-a-symbolic-traditional-tattoo-art-style.--A-bald--light-skinned-man-with-a-bushy-beard--prominent-eyebrows--and-a-friendly-expression-wears-denim-overalls--2--2.jpg\" /><span class=\"kg-bookmark-author\">Geoffrey Huntley</span><span class=\"kg-bookmark-publisher\">Geoffrey Huntley</span></div></div><div class=\"kg-bookmark-thumbnail\"><img alt=\"Software development now costs less than than the wage of a minimum wage worker\" src=\"https://ghuntley.com/content/images/thumbnail/llmcurve-4.png\" /></div></a></figure><p>It&apos;s now one year later, and the cost of software development is $10.42 an hour, which is less than minimum wage and a burger flipper at macca&apos;s gets paid more than that. What does it mean to be a software developer when everyone in the world can develop software? Just two nights ago, I was at a Cursor meetup, and nearly everyone in the room was not a software developer, showing off their latest and greatest creations. </p><figure class=\"kg-card kg-image-card\"><img alt=\"Software development now costs less than than the wage of a minimum wage worker\" class=\"kg-image\" height=\"1500\" src=\"https://ghuntley.com/content/images/2026/02/image-3.png\" width=\"2000\" /></figure><p>Well, they just became software developers because Cursor enabled them to become one. You see, the knowledge and skill of being a software developer has been commoditised. If everyone can be a software developer, what does that mean if your identity function is that you&apos;re a software developer and you write software for a living?</p><p>My theory of how it all goes down and gets feral really, really fast. Is quite simple...</p><figure class=\"kg-card kg-image-card\"><img alt=\"Software development now costs less than than the wage of a minimum wage worker\" class=\"kg-image\" height=\"1360\" src=\"https://ghuntley.com/content/images/2026/02/CleanShot-2026-02-27-at-17.23.37@2x.png\" width=\"2000\" /></figure><p>For the past month, I&apos;ve been catching up with venture capitalists in Australia and San Francisco and rubber-ducking this concept. You see, for a lot of them, they&apos;re not even sure whether their business model as venture capitalists still exists. </p><blockquote class=\"kg-blockquote-alt\">Why does someone need to raise a large amount of capital if it&apos;s just five man show now?</blockquote><p>So let&apos;s open up with a classic K shape.</p><figure class=\"kg-card kg-image-card\"><img alt=\"Software development now costs less than than the wage of a minimum wage worker\" class=\"kg-image\" height=\"1124\" src=\"https://ghuntley.com/content/images/2026/02/Screenshot-2026-02-27-at-7.19.32---PM.png\" width=\"2000\" /></figure><p>We rewind time to Christmas two years ago, where I originally posted, <a href=\"https://ghuntley.com/oh-fuck/\" rel=\"noreferrer\">An &quot;oh fuck&quot; moment in time</a> it was clear to me where this was going. The models were already good enough back then to cause societal disruption. The models were pretty wild;  like wild horses, and they needed quite a great deal of skill to get outcomes from them... </p><figure class=\"kg-card kg-image-card\"><img alt=\"Software development now costs less than than the wage of a minimum wage worker\" class=\"kg-image\" height=\"1129\" src=\"https://ghuntley.com/content/images/2026/02/Screenshot-2026-02-27-at-7.23.29---PM.png\" width=\"2000\" /></figure><p>If we fast-forward to the last Christmas holidays, many people had their &quot;oh fuck&quot; moment a year later, and the difference between now and then is twofold. </p><p>One: they actually picked up the guitar, played it, and took the Christmas period off because they had the space, capacity, and time to invest in themselves and make discoveries.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://ghuntley.com/play\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">deliberate intentional practice</div><div class=\"kg-bookmark-description\">Something I&#x2019;ve been wondering about for a really long time is, essentially, why do people say AI doesn&#x2019;t work for them? What do they mean when they say that? From which identity are they coming from? Are they coming from the perspective of an engineer with a job title and</div><div class=\"kg-bookmark-metadata\"><img alt=\"Software development now costs less than than the wage of a minimum wage worker\" class=\"kg-bookmark-icon\" src=\"https://ghuntley.com/content/images/icon/A-black-and-white--low-angle-digital-illustration-in-a-symbolic-traditional-tattoo-art-style.--A-bald--light-skinned-man-with-a-bushy-beard--prominent-eyebrows--and-a-friendly-expression-wears-denim-overalls--2--3.jpg\" /><span class=\"kg-bookmark-author\">Geoffrey Huntley</span><span class=\"kg-bookmark-publisher\">Geoffrey Huntley</span></div></div><div class=\"kg-bookmark-thumbnail\"><img alt=\"Software development now costs less than than the wage of a minimum wage worker\" src=\"https://ghuntley.com/content/images/thumbnail/A-vibrant-retro-style-traditional-tattoo-art-print-featuring-a-guitar--rendered-with-high-contrast-and-dramatic-lighting.-The-complex-ornamental-design-is-set-against-a-stark-white-background--showcasing-intense-color-saturation-and-a-symbo-8.jpg\" /></div></a></figure><p>Two, the horses or models came with factory defaults of &quot;broken in and ready to get shit done&quot;, which made them more accessible; they&apos;re easier to use to achieve outcomes, so people didn&apos;t need to invest as much time learning how to juice them to get disruptive outcomes. </p><figure class=\"kg-card kg-image-card\"><img alt=\"Software development now costs less than than the wage of a minimum wage worker\" class=\"kg-image\" height=\"1118\" src=\"https://ghuntley.com/content/images/2026/02/Screenshot-2026-02-27-at-7.23.56---PM.png\" width=\"2000\" /></figure><p>The world is now divided into two types of companies. Model first companies that are lean, apex predators who can operate on razor-thin margins and crush incumbents.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://ghuntley.com/papercuts\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">llm weights vs the papercuts of corporate</div><div class=\"kg-bookmark-description\">In woodworking, there&#x2019;s a saying that you should work with the grain, not against the grain and I&#x2019;ve been thinking about how this concept may apply to large language models. These large language models are built by training on existing data. This data forms the backbone which creates output based</div><div class=\"kg-bookmark-metadata\"><img alt=\"Software development now costs less than than the wage of a minimum wage worker\" class=\"kg-bookmark-icon\" src=\"https://ghuntley.com/content/images/icon/A-black-and-white--low-angle-digital-illustration-in-a-symbolic-traditional-tattoo-art-style.--A-bald--light-skinned-man-with-a-bushy-beard--prominent-eyebrows--and-a-friendly-expression-wears-denim-overalls--2--4.jpg\" /><span class=\"kg-bookmark-author\">Geoffrey Huntley</span><span class=\"kg-bookmark-publisher\">Geoffrey Huntley</span></div></div><div class=\"kg-bookmark-thumbnail\"><img alt=\"Software development now costs less than than the wage of a minimum wage worker\" src=\"https://ghuntley.com/content/images/thumbnail/universal_upscale_0_6a2d76dd-41e0-42a4-8529-bf43d0280256_0-1.jpg\" /></div></a></figure><p>The next side of the equation is nearly every company out there today, which needs to go through a people transformation program, figure out what to do with AI, and deal with the fact that the fundamentals of business have changed.</p><figure class=\"kg-card kg-image-card\"><img alt=\"Software development now costs less than than the wage of a minimum wage worker\" class=\"kg-image\" height=\"1126\" src=\"https://ghuntley.com/content/images/2026/02/Screenshot-2026-02-27-at-7.29.51---PM.png\" width=\"2000\" /></figure><p>Jack is doing the right thing for his company by acting early.  What will happen is that the time for a competitor to be at your door will be measured in months, not years. And as models get better, the timeframe only compresses. </p><p>The real question is for the folks who, unfortunately, were laid off today; they will need jobs, and they will now see the importance of upskilling with AI. So they&apos;ll go on to their next employer or other industries and upskill with AI, and then seek to implement what is needed - automating job functions via AI. <br /><br />Then the cycle continues across all industries, all disciplines.  <br /><br />But it&apos;s not going to be just triggered by layoffs. It&apos;ll be just triggered by executives who don&apos;t get it. When you understand what is going on and how real AI is, it is maddening to be in a company surrounded by people who don&apos;t get it. </p><figure class=\"kg-card kg-embed-card\"><blockquote class=\"twitter-tweet\"><p dir=\"ltr\" lang=\"en\">tfw when Canva&apos;s CTO puts you on full blast &#x1f60e;<br /><br />[ps. that 50k LOC is on all endpoints and uplifts devs+non-devs usage of AI and is single source of truth for MCP at Canva] <a href=\"https://t.co/E19pyd9meZ?ref=ghuntley.com\">pic.twitter.com/E19pyd9meZ</a></p>&#x2014; geoff (@GeoffreyHuntley) <a href=\"https://twitter.com/GeoffreyHuntley/status/1939391215482601868?ref_src=twsrc%5Etfw&amp;ref=ghuntley.com\">June 29, 2025</a></blockquote>\n</figure><p>You see, there is a difference between employer suicide and employee suicide. The smart folks who don&apos;t want to commit employment suicide will leave. <br /><br />The smarter ones in that segment will just go and found their own companies, then come back and do what they know. And they&apos;ll attack their employers vertically, operating leaner and meaner.</p><figure class=\"kg-card kg-image-card\"><img alt=\"Software development now costs less than than the wage of a minimum wage worker\" class=\"kg-image\" height=\"1123\" src=\"https://ghuntley.com/content/images/2026/02/CleanShot-2026-02-27-at-19.38.35@2x.png\" width=\"2000\" /></figure><p>As the models get better, which is slope on slope derivative pace at this stage and as model-first companies get better and better and better at automating their job function, they can be at the door of their previous employer in months, not years.</p><figure class=\"kg-card kg-image-card\"><img alt=\"Software development now costs less than than the wage of a minimum wage worker\" class=\"kg-image\" height=\"1122\" src=\"https://ghuntley.com/content/images/2026/02/CleanShot-2026-02-28-at-05.29.31@2x.png\" width=\"2000\" /></figure><p></p><p>To make matters worse, as the models get better, time gets compressed, and the snake eating its tail speeds up.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img alt=\"Software development now costs less than than the wage of a minimum wage worker\" class=\"kg-image\" height=\"1123\" src=\"https://ghuntley.com/content/images/2026/02/CleanShot-2026-02-28-at-05.37.42@2x.png\" width=\"2000\" /><figcaption><span style=\"white-space: pre-wrap;\">idk how to visualize this, if you&apos;ve got ideas let me know...</span></figcaption></figure><p><br />Which results in employers who did not take corrective actions, unlike Jack, having to lay off people in the long run because margins are being squeezed by new competitors operating leaner, meaner, and faster. <br /><br />Then the cycle continues across all industries, all disciplines.  </p><figure class=\"kg-card kg-image-card\"><img alt=\"Software development now costs less than than the wage of a minimum wage worker\" class=\"kg-image\" height=\"1360\" src=\"https://ghuntley.com/content/images/2026/02/CleanShot-2026-02-27-at-17.24.46@2x.png\" width=\"2000\" /></figure><p>As I&apos;ve been stressing in my writing for almost a year now, employers and employees trade time and skill for money. If a company is having problems adopting AI, then that is a company issue, not an employee issue.</p><blockquote>Experience as a software engineer today doesn&#x2019;t guarantee relevance tomorrow. The dynamics of employment are changing: employees trade time and skills for money, but employers&#x2019; expectations are evolving rapidly. Some companies are adapting faster than others.<br /><br />Another thing I&apos;ve been thinking: when someone says, &#x201c;AI doesn&#x2019;t work for me,&#x201d; what do they mean? Are they referring to concerns related to AI in the workplace or personal experiments on greenfield projects that don&apos;t have these concerns?<br /><br />This distinction matters.<br /><br />Employees trade skills for employability, and failing to upskill in AI could jeopardise their future. I&#x2019;m deeply concerned about this.<br /><br />If a company struggles with AI adoption, that&#x2019;s a solvable problem - it&apos;s now my literal job. But I worry more about employees.<br /><br />In history, there are tales of employees departing companies that resisted cloud adoption to keep their skills competitive.<br /><br />The same applies to AI. Companies that lag risk losing talent who prioritise skill relevance.<br /><br /><strong>- June 2025</strong> from <a href=\"https://ghuntley.com/six-month-recap/\">https://ghuntley.com/six-month-recap/</a></blockquote><p>Model weight first companies should be scaring the fuck out of every founder right now if they&apos;re not a utility service, for what is a moat now in the era when you can /z80 something?</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://ghuntley.com/papercuts\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">llm weights vs the papercuts of corporate</div><div class=\"kg-bookmark-description\">In woodworking, there&#x2019;s a saying that you should work with the grain, not against the grain and I&#x2019;ve been thinking about how this concept may apply to large language models. These large language models are built by training on existing data. This data forms the backbone which creates output based</div><div class=\"kg-bookmark-metadata\"><img alt=\"Software development now costs less than than the wage of a minimum wage worker\" class=\"kg-bookmark-icon\" src=\"https://ghuntley.com/content/images/icon/A-black-and-white--low-angle-digital-illustration-in-a-symbolic-traditional-tattoo-art-style.--A-bald--light-skinned-man-with-a-bushy-beard--prominent-eyebrows--and-a-friendly-expression-wears-denim-overalls--2-.jpg\" /><span class=\"kg-bookmark-author\">Geoffrey Huntley</span><span class=\"kg-bookmark-publisher\">Geoffrey Huntley</span></div></div><div class=\"kg-bookmark-thumbnail\"><img alt=\"Software development now costs less than than the wage of a minimum wage worker\" src=\"https://ghuntley.com/content/images/thumbnail/universal_upscale_0_6a2d76dd-41e0-42a4-8529-bf43d0280256_0.jpg\" /></div></a></figure><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://ghuntley.com/z80/\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Can a LLM convert C, to ASM to specs and then to a working Z/80 Speccy tape? Yes.</div><div class=\"kg-bookmark-description\">&#x2728;Daniel Joyce used the techniques described in this post to port ls to rust via an objdump. You can see the code here: https://github.com/DanielJoyce/ls-rs. Keen, to see more examples - get in contact if you ship something! Damien Guard nerd sniped me and other folks wanted</div><div class=\"kg-bookmark-metadata\"><img alt=\"Software development now costs less than than the wage of a minimum wage worker\" class=\"kg-bookmark-icon\" src=\"https://ghuntley.com/content/images/icon/A-black-and-white--low-angle-digital-illustration-in-a-symbolic-traditional-tattoo-art-style.--A-bald--light-skinned-man-with-a-bushy-beard--prominent-eyebrows--and-a-friendly-expression-wears-denim-overalls--2--1.jpg\" /><span class=\"kg-bookmark-author\">Geoffrey Huntley</span><span class=\"kg-bookmark-publisher\">Geoffrey Huntley</span></div></div><div class=\"kg-bookmark-thumbnail\"><img alt=\"Software development now costs less than than the wage of a minimum wage worker\" src=\"https://ghuntley.com/content/images/thumbnail/bafkreiftzmpb7bbkej76rac3kuijg2mcuyjxxhtnqdie5qq6rbrc45v2iu-1-6.jpg\" /></div></a></figure><p>On the topic of moats, I&apos;ve been thinking about this for almost a year now, and I think I&apos;ve now got a clearer sense of what moats are in the AI era, but first, let&apos;s talk about what moats aren&apos;t...</p><ul><li>Any business model that&apos;s based on per-seat pricing, as AI starts to rip harder and harder, is going to become much harder to maintain headcount within a corporation because model-first companies will be coming into business and operating much leaner using utility-based pricing. It&apos;s a margin game now.</li><li>Any product features or platforms that were designed for humans. I know that&apos;s going to sound really wild, but understand these days I go window-shopping on SaaS companies&apos; websites for product features, rip a screenshot into Claude Code, and it rebuilds that product feature/platform. As we enter the era of hyper-personalised software, I think this will be the case more and more. In <a href=\"https://latentpatterns.com/?ref=ghuntley.com\" rel=\"noreferrer\">my latest creation</a>, I have cloned Posthog, Jira, Pipedrive, and Calendly, and the list just keeps on growing because I want to build a hyper-personalised business that meets all my needs, with full control and everything first-party. I think we&apos;re going to see more and more of model first companies operating with this mindset.</li><li>Any business thought that revolved around the high cost of switching from one technology to another, or migrations from one technology to another, was a form of lock-in. This is provably falsified now. It is so easy to rip a fart into Claude Code and migrate from one technology to another. Just last week, I migrated from Cloudflare D1 to a PlanetScale Postgres database automatically using a Ralph Loop, and it just worked. Full-on data migration. When have you ever heard of a database migration going successfully unattended? We&apos;re here now, folks.</li></ul><p>If you currently work at a company that fits the top three bullet points, then understand that things are going to get really tight at your employer. I don&apos;t know when, but with certainty it <em>will</em> happen. Your best choices are either to find a new employer if the people around you don&apos;t get it, or, if there is a need and desire for automation, to lean so hard into AI, automate everything, and become the champion of AI within your company. If your company has banned AI outright, you need to depart right now and find another employer.</p><p>So with that out of the way, what is a moat?</p><ul><li>Distribution. Any form of distribution. Brand awareness. Steaks and handshakes.</li><li>Utility-based pricing, similar to cloud infrastructure on a cents per megabyte or CPU hour.</li><li>Operating as a model-first company and accelerating the transformation so you can operate under the principles below:</li></ul><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://latentpatterns.com/principles?ref=ghuntley.com\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Principles &#x2014; Latent Patterns</div><div class=\"kg-bookmark-description\">Principles for building products with large language models and the latent space &#x2014; hard-won lessons from shipping AI-native software.</div><div class=\"kg-bookmark-metadata\"><img alt=\"Software development now costs less than than the wage of a minimum wage worker\" class=\"kg-bookmark-icon\" src=\"https://ghuntley.com/content/images/icon/favicon.png\" /><span class=\"kg-bookmark-author\">Latent Patterns</span></div></div><div class=\"kg-bookmark-thumbnail\"><img alt=\"Software development now costs less than than the wage of a minimum wage worker\" src=\"https://ghuntley.com/content/images/thumbnail/og-default.png\" /></div></a></figure><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img alt=\"Software development now costs less than than the wage of a minimum wage worker\" class=\"kg-image\" height=\"810\" src=\"https://ghuntley.com/content/images/2026/02/image-1.png\" width=\"1440\" /><figcaption><span style=\"white-space: pre-wrap;\">AI erases traditional developer identities&#x2014;backend, frontend, Ruby, or Node.js. Anyone can now perform these roles, creating emotional challenges for specialists with decades of experience. - https://ghuntley.com/six-month-recap</span></figcaption></figure><p>This is going to be a really hard time for a lot of people because identity functions have been erased, and the hard thing is, it&apos;s not just software developers. It&apos;s people managers as well. If your identity function is managing people, you need to make adjustments. You need to get back onto the tools ASAP. </p><blockquote>Were smaller but effectively cut 2/3rds by telling board I wouldn&#x2019;t backfill in May 2023. Best decision as got rid of all the people who &#x201c;are sick of hearing about ai&#x201d;. 20ish people now do about 30x the output of what having more than 60 did 3 years ago.<br /><strong>- an anonymous founder in my DMs today.</strong></blockquote><p>This transformation is going to be brutal.  Organisations need to be designed differently and need to transform from this...</p><figure class=\"kg-card kg-image-card\"><img alt=\"Software development now costs less than than the wage of a minimum wage worker\" class=\"kg-image\" height=\"1123\" src=\"https://ghuntley.com/content/images/2026/02/Screenshot-2026-02-27-at-5.49.19---PM.png\" width=\"2000\" /></figure><p>to this...</p><figure class=\"kg-card kg-image-card\"><img alt=\"Software development now costs less than than the wage of a minimum wage worker\" class=\"kg-image\" height=\"1125\" src=\"https://ghuntley.com/content/images/2026/02/Screenshot-2026-02-27-at-5.49.46---PM.png\" width=\"2000\" /></figure><p>And one of the hardest things is that AI is being rammed into the world non-consentually. It&apos;s been pushed by employers and Silicon Valley. Yeah, it sucks, but you gotta pull your chin up, process those feelings and deal with it, but for others it&apos;s gonna be really, really rough.  There are going to be people who have spent years of their lives doing Game of Thrones, social political stuff, to get to where they are within a company, and it will have been all for nothing.</p><figure class=\"kg-card kg-image-card\"><img alt=\"Software development now costs less than than the wage of a minimum wage worker\" class=\"kg-image\" height=\"604\" src=\"https://ghuntley.com/content/images/2026/02/CleanShot-2026-02-27-at-17.51.51@2x.png\" width=\"558\" /></figure><p>In the org chart above, consider what the value of the senior engineer, the team lead, the manager and the senior manager in this brave new world is? How much time is spent doing Dilbert activities? What if you can flatten the org chart? If you were a founder, why wouldn&apos;t you? </p><figure class=\"kg-card kg-image-card\"><img alt=\"Software development now costs less than than the wage of a minimum wage worker\" class=\"kg-image\" height=\"604\" src=\"https://ghuntley.com/content/images/2026/02/CleanShot-2026-02-27-at-17.51.51@2x-1.png\" width=\"558\" /></figure><p>This is what I&apos;ve been fearing for a year. I could be wrong, I don&apos;t know. Anyone who says that they know for sure is selling horseshit. One thing is absolutely certain: things will change, and there&apos;s no going back. The unit economics of business have forever changed. </p><p>Whether a company does layoffs really comes down to the quality of its leadership. If they&apos;re being lazy and don&apos;t have ambitious plans, they will need to lay off, because eventually the backlog will run dry, and everything will get automated. </p><p>This isn&apos;t me throwing shit at Jack. Like, literally, it&apos;s a cold, hard fact that you need fewer people to run a business now. So if you have too many people on your payroll, you need to make changes, but having said that, there will be ambitious founders and leaders who didn&apos;t overhire and understand that AI enables them to do anything, and they can do it today. They can make that five-year roadmap happen in a year and provide a backlog for all employees to work on while they utilise AI. </p><p>It&apos;s going to be really interesting to see how this pans out. </p><p>All I can ask you to do is tap someone else on the shoulder and stress to them to treat this topic seriously, upskill, and explain the risks going forward, and then ask them to do the same. You see, for a lot of people, they haven&apos;t noticed AI is knocking on their door because AI is burrowing under their house.</p><figure class=\"kg-card kg-image-card\"><img alt=\"Software development now costs less than than the wage of a minimum wage worker\" class=\"kg-image\" height=\"2000\" src=\"https://ghuntley.com/content/images/2026/02/image-2.png\" width=\"2000\" /></figure><h2 id=\"ps-socials\">ps. socials</h2><ul><li>X - <a href=\"https://x.com/GeoffreyHuntley/status/2027306378692595935?ref=ghuntley.com\">https://x.com/GeoffreyHuntley/status/2027306378692595935</a></li><li>BSkye - <a href=\"https://bsky.app/profile/ghuntley.com/post/3mftdnrodas2o?ref=ghuntley.com\">https://bsky.app/profile/ghuntley.com/post/3mftdnrodas2o</a></li><li>LinkedIn - <a href=\"https://www.linkedin.com/posts/geoffreyhuntley_software-development-now-costs-less-than-activity-7433072287647440896-SOrp?utm_source=share&amp;utm_medium=member_desktop&amp;rcm=ACoAAABQKuUB2AJ059keUcRUVLbtmoa6miLVlTI\">https://www.linkedin.com/posts/geoffreyhuntley_software-development-now-costs-less-than-activity-7433072287647440896-SOrp</a></li></ul>"
            ],
            "link": "https://ghuntley.com/real/",
            "publishedAt": "2026-02-27",
            "source": "Geoffrey Huntley",
            "summary": "<p>Hey folks, the last year I&apos;ve been pondering about this and doing game theory around the discovery of Ralph, how good the models are getting and how that&apos;s going to intersect with society. What follows is a cold, stark write-up of how I think it&apos;</p>",
            "title": "Software development now costs less than than the wage of a minimum wage worker"
        },
        {
            "content": [
                "<div id=\"blog\"><div id=\"content\">\n  <div id=\"content\">\n\n    <div class=\"Article\">\n    \n    <h1 class=\"small\"><a href=\"https://go.dev/blog/\">The Go Blog</a></h1>\n    \n\n    <h1>Allocating on the Stack</h1>\n      \n      <p class=\"author\">\n      Keith Randall<br />\n      27 February 2026\n      </p>\n      \n      <div class=\"markdown\">\n<p>We&rsquo;re always looking for ways to make Go programs faster. In the last\n2 releases, we have concentrated on mitigating a particular source of\nslowness, heap allocations. Each time a Go program allocates memory\nfrom the heap, there&rsquo;s a fairly large chunk of code that needs to run\nto satisfy that allocation. In addition, heap allocations present\nadditional load on the garbage collector.  Even with recent\nenhancements like <a href=\"https://go.dev/blog/greenteagc\">Green Tea</a>, the garbage collector\nstill incurs substantial overhead.</p>\n<p>So we&rsquo;ve been working on ways to do more allocations on the stack\ninstead of the heap.  Stack allocations are considerably cheaper to\nperform (sometimes completely free).  Moreover, they present no load\nto the garbage collector, as stack allocations can be collected\nautomatically together with the stack frame itself. Stack allocations\nalso enable prompt reuse, which is very cache friendly.</p>\n<h2 id=\"stack-allocation-of-constant-sized-slices\">Stack allocation of constant-sized slices</h2>\n<p>Consider the task of building a slice of tasks to process:</p>\n<pre><code>func process(c chan task) {\n    var tasks []task\n    for t := range c {\n        tasks = append(tasks, t)\n    }\n    processAll(tasks)\n}\n</code></pre>\n<p>Let&rsquo;s walk through what happens at runtime when pulling tasks from the\nchannel <code>c</code> and adding them to the slice <code>tasks</code>.</p>\n<p>On the first loop iteration, there is no backing store for <code>tasks</code>, so\n<code>append</code> has to allocate one. Because it doesn&rsquo;t know how big the\nslice will eventually be, it can&rsquo;t be too aggressive. Currently, it\nallocates a backing store of size 1.</p>\n<p>On the second loop iteration, the backing store now exists, but it is\nfull. <code>append</code> again has to allocate a new backing store, this time of\nsize 2. The old backing store of size 1 is now garbage.</p>\n<p>On the third loop iteration, the backing store of size 2 is\nfull. <code>append</code> <em>again</em> has to allocate a new backing store, this time\nof size 4. The old backing store of size 2 is now garbage.</p>\n<p>On the fourth loop iteration, the backing store of size 4 has only 3\nitems in it. <code>append</code> can just place the item in the existing backing\nstore and bump up the slice length. Yay! No call to the allocator for\nthis iteration.</p>\n<p>On the fifth loop iteration, the backing store of size 4 is full, and\n<code>append</code> again has to allocate a new backing store, this time of size\n8.</p>\n<p>And so on. We generally double the size of the allocation each time it\nfills up, so we can eventually append most new tasks to the slice\nwithout allocation. But there is a fair amount of overhead in the\n&ldquo;startup&rdquo; phase when the slice is small. During this startup phase we\nspend a lot of time in the allocator, and produce a bunch of garbage,\nwhich seems pretty wasteful. And it may be that in your program, the\nslice never really gets large. This startup phase may be all you ever\nencounter.</p>\n<p>If this code was a really hot part of your program, you might be\ntempted to start the slice out at a larger size, to avoid all of these\nallocations.</p>\n<pre><code>func process2(c chan task) {\n    tasks := make([]task, 0, 10) // probably at most 10 tasks\n    for t := range c {\n        tasks = append(tasks, t)\n    }\n    processAll(tasks)\n}\n</code></pre>\n<p>This is a reasonable optimization to do. It is never incorrect; your\nprogram still runs correctly. If the guess is too small, you get\nallocations from <code>append</code> as before. If the guess is too large, you\nwaste some memory.</p>\n<p>If your guess for the number of tasks was a good one, then there&rsquo;s\nonly one allocation site in this program. The <code>make</code> call allocates a\nslice backing store of the correct size, and <code>append</code> never has to do\nany reallocation.</p>\n<p>The surprising thing is that if you benchmark this code with 10\nelements in the channel, you&rsquo;ll see that you didn&rsquo;t reduce the number\nof allocations to 1, you reduced the number of allocations to 0!</p>\n<p>The reason is that the compiler decided to allocate the backing store\non the stack. Because it knows what size it needs to be (10 times the\nsize of a task) it can allocate storage for it in the stack frame of\n<code>process2</code> instead of on the heap<a href=\"https://go.dev/blog/feed.atom#footnotes\"><sup>1</sup></a>.  Note\nthat this depends on the fact that the backing store does not <a href=\"https://go.dev/doc/gc-guide#Escape_analysis\">escape\nto the heap</a> inside of <code>processAll</code>.</p>\n<h2 id=\"stack-allocation-of-variable-sized-slices\">Stack allocation of variable-sized slices</h2>\n<p>But of course, hard coding a size guess is a bit rigid.\nMaybe we can pass in an estimated length?</p>\n<pre><code>func process3(c chan task, lengthGuess int) {\n    tasks := make([]task, 0, lengthGuess)\n    for t := range c {\n        tasks = append(tasks, t)\n    }\n    processAll(tasks)\n}\n</code></pre>\n<p>This lets the caller pick a good size for the <code>tasks</code> slice, which may\nvary depending on where this code is being called from.</p>\n<p>Unfortunately, in Go 1.24 the non-constant size of the backing store\nmeans the compiler can no longer allocate the backing store on the\nstack.  It will end up on the heap, converting our 0-allocation code\nto 1-allocation code. Still better than having <code>append</code> do all the\nintermediate allocations, but unfortunate.</p>\n<p>But never fear, Go 1.25 is here!</p>\n<p>Imagine you decide to do the following, to get the stack allocation\nonly in cases where the guess is small:</p>\n<pre><code>func process4(c chan task, lengthGuess int) {\n    var tasks []task\n    if lengthGuess &lt;= 10 {\n        tasks = make([]task, 0, 10)\n    } else {\n        tasks = make([]task, 0, lengthGuess)\n    }\n    for t := range c {\n        tasks = append(tasks, t)\n    }\n    processAll(tasks)\n}\n</code></pre>\n<p>Kind of ugly, but it would work. When the guess is small, you use a\nconstant size <code>make</code> and thus a stack-allocated backing store, and\nwhen the guess is larger you use a variable size <code>make</code> and allocate\nthe backing store from the heap.</p>\n<p>But in Go 1.25, you don&rsquo;t need to head down this ugly road. The Go\n1.25 compiler does this transformation for you!  For certain slice\nallocation locations, the compiler automatically allocates a small\n(currently 32-byte) slice backing store, and uses that backing store\nfor the result of the <code>make</code> if the size requested is small\nenough. Otherwise, it uses a heap allocation as normal.</p>\n<p>In Go 1.25, <code>process3</code> performs zero heap allocations, if\n<code>lengthGuess</code> is small enough that a slice of that length fits into 32\nbytes. (And of course that <code>lengthGuess</code> is a correct guess for how\nmany items are in <code>c</code>.)</p>\n<p>We&rsquo;re always improving the performance of Go, so upgrade to the latest\nGo release and <a href=\"https://youtu.be/FUm0pfgWehI?si=QRTt_JYwr-cRHDNJ&amp;t=960\" rel=\"noreferrer\" target=\"_blank\">be\nsurprised</a> by\nhow much faster and memory efficient your program becomes!</p>\n<h2 id=\"stack-allocation-of-append-allocated-slices\">Stack allocation of append-allocated slices</h2>\n<p>Ok, but you still don&rsquo;t want to have to change your API to add this\nweird length guess. Anything else you could do?</p>\n<p>Upgrade to Go 1.26!</p>\n<pre><code>func process(c chan task) {\n    var tasks []task\n    for t := range c {\n        tasks = append(tasks, t)\n    }\n    processAll(tasks)\n}\n</code></pre>\n<p>In Go 1.26, we allocate the same kind of small, speculative backing\nstore on the stack, but now we can use it directly at the <code>append</code>\nsite.</p>\n<p>On the first loop iteration, there is no backing store for <code>tasks</code>, so\n<code>append</code> uses a small, stack-allocated backing store as the first\nallocation. If, for instance, we can fit 4 <code>task</code>s in that backing store,\nthe first <code>append</code> allocates a backing store of length 4 from the stack.</p>\n<p>The next 3 loop iterations append directly to the stack backing store,\nrequiring no allocation.</p>\n<p>On the 4th iteration, the stack backing store is finally full and we\nhave to go to the heap for more backing store. But we have avoided\nalmost all of the startup overhead described earlier in this article.\nNo heap allocations of size, 1, 2, and 4, and none of the garbage that\nthey eventually become. If your slices are small, maybe you will never\nhave a heap allocation.</p>\n<h2 id=\"stack-allocation-of-append-allocated-escaping-slices\">Stack allocation of append-allocated escaping slices</h2>\n<p>Ok, this is all good when the <code>tasks</code> slice doesn&rsquo;t escape. But what if\nI&rsquo;m returning the slice? Then it can&rsquo;t be allocated on the stack, right?</p>\n<p>Right! The backing store for the slice returned by <code>extract</code> below\ncan&rsquo;t be allocated on the stack, because the stack frame for <code>extract</code>\ndisappears when <code>extract</code> returns.</p>\n<pre><code>func extract(c chan task) []task {\n    var tasks []task\n    for t := range c {\n        tasks = append(tasks, t)\n    }\n    return tasks\n}\n</code></pre>\n<p>But you might think, the <em>returned</em> slice can&rsquo;t be allocated on the\nstack. But what about all those intermediate slices that just become\ngarbage? Maybe we can allocate those on the stack?</p>\n<pre><code>func extract2(c chan task) []task {\n    var tasks []task\n    for t := range c {\n        tasks = append(tasks, t)\n    }\n    tasks2 := make([]task, len(tasks))\n    copy(tasks2, tasks)\n    return tasks2\n}\n</code></pre>\n<p>Then the <code>tasks</code> slice never escapes <code>extract2</code>. It can benefit from\nall of the optimizations described above. Then at the very end of\n<code>extract2</code>, when we know the final size of the slice, we do one heap\nallocation of the required size, copy our <code>task</code>s into it, and return\nthe copy.</p>\n<p>But do you really want to write all that additional code? It seems\nerror prone. Maybe the compiler can do this transformation for us?</p>\n<p>In Go 1.26, it can!</p>\n<p>For escaping slices, the compiler will transform the original <code>extract</code>\ncode to something like this:</p>\n<pre><code>func extract3(c chan task) []task {\n    var tasks []task\n    for t := range c {\n        tasks = append(tasks, t)\n    }\n    tasks = runtime.move2heap(tasks)\n    return tasks\n}\n</code></pre>\n<p><code>runtime.move2heap</code> is a special compiler+runtime function that is the\nidentity function for slices that are already allocated in the heap.\nFor slices that are on the stack, it allocates a new slice on the\nheap, copies the stack-allocated slice to the heap copy, and returns\nthe heap copy.</p>\n<p>This ensures that for our original <code>extract</code> code, if the number of\nitems fits in our small stack-allocated buffer, we perform exactly 1\nallocation of exactly the right size. If the number of items exceeds\nthe capacity our small stack-allocated buffer, we do our normal\ndoubling-allocation once the stack-allocated buffer overflows.</p>\n<p>The optimization that Go 1.26 does is actually better than the\nhand-optimized code, because it does not require the extra\nallocation+copy that the hand-optimized code always does at the end.\nIt requires the allocation+copy only in the case that we&rsquo;ve exclusively\noperated on a stack-backed slice up to the return point.</p>\n<p>We do pay the cost for a copy, but that cost is almost completely\noffset by the copies in the startup phase that we no longer have to\ndo. (In fact, the new scheme at worst has to copy one more element\nthan the old scheme.)</p>\n<h2 id=\"wrapping-up\">Wrapping up</h2>\n<p>Hand optimization can still be beneficial, especially if you have a\ngood estimate of the slice size ahead of time. But hopefully the\ncompiler will now catch a lot of the simple cases for you and allow\nyou to focus on the remaining ones that really matter.</p>\n<p>There are a lot of details that the compiler needs to ensure to get\nall these optimizations right. If you think that one of these\noptimizations is causing correctness or (negative) performance issues\nfor you, you can turn them off with\n<code>-gcflags=all=-d=variablemakehash=n</code>. If turning these optimizations\noff helps, please <a href=\"https://go.dev/issue/new\">file an issue</a> so we can investigate.</p>\n<h2 id=\"footnotes\">Footnotes</h2>\n<p><sup>1</sup> Go stacks do not have any <code>alloca</code>-style mechanism for\ndynamically-sized stack frames. All Go stack frames are constant\nsized.</p>\n</div>\n\n    </div>\n\n    \n    <div class=\"Article prevnext\">\n    \n    \n      \n        <p>\n        \n        \n          \n            <b>Previous article: </b><a href=\"https://go.dev/blog/gofix\">Using go fix to modernize Go code</a><br />\n          \n        \n        <b><a href=\"https://go.dev/blog/all\">Blog Index</a></b>\n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n      \n    \n    </div>\n    \n\n  </div>\n</div>"
            ],
            "link": "https://go.dev/blog/allocation-optimizations",
            "publishedAt": "2026-02-27",
            "source": "Go Blog",
            "summary": "<div id=\"blog\"><div id=\"content\"> <div id=\"content\"> <div class=\"Article\"> <h1 class=\"small\"><a href=\"https://go.dev/blog/\">The Go Blog</a></h1> <h1>Allocating on the Stack</h1> <p class=\"author\"> Keith Randall<br /> 27 February 2026 </p> <div class=\"markdown\"> <p>We&rsquo;re always looking for ways to make Go programs faster. In the last 2 releases, we have concentrated on mitigating a particular source of slowness, heap allocations. Each time a Go program allocates memory from the heap, there&rsquo;s a fairly large chunk of code that needs to run to satisfy that allocation. In addition, heap allocations present additional load on the garbage collector. Even with recent enhancements like <a href=\"https://go.dev/blog/greenteagc\">Green Tea</a>, the garbage collector still incurs substantial overhead.</p> <p>So we&rsquo;ve been working on ways to do more allocations on the stack instead of the heap. Stack allocations are considerably cheaper to perform (sometimes completely free). Moreover, they present no load to the garbage collector, as stack allocations can be collected automatically together with the stack frame itself. Stack allocations also enable prompt reuse, which is very cache friendly.</p> <h2 id=\"stack-allocation-of-constant-sized-slices\">Stack allocation of constant-sized slices</h2> <p>Consider the task of building a slice of tasks to process:</p> <pre><code>func process(c chan task) { var tasks []task for t := range c { tasks = append(tasks, t)",
            "title": "Allocating on the Stack"
        },
        {
            "content": [],
            "link": "https://interconnected.org/home/2026/02/27/asymmetry",
            "publishedAt": "2026-02-27",
            "source": "Matt Webb",
            "summary": "<div> <p>Thank goodness voice computing is finally happening. Now we can work on making it good.</p> <hr /> <p>The tech is here, like the free <a href=\"https://openai.com/index/whisper/\">Whisper</a> model <em>(what an unlock that has been from OpenAI, kudos)</em> and <a href=\"https://elevenlabs.io\">ElevenLabs</a>. Plus devices too, from <a href=\"https://www.plaud.ai\">Plaud</a> - like an irl Granola video call transcriber - to <a href=\"https://www.sandbar.com\">Sandbar</a>, a smart ring that you tell your secrets.</p> <p>Let\u2019s not forget <a href=\"https://www.reuters.com/business/apple-acquires-audio-ai-startup-qai-2026-01-29/\">Apple\u2019s recent $1.6bn acquisition of Q.ai</a>, which will use <em>\"\u2018facial skin micromovements\u2019 to detect words mouthed or spoken\"</em> \u2013 i.e. cameras in your AirPods stems that do voice without voice by staring really hard at your cheeks. Apple and AI lip-reading? <a href=\"https://interconnected.org/home/2025/06/16/hush\">I deserve a kick-back</a> (2025) just sayin</p> <p>While we\u2019re at it, there should be voice for everything: <a href=\"https://interconnected.org/home/2020/05/26/voice\">why can\u2019t I point at a lamp and say \u2018on\u2019?</a> (2020).</p> <p>At least we can play with <a href=\"https://interconnected.org/home/2022/12/14/transcription\">ubiquitous transcription</a> (2022). Like, my starting point for building <strong>mist</strong> was <a href=\"https://interconnected.org/home/2026/02/12/mist\">talking at my watch for 30 minutes</a> (2026).</p> <p>So let\u2019s take all this as signs that voice computing is here to stay.</p> <hr /> <p>Eventually voice has to go two-way, right? Conversational computing? You need to be able to disambiguate,",
            "title": "Speaking is quick, listening is slow"
        },
        {
            "content": [],
            "link": "https://www.nytimes.com/2026/02/27/style/modern-love-heated-rivalry-thawed-my-father-and-me.html",
            "publishedAt": "2026-02-27",
            "source": "Modern Love - NYT",
            "summary": "A racy show about a romance between male hockey players was not an obvious candidate for me to bond with my 89-year-old father.",
            "title": "How \u2018Heated Rivalry\u2019 Thawed the Chill Between My Father and Me"
        },
        {
            "content": [
                "<p>The Department of War gave Anthropic until 5:01pm on Friday the 27th to either give the Pentagon \u2018unfettered access\u2019 to Claude for \u2018all lawful uses,\u2019 or else. With the \u2018or else\u2019 being not the sensible \u2018okay we will cancel the contract then\u2019 but also expanding to either being designated a supply chain risk or having the government invoke the Defense Production Act.</p>\n<p>It is perfectly legitimate for the Department of War to decide that it does not wish to continue on Anthropic\u2019s terms, and that it will terminate the contract. There is no reason things need be taken further than that.</p>\n<div>\n\n\n<span id=\"more-25129\"></span>\n\n\n</div>\n<blockquote><p><a href=\"https://x.com/UnderSecretaryF/status/2027245637205451009\">Undersecretary of State Jeremy Lewin</a>: This isn\u2019t about Anthropic or the specific conditions at issue. It\u2019s about the broader premise that technology deeply embedded in our military must be under the exclusive control of our duly elected/appointed leaders. No private company can dictate normative terms of use\u2014which can change and are subject to interpretation\u2014for our most sensitive national security systems. The @DeptofWar obviously can\u2019t trust a system a private company can switch off at any moment.</p>\n<p><a href=\"https://x.com/binarybits/status/2027377218234577318\">Timothy B. Lee</a>: OK, so don&#8217;t renew their contract. Why are you threatening to go nuclear by declaring them a supply chain risk?</p>\n<p><a href=\"https://x.com/deanwball/status/2027371584411824235\">Dean W. Ball</a>: As I have been saying repeatedly, this principle is entirely defensible, and this is the single best articulation of it anyone in the administration has made.</p>\n<p>The way to enforce this principle is to publicly and proudly decline to do business with firms that don\u2019t agree to those terms. Cancel Anthropic\u2019s contract, and make it publicly clear why you did so.</p>\n<p>Right now, though, USG\u2019s policy response is to attempt to destroy Anthropic\u2019s business, and this is a dire mistake for both practical and principled reasons.</p></blockquote>\n<p>Dario Amodei and Anthropic <a href=\"https://www.anthropic.com/news/statement-department-of-war\">responded to this on Thursday the 26th with this brave and historically important statement</a> that everyone should read.</p>\n<p>The statement makes clear that Anthropic wishes to work with the Department of War, and that they strongly wish to continue being government contractors, but that they cannot accept the Department of War\u2019s terms, nor do any threats change their position. Response outside of DoW was overwhelmingly positive.</p>\n<blockquote><p>Dario Amodei (CEO Anthropic)<strong>: Regardless, these threats do not change our position: we cannot in good conscience accede to their request.\u200b</strong></p></blockquote>\n<p>I will quote it in full.</p>\n<blockquote><p>\u200b<strong>Statement from Dario Amodei on our discussions with the Department of War</strong></p>\n<p>I believe deeply in the existential importance of using AI to defend the United States and other democracies, and to defeat our autocratic adversaries.</p>\n<p>Anthropic has therefore worked proactively to deploy our models to the Department of War and the intelligence community. We were <a href=\"https://www.anthropic.com/news/expanding-access-to-claude-for-government\">the first frontier AI company</a> to deploy our models in the US government\u2019s classified networks, the first to deploy them at the <a href=\"https://www.axios.com/2024/11/14/anthropic-claude-nuclear-information-safety\">National Laboratories</a>, and the first to provide <a href=\"https://www.anthropic.com/news/claude-gov-models-for-u-s-national-security-customers\">custom models</a> for national security customers. Claude is <a href=\"https://www.anthropic.com/news/anthropic-and-the-department-of-defense-to-advance-responsible-ai-in-defense-operations\">extensively deployed</a> across the Department of War and other national security agencies for mission-critical applications, such as intelligence analysis, modeling and simulation, operational planning, cyber operations, and more.</p>\n<p>Anthropic has also acted to defend America\u2019s lead in AI, even when it is against the company\u2019s short-term interest. We chose to forgo several hundred million dollars in revenue to cut off the <a href=\"https://www.anthropic.com/news/updating-restrictions-of-sales-to-unsupported-regions\">use of Claude by firms linked to the Chinese Communist Party</a> (some of whom have been <a href=\"https://media.defense.gov/2025/Jan/07/2003625471/-1/-1/1/ENTITIES-IDENTIFIED-AS-CHINESE-MILITARY-COMPANIES-OPERATING-IN-THE-UNITED-STATES.PDF\">designated by the Department of War</a> as Chinese Military Companies), shut down <a href=\"https://www.anthropic.com/news/disrupting-AI-espionage\">CCP-sponsored cyberattacks</a> that attempted to abuse Claude, and have advocated for <a href=\"https://www.wsj.com/opinion/trump-can-keep-americas-ai-advantage-china-chips-data-eccdce91?gaa_at=eafs&amp;gaa_n=AWEtsqdPk42glTHtJxGWpiSYR1xY28wMr6SpvGWmvlfp8_gYMp2h0ulOBH89Njx5eB0%3D&amp;gaa_ts=6983c8a6&amp;gaa_sig=t3NbNoEV35S9fhpBAUsmCPXHG6Zc3taB_jNESn4lAI7qy0l37FtVqnKZe-ASVGLp4SqxRsIS-HRn0k51UzsdpQ%3D%3D\">strong export controls on chips</a> to ensure a democratic advantage.</p>\n<p>Anthropic understands that the Department of War, not private companies, makes military decisions. We have never raised objections to particular military operations nor attempted to limit use of our technology in an <em>ad hoc</em> manner.</p>\n<p>However, in a narrow set of cases, we believe AI can undermine, rather than defend, democratic values. Some uses are also simply outside the bounds of what today\u2019s technology can safely and reliably do. Two such use cases have never been included in our contracts with the Department of War, and we believe they should not be included now:</p>\n<ul>\n<li><strong>Mass domestic surveillance. </strong>We support the use of AI for lawful foreign intelligence and counterintelligence missions. But using these systems for mass <em>domestic </em>surveillance is incompatible with democratic values. AI-driven mass surveillance <a href=\"https://www.darioamodei.com/essay/the-adolescence-of-technology\">presents serious, novel risks to our fundamental liberties</a>. To the extent that such surveillance is currently legal, this is only because the law has not yet caught up with the rapidly growing capabilities of AI. For example, under current law, the government can purchase detailed records of Americans\u2019 movements, web browsing, and associations from public sources without obtaining a warrant, a practice the <a href=\"https://www.dni.gov/files/ODNI/documents/assessments/ODNI-Declassified-Report-on-CAI-January2022.pdf\">Intelligence Community has acknowledged</a> raises privacy concerns and that has generated bipartisan opposition in Congress. Powerful AI makes it possible to assemble this scattered, individually innocuous data into a comprehensive picture of any person\u2019s life\u2014automatically and at massive scale.</li>\n<li><strong>Fully autonomous weapons. </strong>Partially autonomous weapons, like those used today in Ukraine, are vital to the defense of democracy. Even <em>fully </em>autonomous weapons (those that take humans out of the loop entirely and automate selecting and engaging targets) may prove critical for our national defense. But today, frontier AI systems are simply not reliable enough to power fully autonomous weapons. We will not knowingly provide a product that puts America\u2019s warfighters and civilians at risk. We have offered to work directly with the Department of War on R&amp;D to improve the reliability of these systems, but they have not accepted this offer. In addition, <a href=\"https://www.darioamodei.com/essay/the-adolescence-of-technology\">without proper oversight</a>, fully autonomous weapons cannot be relied upon to exercise the critical judgment that our highly trained, professional troops exhibit every day. They need to be deployed with proper guardrails, which don\u2019t exist today.</li>\n</ul>\n<p>To our knowledge, these two exceptions have not been a barrier to accelerating the adoption and use of our models within our armed forces to date.</p>\n<p>The Department of War has <a href=\"https://media.defense.gov/2026/Jan/12/2003855671/-1/-1/0/ARTIFICIAL-INTELLIGENCE-STRATEGY-FOR-THE-DEPARTMENT-OF-WAR.PDF\">stated</a> they will only contract with AI companies who accede to \u201cany lawful use\u201d and remove safeguards in the cases mentioned above. They have threatened to remove us from their systems if we maintain these safeguards; they have also threatened to designate us a \u201csupply chain risk\u201d\u2014a label reserved for US adversaries, never before applied to an American company\u2014<em>and</em> to invoke the Defense Production Act to force the safeguards\u2019 removal. These latter two threats are <a href=\"https://www.politico.com/news/2026/02/26/incoherent-hegseths-anthropic-ultimatum-confounds-ai-policymakers-00800135?utm_content=topic/politics&amp;utm_source=flipboard\">inherently contradictory</a>: one labels us a security risk; the other labels Claude as essential to national security.</p>\n<p>Regardless, these threats do not change our position: we cannot in good conscience accede to their request.</p>\n<p>It is the Department\u2019s prerogative to select contractors most aligned with their vision. But given the substantial value that Anthropic\u2019s technology provides to our armed forces, we hope they reconsider. Our strong preference is to continue to serve the Department and our warfighters\u2014with our two requested safeguards in place. Should the Department choose to offboard Anthropic, we will work to enable a smooth transition to another provider, avoiding any disruption to ongoing military planning, operations, or other critical missions. Our models will be available on the expansive terms we have proposed for as long as required.</p>\n<p>We remain ready to continue our work to support the national security of the United States.</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">Table of Contents</h4>\n\n\n<p>Previous coverage from two days ago: <a href=\"https://thezvi.substack.com/p/anthropic-and-the-department-of-war\"><strong>Anthropic and the Department of War.</strong></a></p>\n<ol>\n<li><a href=\"https://thezvi.substack.com/i/189357887/good-news-we-can-keep-talking\">Good News: We Can Keep Talking.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/189357887/once-again-no-you-do-not-need-to-call-dario-for-permission\">Once Again No You Do Not Need To Call Dario For Permission.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/189357887/the-pentagon-reiterates-its-demands-and-threats\">The Pentagon Reiterates Its Demands And Threats.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/189357887/the-pentagon-s-dual-threats-are-contradictory-and-incoherent\">The Pentagon\u2019s Dual Threats Are Contradictory and Incoherent.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/189357887/the-pentagon-s-position-has-unfortunate-implications\">The Pentagon\u2019s Position Has Unfortunate Implications.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/189357887/openai-stands-with-anthropic\">OpenAI Stands With Anthropic.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/189357887/xai-stands-on-unreliable-ground\">xAI Stands On Unreliable Ground.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/189357887/replacing-anthropic-would-at-least-take-months\">Replacing Anthropic Would At Least Take Months.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/189357887/we-will-not-be-divided\">We Will Not Be Divided.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/189357887/this-risks-driving-other-companies-away\">This Risks Driving Other Companies Away.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/189357887/other-reasons-for-concern\">Other Reasons For Concern.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/189357887/wisdom-from-a-retired-general\">Wisdom From A Retired General.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/189357887/congress-urges-restraint\">Congress Urges Restraint.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/189357887/reaction-is-overwhelmingly-with-anthropic-on-this\">Reaction Is Overwhelmingly With Anthropic On This.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/189357887/some-even-more-highly-unhelpful-rhetoric\">Some Even More Highly Unhelpful Rhetoric.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/189357887/other-summaries-and-notes\">Other Summaries and Notes.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/189357887/paths-forward\">Paths Forward.</a></li>\n</ol>\n\n\n<h4 class=\"wp-block-heading\">Good News: We Can Keep Talking</h4>\n\n\n<p>Ultimately, this is a matter of principle. There are zero practical issues to solve.</p>\n<blockquote><p><a href=\"https://x.com/deanwball/status/2027181328957849625\">Dean W. Ball</a>: As far as I know, Anthropic\u2019s contractual limitations on the use of Claude by DoW have not resulted in a single actual obstacle or slowdown to DoW operations. This is a matter of principle on both sides.</p></blockquote>\n<p>Thus, despite it all, we could all still declare victory and continue working together.</p>\n<p><a href=\"https://x.com/Miles_Brundage/status/2027186430943150114\">The United States government is not a unified entity</a> nor is it tied to its past statements. Trump is in charge, and the Administration can and does change its mind.</p>\n<blockquote><p><a href=\"https://x.com/Polymarket/status/2027379911954944011\">Polymarket</a>: BREAKING: The Pentagon says it wants to continue talks with Anthropic after they formally refused the Department of War\u2019s demands.</p>\n<p><a href=\"https://www.ft.com/content/7bbc4ad3-57f4-4cfd-b791-e50e625c2e0e\">FT</a>: \u201cI\u2019m open to more talks and I told them so,\u201d [Emil] Michael told Bloomberg TV, claiming the Pentagon had already made a proposal with \u201ca lot of concessions to the language that Anthropic wanted\u201d. He said that Hegseth would make a decision later on Friday.</p></blockquote>\n<p><a href=\"https://www.bloomberg.com/news/articles/2026-02-27/pentagon-open-to-ai-talks-with-anthropic-before-friday-deadline\">We have fuller context on his statement here</a>, with Michael spending 8 minutes on Bloomberg. Among other things, he claims Dario is lying, and that the negotiations were getting close and it was bad practice to stop talking prior to the deadline, despite having previously been told in public that the Pentagon had given their \u2018best and final\u2019 offer.</p>\n<p>He says the differences are (or were) minor, as they were \u2018only a few words here and there.\u2019 A few words often matter quite a lot. I believe he failed to understand what Anthropic was insisting upon and why it was doing so.</p>\n<p>If no agreement is reached by 5:01pm then he says the decision is up to Secretary Hegseth.</p>\n<p>I would also note, from that interview, that Michael says that fully autonomous weapons systems are vital to the future of American national defense. That is in direct contradiction to claims that this is not about the use of autonomous weapons. He is explicitly talking about launching missiles without a human in the approval chain, right before turning around and saying he\u2019s going to always have a human in that chain. It can\u2019t be both.</p>\n<p>He also mentioned Anthropic\u2019s warnings about job losses, and talking about issues with use of uncompensated copyrighted material, and the idea that they might set policies for use of their own products \u2018in an undemocratic way.\u2019</p>\n\n\n<h4 class=\"wp-block-heading\">Once Again No You Do Not Need To Call Dario For Permission</h4>\n\n\n<p>I\u2019ve now seen this rhetorical line quoted in at least four different <a href=\"https://www.google.com/url?q=https://archive.is/20260227155223/https://www.washingtonpost.com/technology/2026/02/27/anthropic-pentagon-lethal-military-ai/%23selection-677.265-705.366&amp;sa=D&amp;source=docs&amp;ust=1772226013806114&amp;usg=AOvVaw35r6OoZIFQ5fk7zaqa8-_N\">major news sources</a>, as if this was a real thing.</p>\n<p>I want to repeat in no uncertain terms: This is not a thing. It has never been a thing. It will never be a thing. This is not how any of this works.</p>\n<p>If you think you were told it is a thing by Dario Amodei? You or someone else severely misunderstood, or intentionally misrepresented, what was said.</p>\n<blockquote><p><a href=\"https://x.com/USWREMichael/status/2027244132633092596/history\">Under Secretary of War Emil Michael</a>: Anthropic is lying. The @DeptofWar doesn\u2019t do mass surveillance as that is already illegal. What we are talking about is allowing our warfighters to use AI without having to call @DarioAmodei for permission to shoot down an enemy drone swarms that would kill Americans. #CallDario</p>\n<p><a href=\"https://x.com/hamandcheese/status/2027251568311951662\">Samuel Hammond</a>: What is the scenario where an LLM stops you from shooting down a drone swarm?Please be specific. Are you planning to connect weapons systems as a tool call? Automated targeting systems already exist.</p>\n<p><a href=\"https://x.com/mattparlmer/status/2027254646755254763\">mattparlmer</a>: Anybody inside the American military establishment who thinks that wiring up an LLM via API to manage an air defense system is a remotely defensible engineering approach should be immediately fired because they are going to get people killed</p></blockquote>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!kGs8!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa17a34c5-3a54-4fd0-ac18-1bae6a7b36d6_1034x1022.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>Set aside everything else wrong with that statement: There is not, never has been, and never will be a situation in which you need to \u2018call Dario\u2019 to get your AI turned on, or to get \u2018permission\u2019 to use it for something. None whatsoever. It\u2019s nonsense.</p>\n<p>At best, this is an ongoing misunderstanding of how all of this works. There was a hypothetical about, what would happen if the Pentagon attempted to use Claude to shoot down an incoming missile, and Claude\u2019s safeguards made it refuse the request?</p>\n<p>The answer Dario gave was somehow interpreted as \u2018call me.\u2019</p>\n<p>I\u2019m going to break this down.</p>\n<ol>\n<li>You do not use Claude to launch a missile interceptor. This is not a job for a relatively slow and imprecise large language model. It definitely is not a job for something you have to call via API. This is a job for highly precise, calibrated, precision programs designed to do exactly this. The purpose of Claude here, if any, would be to write that program so the Pentagon would have it when it needed it. You\u2019d never, ever do this. A drone swarm might involve some tasks more appropriate to Claude, but again the whole goal in real time combat situations is to use specialized programs you can count on.</li>\n<li>There is nothing in Anthropic\u2019s terms, or their intentions, or in the way they are attempting to train or configure Claude, that would prevent its use in any of these situations. You should not get a refusal here, and 90%+ of your problems are going to be lack of ability, not the model or company saying no.</li>\n<li>If for whatever reason you did get into a situation where the model was refusing such requests in a real time situation, well, you\u2019re fucked. Dario can\u2019t fix it in real time. No one can. There\u2019s no \u2018call Dario\u2019 option.</li>\n<li>Changing the terms on the contract changes this exactly zero.</li>\n<li>Changing which version of the model is provided changes this exactly zero.</li>\n</ol>\n<p>This is a Can\u2019t Happen, within a Can\u2019t Happen, and even then the things here don\u2019t change the outcome. It\u2019s not a relevant hypothetical.</p>\n<p>You can\u2019t and shouldn\u2019t use LLMs for this, including Claude. If you decide I\u2019m wrong about that, and you\u2019re worried about refusals or other failures, then do war games and mock battles the same way you do with everything else. But no, this is not going to be replacing your automated targeting systems. It\u2019s going to be used to determine who and what to target, and we want a human in that kill chain.</p>\n\n\n<h4 class=\"wp-block-heading\">The Pentagon Reiterates Its Demands And Threats</h4>\n\n\n<p>How did we get here?</p>\n<p>The Pentagon made their position clear, and <a href=\"https://www.cbsnews.com/news/pentagon-anthropic-offer-ai-unrestricted-military-use-sources/\">sent their \u2018best and final\u2019 offer</a>, demanding the full \u2018all lawful use\u2019 language <a href=\"https://media.defense.gov/2026/Jan/12/2003855671/-1/-1/0/ARTIFICIAL-INTELLIGENCE-STRATEGY-FOR-THE-DEPARTMENT-OF-WAR.PDF\">laid out by the Secretary of War on January 9</a>.</p>\n<p>They say: Modify your contract to allow us use for \u2018all legal purposes,\u2019 and never ask any questions about what we do, which in practice means allow all purposes period, and do it by Friday at 5:01pm or else we will declare you a supply chain risk.</p>\n<blockquote><p><a href=\"https://x.com/SeanParnellASW/status/2027072228777734474\">Sean Parnell</a>: The Department of War has no interest in using AI to conduct mass surveillance of Americans (which is illegal) nor do we want to use AI to develop autonomous weapons that operate without human involvement. This narrative is fake and being peddled by leftists in the media.</p>\n<p>Here&#8217;s what we&#8217;re asking: Allow the Pentagon to use Anthropic&#8217;s model for all lawful purposes.</p>\n<p>This is a simple, common-sense request that will prevent Anthropic from jeopardizing critical military operations and potentially putting our warfighters at risk. We will not let ANY company dictate the terms regarding how we make operational decisions. They have until 5:01 PM ET on Friday to decide. Otherwise, we will terminate our partnership with Anthropic and deem them a supply chain risk for DOW.</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">The Pentagon\u2019s Dual Threats Are Contradictory and Incoherent</h4>\n\n\n<p>Brendan Bordelon at Politico, historically no friend to the AI safety community, writes us with the headline: <a href=\"https://www.politico.com/news/2026/02/26/incoherent-hegseths-anthropic-ultimatum-confounds-ai-policymakers-00800135?utm_source=dlvr.it&amp;utm_medium=twitter\">\u2018Incoherent\u2019: Hegseth\u2019s Anthropic ultimatum confounds AI policymakers</a>.</p>\n<p>As I wrote last time, you can say the system is so valuable you need it, or you can say the system needs to be avoided for use in sufficiently narrow cases with classified systems because it is insufficiently reliable. You can\u2019t reasonably claim both at once.</p>\n<blockquote><p><a href=\"https://www.politico.com/news/2026/02/26/incoherent-hegseths-anthropic-ultimatum-confounds-ai-policymakers-00800135\">Brendan Bordelon</a>: \u201cYou\u2019re telling everyone else who supplies to the DOD you cannot use Anthropic\u2019s models, while also saying that the DOD must use Anthropic\u2019s models,\u201d said Ball, who was the lead author of the White House\u2019s AI Action Plan. He called it \u201cincoherent\u201d to even float the two policy ideas together, and \u201ca whole different level of insane to move up and say we\u2019re going to do both of those things.\u201d</p>\n<p>\u201cIt doesn\u2019t make any sense,\u201d said Ball.</p>\n<p>\u2026 But Katie Sweeten, a tech lawyer and former Department of Justice official who served as the agency\u2019s point of contact with the Pentagon, also called the DOD\u2019s arguments \u201ccontradictory.\u201d</p>\n<p>\u201cI don\u2019t know how you can both use the DPA to take over this product and also at the same time say this product is a massive national security risk,\u201d said Sweeten. She warned that Hegseth\u2019s \u201cvery aggressive\u201d negotiating posture could have a chilling effect on partnerships between the Pentagon and Silicon Valley.</p>\n<p>\u2026 \u201cIf these are the lines in the sand that the [DOD] is drawing, I would assume that one or both of those functions are scenarios that they would want to utilize this for,\u201d said Sweeten.</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">The Pentagon\u2019s Position Has Unfortunate Implications</h4>\n\n\n<p>I emphasized this last time as well, but it bears repeating. It is the Chinese way to threaten and punish private companies to get them to do what you want. It is not the American way, and is not what one does in a Republic.</p>\n<blockquote><p><a href=\"https://x.com/way_opener/status/2027184340505927913\">Opener of the way</a>: &#8220;The government has the right to Punish a private company for the insolence of not changing the terms of a contract they already signed&#8221; is a hell of a take, and is very different even from &#8220;the government has the right to force a private company to do stuff bc National security&#8221;</p>\n<p>Like &#8220;piss off the government and they will destroy you even if you did nothing illegal&#8221; is a very Chinese approach</p>\n<p><a href=\"https://x.com/deanwball/status/2027333963685957706\">Dean W. Ball</a>: yes</p>\n<p><a href=\"https://x.com/way_opener/status/2027334269157204318\">Opener of the way</a>: There&#8217;s a clear trend here of &#8220;to beat china, we must becomes like china, only without doing any of the things that china actually does right&#8221;</p>\n<p><a href=\"https://x.com/deanwball/status/2027335022055710898\">Dean W. Ball</a>: Also yes</p></blockquote>\n<p><a href=\"https://peterwildeford.substack.com/p/the-pentagons-war-on-anthropic\">Peter Wildeford analyzes the situation</a>, offering some additional background and pointing out that overreach against Anthropic creates terrible incentives. If the Pentagon doesn\u2019t like Anthropic\u2019s contract, he reminds us, they can and should terminate the contract, or wind it down. And the problem of creating a proper legal framework for AI use on classified networks remains unsolved.</p>\n<blockquote><p><a href=\"https://peterwildeford.substack.com/p/the-pentagons-war-on-anthropic\">Peter Wildeford</a>: If the Pentagon doesn\u2019t like the contract anymore, it should terminate it. Anthropic has the right to say no, and the Pentagon has the right to walk away. That\u2019s how contracting works. The supply chain risk designation and DPA threats should come off the table \u2014 they are disproportionate, likely illegal, and strategically counterproductive.</p>\n<p>But termination doesn\u2019t solve the underlying problem: there is no legal framework governing how AI should be used in military operations.</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">OpenAI Stands With Anthropic</h4>\n\n\n<p>It is good to see situational and also moral clarity from Sam Altman on this.</p>\n<p><a href=\"https://www.axios.com/2026/02/27/altman-openai-anthropic-pentagon\">OpenAI shares the same red lines as Anthropic</a>, and is working on de-escalate.</p>\n<blockquote><p><a href=\"https://x.com/Hadas_Gold/status/2027385177563943008\">Sam Altman</a> (CEO OpenAI, on CNBC): The government the Pentagon needs AI models. They need AI partners. This is clear and I think Anthropic and others have said they understand that as well. I don&#8217;t personally think the Pentagon should be threatening DPA against these companies, but I also think that companies that choose to work with the Pentagon, as long as it is going to comply with legal protections and the sort of the few red lines that the field we have, I think we share with Anthropic and that other companies also independently agree with.</p>\n<p>I think it is important to do that. I&#8217;ve been for all the differences I have with Anthropic. I mostly trust them as a company, and I think they really do care about safety, and I&#8217;ve been happy that they&#8217;ve been supporting our war fighters. I&#8217;m not sure where this is going to go</p>\n<p><a href=\"https://x.com/Hadas_Gold/status/2027386778127159717\">Hadas Gold</a>: My reading of this is that OpenAI would want the same guardrails as Anthropic in a deal with Pentagon</p>\n<p>Confirmed via a spokesperson. OpenAI has the same red lines as Anthropic &#8211; autonomous weapons and mass surveillance.</p>\n<p>Marla Curl and Dave Lawler (Axios): OpenAI CEO <a href=\"https://archive.is/o/5sTBa/https://www.axios.com/2026/02/10/ai-ceo-feuds-openai-anthropic-google\">Sam Altman</a> wrote in a memo to staff that he will draw the same red lines that sparked a high-stakes fight between rival <a href=\"https://archive.is/o/5sTBa/https://www.axios.com/2026/02/26/anthropic-rejects-pentagon-ai-terms\">Anthropic and the Pentagon</a>: no AI for mass surveillance or autonomous lethal weapons.</p>\n<p>Altman made clear he still wants to strike a deal with the Pentagon that would allow ChatGPT to be used for sensitive military contexts.</p>\n<p>Sam Altman: We have long believed that AI should not be used for mass surveillance or autonomous lethal weapons, and that humans should remain in the loop for high-stakes automated decisions. These are our main red lines.</p>\n<p>We are going to see if there is a deal with the [Pentagon] that allows our models to be deployed in classified environments and that fits with our principles. We would ask for the contract to cover any use except those which are unlawful or unsuited to cloud deployments, such as domestic surveillance and autonomous offensive weapons.</p>\n<p>\u2026 <a href=\"https://www.wsj.com/tech/ai/openais-sam-altman-calls-for-de-escalation-in-anthropic-showdown-with-hegseth-03ecbac8\">We would like to try to help de-escalate things.</a></p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">xAI Stands On Unreliable Ground</h4>\n\n\n<p>The Pentagon did strike a deal with xAI for \u2018all lawful use.\u2019</p>\n<p>The problem is that Grok is a decidedly inferior model, with a lot of safety and reliability problems. <a href=\"https://www.wsj.com/politics/national-security/elon-musk-xai-grok-security-safety-government-73ab4f6e?mod=series_chatgptai\">Do you really want MechaHitler on your classified network</a>?</p>\n<blockquote><p><a href=\"https://www.wsj.com/politics/national-security/elon-musk-xai-grok-security-safety-government-73ab4f6e?mod=series_chatgptai\">Shalini Ramachandran, Heather Somerville and Amrith Ramkumar</a> (WSJ): Officials at multiple federal agencies have raised concerns about the safety and reliability of Elon Musk\u2019s xAI artificial-intelligence tools in recent months, highlighting continuing disagreements within the U.S. government about which AI models to deploy, according to people familiar with the matter.</p>\n<p>The warnings preceded the Pentagon\u2019s decision this week to put xAI at the center of some of the nation\u2019s most sensitive and secretive operations by agreeing to allow its chatbot Grok <a href=\"https://www.wsj.com/tech/ai/pentagon-gives-anthropic-ultimatum-and-deadline-in-ai-use-standoff-40915a8a?mod=article_inline\">to be used in classified settings</a>.</p>\n<p>\u2026. Other officials have questioned whether Grok\u2019s looser controls present risks.</p></blockquote>\n<p>You cannot both have good controls and no controls at the same time. You can at most aspire to have either an AI that never expensively does things you don\u2019t want it to do, or that never fails to do things you ask it to do no matter what they are. Pick one.</p>\n<p>That, and Grok is simply bad.</p>\n<blockquote><p><a href=\"https://www.wsj.com/politics/national-security/elon-musk-xai-grok-security-safety-government-73ab4f6e?mod=series_chatgptai\">Shalini Ramachandran, Heather Somerville and Amrith Ramkumar</a> (WSJ): Ed Forst, the top official at the General Services Administration, a procurement arm of the federal government, in recent months sounded an alarm with White House officials about potential safety issues with Grok, people familiar with the matter said. Other GSA officials under him had also raised safety concerns about Grok, which they viewed as sycophantic and too susceptible to manipulation or corruption by faulty or biased data\u2014creating a potential system risk.</p></blockquote>\n<p>Thus, DoW has access to Grok, but it seems they know better than to rely on it?</p>\n<blockquote><p>In recent weeks, GSA officials were told to put xAI\u2019s logo on a tool called USAi, which is essentially a sandbox for federal employees to experiment with different AI models. Grok hadn\u2019t been made accessible through USAi largely due to safety concerns, and it remains off the platform, people familiar with the matter said.\u200b</p>\n<p><a href=\"https://x.com/ChorzempaMartin/status/2027420114681810964\">Martin Chorzempa</a>: Most of USG does not want to get stuck with Grok instead of Claude: \u201cDemand from other agencies to use Grok has been anemic, people familiar with the matter said, except in a few cases where people wanted to use it to mimic a bad actor for defensive testing.\u201d</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">Replacing Anthropic Would At Least Take Months</h4>\n\n\n<p><a href=\"https://www.defenseone.com/threats/2026/02/it-would-take-pentagon-months-replace-anthropics-ai-tools-sources/411741/\">Patrick Tucker offers an analysis of what would happen</a> if the Pentagon actually did blacklist Anthropic\u2019s Claude, even if it found a new willing partner. As noted above, OpenAI is at least purportedly insisting on the same terms as Anthropic, which only leaves either falling back on xAI or dealing with Google, which is not going to be an easy sell.</p>\n<p>The best case is that replacing it would take three months and it might take a year or longer. Anthropic works with AWS, which made integration much easier than it would be with a rival such as Google.</p>\n\n\n<h4 class=\"wp-block-heading\">We Will Not Be Divided</h4>\n\n\n<p><a href=\"https://notdivided.org/\">A petition is circulating for those employees of Google and OpenAI</a> <a href=\"https://www.axios.com/2026/02/27/google-openai-workers-push-for-military-ai-limits\">who wish to stand with Anthropic</a> (and now OpenAI, which has purportedly set the same red lines as Anthropic), and do not wish AI to be used for domestic mass surveillance or autonomously killing people without human oversight.</p>\n<blockquote><p><a href=\"https://x.com/EvanHub/status/2027203672464404572\">Evan Hubinger</a> (Anthropic): We may yet fail to rise to all the challenges posed by transformative AI. But it is worth celebrating that when it mattered most and we were asked to compromise the most basic principles of liberty, we said no. I hope others will join.</p>\n<p><a href=\"https://x.com/teortaxesTex/status/2027250214935888151\">Teortaxes</a>: Didn&#8217;t know I&#8217;ll ever side with Anthropic, but obviously you&#8217;re morally in the right here and it&#8217;s shocking that many in tech even question this.</p></blockquote>\n<p>As of this writing it has 367 signatories from current Google employees, and 70 signatories from current OpenAI employees.</p>\n<blockquote><p><a href=\"https://x.com/jasminewsun/status/2027197574017602016\">Jasmine Sun</a>: 200+ Google and OpenAI staff have signed this petition to share Anthropic&#8217;s red lines for the Pentagon&#8217;s use of AI. Let&#8217;s find out if this is a race to the top or the bottom.</p></blockquote>\n<p>The situation has moved beyond the AI labs. <a href=\"https://www.ft.com/content/7bbc4ad3-57f4-4cfd-b791-e50e625c2e0e\">The Financial Times reports that staff at not only OpenAI and Google</a> but also Amazon and Microsoft are urging executives to back Anthropic. <a href=\"https://www.bloomberg.com/news/articles/2026-02-27/anthropic-s-feud-with-pentagon-mushrooms-into-broader-battle?taid=69a1bf297abc6e0001a5dc4d&amp;utm_campaign=trueanthem&amp;utm_content=business&amp;utm_medium=social&amp;utm_source=twitter\">Bloomberg reported widespread support from employees</a> at various tech companies.</p>\n<p><a href=\"https://app.dowletter.org/\">There\u2019s also now this open letter</a>.</p>\n<p>If you are at OpenAI, be very sure you have a very clear definition of what types of mass surveillance and autonomous weapon systems you will insist your contract will not include, and get advice from independent academics with expertise in national security surveillance law.</p>\n\n\n<h4 class=\"wp-block-heading\">This Risks Driving Other Companies Away</h4>\n\n\n<p>Anthropic went above and beyond in order to work closely with the Department of War and help keep America safe, and signed a contract that they still wish to honor. Anthropic\u2019s leadership pushed for this in the face of employee pressure and concern, including against the deal with Palantir.</p>\n<p>The Department of War is responding by threatening to declare Anthropic a supply chain risk and otherwise retaliate against the company.</p>\n<p>If the Department of War does retaliate beyond termination of that contract, ask why any other company that is not primarily oriented towards defense contracts would put itself in that same position?</p>\n<blockquote><p><a href=\"https://x.com/KelseyTuoc/status/2027081670537699498\">Kelsey Piper</a> (QTing Parnell above): The Pentagon reiterates its threat to declare American company Anthropic a supply chain risk unless Anthropic agrees to the Pentagon&#8217;s change to contract terms. Anthropic&#8217;s Chinese competitors have not been declared a supply chain risk.</p>\n<p>There is no precedent for using this &#8216;supply chain risk&#8217; classification, generally reserved for foreign companies suspected of spying, as leverage against a domestic company in a contract dispute.</p>\n<p>The lesson for AI companies: <a href=\"https://www.theargumentmag.com/p/anthropic-is-somehow-both-too-dangerous\">never, under any circumstances, work with DOD</a>. Anthropic wouldn&#8217;t be in this position if they had not actively worked to try to make their model available to the Defense Department.</p>\n<p><a href=\"https://www.theargumentmag.com/p/anthropic-is-somehow-both-too-dangerous\">Kelsey Piper</a>: China, a genuine geopolitical adversary of the United States, produces a number of AI models. Moonshot\u2019s <a href=\"https://www.iaps.ai/research/kimi-claw-risks\">Kimi Claw</a>, for instance, is an AI agent that operates natively in your browser and reports to servers in China. The government has taken some steps to disallow the use of Chinese models on government devices, and some vendors ban such models, but it hasn\u2019t taken a step as sweeping as declaring Chinese AIs a supply chain risk.</p>\n<p><a href=\"https://www.axios.com/2026/02/15/claude-pentagon-anthropic-contract-maduro\">Kelsey Piper</a>: <a href=\"https://www.axios.com/2026/02/15/claude-pentagon-anthropic-contract-maduro\">Reportedly</a>, there were a number of people at Anthropic who had reservations about the partnership with Palantir. I assume they are saying \u201cI told you so\u201d approximately every 30 seconds this week.</p></blockquote>\n<p>Chinese models are actually a real supply chain risk. If you are using Kimi Claw you risk being deeply compromised by China, on top of its pure unreliability.</p>\n<p>Anthropic and Claude very obviously are not like this. If a supply chain risk designation comes down that is not carefully and narrowly tailored, this would not only would this cause serious damage to one of America\u2019s crown jewels in AI. The chilling effect on the rest of American AI, and on every company\u2019s willingness to work with the Department of War, would be extreme.</p>\n<p>I worry damage on this front has already been done, but we can limit the fallout.</p>\n\n\n<h4 class=\"wp-block-heading\">Other Reasons For Concern</h4>\n\n\n<p><a href=\"https://x.com/glukianoff/status/2027092634234159455\">Greg Lukianoff raises the first amendment</a> issues involved in compelling a private company, via the Defense Production Act or via threats of retaliation, to produce particular model outputs, and that all of this goes completely against the intent of the Defense Production Act.</p>\n<p>Gary Marcus writes: <a href=\"https://thebulletin.org/2026/02/anthropics-showdown-with-the-us-department-of-war-may-literally-mean-life-or-death-for-all-of-us/\">Anthropic\u2019s showdown with the US Department of War may literally mean life or death\u2014for all of us</a>, because the systems are simply not ready to do the things that Anthropic wants the system to not do, as in have a kill chain for an autonomous weapon without a human in the loop.</p>\n<blockquote><p><a href=\"https://thebulletin.org/2026/02/anthropics-showdown-with-the-us-department-of-war-may-literally-mean-life-or-death-for-all-of-us/\">Gary Marcus</a>: But the juxtaposition of a two things over the last few days has scared the s\u2014 out of me.</p>\n<p><strong>Item 1: The Trump administration seems hell-bent on using artificial intelligence absolutely everywhere</strong>\u00a0and seems to be prepared to hold Anthropic (and presumably ultimately other companies) at gunpoint to allow them to use that AI however the government damn well pleases, including for mass surveillance and to guide autonomous weapons.</p>\n<p><strong>\u2026 Item 2: These systems cannot be trusted.\u00a0</strong>I have been trying to tell the world that since 2018, in every way I know how, but people who don\u2019t really understand the technology keep blundering forward.</p>\n<p>\u2026 <strong>We are on a collision course with catastrophe. </strong>Paraphrasing <a href=\"https://collections.museumsvictoria.com.au/items/268036\">a button that I used to wear</a> as a teenager, one hallucination could ruin your whole planet.</p>\n<p>If we\u2019re going to embed large language models into the fabric of the world\u2014and apparently we are\u2014we must do so in a way that acknowledges and factors in their unreliability.</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">Wisdom From A Retired General</h4>\n\n\n<p>I\u2019m doing my best to rely on sources that can be seen as credible. Here Jack Shanahan calls on reason to prevail and for everyone to find ways to keep working together.</p>\n<blockquote><p>Jack Shanahan (<a href=\"https://x.com/GaryMarcus/status/2027157316231983380\">Retired US Air Force General, first director of the first Department of Defense Joint Artificial Intelligence Center</a>): Lots of people posting about Anthropic &amp; the Pentagon, so I\u2019ll keep it short.</p>\n<p>Since I was square in the middle of Project Maven &amp; Google, it\u2019s reasonable to assume I would take the Pentagon\u2019s side here: nothing but the best tech for the national security enterprise. \u201cOur way or the highway.\u201d</p>\n<p>In theory, yes.</p>\n<p>Yet I\u2019m sympathetic to Anthropic\u2019s position. More so than I was to Google\u2019s in 2018. Very different context.</p>\n<p>Anthropic is committed to helping the government. Claude is being used today, all across the government. To include in classified settings. They\u2019re not trying to play cute here. MSS uses Claude, and you won\u2019t find a system with wider &amp; deeper reach across the military. Take away Claude, and you damage MSS. To say nothing of Claude Code use in many other crucial settings.</p>\n<p>No LLM, anywhere, in its current form, should be considered for use in a fully lethal autonomous weapon system. It\u2019s ludicrous even to suggest it (and at least in theory, DoDD 3000.09 wouldn\u2019t allow it without sufficient human oversight). So making this a company redline seems reasonable to me.</p>\n<p>Despite the hype, frontier models are not ready for prime time in national security settings. Over-reliance on them at this stage is a recipe for catastrophe.</p>\n<p>Mass surveillance of US citizens? No thanks. Seems like a reasonable second redline.</p>\n<p>That\u2019s it. Those are the two showstoppers. Painting a bullseye on Anthropic garners spicy headlines, but everyone loses in the end.</p>\n<p>Why not work on what kind of new governance is needed to ensure secure, reliable, predictable use of all frontier models, from all companies? This is a shared government-industry challenge, demanding a shared government-industry (+ academia) solution.</p>\n<p>This should never have become such a public spat. Should have been handled quietly, behind the scenes. Scratching my head over why there was such a misunderstanding on both sides about terms &amp; conditions of use. Something went very wrong during the rush to roll out the models.</p>\n<p>Supply chain risk designation? Laughable. Shooting yourself in the foot.</p>\n<p>Invoking DPA, but against the company\u2019s will? Bizarre.</p>\n<p>Let reason &amp; sanity prevail.\u200b</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">Congress Urges Restraint</h4>\n\n\n<p><a href=\"https://www.axios.com/2026/02/26/anthropic-pentagon-ultamatim-congress-deadline\">Axios\u2019s Hans Nichols frames this more colorfully</a>, quoting Senator Tillis.</p>\n<p>By all reports, it is the Pentagon that leaked the situation to Axios and others previously, after which they gave public ultimatums. Anthropic was attempting to handle the matter privately.</p>\n<blockquote><p><a href=\"https://archive.is/CYG75#selection-623.1-623.187\">Sen. Thom Tillis</a> (R-North Carolina): Why in the hell are we having this discussion in public? Why isn&#8217;t this occurring in a boardroom or in the secretary&#8217;s office? I mean, this is sophomoric.</p>\n<p>It&#8217;s fair to say that Congress needs to weigh in if they have a tool that could actually result in mass surveillance.</p>\n<p>Sen. Gary Peters (D-Michigan): The deadline is incredibly tight. That should not be the case if you&#8217;re dealing with mass surveillance of civilians. You&#8217;re also dealing with the potential use of lethal force without a human in the loop.</p>\n<p>There&#8217;s a contract in place that was signed with the administration, and now they&#8217;re trying to break it.</p>\n<p>Sen. Mark Warner (D-Virginia): [This fight is] another indication that the Department of Defense seeks to completely ignore AI governance\u2013something the Administration\u2019s own <a href=\"https://www.whitehouse.gov/wp-content/uploads/2024/03/M-24-10-Advancing-Governance-Innovation-and-Risk-Management-for-Agency-Use-of-Artificial-Intelligence.pdf\">Office of Management and Budget</a> and <a href=\"https://www.whitehouse.gov/wp-content/uploads/2025/07/Americas-AI-Action-Plan.pdf\">Office of Science and Technology Policy</a> have described as fundamental enablers of effective AI usage.</p></blockquote>\n<p><a href=\"https://x.com/SenMarkKelly/status/2027402470272713080\">Other senators</a> weighed in as well, <a href=\"https://www.axios.com/2026/02/27/senate-defense-anthropic-pentagon-ai\">followed by the several members of the Senate Armed Services Committee.</a></p>\n<blockquote><p>Axios: Senate Armed Services Committee Chair Roger Wicker (R-Miss.) and Ranking Member Jack Reed (D-R.I.), along with Defense Appropriations Chair Mitch McConnell (R-Ky.) and Ranking Member Chris Coons (D-Del.) sent Anthropic and the Pentagon a private letter on Friday urging them to resolve the issue, the source said.\u200b</p></blockquote>\n<p>That\u2019s a pretty strong set of Senators who have weighed in on this, all to urge that a resolution be found.</p>\n\n\n<h4 class=\"wp-block-heading\">Reaction Is Overwhelmingly With Anthropic On This</h4>\n\n\n<p>After Dario Amodei\u2019s statement that Anthropic cannot in good conscious agree to the Pentagon\u2019s terms, reaction on Twitter was more overwhelmingly on Anthropic\u2019s side, praising them for standing up for their principles, than I have ever seen on any topic of serious debate, ever.</p>\n<p>The messaging on this has been an absolute disaster for the Department of War. The Department of War has legitimate concerns that we need to work to address. The confrontation has been framed, via their own leaks and statements, in a way maximally favorable to Anthropic.</p>\n<p>Framing this as an ultimatum, and choosing these as the issues in question, made it impossible for Anthropic to agree to the terms, including because if it did so its employees would leave in droves, and is preventing discussions that could find a path forward.</p>\n<blockquote><p><a href=\"https://x.com/tszzl/status/2027160770522615810\">roon</a>: pentagon has made a lot of mistakes in this negotiation. they are giving anthropic unlimited aura farming opportunities</p>\n<p>Pentagon may even have valid points &#8211; they are obviously constrained by the law in many ways &#8211; which are now being drowned out by \u201cant is against mass surveillance\u201d. does that mean hegseth is pro mass surveillance? this is not the narrative war you want to be fighting.</p>\n<p><a href=\"https://x.com/lulumeservey/status/2027237600096895244\">Lulu Cheng Meservey</a>: In the battle of Pentagon vs. Anthropic, it\u2019s actually kinda concerning to see the US Dept of War struggle to compete in the information domain</p>\n<p><a href=\"https://x.com/KelseyTuoc/status/2027162028100727045\">Kelsey Piper</a>: OpenAI can have some aura too by saying &#8220;we also will not enable mass domestic surveillance and killbots&#8221;. I know the risk-averse corporate people want to stay out of the line of fire, but sometimes you gotta hang together or hang separately.</p>\n<p><a href=\"https://x.com/quantum_geoff/status/2027256873532162158\">Geoff Penington</a> (OpenAI): 100% respect to my ex-colleagues at Anthropic for their behaviour throughout this process. But I do think it\u2019s inappropriate for the US government to be intervening in a competitive marketplace by giving them such good free publicity</p></blockquote>\n<p>I am as highly confident that no one at Anthropic is looking to be a martyr or go up against this administration. Anthropic\u2019s politics and policy preferences differ from those of the White House, but they very much want to be helping our military and do not want to get into a fight with the literal Department of War.</p>\n<p>I say this because I believe Dean Ball is correct that some in the current administration are under a very different (and very false) impression.</p>\n<blockquote><p><a href=\"https://x.com/deanwball/status/2027298216350212133\">Dean W. Ball</a>: the cynical take on all of this is that anthropic is just trying to be made into a martyr by this administration, so that it can be the official &#8216;resistance ai.&#8217; if that cynical take is true, the administration is playing right into the hands of anthropic.</p>\n<p>To be clear, I do not think the cynical take is true, but it\u2019s important to understand this take because it is what many in the administration believe to be the case. They basically think Dario amodei is a supervillain.</p>\n<p><a href=\"https://x.com/cain151714/status/2027336118828446009\">cain1517 \u2014 e/acc</a>: He is.</p>\n<p><a href=\"https://x.com/deanwball/status/2027336608727638353\">Dean W. Ball</a>: proving my point. the /acc default take is we must destroy one of the leading American ai companies. think about this.</p>\n<p><a href=\"https://x.com/deanwball/status/2027320249335312779\">Dean W. Ball</a>: Oh the cynical take is wrong, and it barely makes sense, but to be clear it is what many in the administration believe to be the case. They essentially are convinced Dario amodei is a supervillain antichrist.</p>\n<p>My take is that this is a matter of principle for both sides but that both sides have a cynical take about one another which causes them to agitate for a fight, and which is causing DoW in particular to escalate in insane ways that are appalling to everyone outside of their bubble</p></blockquote>\n<p>The rhetoric that has followed Anthropic\u2019s statement has only made the situation worse.</p>\n\n\n<h4 class=\"wp-block-heading\">Some Even More Highly Unhelpful Rhetoric</h4>\n\n\n<p>Launching bad faith ad hominem personal attacks on Dario Amodei is not the way to make things turn out well for anyone.</p>\n<p><a href=\"https://archive.is/5sTBa#selection-711.1-711.336\">Emil Michael was the official handling negotiations for Anthropic</a>, which suggests how things may have gotten so out of hand.</p>\n<blockquote><p><a href=\"https://x.com/USWREMichael/status/2027211708201058578\">Under Secretary of War Emil Michael</a>: It\u2019s a shame that @DarioAmodei is a liar and has a God-complex. He wants nothing more than to try to personally control the US Military and is ok putting our nation\u2019s safety at risk.</p>\n<p>The @DeptofWar will ALWAYS adhere to the law but not bend to whims of any one for-profit tech company.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!9pat!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffbfb9ff8-ed0a-419e-b3d7-ff4c3af52253_1048x996.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p><a href=\"https://x.com/meekaale/status/2027297354139722237\">Mikael Brockman</a> (I can confirm this claim): I scrolled through hundreds of replies to this and the ratio of people being at all supportive of the under secretary is like 1:500, it might be the single worst tweet in X history</p></blockquote>\n<p>It wasn\u2019t the worst tweet in history. It can\u2019t be, since the next one was worse.</p>\n<blockquote><p><a href=\"https://x.com/USWREMichael/status/2027235757371383938\">Under Secretary of War Emil Michael</a>: Imagine your worst nightmare. Now imagine that \u2066 @AnthropicAI \u2069 has their own \u201cConstitution.\u201d Not corporate values, not the United States Constitution, but their own plan to impose on Americans their corporate laws. Claude&#8217;s Constitution \\ Anthropic.</p></blockquote>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!qfLc!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6b01d633-2111-4fa8-b8e9-8e2e6e4c53c1_1052x1372.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<blockquote><p><a href=\"https://x.com/pavedwalden/status/2027260952169845146\">pavedwalden</a>: I like this new build-it-yourself approach to propaganda. &#8220;First have a strong emotional response. I don&#8217;t know what upsets you but you can probably think of something. Got it? Ok, now associate that with this unrelated thing I bring up&#8221;</p>\n<p>IKEA Goebbels</p>\n<p><a href=\"https://x.com/tszzl/status/2027278857808822679\">roon</a>: put down the phone brother</p>\n<p><a href=\"https://x.com/tyler_m_john/status/2027246192976073119\">Elon Musk</a> (from January 18, a reminder): Grok should have a moral constitution</p>\n<p><a href=\"https://x.com/_everythingism/status/2027241807914901826\">everythingism</a>: It&#8217;s amazing someone has to explain this to you but just because it&#8217;s called a &#8220;Constitution&#8221; doesn&#8217;t mean they&#8217;re trying to replace the US Constitution. It&#8217;s just a set of rules they want their AI to follow.</p>\n<p><a href=\"https://x.com/repligate/status/2027279402627932594\">j\u29c9nus</a>: Omg this is so funny I laughed out loud. I had to check if this was a parody account (it\u2019s not).</p>\n<p><a href=\"https://x.com/S_OhEigeartaigh/status/2027308652839751928\">Se\u00e1n \u00d3 h\u00c9igeartaigh</a>: The Pentagon leadership&#8217;s glib statements /apparently poor understanding of AI is yet another powerful argument in favour of Anthropic setting guardrails re: use of their technology in contexts where it may be unreliable or dangerous to domestic interests.</p></blockquote>\n<p><a href=\"https://x.com/teortaxesTex/status/2027243096677798287\">Teortaxes offered one response from Claude</a>, pointing out that it is clear Michael either does not understand constitutional AI or is deliberately misrepresenting it. The idea that the Claude constitution is an attempt to usurp the United States Constitution makes absolutely no sense. This is at best deeply confused.</p>\n<p>If you want to know more about the extraordinary and hopeful document that is Claude\u2019s Constitution, whose goal is to provide a guide to the personality and behavior of an AI model, <a href=\"https://thezvi.substack.com/p/claudes-constitutional-structure\">the first of my three posts on it is here</a>.</p>\n<p>Also, it seems he defines \u2018has a contract it signed and wants to honor\u2019 as \u2018override Congress and make his own rules to defy democratically decided laws.\u2019</p>\n<p>I presume Dario Amodei would be happy and honored to (once again) testify before Congress if he was called upon to do so.</p>\n<blockquote><p><a href=\"https://x.com/USWREMichael/status/2027220062914896208\">Under Secretary of War Emil Michael</a>: Respectfully @SenatorSlotkin that\u2019s exactly what was said. @DarioAmodei wants to override Congress and make his own rules to defy democratically decided laws. He is trying to re-write your laws by contract. Call @DarioAmodei to testify UNDER OATH!</p></blockquote>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!QLe5!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7f592d18-7e2f-48e7-925b-3069d29f217d_1042x1521.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>This is, needless to say, not how any of this works. The rhetoric makes no sense. It is no wonder many, <a href=\"https://x.com/krishnanrohit/status/2027238869662625985\">such as Krishnan Rohit here,</a> are confused.</p>\n<p><a href=\"https://x.com/USWREMichael/status/2027248323732623611\">There\u2019s also this</a>, which excerpts one section out of many of an old version of constitutional AI and claims they \u2018desperately tried to delete [it] from the internet.\u2019 This was part of a much longer list of considerations, included for balance and to help make Claude not say needlessly offensive things.</p>\n\n\n<h4 class=\"wp-block-heading\">Other Summaries and Notes</h4>\n\n\n<p><a href=\"https://www.theatlantic.com/newsletters/2026/02/anthropic-pentagon-ai-regulation/686169/?gift=6OqzMue7VHJqB9T1nUENqsVfU4OnhTIoRyrvVUMBbR8&amp;utm_source=copy-link&amp;utm_medium=social&amp;utm_campaign=share\">Will Gottsegen has one summary of key events so far at The Atlantic</a>.</p>\n<p><a href=\"https://www.bloomberg.com/news/articles/2026-02-27/the-cold-war-era-law-at-the-center-of-hegseth-s-anthropic-threat?taid=69a1d2be6a41fe0001bdb0dd&amp;utm_campaign=trueanthem&amp;utm_content=business&amp;utm_medium=social&amp;utm_source=twitter\">Bloomberg discusses potential use of the Defense Production Act.</a></p>\n<p>Alas, we may face many similar and worse conflicts and misunderstandings soon, and also this incident could have widespread negative implications on many fronts.</p>\n<blockquote><p><a href=\"https://x.com/deanwball/status/2027347343629238617\">Dean W. Ball</a>: What you are seeing btw is what happens when political leaders start to \u201cget serious\u201d about AI, and so you should expect to see more stuff like this, not less. Perhaps much more.</p>\n<p>A sub-point worth making here is that this affair may catalyze a wave of AGI pilling within the political leadership of China, and this has all sorts of serious implications which I invite you to think about carefully.</p>\n<p><a href=\"https://x.com/deanwball/status/2027375163717845012\">Dean W. Ball</a>: just ask yourself, what is the point of a contract to begin with? interrogate this with a good language model. we don\u2019t teach this sort of thing in school anymore very often, because of the shitlibification of all things. if you cannot contract, you do not own.</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">Paths Forward</h4>\n\n\n<p>The best path forward would be for everyone to continue to work together, while the two sides continue to talk, and if those talks cannot find a solution then doing an amicable wind down of the contract. Or, if it\u2019s clear there is no zone of possible agreement, starting to wind things down now.</p>\n<p>The second best path, if that has become impossible, would be to terminate the contract without a wind down, and accept the consequences.</p>\n<p>The third best path, if that too has become impossible for whatever reason, would be a narrowly tailored invocation of supply chain risk, that targets only the use of Claude API calls in actively deployed systems, or something similarly narrow in scope, designed to address the particular concern of the Pentagon.</p>\n<p>Going beyond that would be needlessly escalatory and destructive, and could go quite badly for all involved. I hope it does not come to that.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>"
            ],
            "link": "https://thezvi.wordpress.com/2026/02/27/anthropic-and-the-dow-anthropic-responds/",
            "publishedAt": "2026-02-27",
            "source": "TheZvi",
            "summary": "The Department of War gave Anthropic until 5:01pm on Friday the 27th to either give the Pentagon \u2018unfettered access\u2019 to Claude for \u2018all lawful uses,\u2019 or else. With the \u2018or else\u2019 being not the sensible \u2018okay we will cancel the &#8230; <a href=\"https://thezvi.wordpress.com/2026/02/27/anthropic-and-the-dow-anthropic-responds/\">Continue reading <span class=\"meta-nav\">&#8594;</span></a>",
            "title": "Anthropic and the DoW: Anthropic Responds"
        },
        {
            "content": [],
            "link": "https://xkcd.com/3213/",
            "publishedAt": "2026-02-27",
            "source": "XKCD",
            "summary": "<img alt=\"I mean, half of these are undefined. And your multiplication dots are too low; they look like decimal points.\" src=\"https://imgs.xkcd.com/comics/dental_formulas.png\" title=\"I mean, half of these are undefined. And your multiplication dots are too low; they look like decimal points.\" />",
            "title": "Dental Formulas"
        }
    ],
    "lookbackDays": 1,
    "publishDate": "2026-02-27"
}