{
    "articles": [
        {
            "content": [
                "<p><img alt=\"Happiness in Fast Tempo, by Walter Quirt\" src=\"https://www.dbreunig.com/img/fast_tempo.jpg\" /></p>\n\n<p>If you experiment with new tools and technologies, every so often you\u2019ll catch a glimpse of the future. Most of the time, tinkering is just that \u2014 fiddly, half-working experiments. But occasionally, something clicks, and you can see the shift coming.</p>\n\n<p>In the last two months, I\u2019ve experienced this twice while coding with AI. Over the next year, I expect AI-assisted coding to get <em>much faster</em> and <em>more concurrent</em>.</p>\n\n<hr />\n\n<h3 id=\"speed-changes-how-you-code\">Speed Changes How You Code</h3>\n\n<p>Last month, I embarked on an AI-assisted code safari. I tried different applications (Claude Code, Codex, Cursor, Cline, Amp, etc.) and different models (Opus, GPT-5, Qwen Coder, Kimi K2, etc.), trying to get a better lay of the land. I find it useful to take these macro views occasionally, time-boxing them explicitly, to build a mental model of the domain and to prevent me from getting rabbit-holed by tool selection during project work.</p>\n\n<p>The takeaway from this safari was that we are undervaluing speed.</p>\n\n<p>We talk constantly about model accuracy, their ability to reliably solve significant PRs, and their ability to solve bugs or dig themselves out of holes. Coupled with this conversation is the related discussion about what we do while an agent churns on a task. We sip coffee, catch up on our favorite shows, or <a href=\"https://mitchellh.com/writing/non-trivial-vibing\">make breakfast for our family</a> all while the agent chugs away. Others spin up <em>more</em> agents and attack multiple tasks at once, across a grid of terminal windows. Still others go full async, handing off Github issues to OpenAI\u2019s Codex, which works in the cloud by itself\u2026 often for hours.</p>\n\n<p>Using the largest, slowest model is a good idea when tackling a particularly sticky problem or when you\u2019re planning your initial approach, but a good chunk of coding can be handled by smaller, cheaper, <em>faster</em> models.</p>\n\n<p>How much faster? Let\u2019s take the extreme: Qwen 3 Coder 480B runs at <em>2,000 tokens/second</em> on <a href=\"https://www.cerebras.ai/blog/qwen3-coder-480b-is-live-on-cerebras\">Cerebras</a>. That\u2019s 30 times faster than Claude 4.5 Sonnet and 45 times faster than Claude Opus 4.1. It Qwen 3 Coder takes <em>4 seconds</em> to write 1,000 lines of JavaScript; Sonnet needs <em>2 minutes</em>.</p>\n\n<p>No one is arguing Qwen 3 Coder 480B is a more capable model than Sonnet 4.5 (except maybe Qwen and Cerebras\u2026 \ud83e\udd14). But at this speed, your workflow radically changes. I found myself chunking problems into smaller steps, chatting in near real-time with the model as code just appeared and was tested. There was no time for leaning back or sipping coffee. My hands never left the keyboard.</p>\n\n<p>At 30x speed, you experiment more. When the agent is slow there\u2019s a fear that holds you back from trying random things. You experiment less because having to wait a couple of minutes isn\u2019t worth the risk. But with Qwen 3, I found myself firing away with little hesitation, rolling back failures, and trying again.</p>\n\n<p>After Qwen 3, Claude feels like <em>molasses</em>. I still use it for big chunks of work, where I\u2019m fine letting it churn for a bit, but for scripting and frontend it\u2019s hard to give up Qwen\u2019s (or <a href=\"https://www.youtube.com/watch?v=uebFDyX3e98\">Kimi K2\u2019s</a>) speed. For tweaking UI \u2013\u2013 editing HTML and CSS \u2013 speed coupled with a hot-reloader is incredible.</p>\n\n<p>I recommend everyone give Qwen 3 Coder a try, <a href=\"https://inference-docs.cerebras.ai/integrations/cline\">especially the free-tier hosted on Cerebras and harnessed with Cline</a>. If only to see how your behavior adjusts with immediate feedback.</p>\n\n<hr />\n\n<h3 id=\"swarms-speed-up-slow-models-but-thrive-with-conventions\">Swarms Speed Up Slow Models (But Thrive with Conventions)</h3>\n\n<p>To mitigate slow models, many fire up more terminal windows.</p>\n\n<p>Peter Steinberger recently wrote about his usual setup, which illustrates this well:</p>\n\n<blockquote>\n  <p>I\u2019ve completely moved to codex cli as daily driver. I run between 3-8 in parallel in a 3x3 terminal grid, most of them in the same folder, some experiments go in separate folders. I experimented with worktrees, PRs but always revert back to this setup as it gets stuff done the fastest.</p>\n</blockquote>\n\n<p>The main challenge with multi-agent coding is handling Git conflicts. <a href=\"https://x.com/steipete/status/1977498385172050258\">Peter relies on atomic commits</a>, while others go further. Chris Van Pelt at Weights &amp; Biases built <a href=\"https://github.com/wandb/catnip\">catnip</a>, which uses containers to manage parallel agents. Tools like <a href=\"https://github.com/ruvnet/claude-flow\">claude-flow</a> and <a href=\"https://github.com/parruda/claude-swarm\">claude-swarm</a> use <a href=\"https://www.dbreunig.com/2025/06/26/how-to-fix-your-context.html\">context management tactics</a> like RAG, tool loadout, and context quarantining to orchestrate \u201cteams\u201d of specialist agents.</p>\n\n<p>Reading the previous list, we can see the appeal of Peter\u2019s simple approach: nailing down atomic commit behaviors lets him drop into any project and start working. The swarm framework approach requires setup, which can be worth it for major projects.</p>\n\n<p>However, what I\u2019m excited about is when we can build swarm frameworks for common environments. This reduces swarm setup time to near zero, while yielding significantly more effective agents. It\u2019s the agentic coding equivalent of \u201c<a href=\"https://en.wikipedia.org/wiki/Convention_over_configuration\">convention over configuration</a>\u201d, allowing us to pre-fill context for a swarm of agents.</p>\n\n<p>This pattern \u2014 using conventions to standardize how agents collaborate \u2014 naturally aligns with frameworks that already prize convention over configuration. Which brings us to Ruby on Rails.</p>\n\n<p><a href=\"https://x.com/obie\">Obie Fernandez</a> recently released a swarm framework for Rails, <a href=\"https://github.com/obie/claude-on-rails\">claude-on-rails</a>. It\u2019s a preconfigured <a href=\"https://github.com/parruda/claude-swarm\">claude-swarm</a> setup, coupled with an MCP server loaded with documentation matching to your project\u2019s dependencies.</p>\n\n<p>It works <em>extraordinarily</em> well.</p>\n\n<p>Like our experiments with the speedy Qwen 3, <a href=\"https://github.com/obie/claude-on-rails\">claude-on-rails</a> changes how you prompt. Since the swarm is preloaded with Rails-specific agents and documentation, you can provide <em>much</em> less detail when prompting. There\u2019s little need to specify implementation details or approaches. It just cracks on, assuming Rails conventions, and delivers an incredibly high batting average.</p>\n\n<p>To handle the dreaded Git conflicts, <a href=\"https://github.com/obie/claude-on-rails\">claude-on-rails</a> takes advantage of the standard Rails directory structure and isolates agents to specific folders.</p>\n\n<p>Here\u2019s a sample of how <a href=\"https://github.com/obie/claude-on-rails\">claude-on-rails</a> defines the roles in its <a href=\"https://github.com/parruda/claude-swarm\">swarm</a>:</p>\n\n<div class=\"language-yaml highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"na\">architect</span><span class=\"pi\">:</span>\n  <span class=\"na\">description</span><span class=\"pi\">:</span> <span class=\"s2\">\"</span><span class=\"s\">Rails</span><span class=\"nv\"> </span><span class=\"s\">architect</span><span class=\"nv\"> </span><span class=\"s\">coordinating</span><span class=\"nv\"> </span><span class=\"s\">full-stack</span><span class=\"nv\"> </span><span class=\"s\">development</span><span class=\"nv\"> </span><span class=\"s\">for</span><span class=\"nv\"> </span><span class=\"s\">DspyRunner\"</span>\n  <span class=\"na\">directory</span><span class=\"pi\">:</span> <span class=\"s\">.</span>\n  <span class=\"na\">model</span><span class=\"pi\">:</span> <span class=\"s\">opus</span>\n  <span class=\"na\">connections</span><span class=\"pi\">:</span> <span class=\"pi\">[</span><span class=\"nv\">models</span><span class=\"pi\">,</span> <span class=\"nv\">controllers</span><span class=\"pi\">,</span> <span class=\"nv\">views</span><span class=\"pi\">,</span> <span class=\"nv\">stimulus</span><span class=\"pi\">,</span> <span class=\"nv\">jobs</span><span class=\"pi\">,</span> <span class=\"nv\">tests</span><span class=\"pi\">,</span> <span class=\"nv\">devops</span><span class=\"pi\">]</span>\n  <span class=\"na\">prompt_file</span><span class=\"pi\">:</span> <span class=\"s\">.claude-on-rails/prompts/architect.md</span>\n  <span class=\"na\">vibe</span><span class=\"pi\">:</span> <span class=\"no\">true</span>\n<span class=\"na\">models</span><span class=\"pi\">:</span>\n  <span class=\"na\">description</span><span class=\"pi\">:</span> <span class=\"s2\">\"</span><span class=\"s\">ActiveRecord</span><span class=\"nv\"> </span><span class=\"s\">models,</span><span class=\"nv\"> </span><span class=\"s\">migrations,</span><span class=\"nv\"> </span><span class=\"s\">and</span><span class=\"nv\"> </span><span class=\"s\">database</span><span class=\"nv\"> </span><span class=\"s\">optimization</span><span class=\"nv\"> </span><span class=\"s\">specialist\"</span>\n  <span class=\"na\">directory</span><span class=\"pi\">:</span> <span class=\"s\">./app/models</span>\n  <span class=\"na\">model</span><span class=\"pi\">:</span> <span class=\"s\">sonnet</span>\n  <span class=\"na\">allowed_tools</span><span class=\"pi\">:</span> <span class=\"pi\">[</span><span class=\"nv\">Read</span><span class=\"pi\">,</span> <span class=\"nv\">Edit</span><span class=\"pi\">,</span> <span class=\"nv\">Write</span><span class=\"pi\">,</span> <span class=\"nv\">Bash</span><span class=\"pi\">,</span> <span class=\"nv\">Grep</span><span class=\"pi\">,</span> <span class=\"nv\">Glob</span><span class=\"pi\">,</span> <span class=\"nv\">LS</span><span class=\"pi\">]</span>\n  <span class=\"na\">prompt_file</span><span class=\"pi\">:</span> <span class=\"s\">.claude-on-rails/prompts/models.md</span>\n<span class=\"na\">views</span><span class=\"pi\">:</span>\n  <span class=\"na\">description</span><span class=\"pi\">:</span> <span class=\"s2\">\"</span><span class=\"s\">Rails</span><span class=\"nv\"> </span><span class=\"s\">views,</span><span class=\"nv\"> </span><span class=\"s\">layouts,</span><span class=\"nv\"> </span><span class=\"s\">partials,</span><span class=\"nv\"> </span><span class=\"s\">and</span><span class=\"nv\"> </span><span class=\"s\">asset</span><span class=\"nv\"> </span><span class=\"s\">pipeline</span><span class=\"nv\"> </span><span class=\"s\">specialist\"</span>\n  <span class=\"na\">directory</span><span class=\"pi\">:</span> <span class=\"s\">./app/views</span>\n  <span class=\"na\">model</span><span class=\"pi\">:</span> <span class=\"s\">sonnet</span>\n  <span class=\"na\">connections</span><span class=\"pi\">:</span> <span class=\"pi\">[</span><span class=\"nv\">stimulus</span><span class=\"pi\">]</span>\n  <span class=\"na\">allowed_tools</span><span class=\"pi\">:</span> <span class=\"pi\">[</span><span class=\"nv\">Read</span><span class=\"pi\">,</span> <span class=\"nv\">Edit</span><span class=\"pi\">,</span> <span class=\"nv\">Write</span><span class=\"pi\">,</span> <span class=\"nv\">Bash</span><span class=\"pi\">,</span> <span class=\"nv\">Grep</span><span class=\"pi\">,</span> <span class=\"nv\">Glob</span><span class=\"pi\">,</span> <span class=\"nv\">LS</span><span class=\"pi\">]</span>\n  <span class=\"na\">prompt_file</span><span class=\"pi\">:</span> <span class=\"s\">.claude-on-rails/prompts/views.md</span>\n</code></pre></div></div>\n\n<p>The <a href=\"https://github.com/parruda/claude-swarm\">claude-swarm</a> config lets you define each role\u2019s tool loadout, model, available directories, which other roles it can communicate with, and provide a custom prompt. Defining a swarm is a significant amount of work, but the conventions of Rails lets <a href=\"https://github.com/obie/claude-on-rails\">claude-on-rails</a> work effectively out-of-the-box. And since there\u2019s multiple instances of Claude running, you have less time for coffee or cooking.</p>\n\n<p>And installing <a href=\"https://github.com/obie/claude-on-rails\">claude-on-rails</a> is simple. Add it to your Gemfile, run <code class=\"language-plaintext highlighter-rouge\">bundle</code>, and set it up with <code class=\"language-plaintext highlighter-rouge\">rails generate claude_on_rails:swarm</code>.</p>\n\n<p>In the past I\u2019ve worried that LLM-powered coding agents will lock in certain frameworks and tools. The amount of Python content in each model\u2019s pre-training data and post-training tuning appeared an insurmountable advantage. How could a new web framework compete with React when every coding agent knows the React APIs by heart?</p>\n\n<p>But with significant harnesses, like <a href=\"https://github.com/obie/claude-on-rails\">claude-on-rails</a>, the playing field can get pretty even. I hope we see similar swarm projects for other frameworks, like Django, Next.js, or iOS.</p>\n\n<hr />\n\n<p>The conversation around AI-assisted coding has focused on accuracy benchmarks. But <em>speed</em> \u2014 and what speed enables \u2014 will soon take center stage. Being able to chat without waiting or spin up multi-agent swarms will unlock a new era of coding with AI. One with a more natural cadence, where code arrives almost as fast as thought.</p>\n\n<hr />\n\n<form action=\"https://buttondown.com/api/emails/embed-subscribe/dbreunig\" class=\"embeddable-buttondown-form\" method=\"post\" target=\"popupwindow\">\n  <label for=\"bd-email\">Enter your email to receive the occasional update.</label>\n  <div class=\"form-input\">\n    <input id=\"bd-email\" name=\"email\" type=\"email\" />\n    <input type=\"submit\" value=\"Subscribe\" />\n  </div>\n</form>"
            ],
            "link": "https://www.dbreunig.com/2025/10/20/speeds-and-swarms.html",
            "publishedAt": "2025-10-20",
            "source": "Drew Breunig",
            "summary": "When coding models are faster and concurrent, the distance between thought and code shrinks. You can preview this future by trying out Qwen 3 Coder on Cerebras or claude-on-rails.",
            "title": "Glimpses of the Future: Speed &amp; Swarms"
        },
        {
            "content": [],
            "link": "https://www.robinsloan.com/lab/kids/",
            "publishedAt": "2025-10-20",
            "source": "Robin Sloan",
            "summary": "<p>Children? Why so formal? <a href=\"https://www.robinsloan.com/lab/kids/\">Read here.</a></p>",
            "title": "The /Kids are alright"
        },
        {
            "content": [],
            "link": "https://www.robinsloan.com/lab/shape-of-creative-ideas/",
            "publishedAt": "2025-10-20",
            "source": "Robin Sloan",
            "summary": "<p>Maybe not what you think. <a href=\"https://www.robinsloan.com/lab/shape-of-creative-ideas/\">Read here.</a></p>",
            "title": "The shape of creative ideas"
        },
        {
            "content": [],
            "link": "https://simonwillison.net/2025/Oct/20/claude-code-for-web/#atom-entries",
            "publishedAt": "2025-10-20",
            "source": "Simon Willison",
            "summary": "<p>Anthropic launched Claude Code for web this morning. It's an <a href=\"https://simonwillison.net/tags/async-coding-agents/\">asynchronous coding agent</a> - their answer to OpenAI's <a href=\"https://simonwillison.net/2025/May/16/openai-codex/\">Codex Cloud</a> and <a href=\"https://simonwillison.net/2025/May/19/jules/\">Google's Jules</a>, and has a very similar shape. I had preview access over the weekend and I've already seen some very promising results from it.</p> <p>It's available online at <a href=\"https://claude.ai\">claude.ai/code</a> and shows up as a tab in the Claude iPhone app as well:</p> <p><img alt=\"Screenshot of Claude AI interface showing a conversation about updating a README file. The left sidebar shows &quot;Claude&quot; at the top, followed by navigation items: &quot;Chats&quot;, &quot;Projects&quot;, &quot;Artifacts&quot;, and &quot;Code&quot; (highlighted). Below that is &quot;Starred&quot; section listing several items with trash icons: &quot;LLM&quot;, &quot;Python app&quot;, &quot;Check my post&quot;, &quot;Artifacts&quot;, &quot;Summarize&quot;, and &quot;Alt text writer&quot;. The center panel shows a conversation list with items like &quot;In progress&quot;, &quot;Run System C&quot;, &quot;Idle&quot;, &quot;Update Rese&quot;, &quot;Run Matplotl&quot;, &quot;Run Marketin&quot;, &quot;WebAssembl&quot;, &quot;Benchmark M&quot;, &quot;Build URL Qu&quot;, and &quot;Add Read-Or&quot;. The right panel displays the active conversation titled &quot;Update Research Project README&quot; showing a task to update a GitHub README file at https://github.com/simonw/research/blob/main/deepseek-ocr-nvidia-spark/README.md, followed by Claude's response and command outputs showing file listings with timestamps from Oct 20 17:53.\" src=\"https://static.simonwillison.net/static/2025/claude-code-for-web.jpg\" /></p> <p>As far as I can",
            "title": "Claude Code for web - a new asynchronous coding agent from Anthropic"
        },
        {
            "content": [],
            "link": "https://simonwillison.net/2025/Oct/20/deepseek-ocr-claude-code/#atom-entries",
            "publishedAt": "2025-10-20",
            "source": "Simon Willison",
            "summary": "<p>DeepSeek released a new model yesterday: <a href=\"https://github.com/deepseek-ai/DeepSeek-OCR\">DeepSeek-OCR</a>, a 6.6GB model fine-tuned specifically for OCR. They released it as model weights that run using PyTorch and CUDA. I got it running on the NVIDIA Spark by having Claude Code effectively brute force the challenge of getting it working on that particular hardware.</p> <p>This small project (40 minutes this morning, most of which was Claude Code churning away while I had breakfast and did some other things) ties together a bunch of different concepts I've been exploring recently. I <a href=\"https://simonwillison.net/2025/Sep/30/designing-agentic-loops/\">designed an agentic loop</a> for the problem, gave Claude full permissions inside a Docker sandbox, embraced the <a href=\"https://simonwillison.net/2025/Oct/5/parallel-coding-agents/\">parallel agents lifestyle</a> and reused my <a href=\"https://simonwillison.net/2025/Oct/14/nvidia-dgx-spark/\">notes on the NVIDIA Spark</a> from last week.</p> <p>I knew getting a PyTorch CUDA model running on the Spark was going to be a little frustrating, so I decided to outsource the entire process to Claude Code to see what would happen.</p> <p>TLDR: It worked. It took four prompts (one long, three very short) to have Claude Code figure out everything necessary to run the new DeepSeek model on the NVIDIA Spark, OCR a document for me and produce <em>copious</em> notes about the process.</p> <h4 id=\"the-setup\">The",
            "title": "Getting DeepSeek-OCR working on an NVIDIA Spark via brute force using Claude Code"
        },
        {
            "content": [
                "<p>This is the weekly visible open thread. Post about anything you want, ask random questions, whatever. ACX has an unofficial <a href=\"https://www.reddit.com/r/slatestarcodex/\">subreddit</a>, <a href=\"https://discord.gg/RTKtdut\">Discord</a>, and <a href=\"https://www.datasecretslox.com/index.php\">bulletin board</a>, and <a href=\"https://www.lesswrong.com/community?filters%5B0%5D=SSC\">in-person meetups around the world</a>. Most content is free, some is subscriber only; you can subscribe <strong><a href=\"https://astralcodexten.substack.com/subscribe\">here</a></strong>. Also:</p><div><hr /></div><p><strong>1: </strong>Meetups this week include Leipzig, Newark, Copenhagen, Hong Kong, Toronto - see <a href=\"https://www.astralcodexten.com/p/meetups-everywhere-2025-times-and\">the meetup post</a> for more information.</p><p><strong>2: </strong>All nonbook review prizes should be taken care of - people who earned subscriptions should have them, people who earned money should have gotten emails asking how I should send it to them. If this isn&#8217;t true, email or otherwise contact me.</p><p><strong>3: </strong>I&#8217;m still working with Manifund on getting money to grantees, expect an email about this soon.</p><p><strong>4: </strong>I&#8217;m now using my Substack recommendations tab to highlight contest winners&#8217; Substacks. That means I&#8217;ve removed all previous recommendations. If that was you, sorry - I still like your Substacks and will link to them when you make posts I like; I just want to make room to promote up-and-coming bloggers.</p><p><strong>5: </strong>Advertisement: Free in-person AI futures conference in London on November 2 (the organizers told me to call it an &#8220;unconference&#8221;, but I have never been able to figure out a difference, and refuse to cooperate in the use of this word). <a href=\"https://wetwarecraft.substack.com/p/flourish-human-ai-an-in-person-unconference\">See here</a> for more info and RSVP instructions.</p><p><strong>6: </strong>Advertisement: 2024 ACX grantee Alexander Putilin working on the EEG entrainment study replication is looking for study volunteers in London. He says:</p><blockquote><p>The study <a href=\"https://pmc.ncbi.nlm.nih.gov/articles/PMC10152088/\">&#8220;Learning at your brain&#8217;s rhythm: individualized entrainment boosts learning for perceptual decisions&#8221;</a> claims that entrainment (flashing a bright white light) at a person&#8217;s individual peak alpha frequency helps them learn to distinguish between two types of patterns faster.</p><p>I&#8217;m replicating this study &amp; I&#8217;ve collected data from 5 participants. I&#8217;m looking for 5 more volunteers in London to dedicate four hours of their time (split into two two-hour chunks) willing to experience some perceptual learning while providing their brainwave data. To see what it&#8217;s like, watch <a href=\"https://www.youtube.com/watch?v=pP5dO97l9Bo\">this short video of the demo</a>. To participate, <a href=\"https://forms.gle/X37zyTV3KhbSb3Ze9\">fill in the form</a> &#8212; I&#8217;d greatly appreciate your help. More information about the project is in the form description.</p><p>The code for the project is <a href=\"https://psychotechnology.substack.com/\">available on Github</a>. The results will be published on my <a href=\"https://psychotechnology.substack.com/\">psychotechnology</a> Substack.</p></blockquote>"
            ],
            "link": "https://www.astralcodexten.com/p/open-thread-404",
            "publishedAt": "2025-10-20",
            "source": "SlateStarCodex",
            "summary": "<p>This is the weekly visible open thread. Post about anything you want, ask random questions, whatever. ACX has an unofficial <a href=\"https://www.reddit.com/r/slatestarcodex/\">subreddit</a>, <a href=\"https://discord.gg/RTKtdut\">Discord</a>, and <a href=\"https://www.datasecretslox.com/index.php\">bulletin board</a>, and <a href=\"https://www.lesswrong.com/community?filters%5B0%5D=SSC\">in-person meetups around the world</a>. Most content is free, some is subscriber only; you can subscribe <strong><a href=\"https://astralcodexten.substack.com/subscribe\">here</a></strong>. Also:</p><div><hr /></div><p><strong>1: </strong>Meetups this week include Leipzig, Newark, Copenhagen, Hong Kong, Toronto - see <a href=\"https://www.astralcodexten.com/p/meetups-everywhere-2025-times-and\">the meetup post</a> for more information.</p><p><strong>2: </strong>All nonbook review prizes should be taken care of - people who earned subscriptions should have them, people who earned money should have gotten emails asking how I should send it to them. If this isn&#8217;t true, email or otherwise contact me.</p><p><strong>3: </strong>I&#8217;m still working with Manifund on getting money to grantees, expect an email about this soon.</p><p><strong>4: </strong>I&#8217;m now using my Substack recommendations tab to highlight contest winners&#8217; Substacks. That means I&#8217;ve removed all previous recommendations. If that was you, sorry - I still like your Substacks and will link to them when you make posts I like; I just want to make room to promote up-and-coming bloggers.</p><p><strong>5: </strong>Advertisement: Free in-person AI futures conference in London on November 2 (the organizers told me to call it an &#8220;unconference&#8221;, but I",
            "title": "Open Thread 404"
        },
        {
            "content": [
                "<p>We have the classic phenomenon where suddenly everyone decided it is good for your social status to say we are in an \u2018AI bubble.\u2019</p>\n<p>Are these people short the market? Do not be silly. The conventional wisdom response to that question these days is that, as was said in 2007, \u2018if the music is playing you have to keep dancing.\u2019</p>\n<p>So even with lots of people newly thinking there is a bubble the market has not moved down, other than (modestly) on actual news items, usually related to another potential round of tariffs, or that one time we had a false alarm during the <a href=\"https://thezvi.substack.com/p/deepseek-r1-0528-did-not-have-a-moment\">DeepSeek Moment</a>.</p>\n<div>\n\n\n<span id=\"more-24802\"></span>\n\n\n</div>\n<p>So, what\u2019s the case we\u2019re in a bubble? What\u2019s the case we\u2019re not?</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!oVce!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcdc4c135-45ea-4b4a-9e1b-e286972790c0_1024x1024.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n\n\n<h4 class=\"wp-block-heading\">My Answer In Brief</h4>\n\n\n<p>People get confused about bubbles, often applying that label any time prices fall. So you have to be clear on what question is being asked.</p>\n<p>If \u2018that was a bubble\u2019 simply means \u2018number go down\u2019 then it is entirely uninteresting to say things are bubbles.</p>\n<p>So if we operationalize \u2018bubble\u2019 simply means that at some point there is a substantial drawdown in market values (e.g. a 20% drop in the Nasdaq sustained for 6 months) then I would be surprised by this, but the market would need to be dramatically, crazily underpriced for that not to be a plausible thing to happen.</p>\n<p>If a bubble means something similar to the 2000 dot com bubble, as in valuations that are not plausible expectations for the net present values of future cash flows? No.</p>\n<p>[Standard disclaimer: Nothing on this blog is ever investment advice.]</p>\n<p>Before I dive into the details, a time sensitive point of order, that you can skip if you would not consider political donations:</p>\n\n\n<h4 class=\"wp-block-heading\">Time Sensitive Point of Order: Alex Bores Launches Campaign For Congress, If You Care About AI Existential Risk Consider Donating</h4>\n\n\n<p>When trying to pass laws, it is vital to have a champion. You need someone in each chamber of Congress who is willing to help craft, introduce and actively fight for good bills. Many worthwhile bills do not get advanced because no one will champion them.</p>\n<p>Alex Bores did this with New York\u2019s RAISE Act, an AI safety bill along similar lines to SB 53 that is currently on the governor\u2019s desk. <a href=\"https://www.lesswrong.com/posts/dceyoApFTEsaeTByd/rtfb-the-raise-act\">I did a full RTFB (read the bill) on it</a>, and found it to be a very good bill that I strongly supported. It would not have happened without him championing the bill and spending political capital on it.</p>\n<p>By far the strongest argument against the bill is that it would be better if such bills were done on the Federal level.</p>\n<p><a href=\"https://www.nytimes.com/2025/10/20/nyregion/alex-bores-ny-congress-primary.html\">He\u2019s trying to address this by running for Congress</a> in my own distinct, NY-12, to succeed Jerry Nadler. The district is deeply Democratic, so this will have no impact on the partisan balance. What it would do is give real AI safety a knowledgeable champion in the House of Representatives, capable of championing good bills.</p>\n<p><a href=\"https://ericneyman.wordpress.com/2025/10/20/consider-donating-to-alex-bores-author-of-the-raise-act/\">Eric Nayman makes an extensive case for considering donating to Alex Bores today</a>, in his first 24 hours, as donations in the first 24 hours are extremely valuable. Sonnet 4.5 estimates that in this case, a donation on day one is worth about double what it would be worth later. If you do decide to donate, <a href=\"https://secure.actblue.com/donate/boresai?refcode=uv\">they prefer that you use this link</a> to ensure the donation gets fully registered today.</p>\n<p>As always, remember while considering this that political donations are public.</p>\n<p>(Note: I intend to remove this announcement from this post after the 24 hour window closes, and move it to AI #139.)</p>\n\n\n<h4 class=\"wp-block-heading\">So They\u2019re Saying There\u2019s a Bubble</h4>\n\n\n<blockquote><p>Sagarika Jaisinghani (Bloomberg): A record share of global fund managers said artificial intelligence stocks are in a bubble following a torrid rally this year, according to a survey by Bank of America Corp.</p>\n<p>About 54% of participants in the October poll indicated tech stocks were looking too expensive, an about-turn from last month when nearly half had dismissed those concerns. Fears that global stocks were overvalued also hit a peak in the latest survey.</p></blockquote>\n<p>So a month ago things most people thought things were fine and now it\u2019s a bubble?</p>\n<p>This is a very light bubble definition, as these things go.</p>\n<p>Nothing importantly bearish happened in that month other than bullish deals, so presumably this is a \u2018circular deals freak us out\u2019 shift in mood? Or it could be a cascade effect.</p>\n\n\n<h4 class=\"wp-block-heading\">AI Is Atlas And People Worry It Might Shrug</h4>\n\n\n<p>There is definitely reason for concern. If you remove the label \u2018bubble\u2019 and simply say \u2018AI\u2019 then the quote from Deutsche Bank below is correct, as AI is responsible for essentially all economic growth. Also you can mostly replace \u2018US\u2019 with \u2018world.\u2019</p>\n<blockquote><p><a href=\"https://x.com/tszzl/status/1976342078985793619\">Unusual Whales</a>: \u201cThe AI bubble is the only thing keeping the US economy together,\u201d Deutsche Bank has said per TechSpot.</p></blockquote>\n<p>&nbsp;</p>\n\n\n<h4 class=\"wp-block-heading\">Can A Bubble Be Common Knowledge?</h4>\n\n\n<p>Not quite, at this size you need some doubt involved. But the basic answer is yes.</p>\n<blockquote><p>Roon: one reason to disbelief in a sizeable bubble is when the largest financial institutions in the world are openly calling it that.</p>\n<p>Jon Stokes: I disagree. I was in my early 20\u2019s during the dotcom bubble and was in tech, and everyone everywhere knew it was a bubble &#8212; from the banks to the VCs down to the individual programmers in SF. Everyone talked about it openly in the last ~1yr of it, but the numbers kept going up.</p>\n<p>I don\u2019t think this is Dotcom 2.0 but I think it\u2019s possible the market is getting ahead of itself. That said, I also lived through the cloud \u201cbubble\u201d which turned out to not be a bubble at all &#8212; I even wrote my own contributes to \u201care we in a bubble?\u201d literature in like 2012. Anyone who actually traded on the idea that the cloud buildout was a bubble lost out bigtime.</p>\n<p>Every time there\u2019s a big new infra buildout there\u2019s bubble talk.</p>\n<p>My point is that is very possible to have a bubble that everyone everywhere knows is a bubble, yet it keeps on bubbling because nobody wants to miss the action &amp; everyone thinks they can time an exit. \u201cEnjoy the party, but dance close to the exits\u201d was the slogan back then.</p></blockquote>\n<p>It is definitely possible to get into an <a href=\"https://thezvi.substack.com/p/everybody-knows\">Everybody Knows</a> situation with a bubble, for various reasons, both when it is and when it isn\u2019t actually a bubble. For example, there\u2019s Bitcoin, and Bitcoin, and Bitcoin, and Bitcoin, but there\u2019s also Bitcoin.</p>\n<p>Is it evidence for or against a bubble when everyone says it\u2019s a bubble?</p>\n<p>My gut answer is it depends on who is everyone.</p>\n<p>If everyone is everyone working in the industry? Then yeah, evidence for a bubble.</p>\n<p>If everyone is everyone at the major economic institutions? Not so much.</p>\n<p>So I decided to check.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!kfP3!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F11f676ba-734f-40a7-a2b6-1b0bf312e089_1053x544.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>There was essentially no correlation, with 42.5% of AI workers and 41.7% of others saying there is a bubble, and that\u2019s a large percentage, so things are certainly somewhat concerning. It certainly seems likely that certain subtypes of AI investment are \u2018in a bubble\u2019 in the sense that investors in those subtypes will lose money, which you would expect in anything like an efficient market.</p>\n\n\n<h4 class=\"wp-block-heading\">Steamrollers, Picks and Shovels</h4>\n\n\n<p>In particular, consensus seems to be, and I agree with it (reminder: not investment advice), that investment in \u2018companies with products in position to get steamrolled by OpenAI and other frontier labs\u2019 are as a group not going to do well. If you want to call that an \u2018AI bubble\u2019 you can, but that seems net misleading. I also wouldn\u2019t be excited to short that basket, since you\u2019re exposed if even one of them hits it big. Remember that if you bought a tech stock portfolio at the dot com peak, you still got Amazon.</p>\n<p>Whereas if you had a portfolio of \u2018picks and shovels\u2019 or of the frontier labs themselves, that still seems to me like a fine place to bet, although it is no longer a \u2018I can\u2019t believe they\u2019re letting me buy at these prices, this is free money\u2019 level of fine. You now have to actually have beliefs about the future and an investment thesis.</p>\n\n\n<h4 class=\"wp-block-heading\">What Can Go Up Must Sometimes Go Down</h4>\n\n\n<p>Noah Smith speculates on bubble causes and types when it comes to AI.</p>\n<blockquote><p><a href=\"https://x.com/Noahpinion/status/1977357836825837572\">Noah Smith</a>: An AI crash isn\u2019t certain, but I think it\u2019s more likely than people think.</p>\n<p><a href=\"https://www.noahpinion.blog/p/americas-future-could-hinge-on-whether\">Looking at the historical examples of railroads</a>, electricity, dotcoms, and housing can help us understand what an AI crash would look like.</p>\n<p>A burning question that\u2019s on a lot of people\u2019s minds right now is: Why is the U.S. economy still holding up? The manufacturing industry is <a href=\"https://www.cbc.ca/news/business/trade-trump-carney-meeting-tariffs-1.7652580\">hurting badly</a> from Trump\u2019s tariffs, the payroll numbers <a href=\"https://www.cnn.com/2025/10/01/economy/adp-private-jobs-report-september\">are looking weak</a>, and consumer sentiment is at Great Recession levels.</p>\n<p>\u2026 Another possibility is that tariffs are bad, but are being canceled out by an even more powerful force \u2014 the AI boom.</p></blockquote>\n<p>You could have a speculative bubble, or an extrapolative bubble, or simply a big mistake about the value of the tech. He thinks if it is a bubble it would be of the later type, proposing we use Bezos\u2019 term \u2018industrial bubble.\u2019</p>\n<blockquote><p>Noah Smith: \u2026 When we look at the history of industrial bubbles, and of new technologies in general, it becomes clear that in order to cause a crash, AI doesn\u2019t have to fail. It just has to mildly disappoint the most ardent optimists.</p></blockquote>\n<p>I don\u2019t think that\u2019s quite right. The market reflects a variety of perspectives, and it will almost always be way below where the ardent optimists would place it. The ardent optimists are the rock with the word \u2018BUY!\u2019 written on it.</p>\n<p>What is right is that if AI over some time frame disappoints relative to expectations, sufficiently to shift forward expectations downward from their previous level, that would cause a substantial drop in prices, which could then break momentum and worsen various positions, causing a larger drop in prices.</p>\n<p>Thus, we could have AI ultimately having a huge economic impact and ultimately being fully transformative (maybe killing everyone, maybe being amazingly great), and have nothing go that wrong along the way, but still have what people at the time would call \u2018the bubble bursting.\u2019</p>\n\n\n<h4 class=\"wp-block-heading\">What Can Go Up Quite A Lot Can Go Even More Down</h4>\n\n\n<p>Indeed, if the market is at all efficient, there is a lot of \u2018upside risk\u2019 of AI being way more impactful than suggested by the market price, which means there has to be a corresponding downside risk too. Part of that risk is geopolitical, an anti-AI movement could rise, or the supply chain could be disrupted by tariff battles or a war over Taiwan. By traditional definitions of \u2018bubble,\u2019 that means a potential bubble.</p>\n<blockquote><p><a href=\"https://x.com/emollick/status/1977977082744279420\">Ethan Mollick</a>: I don\u2019t have much to add to the bubble discussion, but the \u201cthis time is different\u201d argument is, in part, based on the sincere belief of many at the AI labs that there is a race to superintelligence &amp; the winner gets,.. everything.</p>\n<p>It is a key dynamic that is not discussed much.</p>\n<p>You don\u2019t have to believe it (or think this is a good idea), but many of the AI insiders really do. Their public statements are not much different than their private ones. Without considering that zero sum dimension, a lot of what is happening in the space makes less sense.</p></blockquote>\n<p>Even a small chance of a big upside should mean a big boost to valuation. Indeed that is the reason tech startups are funded and venture capital firms exist. If you don\u2019t get the fully transformational level of impact, then at some point value will drop.</p>\n<p>Consider the parallel to Bitcoin, and in thinking there is some small percentage chance of becoming \u2018digital gold\u2019 or even the new money. If you felt there was no way it could fall by a lot from any given point in time, or even if you were simply confident that it was probably not going to crash, it would be a fantastic screaming buy.</p>\n\n\n<h4 class=\"wp-block-heading\">Step Two Remains Important</h4>\n\n\n<p>AI also has to retain expectations that providers will be profitable. If AI is useful but it is expected to not provide enough profits, that too can burst the bubble.</p>\n<blockquote><p><a href=\"https://x.com/mattyglesias/status/1977494095225410007\">Matthew Yglesias</a>: Key point in here from @Noahpinion \u2014 even if the AI tech turns out to be exactly as promising as the bulls think, it\u2019s not totally clear whether this would mean high margin businesses.</p>\n<p>A slightly random example but passenger jetliners have definitely worked out as a technology, tons of people use them and they are integral to the whole world economy. But the combined market cap of Boeing + Airbus is unimpressive.</p>\n<p>Jetliners seem a lot more important and impressive than the idea of a big box building supply store, but in terms of market cap Home Depot &gt; Boeing + Airbus. Technology is hard but then business is also hard.</p>\n<p><a href=\"https://x.com/sdamico/status/1977596861860233569\">Sam D\u2019Amico</a>: AI is going to rock but we may have a near-term capex bubble like the fiber buildout during the dotcom boom.</p></blockquote>\n<p><a href=\"https://www.slowboring.com/p/the-ai-boom-is-propping-up-the-whole\">Matthew Yglesias writes more thoughts here</a>, noting that AI is propping up the whole economy and offering reasons some people believe there\u2019s a bubble and also reasons it likely isn\u2019t one, and especially isn\u2019t one in the pure bubble sense of cryptocurrency or Beanie babies, there\u2019s clearly a there there.</p>\n<p>To say confidently that there is no bubble in AI is to claim, among other things, that the market is horribly inefficient, and that AI assets are and will remain dramatically underpriced but reliably gain value as people gain <a href=\"https://thezvi.substack.com/p/the-leopold-model-analysis-and-reactions\">situational awareness</a> and are mugged by reality. This includes the requirement that the currently trading AI assets will be poised to capture a lot of value.</p>\n\n\n<h4 class=\"wp-block-heading\">Oops We Might Do It Again</h4>\n\n\n<p>Alternatively, how about the possibility that there could be a crash for no reason?</p>\n<blockquote><p>Simeon: Agreed with Noah here. People underestimate the odds of a crash, and things like the OA x AMD deal make such things more likely. It just takes a sufficient number of people to be scared at the same time.</p>\n<p>Remember the market reaction to DeepSeek? It can be irrational.</p></blockquote>\n<p>The <a href=\"https://thezvi.substack.com/p/deepseek-r1-0528-did-not-have-a-moment\">DeepSeek moment</a> is sobering, since the AI market was down quite a lot on news that should have been priced in and if anything should have made prices go up. What is to stop a similar incorrect information cascade from happening again? Other than a potential \u2018Trump put\u2019 or Fed put, very little.</p>\n\n\n<h4 class=\"wp-block-heading\">Derek Thompson Breaks Down The Arguments</h4>\n\n\n<p>Derek Thompson provides his best counterargument, saying AI probably isn\u2019t a bubble. He also <a href=\"https://podcasts.apple.com/us/podcast/everybody-thinks-ai-is-a-bubble-what-if-theyre-wrong/id1594471023?i=1000732281640\">did an episode on this for the Plain English podcast</a> with Azeem Azhar of Exponential View to balance his <a href=\"https://podcasts.apple.com/us/podcast/this-is-how-the-ai-bubble-could-burst/id1594471023?i=1000728026459\">previous episode from September 23 on \u2018how the AI bubble could burst.</a>\u2019</p>\n<blockquote><p><a href=\"https://www.derekthompson.org/p/why-ai-is-not-a-bubble\">Derek Thompson</a>: And yet, look around: Is <em>anybody</em> actually acting as if AI is a bubble?</p>\n<p>\u2026 Everyone claims that they know the music is ending soon, and yet everybody is still dancing along to the music.</p></blockquote>\n<p>Well, yeah, when there\u2019s a bubble everyone goes around saying \u2018there\u2019s a bubble\u2019 but no one does anything about it, until they do and then there\u2019s no bubble?</p>\n<p>As Tyler Cowen sometimes asks, are you short the market? Me neither.</p>\n<p>Derek breaks down the top arguments for a bubble.</p>\n<blockquote>\n<ol>\n<li>Lofty valuations for companies with no clear path to profit.</li>\n<li>Unprecedented spending on an unproven business.</li>\n<li>A historic chasm between capex spending and revenue.</li>\n<li>An eerie level of financial opacity.</li>\n<li>A byzantine level of corporate entanglement.</li>\n</ol>\n</blockquote>\n<p>A lot of overlap here. We have a lot of money being invested in and spent on AI, without much revenue. True that. The AI companies all invest in and buy from each other, at a level that yeah is somewhat suspicious. Yeah, fair. The chips are only being discounted on five year horizons and that seems a bit long? Eh, that seems fine to me, older chips are still useful as long as demand exceeds supply.</p>\n<p>So why not a bubble? That part is gated, <a href=\"https://x.com/DKThomp/status/1978482238229561816\">but his thread lays out the cor</a>e responses. One, the AI companies look nothing like the joke companies in the dot com bubble.</p>\n\n\n<h4 class=\"wp-block-heading\">AI Revenues Are Probably Going To Go Up A Lot</h4>\n\n\n<p>Two, the AI companies need AI revenues to grow 100%-200% a year, and that sounds like a lot, but so far you\u2019re seeing even more than that.</p>\n<blockquote><p>Epoch AI: One way bubbles pop: a technology doesn\u2019t deliver value as quickly as investors bet it will. In light of that, it\u2019s notable that <a href=\"https://epoch.ai/gradient-updates/openai-is-projecting-unprecedented-revenue-growth\">OpenAI is projecting historically unprecedented revenue growth \u2014 from $10B to $100B </a>\u2014 over the next three years.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!pbkQ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffcad6463-b346-4b78-882f-d1c504c07796_1025x1280.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>OpenAI\u2019s revenue growth has been extremely impressive: from &lt;$1B to &gt;$10B in only three years. Still, a few other companies have pulled off similar growth.</p>\n<p>We found four such US companies in the past fifty years. Of these, only Google went on to top $100B in revenue.</p>\n<p><a href=\"https://x.com/peterwildeford/status/1978563530342162491\">Peter Wildeford</a>: OpenAI is claiming they will double revenue three years in a row&#8230; this is historically unprecedented, but may be possible (so far they are 3x/year and NVIDIA has done 2x/yr lately)</p>\n<p>But OpenAI has also projected revenue of $100B in 2028. We found seven companies which achieved revenue growth from $10B to $100B in under a decade.</p>\n<p>None of them did it in six years, let alone three.</p></blockquote>\n<p><a href=\"https://www.bloomberg.com/opinion/newsletters/2025-10-15/openai-has-a-business-plan\">As Matt Levine says, OpenAI has a business model</a> now, because when you need debt investors you need to have a business plan. This one strikes a balance between \u2018good enough to raise money\u2019 and \u2018not so good no one will believe it.\u2019 Which makes it well under where I expect their revenue to land.</p>\n<p>Frankly, OpenAI is downplaying their expectations because if they used their actual projections then no one would believe them, and they might get sued if things didn\u2019t work out. The baseline scenario is that OpenAI (and Anthropic) blow the projections out of the water.</p>\n<blockquote><p><a href=\"https://x.com/marthagimbel/status/1978483002318651552\">Martha Gimbel</a>: Ok not the main point of [Thompson\u2019s] article but I love this line: \u201cThe whole thing is vaguely Augustinian: O Lord, make me sell my Nvidia position and rebalance toward consumer staples, but not yet.\u201d</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">True Costs That Matter Are Absolute Not Relative</h4>\n\n\n<p><a href=\"https://x.com/binarybits/status/1978485348112965811\">Timothy Lee thinks it\u2019s probably \u2018not a bubble yet,\u2019</a> partly citing Thompson and partly because we are seeing differentiation on which models do tasks best. He also links to the worry that there might be no moat, as fast follows offer the same service much cheaper and kill your margin, since your product might be only slightly better.</p>\n<p>The thing about AI is that it might in total cost a lot, but in exchange you get a ton. It doesn\u2019t have to be ten times better to have the difference be a big deal. For most use cases of AI, you would be wise to pay twice the price for something 10% better, and often wise to pay 10 or 100 times as much. Always think absolute cost, not relative.</p>\n\n\n<h4 class=\"wp-block-heading\">We Are Spending a Lot But Also Not a Lot</h4>\n\n\n<blockquote><p>Vinay Sridhar: What finally caught my attention was this stat from an <a href=\"https://www.nytimes.com/2025/10/06/opinion/ai-growth-economy-jobs-tariffs.html\">NYT article by Natasha Sarin</a> (via Marginal Revolution): <em>\u201cTo provide some sense of scale, that means the equivalent of about $1,800 per person in America will be invested this year on AI\u201d</em>. That is a <strong>bucketload</strong> of spending.</p></blockquote>\n<p>It is, but is it? I spend more than that on one of my AI subscriptions, and get many times that much value in return. Thinking purely in terms of present day concrete benefits, when I ask \u2018how many different use cases of AI are providing me $1,800 in value?\u2019 I can definitely include taxes and accounting, product evaluation and search, medical help, analysis of research papers, coding and general information and search. So that\u2019s at least six.</p>\n<p>Similarly, does this sound like a problem, given the profit margins of these companies?</p>\n<blockquote><p>Vinay Sridhar: Hyperscalers (Microsoft, Amazon, Alphabet and Meta) historically ran capex at 11-16% of revenue. Today they\u2019re at 22%, with revenue YoY growth in the 15-25% range (ex Nvidia) &#8211; capex spending is dramatically outpacing revenue growth. The four major hyperscalers are spending approximately $320 billion combined on AI infrastructure in 2025 &#8211; with public statements on how <a href=\"https://www.reuters.com/business/zuckerberg-says-meta-will-invest-hundreds-billions-superintelligence-2025-07-14/\">this will likely continue in the coming years.</a></p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">Valuations Are High But Not Super High</h4>\n\n\n<p>Similarly, Vinay notes that the valuations are only somewhat high.</p>\n<blockquote><p>Current valuations, while elevated, remain \u201cmuch lower\u201d than prior tech bubbles. The Nasdaq\u2019s forward P/E ratio is ~28X today. At the 2000 peak, it exceeded 70X. Even in 2007 before the financial crisis, tech valuations were higher relative to earnings than they are now.</p>\n<p>Looking more closely, the MAG7 \u2014 who are spending the majority of this capex \u2014 has a blended P/E of ~32X \u2014 expensive, as Coatue\u2019s Laffont brothers <a href=\"https://open.spotify.com/episode/7h8ctH9qH746Dj20h0QDIx?si=93ac6695e4f84c46\">said in June</a>, but not extreme relative to past tech bubbles.</p></blockquote>\n<p>That\u2019s a P/E ratio, and all this extra capex spending if anything reduces short term earnings. Does a 28x forward P/E ratio sound scary in context, with YoY growth in the 20% range? It doesn\u2019t to me. Sure, there\u2019s some downside, but it would be a dramatic inefficiency if there wasn\u2019t.</p>\n<p><a href=\"https://vinaysridhar.com/ai-capital-markets-reflections.html\">Vinay offers several other notes as well.</a></p>\n\n\n<h4 class=\"wp-block-heading\">Official GPU Depreciation Schedules Seem Pretty Reasonable To Me</h4>\n\n\n<p>One thing I find confusing is all the \u2018look how fast the chips will lose value\u2019 arguments. Here\u2019s Vinay\u2019s supremely confident claims, as another example of this:</p>\n<blockquote><p>Vinay Sridhar: <strong>7. GPU Depreciation Schedules Don\u2019t Match Reality</strong></p>\n<p>Nvidia now unveils a new AI chip every year instead of every two years. Jensen Huang said in March that <em>\u201cwhen Blackwell starts shipping in volume you couldn\u2019t give Hoppers away\u201d</em>.</p>\n<p>Meanwhile, companies keep extending depreciation schedules. Microsoft: 4 to 6 years (2022). Alphabet: 4 to 6 years (2023). Amazon and Oracle: 5 to 6 years (2024). Meta: 5 to 5.5 years (January 2025). Amazon partially reversed course in January 2025, moving some assets back to 5 years, noting this would cut operating profit by $700m.</p>\n<p><a href=\"https://www.economist.com/business/2025/09/18/the-4trn-accounting-puzzle-at-the-heart-of-the-ai-cloud\">The Economist</a> analyzed the impact: if servers depreciate over 3 years instead of current schedules, the AI big five\u2019s combined annual pre-tax profit falls by $26bn (8% of last year\u2019s total). Over 2 years: $1.6trn market cap hit. If you take Huang literally at 1 year, this implies $4trn, one-third of their collective worth. Barclays estimated higher depreciation costs would shave 5-10% from earnings per share.</p></blockquote>\n<p>Hedgie takes a similar angle, <a href=\"https://x.com/HedgieMarkets/status/1977807297759023375\">calling the economics unsustainable</a> because the lifespan of data center components is only 3-10 years due to rapid technological advances.</p>\n<blockquote><p>Hedgie: Kupperman originally assumed data center components would depreciate over 10 years, but learned from two dozen senior professionals that the actual lifespan is just 3-10 years due to rapid technology advances. His revised calculations show the industry needs $320-480 billion in revenue just to break even on 2025 data center spending alone. Current AI revenue sits around $20 billion annually.</p>\n<p>What strikes me most is that none of the senior data center professionals Kupperman spoke with understand how the financial math works either.</p></blockquote>\n<p>No one I have seen is saying that chip capability improvements are accelerating dramatically. If that is the case we need to update our timelines.</p>\n<p>When Nvidia releases a new chip every year, that doesn\u2019t mean they do the 2027 chip in 2026 and then do the 2029 chip in 2027. It means they do the 2027 chip in 2027, and before that do the best chip you can do in 2026, and it also means Nvidia is good at marketing and life is coming at them fast.</p>\n<p>Huang\u2019s statement about free hoppers is obviously deeply silly, and everyone knows not to take such Nvidia statements seriously or literally. The existence of new better chips does not invalidate older worse chips unless supply exceeds demand by enough that the old chips cost more to run then the value they bring.</p>\n<p>That\u2019s very obviously not going to happen over three years let alone one or two. You can do math on the production capacity available.</p>\n<p>If the marginal cost of hoppers in 2028 was going to be approximately zero, what does that imply?</p>\n<p>By default? Stop thinking about capex depreciation and start thinking about whether this means we get a singularity in 2028, since you can now scale compute as long as you have power. Also, get long China, since they have unlimited power generation.</p>\n<p>If that\u2019s not why, then it means AI use cases turned out to be severely limited, and the world has a large surplus of compute and not much to do with it.</p>\n<p>It kind of has to be one or the other. Neither seems plausible.</p>\n<p>I see not only no sign of overcapacity, I see signs of undercapacity, including a scramble for every chip people can get and compute being a limiting factor on many labs in practice right now, including OpenAI and Anthropic. The price of compute has recently been rising, not falling, including the price for renting older chips.</p>\n<p><a href=\"https://davefriedman.substack.com/p/when-the-accountants-come-for-the?r=37ez3&amp;utm_medium=ios&amp;triedRedirect=true\">Dave Friedman looked into the accounting here</a>, ultimately not seeing this as a solvency or liquidity issue, but he thinks there could be an accounting optics issue.</p>\n<p>Could recent trends reverse, and faster than expected depreciations and ability to charge for older chips cause problems for the accounting in data centers? I mean, sure, that\u2019s obviously possible, if we actually produce enough better chips, or demand sufficiently lags expectations, or some combination thereof.</p>\n<p>This whole question seems like a strange thing for those investing hundreds of billions and everyone trading the market to not have priced into their plans and projections? Yes, current OpenAI revenue is on the order of $20 billion, but if you project that out over 3-10 years, that number is going to be vastly higher, and there are other companies.</p>\n\n\n<h4 class=\"wp-block-heading\">The Bubble Case Seems Weak</h4>\n\n\n<p><a href=\"https://x.com/CharlesD353/status/1978800787640987830\">I mostly agree with Charles that the pro-bubble arguments are remarkably weak</a>, given the amount of bubble talk we are seeing, and that when you combine these two facts it should move you towards there not being a bubble.</p>\n<p>Unlike Charles, I am not about to use leverage. I consider leverage in personal investing to be reserved for extreme situations, and a substantial drop in prices is very possible. But I definitely understand.</p>\n<blockquote><p>Charles: There have been so many terrible arguments for why we\u2019re in an AI bubble lately, and so few good ones, that I\u2019ve been convinced the appropriate update is in the \u201cnot a bubble\u201d direction and increased my already quite long position.</p>\n<p>Fwiw that looks like now being 1.4x leveraged long a mix of about 50% index funds and 50% specific bets (GOOG, TSMC, AMZN the biggest of those).</p></blockquote>\n<p>Most of what changed, I think, is that there were a bunch of circular deals done in close succession, and when combined with the exponential growth expectations for AI and people\u2019s lack of understanding the technology and what it will be able to do, and the valuations approaching the point where one can question there being any room to grow, this reasonably triggered various heuristics and freaked people out.</p>\n<p>If we define a bubble narrowly as \u2018we see a Nasdaq price decline of 20% sustained for 6 months\u2019 I would give that on the order of 25% to happen within the next few years, including as part of a marketwide decline in prices. It has happened to the wider market as recently as 2022, and about 5 times in the last 50 years.</p>\n\n\n<h4 class=\"wp-block-heading\">What It Would Mean If Prices Did Go Down</h4>\n\n\n<p>If a decline does happen, I predict I will probably use that opportunity to buy more.</p>\n<p>That does not have to be true. Perhaps there will have been large shifts in anticipated future capabilities, or in the competitive landscape and ability to capture profits, or the general economic conditions, and the drop will be fully justified and reflect AI slowing down.</p>\n<p>But most of the time this will not be what happened, and the drop will not ultimately have much effect, although it would presumably slow down progress slightly.</p>\n<blockquote><p><a href=\"https://x.com/NPCollapse/status/1979445329796673714\">Connor Leahy</a>: I want to preregister the following opinion:</p>\n<p>I think it\u2019s plausible, but by no means guaranteed, that we could see a massive financial crisis or bubble pop affecting AI in the next year.</p>\n<p>I expect if this happens, it will be mostly for mundane economic reasons (overleveraged markets, financial policy of major nations, mistiming of bets even by small amounts and good ol\u2019 fraud), not because the technology isn\u2019t making rapid progress.</p>\n<p>I expect such a crisis to have at most modest effects on timelines to existentially dangerous ASI being developed, but will be used by partisans to try and dismiss the risk.</p>\n<p>Sadly, a bunch of people making poorly thought through leveraged bets on the market tells you little about underlying object reality of how powerful AI is or soon will be.</p>\n<p>Do not be fooled by narratives.</p></blockquote>\n<p>&nbsp;</p>\n<p>&nbsp;</p>"
            ],
            "link": "https://thezvi.wordpress.com/2025/10/20/bubble-bubble-toil-and-trouble/",
            "publishedAt": "2025-10-20",
            "source": "TheZvi",
            "summary": "We have the classic phenomenon where suddenly everyone decided it is good for your social status to say we are in an \u2018AI bubble.\u2019 Are these people short the market? Do not be silly. The conventional wisdom response to that &#8230; <a href=\"https://thezvi.wordpress.com/2025/10/20/bubble-bubble-toil-and-trouble/\">Continue reading <span class=\"meta-nav\">&#8594;</span></a>",
            "title": "Bubble, Bubble, Toil and Trouble"
        },
        {
            "content": [],
            "link": "https://xkcd.com/3157/",
            "publishedAt": "2025-10-20",
            "source": "XKCD",
            "summary": "<img alt=\"Many things about Star Wars were not well planned out, but having a 37-year-old in old-age makeup play the Emperor in Return of the Jedi was such an incredible call.\" src=\"https://imgs.xkcd.com/comics/emperor_palpatine.png\" title=\"Many things about Star Wars were not well planned out, but having a 37-year-old in old-age makeup play the Emperor in Return of the Jedi was such an incredible call.\" />",
            "title": "Emperor Palpatine"
        }
    ],
    "lookbackDays": 1,
    "publishDate": "2025-10-20"
}