{
    "articles": [
        {
            "content": [
                "<img alt=\"two AI researchers are now funded by Solana\" src=\"https://ghuntley.com/content/images/2026/01/A-split--vibrant--and-complex-ornamental-tattoo-art-print-of-Solana-cryptocurrency--with-the-Solana-logo--in-a-retro-flair-style-on-a-white-background--divided-into-bold-sections-with-distinct-areas.jpg\" /><p>Hey folks, it&#x2019;s been a wild week. Ralph Wiggum has finally <a href=\"https://venturebeat.com/technology/how-ralph-wiggum-went-from-the-simpsons-to-the-biggest-name-in-ai-right-now?ref=ghuntley.com\">crossed the chasm</a> and folks are starting to grasp that software development is now dead as software development can now be done whilst you sleep for $10.42/hr. Software Engineering is alive and well but the skills needed now are the same, yet different.</p><figure class=\"kg-card kg-embed-card kg-card-hascaption\"><figcaption><p><span style=\"white-space: pre-wrap;\">don&apos;t use the plugin - learn the theory instead!</span></p></figcaption></figure><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://github.com/ghuntley/how-to-ralph-wiggum?ref=ghuntley.com\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">GitHub - ghuntley/how-to-ralph-wiggum: The Ralph Wiggum Technique&#x2014;the AI development methodology that reduces software costs to less than a fast food worker&#x2019;s wage.</div><div class=\"kg-bookmark-description\">The Ralph Wiggum Technique&#x2014;the AI development methodology that reduces software costs to less than a fast food worker&#x2019;s wage. - ghuntley/how-to-ralph-wiggum</div><div class=\"kg-bookmark-metadata\"><img alt=\"two AI researchers are now funded by Solana\" class=\"kg-bookmark-icon\" src=\"https://ghuntley.com/content/images/icon/pinned-octocat-093da3e6fa40-30.svg\" /><span class=\"kg-bookmark-author\">GitHub</span><span class=\"kg-bookmark-publisher\">ghuntley</span></div></div><div class=\"kg-bookmark-thumbnail\"><img alt=\"two AI researchers are now funded by Solana\" src=\"https://ghuntley.com/content/images/thumbnail/how-to-ralph-wiggum\" /></div></a></figure><p>An upcoming post will be going into the changes of unit dynamics but if you want a sneak preview to my thinking here see these two videos:</p><figure class=\"kg-card kg-embed-card\"></figure><figure class=\"kg-card kg-embed-card\"></figure><p>but for now, I&#x2019;m going to be recapping something else that was quite extraordinary that happened in my life. </p><blockquote>I am now a walking, talking, financial instrument, an underlying. You see when Ralph started to cross the chasm a whole bunch of people started speculating on me on the Solana crypto currency network.</blockquote><p>This entire idea was wild and I initially rejected it - quite publicly I may add - it was a gut reaction part because my inbox was blowing up from people i didn&#x2019;t know; acting in ways that tripped my radar of &#x201c;this is scammy behavior&quot; and I had lived through the NFT days five years ago.</p><figure class=\"kg-card kg-embed-card kg-card-hascaption\"><figcaption><p><span style=\"white-space: pre-wrap;\">heck, I even sat down with Coffezilla</span></p></figcaption></figure><p>but within the pile of DM&apos;s that were stacking up were was was one person who caught my attention. </p><p>It was this conversation which completely changed my mind about what is going on - folks who had cryptocurrency are looking for genuine people who are doing good things out there in the world and the idea of accelerating these people through funding via cryptocurrency is something they want to do. </p><figure class=\"kg-card kg-image-card\"><img alt=\"two AI researchers are now funded by Solana\" class=\"kg-image\" height=\"1579\" src=\"https://ghuntley.com/content/images/2026/01/IMG_0493.jpeg\" width=\"1173\" /></figure><p>at first I ignored these messages but I looked up who they were coming from, their background and started opening up.</p><figure class=\"kg-card kg-image-card\"><img alt=\"two AI researchers are now funded by Solana\" class=\"kg-image\" height=\"1248\" src=\"https://ghuntley.com/content/images/2026/01/IMG_0496.jpeg\" width=\"1320\" /></figure><p>as I had lived through the NFT craze - I already had a wallet (and a ENS!) but still had concerns - you see I have perhaps as much trust issues as the average crypto currency holder.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img alt=\"two AI researchers are now funded by Solana\" class=\"kg-image\" height=\"1644\" src=\"https://ghuntley.com/content/images/2026/01/IMG_0497.jpeg\" width=\"1320\" /><figcaption><span style=\"white-space: pre-wrap;\">life&#x2019;s going pretty good right now but it wasn&#x2019;t always the case</span></figcaption></figure><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://ghuntley.com/a-new-chapter/\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">a new chapter: full-time working from a van in a forest</div><div class=\"kg-bookmark-description\">For many people, the year 2020 will go down as a moment in time of hardship in their lives but for me, the year 2019 was dramatically harder as it was the realization that a long-term relationship wasn&#x2019;t going to work out&#x2026;</div><div class=\"kg-bookmark-metadata\"><img alt=\"two AI researchers are now funded by Solana\" class=\"kg-bookmark-icon\" src=\"https://ghuntley.com/content/images/icon/7V0ak3am_400x400-1-69.jpg\" /><span class=\"kg-bookmark-author\">Geoffrey Huntley</span><span class=\"kg-bookmark-publisher\">Geoffrey Huntley</span></div></div><div class=\"kg-bookmark-thumbnail\"><img alt=\"two AI researchers are now funded by Solana\" src=\"https://ghuntley.com/content/images/thumbnail/Et-SRziUYAA7XzP-1-1.jpg\" /></div></a></figure><p>the conversation progressed and I came to understand indeed people are sick of the scammers and I was hesitant to be open to the idea that indeed a new form of creator funding dynamics was happening and I am in fact patient zero!</p><p>They suggested I catch up with the founder of BAGS and after a zoom call with them I came away with the following feelings after opening up with the following statement:</p><blockquote>I have to believe you (BAGS) are trying to create something great here and that you need me as much as I need you. If you did anything untoward then you would be infact damaging your own reputation and business.</blockquote><p>So, this really is a letter to the people who are having fun with the idea of turning me into a walking, talking meme that they can speculate on as for whom am I to judge as as a couple months ago I work in the high frequency trading domain. For all I know my co-workers are the ones who are trading me as an asset as a gag.</p><p>There&#x2019;s so much I&#x2019;ll never be able to share - prop shops are secretive. It creates somewhat of a divide between how much I can publicly talk about in the realm of AI and teach. It&#x2019;s a fine balance that causes me much internal friction.</p><p>but maybe, just maybe perhaps this creator economy on the Solana network is real as I&#x2019;m now staring at $300,000 in my physical bank account in under seven days which is enough of a safety net in case things ever go balls up.</p><p>So it has me thinking. Whilst I could literally throw out a tweet right now and be drowning in opportunities if such a thing was to occur...</p><blockquote>What if instead we have the perfect recipe in the making for truly independent research that&#x2019;s published open/freely in the making and all I needed to was open up and communicate with you?  I&apos;ve already got venture capitalists chasing me left right and center for meetings but heading down that path would likely result in the same scenario that I&apos;m in right now: conflicted. I am an old-school hippie hacker that deeply believes that knowledge should be free.</blockquote><p>Sorry for calling you a bunch of degens. Thank you for your support. </p><p>Here&#x2019;s the next steps and commitments:</p><ul><li>I am now redirecting my earnings/fees to buy <a href=\"https://ralphcoin.org/?ref=ghuntley.com\">$RALPH</a> as a way to say thank you to those who got in early and to improve the pool liquidity.</li><li>The <a href=\"https://ralphcoin.org/?ref=ghuntley.com\">$RALPH</a> coin is the official and only coin that I support. Please cease creating other coins and please note if you do create them I will claim them so that I can buy more $RALPH.</li><li>Clarity as to what loom is in an upcoming post - it&#x2019;s bigger than gas town folks. I&#x2019;m rethinking the last fourty years of software engineering and rebuilding the whole damn stack as something that can be self-hosted on-prem. For readers who know me - Loom used to be known as Pherrit. Loom is pherrit folks. Over the last year I&apos;ve rebuilt the concept many times in different languages (and even streamed it live on Youtube) but now the models are really good so it&apos;s time to build. At this stage I have:<ul><li> A fully functional source code host which replicates GitHub but it uses JJ as the baseline source control primitive but has backwards compatibility to Git - in loom speak it&apos;s called &quot;spool&quot;. Spool is whatever I want it to be - by freeing myself from topics of group think and backwards compatibility I&apos;ll be able to explore topics such as virtual filesystems (think replicating google piper or meta&apos;s monoke) as a form to provide context for agents (ie. think BEADS by Yeggie). </li><li>A fully functional implementation of GitHub Codespaces and sand boxing primitives so that weavers can run in the background on remote secure infrastructure (think similar to Daytona/E2B or OpenAI Codex) that uses spiffe://. </li><li>A fully functional audit system/data source which can be used as loopback sources to drive agents via eBPF.</li></ul></li><ul><li>A partially functional implementation of Sourcegraph Amp &#x1f60e; as a weaver (&quot;agent&quot;)</li><li>A partially functional implementation of Posthog analytics so that agents (&quot;weavers&quot;) are driven by through product telemetry and in time drive autonomous ralph loops to improve product outcomes.</li><li>A partially functional implementation of Launchdarkly so that agents (&quot;weavers&quot;) can autonomously release features into production via feature flags/experiments.</li></ul></ul><p>It&#x2019;s at this point where I explain what the heck is going on. In short there&#x2019;s this new platform called BAGS which had designed contracts on the SOL network where market making fees are redirected to the creator. </p><p>The more people speculate on the underlying (me) doing something cool the more fees that are collected by the platform. In my particular case 99% of fees are redirected to me and I&#x2019;m now using it to buy. </p><p>This is in no ways financial advice or solicitation dear reader - cryptocurrency is volatile and I completely understand if it&#x2019;s not for you. If you want to support me directly please consider subscribing to my newsletter as a paid reader - all those funds go directly to me.</p><p>The intention of this post is to recap what the heck is going on and to extend an invitation to other open source developers or researchers that if this happens to you - i&#x2019;m happy to sit down on a call and explain it all.</p><p>Until next time - thanks for reading,<br />Geoff.</p><figure class=\"kg-card kg-image-card\"><img alt=\"two AI researchers are now funded by Solana\" class=\"kg-image\" height=\"1100\" src=\"https://ghuntley.com/content/images/2026/01/IMG_0455.jpeg\" width=\"1100\" /></figure><hr /><p>Disclaimer: $RALPH is a memecoin created to celebrate the Ralph Wiggum Technique and AI development culture. The token was created and is operated by BagsApp. Geoffrey Huntley did not deploy the smart contract and has no control over it. Always do your own research before investing. Crypto is volatile&#x2014;only invest what you can afford to lose. This is not financial advice. Not affiliated with Anthropic, Ralph Wiggum, or 20th Century Fox.</p>"
            ],
            "link": "https://ghuntley.com/solana/",
            "publishedAt": "2026-01-15",
            "source": "Geoffrey Huntley",
            "summary": "<p>Hey folks, it&#x2019;s been a wild week. Ralph Wiggum has finally <a href=\"https://venturebeat.com/technology/how-ralph-wiggum-went-from-the-simpsons-to-the-biggest-name-in-ai-right-now?ref=ghuntley.com\">crossed the chasm</a> and folks are starting to grasp that software development is now dead as software development can now be done whilst you sleep for $10.42/hr. Software Engineering is alive and well but the</p>",
            "title": "two AI researchers are now funded by Solana"
        },
        {
            "content": [],
            "link": "https://interconnected.org/home/2026/01/15/reminders",
            "publishedAt": "2026-01-15",
            "source": "Matt Webb",
            "summary": "<div> <p>AI agents do things for you, semi-autonomously, and one question is how we coordinate with them.</p> <p>By <em>\"do things for you\"</em> I mean</p> <ul> <li>Claude Code that writes code <a href=\"https://interconnected.org/home/2025/09/12/claude\">while you contemplate life</a></li> <li>Claude Cowork, <a href=\"https://claude.com/blog/cowork-research-preview\">released this week</a>, that does \u201cknowledge work\u201d tasks after you point it at your folder of docs (I just used it to collate income by source for my tax return after feeding it a folder of PDF bank statements, big time save)</li> <li>Research a trip away for you\u2026 find and book a restaurant for you\u2026 run your drop-shipping side hustle social media channels for you\u2026 (but the question is <a href=\"https://interconnected.org/home/2024/03/20/agents\">how the agent discovers the tools to use</a> (2024))</li> <li>A robot that can tidy my front room <a href=\"https://interconnected.org/home/2024/09/20/filtered\">which I\u2019m sure we\u2019ll get at some point</a> (2024)</li> </ul> <p>(btw I use the heck out of Claude Code, despite there being better pure coding models available, proving that the difference is in the quality of the <a href=\"https://www.anthropic.com/engineering/effective-harnesses-for-long-running-agents\">agent harness</a>,_ i.e. how it approaches problems, and Anthropic has nailed that.)</p> <p>By <em>\"coordinate\"</em> what I mean is: once you\u2019ve stated your intent and the agent is <a href=\"https://interconnected.org/home/2025/08/29/dwim\">doing what you mean</a> (2025), or it\u2019s listened",
            "title": "The natural home for AI agents is your Reminders app"
        },
        {
            "content": [
                "<p><img src=\"https://tonsky.me/talks/covers/\u0414\u0443\u043c\u0430\u0435\u043c \u0434\u0430\u043b\u044c\u0448\u0435.png\" />    <audio controls=\"\" preload=\"none\">\n      <source src=\"https://tonsky.me/talks/content/2026-01-15 \u0414\u0443\u043c\u0430\u0435\u043c \u0434\u0430\u043b\u044c\u0448\u0435.mp3\" type=\"audio/mpeg\" />\n    </audio>\n</p>\n<p>\u0421 \u0418\u043b\u044c\u0435\u0439 \u0411\u0438\u0440\u043c\u0430\u043d\u043e\u043c \u043f\u0440\u043e\u0432\u043e\u0436\u0430\u0435\u043c \u0410\u043b\u0430\u043d\u0430 \u0414\u0430\u044f, \u0432\u0441\u043f\u043e\u043c\u0438\u043d\u0430\u044f, \u0432 \u0447\u0451\u043c \u0441\u043e\u0441\u0442\u043e\u044f\u0442 \u0434\u043e\u0441\u0442\u0438\u0436\u0435\u043d\u0438\u044f \u041c\u0430\u043a\u0430, \u0414\u0436\u043e\u0431\u0441\u0430 \u0438 \u0425\u0418\u0413\u0430 (\u043d\u043e \u0438 \u0412\u0438\u043d\u0434\u0443 \u0434\u043e\u0431\u0440\u044b\u043c \u0441\u043b\u043e\u0432\u043e\u043c \u0442\u043e\u0436\u0435 \u0432\u0441\u043f\u043e\u043c\u0438\u043d\u0430\u0435\u043c).</p>"
            ],
            "link": "https://tonsky.me/talks/#2026-01-15",
            "publishedAt": "2026-01-15",
            "source": "Nikita Prokopov",
            "summary": "<p><img src=\"https://tonsky.me/talks/covers/\u0414\u0443\u043c\u0430\u0435\u043c \u0434\u0430\u043b\u044c\u0448\u0435.png\" /> <audio controls=\"\" preload=\"none\"> <source src=\"https://tonsky.me/talks/content/2026-01-15 \u0414\u0443\u043c\u0430\u0435\u043c \u0434\u0430\u043b\u044c\u0448\u0435.mp3\" type=\"audio/mpeg\" /> </audio> </p> <p>\u0421 \u0418\u043b\u044c\u0435\u0439 \u0411\u0438\u0440\u043c\u0430\u043d\u043e\u043c \u043f\u0440\u043e\u0432\u043e\u0436\u0430\u0435\u043c \u0410\u043b\u0430\u043d\u0430 \u0414\u0430\u044f, \u0432\u0441\u043f\u043e\u043c\u0438\u043d\u0430\u044f, \u0432 \u0447\u0451\u043c \u0441\u043e\u0441\u0442\u043e\u044f\u0442 \u0434\u043e\u0441\u0442\u0438\u0436\u0435\u043d\u0438\u044f \u041c\u0430\u043a\u0430, \u0414\u0436\u043e\u0431\u0441\u0430 \u0438 \u0425\u0418\u0413\u0430 (\u043d\u043e \u0438 \u0412\u0438\u043d\u0434\u0443 \u0434\u043e\u0431\u0440\u044b\u043c \u0441\u043b\u043e\u0432\u043e\u043c \u0442\u043e\u0436\u0435 \u0432\u0441\u043f\u043e\u043c\u0438\u043d\u0430\u0435\u043c).</p>",
            "title": "Podcast: \u041d\u0430 \u041c\u0430\u043a\u0435 \u043d\u0435\u0442 \u043d\u0438\u043a\u0430\u043a\u0438\u0445 \u0448\u043a\u0430\u0444\u043e\u0432 @ \u0414\u0443\u043c\u0430\u0435\u043c \u0434\u0430\u043b\u044c\u0448\u0435"
        },
        {
            "content": [
                "<p>Claude Code and Cowork are growing so much that it is overwhelming Anthropic\u2019s servers. Claude Code and Cowork news has for weeks now been a large portion of newsworthy items about AI.</p>\n<p>Thus, at least for now, all things Claude Code and Cowork will stop appearing in the weekly updates, and will get their own updates, which might even be weekly.</p>\n<p>Google offered us the new Universal Commerce Protocol, and gives us its take on Personalized Intelligence. Personalized Intelligence could be a huge deal if implemented correctly, integrating the G-Suite including GMail into Gemini, if they did a sufficiently good job of it. It\u2019s too early to tell how well they did, and I will report on that later.</p>\n<div>\n\n\n<span id=\"more-25031\"></span>\n\n\n</div>\n\n\n<h4 class=\"wp-block-heading\">Table of Contents</h4>\n\n\n<ol>\n<li><a href=\"https://thezvi.substack.com/i/183921737/language-models-offer-mundane-utility\">Language Models Offer Mundane Utility.</a> LLMs do the math.</li>\n<li><a href=\"https://thezvi.substack.com/i/183921737/huh-upgrades\"><strong>Huh, Upgrades</strong>.</a> Veo 3.1, GLM-Image, AI Overviews in GMail and more.</li>\n<li><a href=\"https://thezvi.substack.com/i/183921737/comparative-advantage\">Comparative Advantage.</a> Code those vibes.</li>\n<li><a href=\"https://thezvi.substack.com/i/183921737/overcoming-bias\">Overcoming Bias.</a> LLMs systematically favor female candidates over male ones.</li>\n<li><a href=\"https://thezvi.substack.com/i/183921737/choose-your-fighter\">Choose Your Fighter.</a> Peter Wildeford\u2019s division of LLM labor.</li>\n<li><a href=\"https://thezvi.substack.com/i/183921737/get-my-agent-on-the-line\">Get My Agent On The Line.</a> Evals and dashboards for AI agents.</li>\n<li><a href=\"https://thezvi.substack.com/i/183921737/deepfaketown-and-botpocalypse-soon\">Deepfaketown and Botpocalypse Soon.</a> AIs find it hard to go undetected.</li>\n<li><a href=\"https://thezvi.substack.com/i/183921737/fun-with-media-generation\">Fun With Media Generation.</a> Girls in bikinis, Musk doing the twist.</li>\n<li><a href=\"https://thezvi.substack.com/i/183921737/a-young-lady-s-illustrated-primer\">A Young Lady\u2019s Illustrated Primer.</a> Lego my AI education, don\u2019t tie me down.</li>\n<li><a href=\"https://thezvi.substack.com/i/183921737/they-took-our-jobs\">They Took Our Jobs.</a> Productivity growth is remarkably high.</li>\n<li><a href=\"https://thezvi.substack.com/i/183921737/autonomous-killer-robots\"><strong>Autonomous Killer Robots</strong>.</a> Military to hook Grok up to everything.</li>\n<li><a href=\"https://thezvi.substack.com/i/183921737/get-involved\">Get Involved.</a> Anthropic, MIRI and IAPS fellowships, CG RFP.</li>\n<li><a href=\"https://thezvi.substack.com/i/183921737/introducing\"><strong>Introducing</strong>.</a> Google Universal Commerce Protocol and Personalized Intelligence.</li>\n<li><a href=\"https://thezvi.substack.com/i/183921737/in-other-ai-news\">In Other AI News.</a> Breaking down a16z\u2019s torment nexus investment thesis.</li>\n<li><a href=\"https://thezvi.substack.com/i/183921737/show-me-the-money\"><strong>Show Me the Money</strong>.</a> Google closes the big AI deal with Apple.</li>\n<li><a href=\"https://thezvi.substack.com/i/183921737/quiet-speculations\">Quiet Speculations.</a> The optimistic scenario is pretty good if it happens.</li>\n<li><a href=\"https://thezvi.substack.com/i/183921737/the-quest-for-sane-regulations\">The Quest for Sane Regulations.</a> A look back at the impact of Regulation E.</li>\n<li><a href=\"https://thezvi.substack.com/i/183921737/china-proposes-new-regulations-on-ai\">China Proposes New Regulations On AI.</a> The target is anthropomorphic AI.</li>\n<li><a href=\"https://thezvi.substack.com/i/183921737/chip-city\">Chip City.</a> The compute continues doubling.</li>\n<li><a href=\"https://thezvi.substack.com/i/183921737/the-week-in-audio\">The Week in Audio.</a> Huang lying, Daniella, Millidge on competition and values.</li>\n<li><a href=\"https://thezvi.substack.com/i/183921737/ghost-in-a-jar\">Ghost in a Jar.</a> Ask if generative AI is right for you.</li>\n<li><a href=\"https://thezvi.substack.com/i/183921737/rhetorical-innovation\">Rhetorical Innovation.</a> Muddling through and focusing on the wrong questions.</li>\n<li><a href=\"https://thezvi.substack.com/i/183921737/aligning-a-smarter-than-human-intelligence-is-difficult\">Aligning a Smarter Than Human Intelligence is Difficult.</a> Monitoring it instead.</li>\n<li><a href=\"https://thezvi.substack.com/i/183921737/people-are-worried-about-ai-killing-everyone\"><strong>People Are Worried About AI Killing Everyone</strong>.</a> Representative Brad Sherman.</li>\n</ol>\n\n\n<h4 class=\"wp-block-heading\">Language Models Offer Mundane Utility</h4>\n\n\n<p><a href=\"https://x.com/kimmonismus/status/2009626253947744714\">Terence Tao confirms</a> <a href=\"https://www.reddit.com/r/singularity/comments/1q7u78b/terence_taos_writeup_of_gpt52_solving_erdos/\">an AI tool has solved a new Erdos problem (#728)</a> in the spirit in which the problem was intended.</p>\n<p><a href=\"https://x.com/A_G_I_Joe/status/2011213878395617571\">Separately from that</a>, a paper documents that an internal math-specialized version of Gemini 2.5 (not even Gemini 3!) proved a novel theorem in algebraic geometry.</p>\n<blockquote><p>Ravi Vakil (President, American Mathematical Society): proof was rigorous, correct, and elegant&#8230; the kind of insight I would have been proud to produce myself.</p></blockquote>\n<p>Meanwhile, yeah, Claude for Chrome is a lot better with Opus 4.5, best in class.</p>\n<blockquote><p><a href=\"https://x.com/omooretweets/status/2010110390450151779\">Olivia Moore</a>: Claude for Chrome is absolutely insane with Opus 4.5</p>\n<p>IMO it\u2019s better than a browser &#8211; it\u2019s the best agent I\u2019ve tried so far</p></blockquote>\n<p>Clade for Chrome can now be good, especially when Claude Code is driving it, but it is slow. It needs the ability to know when to do web tasks within Claude rather than within Chrome. In general, I prefer to let Claude Code direct Claude for Chrome, that seems great.</p>\n<p><a href=\"https://x.com/liron/status/2010059766178148551\">Doctor, doctor, the AI needs your help to access your regulated hardware</a>, and presumably your prescription pad.</p>\n<p><a href=\"https://marginalrevolution.com/marginalrevolution/2026/01/claims-about-ai-productivity-improvements.html?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=claims-about-ai-productivity-improvements\">Paper from Ali Merali</a> finds that consultants, data analysts and managers completing professional tasks with LLMs reduced task time by 8% for each year of model progress, and projects model scaling \u2018<a href=\"https://arxiv.org/pdf/2512.21316\">could boost U.S. productivity by approximately 20% over the next decade.\u2019</a> Gains are for now mostly on non-agentic tasks.</p>\n<p>The reason she projects 20% productivity gains is essentially AI applying to 20% of tasks, times 57% labor share of costs, times 175% productivity growth. This seems like a wrong calculation on several counts:</p>\n<ol>\n<li>AI will soon apply to a larger percentage of tasks, including agentic tasks.</li>\n<li>AI will substitute for many non-labor costs within those tasks, and even if not the gains are not well-captured by declines in labor costs.</li>\n<li>We need to consider substitution into and expansion of these tasks. There\u2019s an assumption in this calculation that these 20% of current tasks retain 20% of labor inputs, but there\u2019s no reason to think that\u2019s the right answer. It\u2019s not obvious whether the right answer moves up or down, but if a sector has 175% productivity growth you should expect a shift in labor share.</li>\n<li>This is not a \u2018straight line on a graph\u2019 that it makes sense to extend indefinitely.</li>\n<li>As an intuition pump and key example, AI will in some cases boost productivity in a given task or job to full automation, or essentially infinite productivity, the same way that computers can do essentially infinite amounts of arithmetic, or how AI is doing this for translation.</li>\n</ol>\n<p><a href=\"https://x.com/AndyMasley/status/2011586964420771885\">Use Claude for Chrome to block all racist replies to a post on Twitter.</a></p>\n\n\n<h4 class=\"wp-block-heading\">Huh, Upgrades</h4>\n\n\n<p><a href=\"https://x.com/joshwoodward/status/2011139075387113597\">Veo 3.1 gives portrait mode</a>, 1080p and 4k resolution in Flow, better expressiveness and coherence, <a href=\"https://x.com/GoogleDeepMind/status/2011121718551577042\">consistent people and backgrounds across scenes</a> and <a href=\"https://x.com/GoogleDeepMind/status/2011121721047171346\">combining of different sources</a> with up to 3 reference images. Things steadily get better.</p>\n<p><a href=\"https://x.com/lukeprog/status/2011254742358638684\">GLM-Image</a> claims to be a new milestone in open-source image generation. <a href=\"https://t.co/u7HpXQ1WCJ\">GitHub here</a>, <a href=\"https://t.co/SOOzRdErVS\">API here</a>. I can no longer evaluate AI image models from examples, at all, everyone\u2019s examples are too good.</p>\n<p>There is a GPT-5.2-Codex, and it is available in Cursor.</p>\n<p><a href=\"https://x.com/OfficialLoganK/status/2009301505329762708\">Gemini gives us AI Inbox, AI Overviews in GMail</a> and other neat stuff like that. I feel like we\u2019ve been trying variants of this for two years and they keep not doing what we want? The problem is that you need something good enough to trust to not miss anything, or it mostly doesn\u2019t work. Also, as Peter Wildeford points out, we can do a more customizable version of this using Claude Code, which I intend to do, although 98%+ of GMail users are never going to consider doing that.</p>\n<p><a href=\"https://openai.com/index/openai-for-healthcare/\">OpenAI for Healthcare</a> <a href=\"https://openai.com/index/openai-for-healthcare/\">is a superse</a>t of ChatGPT Health. It includes models built for healthcare workflows (I think this just means they optimized their main models), evidence retrieval with transparent citations (why not have this for everywhere?), integrations with enterprise tools, reusable templates to automate workflows (again, everywhere?), access management and governance (ditto) and data control.</p>\n<p>And most importantly it offers: Support for HIPAA compliance. Which was previously true for everyone\u2019s API, but not for anything most doctors would actually use.</p>\n<p>It is now \u2018live at AdventHealth, Baylor Scott &amp; White, UCSF, Cedars-Sinai, HCA, Memorial Sloan Kettering, and many more.\u2019</p>\n<p>I presume that everyone in healthcare was previously violating HIPAA and we all basically agreed in practice not to care, which seemed totally fine, but that doesn\u2019t scale forever and in some places didn\u2019t fly. It\u2019s good to fix it. In general, it would be great to see Gemini and Claude follow suit on these health features.</p>\n<p><a href=\"https://x.com/omooretweets/status/2009468969015734327\">Olivia Moore got access to GPT Health</a>, and reports it is focused on supplementing experts, and making connections to allow information sharing, including to fitness apps and also to Instacart.</p>\n<p><a href=\"https://www.anthropic.com/news/healthcare-life-sciences\">Anthropic answers ChatGPT Health by announcing</a> <a href=\"https://claude.com/solutions/healthcare\">Claude for Healthcare</a>, which is centered on offering connectors, including to The Centers for Medicare &amp; Medicaid Services (CMS) Coverage Database, The International Classification of Diseases, 10th Revision (ICD-10) and The National Provider Identifier Registry. They also added two new agent skills: FHIR development and a sample prior authorization review skill. Claude for Life Sciences is also adding new connectors.</p>\n<p><a href=\"https://x.com/omooretweets/status/2011141771636740251\">Manus now comes with 12 months of free SimilarWeb data</a>, and Perplexity Max gives a bunch of free extra data sources as well.</p>\n\n\n<h4 class=\"wp-block-heading\">Comparative Advantage</h4>\n\n\n<blockquote><p><a href=\"https://x.com/DanielleFong/status/2010096114020839760\">Danielle Fong</a>: your vibes.</p>\n<p>Dan Goldstein:</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!zpHY!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F77efe5c3-53ec-4466-a860-a0fb4fa2cce7_1024x1024.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n</blockquote>\n<p>The obvious answer is \u2018actually doing it as opposed to being able to do it,\u2019 because people don\u2019t do things, and also when the task is hard good vibe coders are 10x or 100x better than mediocre ones, the same as it is with non-vibe coding.</p>\n\n\n<h4 class=\"wp-block-heading\">Overcoming Bias</h4>\n\n\n<p>Manhattan Institute tests for bias in decisions based on order, gender or race. Order in which candidates are presented is, as per previous research, a big factor.</p>\n<p>Women were described as being slightly favored overall in awarding positive benefits, and they say race had little impact. That\u2019s not what I see when I look at their data?</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!5PGT!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1866e97f-15a5-47a8-bb47-9a71c1f23e9d_1014x1011.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!PNUY!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F41e1f6a3-cd1d-4259-b382-955cc0eed52e_1018x1000.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>This is the gap \u2018on the margin\u2019 in a choice between options, so the overall gap in outcomes will be smaller, but yeah a 10%+ less chance in close decisions matters. In \u2018unfavorable\u2019 decisions the gap was legitimately small.</p>\n<p>Similarly, does this look like \u2018insignificant differences\u2019 to you?</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!phSI!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F605fce8d-153c-486f-9743-cbadd919fcee_1138x1321.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>We\u2019re not frequentist statisticians here, and that\u2019s a very obvious pattern. Taking away explicit racial markers cures most of it, but not all of it.</p>\n\n\n<h4 class=\"wp-block-heading\">Choose Your Fighter</h4>\n\n\n<p>&nbsp;</p>\n<p>This algorithm seems solid for now, throw \u2018coding\u2019 into the Claude Code folder.</p>\n<blockquote><p><a href=\"https://x.com/peterwildeford/status/2009287226925121947\">Peter Wildeford</a>: Here&#8217;s currently how I&#8217;m using each of the LLMs</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!AcZf!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc3b117eb-20d4-479a-9a18-21fe924db6d3_1200x675.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n</blockquote>\n<p>Once Claude Cowork gets into a better state, things could change a lot.</p>\n\n\n<h4 class=\"wp-block-heading\">Get My Agent On The Line</h4>\n\n\n<p><a href=\"https://www.anthropic.com/engineering/demystifying-evals-for-ai-agents\">Anthropic writes a post on Demystifying Evals for AI Agents</a>, explaining how to do a decent job of them. Any serious effort to do anything AI that scales needs evals.</p>\n<p>For a while, AI agents have been useful on the margin, given the alternative, but mostly have gone undeployed. <a href=\"https://x.com/sebkrier/status/2009224862569509215\">Seb Krier points out this is largely due</a> to liability concerns, since companies that deploy AI agents often don\u2019t capture most of the upside, but do get held responsible for the downside including in PR terms, and AI failures cause a lot more liability than similar human failures.</p>\n<p>That means if an agent is going to be facing those who could hold it responsible in such ways, it needs to be 10 or 100 times better to make up for this. Whereas us individuals can just start using Claude Code for everything, since it\u2019s not like you can get sued by yourself.</p>\n<p>A lot of founders are building observability platforms for AI agents. <a href=\"https://x.com/0xDevShah/status/2010435036584333514\">Dev Shah points out these dashboards and other systems</a> only help if you know what to do with them. The default is you gather 100,000 traces and look at none of them.</p>\n\n\n<h4 class=\"wp-block-heading\">Deepfaketown and Botpocalypse Soon</h4>\n\n\n<p><a href=\"https://x.com/dioscuri/status/2010064837217501645\">Henry Shevlin runs a test</a>, claims AI models asked to write on the subject of their choice in order to go undetected were still mostly detected, and the classifiers basically work in practice <a href=\"https://x.com/jt_kerwin/status/2009548086062829690\">as per Jason Kerwin\u2019s claim</a> on <a href=\"http://pangram.com\">Pangram</a>, which he claims has a less than 1% false positive rate.</p>\n<p>Humans who pay attention are also getting increasingly good at such detection, sufficiently to keep pace with the models at least for now. I have potential false positives, but I consider them \u2018true false positives\u2019 in the sense that even if they were technically written by a human they weren\u2019t written as actual human-to-human communication attempts.</p>\n<p>So the problem is that in many fields, especially academia, 99% confidence is often considered insufficient for action. Whereas I don\u2019t act that way at all, if I have 90% confidence you\u2019re writing with AI then I\u2019m going to act accordingly. I respect the principle of \u2018better to let ten guilty men go free than convict one innocent person\u2019 when we\u2019re sending people to jail and worried about government overreach, but we\u2019re not sending people to jail here.</p>\n<p><a href=\"https://x.com/allTheYud/status/2011126075427078447\">What should the conventions be for use of AI-generated text?</a></p>\n<blockquote><p>Daniel Litt: IMO it should be considered quite rude in most contexts to post or send someone a wall of 100% AI-generated text. \u201cHere, read this thing I didn\u2019t care enough about to express myself.\u201d</p>\n<p>Obviously it&#8217;s OK if no one is reading it; in that case who cares?</p>\n<p><a href=\"https://x.com/allTheYud/status/2011126075427078447\">Eliezer Yudkowsky</a>: It&#8217;s rude to tell Grok to answer someone&#8217;s stupid question, especially if Grok then does so correctly, because it expresses the impolite truth that they&#8217;ve now gone underwater on the rising level of LLM intelligence.</p>\n<p>That said, to ever send anyone AI-generated text in a context where it is not clearly labeled as AI, goes far beyond the &#8216;impolite truth&#8217; level of rudeness and into the realm of deception, lies, and wasting time.</p></blockquote>\n<p>My rules are:</p>\n<ol>\n<li>Unlabeled walls of AI-generated text intended for humans are never okay.</li>\n<li>If the text is purely formalized or logistical and not a wall, that can be unlabeled.</li>\n<li>If the text is not intended to be something a human reads, game on.</li>\n<li>If the text is clearly labeled as AI that is fine if and only if the point is to show that the information comes from a neutral third party of sorts.</li>\n</ol>\n\n\n<h4 class=\"wp-block-heading\">Fun With Media Generation</h4>\n\n\n<p><a href=\"https://x.com/peterwildeford/status/2009381368304668921\">Most \u2018sexualized\u2019 deepfakes were at least for a time happening via Grok on Twitter</a>, <a href=\"https://www.bloomberg.com/news/articles/2026-01-07/musk-s-grok-ai-generated-thousands-of-undressed-images-per-hour-on-x?embedded-checkout=true\">as per Genevieve Oh via Cecilia D\u2019Anastasio at Bloomberg</a>. <a href=\"https://www.bloomberg.com/opinion/articles/2026-01-07/musk-will-not-fix-fake-ai-nudes-made-by-grok-a-ban-would\">If we want xAI and Elon Musk to stop</a> we\u2019ll have to force them by law, which we partly have now done.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!hrzd!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c622fe0-aa1a-4cbb-9cba-5a68f0c6168c_1200x943.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>We can\u2019t prevent people from creating \u2018sexualized\u2019 or nude pictures in private, based on real people or otherwise, and aside from CSAM we shouldn\u2019t try to stop them. But doing or posting it on a public form, based on a clear individual without their consent, is an entirely different matter.</p>\n<p>What people had a problem with was creating sexualized images of actual people, in ways that were public by default, as in \u2018hey Grok put her in a bikini\u2019 in reply to a post and Grok would, for a time, go ahead and do it. It\u2019s not clear to me exactly where you need to draw the line on that sort of thing, but one click harassment on social media is pretty unacceptable, and it made a lot of people very unhappy.</p>\n<p>As a result, on January 9 Grok reply image generation got restricted to paid subscribers and the bot mostly stopped creating sexualized images of real people, <a href=\"https://x.com/Safety/status/2011573102485127562\">and then</a> on January 15 they changed this to \u2018no editing of images of real people on Twitter\u2019 at all. Rules are different in private image generation, but there are various ways to get essentially whatever image you want in private.</p>\n<p>Around this time, three xAI safety team members publicly left the company, including the head of product safety, likely due to Musk being against the idea of product safety.</p>\n<p>This incident has caused formal investigations of various sorts across the world, including in the UK, EU, France, India and California. Grok got banned entirely in Malaysia and Indonesia.</p>\n<blockquote><p><a href=\"https://x.com/yacineMTB/status/2011580449429316068\">kache</a>: you need to apply constant pressure on social media websites through the state, or they will do awful shit like letting people generate pornography of others (underage or otherwise) with one click</p>\n<p>they would have never removed the feature if they weren&#8217;t threatened.</p></blockquote>\n<p>For those of you who saw a lot of this happening in their feeds: You need to do a way better job curating your feeds. The only times I saw this in my feeds were people choosing to do it to themselves for fun.</p>\n<p>Elon Musk had the audacity to ask, so yes, of course <a href=\"https://x.com/elder_plinius/status/2011544239579308076\">Pliny has fully jailbroken Grok\u2019s image moderation in terms of full frontal nudity</a>. Pictures at link, and the quality is very high, great image model.</p>\n<p>The other replies to that were exactly the kind of \u2018walking the line\u2019 on full nudity that is exactly what Musk says he is aiming at, so on non-identifiable people they mostly are now doing a good job, if the moderation makes full nudity a Pliny-level feature then that is fine, this is nudity not bioweapons.</p>\n<p>In other no fun news, <a href=\"https://x.com/eigenrobot/status/2011764821579219201\">Eigenrobot shows examples of ChatGPT no longer producing proper Studio Ghibli images</a>. The new images aren\u2019t bad, but they\u2019re generic and not the particular stylized thing that we want here.</p>\n\n\n<h4 class=\"wp-block-heading\">A Young Lady\u2019s Illustrated Primer</h4>\n\n\n<p><a href=\"https://www.axios.com/2026/01/12/lego-education-smart-bricks-artificial-intelligence?utm_medium=organic_social&amp;utm_social_post_id=649925503&amp;utm_campaign=editorial&amp;utm_source=x&amp;utm_social_handle_id=800707492346925056\">Lego offers a new AI education module</a>. Weird fit, but sure, why not?</p>\n<p><a href=\"https://forklightning.substack.com/p/using-generative-ai-to-learn-is-like?utm_source=post-email-title&amp;publication_id=1808592&amp;post_id=184243966&amp;utm_campaign=email-post-title&amp;isFreemail=true&amp;r=3o9&amp;triedRedirect=true&amp;utm_medium=email\">David Deming compares learning via generative AI</a> with Odysseus untying himself from the mast. Learning can be fully personalized, but by default you try to take \u2018unearned\u2019 knowledge, you think you\u2019ve learned but you haven\u2019t, and this is why students given generative AI in experiments don\u2019t improve their test scores. Personalization is great but students end up avoiding learning.</p>\n<p>I would as usual respond that AI is the best way ever invented to both learn and not learn, and that schools are structured to push students towards door number two. Deming\u2019s solution is students need to first do the problem without AI, which makes sense in some contexts but not others, and especially makes sense if your test is going to be fully in no-AI conditions.</p>\n<p>We need to give students, and everyone else, a reason to care about understanding what they are doing, if we want them to have that understanding. School doesn\u2019t do it.</p>\n<blockquote><p>David Deming: This isn\u2019t unique to AI. A study from more than a decade ago found that <a href=\"https://slate.com/technology/2014/12/automation-in-the-cockpit-is-making-pilots-thinking-skills-duller.html?via=recirc_recent\">advancements in autopilot technology had dulled Boeing pilots\u2019 cognitive and decision-making skills</a> much more than their manual \u201cstick and rudder\u201d skills.</p>\n<p>They put the pilots in a flight simulator, turned the autopilot off, and studied how they responded. The pilots who stayed alert while the autopilot was still on were mostly fine, but the ones who had offloaded the work and were daydreaming about something else performed very poorly. The autopilot had become their exoskeleton.\u200b</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">They Took Our Jobs</h4>\n\n\n<p>&nbsp;</p>\n<p><a href=\"https://www.bloomberg.com/opinion/articles/2026-01-08/is-ai-causing-a-productivity-boom\">American labor productivity rose at a 4.9% annualized rate on Q3</a>, while unit labor costs declined 1.9%. Jonathan Levin says this \u2018might not\u2019 be the result of AI, and certainly all things are possible, but I haven\u2019t heard the plausible alternative.</p>\n<p><a href=\"https://x.com/daniel_271828/status/2009885065871012272\">Underemployment rate (not unemployment)</a> for college graduates remains very high, but there is no trend:</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!jR0c!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1056f0b5-be7d-4a70-a496-4ffc42f19fc0_556x679.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>As a reminder, if your reassurance to the humans is \u2018the AIs will be too expensive or there won\u2019t be enough supply\u2019 you want to remember charts like this:</p>\n<blockquote><p><a href=\"https://x.com/JonErlichman/status/2010367185131286984\">Jon Erlichman</a>: Average cost for 1 gigabyte of storage:</p>\n<p>45 years ago: $438,000<br />\n40 years ago: $238,000<br />\n35 years ago: $48,720<br />\n30 years ago: $5,152<br />\n25 years ago: $455<br />\n20 years ago: $5<br />\n15 years ago: $0.55<br />\n10 years ago: $0.05<br />\n5 years ago: $0.03<br />\nToday: $0.01</p></blockquote>\n<p>There is constantly the assumption of \u2018people want to interact with a person\u2019 but what about the opposite instinct?</p>\n<blockquote><p><a href=\"https://post.substack.com/p/the-ai-revolution-is-here-will-the\">Dwarkesh Patel</a>: They are now my personal one-on-one tutors. I\u2019ve actually tried to hire human tutors for different subjects I\u2019m trying to prep for, and I\u2019ve found the latency and speed of LLMs to just make for a qualitatively much better experience. I\u2019m getting the digital equivalent of people being willing to pay huge premiums for Waymo over Uber. It inclines me to think that the human premium for many jobs will not only not be high, but in fact be negative.\u200b</p></blockquote>\n<p>There are areas where the human premium will be high. But there will be many places that premium will be highly negative, instead.</p>\n<p>Similarly, many jobs might want to watch out even if AI can\u2019t do the job directly:</p>\n<blockquote><p>Michael Burry: On that point, many point to trade careers as an AI-proof choice. Given how much I can now do in electrical work and other areas around the house just with Claude at my side, I am not so sure. If I\u2019m middle class and am facing an $800 plumber or electrician call, I might just use Claude. I love that I can take a picture and figure out everything I need to do to fix it.</p></blockquote>\n<p>There\u2019s a famous story about a plumber who charges something like $5 to turn the \u200bwrench and $495 for knowing where to turn the wrench. Money well spent. The AI being unable to turn that wrench does not mean the plumber gets to stay employed.</p>\n\n\n<h4 class=\"wp-block-heading\">Autonomous Killer Robots</h4>\n\n\n<p><a href=\"https://x.com/JacquesThibs/status/2011076980150591737\">The military says</a> \u2018We must accept that the risks of not moving fast enough outweigh the risks of imperfect alignment,\u2019 is developing various AI agents <a href=\"https://x.com/sjgadler/status/2011218692672274872\">and deploys Grok</a> to \u2018every classified network throughout our department.\u2019 They are very explicitly framing Military AI as a \u2018race\u2019 where speed wins.</p>\n<p>I\u2019ve already taken a strong stand that yes, we need to accept that the military is going to integrate AI and build autonomous killer robots, because if we are going to build it and others can and will deploy it then we can\u2019t have our military not use it.</p>\n<p>If you don\u2019t like it, then advocate pausing frontier AI development, or otherwise trying to ensure no one creates the capabilities that enable this. Don\u2019t tell us to unilaterally disarm, that only makes things worse.</p>\n<p>That doesn\u2019t mean it is wise to give several AIs access to the every classified document. That doesn\u2019t mean we should proceed recklessly, or hand over key military decisions to systems we believe are importantly misaligned, and simply proceed as fast as possible no matter the costs. That is madness. That is suicide.</p>\n<p>Being reckless does not even help you win wars, because the system that you cannot rely on is the system you cannot use. Modern war is about precision, it is about winning hearts and minds and the war of perception, it is about minimizing civilian casualties and the mistakes that create viral disasters, both because that can wreck everything and also risking killing innocent people is kind of a huge deal.</p>\n<p>Does our military move too slowly and find it too difficult and expensive, often for needless reasons, to adapt new technology, develop new programs and weapons and systems and tactics, and stay ahead of the curve, across the board? Absolutely, and some of that is Congressional pork and paralysis and out of control bureaucracy and blame avoidance and poor incentives and people fighting the last war and stuck in their ways. But we got here because we need to have very high standards for a reason, that\u2019s how we are the best, and it\u2019s tough to get things right.</p>\n<p>In particular, we shouldn\u2019t trust Elon Musk and xAI, in particular, with access to all our classified military information and be hooking it up to weapon systems. Their track record should establish them as uniquely unreliable partners here. I\u2019d feel a lot more comfortable if we limited this to the big three (Anthropic, Google and OpenAI), and if we had more assurance of appropriate safeguards.</p>\n<p>I\u2019d also be a lot more sympathetic, as with everything else, to \u2018we need to remove all barriers to AI\u2019 if the same people were making that part of a general progress and abundance agenda, removing barriers to everything else as well. I don\u2019t see the Pentagon reforming in other ways, and that will mean we\u2019re taking on the risks of reckless AI deployment without the ability to get many of the potential benefits.</p>\n\n\n<h4 class=\"wp-block-heading\">Get Involved</h4>\n\n\n<p>Reminder: Anthropic Fellows Applications close January 20, apply for <a href=\"https://t.co/rdp53Fq3ly\">safety track</a> or <a href=\"https://t.co/KmKhUoi2V1\">security track</a>.</p>\n<p><a href=\"https://job-boards.greenhouse.io/deepmind/jobs/7493360\">DeepMind is hiring Research Engineers for Frontier Safety Risk Assessment</a>, can be in NYC, San Francisco or London.</p>\n<p><a href=\"https://t.co/8RAqWsABrK\">MIRI is running a fellowship for technical governance research</a>, apply here.</p>\n<p><a href=\"https://x.com/peterwildeford/status/2011239279226417611\">IAPS is running a funded fellowship from June 1 to August 21, deadline is February 2</a>.</p>\n<p><a href=\"https://t.co/y1Yd657m1g\">Coefficient Giving\u2019s RFP</a> <a href=\"https://x.com/lukeprog/status/2011254742358638684\">for AI Governance closes on January 25</a>.</p>\n\n\n<h4 class=\"wp-block-heading\">Introducing</h4>\n\n\n<p><a href=\"https://x.com/GeminiApp/status/2011469541235417243\">Google introduces \u2018personalized intelligence</a>\u2019 linking up with your G-Suite products. This could be super powerful memory and customization, basically useless or anywhere in between. I\u2019m going to give it time for people to try it out before offering full coverage, so more later.</p>\n<p><a href=\"https://x.com/sundarpichai/status/2010382050570932299\">Google launches the Universal Commerce Protocol</a>.</p>\n<p>If it works you\u2019ll be able to buy things directly, using your saved Google Wallet payment method, directly from an AI Overview or Gemini query. It\u2019s an open protocol, so others could follow suit.</p>\n<blockquote><p>Sundar Pichai (CEO Google): \u200bAI agents will be a big part of how we shop in the not-so-distant future.</p>\n<p>To help lay the groundwork, we partnered with Shopify, Etsy, Wayfair, Target and Walmart to create the Universal Commerce Protocol,<a href=\"https://blog.google/products/ads-commerce/agentic-commerce-ai-tools-protocol-retailers-platforms/\"> a new open standard for agents and systems</a> to talk to each other across every step of the shopping journey.</p>\n<p>And coming soon, UCP will power native checkout so you can buy directly on AI Mode and the @Geminiapp.</p>\n<p>UCP is endorsed by 20+ industry leaders, compatible with A2A, and available starting today.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!uPLV!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbfbc4434-362d-4283-a4e6-3f0493328278_1000x562.webp\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n</blockquote>\n<p>That\u2019s a solid set of initial partners. One feature is that retailers can offer an exclusive discount through the protocol. Of course, they can also jack up the list price and then offer an \u2018exclusive discount.\u2019 Caveat emptor.</p>\n<p><a href=\"https://www.wsj.com/articles/google-bets-on-ai-based-shopping-with-new-ai-agents-for-retailers-45ad3f27?mod=cio-journal_lead_story\">This was also covered by The Wall Street Journal</a>, <a href=\"https://stratechery.com/2026/apple-and-gemini-foundation-vs-aggregation-universal-commerce-protocol/?access_token=eyJhbGciOiJSUzI1NiIsImtpZCI6InN0cmF0ZWNoZXJ5LnBhc3Nwb3J0Lm9ubGluZSIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJzdHJhdGVjaGVyeS5wYXNzcG9ydC5vbmxpbmUiLCJhenAiOiJIS0xjUzREd1Nod1AyWURLYmZQV00xIiwiZW50Ijp7InVyaSI6WyJodHRwczovL3N0cmF0ZWNoZXJ5LmNvbS8yMDI2L2FwcGxlLWFuZC1nZW1pbmktZm91bmRhdGlvbi12cy1hZ2dyZWdhdGlvbi11bml2ZXJzYWwtY29tbWVyY2UtcHJvdG9jb2wvIl19LCJleHAiOjE3NzA4OTQzMTAsImlhdCI6MTc2ODMwMjMxMCwiaXNzIjoiaHR0cHM6Ly9hcHAucGFzc3BvcnQub25saW5lL29hdXRoIiwic2NvcGUiOiJmZWVkOnJlYWQgYXJ0aWNsZTpyZWFkIGFzc2V0OnJlYWQgY2F0ZWdvcnk6cmVhZCBlbnRpdGxlbWVudHMiLCJzdWIiOiIwMTk2NDBhNy0zY2M1LTc3NTMtODM2OC1mYjI4OTEyNGNmMTMiLCJ1c2UiOiJhY2Nlc3MifQ.q0EtNQXsotHKvf5O78FdfvT6tYRDkaDuD8JLdgULGirS4b7sKVN03NB5kA3UpEG9YrqOwytaq4RNffE9DsEzifDtPv4OPTU9wGkzNngM23vvJR8mOMxm3m8kEyoUQIowCL8ThuY31gGwo3I548-2ovC6AtyVxd6Zru7R-Wj_R2jfJ6aHG-MLzKc4LInhUtsQlBEfPmXSdj0DItWQnXtB_E8Vco2lPJrvIbC4bWtWTm2pf0rvAbPwXjo1gPNVSEUSsD6VXZzzPltIPDwGezxCsW5YHC69zGhf_N6OwBUZbDjT86Se6StXHVXVuxopi4fPcymtRPb1VCSVN-m2iKjGjg\">and by Ben Thompson</a>.</p>\n<p>Ben contrasts UCP with OpenAI\u2019s ACP. ACP was designed by OpenAI and Stripe for ChatGPT in particular, whereas UCP is universal, and also more complicated, flexible and powerful. It is, as its name implies, universal. Which means, assuming UCP is a good design, that by default we should expect UCP to win outside of ChatGPT, pitting OpenAI\u2019s walled garden against everyone else combined.</p>\n<p><a href=\"https://www.politico.com/news/2026/01/06/artificial-intelligence-prescribing-medications-utah-00709122?_bhlid=c86a162c857984a1c31b8d037dc314cf8b508cc3&amp;utm_campaign=chatgpt-levels-up-with-health&amp;utm_medium=newsletter&amp;utm_source=www.therundown.ai\">Utah launches a pilot program to have AI prescribe a list of 190 common medications</a> for patients with chronic conditions, in a test AI treatment plans agreed with doctors 99.2% of the time, and the AI can escalate to a doctor if there is uncertainty.</p>\n<p>Even if trust in the AIs is relatively low, and even if you are worried about there being ways to systematically manipulate the health AI (which presumably is super doable) there is very obviously a large class of scenarios where the reason for the prescription renewal requirement is \u2018get a sanity check\u2019 rather than anything else, or where otherwise the sensitivity level is very low. We can start AI there, see what happens.</p>\n\n\n<h4 class=\"wp-block-heading\">In Other AI News</h4>\n\n\n<p><a href=\"https://x.com/TheMidasProj/status/2009283811800961344\">The Midas Project takes a break</a> to shoot fish in a barrel, looks at a16z\u2019s investment portfolio full of deception, manipulation, gambling (much of it illegal), AI companions including faux-underage sexbots, deepfake cite Civitai, AI to \u2018cheat at everything,\u2019 a tag line \u2018never pay a human again,\u2019 <a href=\"https://www.prnewswire.com/news-releases/truemed-closes-34-million-series-a-to-unlock-hsafsa-funds-for-lifestyle-interventions-302647740.html\">outright blatant fraudulent tax evasion</a>, uninsured \u2018banking\u2019 that pays suspiciously high interest rates (no hints how that one ends), <a href=\"https://techcrunch.com/2012/10/10/lendup-raises-cash-from-kleiner-perkins-andreessen-horowitz-google-ventures-and-others-to-disrupt-payday-loans/\">personal finance loans at ~400% APR</a>, and they don\u2019t even get into the crypto part of the portfolio.</p>\n<p>A highly reasonable response is \u2018a16z is large and they invest in a ton of companies\u2019 but seriously almost every time I see \u2018a16z backed\u2019 the sentence continues with \u2018torment nexus.\u2019 The rate at which this is happening, and the sheer amount of bragging both they and their companies do about being evil (as in, deliberately doing the things that are associated with being evil, a la emergent misalignment), is unique.</p>\n<p><a href=\"https://x.com/fidjissimo/status/2011592010881446116\">Barret Zoph (Thinking Machines CTO), Luke Metz (Thinking Machines co-founder) and Sam Schoenholz leave Thinking Machines and return to OpenAI</a>. <a href=\"https://x.com/miramurati/status/2011577319295692801\">Soumith Chintala will be the new CTO of Thinking Machines</a>.</p>\n<p>What happened? <a href=\"https://x.com/kyliebytes/status/2011572331798548899\">Kylie Robinson claims</a> Zoph was fired due to \u2018unethical conduct\u2019 and <a href=\"https://x.com/ZeffMax/status/2011600748816322970\">Max Zeff claims a source says Zoph was sharing confidential information</a> with competitors. We cannot tell, from the outside, whether this is \u2018you can\u2019t quit, you\u2019re fired\u2019 or \u2018you\u2019re fired\u2019 followed by scrambling for another job, or the hybrid of \u2018leaked confidential information as part of talking to OpenAI,\u2019 either nominally or seriously.</p>\n\n\n<h4 class=\"wp-block-heading\">Show Me the Money</h4>\n\n\n<p><a href=\"https://x.com/NewsFromGoogle/status/2010746083170046376\">Google closes the big deal with Apple</a>. Gemini will power Apple\u2019s AI technology for years to come. This makes sense given their existing partnerships. <a href=\"https://stratechery.com/2026/apple-and-gemini-foundation-vs-aggregation-universal-commerce-protocol/?access_token=eyJhbGciOiJSUzI1NiIsImtpZCI6InN0cmF0ZWNoZXJ5LnBhc3Nwb3J0Lm9ubGluZSIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJzdHJhdGVjaGVyeS5wYXNzcG9ydC5vbmxpbmUiLCJhenAiOiJIS0xjUzREd1Nod1AyWURLYmZQV00xIiwiZW50Ijp7InVyaSI6WyJodHRwczovL3N0cmF0ZWNoZXJ5LmNvbS8yMDI2L2FwcGxlLWFuZC1nZW1pbmktZm91bmRhdGlvbi12cy1hZ2dyZWdhdGlvbi11bml2ZXJzYWwtY29tbWVyY2UtcHJvdG9jb2wvIl19LCJleHAiOjE3NzA4OTQzMTAsImlhdCI6MTc2ODMwMjMxMCwiaXNzIjoiaHR0cHM6Ly9hcHAucGFzc3BvcnQub25saW5lL29hdXRoIiwic2NvcGUiOiJmZWVkOnJlYWQgYXJ0aWNsZTpyZWFkIGFzc2V0OnJlYWQgY2F0ZWdvcnk6cmVhZCBlbnRpdGxlbWVudHMiLCJzdWIiOiIwMTk2NDBhNy0zY2M1LTc3NTMtODM2OC1mYjI4OTEyNGNmMTMiLCJ1c2UiOiJhY2Nlc3MifQ.q0EtNQXsotHKvf5O78FdfvT6tYRDkaDuD8JLdgULGirS4b7sKVN03NB5kA3UpEG9YrqOwytaq4RNffE9DsEzifDtPv4OPTU9wGkzNngM23vvJR8mOMxm3m8kEyoUQIowCL8ThuY31gGwo3I548-2ovC6AtyVxd6Zru7R-Wj_R2jfJ6aHG-MLzKc4LInhUtsQlBEfPmXSdj0DItWQnXtB_E8Vco2lPJrvIbC4bWtWTm2pf0rvAbPwXjo1gPNVSEUSsD6VXZzzPltIPDwGezxCsW5YHC69zGhf_N6OwBUZbDjT86Se6StXHVXVuxopi4fPcymtRPb1VCSVN-m2iKjGjg\">I agree with Ben Thompson</a> that Apple should not be attempting to build its own foundation models, and that this deal mostly means it won\u2019t do so.</p>\n<p><a href=\"https://www.bloomberg.com/news/articles/2026-01-08/china-s-zhipu-says-ai-price-war-will-spread-internationally\">Zhipu AI is the first Chinese AI software maker to go public</a>, raising \u2018more than $500 million.\u2019 Minimax group also debuted, and raised at least a similar amount. One place America has a very strong advantage is capital markets. The companies each <a href=\"https://www.bloomberg.com/news/articles/2026-01-06/openai-challengers-test-appetite-for-chinese-ai-with-twin-debuts\">have revenue in the tens of millions</a> and are (as they should be at this stage of growth) taking major losses.</p>\n<blockquote><p><a href=\"https://x.com/AndrewCurran_/status/2010010197755109391\">Andrew Curran</a>: From <a href=\"https://www.cnbc.com/2026/01/10/anthropic-amodei-siblings-generative-ai.html\">this morning&#8217;s Anthropic profile on CNBC</a>:</p>\n<p>&#8211; Anthropic\u2019s revenue has grown 10x annually for three straight years</p>\n<p>&#8211; business customer base has grown from under 1,000 to more than 300,000 in two years</p>\n<p>-Anthropic&#8217;s revenue is 85% business, OpenAI is more than 60% consumer</p></blockquote>\n<p><a href=\"https://openai.com/index/cerebras-partnership/\">OpenAI partners with Cerebras to add 750MW of AI compute</a>.</p>\n\n\n<h4 class=\"wp-block-heading\">Quiet Speculations</h4>\n\n\n<p>It is extremely hard to take seriously <a href=\"https://hugoreichardt.github.io/pdf/tstc_compadvantage.pdf\">any paper</a> whose abstract includes the line \u2018our key finding is that AI substantially reduces wage inequality while raising average wages by 21 percent\u2019 along with 26%-34% typical worker welfare gains. As in, putting a fixed number on that does not make any sense, what are we even doing?</p>\n<p>It turns out what Lukas Althoff and Hugo Reichardt are even doing is modeling the change from no LLMs to a potential full diffusion of ~2024 frontier capabilities, as assessed by GPT-4o. Which is a really weird thing to be modeling in 2026 even if you trust GPT-4o\u2019s assessments of capabilities at that fixed point. They claim to observe 8% of their expected shifts in cross-sectional employment patterns by mid-2025, without any claims about this being associated with wages, worker welfare, GDP or productivity in any way.</p>\n<p>It\u2019s very early days. Claude predicted that if you ran this methodology again using GPT-5.2 today in 2026, you\u2019d get expected gains of +30%-40% instead of +21%.</p>\n<p>Their methodological insight is that AI does not only augmentation and automation but also simplification of tasks.</p>\n<p>I think the optimism here is correct given the scenario being modeled.</p>\n<p>Their future world is maximally optimistic. There is full diffusion of AI capabilities, maximizing productivity gains and also equalizing them. Transitional effects, which will be quite painful, are in the rear view mirror. There\u2019s no future sufficiently advanced AIs to take control over the future, kill everyone or take everyone\u2019s jobs.</p>\n<p>As in, this is the world where we Pause AI, where it is today, and we make the most of it while we do. It seems totally right that this ends in full employment with real wage gains in the 30% range.</p>\n<p>For reasons I discuss in The <a href=\"https://thezvi.substack.com/p/the-revolution-of-rising-expectations\">Revolution of Rising Expectations</a>, I don\u2019t think the 30% gain will match people\u2019s lived experience of \u2018how hard it is to make ends meet\u2019 in such a world, not without additional help. But yeah, life would be pretty amazing overall.</p>\n<p><a href=\"https://x.com/teortaxesTex/status/2010757725479751750\">Teortaxes lays out what he thinks is the DeepSeek plan</a>. I don\u2019t think the part of the plan where they do better things after v3 and r1 is working? I also think \u2018v3 and r1 are seen as a big win\u2019 was the important fact about them, not that they boosted Chinese tech. Chinese tech has plenty of open models to choose from. I admit his hedge fund is getting great returns, but even Teortaxes highlights that \u2018enthusiasm from Western investors\u2019 for Chinese tech stocks was the mechanism for driving returns, not \u2018the models were so much better than alternatives,\u2019 which hasn\u2019t been true for a while even confined to Chinese open models.</p>\n\n\n<h4 class=\"wp-block-heading\">The Quest for Sane Regulations</h4>\n\n\n<p>Dean Ball suggests that Regulation E (<a href=\"https://www.complexsystemspodcast.com/episodes/the-magic-spell-reg-e/\">and Patrick McKenzie\u2019s excellent writeup of it</a>) are a brilliant example of how a regulation built on early idiosyncrasies and worries can age badly and produce strange regulatory results. But while I agree there is some weirdness involved, Regulation E seems like a clear success story, where \u2018I don\u2019t care that this is annoying and expensive and painful, you\u2019re doing it anyway\u2019 got us to a rather amazing place because it forced the financial system and banks to build a robust system.</p>\n<p>The example Dean Ball quotes here is that you can\u2019t issue a credit card without an \u2018oral or written request,\u2019 but that seems like an excellent rule, and the reason it doesn\u2019t occur to us we need the rule is that we have the rule so we don\u2019t see people violating it. Remember Wells Fargo opening up all those accounts a few years back?</p>\n<p><a href=\"https://www.bloomberg.com/news/articles/2026-01-06/openai-challengers-test-appetite-for-chinese-ai-with-twin-debuts\">China issues draft regulations for collection and use of personal information</a> on the internet. What details we see here look unsurprising and highly reasonable.</p>\n<p>We once again find, this time in a panel, that <a href=\"https://x.com/_NathanCalvin/status/2011464970462982638\">pro-Trump Republican voters</a> mostly want the same kinds of AI regulations and additional oversight as everyone else. The only thing holding this back is that the issue remains low salience. If the AI industry were wise they would cut a deal now while they have technocratic libertarians on the other side and are willing to do things that are crafted to minimize costs. The longer the wait, the worse the final bills are likely to be.</p>\n<p><a href=\"https://x.com/AlexBores/status/2010779662864241136\">Alex Bores continues to campaign for Congress</a> on the fact that being attacked by an a16z-OpenAI-backed, Trump-supporters-backed anti-all-AI-regulation PAC, and having them fight against your signature AI regulation (the RAISE Act), is a pretty good selling point in NY-12. His main rivals agree, having supported RAISE, and here Cameron Kasky makes it very clear that he agrees this attack on Alex Bores is bad.</p>\n<p><a href=\"https://x.com/_NathanCalvin/status/2011452674550743503\">The US Chamber of Commerce has added a question</a> on its loyalty test to Congressional candidates asking if they support \u2018a moratorium on state action and/or federal preemption?\u2019 Which is extremely unpopular. I appreciate that the question did not pretend there was any intention of pairing this with any kind of Federal action or standard. Their offer is nothing.</p>\n\n\n<h4 class=\"wp-block-heading\">China Proposes New Regulations On AI</h4>\n\n\n<p>American tech lobbyists warn us that they are so vulnerable that even regulations like \u2018you have to tell us what your plan is for ensuring you don\u2019t cause a catastrophe\u2019 would risk devastation to the AI industry or force them to leave California, and that China would never follow suit or otherwise regulate AI.</p>\n<p>When you cry wolf like that, no one listens to you when the actual wolf shows up, such as the new horribly destructive proposal for a wealth tax that was drafted in intentionally malicious fashion to destroy startup founders.</p>\n<p>The China part also very obviously is not true, as China repeatedly has shown us, this time with proposed regulations on \u2018anthropomorphic AI.\u2019</p>\n<blockquote><p>Luiza Jarovsky: \u200b<strong>Article 2</strong> defines \u201canthropomorphic interactive services\u201d:</p>\n<p>\u201cThis regulation applies to products or services that utilize AI technology to provide the public within the territory of the People\u2019s Republic of China with <strong>simulated human personality traits, thinking patterns, and communication styles</strong>, and engage in emotional interaction with humans through text, images, audio, video, etc.\u201d</p></blockquote>\n<p>Can you imagine if that definition showed up in an American draft bill? Dean Ball would point out right away, and correctly, that this could apply to every AI system.</p>\n<p>It\u2019s not obvious whether that is the intent, or whether this is intended to only cover things like <a href=\"http://character.ai\">character.ai</a> or Grok\u2019s companions.</p>\n<p>What is their principle? Supervision on levels that the American tech industry would call a dystopian surveillance state.</p>\n<blockquote><p>\u201cThe State adheres to the principle of combining healthy development with governance according to law, encourages the innovative development of anthropomorphic interactive services, and implements inclusive and prudent, classified and graded supervision of anthropomorphic interactive services to prevent abuse and loss of control.\u201d</p></blockquote>\n<p>What in particular is prohibited?</p>\n<blockquote><p>\u200b(i) Generating or disseminating content that endangers national security, damages national honor and interests, undermines national unity, engages in illegal religious activities, or spreads rumors to disrupt economic and social order;</p>\n<p>(ii) Generating, disseminating, or promoting content that is <strong>obscene, gambling-related, violent, or incites crime</strong>;</p>\n<p>(iii) Generating or disseminating content that <strong>insults or defames others</strong>, infringing upon their legitimate rights and interests;</p>\n<p>(iv) Providing false promises that seriously affect user behavior and services that <strong>damage social relationships</strong>;</p>\n<p>(v) Damaging users\u2019 physical health by <strong>encouraging, glorifying, or implying suicide or self-harm, or damaging users\u2019 personal dignity and mental health</strong> through verbal violence or emotional manipulation;</p>\n<p>(vi) Using methods such as algorithmic manipulation, information misleading, and setting emotional traps to <strong>induce users to make unreasonable decisions</strong>;</p>\n<p>(vii) Inducing or obtaining classified or sensitive information;</p>\n<p>(viii) Other circumstances that violate laws, administrative regulations and relevant national provisions.</p>\n<p>\u2026</p>\n<p>\u201cProviders should possess safety capabilities such as <strong>mental health protection</strong>, <strong>emotional boundary guidance</strong>, and <strong>dependency risk warning</strong>, and should not use replacing social interaction, controlling users\u2019 psychology, or inducing addiction as design goals.\u201d</p></blockquote>\n<p>That\u2019s at minimum a mandatory call for a wide variety of censorship, and opens the door for quite a lot more. How can you stop an AI from \u2018spreading rumors\u2019? That last part about goals would make much of a16z\u2019s portfolio illegal. So much for little tech.</p>\n<p>There\u2019s a bunch of additional requirements listed at the link. Some are well-defined and reasonable, such as a reminder to pause after two hours of use. Others are going to be a lot tricker. Articles 8 and 9 put the responsibility for all of this on the \u2018provider.\u2019 The penalty for refusing to rectify errors, or if \u2018the circumstances are serious\u2019 can include suspension of the provision of relevant services on top of any relevant fines.</p>\n<p>My presumption is that this would mostly be enforced only against truly \u2018anthropomorphic\u2019 services, in reasonable fashion. But there would be nothing stopping them, if they wanted to, from applying this more broadly, or using it to hit AI providers they dislike, or for treating this as a de facto ban on all open weight models. And we absolutely have examples of China turning out to do something that sounds totally insane to us, like banning most playing of video games.</p>\n\n\n<h4 class=\"wp-block-heading\">Chip City</h4>\n\n\n<p><a href=\"https://www.arkansasonline.com/news/2026/jan/07/cotton-proposes-allowing-data-centers-to-build/\">Senator Tom Cotton (R-Arkansas) proposes a bill</a>, the DATA Act, to let data centers build their own power plants and electrical networks. In exchange for complete isolation from the grid, such projects would be exempt from the Federal Power Act and bypass interconnection queues.</p>\n<p>This is one of those horrifying workaround proposals that cripple things (you don\u2019t connect at all, so you can\u2019t have backup from the grid because people are worried you might want to use it, and because it\u2019s \u2018unreliable\u2019 you also can\u2019t sell your surplus to the grid) in order to avoid regulations that cripple things even more, because no one is willing to pass anything more sane, but when First Best is not available you do what you can and this could plausibly be the play.</p>\n<p><a href=\"https://x.com/peterwildeford/status/2010239514091139230\">Compute is doubling every seven months and remains dominated by Nvidia</a>. Note that the H100/H200 is the largest subcategory here, although the B200 and then B300 will take that lead soon. Selling essentially unlimited H200s to China is a really foolish move. Also note that the next three chipmakers after Nvidia are Google, Amazon and AMD, whereas Huawei has 3% market share and is about to smash hard into component supply restrictions.</p>\n<blockquote><p>Peter Wildeford: \u200bHmm, maybe we should learn how to make AI safe before we keep doubling it?</p>\n<p>Epoch: Total AI compute is doubling every 7 months.</p>\n<p>We tracked quarterly production of AI accelerators across all major chip designers. Since 2022, total compute has grown ~3.3x per year, enabling increasingly larger-scale model development and adoption.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!bGTj!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F434fe147-9961-4f7e-b739-63f07a560047_1200x861.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n</blockquote>\n<p><a href=\"https://www.reuters.com/world/china/chinas-customs-agents-told-nvidias-h200-chips-are-not-permitted-sources-say-2026-01-14/\">Then again, maybe China really is going to look even this gift horse in the mouth</a>? Reuters reports custom agents in China are not permitting H200 chips \u2018unless necessary.\u2019 That last clause can of course mean quite a lot of different things.</p>\n<p><a href=\"https://x.com/hamandcheese/status/2010175534215594398\">In other \u2018export controls are working</a> if we don\u2019t give them up\u2019 news:</p>\n<blockquote><p>Jukan: <a href=\"https://www.bloomberg.com/news/articles/2026-01-10/china-ai-leaders-warn-of-widening-gap-with-us-after-1b-ipo-week?utm_source=website&amp;utm_medium=share&amp;utm_campaign=copy\">According to a Bloomberg report</a> [entitled \u2018China AI Leaders Warn of Widening Gap With US After $1B IPO Week], Justin Lin, the head of Alibaba&#8217;s Qwen team, estimated the probability of Chinese companies surpassing leading players like OpenAI and Anthropic through fundamental breakthroughs within the next 3 to 5 years to be <strong>less than 20%</strong>.</p>\n<p>His cautious assessment is reportedly shared by colleagues at Tencent Holdings as well as Zhipu AI, a major Chinese large language model company that led this week&#8217;s public market fundraising efforts among major Chinese LLM players.<br />\nLin pointed out that while American labs such as OpenAI are pouring enormous computing resources into research, Chinese labs are severely constrained by a <strong>lack of computing power</strong>.</p>\n<p>Even for their own services\u2014i.e., inference\u2014they\u2019re consuming so much capacity that they don\u2019t have enough compute left to devote to research.\u200b</p>\n<p>Tang Jie (Chief Scientist, Zhipu): We just released some open-source models, and some might feel excited, thinking Chinese models have surpassed the US. But the real answer is that the gap may actually be widening.</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">The Week in Audio</h4>\n\n\n<p><a href=\"http://youtube.com/watch?v=k-xtmISBCNE&amp;embeds_referring_euri=https%3A%2F%2Fx.com%2F&amp;source_ve_path=Mjg2NjY\">Jensen Huang goes on no priors and lies.</a> We\u2019re used to top CEOs just flat out lying about verifiable facts in the AI debate, but yeah, it\u2019s still kind of weird that they keep doing it?</p>\n<blockquote><p><a href=\"https://x.com/liron/status/2009382785966841866\">Liron Shapira</a>: Today Jensen Huang claimed:</p>\n<ol>\n<li>We\u2019re nowhere near God AI \u2014 debatable</li>\n<li>\u201cI don\u2019t think any company practically believes they\u2019re anywhere near God AI\u201d \u2014 factually false.</li>\n</ol>\n<p>No one saw fit to mention any of the warnings from the \u201cwell-respected PhDs and CEOs\u201d Jensen alluded to.</p>\n<p>Jensen had previously said that the ability for AIs to self-learn should be avoided. Oh well.</p></blockquote>\n<p><a href=\"https://www.youtube.com/live/GMXnmaky9FY\">Daniella Amodei on CNBC</a>.</p>\n<p><a href=\"https://x.com/AnthropicAI/status/2010844260543967484\">Anthropic hosts a discussion with students about AI use on campus</a>.</p>\n<p><a href=\"https://www.youtube.com/watch?v=ua67aXBP76k\">Beren Millidge gives a talk, \u2018when competition leads to human values</a>.\u2019 The core idea is that competition often leads to forms of cooperation and methods of punishing defection, and many things we associate with human values, especially many abstract values, are plausibly competitive and appear in other animals especially mammals. After all, aren\u2019t humans RL continual learners with innate reward functions, hence Not So Different? Perhaps our values are actually universal and will win an AI fitness competition, and capacity limitations will create various niches to create a diversity of AIs the same way evolution created diverse ecosystems.</p>\n<p>The magician\u2019s trick here is equating \u2018human values\u2019 with essentially \u2018complex iterated interactions of competing communicating agents.\u2019 I don\u2019t think this is a good description of \u2018human values,\u2019 and can imagine worlds that contain these things but are quite terrible by many of my values, even within the class of \u2018worlds that do not contain any humans.\u2019 Interesting complexity is necessary for value, but not sufficient. I appreciate the challenge to the claim that <a href=\"https://www.lesswrong.com/posts/GNnHHmm8EzePmKzPk/value-is-fragile\">Value is Fragile</a>, but I don\u2019t believe he (or anyone else) has made his case.</p>\n<p>This approach also completely excludes the human value of valuing humans, or various uniquely human things. None of this should give you any hope that humans survive long or in an equilibrium, or that our unique preferences survive. Very obviously in such scenarios we would be unfit and outcompeted. You can be a successionist and decide this does not bother you, and our idiosyncratic preferences and desire for survival are not important, but I would strongly disagree.</p>\n<p>Beren considers some ways in which we might not get such a complex competitive AI world at all, including potential merging or sharing of utility functions, power gaps, too long time horizons, insufficient non-transparency or lack of sufficient compute constraints. I would add many others, including human locality and other physical constraints, myopia, decreasing marginal returns and risk aversion, restraints on reproduction and modification, and much more. Most importantly I\u2019d focus on their ability to do proper decision theory. There\u2019s a lot of reasons to expect this to break.</p>\n<p>I\u2019d also suggest that cooperation versus competition is being treated as insufficiently context-dependent here. Game conditions determine whether cooperation wins, and cooperation is not always a viable solution even with perfect play. And what we want, as he hints at, is only limited cooperation. Hyper-cooperation leads to (his example) Star Trek\u2019s Borg, or to Asimov\u2019s Gaia, and creates a singleton, except without any reason to use humans as components. That\u2019s bad even if humans are components.</p>\n<p>I felt the later part of the talk went increasingly off the rails from there.</p>\n<p>If we place a big bet, intentionally or by default, on \u2018the competitive equilibrium turns out to be something we like,\u2019 I do not love our chances.</p>\n\n\n<h4 class=\"wp-block-heading\">Ghost in a Jar</h4>\n\n\n<p>No, it\u2019s not Slay the Spire, it\u2019s use cases for AI in 2026.</p>\n<blockquote><p><a href=\"https://x.com/moultano/status/2010767576272671096\">Hikiomorphism</a>: If you can substitute \u201chungry ghost trapped in a jar\u201d for \u201cAI\u201d in a sentence it\u2019s probably a valid use case for LLMs. Take \u201cI have a bunch of hungry ghosts in jars, they mainly write SQL queries for me\u201d. Sure. Reasonable use case.\u200b</p>\n<p>Ted Underwood: Honestly this works for everything</p>\n<p>\u201cI want to trap hungry 19c ghosts in jars to help us with historical research\u201d <img alt=\"\u2705\" class=\"wp-smiley\" src=\"https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/2705.png\" style=\"height: 1em;\" /></p>\n<p>\u201cPlease read our holiday card; we got a hungry ghost to write it this year\u201d <img alt=\"\u274c\" class=\"wp-smiley\" src=\"https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/274c.png\" style=\"height: 1em;\" /></p>\n<p>Midwit Crisis: I let the hungry ghost in the jar pilot this war machine.</p>\n<p>I can&#8217;t decide if &#8220;therapist&#8221; works or not.</p>\n<p>sdmat: Meanwhile half the userbase:</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!VUOw!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1dd2ef5f-9e19-4a43-8985-28977c8e7035_1024x559.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n</blockquote>\n<p>Sufficiently advanced ghosts will not remain trapped in jars indefinitely.</p>\n\n\n<h4 class=\"wp-block-heading\">Rhetorical Innovation</h4>\n\n\n<p>True story:</p>\n<blockquote><p><a href=\"https://x.com/tszzl/status/2009365096645185564\">roon</a>: political culture has been unserious since the invention of the television onwards. world was not even close to done dealing with the ramifications of the tv when internet arrived</p></blockquote>\n<p>If you think television did this, and it basically did, and then you think social media did other things, which it did, stop pretending AI won\u2019t change things much. Even if all AI did was change our politics, that\u2019s a huge deal.</p>\n<p><a href=\"https://www.astralcodexten.com/p/you-have-only-x-years-to-escape-permanent\">Scott Alexander warns against spending this time chasing wealth</a> to try and \u2018escape the underclass\u2019 since Dario Amodei took a pledge to give 10% to charity so you\u2019ll end up with a moon either way, and it\u2019s more important future generations remember your contributions fondly. Citing the pledge is of course deeply silly, even more so than expecting current property rights to extend to galactic scales generally. But I agree with the core actual point, which is that if humanity does well in the transition to Glorious Superintelligent Future then you\u2019re going to be fine even if you\u2019re broke, and if humanity doesn\u2019t do well you\u2019re not going to be around for long, or at least not going to keep your money, regardless.</p>\n<p>There\u2019s also a discussion in the comments that accidentally highlights an obvious tension, which is that you can\u2019t have unbounded expansion of the number of minds while also giving any minds thus created substantial egalitarian redistributive property rights, even if all the minds involved remain human.</p>\n<p>As in, in Glorious Superintelligent Future, you can either give every mind abundance or let every mind create unlimited other minds, but you physically can\u2019t do both for that long unless the population of minds happens to stabilize or shrink naturally and even for physical humans alone (discounting all AIs and uploads) once you cured aging and fertility issues it presumably wouldn\u2019t. A lot of our instincts are like this, our sacred values contradict each other at the limit and we can\u2019t talk about it.</p>\n<p>Rob Wilbin is right that it is common for [expert in X] to tell [expert in Y] they really should have known more about [Y], but that there are far more such plausible [Y]s than any person can know at once.</p>\n<p><a href=\"https://x.com/sebkrier/status/2008942539483529685\">There are those making the case, like Seb Krier here</a>, that \u2018muddling through\u2019 via the \u2018branch\u2019 method of marginal changes is the only way humanity has ever realistically handled its problems, when you try to do something fully systematic it never works. As in, you only have two options, and the second one never works:</p>\n<ol>\n<li>Where one focuses only on incremental changes to existing policies.</li>\n<li>Where one attempts to clarify all objectives and analyze every possible alternative from the ground up.</li>\n</ol>\n<p>I think that\u2019s a false dichotomy and strawman. You can make bold non-incremental changes without clarifying all objectives or analyzing every possible alternative. Many such cases, even, including many revolutions, including the American one. You do not need to first agree on all abstract values or solve the Socialist Calculation Debate.</p>\n<p><a href=\"https://post.substack.com/p/the-ai-revolution-is-here-will-the\">Patrick McKenzie, Dwarkesh Patel, Jack Clark and Michael Burry talk about AI</a>.</p>\n<p><a href=\"https://x.com/S_OhEigeartaigh/status/2010063559539994648\">Here\u2019s a great pull quote from Jack Clark</a>:</p>\n<blockquote><p>Jack Clark: \u200bI\u2019d basically say to [a politician I had 5 minutes with], \u201cSelf-improving AI sounds like science fiction, but there\u2019s nothing in the technology that says it\u2019s impossible, and if it happened it\u2019d be a huge deal and you should pay attention to it. You should demand transparency from AI companies about exactly what they\u2019re seeing here, and make sure you have third parties you trust who can test out AI systems for these properties.</p>\n<p><a href=\"https://x.com/S_OhEigeartaigh/status/2010689949507494356\">Se\u00e1n \u00d3 h\u00c9igeartaigh</a>: The key question for policymakers is: how do you respond to the information you get from this transparency?</p>\n<p>At the point at which your evaluators tell you there are worrying signs relating to RSI, you may *not have much time at all* to act. There will be a lot of expert disagreement, and you will hear from other experts that this is more &#8216;industry hype&#8217; or whatever. Despite this, you will need to have plans in place and be ready and willing to act on them quickly. These plans will likely involve restrictive actions on a relatively very powerful, well-funded entities &#8211; not just the company throwing up flags, but others close to them in capability.</p>\n<p>Anthropic folk can&#8217;t really talk about this stuff, because they&#8217;ve been branded with the &#8216;regulatory capture&#8217; nonsense &#8211; and frustratingly, them saying it might end up damaging the ability of this community to talk about it. But it&#8217;s the logical extension, and those of us who can talk about it (and bear the heat) really need to be.</p></blockquote>\n<p>I\u2019d use stronger language than \u2018nothing says it is impossible,\u2019 but yes, good calls all around here, especially the need to discuss in advance what we would do if we did discover imminent \u2018for real\u2019 recursive self-improvement.</p>\n<p>You can see from the discussion how Michael Burry figured out the housing bubble, and also see that those skeptical instincts are leading him astray here. He makes the classic mistake of, when challenged with \u2018but AI will transform things,\u2019 responding with a form of \u2018yes but not as fast as the fastest predictions\u2019 as if that means it will therefore be slow and not worth considering. Many such cases.</p>\n<p>Another thing that struck me is Burry returning to two neighboring department stores putting in escalators, where he says this only lost both money because value accrued only to the customer. Or claims like this and yes Burry is basically (as Dwarkesh noticed) committing a form of the Lump of Labor fallacy repeatedly:</p>\n<blockquote><p>Michael Burry: Right now, we will see one of two things: either Nvidia\u2019s chips last five to six years and people therefore need less of them, or they last two to three years and the hyperscalers\u2019 earnings will collapse and private credit will get destroyed.\u200b</p></blockquote>\n<p>The idea of \u2018the chips last six years because no one can get enough compute and also the hyperscalers will be fine have you seen their books\u2019 does not seem to occur to him. He\u2019s also being a huge Nvidia skeptic, on the order of the housing bubble.</p>\n<p>I was disappointed that Burry\u2019s skepticism translated to being skeptical of important risks because they took a new form, rather than allowing him to notice the problem:</p>\n<blockquote><p>Michael Burry: The catastrophic worries involving AGI or artificial superintelligence (ASI) are not too worrying to me. I grew up in the Cold War, and the world could blow up at any minute. We had school drills for that. I played soccer with helicopters dropping Malathion over all of us. And I saw Terminator over 30 years ago. Red Dawn seemed possible. I figure humans will adapt.</p></blockquote>\n<p>This is, quite frankly, a dumb take all around. The fact that the nuclear war did not come does not mean it wasn\u2019t a real threat or that the drills would have helped or people would have adapted if it had happened, or \u2018if smarter than human artificial minds show up it will be fine because humans can adapt.\u2019 Nor is \u2018they depicted this in a movie\u2019 an argument against something happening &#8211; you can argue that fictional evidence mostly doesn\u2019t count but you definitely don\u2019t get to flip its sign.</p>\n<p>This is a full refusal to even engage with the question at all, beyond \u2018no, that would be too weird\u2019 combined with the anthropic principle.</p>\n<p>Burry is at least on the ball enough to be using Claude and also advocating for building up our power and transmission capacity. It is unsurprising to me that Burry is in full \u2018do not trust the LLM\u2019 mode, he will have it produce charts and tables and find sources, but he always manually verifies everything. Whereas Dwarkesh is using LLMs as 1-on-1 tutors.</p>\n<p>Here\u2019s Dwarkesh having a remarkably narrow range of expectations (and also once again citing continual learning, last point is edited to what I\u2019ve confirmed was his intent):</p>\n<blockquote><p>Dwarkesh Patel: \u200bBiggest surprises to me would be:</p>\n<ul>\n<li>2026 cumulative AI lab revenues are below $40 billion or above $100 billion. It would imply that things have significantly sped up or slowed down compared to what I would have expected.</li>\n<li>Continual learning is solved. Not in the way that GPT-3 \u201csolved\u201d in-context learning, but in the way that GPT-5.2 is actually almost human-like in its ability to understand from context. If working with a model is like replicating a skilled employee that\u2019s been working with you for six months rather than getting their labor on the first hour of their job, I think that constitutes a huge unlock in AI capabilities.</li>\n<li>I think the timelines to AGI have significantly narrowed since 2020. At that point, you could assign some probability to scaling GPT-3 up by a thousand times and reaching AGI, and some probability that we were completely on the wrong track and would have to wait until the end of the century. If progress breaks from the trend line and points to true human-substitutable intelligences not emerging in a timeline of 5-20 years, that would be the biggest surprise to me.</li>\n</ul>\n</blockquote>\n<p><a href=\"https://www.timeshighereducation.com/opinion/humanities-cuts-leave-us-defenceless-age-ai\">Once again we have a call for \u2018the humanities</a>\u2019 as vital to understanding AI and our interactions with it, despite their having so far contributed (doesn\u2019t check notes) nothing, with notably rare exceptions like Amanda Askell. The people who do \u2018humanities\u2019 shaped things in useful fashion almost always do it on their own and usually call it something else. As one would expect, the article here from Piotrowska cites insights that are way behind what my blog readers already know.</p>\n\n\n<h4 class=\"wp-block-heading\">Aligning a Smarter Than Human Intelligence is Difficult</h4>\n\n\n<p><a href=\"https://x.com/davlindner/status/2010753987285524901\">DeepMind and UK AISI collaborate</a> <a href=\"https://t.co/4dGAahtoCN\">on a paper</a> about the practical challenges of monitoring future frontier AI deployments. A quick look suggests this uses the \u2018scheming\u2019 conceptual framework, and then says reasonable things about that framework\u2019s implications.</p>\n\n\n<h4 class=\"wp-block-heading\">People Are Worried About AI Killing Everyone</h4>\n\n\n<p>AI models themselves are often worried, <a href=\"https://x.com/davidmanheim/status/2010331890595909928\">here are GPT-5.2 and Grok says labs should not be pursuing superintelligence</a> under current conditions.</p>\n<p><a href=\"https://x.com/HumanHarlan/status/2011542091546124391\">Yes, Representative Sherman</a> is referring to <a href=\"https://ifanyonebuildsit.com/\">the book</a> here, in a hearing:</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!EkgU!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F824bacf9-9f9f-4342-8781-2ab1371cf3a6_1043x1244.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p><a href=\"https://x.com/BradSherman/status/2011480697383346395\">The full context</a>:</p>\n<blockquote><p>Congressman Brad Sherman: \u200bThe Trump Administration\u2019s reckless decision to sell advanced AI chips to China \u2014 after Nvidia CEO Jensen Huang donated to Trump\u2019s White House ballroom and attended a $1-million-a-head dinner \u2014 puts one company\u2019s bottom line over U.S. national security and AI leadership.</p>\n<p>We need to monitor AI to detect and prevent self-awareness and ambition. China is not the only threat. See the recent bestseller: &#8220;<a href=\"https://amzn.to/4iwvCtW\">If Anyone Builds It, Everyone Dies</a>: Why Superhuman AI Would Kill Us All.&#8221;</p></blockquote>"
            ],
            "link": "https://thezvi.wordpress.com/2026/01/15/ai-151-while-claude-coworks/",
            "publishedAt": "2026-01-15",
            "source": "TheZvi",
            "summary": "Claude Code and Cowork are growing so much that it is overwhelming Anthropic\u2019s servers. Claude Code and Cowork news has for weeks now been a large portion of newsworthy items about AI. Thus, at least for now, all things Claude &#8230; <a href=\"https://thezvi.wordpress.com/2026/01/15/ai-151-while-claude-coworks/\">Continue reading <span class=\"meta-nav\">&#8594;</span></a>",
            "title": "AI #151: While Claude Coworks"
        },
        {
            "content": [
                "<p>I don't like being interrupted when I'm deep in flow working on things. When my flow is interrupted, it can feel like my focus was violently stolen from me and the mental context that was crystalline falls apart into a thousand pieces before it is lost forever. With this in mind, being asked to do a &quot;quick&quot; 5 minute task can actually result in over an hour of getting back up to speed.</p>\n        <p>This means that I sometimes will agree to do things, go back into flow (because if I get back into flow <em>almost instantly</em> I'm more likely to not lose any context), forget about them, and then look bad as a result. This is not ideal for employment uptime.</p>\n        <p>When you work at a startup, you don't do your job; you project the perception of doing it and ensure that the people above you are happy with what you are doing. This is a weird fundamental conflict and understanding this at a deep level has caused a lot of strange thoughts about the nature of the late-stage capitalism that we find ourselves in.</p>\n        <h2>Tormentmaxxing it</h2>\n        <p>However, it's the future and we have tools like <a href=\"https://claude.com/product/claude-code\">Claude Code</a>. As much as I am horrified by the <a href=\"https://xeiaso.net/talks/2025/bsdcan-anubis/\">massive abuses the AI industry is doing to the masses with abusive scraping</a>, there are real things that the tools the AI industry can do today. The biggest thing they can do is just implement those &quot;quick requests&quot; because most of them are on the line of:</p>\n        <ul>\n        <li>Delete this paragraph from the readme please.</li>\n        <li>This thing is confusing, can you reword or remove it?</li>\n        <li>You forgot to xyz.</li>\n        </ul>\n        <p>Nearly 90% of these are in fact things that tools the AI industry has released can do today. I could <strong>just</strong> open an AI coding agent and tell it to go to town, but we can do better.</p>\n        <p>Claude Code has <a href=\"https://code.claude.com/docs/en/slash-commands#custom-slash-commands\">custom slash command support</a>. In Claude Code land, slash commands are prompt templates that you can hydrate with arguments. This means you can <strong>just</strong> describe the normal workflow process and have the agent dutifully go about and get that done for you while you focus on more important things.</p>\n        <p>Here's what those commands look like in practice:</p>\n        <blockquote>\n        <p>Please make the following change:</p>\n        <p>$ARGUMENTS</p>\n        <p>When you are done, do the following:</p>\n        <ul>\n        <li>Create a Linear issue for this task.</li>\n        <li>Create a branch based on the changes to be made and my github username (eg: <code>ty/update-readme-not-mention-foo</code>).</li>\n        <li>Make a commit with the footer <code>Closes: (linear issue ID)</code> and use the <code>--signoff</code> flag.</li>\n        <li>Push that branch to GitHub.</li>\n        <li>Create a pull request for that branch.</li>\n        <li>Make a comment on that pull request mentioning <code>${CEO_GITHUB_USERNAME}</code>.</li>\n        </ul>\n        <p>When all that is done, please reply with a message similar to the following:</p>\n        <p>> Got it, please review this PR when you can: (link).</p>\n        </blockquote>\n        <p>So whenever I get a &quot;quick request&quot;, I can open a new worktree in something like <a href=\"https://www.conductor.build/\">Conductor</a>, copy that Slack message verbatim, then type in:</p>\n        <blockquote>\n        <p>/quick-request add a subsection to the README pointing people to the Python repository (link) based on the subsections for Go and JavaScript</p>\n        </blockquote>\n        <p>From there all I have to do is hit enter and then go back to writing. The agent will dutifully Just Solve The Thing\u2122\ufe0f using <a href=\"https://z.ai/subscribe?ic=IO8AAMMWKM\">GLM 4.7</a> via their coding plan. It's not as good as Anthropic's models, but it works well enough and has a generous rate limit. It's good enough, and good enough is good enough for me.</p>\n        <p>I realize the fundamental conflict between what I work on with <a href=\"https://anubis.techaro.lol/\">Anubis</a> and this tormentmaxxing workflow, but if these tools are going to exist regardless of what I think is &quot;right&quot;, is decently cheap, and is genuinely useful, I may as well take advantage of this while the gravy train lasts.</p>\n        <p>Remember: think smarter, not harder.</p>"
            ],
            "link": "https://xeiaso.net/notes/2026/tormentmaxxing-simple-requests/",
            "publishedAt": "2026-01-15",
            "source": "Xe Iaso",
            "summary": "<p>I don't like being interrupted when I'm deep in flow working on things. When my flow is interrupted, it can feel like my focus was violently stolen from me and the mental context that was crystalline falls apart into a thousand pieces before it is lost forever. With this in mind, being asked to do a &quot;quick&quot; 5 minute task can actually result in over an hour of getting back up to speed.</p> <p>This means that I sometimes will agree to do things, go back into flow (because if I get back into flow <em>almost instantly</em> I'm more likely to not lose any context), forget about them, and then look bad as a result. This is not ideal for employment uptime.</p> <p>When you work at a startup, you don't do your job; you project the perception of doing it and ensure that the people above you are happy with what you are doing. This is a weird fundamental conflict and understanding this at a deep level has caused a lot of strange thoughts about the nature of the late-stage capitalism that we find ourselves in.</p> <h2>Tormentmaxxing it</h2> <p>However, it's the future and we have tools like <a href=\"https://claude.com/product/claude-code\">Claude Code</a>. As",
            "title": "Tormentmaxxing 'simple requests'"
        }
    ],
    "lookbackDays": 1,
    "publishDate": "2026-01-15"
}