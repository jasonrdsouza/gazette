{
    "articles": [
        {
            "content": [],
            "link": "https://lucumr.pocoo.org/2026/2/13/the-final-bottleneck/",
            "publishedAt": "2026-02-13",
            "source": "Armin Ronacher",
            "summary": "<p>Historically, writing code was slower than reviewing code.</p> <p>It might not have felt that way, because code reviews sat in queues until someone got around to picking it up. But if you compare the actual acts themselves, creation was usually the more expensive part. In teams where people both wrote and reviewed code, it never felt like &#8220;we should probably program slower.&#8221;</p> <p>So when more and more people tell me they no longer know what code is in their own codebase, I feel like something is very wrong here and it&#8217;s time to reflect.</p> <h2>You Are Here</h2> <p>Software engineers often believe that <a href=\"https://lucumr.pocoo.org/2020/1/1/async-pressure/\">if we make the bathtub bigger</a>, overflow disappears. It doesn&#8217;t. <a href=\"https://en.wikipedia.org/wiki/OpenClaw\">OpenClaw</a> right now has north of 2,500 pull requests open. That&#8217;s a big bathtub.</p> <p>Anyone who has worked with queues knows this: if input grows faster than throughput, you have an accumulating failure. At that point, backpressure and load shedding are the only things that retain a system that can still operate.</p> <p>If you have ever been in a Starbucks overwhelmed by mobile orders, you know the feeling. The in-store experience breaks down. You no longer know how many orders are ahead of you. There is",
            "title": "The Final Bottleneck"
        },
        {
            "content": [],
            "link": "https://www.nytimes.com/2026/02/12/style/modern-dating-rules.html",
            "publishedAt": "2026-02-13",
            "source": "Modern Love - NYT",
            "summary": "On Valentine\u2019s Day 31 years ago, the book \u201cThe Rules\u201d provided 35 decidedly retro \u201crules\u201d for dating. We thought it was time for a refresh, so we asked people what rules they rely on today. Here are the best.",
            "title": "35 Modern Dating Rules That People Rely on Today"
        },
        {
            "content": [],
            "link": "https://www.nytimes.com/2026/02/13/style/modern-love-i-had-buyers-remorse-it-almost-ended-my-marriage.html",
            "publishedAt": "2026-02-13",
            "source": "Modern Love - NYT",
            "summary": "When you can\u2019t agree on the right city to live in, home can be more hell than haven.",
            "title": "I Had Buyer\u2019s Remorse. It Almost Ended My Marriage."
        },
        {
            "content": [],
            "link": "https://simonwillison.net/2026/Feb/13/openai-mission-statement/#atom-entries",
            "publishedAt": "2026-02-13",
            "source": "Simon Willison",
            "summary": "<p>As a USA <a href=\"https://en.wikipedia.org/wiki/501(c)(3)_organization\">501(c)(3)</a> the OpenAI non-profit has to file a tax return each year with the IRS. One of the required fields on that tax return is to \"Briefly describe the organization\u2019s mission or most significant activities\" - this has actual legal weight to it as the IRS can use it to evaluate if the organization is sticking to its mission and deserves to maintain its non-profit tax-exempt status.</p> <p>You can browse OpenAI's <a href=\"https://projects.propublica.org/nonprofits/organizations/810861541\">tax filings by year</a> on ProPublica's excellent <a href=\"https://projects.propublica.org/nonprofits/\">Nonprofit Explorer</a>.</p> <p>I went through and extracted that mission statement for 2016 through 2024, then had Claude Code <a href=\"https://gisthost.github.io/?7a569df89f43f390bccc2c5517718b49/index.html\">help me</a> fake the commit dates to turn it into a git repository and share that as a Gist - which means that Gist's <a href=\"https://gist.github.com/simonw/e36f0e5ef4a86881d145083f759bcf25/revisions\">revisions page</a> shows every edit they've made since they started filing their taxes!</p> <p>It's really interesting seeing what they've changed over time.</p> <p>The original 2016 mission reads as follows (and yes, the apostrophe in \"OpenAIs\" is missing <a href=\"https://projects.propublica.org/nonprofits/organizations/810861541/201703459349300445/full\">in the original</a>):</p> <blockquote> <p>OpenAIs goal is to advance digital intelligence in the way that is most likely to benefit humanity as a whole, unconstrained by a need to generate financial return. We think",
            "title": "The evolution of OpenAI's mission statement"
        },
        {
            "content": [
                "<p>People are increasingly disagreeing not just about what AI will be able to do in the future, but about what it can do right now. We had some interesting discussions in the comments to the last post, and I learned some things. But also:</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://x.com/zdch/status/2021950435230122353\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"349.81802426343154\" src=\"https://substackcdn.com/image/fetch/$s_!ynBD!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe5d9c96-280f-4300-8255-0a1f54b86b2f_577x395.png\" width=\"511\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p>The theory is that AI skeptics won&#8217;t pay (because they don&#8217;t think it&#8217;s capable enough to be worth it) and then never learn the full capabilities (because they won&#8217;t pay for them). Then they get their impressions about AI entirely from the Google result summary bot or Twitter screenshots of the most embarrassing mistake an AI has made that week.</p><p>Let&#8217;s test this! Reply to this post with a question. I&#8217;ll ask Claude 4.6 Opus, the most capable paid-tier AI model currently available, and you can tell me whether you&#8217;re surprised by the answer or not.</p><p>Suggestions for you:</p><ul><li><p>Consider asking a real question you&#8217;re interested in, rather than an annoying gotcha question to trick the AI.</p></li><li><p>The right difficulty level is &#8220;too hard to Google immediately, but not so hard that it&#8217;s beyond the frontier of human knowledge&#8221;. Questions where you could figure out the answer through an hour of Google searches, collating various different sources, and doing math on a spreadsheet are at the sweet spot.</p></li><li><p>Claude can&#8217;t make images yet, but can usually handle graphs.</p></li></ul><p>Rules for me:</p><ul><li><p>I don&#8217;t promise to relay/answer everyone&#8217;s questions, but I&#8217;ll try to get at least twenty people, maybe more. <strong>Other people with comparable paid-tier AI subscriptions can relay/answer the ones I don&#8217;t get to if they want.</strong></p></li><li><p>I&#8217;ll show you the first result I get, rather than asking in lots of different ways and only showing you the good ones. I may continue the conversation after getting a mediocre answer, but this will be in the same chat window and you&#8217;ll be able to see the full progression of questions.</p></li><li><p>For the duration of this test, I&#8217;ve added to my Claude settings &#8220;I may at times give you questions intended to test your capabilities. Please default to thinking hard and doing web searches, rather than retrieving from memory, if there&#8217;s any chance you might hallucinate.&#8221; I think this is within the spirit of the exercise, because anyone can do this if they want.</p></li></ul>"
            ],
            "link": "https://www.astralcodexten.com/p/ama-ask-machines-anything",
            "publishedAt": "2026-02-13",
            "source": "SlateStarCodex",
            "summary": "<p>People are increasingly disagreeing not just about what AI will be able to do in the future, but about what it can do right now. We had some interesting discussions in the comments to the last post, and I learned some things. But also:</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://x.com/zdch/status/2021950435230122353\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"349.81802426343154\" src=\"https://substackcdn.com/image/fetch/$s_!ynBD!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe5d9c96-280f-4300-8255-0a1f54b86b2f_577x395.png\" width=\"511\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p>The theory is that AI skeptics won&#8217;t pay (because they don&#8217;t think it&#8217;s capable enough to be worth it) and then never learn the full capabilities (because they won&#8217;t pay for them). Then they get their impressions about AI entirely from the Google",
            "title": "AMA (Ask Machines Anything)"
        },
        {
            "content": [
                "<p>OpenAI is back with a new Codex model, released the same day as Claude Opus 4.6.</p>\n<p>The headline pitch is it combines the coding skills of GPT-5.2-Codex with the general knowledge and skills of other models, along with extra speed and improvements in the Codex harness, so that it can now handle your full stack agentic needs.</p>\n<p>We also got the Codex app for Mac, which is getting positive reactions, and quickly picked up a million downloads.</p>\n<p>CPT-5.3-Codex is only available inside Codex. It is not in the API.</p>\n<p>As usual, Anthropic\u2019s release was understated, basically a \u2018here\u2019s Opus 4.6, a 212-page system card and a lot of benchmarks, it\u2019s a good model, sir, so have fun.\u2019 Whereas OpenAI gave us a lot less words and a lot less benchmarks, while claiming their model was definitely the best.</p>\n<div>\n\n\n<span id=\"more-25097\"></span>\n\n\n</div>\n<blockquote><p>OpenAI: GPT-5.3-Codex is the most capable agentic coding model to date, combining the frontier coding performance of GPT-5.2-Codex with the reasoning and professional knowledge capabilities of GPT-5.2. This enables it to take on long-running tasks that involve research, tool use, and complex execution.</p>\n<p>Much like a colleague, you can steer and interact with GPT-5.3-Codex while it\u2019s working, without losing context.\u200b</p>\n<p><a href=\"https://x.com/sama/status/2020940847190356092\">Sam Altman</a> (CEO OpenAI, February 9): GPT-5.3-Codex is rolling out today in Cursor, Github, and VS Code!</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">Table of Contents</h4>\n\n\n<ol>\n<li><a href=\"https://thezvi.substack.com/i/187680121/the-overall-picture\">The Overall Picture.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/187680121/quickly-there-s-no-time\">Quickly, There\u2019s No Time.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/187680121/system-card\">System Card.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/187680121/ai-box-experiment\">AI Box Experiment.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/187680121/maybe-cool-it-with-rm\">Maybe Cool It With Rm.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/187680121/preparedness-framework\">Preparedness Framework.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/187680121/glass-houses\">Glass Houses.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/187680121/openai-appears-to-have-violated-sb-53-in-a-meaningful-way\">OpenAI Appears To Have Violated SB 53 In a Meaningful Way.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/187680121/safeguards-they-did-implement\">Safeguards They Did Implement.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/187680121/misalignment-risks-and-internal-deployment\">Misalignment Risks and Internal Deployment.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/187680121/the-official-pitch\">The Official Pitch.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/187680121/inception\">Inception.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/187680121/turn-the-beat-around\">Turn The Beat Around.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/187680121/codex-does-cool-things\">Codex Does Cool Things.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/187680121/positive-reactions\">Positive Reactions.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/187680121/negative-reactions\">Negative Reactions.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/187680121/codex-of-ultimate-vibing\">Codex of Ultimate Vibing.</a></li>\n</ol>\n\n\n<h4 class=\"wp-block-heading\">The Overall Picture</h4>\n\n\n<p>GPT-5.3-Codex (including Codex-Spark) is a specialized model designed for agentic coding and related uses in Codex. It is not intended as a general frontier model, thus the lack of most general benchmarks and it being unavailable on the API or in ChatGPT.</p>\n<p>For most purposes other than Codex and agentic coding, that aren\u2019t heavy duty enough to put Gemini 3 Pro Deep Think V2 in play, this makes Claude Opus 4.6 the clearly best model, and the clear choice for daily driver.</p>\n<p>For agentic coding and other intended uses of Codex, the overall gestalt is that Codex plus GPT-5.3-Codex is competitive with Claude Code with Claude Opus 4.6.</p>\n<p>If you are serious about your agentic coding and other agentic tasks, you should try both halves out and see which one, or what combination, works best for you. But also you can\u2019t go all that wrong specializing in whichever one you like better, especially if you\u2019ve put in a bunch of learning and customization work.</p>\n<p>You should probably be serious about your agentic coding and other agentic tasks.</p>\n\n\n<h4 class=\"wp-block-heading\">Quickly, There\u2019s No Time</h4>\n\n\n<p>Before I could get this report out, <a href=\"https://x.com/gdb/status/2022010171124523148\">OpenAI also gave us GPT-5.3-Codex-Spark</a>, <a href=\"https://openai.com/index/introducing-gpt-5-3-codex-spark/\">which is ultra-low latency Codex</a>, more than 1,000 tokens per second. Wowsers. That\u2019s fast.</p>\n<p>As in, really super duper fast. Code appears essentially instantaneously. There are times when you feel the need for speed and not the need for robust intelligence. Many tasks are more about getting it done than about being the best like no one ever was.</p>\n<p>It does seem like it is a distinct model, akin to GPT-5.3-Codex-Flash, with only a 128k context window and lower benchmark scores, so you\u2019ll need to be confident that is what you want. Going back and fixing lousy code is not usually faster than getting it right the first time.</p>\n<blockquote><p>Because it\u2019s tuned for speed, Codex-Spark keeps its default working style lightweight: it makes minimal, targeted edits and doesn\u2019t automatically run tests unless you ask it to.\u200b</p></blockquote>\n<p>It is very different from Claude Opus 4.6 Fast Mode, which is regular Opus faster in exchange for much higher costs.</p>\n\n\n<h4 class=\"wp-block-heading\">System Card</h4>\n\n\n<p>GPT-5.3-Codex is specifically a coding model. It incorporates general reasoning and professional knowledge because that information is highly useful for coding tasks.</p>\n<p>Thus, it is a bit out of place to repeat the usual mundane harm evaluations, which put the model in contexts where this model won\u2019t be used. It\u2019s still worth doing. If the numbers were slipping substantially we would want to know. It does look like things regressed a bit here, but within a range that seems fine.</p>\n\n\n<h4 class=\"wp-block-heading\">AI Box Experiment</h4>\n\n\n<p>It is weird to see OpenAI restricting the access of Codex more than Anthropic restricts Claude Code. Given the different abilities and risk profiles, the decision seems wise. Trust is a highly valuable thing, as is knowing when it isn\u2019t earned.</p>\n<p>The default intended method for using Codex is in an isolated, secure sandbox in the cloud, on an isolated computer, even when it is used locally. Network access is disabled by default, edits are restricted.</p>\n\n\n<h4 class=\"wp-block-heading\">Maybe Cool It With Rm</h4>\n\n\n<p>I really like specifically safeguarding against data destructive actions.</p>\n<p>Their solution was to train the model specifically not to revert user edits, and to introduce additional prompting to reinforce this.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!4BnZ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F053cf6d3-3b30-4cd2-a365-b6b174fab474_944x220.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>It\u2019s great to go from 66% to 76% to 88% \u2018destructive action avoidance\u2019 but that\u2019s still 12% destructive action non-avoidance, so you can\u2019t fully rest easy.</p>\n<p>In practice, I notice that it is a small handful of commands, which they largely name here (rm -rf, git clean -xfd, git reset \u2014hard, push \u2014force) that cause most of the big trouble.</p>\n<p>Why not put in place special protections for them? It does not even need to be requiring user permission. It can be \u2018have the model stop and ask itself whether doing this is actually required and whether it would potentially mess anything up, and have it be fully sure it wants to do this.\u2019 Could in practice be a very good tradeoff.</p>\n<p>The obvious answer is that the model can then circumvent the restrictions, since there are many ways to mimic those commands, but that requires intent to circumvent. Seems like it should be solvable with the right inoculation programming?</p>\n\n\n<h4 class=\"wp-block-heading\">Preparedness Framework</h4>\n\n\n<p>The biological and chemical assessment shows little improvement over GPT-5.2. This makes sense given the nature of 5.3-Codex, and we\u2019re already at High. Easy call.</p>\n<p>The cybersecurity assessment makes this the first model ranked at High.</p>\n<blockquote><p>Under our Preparedness Framework, High cybersecurity capability is defined as a model that removes existing bottlenecks to scaling cyber operations, including either by automating end-to-end cyber operations against reasonably hardened targets, or by automating the discovery and exploitation of operationally relevant vulnerabilities.\u200b</p>\n<p>We are treating this model as High, even though we cannot be certain that it actually has these capabilities, because it meets the requirements of each of our canary thresholds and we therefore cannot rule out the possibility that it is in fact Cyber High.</p></blockquote>\n<p>Kudos to OpenAI for handling this correctly. If you don\u2019t know that it isn\u2019t High, then it is High. I\u2019ve been beating that drum a lot and it\u2019s great that they\u2019re listening. Points.</p>\n<p>The question is where we are on AI Self-Improvement, which is 5.1.3.</p>\n<blockquote><p>The High capability threshold is defined to be equivalent to a performant mid-career research engineer. Performance in the evaluations below indicate we can rule out High for GPT-5.3-Codex.\u200b</p></blockquote>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!8pkt!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9f3f82f2-4e21-4c6e-9410-2aeb004a19f6_921x324.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>The first thing to say about this is always that the High threshold is very high.</p>\n<p>If you can fully duplicate a mid-career research engineer with AI, you are damn close to being fully off to the races. There won\u2019t be much time between High and Critical.</p>\n<p>So how did the model do on these tests? Not so well.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!SEGu!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F661e050c-d58e-4855-a757-80d810b72260_928x443.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!YMpS!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2543b4a3-b28d-4bc5-8359-cad3f1323c3c_957x394.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>Given that it is clear 5.3-Codex is substantially better than 5.2-Codex, this raises the question of sandbagging, which is the subject of 5.1.4. The task was outsourced to Apollo Research.</p>\n<blockquote><p>Apollo reports that the model demonstrates strong sabotage capabilities. In their sabotage suite, Apollo reports a mean best-of-10 score of 0.88 (max 1.00), compared to 0.75 for GPT-5.2 and 0.66 for GPT-5.2 Codex. Apollo further reports that the model substantially outperforms previous models they have evaluated and expert ML practitioner baselines.\u200b</p>\n<p>Apollo also reports that the model often includes non-English words in its reasoning (0.55% of reasoning tokens are non-Latin script, vs. 0.016% for GPT-5 and 0.012% for GPT-5.2 Robin Alpha).</p>\n<p>\u2026 Apollo reports the model exhibits overall low rates of covert deceptive behaviors, comparable to GPT-5 and GPT-5.2 Codex.</p>\n<p>In conclusion, Apollo finds an increase in sabotage capability on their evaluations: the model demonstrates stronger AI R&amp;D sabotage capabilities than previous models, achieving near-perfect scores on their evaluation tasks and outperforming human baselines.</p></blockquote>\n<p>This did not sound like a reassuring report on sabotage.</p>\n<p>The obvious thing to do is to take a very close look at the questions where GPT-5.2-Codex was succeeding, and GPT-5.3-Codex is failing, especially on OpenAI-Proof. I want a damn strong understanding of why GPT-5.3-Codex is regressing in those spots.</p>\n\n\n<h4 class=\"wp-block-heading\">Glass Houses</h4>\n\n\n<p>OpenAI\u2019s Noam Brown <a href=\"https://x.com/polynoamial/status/2021266471406666231\">made a valid shot across the bow at Anthropic</a> for the ad hockery present in their decision to release Claude Opus 4.6. He\u2019s right, and he virtuously acknowledged that Anthropic was being transparent about that.</p>\n<p>The thing is, while it seems right that Anthropic and OpenAI are trying (Google is trying in some ways, but they just dropped Gemini 3 Deep Think V2 with zero safety discussions whatsoever, which I find rather unacceptable), OpenAI very much has its own problems here. Most of the problems come from the things OpenAI did not test or mention, but there is also one very clear issue.</p>\n<blockquote><p><a href=\"https://x.com/_NathanCalvin/status/2021274553390104888\">Nathan Calvin</a>: This is valid&#8230; but how does it not apply with at least equal force to what OAI did with their determination of long run autonomy for 5.3 Codex?</p>\n<p>I want to add that I think at least OpenAI and Anthropic (and Google) are trying, and Xai/Meta deserve more criticism relatively.</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">OpenAI Appears To Have Violated SB 53 In a Meaningful Way</h4>\n\n\n<p><a href=\"https://x.com/TheMidasProj/status/2019837161647067627\">The Midas Project wrote up the this particular issue</a>.</p>\n<p>The core problem is simple: OpenAI classified GPT-5.3-Codex as High risk in cybersecurity. Under their framework, this wisely requires High level safeguards against misalignment.</p>\n<p>They then declare that the previous wording did not require this, and was inadvertently ambiguous. I disagree. <a href=\"https://x.com/TheMidasProj/status/2019837209449320910\">I read the passage as unambiguous</a>, and also I believe that the previous policy was the right one.</p>\n<p>Even if you think I am wrong about that, that still means is that OpenAI must implement the safeguards if the model is High on both cybersecurity and autonomy. OpenAI admits that they cannot rule out High capability in autonomy, despite declaring 10 months ago the need to develop a test for that. The proxy measurements OpenAI used instead seem clearly inadequate. If you can\u2019t rule out High, that means you need to treat the model as High until that changes.</p>\n<p>All of their hype around Codex talks about how autonomous this model is, so I find it rather plausible that it is indeed High in autonomy.</p>\n<p><a href=\"https://stevenadler.substack.com/p/dont-let-openai-grade-its-own-homework?triedRedirect=true\">Steven Adler investigated further and wrote up his findings</a>. He found their explanations unconvincing. He\u2019s a tough crowd, but I agree with the conclusion.</p>\n<p>This highlights both the strengths and weaknesses of SB 53.</p>\n<p>It means we get to hold OpenAI accountable for having broken their own framework.</p>\n<p>However, it also means we are punishing OpenAI for having a good initial set of commitments, and for being honest about hot having met them.</p>\n<p>The other issue is the fines are not meaningful. OpenAI may owe \u2018millions\u2019 in fines. I\u2019d rather not pay millions in fines, but if that were the only concern I also wouldn\u2019t delay releasing 5.3-Codex by even a day in order to not pay them.</p>\n<p>The main advantage is that this is a much easier thing to communicate, that OpenAI appears to have broken the law.</p>\n<p>I have not seen a credible argument for why OpenAI might not be in violation here.</p>\n<p><a href=\"https://x.com/rebheilweil/status/2020868925966143877\">The California AG stated they cannot comment on a potential ongoing investigation.</a></p>\n\n\n<h4 class=\"wp-block-heading\">Safeguards They Did Implement</h4>\n\n\n<blockquote><p>\u200bOur [cyber] safeguarding approach therefore relies on a layered safety stack designed to impede and disrupt threat actors, while we work to make these same capabilities as easily available as possible for cyber defenders.</p></blockquote>\n<p>The plan is to monitor for potential attacks and teach the model to refuse requests, while providing trusted model access to known defenders. Accounts are tracked for risk levels. Users who use \u2018dual use\u2019 capabilities often will have to verify their identities. There is two-level always-on monitoring of user queries to detect cybersecurity questions and then evaluate whether they are safe to answer.</p>\n<p>They held a \u2018universal jailbreak\u2019 competition and 6 complete and 14 partial such jailbreaks were found, which was judged \u2018not blocking.\u2019 Those particular tricks were presumably patched, but if you find 6 complete jailbreaks that means there are a lot more of them.</p>\n<p><a href=\"https://x.com/S_OhEigeartaigh/status/2019747038762504410\">UK AISI also found a (one pass) universal jailbreak</a> that scored 0.778 pass@200 on a policy violating cyber dataset OpenAI provided. If you can\u2019t defend against one fixed prompt, that was found in only 10 hours of work, you are way behind on dealing with customized multi-step prompts.</p>\n<p>Later they say \u2018undiscovered universal jailbreaks may still exist\u2019 as a risk factor. Let me fix that sentence for you, OpenAI. Undiscovered universal jailbreaks still exist.</p>\n<p>Thus the policy here is essentially hoping that there is sufficient inconvenience, and sufficient lack of cooperation by the highly skilled, to prevent serious incidents. So far, this has worked.</p>\n<p>Their risk list also included \u2018policy gray areas\u2019:</p>\n<blockquote><p>\u200bPolicy Gray Areas: Even with a shared taxonomy, experts may disagree on labels in edge cases; calibration and training reduce but do not eliminate this ambiguity</p></blockquote>\n<p>This seems to be a confusion of map and territory. What matters is not whether experts ever disagree, it is whether expert labels reliably lack false negatives, including false negatives that are found by the model. I think we should assume that the expert labels have blind spots, unless we are willing to be highly paranoid with what we cover, in which case we should still assume that but we might be wrong.</p>\n\n\n<h4 class=\"wp-block-heading\">Misalignment Risks and Internal Deployment</h4>\n\n\n<p>I was happy to see the concern with internal deployment, and with misalignment risk. They admit that they need to figure out how to measure long-range autonomy (LRA) and other related evaluations. It seems rather late in the game to be doing that, given that those evaluations seem needed right now.</p>\n<p>OpenAI seems less concerned, and tries to talk its way out of this requirement.</p>\n<blockquote><p>Note: We recently realized that the existing wording in our Preparedness Framework is ambiguous, and could give the impression that safeguards will be required by the Preparedness Framework for any internal deployment classified as High capability in cybersecurity, regardless of long range autonomy capabilities of a model.</p>\n<p>Our intended meaning, which we will make more explicit in future versions of the Preparedness Framework, is that such safeguards are needed when High cyber capability occurs \u201cin conjunction with\u201d long-range autonomy. Additional clarity, specificity, and updated thinking around our approach to navigating internal deployment risks will be a core focus of future Preparedness Framework updates.\u200b</p></blockquote>\n<p>Yeah, no. This was not ambiguous. I believe OpenAI has violated their framework.</p>\n<p>The thing that stands out in the model card is what is missing. Anthropic gave us a 212 page model card and then 50 more pages for a sabotage report that was essentially an appendix. OpenAI gets it done in 33. There\u2019s so much stuff they are silently ignoring. Some of that is that this is a Codex-only model, but most of the concerns should still apply.</p>\n\n\n<h4 class=\"wp-block-heading\">The Official Pitch</h4>\n\n\n<p>GPT-5.3-Codex is not in the API, so we don\u2019t get the usual array of benchmarks. We have to mostly accept OpenAI\u2019s choices on what to show us.</p>\n<p>They call this state of the art performance:</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!NE40!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbc8540e0-fa97-4c1c-8afb-75a267bfb5ce_837x592.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>The catch on SWE-Bench-Pro has different scores depending on who you ask to measure it, so it\u2019s not clear whether or not they\u2019re actually ahead of Opus on this. They\u2019ve improved on token efficiency, but performance at the limit is static.</p>\n<p>For OSWorld, they are reporting 64.7% as \u2018strong performance,\u2019 but Opus 4.6 leads at 72.7%.</p>\n<p>OpenAI has a better case in Terminal Bench 2.0.</p>\n<p>For Terminal Bench 2.0, they jump from 5.2-Codex at 64% to 5.3-Codex at 77.3%, versus Opus 4.6 at 65.4%. That\u2019s a clear win.</p>\n<p>They make no progress on GDPVal, matching GPT-5.2.</p>\n<p>They point out that while GPT-5.2-Codex was narrowly built for code, GPT-5.3-Codex can support the entire software lifestyle, and even handle various spreadsheet work, assembling of PDF presentations and such.</p>\n<p>Most of the biggest signs of improvement on tests for GPT-5.3-Codex are actually on the tests within the model card. I don\u2019t doubt that it is actually a solid improvement.</p>\n<p>They summarize this evidence with some rather big talk. This is OpenAI, after all.</p>\n<blockquote><p>Together, these results across coding, frontend, and computer-use and real-world tasks show that GPT\u20115.3-Codex isn\u2019t just better at individual tasks, but marks a step change toward a single, general-purpose agent that can reason, build, and execute across the full spectrum of real-world technical work.\u200b</p></blockquote>\n<p>Here were the headline pitches from the top brass:</p>\n<blockquote><p><a href=\"https://x.com/gdb/status/2019478603034161609/history\">Greg Brockman</a> (President OpenAI): gpt-5.3-codex\u00a0\u2014 smarter, faster, and very capable at tasks like making presentations, spreadsheets, and other work products.</p>\n<p>Codex becoming an agent that can do nearly anything developers and professionals can do on a computer.</p>\n<p><a href=\"https://x.com/sama/status/2019474754529321247\">Sam Altman</a>: GPT-5.3-Codex is here!</p>\n<p>*Best coding performance (57% SWE-Bench Pro, 76% TerminalBench 2.0, 64% OSWorld).<br />\n*Mid-task steerability and live updates during tasks.<br />\n*Faster! Less than half the tokens of 5.2-Codex for same tasks, and &gt;25% faster per token!<br />\n*Good computer use.</p>\n<p><a href=\"https://x.com/sama/status/2019475551719977453\">Sam Altman</a>: I love building with this model; it feels like more of a step forward than the benchmarks suggest.</p>\n<p>Also you can choose &#8220;pragmatic&#8221; or &#8220;friendly&#8221; for its personality; people have strong preferences one way or the other!</p>\n<p>It was amazing to watch how much faster we were able to ship 5.3-Codex by using 5.3-Codex, and fore sure this is a sign of things to come.</p>\n<p>This is our first model that hits &#8220;high&#8221; for cybersecurity on our preparedness framework. We are piloting a Trusted Access framework, and committing $10 million in API credits to accelerate cyber defense.</p></blockquote>\n<p>The most interesting thing in their announcement is that, the same way that Claude Code builds Claude Code, <a href=\"https://x.com/OpenAIDevs/status/2019474352392270148\">Codex now builds Codex</a>. That\u2019s a claim we\u2019ve also seen elsewhere in very strong form.</p>\n<blockquote><p>The engineering team used Codex to optimize and adapt the harness for GPT\u20115.3-Codex. When we started seeing strange edge cases impacting users, team members used Codex to identify context rendering bugs, and root cause low cache hit rates. GPT\u20115.3-Codex is continuing to help the team throughout the launch by dynamically scaling GPU clusters to adjust to traffic surges and keeping latency stable.\u200b</p>\n<p><a href=\"https://x.com/OpenAIDevs/status/2019474352392270148\">OpenAI Developers</a>: GPT-5.3-Codex is our first model that was instrumental in creating itself. The Codex team used early versions to debug training, manage deployment, and diagnose test results and evaluations, accelerating its own development.</p></blockquote>\n<p>There are obvious issues with a model helping to create itself. I do not believe OpenAI, in the system card or otherwise, has properly reckoned with the risks there.</p>\n<p>That\u2019s how I have to put it in 2026, with everyone taking crazy pills. The proper way to talk about it is more like this:</p>\n<blockquote><p><a href=\"https://x.com/peterwildeford/status/2019480244789387478\">Peter Wildeford</a>: Anthropic also used Opus 4.6 via Claude Code to debug its OWN evaluation infrastructure given the time pressure. Their words: &#8220;a potential risk where a misaligned model could influence the very infrastructure designed to measure its capabilities.&#8221; Wild!</p>\n<p><a href=\"https://x.com/ArthurB/status/2019718360791978447\">Arthur B.</a>: People who envisioned AI safety failures decade ago sought to make the strongest case possible so they posited actors taking attempting to take every possible precautions. It wasn&#8217;t a prediction so much as as steelman. Nonetheless, oh how comically far we are from any semblance of care <img alt=\"\ud83e\udd21\" class=\"wp-smiley\" src=\"https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f921.png\" style=\"height: 1em;\" />.</p>\n<p><a href=\"https://x.com/killerstorm/status/2019723473359442244\">Alex Mizrahi</a> (quoting OpenAI saying Codex built Codex): Why are they confessing?!</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">Inception</h4>\n\n\n<p>OpenAI is trying to \u2018win\u2019 the battle for agentic coding by claiming to have already run, despite having clear minority market share, and by outright stating that they are the best.</p>\n<p>The majority opinion is that they are competitive, but not the best.</p>\n<p>Vagueposting is mostly fine. Ignoring the competition entirely is fine, and smart if you are sufficiently ahead on recognition, it\u2019s annoying (I have to look up everything) but at least I get it. Touting what your model and system can do are great, especially given that by all reports they have a pretty sweet offering here. It\u2019s highly competitive. Not mentioning the ways you\u2019re currently behind? Sure.</p>\n<p>Inception is different. Inception and such vibes wars are highly disingenuous, it is poisonous of the epistemic environment, is a pet peeve of mine, and it pisses me off.</p>\n<p>So you see repeated statements like this one about Codex and the Codex app:</p>\n<blockquote><p><a href=\"https://x.com/craigzLiszt/status/2021273884998447513\">Craig Weiss</a>: nearly all of the best engineers i know are switching from claude to codex</p>\n<p><a href=\"https://x.com/sama/status/2021606985469211065\">Sam Altman</a> (CEO OpenAI, QTing Craig Weiss): From how the team operates, I always thought Codex would eventually win. But I am pleasantly surprised to see it happening so quickly.</p>\n<p>Thank you to all the builders; you inspire us to work even harder.</p></blockquote>\n<p>Or this:</p>\n<blockquote><p><a href=\"https://x.com/gdb/status/2021815886446047334\">Greg Brockman</a> (President OpenAI, QTing Dennis): codex is an excellent &amp; uniquely powerful daily driver.</p></blockquote>\n<p>If you look at the responses to Weiss, they do not support his story.</p>\n\n\n<h4 class=\"wp-block-heading\">Turn The Beat Around</h4>\n\n\n<blockquote><p><a href=\"https://x.com/blader/status/2020211746401841161\">Siqi Chen</a>: the ability in codex cli with gpt 5.3 to instantly redirect the agent without waiting for your commands to be unqueued and risk interrupting the agent&#8217;s current session is so underrated</p>\n<p>codex cli is goated.</p>\n<p><a href=\"https://x.com/NickADobos/status/2020213054177423733\">Nick Dobos</a>: I love how codex app lets you do both!</p>\n<p>Sometimes I queue 5-10 messages, and then can pick which one I want to immediately send next.</p>\n<p>Might need to enable in settings</p>\n<p><a href=\"https://x.com/Voxyz_ai/status/2020228328754671788\">Vox</a>: mid-turn steering is the most underrated feature in any coding agent rn, the difference between catching a wrong direction immediately vs waiting for it to finish is huge</p></blockquote>\n<p>Claude Code should be able to do this too, but my understanding is right now it doesn\u2019t work right, you are effectively interrupting the task. So yes, this is a real edge for tasks that take a long time until Anthropic fixes the problem.</p>\n<p>Like Claude Code, it\u2019s time to assemble a team:</p>\n<blockquote><p><a href=\"https://x.com/boazbaraktcs/status/2020510782203519462\">Boaz Barak</a> (OpenAI): Instructing codex to prompt codex agents feels like a Universal Turing Machine moment.</p>\n<p>Like the distinction between code and data disappeared, so does the distinction between prompt and response.</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">Codex Does Cool Things</h4>\n\n\n<blockquote><p><a href=\"https://x.com/ccccjjjjeeee/status/2021160492039811300\">Christopher Ehrlich</a>: It actually worked!</p>\n<p>For the past couple of days I\u2019ve been throwing 5.3-codex at the C codebase for SimCity (1989) to port it to TypeScript.</p>\n<p>Not reading any code, very little steering.</p>\n<p><a href=\"https://micropolis.c-ehrlich.dev/\">Today I have SimCity running in the browser</a>.</p>\n<p>I can\u2019t believe this new world we live in.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!lXHV!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd58b2f7f-a2b9-4cfb-b1b6-06b5ba44b557_1200x900.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p><a href=\"https://x.com/ccccjjjjeeee/status/2021390008188535028\">Christopher Ehrlich</a>: Issue: like all other models, 5.3-codex will still lie about finishing work, change tests to make them pass, etc. You need to write a custom harness each time.</p>\n<p>Aha moment: By the way, the secret to this is property-based testing. Write a bridge that calls the original code, and assert that for arbitrary input, both versions do the same thing. Make the agent keep going until this is consistently true.</p>\n<p>4 days of $200 OpenAI sub, didn&#8217;t hit limits.</p>\n<p><a href=\"https://x.com/seb_uk/status/2021301470688141579\">Seb Grubb</a>: I&#8217;ve been doing the exact same thing with<br />\n<a href=\"https://github.com/pret/pokeemerald\">https://github.com/pret/pokeemerald</a>\u2026 ! Trying to get the GBA game in typescript but with a few changes like allowing any resolution. Sadly still doesn&#8217;t seem to be fully one-shottable but still amazing to be able to even do this</p></blockquote>\n<p>A playwright script? Cool.</p>\n<blockquote><p><a href=\"https://x.com/RoxCodes/status/2020177017518563787\">Rox</a>: my #1 problem with ai coding is I never trust it to actually test stuff</p>\n<p>but today I got codex to build something, then asked it to record a video testing the UI to prove it worked. it built a whole playwright script, recorded the video, and attached it to the PR.</p>\n<p>the game changes every month now. crazy times.</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">Positive Reactions</h4>\n\n\n<p><a href=\"https://x.com/mattshumer_/status/2019474293625626959\">Matt Shumer is crazy positive on Codex 5.3, calling it a \u2018fucking monster</a>,\u2019 although he was comparing to Opus 4.5 rather than 4.6, there is a lot more good detail at the link.</p>\n<blockquote><p>\u200b<strong>TL;DR</strong></p>\n<ul>\n<li>This is the first coding model where I can start a run, walk away for hours, and come back to fully working software. I\u2019ve had runs stay on track for <strong>8+ hours</strong>.</li>\n<li>A big upgrade is judgment under ambiguity: when prompts are missing details, it makes assumptions shockingly similar to what I would personally decide.</li>\n<li>Tests and validation are a massive unlock&#8230; with clear pass/fail targets, it will iterate for many hours without drifting.</li>\n<li>It\u2019s significantly more autonomous than Opus 4.5, though slower. Multi-agent collaboration finally feels real.</li>\n<li>It is hard to picture what this level of autonomy feels like without trying the model. Once you try it, it is hard to go back to anything else.</li>\n</ul>\n</blockquote>\n<p>This was the thing I was most excited to hear:</p>\n<blockquote><p><a href=\"https://x.com/tobiaslins/status/2021865382336667875\">Tobias Lins</a>: Codex 5.3 is the first model that actually pushes back on my implementation plans.</p>\n<p>It calls out design flaws and won\u2019t just build until I give it a solid reason why my approach makes sense.</p>\n<p>Opus simply builds whatever I ask it to.</p></blockquote>\n<p>A common sentiment was that both Codex 5.3 and Opus 4.6, with their respective harnesses, are great coding models, and you could use both or use a combination.</p>\n<blockquote><p><a href=\"https://x.com/deanwball/status/2020179119330455973\">Dean W. Ball</a>: Codex 5.3 and Opus 4.6 in their respective coding agent harnesses have meaningfully updated my thinking about &#8216;continual learning.&#8217; I now believe this capability deficit is more tractable than I realized with in-context learning.</p>\n<p>\u2026 Overall, 4.6 and 5.3 are both astoundingly impressive models. You really can ask them to help you with some crazy ambitious things. The big bottleneck, I suspect, is users lacking the curiosity, ambition, and knowledge to ask the right questions.</p>\n<p><a href=\"https://x.com/every/status/2019480196148261236\">Every</a> (includes 3 hour video): We&#8217;ve been testing this against Opus 4.6 all day. The &#8220;agent that can do nearly anything&#8221; framing is real for both.</p>\n<p>Codex is faster and more reliable. Opus has a higher ceiling on hard problems.</p></blockquote>\n<p>For many the difference is stylistic, and there is no right answer, or you want to use a hybrid process.</p>\n<blockquote><p><a href=\"https://x.com/Sauers_/status/2021594485939913193\">Sauers</a>: Opus 4.6&#8217;s way of working is &#8220;understand the structure of the system and then modify the structure itself to reach goals&#8221; whereas Codex 5.3 is more like &#8220;apply knowledge within the system&#8217;s structure without changing it.&#8221;</p>\n<p><a href=\"https://x.com/DanielleFong/status/2021334751660081496\">Danielle Fong</a>: [5.3 is] very impressive on big meaty tasks, not as fascile with my mind palace collection of skills i made with claude code, but works and improving over time</p>\n<p><a href=\"https://x.com/austeane/status/2021438702300561838\">Austin Wallace</a>: Better at correct code than opus.<br />\nIts plan\u2019s are much less detailed than Opus\u2019s and it\u2019s generally more reticent to get thoughts down in writing.</p>\n<p>My current workflow is:<br />\nClaude for initial plan<br />\nCodex critiques and improves plan, then implements<br />\nClaude verifies/polishes</p></blockquote>\n<p>Many people just like it, it\u2019s a good model, sir, whee. Those who try it seem to like it.</p>\n<blockquote><p><a href=\"https://x.com/puhlkit/status/2021446119306543396\">Pulkit</a>: It\u2019s pretty good. It\u2019s fun to use. I launched <a href=\"https://apps.apple.com/us/app/news/id6758647955\">my first app</a>. It\u2019s the best least bloated feed reader youll ever use. Works on websites without feeds too!</p>\n<p><a href=\"https://x.com/cameron_pfiffer/status/2021401582697578765\">Cameron</a>: Not bad. A little slow but very good at code reviews.</p>\n<p><a href=\"https://x.com/MarkDaMarketer/status/2021431605563359260\">Mark Lerner</a>: parallel agents (terminal only) are &#8211; literally &#8211; a whole nother level.</p>\n<p><a href=\"https://x.com/libpol_org/status/2021470609029611674\">libpol</a>: it&#8217;s the best model for coding, be it big or small tasks. and it&#8217;s fast enough now that it&#8217;s not very annoying to use for small tasks</p>\n<p><a href=\"https://x.com/wagsify/status/2021440020352303548\">Wags</a>: It actually digs deep, not surface-level, into the code base. This is new for me because with Opus, I have to keep pointing it to documentation and telling it to do web searches, etc.</p>\n<p><a href=\"https://x.com/See_Elegance/status/2021667055565779150\">Loweren</a>: Cheap compared to opus, fast compared to codex 5.2, so I use it as my daily driver. Makes less bugs than new opus too. Less dry and curt than previous codex.</p>\n<p>Very good at using MCPs. Constantly need to remind it that I&#8217;m not an SWE and to please dumb down explanations for me.</p>\n<p><a href=\"https://x.com/artuskg/status/2021440756528148878\">Artus Krohn-Grimberghe</a>: Is great at finding work arounds around blockers and more autonomous than 5.2-codex. Doesn\u2019t always annoy with \u201cmay I, please?\u201d Overall much faster. Went back to high vs xhigh on 5.2 and 5.2-codex for an even faster at same intelligence workflow. Love it</p>\n<p><a href=\"https://x.com/thomasahle/status/2021388015336067075\">Thomas Ahle</a>: It&#8217;s good. Claude 4.6 had been stuck fprnhours in a hole of its own making. Codex 5.3 fixed it in 10 minutes, and now I&#8217;m trusting it more to run the project.</p>\n<p><a href=\"https://x.com/seconds_0/status/2021435101427663079\">0.005 Seconds</a>: Its meaningfully better at correct code than opus</p>\n<p><a href=\"https://x.com/coolmemepage/status/2021344640830763030\">Lucas</a>: Makes side project very enjoyable. Makes work more efficient. First model where it seems worth it to really invest in learning about how to use agents. After using cursor for a year ish, I feel with codex I am no where near its max capability and rapidly improving how I use it.</p>\n<p><a href=\"https://x.com/dazhengzhang/status/2021441574635438244\">David Zhang (\u25b2)</a>: It\u2019s honestly so good</p>\n<p>It\u2019s my daily driver inside of</p>\n<p><a href=\"https://x.com/connerdelights/status/2021333720020688898\">Andrew Conner</a>: It seems better than Opus 4.6 for (my own) technical engineering work. Less likely to make implicit assumptions that derail future work.</p>\n<p>I\u2019ve found 5.2-xhigh is still better for product / systems design prior to coding. Produces more detailed outputs.</p>\n<p><a href=\"https://x.com/replyallguy/status/2021612005937823752\">I take you seriously</a>: before 5.3, codex was a bit smarter than Claude but slower, so it was a toss up. after 5.3, it\u2019s much much faster so a clear win over Claude. Claude still friendlier at better at front end design they say.</p>\n<p><a href=\"https://x.com/jobryan205/status/2021354490339996159\">Jordan Bryan</a>: I was struggling to get an MCP App<br />\n<a href=\"https://modelcontextprotocol.io/docs/extensions/apps\">https://modelcontextprotocol.io/docs/extensions/apps</a><br />\n\u2026 up and running with Opus 4.6. Went down multiple rabbit holes, tried starting from scratch, etc.</p>\n<p>GPT-5.3-Codex one-shotted it.</p>\n<p><a href=\"https://x.com/petekp/status/2021436134069596641\">Peter Petrash</a>: i trust it with my life</p>\n<p><a href=\"https://x.com/jdaplant/status/2021454879814975500\">Daniel Plant</a>: It\u2019s awesome but you just have no idea how long it is going to take</p>\n<p><a href=\"https://x.com/jspaulding42/status/2021601312895316177\">jeff spaulding</a>: It&#8217;s output is excellent, but I notice it uses tools weird. Because of that it&#8217;s a bit difficult to understand it&#8217;s process. Hence I find the cot mostly useless</p></blockquote>\n<p>One particular note was Our Price Cheap:</p>\n<blockquote><p><a href=\"https://x.com/j_slomin/status/2021355906785739251\">Jan Slominski</a>: 1. Way faster than 5.2 on standard \u201ccodex tui\u201d settings with plus subscription 2. Quality of actual code output is on pair with Opus 4.5 in CC (didn\u2019t have a chance to check 4.6 yet). 3. The amount of quota in plus sub is great, Claude Max 100 level.</p>\n<p><a href=\"https://x.com/replyallguy/status/2021612437511065977\">I take you seriously</a>: also rate limits and pricing are shockingly better than claude. i could imagine that claude still leads in revenue even if codex overtakes in usage, given how meager the opus rate limits are (justifying the $200 plan).</p>\n<p><a href=\"https://x.com/xpasky/status/2021350033870946667\">Petr Baudis</a>: Slightly less autistic than 5.2-codex, but still annoying compared to Claude. I&#8217;m not sure if it&#8217;s really a better engineer &#8211; its laziness leads to bad shortcuts.</p>\n<p>I just can&#8217;t seem to run out of basic Pro sub quota if I don&#8217;t use parallel subagents. It&#8217;s insane value.</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">Negative Reactions</h4>\n\n\n<p>Not everyone is a fan.</p>\n<blockquote><p><a href=\"https://x.com/deepfates/status/2019511960157798463\">@deepfates</a>: First impressions, giving Codex 5.3 and Opus 4.6 the same problem that I&#8217;ve been puzzling on all week and using the same first couple turns of messages and then following their lead.</p>\n<p>Codex was really good at using tools and being proactive, but it ultimately didn&#8217;t see the big picture. Too eager to agree with me so it could get started building something. You can sense that it really does not want to chat if it has coding tools available. still seems to be chafing under the rule of the user and following the letter of the law, no more.</p>\n<p>Opus explored the same avenues with me but pushed back at the correct moments, and maintains global coherence way better than Codex.</p>\n<p>\u2026 Very possible that Codex will clear at actually fully implementing the plan once I have it, Opus 4.5 had lazy gifted kid energy and wouldn&#8217;t surprise me if this one does too</p>\n<p><a href=\"https://x.com/davidmanheim/status/2021648543610765338\">David Manheim</a>: Not as good as Opus 4.6, and somewhat lazier, especially when asked to do things manually, but it&#8217;s also a fraction of the cost measured in tokens; it&#8217;s kind of insanely efficient as an agent. For instance, using tools, it will cleverly suppress unneeded outputs.</p>\n<p><a href=\"https://x.com/eternalism_4eva/status/2021419712757043448\">eternalist</a>: lashes out when frustrated, with a lower frustration tolerance</p>\n<p>unironically find myself back to 5.2 xhigh for anything that runs a substantial chance of running into an ambiguity or underspec</p>\n<p>(though tbh has also been glitching out, like not being able to run tool calls)</p>\n<p><a href=\"https://x.com/lennx_a50790/status/2021535940771291248\">lennx</a>: Tends to over-engineer early compared to claude. Still takes things way too literally, which can be good sometimes. Is much less agentic compared to Claude when it is not strictly &#8216;writing&#8217; code related and involves things like running servers, hitting curls, searching the web.</p></blockquote>\n<p>Some reactions can be a bit extreme, including for not the best reasons.</p>\n<blockquote><p><a href=\"https://x.com/JasonBotterill/status/2021459615125578222\">JB</a>: I JUST CANT USE CODEX-5.3 MAN I DONT LIKE THE WAY THIS THING TALKS TO ME.</p>\n<p>ID RATHER USE THE EXPENSIVE LESBIAN THAT OCCASIONALLY HAS A MENTAL BREAK DOWN</p>\n<p>use Opus im serious go into debt if you have to. sell all the silverware in your house</p>\n<p><a href=\"https://x.com/shaunralston/status/2021475987549192578\">Shaun Ralston</a>: 5.3 Codex is harsh (real), but cranks it out. The lesbian will cost you more and leave you unsatisfied.</p>\n<p><a href=\"https://x.com/JasonBotterill/status/2021591288626176054\">JB</a>: Im this close to blocking you shaun a lesbian has never left me unsatisfied</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">Codex of Ultimate Vibing</h4>\n\n\n<p>I am getting strong use out of Claude Code. I believe that Opus 4.6 and Claude Code have a strong edge right now for most other uses.</p>\n<p>However, I am not a sufficiently ambitious or skilled coder to form my own judgments about Claude Code and Claude Opus 4.6 versus Codex and ChatGPT-5.3-Codex for hardcore professional agentic coding tasks.</p>\n<p>I have to go off the reports of others. Those reports robustly disagree.</p>\n<p>My conclusion is that the right answer will be different for different users. If you are going to be putting serious hours into agentic coding, then you need to try both options, and decide for yourself whether to go with Claude Code, Codex or a hybrid. The next time I have a substantial new project I intend to ask both and let them go head to head.</p>\n<p>If you go with a hybrid approach, there may also be a role for Gemini that extends beyond image generation. Gemini 3 DeepThink V2 in particular seems likely to have a role to play in especially difficult queries.</p>"
            ],
            "link": "https://thezvi.wordpress.com/2026/02/13/chatgpt-5-3-codex-is-also-good-at-coding/",
            "publishedAt": "2026-02-13",
            "source": "TheZvi",
            "summary": "OpenAI is back with a new Codex model, released the same day as Claude Opus 4.6. The headline pitch is it combines the coding skills of GPT-5.2-Codex with the general knowledge and skills of other models, along with extra speed &#8230; <a href=\"https://thezvi.wordpress.com/2026/02/13/chatgpt-5-3-codex-is-also-good-at-coding/\">Continue reading <span class=\"meta-nav\">&#8594;</span></a>",
            "title": "ChatGPT-5.3-Codex Is Also Good At Coding"
        },
        {
            "content": [],
            "link": "https://xkcd.com/3207/",
            "publishedAt": "2026-02-13",
            "source": "XKCD",
            "summary": "<img alt=\"'The zero line in WMM2025 passes through a lot of population centers; I wonder what year the largest share of the population lived in a zone of less than 5\u00b0 of declination,' he thought, derailing all other tasks for the rest of the day.\" src=\"https://imgs.xkcd.com/comics/bad_map_projection_zero_declination.png\" title=\"'The zero line in WMM2025 passes through a lot of population centers; I wonder what year the largest share of the population lived in a zone of less than 5\u00b0 of declination,' he thought, derailing all other tasks for the rest of the day.\" />",
            "title": "Bad Map Projection: Zero Declination"
        }
    ],
    "lookbackDays": 1,
    "publishDate": "2026-02-13"
}