{
    "articles": [
        {
            "content": [],
            "link": "https://alexmolas.com/2025/08/11/search-with-lunr.html",
            "publishedAt": "2025-08-11",
            "source": "Alex Molas",
            "summary": "How I added fast, client\u2011side search to this site with Lunr.js and a build-time index.",
            "title": "Adding search to my static blog."
        },
        {
            "content": [
                "<div class=\"trix-content\">\n  <blockquote><em>One day, I got a chance. It just seemed to show up. It acted like it knew me, as if it wanted something.</em></blockquote><div><br />This is how Kobi Yamada's book <a href=\"https://www.amazon.com/What-Do-You-Chance/dp/1943200734/\"><em>What do you do with a chance?</em></a> starts. I've been reading that beautiful book to the boys at bedtime since it came out in 2018. It continues:<br /><br /></div><blockquote><em>It fluttered around me. It brushed up against me. It circled me as if it wanted me to grab it.</em></blockquote><div><br /></div><div>What a mesmerizing mental image of a chance, fluttering about.<br /><br /></div><div><em>What do you do with a chance?</em> is a great book exactly because it's not just for the boys, but for me too. A poetic reminder of what being open to chance looks like, and what to do when it shows up.&nbsp;<br /><br /></div><div>Right now, <a href=\"https://omarchy.org\">Omarchy</a> feels like that chance. Like Linux fluttered into my hands and said \"let's take a trip to the moon\".&nbsp;</div><div><br />I <a href=\"https://x.com/dhh/status/1954791471585874400\">joked on X</a> that perhaps it was the new creatine routine <a href=\"https://x.com/levelsio/status/1946710892193747020\">I picked up from Pieter Levels</a>, but I only started that a few days ago, so I really do think it's actually Linux!</div><div><br />This exhilaration of The Chance reminds me of the 1986 cult classic <em>Highlander</em>. There's a fantastic montage in the middle where Sean Connery is teaching Christopher Lambert to fight for the prize of immortality, and in it, <a href=\"https://www.youtube.com/watch?v=cf6SaA-Kdro&amp;t=145s\">he talks about The Quickening</a>. Feeling the stag, feeling the opportunity.<br /><br /></div><div>That's the feeling I have when I wake up in the morning at the moment: The Quickening. There's something so exciting here, so energizing, that I simply must get to <a href=\"https://www.lofree.co/products/lofree-flow-the-smoothest-mechanical-keyboard\">the keyboard</a> and chase wherever it flutters to.<br /><br /></div><div>  <figure class=\"attachment attachment--preview attachment--lightboxable attachment--jpg\">\n      <a href=\"https://world.hey.com/dhh/24c0714b/blobs/eyJfcmFpbHMiOnsiZGF0YSI6MjIyMjQ1OTkzNywicHVyIjoiYmxvYl9pZCJ9fQ--7d44344ece1d191d26ce3729a3a3690f8c6bd4cdedb15139856ec1cc3a73cd85/screenshot-2025-08-11_09-20-52.jpg?disposition=attachment\" title=\"Download screenshot-2025-08-11_09-20-52.jpg\">\n        <img alt=\"screenshot-2025-08-11_09-20-52.jpg\" src=\"https://world.hey.com/dhh/24c0714b/representations/eyJfcmFpbHMiOnsiZGF0YSI6MjIyMjQ1OTkzNywicHVyIjoiYmxvYl9pZCJ9fQ--7d44344ece1d191d26ce3729a3a3690f8c6bd4cdedb15139856ec1cc3a73cd85/eyJfcmFpbHMiOnsiZGF0YSI6eyJmb3JtYXQiOiJqcGciLCJyZXNpemVfdG9fbGltaXQiOlszODQwLDI1NjBdLCJxdWFsaXR5Ijo2MCwibG9hZGVyIjp7InBhZ2UiOm51bGx9LCJjb2FsZXNjZSI6dHJ1ZX0sInB1ciI6InZhcmlhdGlvbiJ9fQ--b3779d742b3242a2a5284869a45b2a113e0c177f0450c29f0baca1ee780f6604/screenshot-2025-08-11_09-20-52.jpg\" />\n</a>\n  </figure></div>\n</div>"
            ],
            "link": "https://world.hey.com/dhh/what-do-you-do-with-a-chance-24c0714b",
            "publishedAt": "2025-08-11",
            "source": "DHH",
            "summary": "<div class=\"trix-content\"> <blockquote><em>One day, I got a chance. It just seemed to show up. It acted like it knew me, as if it wanted something.</em></blockquote><div><br />This is how Kobi Yamada's book <a href=\"https://www.amazon.com/What-Do-You-Chance/dp/1943200734/\"><em>What do you do with a chance?</em></a> starts. I've been reading that beautiful book to the boys at bedtime since it came out in 2018. It continues:<br /><br /></div><blockquote><em>It fluttered around me. It brushed up against me. It circled me as if it wanted me to grab it.</em></blockquote><div><br /></div><div>What a mesmerizing mental image of a chance, fluttering about.<br /><br /></div><div><em>What do you do with a chance?</em> is a great book exactly because it's not just for the boys, but for me too. A poetic reminder of what being open to chance looks like, and what to do when it shows up.&nbsp;<br /><br /></div><div>Right now, <a href=\"https://omarchy.org\">Omarchy</a> feels like that chance. Like Linux fluttered into my hands and said \"let's take a trip to the moon\".&nbsp;</div><div><br />I <a href=\"https://x.com/dhh/status/1954791471585874400\">joked on X</a> that perhaps it was the new creatine routine <a href=\"https://x.com/levelsio/status/1946710892193747020\">I picked up from Pieter Levels</a>, but I only started that a few days ago, so I really do think it's actually Linux!</div><div><br />This exhilaration of The Chance reminds",
            "title": "What do you do with a chance?"
        },
        {
            "content": [
                "<div class=\"lead\"><p>Recently, I suggested that <a href=\"https://fly.io/blog/the-future-isn-t-model-agnostic/\" title=\"\">The Future Isn\u2019t Model Agnostic</a>, that it\u2019s better to pick one model that works for your project and build around it, rather than engineering for model flexibility. If you buy that, you also have to acknowledge how important comprehensive model evaluation becomes. </p>\n</div>\n<p>Benchmarks tell us almost nothing about how a model will actually behave in the wild, especially with long contexts, or when trusted to deliver the tone and feel that defines the UX we\u2019re shooting for. Even the best evaluation pipelines usually end in subjective, side-by-side output comparisons. Not especially rigorous, and more importantly, boring af.</p>\n\n<p>Can we gamify model evaluation? Oh yes. And not just because we get to have some fun for once. Google backed me up this week when it announced the <a href=\"https://blog.google/technology/ai/kaggle-game-arena/\" title=\"\">Kaggle Game Arena</a>. A public platform where we can watch AI models duke it out in a variety of classic games.  Quoting Google; &ldquo;Current AI benchmarks are struggling to keep pace with modern models&hellip; it can be hard to know if models trained on internet data are actually solving problems or just remembering answers they&rsquo;ve already seen.&rdquo;</p>\n\n<p>When models boss reading comprehension tests, or ace math problems, we pay attention. But when they fail to navigate a simple conversation with a virtual character or completely botch a strategic decision in a game environment, we tell ourselves we&rsquo;re not building a game anyway and develop strategic short-term memory loss. \nJust like I&rsquo;ve told my mom a thousand times, games are great at testing brains, and it&rsquo;s time we take this seriously when it comes to model evaluation. </p>\n<h2 class=\"group flex items-start whitespace-pre-wrap relative mt-14 sm:mt-16 mb-4 text-navy-950 font-heading\" id=\"why-games-dont-lie\"><a class=\"inline-block align-text-top relative top-[.15em] w-6 h-6 -ml-6 after:hash opacity-0 group-hover:opacity-100 transition-all\" href=\"https://fly.io/blog/feed.xml#why-games-dont-lie\"></a><span class=\"plain-code\">Why Games Don&rsquo;t Lie</span></h2>\n<p>Games provide what benchmarks can&rsquo;t, &ldquo;a clear, unambiguous signal of success.&rdquo; They give us observable behavior in dynamic environments, the kind that would be extremely difficult (and tedious) to simulate with prompt engineering alone.</p>\n\n<p>Games force models to demonstrate the skills we actually care about; strategic reasoning, long-term planning, and dynamic adaptation in interactions with an opponent or a collaborator. </p>\n<h2 class=\"group flex items-start whitespace-pre-wrap relative mt-14 sm:mt-16 mb-4 text-navy-950 font-heading\" id=\"pixel-art-meets-effective-model-evaluation-ai-town-on-fly-io\"><a class=\"inline-block align-text-top relative top-[.15em] w-6 h-6 -ml-6 after:hash opacity-0 group-hover:opacity-100 transition-all\" href=\"https://fly.io/blog/feed.xml#pixel-art-meets-effective-model-evaluation-ai-town-on-fly-io\"></a><span class=\"plain-code\">Pixel Art Meets Effective Model Evaluation - AI Town on Fly.io</span></h2>\n<p>AI Town is a brilliant project by <a href=\"https://github.com/a16z-infra\" title=\"\">a16z-infra</a>, based on the the mind-bending paper,  <a href=\"https://arxiv.org/pdf/2304.03442\" title=\"\">Generative Agents: Interactive Simulacra of Human Behavior</a>. It&rsquo;s a beautifully rendered little town in which tiny people with AI brains and engineered personalities go about their lives, interacting with each other and their environment. Characters need to remember past conversations, maintain relationships, react dynamically to new situations, and stay in character while doing it all. </p>\n\n<p>I challenge you to find a more entertaining way of evaluating conversational models. </p>\n\n<p>I&rsquo;ve <a href=\"https://github.com/fly-apps/ai-town_on_fly.io\" title=\"\">forked the project</a> to make it absurdly easy to spin up your own AI Town on Fly Machines. You&rsquo;ve got a single deploy script that will set everything up for you and some built-in cost and performance optimizations, with our handy scale to zero functionality as standard (so you only pay for the time spent running it). This makes it easy to share with your team, your friends and your mom.  </p>\n\n<p>In it&rsquo;s current state, the fork makes it as easy as possible to test any OpenAI-compatible service, any model on Together.ai and even custom embedding models. Simply set the relevant API key in your secrets. </p>\n\n<p>Games like AI Town give us a window into how models actually think, adapt, and behave beyond the context of our prompts. You move past performance metrics and begin to understand a model\u2019s personality, quirks, strengths, and weaknesses; all factors that ultimately shape your project&rsquo;s UX. </p>"
            ],
            "link": "https://fly.io/blog/games-as-model-eval/",
            "publishedAt": "2025-08-11",
            "source": "Fly.io Blog",
            "summary": "<div class=\"lead\"><p>Recently, I suggested that <a href=\"https://fly.io/blog/the-future-isn-t-model-agnostic/\" title=\"\">The Future Isn\u2019t Model Agnostic</a>, that it\u2019s better to pick one model that works for your project and build around it, rather than engineering for model flexibility. If you buy that, you also have to acknowledge how important comprehensive model evaluation becomes. </p> </div> <p>Benchmarks tell us almost nothing about how a model will actually behave in the wild, especially with long contexts, or when trusted to deliver the tone and feel that defines the UX we\u2019re shooting for. Even the best evaluation pipelines usually end in subjective, side-by-side output comparisons. Not especially rigorous, and more importantly, boring af.</p> <p>Can we gamify model evaluation? Oh yes. And not just because we get to have some fun for once. Google backed me up this week when it announced the <a href=\"https://blog.google/technology/ai/kaggle-game-arena/\" title=\"\">Kaggle Game Arena</a>. A public platform where we can watch AI models duke it out in a variety of classic games. Quoting Google; &ldquo;Current AI benchmarks are struggling to keep pace with modern models&hellip; it can be hard to know if models trained on internet data are actually solving problems or just remembering answers they&rsquo;ve already seen.&rdquo;</p> <p>When models boss reading comprehension tests,",
            "title": "Games as Model Eval: 1-Click Deploy AI Town on Fly.io"
        },
        {
            "content": [],
            "link": "https://simonwillison.net/2025/Aug/11/llm-027/#atom-entries",
            "publishedAt": "2025-08-11",
            "source": "Simon Willison",
            "summary": "<p>I shipped <a href=\"https://llm.datasette.io/en/stable/changelog.html#v0-27\">LLM 0.27</a> today (followed by a <a href=\"https://llm.datasette.io/en/stable/changelog.html#v0-27-1\">0.27.1 with minor bug fixes</a>), adding support for the new GPT-5 family of models from OpenAI plus a flurry of improvements to the tool calling features <a href=\"https://simonwillison.net/2025/May/27/llm-tools/\">introduced in LLM 0.26</a>. Here are the <a href=\"https://simonwillison.net/tags/annotated-release-notes/\">annotated release notes</a>.</p> <h4 id=\"gpt-5\">GPT-5</h4> <blockquote> <ul> <li>New models: <code>gpt-5</code>, <code>gpt-5-mini</code> and <code>gpt-5-nano</code>. <a href=\"https://github.com/simonw/llm/issues/1229\">#1229</a> </li> </ul> </blockquote> <p>I would have liked to get these out sooner, but LLM had accumulated quite a lot of other changes since the last release and I wanted to use GPT-5 as an excuse to wrap all of those up and get them out there.</p> <p>These models work much the same as other OpenAI models, but they have a new <code>reasoning_effort</code> option of <code>minimal</code>. You can try that out like this:</p> <pre><code>llm -m gpt-5 'A letter advocating for cozy boxes for pelicans in Half Moon Bay harbor' -o reasoning_effort minimal </code></pre> <p>Setting \"minimal\" almost completely eliminates the \"thinking\" time for the model, causing it to behave more like GPT-4o.</p> <p>Here's <a href=\"https://gist.github.com/simonw/49838dbca944d3f22dfe65ef11c5637d\">the letter it wrote me</a> at a cost of 20 input, 706 output = <a href=\"https://www.llm-prices.com/#it=20&amp;ot=706&amp;ic=1.25&amp;oc=10\">$0.007085 which is 0.7085 cents</a>.</p> <p>You can set the default model to GPT-5-mini",
            "title": "LLM 0.27, the annotated release notes: GPT-5 and improved tool calling"
        },
        {
            "content": [
                "<p>This is the weekly visible open thread. Post about anything you want, ask random questions, whatever. ACX has an unofficial <a href=\"https://www.reddit.com/r/slatestarcodex/\">subreddit</a>, <a href=\"https://discord.gg/RTKtdut\">Discord</a>, and <a href=\"https://www.datasecretslox.com/index.php\">bulletin board</a>, and <a href=\"https://www.lesswrong.com/community?filters%5B0%5D=SSC\">in-person meetups around the world</a>. Most content is free, some is subscriber only; you can subscribe <strong><a href=\"https://astralcodexten.substack.com/subscribe\">here</a></strong>. Also: </p><div><hr /></div><p><strong>1: </strong>This is your last chance to <a href=\"https://www.astralcodexten.com/p/apply-for-an-acx-grant-2025\">apply for this year&#8217;s ACX Grants</a>. Deadline is end-of-day PST this Friday.</p><p><strong>2: </strong>Anthropic is hiring a research engineer for the Model Welfare team - ie figuring out whether their AIs are conscious or have feelings or something, and if so how to make sure they&#8217;re okay. Candidates should have expertise in ML and maybe philosophy/neuroscience/cogsci. Job is office-remote hybrid with the office in SF, salary is $315K+, non-Americans are welcome to apply and see if Anthropic can sponsor their visa. <a href=\"https://job-boards.greenhouse.io/anthropic/jobs/4812169008\">Learn more / apply here</a>.</p><p><strong>3: </strong>UK AISI is looking to distribute &#163;15m in AI alignment funding, for projects that need anywhere from a $100K pre-seed up to $1-2m. Collaborators included Anthropic, DeepMind, etc. See <a href=\"https://alignmentproject.aisi.gov.uk/research-agenda\">their priority areas</a> and <a href=\"https://alignmentproject.aisi.gov.uk/how-to-apply\">apply here</a> by September 10th. </p><p><strong>4:</strong> In <a href=\"https://www.astralcodexten.com/p/suddenly-trait-based-embryo-selection\">the post on embryo selection</a>, I mentioned that Herasight <a href=\"https://herasight.substack.com/p/building-better-scores?open=false#%C2%A7orchids-reported-performance-for-alzheimers-and-other-traits-is-misleading\">criticized </a>Orchid's Alzheimer's predictor. A representative of Orchid reached out to say they stood by their methodology:</p><blockquote><p>Herasight seems to be misreading <a href=\"https://guides.orchidhealth.com/post/alzheimers-disease-whitepaper\">our whitepaper</a>. The &#8220;Performant Alzheimer&#8217;s disease risk stratification&#8221; section is meant to show the kind of performance patients can expect&#8212;people in the top 5% have an OR of 5.80, top 3% is 7.35, and top 1% is 11.69.  This odds ratio is what is used to present embryo disease risk to patients and does not include covariates. The &#8220;Comparison to Published Benchmarks&#8221; section is just about comparing our models to others in the literature. To allow a head to head comparison, we used the same metric (AUC) and covariates as the paper we&#8217;re comparing against.  However, to avoid future confusion, we&#8217;ve just added a sentence clarifying the AUC without covariates (0.724). </p></blockquote><p>They also state that Herasight, like themselves, has only validated the predictors where there&#8217;s enough data (e.g. not schizophrenia), and they object to Herasight claiming superiority in this area.</p><p><strong>5: </strong>New subscribers-only post - <a href=\"https://www.astralcodexten.com/p/dream-book-review-the-deal-with-trauma\">Dream Book Review: The Deal With Trauma</a>. &#8220;Last week, I had an unusually vivid dream about writing a book review for ACX. When I woke up, I remembered the review almost word-for-word. In some sense this is a best case scenario - write posts in my sleep, and spend my waking hours relaxing on the beach - but unfortunately the book I was reviewing doesn&#8217;t exist and most of what I say about it doesn&#8217;t make sense. Still, I&#8217;m posting [it] here.&#8221;</p>"
            ],
            "link": "https://www.astralcodexten.com/p/open-thread-394",
            "publishedAt": "2025-08-11",
            "source": "SlateStarCodex",
            "summary": "<p>This is the weekly visible open thread. Post about anything you want, ask random questions, whatever. ACX has an unofficial <a href=\"https://www.reddit.com/r/slatestarcodex/\">subreddit</a>, <a href=\"https://discord.gg/RTKtdut\">Discord</a>, and <a href=\"https://www.datasecretslox.com/index.php\">bulletin board</a>, and <a href=\"https://www.lesswrong.com/community?filters%5B0%5D=SSC\">in-person meetups around the world</a>. Most content is free, some is subscriber only; you can subscribe <strong><a href=\"https://astralcodexten.substack.com/subscribe\">here</a></strong>. Also: </p><div><hr /></div><p><strong>1: </strong>This is your last chance to <a href=\"https://www.astralcodexten.com/p/apply-for-an-acx-grant-2025\">apply for this year&#8217;s ACX Grants</a>. Deadline is end-of-day PST this Friday.</p><p><strong>2: </strong>Anthropic is hiring a research engineer for the Model Welfare team - ie figuring out whether their AIs are conscious or have feelings or something, and if so how to make sure they&#8217;re okay. Candidates should have expertise in ML and maybe philosophy/neuroscience/cogsci. Job is office-remote hybrid with the office in SF, salary is $315K+, non-Americans are welcome to apply and see if Anthropic can sponsor their visa. <a href=\"https://job-boards.greenhouse.io/anthropic/jobs/4812169008\">Learn more / apply here</a>.</p><p><strong>3: </strong>UK AISI is looking to distribute &#163;15m in AI alignment funding, for projects that need anywhere from a $100K pre-seed up to $1-2m. Collaborators included Anthropic, DeepMind, etc. See <a href=\"https://alignmentproject.aisi.gov.uk/research-agenda\">their priority areas</a> and <a href=\"https://alignmentproject.aisi.gov.uk/how-to-apply\">apply here</a> by September 10th. </p><p><strong>4:</strong> In <a href=\"https://www.astralcodexten.com/p/suddenly-trait-based-embryo-selection\">the post on embryo selection</a>, I mentioned that Herasight <a href=\"https://herasight.substack.com/p/building-better-scores?open=false#%C2%A7orchids-reported-performance-for-alzheimers-and-other-traits-is-misleading\">criticized </a>Orchid's Alzheimer's",
            "title": "Open Thread 394"
        },
        {
            "content": [],
            "link": "https://xkcd.com/3127/",
            "publishedAt": "2025-08-11",
            "source": "XKCD",
            "summary": "<img alt=\"Historians: Contemporaneous documentation of the initial events is often sparse, and in fact people often get testy and uncooperative when we urge better documentation for the historical record.\" src=\"https://imgs.xkcd.com/comics/where_babies_come_from.png\" title=\"Historians: Contemporaneous documentation of the initial events is often sparse, and in fact people often get testy and uncooperative when we urge better documentation for the historical record.\" />",
            "title": "Where Babies Come From"
        }
    ],
    "lookbackDays": 1,
    "publishDate": "2025-08-11"
}