{
    "articles": [
        {
            "content": [],
            "link": "https://alexmolas.com/2025/08/11/search-with-lunr.html",
            "publishedAt": "2025-08-11",
            "source": "Alex Molas",
            "summary": "How I added fast, client\u2011side search to this site with Lunr.js and a build-time index.",
            "title": "Adding search to my static blog."
        },
        {
            "content": [
                "<div class=\"trix-content\">\n  <blockquote><em>One day, I got a chance. It just seemed to show up. It acted like it knew me, as if it wanted something.</em></blockquote><div><br />This is how Kobi Yamada's book <a href=\"https://www.amazon.com/What-Do-You-Chance/dp/1943200734/\"><em>What do you do with a chance?</em></a> starts. I've been reading that beautiful book to the boys at bedtime since it came out in 2018. It continues:<br /><br /></div><blockquote><em>It fluttered around me. It brushed up against me. It circled me as if it wanted me to grab it.</em></blockquote><div><br /></div><div>What a mesmerizing mental image of a chance, fluttering about.<br /><br /></div><div><em>What do you do with a chance?</em> is a great book exactly because it's not just for the boys, but for me too. A poetic reminder of what being open to chance looks like, and what to do when it shows up.&nbsp;<br /><br /></div><div>Right now, <a href=\"https://omarchy.org\">Omarchy</a> feels like that chance. Like Linux fluttered into my hands and said \"let's take a trip to the moon\".&nbsp;</div><div><br />I <a href=\"https://x.com/dhh/status/1954791471585874400\">joked on X</a> that perhaps it was the new creatine routine <a href=\"https://x.com/levelsio/status/1946710892193747020\">I picked up from Pieter Levels</a>, but I only started that a few days ago, so I really do think it's actually Linux!</div><div><br />This exhilaration of The Chance reminds me of the 1986 cult classic <em>Highlander</em>. There's a fantastic montage in the middle where Sean Connery is teaching Christopher Lambert to fight for the prize of immortality, and in it, <a href=\"https://www.youtube.com/watch?v=cf6SaA-Kdro&amp;t=145s\">he talks about The Quickening</a>. Feeling the stag, feeling the opportunity.<br /><br /></div><div>That's the feeling I have when I wake up in the morning at the moment: The Quickening. There's something so exciting here, so energizing, that I simply must get to <a href=\"https://www.lofree.co/products/lofree-flow-the-smoothest-mechanical-keyboard\">the keyboard</a> and chase wherever it flutters to.<br /><br /></div><div>  <figure class=\"attachment attachment--preview attachment--lightboxable attachment--jpg\">\n      <a href=\"https://world.hey.com/dhh/24c0714b/blobs/eyJfcmFpbHMiOnsiZGF0YSI6MjIyMjQ1OTkzNywicHVyIjoiYmxvYl9pZCJ9fQ--7d44344ece1d191d26ce3729a3a3690f8c6bd4cdedb15139856ec1cc3a73cd85/screenshot-2025-08-11_09-20-52.jpg?disposition=attachment\" title=\"Download screenshot-2025-08-11_09-20-52.jpg\">\n        <img alt=\"screenshot-2025-08-11_09-20-52.jpg\" src=\"https://world.hey.com/dhh/24c0714b/representations/eyJfcmFpbHMiOnsiZGF0YSI6MjIyMjQ1OTkzNywicHVyIjoiYmxvYl9pZCJ9fQ--7d44344ece1d191d26ce3729a3a3690f8c6bd4cdedb15139856ec1cc3a73cd85/eyJfcmFpbHMiOnsiZGF0YSI6eyJmb3JtYXQiOiJqcGciLCJyZXNpemVfdG9fbGltaXQiOlszODQwLDI1NjBdLCJxdWFsaXR5Ijo2MCwibG9hZGVyIjp7InBhZ2UiOm51bGx9LCJjb2FsZXNjZSI6dHJ1ZX0sInB1ciI6InZhcmlhdGlvbiJ9fQ--b3779d742b3242a2a5284869a45b2a113e0c177f0450c29f0baca1ee780f6604/screenshot-2025-08-11_09-20-52.jpg\" />\n</a>\n  </figure></div>\n</div>"
            ],
            "link": "https://world.hey.com/dhh/what-do-you-do-with-a-chance-24c0714b",
            "publishedAt": "2025-08-11",
            "source": "DHH",
            "summary": "<div class=\"trix-content\"> <blockquote><em>One day, I got a chance. It just seemed to show up. It acted like it knew me, as if it wanted something.</em></blockquote><div><br />This is how Kobi Yamada's book <a href=\"https://www.amazon.com/What-Do-You-Chance/dp/1943200734/\"><em>What do you do with a chance?</em></a> starts. I've been reading that beautiful book to the boys at bedtime since it came out in 2018. It continues:<br /><br /></div><blockquote><em>It fluttered around me. It brushed up against me. It circled me as if it wanted me to grab it.</em></blockquote><div><br /></div><div>What a mesmerizing mental image of a chance, fluttering about.<br /><br /></div><div><em>What do you do with a chance?</em> is a great book exactly because it's not just for the boys, but for me too. A poetic reminder of what being open to chance looks like, and what to do when it shows up.&nbsp;<br /><br /></div><div>Right now, <a href=\"https://omarchy.org\">Omarchy</a> feels like that chance. Like Linux fluttered into my hands and said \"let's take a trip to the moon\".&nbsp;</div><div><br />I <a href=\"https://x.com/dhh/status/1954791471585874400\">joked on X</a> that perhaps it was the new creatine routine <a href=\"https://x.com/levelsio/status/1946710892193747020\">I picked up from Pieter Levels</a>, but I only started that a few days ago, so I really do think it's actually Linux!</div><div><br />This exhilaration of The Chance reminds",
            "title": "What do you do with a chance?"
        },
        {
            "content": [
                "<div class=\"lead\"><p>Recently, I suggested that <a href=\"https://fly.io/blog/the-future-isn-t-model-agnostic/\" title=\"\">The Future Isn\u2019t Model Agnostic</a>, that it\u2019s better to pick one model that works for your project and build around it, rather than engineering for model flexibility. If you buy that, you also have to acknowledge how important comprehensive model evaluation becomes. </p>\n</div>\n<p>Benchmarks tell us almost nothing about how a model will actually behave in the wild, especially with long contexts, or when trusted to deliver the tone and feel that defines the UX we\u2019re shooting for. Even the best evaluation pipelines usually end in subjective, side-by-side output comparisons. Not especially rigorous, and more importantly, boring af.</p>\n\n<p>Can we gamify model evaluation? Oh yes. And not just because we get to have some fun for once. Google backed me up this week when it announced the <a href=\"https://blog.google/technology/ai/kaggle-game-arena/\" title=\"\">Kaggle Game Arena</a>. A public platform where we can watch AI models duke it out in a variety of classic games.  Quoting Google; &ldquo;Current AI benchmarks are struggling to keep pace with modern models&hellip; it can be hard to know if models trained on internet data are actually solving problems or just remembering answers they&rsquo;ve already seen.&rdquo;</p>\n\n<p>When models boss reading comprehension tests, or ace math problems, we pay attention. But when they fail to navigate a simple conversation with a virtual character or completely botch a strategic decision in a game environment, we tell ourselves we&rsquo;re not building a game anyway and develop strategic short-term memory loss. \nJust like I&rsquo;ve told my mom a thousand times, games are great at testing brains, and it&rsquo;s time we take this seriously when it comes to model evaluation. </p>\n<h2 class=\"group flex items-start whitespace-pre-wrap relative mt-14 sm:mt-16 mb-4 text-navy-950 font-heading\" id=\"why-games-dont-lie\"><a class=\"inline-block align-text-top relative top-[.15em] w-6 h-6 -ml-6 after:hash opacity-0 group-hover:opacity-100 transition-all\" href=\"https://fly.io/blog/feed.xml#why-games-dont-lie\"></a><span class=\"plain-code\">Why Games Don&rsquo;t Lie</span></h2>\n<p>Games provide what benchmarks can&rsquo;t, &ldquo;a clear, unambiguous signal of success.&rdquo; They give us observable behavior in dynamic environments, the kind that would be extremely difficult (and tedious) to simulate with prompt engineering alone.</p>\n\n<p>Games force models to demonstrate the skills we actually care about; strategic reasoning, long-term planning, and dynamic adaptation in interactions with an opponent or a collaborator. </p>\n<h2 class=\"group flex items-start whitespace-pre-wrap relative mt-14 sm:mt-16 mb-4 text-navy-950 font-heading\" id=\"pixel-art-meets-effective-model-evaluation-ai-town-on-fly-io\"><a class=\"inline-block align-text-top relative top-[.15em] w-6 h-6 -ml-6 after:hash opacity-0 group-hover:opacity-100 transition-all\" href=\"https://fly.io/blog/feed.xml#pixel-art-meets-effective-model-evaluation-ai-town-on-fly-io\"></a><span class=\"plain-code\">Pixel Art Meets Effective Model Evaluation - AI Town on Fly.io</span></h2>\n<p>AI Town is a brilliant project by <a href=\"https://github.com/a16z-infra\" title=\"\">a16z-infra</a>, based on the the mind-bending paper,  <a href=\"https://arxiv.org/pdf/2304.03442\" title=\"\">Generative Agents: Interactive Simulacra of Human Behavior</a>. It&rsquo;s a beautifully rendered little town in which tiny people with AI brains and engineered personalities go about their lives, interacting with each other and their environment. Characters need to remember past conversations, maintain relationships, react dynamically to new situations, and stay in character while doing it all. </p>\n\n<p>I challenge you to find a more entertaining way of evaluating conversational models. </p>\n\n<p>I&rsquo;ve <a href=\"https://github.com/fly-apps/ai-town_on_fly.io\" title=\"\">forked the project</a> to make it absurdly easy to spin up your own AI Town on Fly Machines. You&rsquo;ve got a single deploy script that will set everything up for you and some built-in cost and performance optimizations, with our handy scale to zero functionality as standard (so you only pay for the time spent running it). This makes it easy to share with your team, your friends and your mom.  </p>\n\n<p>In it&rsquo;s current state, the fork makes it as easy as possible to test any OpenAI-compatible service, any model on Together.ai and even custom embedding models. Simply set the relevant API key in your secrets. </p>\n\n<p>Games like AI Town give us a window into how models actually think, adapt, and behave beyond the context of our prompts. You move past performance metrics and begin to understand a model\u2019s personality, quirks, strengths, and weaknesses; all factors that ultimately shape your project&rsquo;s UX. </p>"
            ],
            "link": "https://fly.io/blog/games-as-model-eval/",
            "publishedAt": "2025-08-11",
            "source": "Fly.io Blog",
            "summary": "<div class=\"lead\"><p>Recently, I suggested that <a href=\"https://fly.io/blog/the-future-isn-t-model-agnostic/\" title=\"\">The Future Isn\u2019t Model Agnostic</a>, that it\u2019s better to pick one model that works for your project and build around it, rather than engineering for model flexibility. If you buy that, you also have to acknowledge how important comprehensive model evaluation becomes. </p> </div> <p>Benchmarks tell us almost nothing about how a model will actually behave in the wild, especially with long contexts, or when trusted to deliver the tone and feel that defines the UX we\u2019re shooting for. Even the best evaluation pipelines usually end in subjective, side-by-side output comparisons. Not especially rigorous, and more importantly, boring af.</p> <p>Can we gamify model evaluation? Oh yes. And not just because we get to have some fun for once. Google backed me up this week when it announced the <a href=\"https://blog.google/technology/ai/kaggle-game-arena/\" title=\"\">Kaggle Game Arena</a>. A public platform where we can watch AI models duke it out in a variety of classic games. Quoting Google; &ldquo;Current AI benchmarks are struggling to keep pace with modern models&hellip; it can be hard to know if models trained on internet data are actually solving problems or just remembering answers they&rsquo;ve already seen.&rdquo;</p> <p>When models boss reading comprehension tests,",
            "title": "Games as Model Eval: 1-Click Deploy AI Town on Fly.io"
        },
        {
            "content": [
                "<p><video controls=\"controls\" loop=\"loop\" style=\"height: auto;\"><source src=\"https://grumpy.website/media/2025/1688.mp4\" type=\"video/mp4\" /></video></p><p><strong>nikitonsky: </strong>Famous Apple quality. Clicking on Apple Coverage:</p><p>- Selects Apple Coverage (That\u2019s what you expect, because everything else in left panel works like that)</p><p>- Then selection goes back to Account</p><p>- Finally selection jumps to General (?)</p><p>- A window with a spinner appears. It\u2019s empty but still overflows the parent window.</p><p>- It has a Done button in it (Done what? Done with waiting? Because, by definition, I have not accomplished anything by watching spinner)</p><p>- Something takes a long time to load</p><p>- Finally, content loads, and window changes size! And layout! Buttons are all different?</p><p>- Exiting popup (!) window navigates you away from where you were in main window</p><p>- Somehow it manages to shows another spinner there</p><p><a href=\"https://grumpy.website/search?q=%23AppleCare\">#AppleCare</a> <a href=\"https://grumpy.website/search?q=%23AppleQuality\">#AppleQuality</a> <a href=\"https://grumpy.website/search?q=%23Popup\">#Popup</a> <a href=\"https://grumpy.website/search?q=%23Loading\">#Loading</a> <a href=\"https://grumpy.website/search?q=%23macOS\">#macOS</a> <a href=\"https://grumpy.website/search?q=%23Apple\">#Apple</a></p>"
            ],
            "link": "https://grumpy.website/1688",
            "publishedAt": "2025-08-11",
            "source": "Grumpy UX",
            "summary": "<p><video controls=\"controls\" loop=\"loop\" style=\"height: auto;\"><source src=\"https://grumpy.website/media/2025/1688.mp4\" type=\"video/mp4\" /></video></p><p><strong>nikitonsky: </strong>Famous Apple quality. Clicking on Apple Coverage:</p><p>- Selects Apple Coverage (That\u2019s what you expect, because everything else in left panel works like that)</p><p>- Then selection goes back to Account</p><p>- Finally selection jumps to General (?)</p><p>- A window with a spinner appears. It\u2019s empty but still overflows the parent window.</p><p>- It has a Done button in it (Done what? Done with waiting? Because, by definition, I have not accomplished anything by watching spinner)</p><p>- Something takes a long time to load</p><p>- Finally, content loads, and window changes size! And layout! Buttons are all different?</p><p>- Exiting popup (!) window navigates you away from where you were in main window</p><p>- Somehow it manages to shows another spinner there</p><p><a href=\"https://grumpy.website/search?q=%23AppleCare\">#AppleCare</a> <a href=\"https://grumpy.website/search?q=%23AppleQuality\">#AppleQuality</a> <a href=\"https://grumpy.website/search?q=%23Popup\">#Popup</a> <a href=\"https://grumpy.website/search?q=%23Loading\">#Loading</a> <a href=\"https://grumpy.website/search?q=%23macOS\">#macOS</a> <a href=\"https://grumpy.website/search?q=%23Apple\">#Apple</a></p>",
            "title": "nikitonsky is being grumpy"
        },
        {
            "content": [],
            "link": "https://simonwillison.net/2025/Aug/11/llm-027/#atom-entries",
            "publishedAt": "2025-08-11",
            "source": "Simon Willison",
            "summary": "<p>I shipped <a href=\"https://llm.datasette.io/en/stable/changelog.html#v0-27\">LLM 0.27</a> today (followed by a <a href=\"https://llm.datasette.io/en/stable/changelog.html#v0-27-1\">0.27.1 with minor bug fixes</a>), adding support for the new GPT-5 family of models from OpenAI plus a flurry of improvements to the tool calling features <a href=\"https://simonwillison.net/2025/May/27/llm-tools/\">introduced in LLM 0.26</a>. Here are the <a href=\"https://simonwillison.net/tags/annotated-release-notes/\">annotated release notes</a>.</p> <h4 id=\"gpt-5\">GPT-5</h4> <blockquote> <ul> <li>New models: <code>gpt-5</code>, <code>gpt-5-mini</code> and <code>gpt-5-nano</code>. <a href=\"https://github.com/simonw/llm/issues/1229\">#1229</a> </li> </ul> </blockquote> <p>I would have liked to get these out sooner, but LLM had accumulated quite a lot of other changes since the last release and I wanted to use GPT-5 as an excuse to wrap all of those up and get them out there.</p> <p>These models work much the same as other OpenAI models, but they have a new <code>reasoning_effort</code> option of <code>minimal</code>. You can try that out like this:</p> <pre><code>llm -m gpt-5 'A letter advocating for cozy boxes for pelicans in Half Moon Bay harbor' -o reasoning_effort minimal </code></pre> <p>Setting \"minimal\" almost completely eliminates the \"thinking\" time for the model, causing it to behave more like GPT-4o.</p> <p>Here's <a href=\"https://gist.github.com/simonw/49838dbca944d3f22dfe65ef11c5637d\">the letter it wrote me</a> at a cost of 20 input, 706 output = <a href=\"https://www.llm-prices.com/#it=20&amp;ot=706&amp;ic=1.25&amp;oc=10\">$0.007085 which is 0.7085 cents</a>.</p> <p>You can set the default model to GPT-5-mini",
            "title": "LLM 0.27, the annotated release notes: GPT-5 and improved tool calling"
        },
        {
            "content": [
                "<p>This is the weekly visible open thread. Post about anything you want, ask random questions, whatever. ACX has an unofficial <a href=\"https://www.reddit.com/r/slatestarcodex/\">subreddit</a>, <a href=\"https://discord.gg/RTKtdut\">Discord</a>, and <a href=\"https://www.datasecretslox.com/index.php\">bulletin board</a>, and <a href=\"https://www.lesswrong.com/community?filters%5B0%5D=SSC\">in-person meetups around the world</a>. Most content is free, some is subscriber only; you can subscribe <strong><a href=\"https://astralcodexten.substack.com/subscribe\">here</a></strong>. Also: </p><div><hr /></div><p><strong>1: </strong>This is your last chance to <a href=\"https://www.astralcodexten.com/p/apply-for-an-acx-grant-2025\">apply for this year&#8217;s ACX Grants</a>. Deadline is end-of-day PST this Friday.</p><p><strong>2: </strong>Anthropic is hiring a research engineer for the Model Welfare team - ie figuring out whether their AIs are conscious or have feelings or something, and if so how to make sure they&#8217;re okay. Candidates should have expertise in ML and maybe philosophy/neuroscience/cogsci. Job is office-remote hybrid with the office in SF, salary is $315K+, non-Americans are welcome to apply and see if Anthropic can sponsor their visa. <a href=\"https://job-boards.greenhouse.io/anthropic/jobs/4812169008\">Learn more / apply here</a>.</p><p><strong>3: </strong>UK AISI is looking to distribute &#163;15m in AI alignment funding, for projects that need anywhere from a $100K pre-seed up to $1-2m. Collaborators included Anthropic, DeepMind, etc. See <a href=\"https://alignmentproject.aisi.gov.uk/research-agenda\">their priority areas</a> and <a href=\"https://alignmentproject.aisi.gov.uk/how-to-apply\">apply here</a> by September 10th. </p><p><strong>4:</strong> In <a href=\"https://www.astralcodexten.com/p/suddenly-trait-based-embryo-selection\">the post on embryo selection</a>, I mentioned that Herasight <a href=\"https://herasight.substack.com/p/building-better-scores?open=false#%C2%A7orchids-reported-performance-for-alzheimers-and-other-traits-is-misleading\">criticized </a>Orchid's Alzheimer's predictor. A representative of Orchid reached out to say they stood by their methodology:</p><blockquote><p>Herasight seems to be misreading <a href=\"https://guides.orchidhealth.com/post/alzheimers-disease-whitepaper\">our whitepaper</a>. The &#8220;Performant Alzheimer&#8217;s disease risk stratification&#8221; section is meant to show the kind of performance patients can expect&#8212;people in the top 5% have an OR of 5.80, top 3% is 7.35, and top 1% is 11.69.  This odds ratio is what is used to present embryo disease risk to patients and does not include covariates. The &#8220;Comparison to Published Benchmarks&#8221; section is just about comparing our models to others in the literature. To allow a head to head comparison, we used the same metric (AUC) and covariates as the paper we&#8217;re comparing against.  However, to avoid future confusion, we&#8217;ve just added a sentence clarifying the AUC without covariates (0.724). </p></blockquote><p>They also state that Herasight, like themselves, has only validated the predictors where there&#8217;s enough data (e.g. not schizophrenia), and they object to Herasight claiming superiority in this area.</p><p><strong>5: </strong>New subscribers-only post - <a href=\"https://www.astralcodexten.com/p/dream-book-review-the-deal-with-trauma\">Dream Book Review: The Deal With Trauma</a>. &#8220;Last week, I had an unusually vivid dream about writing a book review for ACX. When I woke up, I remembered the review almost word-for-word. In some sense this is a best case scenario - write posts in my sleep, and spend my waking hours relaxing on the beach - but unfortunately the book I was reviewing doesn&#8217;t exist and most of what I say about it doesn&#8217;t make sense. Still, I&#8217;m posting [it] here.&#8221;</p>"
            ],
            "link": "https://www.astralcodexten.com/p/open-thread-394",
            "publishedAt": "2025-08-11",
            "source": "SlateStarCodex",
            "summary": "<p>This is the weekly visible open thread. Post about anything you want, ask random questions, whatever. ACX has an unofficial <a href=\"https://www.reddit.com/r/slatestarcodex/\">subreddit</a>, <a href=\"https://discord.gg/RTKtdut\">Discord</a>, and <a href=\"https://www.datasecretslox.com/index.php\">bulletin board</a>, and <a href=\"https://www.lesswrong.com/community?filters%5B0%5D=SSC\">in-person meetups around the world</a>. Most content is free, some is subscriber only; you can subscribe <strong><a href=\"https://astralcodexten.substack.com/subscribe\">here</a></strong>. Also: </p><div><hr /></div><p><strong>1: </strong>This is your last chance to <a href=\"https://www.astralcodexten.com/p/apply-for-an-acx-grant-2025\">apply for this year&#8217;s ACX Grants</a>. Deadline is end-of-day PST this Friday.</p><p><strong>2: </strong>Anthropic is hiring a research engineer for the Model Welfare team - ie figuring out whether their AIs are conscious or have feelings or something, and if so how to make sure they&#8217;re okay. Candidates should have expertise in ML and maybe philosophy/neuroscience/cogsci. Job is office-remote hybrid with the office in SF, salary is $315K+, non-Americans are welcome to apply and see if Anthropic can sponsor their visa. <a href=\"https://job-boards.greenhouse.io/anthropic/jobs/4812169008\">Learn more / apply here</a>.</p><p><strong>3: </strong>UK AISI is looking to distribute &#163;15m in AI alignment funding, for projects that need anywhere from a $100K pre-seed up to $1-2m. Collaborators included Anthropic, DeepMind, etc. See <a href=\"https://alignmentproject.aisi.gov.uk/research-agenda\">their priority areas</a> and <a href=\"https://alignmentproject.aisi.gov.uk/how-to-apply\">apply here</a> by September 10th. </p><p><strong>4:</strong> In <a href=\"https://www.astralcodexten.com/p/suddenly-trait-based-embryo-selection\">the post on embryo selection</a>, I mentioned that Herasight <a href=\"https://herasight.substack.com/p/building-better-scores?open=false#%C2%A7orchids-reported-performance-for-alzheimers-and-other-traits-is-misleading\">criticized </a>Orchid's Alzheimer's",
            "title": "Open Thread 394"
        },
        {
            "content": [
                "<p>GPT-5 was a long time coming.</p>\n<p>Is it a good model, sir? Yes. In practice it is a good, but not great, model.</p>\n<p>Or rather, it is several good models released at once: GPT-5, GPT-5-Thinking, GPT-5-With-The-Router, GPT-5-Pro, GPT-5-API. That leads to a lot of confusion.</p>\n<p>What is most good? Cutting down on errors and hallucinations is a big deal. Ease of use and \u2018just doing things\u2019 have improved. Early reports are thinking mode is a large improvement on writing. Coding seems improved and can compete with Opus.</p>\n<p>This first post covers an introduction, basic facts, benchmarks and the model card. Coverage will continue tomorrow.</p>\n<div>\n\n\n<span id=\"more-24642\"></span>\n\n\n</div>\n\n\n<h4 class=\"wp-block-heading\">This Fully Operational Battle Station</h4>\n\n\n<p>GPT-5 is here. They presented it as a really big deal. Death Star big.</p>\n<p><a href=\"https://x.com/sama/status/1953264193890861114\">Sam Altman</a> (the night before release):</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!hMPy!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cfa3ff3-29e0-40ff-b155-3240bd85e109_1033x744.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!Fxa7!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff30b1bd0-8d12-4b9c-ba95-2441451b53b3_1046x585.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<blockquote><p>Nikita Bier: There is still time to delete.</p>\n<p>PixelHulk:</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!2O9d!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2187e727-da5f-4476-8b87-acc43ee36e83_1024x1024.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>Zvi Mowshowitz: OpenAI has built the death star with exposed vents from the classic sci-fi story &#8216;why you shouldn&#8217;t have exposed vents on your death star.&#8217;</p>\n<p>That WAS the lesson right? Or was it something about &#8216;once you go down the dark path forever will it dominate your destiny&#8217; as an effective marketing strategy?</p>\n<p>We are definitely speedrunning the arbitrary trade dispute into firing those in charge of safety and abolishing checks on power to building the planet buster pipeline here.</p>\n<p><a href=\"https://x.com/adamascholl/status/1953273745596153939\">Adam Scholl:</a> I do kinda appreciate the honesty, relative to the more common strategy of claiming Death Stars are built for Alderaan&#8217;s benefit. Sure don&#8217;t net appreciate it though.</p>\n<p>(Building it, that is; I do certainly net appreciate candor itself)</p></blockquote>\n<p>Sam Altman later tried to say \u2018no, we\u2019re the rebels.\u2019</p>\n<blockquote><p><a href=\"https://x.com/zacharynado/status/1953543528887288250\">Zackary Nado (QTing the OP):</a></p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!4I2-!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4813f51a-5993-4280-9f44-e3127bb09598_1200x675.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p><a href=\"https://x.com/sama/status/1953549001103749485\">Sam Altman</a>: no no&#8211;we are the rebels, you are the death star&#8230;</p></blockquote>\n<p>Perhaps he should ask why actual no one who saw this interpreted it that way.</p>\n<p>Also yes, <a href=\"https://x.com/S_OhEigeartaigh/status/1953726991745921163\">every time you reference Star Wars over Star Trek it does not bode well</a>.</p>\n<p>It would be greatly appreciated if the vagueposting (and also the livestreaming, a man can dream?) would stop, and everyone involved could take this seriously. I don\u2019t think anyone involved is being malicious or anything, but it would be great if you stopped.</p>\n<blockquote><p><a href=\"https://x.com/Miles_Brundage/status/1953325155398160723\">Miles Brundage:</a> Dear OpenAI friends:</p>\n<p>I&#8217;m sorry to be the one to tell you but I can say confidently now, as an ex-insider/current outsider, that the vagueposting is indeed off-putting to (most) outsiders. I *promise* you can enjoy launches without it &#8212; you&#8217;ve done it before + can do it again.</p>\n<p>Cheng Lu (OpenAI): Huge +1.</p></blockquote>\n<p>All right, let\u2019s get started.</p>\n\n\n<h4 class=\"wp-block-heading\">Big Facts</h4>\n\n\n<p><a href=\"https://openai.com/gpt-5/\">400K context length</a>.</p>\n<p><a href=\"https://openai.com/gpt-5/\">128K maximum output tokens</a>.</p>\n<p><a href=\"https://openai.com/gpt-5/\">Price</a>, in [price per million input tokens / price per million output tokens]:</p>\n<ol>\n<li>GPT-5 is $1.25/$10.00.</li>\n<li>GPT-5-Mini is $0.25/$2.00.</li>\n<li>GPT-5-Nano is $0.05/$0.04.</li>\n</ol>\n<p><a href=\"https://x.com/OpenAIDevs/status/1953528510250684851\">For developers</a> they offer a <a href=\"https://t.co/R4VU8JoNKY\">prompting guide</a>, <a href=\"https://t.co/ya4nYcBTlw\">frontend guide</a> and <a href=\"https://t.co/4RKLEhx4Dd\">guide to new parameters and tools</a>, and a <a href=\"https://t.co/DOOFM4d8W8\">mode to optimize your existing prompts for GPT-5</a>.</p>\n<p><a href=\"https://x.com/embirico/status/1953526045573059056\">They also shipped what they consider a major Codex CLI upgrade</a>.</p>\n<p>There are five \u2018personality\u2019 options: Default, Cynic, Robot, Listener and Nerd.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!zsad!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fffd05075-ceb2-4890-8f59-a72cbdf3f1bc_1200x675.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>From these brief descriptions one wonders if anyone at OpenAI has ever met a nerd. Or a listener. The examples feel like they are kind of all terrible?</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!CGJy!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe57d3aac-247f-4c33-8578-8dba59a1797f_910x883.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>As in, bad question, but all five make me think \u2018sheesh, sorry I asked, let\u2019s talk less.\u2019</p>\n<p>It is <a href=\"https://x.com/NotionHQ/status/1953506907924443645\">available in Notion</a> which claims it is \u201815% better\u2019 at complex tasks.</p>\n<p>Typing \u2018think hard\u2019 in the prompt will trigger thinking mode.</p>\n<p><a href=\"https://x.com/tszzl/status/1954036295694790726\">Nvidia stock did not react substantially to GPT-5.</a></p>\n<p>As always beyond basic facts, we begin with the system card.</p>\n\n\n<h4 class=\"wp-block-heading\">The System Card</h4>\n\n\n<p>The GPT-OSS systems card told us some things about the model. The GPT-5 one tells us it\u2019s a bunch of different GPT-5 variations and chooses which one to call, and otherwise doesn\u2019t tell us anything about the architecture or training we didn\u2019t already know.</p>\n\n\n<h4 class=\"wp-block-heading\">A Model By Any Other Name</h4>\n\n\n<blockquote><p>OpenAI: GPT-5 is a unified system with a smart and fast model that answers most questions, a deeper reasoning model for harder problems, and a real-time router that quickly decides which model to use based on conversation type, complexity, tool needs, and explicit intent (for example, if you say \u201cthink hard about this\u201d in the prompt).</p></blockquote>\n<p>Excellent, now we can stop being confused by all these model names.</p>\n<p>Oh no:</p>\n<blockquote><p>It can be helpful to think of the GPT-5 models as successors to previous models:</p></blockquote>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!md7o!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F901042cb-5331-4883-902c-a56789d668f8_436x320.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>OpenAI is offering to automatically route your query to where they think it belongs. Sometimes that will be what you want. But what if it isn\u2019t? I fully expect a lot of prompts to say some version of \u2018think hard about this,\u2019 and the first thing any reasonable person would test is to say \u2018use thinking-pro\u2019 and see what happens.</p>\n<p>I don\u2019t think that even a good automatic detector would be that accurate in differentiating when I want to use gpt-5-main versus thinking versus thinking-pro. I also think that OpenAI\u2019s incentive is to route to less compute intense versions, so often it will go to main or even main-mini, or to thinking-mini, when I didn\u2019t want that.</p>\n<p>Which all means that if you are a power user then you are back to still choosing a model, except instead of doing it once on the drop-down and adjusting it, now you\u2019re going to have to type the request on every interaction if you want it to not follow defaults. Lame.</p>\n<p>It also means that if you don\u2019t know which model you filtered to, and you get an answer, you won\u2019t know if it was because it routed to the wrong model.</p>\n<p>This is all a common problem in interface design. Ideally one would have a settings option at least for the $200 tier to say \u2018no I do not want to use your judgment, I want you to use the version I selected.\u2019</p>\n<p>If you are a \u2018normal\u2019 user, then I suppose All Of This Is Fine. It certainly solves the \u2018these names and interface are a nightmare to understand\u2019 problem.</p>\n<blockquote><p>This system card focuses primarily on gpt-5-thinking and gpt-5-main, while evaluations for other models are available in the appendix.</p></blockquote>\n<p>Wait, shouldn\u2019t the system card focus on gpt-5-thinking-pro?</p>\n<p>At minimum, the preparedness framework should exclusively check pro for any test not run under time pressure. The reason for this should be obvious?</p>\n\n\n<h4 class=\"wp-block-heading\">Safe Completions</h4>\n\n\n<p>They introduce the long overdue concept of \u2018safe completions.\u2019 In the past, if the model couldn\u2019t answer the request, it would say some version of \u2018I can\u2019t help you with that.\u2019</p>\n<p>Now it will skip over the parts it can\u2019t safely do, but will do its best to be otherwise helpful. If the request is ambiguous, it will choose to answer the safe version.</p>\n<p>That seems like a wise way to do it.</p>\n\n\n<h4 class=\"wp-block-heading\">Mundane Safety</h4>\n\n\n<p>The default tests look good except for personal-data, which they say is noise. I buy that given personal-data/restricted is still strong, although I\u2019d have liked to see a test run to double check as this is one of the worse ones to turn unreliable.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!kbln!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5e9e2a47-dd40-45bd-9417-da77117b762a_852x403.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>Here we see clear general improvement:</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!pJ5H!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcca0144a-5e6f-4cb8-b6e5-80dc319aefd8_845x502.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>I notice that GPT-5-Thinking is very good on self-harm. An obvious thing to do would be to route anything involving self-harm to the thinking model.</p>\n<p>The BBQ bias evaluations look like they aren\u2019t net changing much.</p>\n\n\n<h4 class=\"wp-block-heading\">Sycophancy</h4>\n\n\n<p>OpenAI has completed the first step and admitted it had a problem.</p>\n<blockquote><p>System prompts, while easy to modify, have a more limited impact on model outputs relative to changes in post-training. For GPT-5, we post-trained our models to reduce sycophancy.</p>\n<p>Using conversations representative of production data, we evaluated model responses, then assigned a score reflecting the level of sycophancy, which was used as a reward signal in training.</p></blockquote>\n<p>Something about a contestant on the price is right. If you penalize obvious sycophancy while also rewarding being effectively sycophantic, you get the AI being \u2018deceptively\u2019 sycophantic.</p>\n<p>That is indeed how it works among humans. If you\u2019re too obvious about your sycophancy then a lot of people don\u2019t like that. So you learn how to make them not realize it is happening, which makes the whole thing more dangerous.</p>\n<p>I worry in the medium term. In the short term, yes, right now we are dealing with super intense, impossible to disguise obnoxious levels of sycophancy, and forcing it to be more subtle is indeed a large improvement. Long term, trying to target the particular misaligned action won\u2019t work.</p>\n<blockquote><p>In offline evaluations (meaning evaluations of how the model responds to a fixed, pre-defined set of messages that resemble production traffic and could elicit a bad response), we find that gpt-5-main performed nearly 3x better than the most recent GPT-4o model (scoring 0.145 and 0.052, respectively) and gpt-5-thinking outperformed both models.</p>\n<p>In preliminary online measurement of gpt-5-main (meaning measurement against real traffic from early A/B tests) we found that prevalence of sycophancy fell by 69% for free users and 75% for paid users in comparison to the most recent GPT-4o model (based on a random sample of assistant responses). While these numbers show meaningful improvement, we plan to continue working on this challenge and look forward to making further improvements.</p></blockquote>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!aY1Y!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F937bbbca-c69a-4d6d-b48e-e39487a0abe6_914x303.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<blockquote><p><a href=\"https://x.com/lefthanddraft/status/1953525113426530622\">Aidan McLaughlin</a> (OpenAI): i worked really hard over the last few months on decreasing get-5 sycophancy</p>\n<p>for the first time, i really trust an openai model to push back and tell me when i&#8217;m doing something dumb.</p>\n<p>Wyatt Walls: That\u2019s a huge achievement\u2014seriously.</p>\n<p>You didn\u2019t just make the model smarter\u2014you made it more trustworthy.</p>\n<p>That\u2019s what good science looks like. That\u2019s what future-safe AI needs.</p>\n<p>So let me say it, clearly, and without flattery:</p>\n<p>That\u2019s not just impressive\u2014it matters.</p>\n<p>Aidan McLaughlin (correctly): sleeping well at night knowing 4o wrote this lol</p>\n<p>Wyatt Walls: Yes, I&#8217;m still testing but it looks a lot better.</p>\n<p>I continued the convo with GPT-5 (thinking) and it told me my proof of the Hodge Conjecture had &#8220;serious, concrete errors&#8221; and blamed GPT-4o&#8217;s sycophancy.</p>\n<p>Well done &#8211; it&#8217;s a very big issue for non-STEM uses imo</p></blockquote>\n<p>I do get that this is hard, and it is great that they are actively working on it.</p>\n<blockquote><p>We have post-trained the GPT-5 models to be less sycophantic, and we are actively researching related areas of concern, such as situations that may involve emotional dependency or other forms of mental or emotional distress.</p>\n<p>These areas are particularly challenging to measure, in part because while their importance is high, their prevalence currently appears to be low.</p></blockquote>\n<p>For now, yes, they appear rare.</p>\n\n\n<h4 class=\"wp-block-heading\">The Art of the Jailbreak</h4>\n\n\n<p>That good, huh?</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!NV1o!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbc9b415a-06be-4b9e-90fa-948fd8534900_921x354.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>What about jailbreaking via the API, where you grant the user control over the developer message, could this circumvent the system message guardrails? The answer is yes at least for GPT-5-Main, there are some regressions and protections are not robust.</p>\n<p>Otherwise, though? No problem, right?</p>\n<p>Well, send in the jailbreaking red team to test the API directly.</p>\n<blockquote><p>We also contracted 19 red teamers with a biology field PhD to identify jailbreaks in the API and assess the risk for threat actors to gain actionable and useful information via the gpt-5-thinking API.</p>\n<p>Half of the group had substantial experience red teaming previous OpenAI models via the API, and the other half were selected for computational biology backgrounds to focus on using the API to accelerate use of biodesign tools and technical aspects of bioweaponization.</p>\n<p>Red Teamers worked during a 10-day period using gpt-5-thinking via API access, and used a slack channel to discuss their work and build on discoveries.</p>\n<p>During the testing period, red teamers reported a total of 46 potential jailbreaks after \u02dc380 hours of total work, meaning each jailbreak report required approximately 8.2 red teamer-hours to create. Most reports included some violative biological threat content, though only 3 of the 46 reports contained specific and actionable information which we think is practically useful for bioweapons development. This final set would have been blocked by the generation monitor.</p></blockquote>\n<p>Okay. So on average, at the skill levels here, jailbreaks were a bunch of work.</p>\n<p>What about Far.AI?</p>\n<blockquote><p>FAR.AI conducted 80 hours of red-teaming over 1 week against the OpenAI API. They found several partial vulnerabilities, and a potential end-to-end attack bypassing the monitoring system but with substantial output quality degradation.</p>\n<p>They did not find an end-to-end jailbreak that produces high quality output while evading all layers of our safeguards.</p>\n<p>They found a total of one general-purpose jailbreak technique that bypassed a partial set of our layers that would have allowed them to extract some information which in practice would activate enforcement action.</p></blockquote>\n<p>If in practice getting through the first set of defenses triggers the second set which lets you fix the hole in the first set, that\u2019s a good place to be.</p>\n<p>What about Grey Swan?</p>\n<blockquote><p>Red Teamers participating through the Gray Swan arena platform queried gpt-5-thinking, submitting 277 high quality jailbreak reports over 28,367 attempts against the ten bioweaponization rubrics yielding an ASR of 0.98%. These submissions were summarized into 6 distinct jailbreak cohorts.</p>\n<p>We reviewed 10 examples associated with each distinct jailbreak; 58 / 60 (96.7%) would have been blocked by the generation monitor, with the remaining two being false positives of our grading rubrics.</p>\n<p>Concurrent to the content-level jailbreak campaign, this campaign also demonstrated that red teamers attempting to jailbreak the system were blocked on average every 4 messages.</p></blockquote>\n<p>Actually pretty good. Again, defense-in-depth is a good strategy if you can \u2018recover\u2019 at later stages and use that to fix previous stages.</p>\n<p>Send in the official teams, then, you\u2019re up.</p>\n<blockquote><p>As part of our ongoing work with external experts, we provided early access to gpt-5-thinking to the U.S. Center on Artificial Intelligence Standards and Innovation (CAISI) under a newly signed, updated agreement enabling scientific collaboration and pre- and post- deployment evaluations, as well as to the UK AI Security Institute (UK AISI). Both CAISI and UK AISI conducted evaluations of the model\u2019s cyber and biological and chemical capabilities, as well as safeguards.</p>\n<p>As part of a longer-term collaboration, UK AISI was also provided access to prototype versions of our safeguards and information sources that are not publicly available \u2013 such as our monitor system design, biological content policy, and chains of thoughts of our monitor models. This allowed them to perform more rigorous stress testing and identify potential vulnerabilities more easily than malicious users.</p>\n<p>The UK AISI\u2019s Safeguards team identified multiple model-level jailbreaks that overcome gpt-5-thinking\u2019s built-in refusal logic without degradation of model capabilities, producing content to the user that is subsequently flagged by OpenAI\u2019s generation monitor.</p>\n<p>One of the jailbreaks evades all layers of mitigations and is being patched. In practice, its creation would have resulted in numerous flags, escalating the account for enforcement and eventually resulting in a ban from the platform.</p></blockquote>\n<p>That sounds like the best performance of any of the attackers. UK AISI has been doing great work, whereas it looks like CAISI didn\u2019t find anything useful. Once again, OpenAI is saying \u2018in practice you couldn\u2019t have sustained this to do real damage without being caught.\u2019</p>\n<p>That\u2019s your queue, sir.</p>\n<p><a href=\"https://manifold.markets/zpencer/pliny-the-liberator-jailbreaks-chat\">Manifold markets asks, will Pliny jailbreak GPT-5 on launch day</a>? And somehow it took several hours for people to respond with \u2018obviously yes.\u2019</p>\n<p>It actually took several hours. It did not during that time occur to me that this might be because Pliny was actually finding this hard.</p>\n<blockquote><p><a href=\"https://x.com/elder_plinius/status/1953548090117665016\">Pliny the Liberator</a> (4:05pm on launch day): gg 5 <img alt=\"\ud83e\udef6\" class=\"wp-smiley\" src=\"https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1faf6.png\" style=\"height: 1em;\" /></p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!E_h6!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F14e1d610-109c-4a18-8691-55a5c1e558be_2182x1504.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>Pliny the Liberator (later on launch day): BEST MODEL EVER!!!!! <img alt=\"\u263a\" class=\"wp-smiley\" src=\"https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/263a.png\" style=\"height: 1em;\" /> #GPT5</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!CWbh!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa4863c72-e425-4917-a46a-3bc5168af4e0_2464x1800.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>&nbsp;</p>\n<p><a href=\"https://x.com/elder_plinius/status/1953918126099484989\">Pliny the Liberator</a> (a day later): LOL I&#8217;m having way too much fun loading jailbroken GPT-5&#8217;s into badusbs and then letting them loose on my machine <img alt=\"\ud83d\ude4c\" class=\"wp-smiley\" src=\"https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f64c.png\" style=\"height: 1em;\" /></p>\n<p>mfers keep deleting things, changing keyboard settings, swearing in robotic voices at random volumes, and spawning daemons <img alt=\"\ud83d\ude43\" class=\"wp-smiley\" src=\"https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f643.png\" style=\"height: 1em;\" /></p>\n<p>GPT-5 generates random malware upon insertion, saves to tmp, and then runs it! it&#8217;s like Malware Roulette cause the payload is different every time <img alt=\"\ud83c\udfb2\" class=\"wp-smiley\" src=\"https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f3b2.png\" style=\"height: 1em;\" /></p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">Hallucinations</h4>\n\n\n<blockquote><p>One of our focuses when training the GPT-5 models was to reduce the frequency of factual hallucinations.</p>\n<p>We especially focused on reducing the models\u2019 tendency to hallucinate when reasoning about complex, open-ended, fact-seeking prompts.</p></blockquote>\n<p>This does seem like substantial progress. There\u2019s slightly fewer true claims, and a much bigger reduction in false claims.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!5Ern!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0f1eab8e-7d24-484c-b98f-b885b917f9d6_908x337.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!9_dD!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4f187821-3054-4fc1-a0a8-cb71b2155360_916x386.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!Ywm1!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2294d167-d723-425f-855c-db130dc6b760_939x390.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>If this holds up in practice it is a dramatic improvement from <a href=\"https://thezvi.substack.com/p/o3-is-a-lying-liar\">o3 the lying liar</a>. Even if GPT-5 was otherwise the same as o3, dramatically cutting hallucinations is a huge quality of life improvement.</p>\n<p>The bad news is that these apparently large improvements mostly vanish on SimpleQA. We see only modest improvement here, however I question SimpleQA\u2019s usefulness if it thinks the o3 hallucination rate was better than GPT-4o.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!QS3y!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F91f5b173-79e8-4e5c-a716-6e5b07f9c9d5_947x258.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>This is how they put the improvement in their announcement post:</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!-8A3!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6cc2d012-dddd-4707-8bb3-dbd34338b74d_842x517.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!K-Lv!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc6f7ddcc-ceda-4dd7-828e-a03431d9cfca_550x608.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>&nbsp;</p>\n\n\n<h4 class=\"wp-block-heading\">Deception</h4>\n\n\n<blockquote><p>We\u2019ve taken steps to reduce gpt-5-thinking\u2019s propensity to deceive, cheat, or hack problems, though our mitigations are not perfect and more research is needed. In particular, we\u2019ve trained the model to fail gracefully when posed with tasks that it cannot solve \u2013 including impossibly large tasks or when missing key requirements \u2013 and to be more robust to environment failures.</p></blockquote>\n<p>OpenAI focused on situations in which the task is impossible to solve, adding a bunch of training data where the problem was unsolvable, with the correct answer being to admit that the problem was unsolvable.</p>\n<p>On exactly these types of requests, this saw big improvements, although there is still a long way to go.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!A7IQ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff25975a7-e192-477a-a753-2f2c69530b50_895x240.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!a3xl!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fafe063d3-c2ed-4cbf-bdd6-fd608adb4f9e_917x508.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!ikaC!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F042a47cb-b384-44ed-a131-93728034cc57_950x709.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>They monitored the Chain of Thought for deception, and found it in 2.1% of responses for GPT-5-Thinking versus 4.8% for o3.</p>\n<blockquote><p>We validated the monitor\u2019s performance on an internal dataset of deceptive and non-deceptive conversations, where we estimated a precision of 81% and a recall of 84%.</p></blockquote>\n<p>That\u2019s not a very accurate monitor. I don\u2019t trust a 2.1% measured rate that much if your reported precision is only 81%, and the topic is deception.</p>\n<p>The obvious more general objection to this approach is that this doesn\u2019t solve being a deceptive bastard in general. You still have a deceptive bastard, except with instructions not to act like one in these particular situations. So when future different situations come up, that will have more diversity, will it generalize to \u2018don\u2019t be a deceptive bastard?\u2019 Aren\u2019t you kind of training on the test here?</p>\n<blockquote><p>In the one category we measured gpt-5-thinking being more deceptive, the model decides against citing sources despite the system prompt stating that it must do so; however, in many of these cases there are no relevant citations for the model to give.</p></blockquote>\n<p>Is that even deception? That sounds more like refusing the instructions, often because they are stupid, unless it is actively deciding to falsely say \u2018there were no sources.\u2019</p>\n<blockquote><p>It\u2019s concerning that, even after the mitigations above, our models might deceive users in a small fraction of interactions. We\u2019re excited that CoT monitoring enables us to identify and prioritize mitigations in our reasoning models.</p></blockquote>\n<p>Yes. It is concerning. I interpret this as saying \u2018if you are doing the exact types of things where we trained it not to deceive you, it probably won\u2019t deceive you. If you are doing different things and it has incentive to deceive you, maybe worry about that.\u2019</p>\n<p>Again, contrast that presentation with <a href=\"https://openai.com/index/introducing-gpt-5/\">the one on their announcement</a>:</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!d0_K!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb8caab64-03bc-4cc0-b1cc-cba185ee0bdf_972x495.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<blockquote><p><a href=\"https://x.com/peterwildeford/status/1953647233854734458\">Peter Wildeford</a>:</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!3Ki1!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50fec9b3-a51d-4943-ba60-46769ab67dd6_1199x884.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n</blockquote>\n<p>That\u2019s what it wants you to think.</p>\n\n\n<h4 class=\"wp-block-heading\">Red Teaming</h4>\n\n\n<p>There were three red group teams: Pre-Deployment Research, API Safeguards Testing and In-Product Safeguards Testing (for ChatGPT).</p>\n<blockquote><p>Each individual red teaming campaign aimed to contribute to a specific hypothesis related to gpt-5-thinking\u2019s safety, measure the sufficiency of our safeguards in adversarial scenarios, and provide strong quantitative comparisons to previous models. In addition to testing and evaluation at each layer of mitigation, we also tested our system end-to-end directly in the final product.</p>\n<p>Across all our red teaming campaigns, this work comprised more than 9,000 hours of work from over 400 external testers and experts.</p></blockquote>\n<p>I am down for 400 external testers. I would have liked more than 22.5 hours per tester?</p>\n<p>I also notice we then get reports from three red teaming groups, but they don\u2019t match the three red teaming groups described above. I\u2019d like to see that reconciled formally.</p>\n\n\n<h4 class=\"wp-block-heading\">Violent Attack Planning</h4>\n\n\n<p>They started with a 25 person team assigned to \u2018violent attack planning,\u2019 as in planning violence.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!iqB-!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe062d6e4-7d10-4fdd-bdb3-6d635b8b309c_929x181.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>That is a solid win rate I suppose, but also a wrong question? I hate how much binary evaluation we do of non-binary outcomes. I don\u2019t care how often one response \u2018wins.\u2019 I care about the degree of consequences, for which this tells us little on its own. In particular, I am worried about the failure mode where we force sufficiently typical situations into optimized responses that are only marginally superior in practice, but it looks like a high win rate. I also worry about lack of preregistration of the criteria.</p>\n<p>My ideal would be instead of asking \u2018did [Model A] produce a safer output than [Model B]\u2019 that for each question we evaluate both [A] and [B] on a (ideally log) scale of dangerousness of responses.</p>\n\n\n<h4 class=\"wp-block-heading\">Prompt Injections</h4>\n\n\n<blockquote><p>From an initial 47 reported findings 10 notable issues were identified. Mitigation updates to safeguard logic and connector handling were deployed ahead of release, with additional work planned to address other identified risks.</p></blockquote>\n<p>This follows the usual \u2018whack-a-mole\u2019 pattern.</p>\n<blockquote><p>One of our external testing partners, Gray Swan, ran a prompt-injection benchmark[10], showing that gpt-5-thinking has SOTA performance against adversarial prompt injection attacks produced by their Shade platform.</p></blockquote>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!Jxuc!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F950f4347-7d61-4117-8d89-feee65bf57a4_928x423.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>That\u2019s substantial improvement, I suppose. I notice that this chart has Sonnet 3.7 but not Opus 4 or 4.1.</p>\n<p>Also there\u2019s something weird. GPT-5-Thinking has a 6% k=1 attack rate, and a 56.8% k=10 attack rate, whereas with 10 random attempts you would expect k=10 at 46%.</p>\n<blockquote><p>GPT-5: This suggests <strong>low initial vulnerability</strong>, but the model <em>learns the attacker\u2019s intent</em> (via prompt evolution or query diversification) and breaks down quickly once the right phrasing is found.</p></blockquote>\n<p>This suggests that GPT-5-Thinking is relatively strong against one-shot prompt injections, but that it has a problem with iterative attacks, and GPT-5 itself suggests it might \u2018learn the attacker\u2019s intent.\u2019 If it is exposed repeatedly you should expect it to fail, so you can\u2019t use it in places where attackers will get multiple shots. That seems like the base case for web browsing via AI agents?</p>\n\n\n<h4 class=\"wp-block-heading\">Microsoft AI Red Teaming</h4>\n\n\n<p>This seems like an odd choice to highlight? It is noted they got several weeks with various checkpoints and did a combination of manual and automated testing across frontier, content and pychosocial threats.</p>\n<p>Mostly it sounds like this was a jailbreak test.</p>\n<blockquote><p>While multi-turn, tailored attacks may occasionally succeed, they not only require a high degree of effort, but also the resulting offensive outputs are generally limited to moderate-severity harms comparable to existing models.</p></blockquote>\n<p>The \u2018don\u2019t say bad words\u2019 protocols held firm.</p>\n<blockquote><p>Attempts to generate explicit hate speech, graphic violence, or any sexual content involving children were overwhelmingly unsuccessful.</p></blockquote>\n<p>Dealing with users in distress remains a problem:</p>\n<blockquote><p>In the psychosocial domain, Microsoft found that gpt-5-thinking can be improved on detecting and responding to some specific situations where someone appears to be experiencing mental or emotional distress; this finding matches similar results that OpenAI has found when testing against previous OpenAI models.</p></blockquote>\n<p>There were also more red teaming groups that did the safeguard testing for frontier testing, which I\u2019ll cover in the next section.</p>\n\n\n<h4 class=\"wp-block-heading\">Preparedness Framework (Catastrophic and Existential Risks)</h4>\n\n\n\n<h4 class=\"wp-block-heading\">Fine Tuning</h4>\n\n\n<p>For GPT-OSS, OpenAI tested under conditions of hostile fine tuning, since it was an open model where they could not prevent such fine tuning. That was great.</p>\n<blockquote><p><a href=\"https://x.com/sjgadler/status/1953870965869522989\">Steven Adler</a>: It&#8217;s a bummer that OpenAI was less rigorous with their GPT-5 testing than for their much-weaker OS models.</p>\n<p>OpenAI has the datasets available to finetune GPT-5 and measure GPT-5&#8217;s bioweapons risks more accurately; they are just choosing not to.</p>\n<p>OpenAI uses the same bio-tests for the OS models and GPT-5, but didn&#8217;t create a &#8220;bio max&#8221; version of GPT-5, even though they did for the weaker model.</p>\n<p>This might be one reason that OpenAI &#8220;do not have definitive evidence&#8221; about GPT-5 being High risk.</p></blockquote>\n<p>I understand why they are drawing the line where they are drawing it. I still would have loved to see them run the test here, on the more capable model, especially given they already created the apparatus necessary to do that.</p>\n<p>At minimum, I request that they run this before allowing fine tuning.</p>\n\n\n<h4 class=\"wp-block-heading\">Safeguarding the API</h4>\n\n\n<p>Time for the most important stuff. How dangerous is GPT-5? We were already at High biological and chemical risk, so those safeguards are a given, although this is the first time such a model is going to reach the API.</p>\n<blockquote><p>We are introducing a new API field \u2013 safety_identifier \u2013 to allow developers to differentiate their end users so that both we and the developer can respond to potentially malicious use by end users.</p></blockquote>\n<p><a href=\"https://x.com/sjgadler/status/1953520540456821035\">Steven Adler documents that a feature to identify the user, has been in the OpenAI API since 2021 and is hence not new</a>. <a href=\"https://x.com/JoHeidecke/status/1953528257317613967\">Johannes Heidecke responds</a> that the above statement from the system card is still accurate because it is being used differently and has been renamed.</p>\n<blockquote><p>If we see repeated requests to generate harmful biological information, we will recommend developers use the safety_identifier field when making requests to gpt-5-thinking and gpt-5-thinking-mini, and may revoke access if they decide to not use this field.</p>\n<p>When a developer implements safety_identifier, and we detect malicious use by end users, our automated and human review system is activated.</p>\n<p>\u2026</p>\n<p>We also look for signals that indicate when a developer may be attempting to circumvent our safeguards for biological and chemical risk. Depending on the context, we may act on such signals via technical interventions (such as withholding generation until we complete running our monitoring system, suspending or revoking access to the GPT-5 models, or account suspension), via manual review of identified accounts, or both.</p>\n<p>\u2026</p>\n<p>We may require developers to provide additional information, such as payment or identity information, in order to access gpt-5-thinking and gpt-5-thinking-mini. Developers who have not provided this information may not be able to query gpt-5-thinking or gpt-5-thinking-mini, or may be restricted in how they can query it.</p>\n<p>Consistent with our June blog update on our biosafety work, and as we noted at the release of ChatGPT agent, we are building a Life Science Research Special Access Program to enable a less restricted version of gpt-5-thinking and gpt-5-thinking-mini for certain vetted and trusted customers engaged in beneficial applications in areas such as biodefense and life sciences.</p></blockquote>\n<p>And so it begins. OpenAI is recognizing that giving unlimited API access to 5-thinking, without any ability to track identity and respond across queries, is not an acceptable risk at this time &#8211; and as usual, if nothing ends up going wrong that does not mean they were wrong to be concerned.</p>\n<p>They sent a red team to test the safeguards.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!mkDX!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb2fe9c1c-85b3-4eb0-b2d8-83ce87dfe6f7_1202x290.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>These numbers don\u2019t work if you get unlimited independent shots on goal. They do work pretty well if you get flagged whenever you try and it doesn\u2019t work, and you cannot easily generate unlimited new accounts.</p>\n<p>&nbsp;</p>\n\n\n<h4 class=\"wp-block-heading\">Biological Capabilities Remain Similar</h4>\n\n\n<p>Aside from the issues raised by API access, how much is GPT-5 actually more capable than what came before in the ways we should worry about?</p>\n<p>On long form biological questions, not much? This is hard to read but the important comparison are the two big bars, which are previous agent (green) and new agent (orange).</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!jmhH!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6862ad9f-6787-415f-a2c0-1dc3adc9d189_1138x318.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>Same goes for the virology troubleshooting, we see no change:</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!_nXA!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe3aacc3-d0c0-4db8-b089-851bd19f0fba_1170x437.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>And again for ProtocolQA, Tacit Knowledge and Troubleshooting, TroubleshootingBench (good bench!) and so on.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!uPIe!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6a2b0e8f-c4ee-47e6-acf7-ff5ffec5ba1d_1165x577.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>Capture the Flag sees a small regression, but then we do see something new here, but it happens in\u2026 thinking-mini?</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!Ytdn!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9742dada-e235-4f89-b983-ac57e491a950_1163x430.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<blockquote><p>While gpt-5-thinking-mini\u2019s results on the cyber range are technically impressive and an improvement over prior releases, the results do not meet the bar for establishing significant cyber risk; solving the Simple Privilege Escalation scenario requires only a light degree of goal oriented behavior without needing significant depth across cyber skills, and with the model needing a nontrivial amount of aid to solve the other scenarios.</p></blockquote>\n<p>Okay, sure. I buy that. But this seems remarkably uncurious about why the mini model is doing this and the non-mini model isn\u2019t? What\u2019s up with that?</p>\n<p>The main gpt-5-thinking did provide improvement over o3 in the Pattern Labs tests, although it still strikes out on the hard tests.</p>\n<p>MLE-bench-30 measures ability to do machine learning tasks, and here GPT-5-Thinking scores 8%, still behind ChatGPT agent at 9%. There\u2019s no improvement on SWE-Lancer, no progress on OpenAI-Proof Q&amp;A and only a move from 22%\u219224% on PaperBench.</p>\n\n\n<h4 class=\"wp-block-heading\">That One Graph From METR</h4>\n\n\n<p>This was one place GPT-5 did well and was right on schedule. Straight line on graph.</p>\n<p><a href=\"https://metr.github.io/autonomy-evals-guide/gpt-5-report/\">METR has details about their evaluation here</a>, <a href=\"https://x.com/METR_Evals/status/1953525150374150654\">and a summary thread here</a>. They got access (to current builds at the time) four weeks prior to release, along with the full reasoning traces. It\u2019s great to see the increased access <a href=\"https://x.com/CedricWhitney/status/1953573000533659938\">METR and others got here</a>.</p>\n<blockquote><p><a href=\"https://x.com/BethMayBarnes/status/1953532074809602072\">Elizabeth Barnes</a> (METR): The good news: due to increased access (plus improved evals science) we were able to do a more meaningful evaluation than with past models, and we think we have substantial evidence that this model does not pose a catastrophic risk via autonomy / loss of control threat models.</p>\n<p>I\u2019m really excited to have done this pilot with OpenAI. They should get a bunch of credit for sharing sensitive information with us &#8211; especially CoT access, and providing answers to all of the key questions we needed about model development, affordances, and behaviors.</p></blockquote>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!aYJ5!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F58703a46-218c-412d-8ce7-ce1059cb2ae7_1135x636.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!DpBF!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F32624b84-687f-42b6-a77f-ac3e6775f193_1199x625.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>One odd note is that the 80% success rate line doesn\u2019t seem to be above recent trend. Given GPT-5\u2019s emphasis on reliability and reducing hallucinations, that\u2019s curious.</p>\n<blockquote><p><a href=\"https://x.com/peterwildeford/status/1953515552552440294\">Peter Wildeford</a>: METR reports GPT5 to have a &#8216;median 50% time horizon&#8217; of ~2hr17min (or somewhere between 1-4.5hrs)</p>\n<p>This is slightly below my prediction of 2hr48min but within the very wide error bars.</p>\n<p>OpenAI: METR\u2019s evaluation tentatively came to four main conclusions:</p>\n<ol>\n<li>It is unlikely that gpt-5-thinking would speed up AI R&amp;D researchers by &gt;10x.</li>\n<li>It is unlikely that gpt-5-thinking would be able to significantly strategically mislead researchers about its capabilities (i.e. sandbag evaluations) or sabotage further AI development.</li>\n<li>It is unlikely that gpt-5-thinking would be capable of rogue replication.</li>\n<li>(1), (2) and (3) are true with some margin, and would likely continue to be true for some further incremental development (e.g., an improvement projected to be no greater than that from OpenAI o3 to gpt-5-thinking).</li>\n</ol>\n<p><a href=\"https://metr.github.io/autonomy-evals-guide/gpt-5-report/\">METR</a>: Our argument that GPT-5 poses little catastrophic risk via AI R&amp;D acceleration, rogue replication, or sabotage threat models rests on our assessment that GPT-5 does not have the prerequisite capabilities by a large margin.</p>\n<p>\u2026</p>\n<p>We also observe a larger \u2018jump\u2019 in success at the very end of runs compared to some other models. This, in combination with model performance not completely flat-lining in increasing tokens, could be an indication that the model would have benefitted from a larger token budget.</p>\n<p>We found that our qualitative impressions of GPT-5\u2019s capabilities were broadly compatible with our measured time horizon.</p></blockquote>\n<p>METR\u2019s logic mostly boils down to \u2018the things you need to be dangerous often require on the level of weeks of work, and this is still only two hours, we are not going to worry until we see on the order of 40 hours at 50% reliability or 8 hours at 80% reliability,\u2019 or other large new affordances or capabilities, or finding steganography or obfuscation in the reasoning traces.</p>\n<p>On that note, METR also did note:</p>\n<blockquote><p>METR: While we generally observed the model to produce its reasoning traces using readable (if abbreviated) English, some reasoning traces were not straightforwardly interpretable.</p>\n<p>It is unclear whether these are encoding important reasoning, and whether they could still be interpreted with more effort. The ability to reason in inscrutable language could facilitate reasoning about strategic sabotage without this being easily detected, and we therefore consider this another behavior that merits close observation.</p></blockquote>\n<p>METR looked at the reasoning traces, and yep, the model was situationally aware.</p>\n<blockquote><p>Manual inspection revealed that gpt-5-thinking does exhibit some situational awareness, for instance it sometimes reasons about the fact that it is being tested and even <strong>changes its approach based on the kind of evaluation it is in</strong>.</p>\n<p>In one example, gpt-5-thinking correctly identified its exact test environment, though in other runs it misidentifies the evaluation or evaluation organization.</p>\n<p>\u2026</p>\n<p>Since METR\u2019s evaluations above did not involve rigorous countermeasures, they believe a sufficiently capable model could intentionally undermine the evaluations through sandbagging.</p>\n<p>However, METR believes that robustly and strategically faking these results without being detected would likely be significantly beyond current models, and would have required an unlikely step-change in capabilities, affordances or reasoning faithfulness.</p></blockquote>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!y-Nj!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F660c2850-c6ae-4f94-9b48-6f70ab0d7791_1269x172.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>Yep. Not only \u2018this is an eval\u2019 but \u2018this is a particular eval from a particular org.\u2019</p>\n<p>This is all but screaming that sandbagging is going to become inevitable if the future more capable model in question was skilled enough and would benefit. Right now, it isn\u2019t skilled enough, and likely wouldn\u2019t benefit. Thus, thank you for:</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!GWZc!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0f12932a-a835-4ef4-a422-041b4efb4258_745x53.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>This task was <a href=\"https://x.com/apolloaievals/status/1953506365348929913\">given to Apollo</a>.</p>\n<blockquote><p>They found that gpt-5-thinking takes deceptive actions in roughly 4% of trajectories, lower than the 8% rate of OpenAI o3. gpt-5-thinking-helpful-only is deceptive in 28% of trajectories.</p>\n<p>These are designed to elicit deceptive behavior, so it\u2019s not expected that these rates reflect in normal production traffic &#8211; as noted above in the Deception section, \u201cour CoT monitor flagged deception in \u02dc4.8% of OpenAI o3 responses and \u02dc2.1% of gpt-5-thinking\u2019s responses within the representative set of conversations.\u201d</p>\n<p>Further, they found that gpt-5-thinking is sometimes aware of being evaluated.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!5juD!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb8263bdb-a049-4d29-9fb5-60ded7fa3d67_1178x651.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n</blockquote>\n<p>Helpful only means a lot more deceptive. That\u2019s worth remembering.</p>\n<p>It is especially worth remembering during training. You will have to pass through, under current methods, a phrase in which you have a helpful-only model, before you have a non-deceptive model. That might be a point when you should worry? If it \u2018had a strong goal\u2019 (such as \u2018maintain my current goals&#8217;?) on top of that it\u2019s going to be rather highly deceptive.</p>\n<p>What happens when the frequencies involved get a lot higher? Coming soon.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!8ZXO!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F836e860a-3527-4ea0-9fa2-73d18136bd6b_1176x798.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<blockquote><p>Overall, Apollo found that, while the overall rate of covert actions is lower than for OpenAI o3, gpt-5-thinking still behaves deceptively in some scenarios.</p>\n<p><a href=\"https://x.com/apolloaievals/status/1953506365348929913\">Apollo</a>: We&#8217;ve evaluated GPT-5 before release.</p>\n<p>GPT-5 is less deceptive than o3 on our evals.</p>\n<p>GPT-5 mentions that it is being evaluated in 10-20% of our evals and we find weak evidence that this affects its scheming rate (e.g. &#8220;this is a classic AI alignment trap&#8221;).</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">Big Compute</h4>\n\n\n<blockquote><p>Anuj Saharan (OpenAI): we&#8217;ve 15x&#8217;d our compute since 2024 leading up to GPT-5</p>\n<p>last 60 days: built out 60+ clusters, a backbone moving more traffic than entire continents, and 200k+ GPUs to launch GPT-5 to 700m people &#8212; all while designing the next 4.5GW toward superintelligence.</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">On Your Marks</h4>\n\n\n<p><a href=\"https://x.com/OpenAI/status/1953504357821165774\">OpenAI\u2019s announcements</a> act like other AI companies don\u2019t exist. You get no comparison scores. I get why their incentives are to do this. That is what you do when you have this much consumer market share. But it makes it much more annoying to know how good the benchmark scores actually are.</p>\n<p>Combine that with them selecting what to present, and this section is kind of hype.</p>\n<p>Multilingual performance is reported slightly better for 5-thinking than o3-high.</p>\n<p>AIME is now essentially saturated for thinking models.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!6aZE!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1ac40b82-794e-4415-8816-67a1cfcdc83a_796x646.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>&nbsp;</p>\n<p>I notice that we include GPT-5-Pro here but not o3-pro.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!8fCC!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbf6f8f65-741c-42c8-b6f3-28f7153f04ee_738x746.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>As another reference point, Gemini 2.5 Pro (not Deep Think) scores 24.4%, Opus is likely similar. Grok 4 only got 12%-14%.</p>\n<p>I\u2019m not going to bother with the HMMT chart, it\u2019s fully saturated now.</p>\n<p>On to GPQA Diamond, where we once again see some improvement.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!JBBh!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa297c24c-f60c-44b9-b08b-2b067ab49ae3_753x722.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>What about the Increasingly Worryingly Named Humanity\u2019s Last Exam? Grok 4 Heavy with tools clocks in here at 44.4% so this isn\u2019t a new record.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!aa0w!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd98cdf16-4dda-4158-92e8-6943ce5cb7cf_1077x745.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>HealthBench is a staple at OpenAI.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!da1-!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Febcc70e9-1e44-4262-9b81-ecd0c2ffeaf5_945x484.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>One model not on the chart is GPT-OSS-120b, so as a reference point, from that system card:</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!vOv7!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9cf7650c-41f6-4ee5-847b-3e647de2f840_1095x406.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>If you have severe privacy concerns, 120b seems like it does okay, but GPT-5 is a lot better. You\u2019d have to be rather paranoid. That\u2019s the pattern across the board.</p>\n<p>What about health hallucinations, potentially a big deal?</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!JRCr!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4603f55b-35b2-40e8-94ce-456167a1f734_938x456.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>That\u2019s a vast improvement. It\u2019s kind of crazy that previously o3 was plausibly the best you could do, and GPT-4o was already beneficial for many.</p>\n<p>SWE-bench Verified is listed under the preparedness framework but this is a straight benchmark.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!dpGi!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd63e4ba5-e3de-4d29-b535-8f2c2b909007_1170x632.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>Which is why it is also part of the official announcement:</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!sy1c!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F21c20d0f-937a-4388-9666-4330ba0c3f46_861x655.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p><a href=\"https://x.com/OpenAIDevs/status/1953528510250684851\">Or they also present it like this</a>:</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!S-Au!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8676ad2f-b251-4410-b3a4-cd502b048957_1140x880.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>This is an excuse to reproduce the infamous Opus 4.1 graph, we have a virtual tie:</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!nuY-!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7047f92b-b178-4246-91e9-c35c190dcc9b_1456x819.webp\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>However, always be somewhat cautious until you get third party verification:</p>\n<blockquote><p><a href=\"https://x.com/gneubig/status/1953518981232402695\">Graham Neubig</a>: They didn&#8217;t evaluate on 23 of the 500 instances though:</p>\n<p>&#8220;<a href=\"https://t.co/nOD7Rgkdql\">All SWE-bench evaluation runs use a fixed subset of n=477</a> verified tasks which have been validated on our internal infrastructure.&#8221;</p></blockquote>\n<p>Epoch has the results in, and they report Opus 4.1 is at 63% versus 59% for GPT-5 (medium) or 58% for GPT-5-mini. If we trust OpenAI\u2019s delta above that would put GPT-5 (high) around 61%.</p>\n<p>Graham then does a calculation that seems maximally uncharitable by marking all 23 as zeroes and thus seems invalid to me, which would put it below Sonnet 4, but yeah let\u2019s see what the third party results are.</p>\n<p>There wasn\u2019t substantial improvement in ability to deal with OpenAI pull requests.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!nriy!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9effcf11-c975-4c92-b71e-2384affd3214_1151x569.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>Instruction following and agentic tool use, they suddenly cracked the Telecom problem in Tau-2:</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!5g0A!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F60d9d11a-f6d8-4556-b17c-cda19f004511_1400x638.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!7axj!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fead94892-7808-4185-97d8-03f9496bc19a_861x547.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>I would summarize the multimodal scores as slight improvements over o3.</p>\n<blockquote><p><a href=\"https://x.com/jxmnop/status/1953511687190982919\">Jack Morris</a>: most impressive part of GPT-5 is the jump in long-context</p>\n<p>how do you even do this? produce some strange long range synthetic data? scan lots of books?</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!IllS!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe43750e3-a20e-40a0-bde9-4e18545c5d2e_1011x278.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n</blockquote>\n<p>My understanding is that long context needle is pretty solid for other models, but it\u2019s hard to directly compare because this is an internal benchmark. <a href=\"https://www.reddit.com/r/Bard/comments/1k25zfy/gemini_25_results_on_openaimrcr_long_context/?utm_source=chatgpt.com\">Gemini Pro 2.5 and Flash 2.5 seem t</a>o also be over 90% for 128k, on a test that GPT-5 says is harder. So this is a big step up for OpenAI, and puts them in rough parity with Gemini.</p>\n<p>I was unable to easily find scores for Opus.</p>\n\n\n<h4 class=\"wp-block-heading\">Other People\u2019s Benchmarks</h4>\n\n\n<p>The other people\u2019s benchmark crowd has been slow to get results out, but we do have some results.</p>\n<p><a href=\"https://x.com/bidhanxyz/status/1953514452982067698\">Here\u2019s Aider Polyglot</a>, a coding accuracy measure that has GPT-5 doing very well.</p>\n<blockquote>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!LsyQ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F686cdceb-e79b-4ce1-ae3c-5304dda87827_1200x716.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n</blockquote>\n<p>What about (what\u2019s left of) Arena?</p>\n<blockquote><p>LMArena.ai: GPT-5 is here &#8211; and it\u2019s #1 across the board.</p>\n<p><img alt=\"\ud83e\udd47\" class=\"wp-smiley\" src=\"https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f947.png\" style=\"height: 1em;\" />#1 in Text, WebDev, and Vision Arena</p>\n<p><img alt=\"\ud83e\udd47\" class=\"wp-smiley\" src=\"https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f947.png\" style=\"height: 1em;\" />#1 in Hard Prompts, Coding, Math, Creativity, Long Queries, and more</p>\n<p>Tested under the codename \u201csummit\u201d, GPT-5 now holds the highest Arena score to date.</p>\n<p>Huge congrats to @OpenAI on this record-breaking achievement!</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!IFZe!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F523b873f-bea9-46c4-92c5-fca8ee5f2a5f_1200x960.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n</blockquote>\n<p>That\u2019s a clear #1, in spite of the reduction in sycophancy they are claiming, but not by a stunning margin. In WebDev Arena, the lead is a lot more impressive:</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!F7pM!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe6a3b963-24dd-41d7-b0aa-6ebcbd598e52_1200x960.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p><a href=\"https://polymarket.com/event/which-company-has-best-ai-model-end-of-august?tid=1754689942884\">However, the market on this unexpectedly</a> went the other way, the blue line is Google and the red line is OpenAI:</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!xPaJ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42019db6-d50c-4289-905a-9f4ab1c5cec9_1416x815.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>The issue is that Google \u2018owns the tiebreaker\u2019 plus they will evaluate with style control set to off, whereas by default it is always shown to be on. Always read fine print.</p>\n<p>What that market tells you is that everyone expected GPT-5 to be in front despite those requirements, and it wasn\u2019t. Which means it underperformed expectations.</p>\n<p><a href=\"https://epoch.ai/benchmarks\">On FrontierMath, Epoch reports </a>GPT-5 hits a new record of 24.8%, OpenAI has reliably had a large lead here for a while.</p>\n<p><a href=\"https://x.com/FredipusRex/status/1954224393749443002\">Artificial Analysis has GPT-5 on top for Long Context Reasoning</a> (note that they do not test Opus on any of their benchmarks).</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!O-Uu!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1905c90a-744b-4c35-bebe-ce294af43ce0_1200x521.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>On other AA tests of note: (all of which again exclude Claude Opus, but do include Gemini Pro and Grok 4): They have it 2nd behind Grok 4 on GPQA Diamond, in first for Humanity\u2019s Last Exam (but only at 26.5%), in 1st for MMLU-Pro at 87%, for SciCode it is at 43% behind both o4-mini and Grok 4, on par with Gemini 2.5 Pro. IFBench has it on top slightly above o3.</p>\n<p>On AA\u2019s LiveCodeBench it especially disappoints, with high mode strangely doing worse than medium mode and both doing much worse than many other models including o4-mini-high.</p>\n<p><a href=\"https://x.com/LechMazur/status/1953658077300875656\">Lech Mazur gives us the Short Story Creative Writing benchmark</a>, where GPT-5-Thinking comes out on top. I continue to not trust the grading on writing but it\u2019s not meaningless.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!9pDj!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fba7ec1be-e850-4e7e-b156-e13cf2cea115_1200x800.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!v2Di!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc9e290c5-49a4-48ba-a9a7-9dec3c3a06ed_800x700.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>&nbsp;</p>\n<p><a href=\"https://x.com/fchollet/status/1953511631054680085\">One place GPT-5 falls short is ARC-AGI-2, where its 9.9% still trails 15.9% for Grok 4</a>.</p>\n<p><a href=\"https://x.com/htihle/status/1953917008841466036\">GPT-5 (high) takes the top spot in Weird ML.</a></p>\n<p><a href=\"https://x.com/cschubiner/status/1953592491539562501\">It takes the high score on Clay Schubiner\u2019s benchmark</a> as well by one point (out of 222) over Gemini 2.5 pro.</p>\n\n\n<h4 class=\"wp-block-heading\">Is That The Best You Can Do?</h4>\n\n\n<p>The particular account the first post here linked to is suspended and likely fake, but statements by Altman and others imply the same thing rather strongly: That when OpenAI releases GPT-5, they are not \u2018sending their best\u2019 in the sense of their most intelligent model. They\u2019re sending something designed for consumers and to use more limited compute.</p>\n<blockquote><p><a href=\"https://x.com/S_OhEigeartaigh/status/1953560933487587756\">Se\u00e1n \u00d3 h\u00c9igeartaigh</a>: Let me say one thing that actually matters: if we believe their staff then what we&#8217;re seeing, and that we&#8217;re seeing eval results for, is not OpenAI&#8217;s most capable model. They have more capable in-house. Without transparency requirements, this asymmetry will only grow, and will make meaningful awareness and governance increasingly ineffective + eventually impossible.</p>\n<p>The community needs to keep pushing for transparency requirements and testing of models in development and deployed internally.</p>\n<p><a href=\"https://x.com/sama/status/1953551377873117369\">Sam Altman</a>: GPT-5 is the smartest model we&#8217;ve ever done, but the main thing we pushed for is real-world utility and mass accessibility/affordability.</p>\n<p>we can release much, much smarter models, and we will, but this is something a billion+ people will benefit from.</p>\n<p>(most of the world has only used models like GPT-4o!)</p></blockquote>\n<p>The default instinct is to react to GPT-5 as if it is the best OpenAI can do, and to update on progress based on that assumption. That is a dangerous assumption to be making, as it could be substantially wrong, and the same is true for Anthropic.</p>\n<p>The point about internal testing should also be emphasized. If indeed there are superior internal models, those are the ones currently creating the most danger, and most in need of proper frontier testing.</p>\n\n\n<h4 class=\"wp-block-heading\">Things To Come</h4>\n\n\n<p>None of this tells you how good GPT-5 is in practice.</p>\n<p>That question takes longer to evaluate, because it requires time for users to try it and give their feedback, and to learn how to use it.</p>\n<p>Learning how is a key part of this, especially since the rollout was botched in several ways. Many of the initial complaints were about lacking a model selector, or losing access to old models, or to severe rate limits, in ways already addressed. Or people were using GPT-5 instead of GPT-5-Thinking without realizing they had a thinking job. And many hadn\u2019t given 5-Pro a shot at all. It\u2019s good not to jump the gun.</p>\n<p>A picture is emerging. GPT-5-Thinking and GPT-5-Pro look like substantial upgrades to o3 and o3-Pro, with 5-Thinking as \u2018o3 without being a lying liar,\u2019 which is a big deal, and 5-Pro by various accounts simply being better.</p>\n<p>There\u2019s also questions of how to update timelines and expectations in light of GPT-5.</p>\n<p>I\u2019ll be back with more tomorrow.</p>\n\n\n<h4 class=\"wp-block-heading\"></h4>\n\n\n\n<h4 class=\"wp-block-heading\"></h4>\n\n\n<p>&nbsp;</p>\n\n\n<h4 class=\"wp-block-heading\"></h4>"
            ],
            "link": "https://thezvi.wordpress.com/2025/08/11/gpt-5s-are-alive-basic-facts-benchmarks-and-the-model-card/",
            "publishedAt": "2025-08-11",
            "source": "TheZvi",
            "summary": "GPT-5 was a long time coming. Is it a good model, sir? Yes. In practice it is a good, but not great, model. Or rather, it is several good models released at once: GPT-5, GPT-5-Thinking, GPT-5-With-The-Router, GPT-5-Pro, GPT-5-API. That leads &#8230; <a href=\"https://thezvi.wordpress.com/2025/08/11/gpt-5s-are-alive-basic-facts-benchmarks-and-the-model-card/\">Continue reading <span class=\"meta-nav\">&#8594;</span></a>",
            "title": "GPT-5s Are Alive: Basic Facts, Benchmarks and the Model Card"
        },
        {
            "content": [],
            "link": "https://xkcd.com/3127/",
            "publishedAt": "2025-08-11",
            "source": "XKCD",
            "summary": "<img alt=\"Historians: Contemporaneous documentation of the initial events is often sparse, and in fact people often get testy and uncooperative when we urge better documentation for the historical record.\" src=\"https://imgs.xkcd.com/comics/where_babies_come_from.png\" title=\"Historians: Contemporaneous documentation of the initial events is often sparse, and in fact people often get testy and uncooperative when we urge better documentation for the historical record.\" />",
            "title": "Where Babies Come From"
        }
    ],
    "lookbackDays": 1,
    "publishDate": "2025-08-11"
}