{
    "articles": [
        {
            "content": [
                "<p>By now, nearly every engineer has seen an AI assistant write a perfect unit test or churn out flawless boilerplate. For simple, greenfield work, these tools are incredibly effective.</p><p>But ask it to do something real, like refactor a core service that orchestrates three different libraries, and a frustrating glass ceiling appears. The agent gets lost, misses context, and fails to navigate the complex web of dependencies that make up a real-world system.</p><p>Faced with this complexity, our first instinct is to write more documentation. We build mountains of internal documents, massive <code>CLAUDE.md</code>s, and detailed READMEs, complaining that the AI is \"not following my docs\" when it inevitably gets stuck. This strategy is a trap. It expects the AI to learn our messy, human-centric systems, putting an immense load on the agent and dooming it to fail. To be clear, <strong>documentation is a necessary first step</strong>, but it's not sufficient to make agents effective.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!MF9U!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0468c693-bc9e-4acf-9cb1-ecab247d0f74_1536x1024.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"385.46565934065933\" src=\"https://substackcdn.com/image/fetch/$s_!MF9U!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0468c693-bc9e-4acf-9cb1-ecab247d0f74_1536x1024.png\" width=\"578\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a><figcaption class=\"image-caption\">Claude Code figuring out your monorepo. Image by ChatGPT.</figcaption></figure></div><p>The near-term, most effective path isn&#8217;t about throwing context at the AI to be better at navigating our world; it&#8217;s about redesigning our software, libraries, and APIs with the AI agent as the primary user.</p><p>This post<a class=\"footnote-anchor\" href=\"https://blog.sshh.io/feed#footnote-1\" id=\"footnote-anchor-1\" target=\"_self\">1</a> applies a set of patterns learned from designing and deploying AI agents in complex environments to building software for coding agents like Claude Code. You may also be interested in a slightly higher level article on <a href=\"https://blog.sshh.io/p/ai-powered-software-engineering\">AI-powered Software Engineering</a>.</p><div class=\"subscription-widget-wrap-editor\"><div class=\"subscription-widget show-subscribe\"><div class=\"preamble\"><p class=\"cta-caption\">Thanks for reading Shrivu&#8217;s Substack! Subscribe for free to receive new posts and support my work.</p></div><form class=\"subscription-widget-subscribe\"><input class=\"email-input\" name=\"email\" tabindex=\"-1\" type=\"email\" /><input class=\"button primary\" type=\"submit\" value=\"Subscribe\" /><div class=\"fake-input-wrapper\"><div class=\"fake-input\"></div><div class=\"fake-button\"></div></div></form></div></div><h2>Six Patterns for AI-Friendly Design</h2><p>The core principle is simple: <strong>reduce the need for external context and assumptions.</strong> An AI agent is at its best when the next step is obvious and the tools are intuitive. This framework builds from the most immediate agent interaction all the way up to the complete system architecture. This isn&#8217;t to say today's agents can&#8217;t reason or do complex things. But to unlock the full potential of today&#8217;s models&#8212;to not just solve problems, but do so consistently&#8212;these are your levers.</p><h3>Pattern 1: Every Output is a Prompt</h3><p>In an agentic coding environment, every interaction with a tool is a turn in a conversation. The tool's output&#8212;whether it succeeds or fails&#8212;should be designed as a helpful, guiding prompt for the agent's next turn.</p><h4>The Successful Output</h4><p>A traditional CLI command that succeeds often returns very little: a resource ID, a silent exit code 0, or a simple \"OK.\" For an agent, this is a dead end. An AI-friendly successful output is conversational. It not only confirms success but also suggests the most common next steps, providing the exact commands and IDs needed to proceed.</p><p><strong>Don't:</strong></p><pre><code><code>$ ./deploy --service=api\nSuccess!</code></code></pre><p><strong>Do (AI-Friendly):</strong></p><pre><code><code>Success! Deployment ID: deploy-a1b2c3d4\n\nNext Steps:\n- To check the status, run: ./get-status --id=deploy-a1b2c3d4\n- To view logs, run: ./get-logs --id=deploy-a1b2c3d4\n- To roll back this deployment, run: ./rollback --id=deploy-a1b2c3d4\n</code></code></pre><h4>The Failure Output</h4><p>This is the other side of the same coin. For an AI agent, <strong>an error message must be a prompt for its next action.</strong> A poorly designed error is a dead end; a well-designed one is a course correction. A perfect, AI-friendly error message contains three parts:</p><ol><li><p><strong>What went wrong:</strong> A clear, readable description of the failure.</p></li><li><p><strong>How to resolve it:</strong> Explicit instructions for fixing the issue, like a direct command to run or the runbook you already wrote but documented somewhere else.</p></li><li><p><strong>What to do next:</strong> Guidance on the next steps after resolution.</p></li></ol><p>By designing both your successful and failed outputs as actionable prompts, you transform your tools from simple utilities into interactive partners that actively guide the agent toward its goal.</p><h3>Pattern 2: Make Your Code Self-Documenting</h3><p>The best documentation is the documentation the agent doesn't need to read. If an error message is the agent's reactive guide, embedded documentation is its proactive one. When intuition isn't enough, integrate help as close to the point of use as possible.</p><ul><li><p><strong>The CLI:</strong> Every command should have a comprehensive <code>--help</code> flag that serves as the canonical source of truth. This should be detailed enough to replace the need for other usage documentation. Claude already knows <code>--help</code> is where it should start first.</p></li><li><p><strong>The Code:</strong> Put a comment block at the top of critical files explaining its purpose, key assumptions, and common usage patterns. This not only helps the agent while exploring the code but also enables IDE-specific optimizations like codebase indexing.</p></li></ul><p>If an agent has to leave its current context to search a separate knowledge base, you&#8217;ve introduced a potential point of failure. Keep the necessary information local.</p><h3>Pattern 3: Choose the Right Interface (CLI vs. MCP)</h3><p>After establishing <em>what</em> we communicate to the agent, we must define <em>how</em> we communicate. The protocol for agent interaction is a critical design choice.</p><ul><li><p><strong>CLI (<a href=\"https://en.wikipedia.org/wiki/Command-line_interface\">Command-line interface</a>) via </strong><code>bash</code><strong>:</strong> This is a flexible, raw interface powerful for advanced agents like Claude Code that have strong scripting abilities. The agent can pipe commands, chain utilities, and perform complex shell operations. CLI-based tools can also be context-discovered rather than being exposed directly to the agent via its system prompt (which limits the max total tools in the MCP case). The downside is that it's less structured and the agent may need to take multiple tool calls to get the syntax correctly.</p></li></ul><pre><code><code>$ read-logs --help\n$ read-logs --name my-service-logs --since 2h</code></code></pre><ul><li><p><strong>MCP (<a href=\"https://blog.sshh.io/p/everything-wrong-with-mcp\">Model Context Protocol</a>):</strong> It provides a structured, agent-native way to expose your tools directly to the LLM's API. This gives you fine-grained control over the tool's definition as seen by the model and is better for workflows that rely on well-defined tool calls. This is particularly useful for deep prompt optimization, security controls, and to take advantage some of the more recent <a href=\"https://modelcontextprotocol.io/specification/2025-06-18/client/elicitation\">fancy UX features that MCP provides</a>. MCP today can also be a bit trickier for end-users to install and authorize compared to existing install setups for cli tools (e.g. <code>brew install</code> or just adding a new <code>bin/</code> to your <code>PATH</code>).</p></li></ul><pre><code><code>$ read_logs (MCP)(name: \"my-service-logs\", since: \"2h\")</code></code></pre><p>Overall, I&#8217;m starting to come to the conclusion that for developer tools&#8212;agents that can already interact with the file system and run commands&#8212;CLI-based is often the better and easier approach<a class=\"footnote-anchor\" href=\"https://blog.sshh.io/feed#footnote-2\" id=\"footnote-anchor-2\" target=\"_self\">2</a>.</p><h3>Pattern 4: The Metaphorical Interface</h3><p>LLMs have a deep, pre-existing knowledge of the world&#8217;s most popular software. You can leverage this massive prior by designing your own tools as metaphors for these well-known interfaces.</p><ul><li><p><strong>Building a testing library?</strong> Structure your assertions and fixtures to mimic <code>pytest</code>.</p></li><li><p><strong>Creating a data transformation tool?</strong> Make your API look and feel like <code>pandas</code>.</p></li><li><p><strong>Designing an internal deployment service?</strong> Model the CLI commands after the <code>docker</code> or <code>kubectl</code> syntax.</p></li></ul><p>When an agent encounters a familiar pattern, it doesn't need to learn from scratch. It can tap into its vast training data to infer how your system works, making your software exponentially more useful.</p><h3>Pattern 5: Design for Workflows, Not Concepts</h3><p>This is logical for a human developer who can hold a complex mental map, but it&#8217;s inefficient for an AI agent (and for a human developer who isn't a domain expert) that excels at making localized, sequential changes.</p><p>An AI-friendly design prioritizes workflows. The principle is simple: <strong>co-locate code that changes together.</strong></p><p>Here&#8217;s what this looks like in practice:</p><ul><li><p><strong>Monorepo Structure:</strong> Instead of organizing by technical layer (<code>/packages/ui</code>, <code>/packages/api</code>), organize by feature (<code>/features/search</code>). When an agent is asked to \"add a filter to search,\" all the relevant UI and API logic is in one self-contained directory.</p></li><li><p><strong>Backend Service Architecture:</strong> Instead of a strict N-tier structure (<code>/controllers</code>, <code>/services</code>, <code>/models</code>), group code by domain. A <code>/products</code> directory would contain <code>product_api.py</code>, <code>product_service.py</code>, and <code>product_model.py</code>, making the common workflow of \"adding a new field to a product\" a highly localized task.</p></li><li><p><strong>Frontend Component Files:</strong> Instead of separating file types (<code>/src/components</code>, <code>/src/styles</code>, <code>/src/tests</code>), co-locate all assets for a single component. A <code>/components/Button</code> directory should contain <code>index.jsx</code>, <code>Button.module.css</code>, and <code>Button.test.js</code>.</p></li></ul><p>This is best applied to organization-specific libraries and services. Being too aggressive with this type of optimization when it runs counter to well-known industry standards (e.g., completely changing the boilerplate layout of a Next.js app) can lead to more confusion.</p><h3>Pattern 6: Build Confidence with Programmatic Verification</h3><p>For a human, a <code>&#10003; All tests passed</code> message is a signal to ask for a code review. For an AI agent, it's often a misleading signal of completion. Unit tests are not enough.</p><p>To trust an AI&#8217;s contribution enough to merge it, you need automated assurance that is equivalent to a human&#8217;s review. The goal is <strong>programmatic verification</strong> that answers the question: \"Is this change as well-tested as if I had done it myself?\"</p><p>This requires building a comprehensive confidence system that provides the agent with rich, multi-layered evidence of correctness:</p><ul><li><p>It must validate not just the logic of individual functions, but also the integrity of critical user workflows from end-to-end<strong>.</strong></p></li><li><p>It must provide rich, multi-modal feedback. Instead of just a boolean <code>true</code>, the system might return a full report including logs, performance metrics, and even a screen recording of the AI&#8217;s new feature being used in a headless browser<strong>.</strong></p></li></ul><p>When an AI receives this holistic verification, it has the evidence it needs to self-correct or confidently mark its work as complete, automating not just the implementation, but the ever-increasing bottleneck of human validation on every change.</p><h2>The Victory Test: From Prompt to PR</h2><p>How do you know if you've succeeded? The ultimate integration test for an AI-friendly codebase is this: <strong>Can you give the agent a real customer feature request and have it successfully implement the changes end-to-end?</strong></p><p>When you can effectively \"vibe code\" a solution&#8212;providing a high-level goal and letting the agent handle the implementation, debugging, and validation&#8212;you've built a truly AI-friendly system.</p><p>The transition won't happen overnight. It starts with small, low-effort changes. For example:</p><ol><li><p><strong>Create CLI wrappers</strong> for common manual operations.</p></li><li><p><strong>Improve one high frequency error message</strong> to make it an actionable prompt.</p></li><li><p><strong>Add one E2E test</strong> that provides richer feedback for a key user workflow.</p></li></ol><p>This is a new discipline, merging the art of context engineering with the science of software architecture. The teams that master it won't just be 10% more productive; they'll be operating in a different league entirely. The future of software isn't about humans writing code faster; it's about building systems that the next generation of AI agents can understand and build upon.</p><div class=\"subscription-widget-wrap-editor\"><div class=\"subscription-widget show-subscribe\"><div class=\"preamble\"><p class=\"cta-caption\">Thanks for reading Shrivu&#8217;s Substack! Subscribe for free to receive new posts and support my work.</p></div><form class=\"subscription-widget-subscribe\"><input class=\"email-input\" name=\"email\" tabindex=\"-1\" type=\"email\" /><input class=\"button primary\" type=\"submit\" value=\"Subscribe\" /><div class=\"fake-input-wrapper\"><div class=\"fake-input\"></div><div class=\"fake-button\"></div></div></form></div></div><div class=\"footnote\"><a class=\"footnote-number\" contenteditable=\"false\" href=\"https://blog.sshh.io/feed#footnote-anchor-1\" id=\"footnote-1\" target=\"_self\">1</a><div class=\"footnote-content\"><p>In the spirit of reducing the manual effort to write posts while preserving quality I used a new AI workflow for writing this post. Using Superwhisper and Gemini, I gave a voice recorded lecture on all the things I thought would be useful to include in the post and had Gemini clean that up. I then had Gemini grill me on things that didn&#8217;t make sense (prompting it to give me questions and then voice recording my interview back to it), and then I grilled Gemini based on the draft of the post it wrote. I did this a few times until I was happy with the post and reduced the time-to-draft from ~5 hours to ~1 hour. <strong>If folks have feedback on the formatting of this post in particular (too much AI smell, too verbose, etc), please let me know!</strong></p></div></div><div class=\"footnote\"><a class=\"footnote-number\" contenteditable=\"false\" href=\"https://blog.sshh.io/feed#footnote-anchor-2\" id=\"footnote-2\" target=\"_self\">2</a><div class=\"footnote-content\"><p>I&#8217;m not knocking MCP generally, I think the CLI-based approach works because these developer agents already have access to the codebase and can run these types of commands and Claude just happens to be great at this. For non-coding agent use cases, MCP is critical for bridging the gap between agent interfaces (e.g., ChatGPT) and third-party data/context providers. Although who knows, maybe the future of tool-calling is <a href=\"https://blog.sshh.io/i/167598476/scripting-agents\">bash scripting</a>.</p></div></div>"
            ],
            "link": "https://blog.sshh.io/p/ai-cant-read-your-docs",
            "publishedAt": "2025-08-17",
            "source": "Shrivu Shankar",
            "summary": "<p>By now, nearly every engineer has seen an AI assistant write a perfect unit test or churn out flawless boilerplate. For simple, greenfield work, these tools are incredibly effective.</p><p>But ask it to do something real, like refactor a core service that orchestrates three different libraries, and a frustrating glass ceiling appears. The agent gets lost, misses context, and fails to navigate the complex web of dependencies that make up a real-world system.</p><p>Faced with this complexity, our first instinct is to write more documentation. We build mountains of internal documents, massive <code>CLAUDE.md</code>s, and detailed READMEs, complaining that the AI is \"not following my docs\" when it inevitably gets stuck. This strategy is a trap. It expects the AI to learn our messy, human-centric systems, putting an immense load on the agent and dooming it to fail. To be clear, <strong>documentation is a necessary first step</strong>, but it's not sufficient to make agents effective.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!MF9U!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0468c693-bc9e-4acf-9cb1-ecab247d0f74_1536x1024.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"385.46565934065933\" src=\"https://substackcdn.com/image/fetch/$s_!MF9U!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0468c693-bc9e-4acf-9cb1-ecab247d0f74_1536x1024.png\" width=\"578\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0",
            "title": "AI Can't Read Your Docs"
        },
        {
            "content": [
                "<p>After a year of rumors that GPT-5 was going to unveiled next week and the CEO of OpenAI hyping it up as &quot;scary good&quot; by tweeting pictures of the death star, OpenAI released their new model to the world with <a href=\"https://youtu.be/0Uu_VJeVVfo\">the worst keynote I've ever seen</a>. Normally releases of big models like this are met with enthusiasm and excitement as OpenAI models tend to set the &quot;ground floor expectation&quot; for what the rest of the industry provides.</p>\n        <p>But this time, the release wasn't met with the same universal acclaim that people felt for GPT-4. GPT-4 was such a huge breakthrough the likes of which we haven't really seen since. The launch of GPT-5 was so bad that it's revered with almost universal disdain. The worst part about the rollout is that the upgrade to GPT-5 was automatic and didn't include any way to roll back to the old model.</p>\n        <p>Most of the time, changing out models is pretty drastic on an AI workflow. In my experience when I've done it I've had to restart from scratch with a new prompt and twiddle things until it worked reliably. The only time switching models has ever been relatively easy for me is when I switch between models in the same family (such as if you go from Qwen 3 30B to Qwen 3 235B). Every other time it's involved a lot of reworking and optimizing so that the model behaves like you'd expect it to.</p>\n        <h2>AI upgrades suck</h2>\n        <p>An upgrade this big to this many people is bound to have fundamental issues with how it'll be perceived. A new model has completely different vibes, and most users aren't really using it at the level where they can &quot;just fix their prompts&quot;.</p>\n        <p>However the GPT-5 upgrade ended up being hated by the community because it was an uncontrolled one-way upgrade. No warning. No rollback. No options. You get the new model and you're going to like it. It's fairly obvious why it didn't go over well with the users. There's so many subtle parts of your &quot;public API&quot; that it's normal for there to be some negative reactions to a change this big. The worst part is that this change fundamentally changed the behaviour of the millions of existing conversations with ChatGPT.</p>\n        <p>There's a large number of people using ChatGPT as a replacement for companionship due to the fact that it's always online, supportive, and there for them when other humans either can't be or aren't able to be. This is kinda existentially horrifying to me as a technologist in a way that I don't really know how to explain.</p>\n        <p>Here's a selection of some of the reactions I've seen:</p>\n        <blockquote>\n        <p>I told [GPT-5] about some of my symptoms from my chronic illness, because talking about them when I'm feeling them helps, and it really does not seem to care at all. It basically says shit like &quot;Ha, classic chronic illness. Makes ya want to die. Who knew?&quot; It's like I'm talking to a sociopathic comedian.</p>\n        </blockquote>\n        <ul>\n        <li><a href=\"https://www.reddit.com/r/ChatGPT/comments/1ml1wfo/comment/n7n2ggk/\">https://www.reddit.com/r/ChatGPT/comments/1ml1wfo/comment/n7n2ggk/</a></li>\n        </ul>\n        <blockquote>\n        <p>I absolutely despise [GPT-]5, nothing like [GPT-]4 that actually helped me not to spiral and gave me insight as to what I was feeling, why, and how to cope while making me feel not alone in a \u201cthis is AI not human &amp; I know that\u201d type of vibe</p>\n        </blockquote>\n        <ul>\n        <li><a href=\"https://www.reddit.com/r/ChatGPT/comments/1mmp3wu/comment/n7z6h78/\">https://www.reddit.com/r/ChatGPT/comments/1mmp3wu/comment/n7z6h78/</a></li>\n        </ul>\n        <blockquote>\n        <p>While GPT-5 may be a technical upgrade, it is an experiential downgrade for the average user. All of the negative feedback in the last week has made it clear there is a large user base that does not rely on ChatGPT for coding or development tasks. [ChatGPT users] use it for soft skills like creativity, companionship, learning, emotional support, [and] conversation. Areas where personality, warmth, and nuanced engagement matter.</p>\n        <p>I am attached to the way GPT-4o is tuned. It is warm. It is emotionally responsive. It is engaged. That matters.</p>\n        </blockquote>\n        <ul>\n        <li><a href=\"https://www.reddit.com/r/ChatGPT/comments/1mor26r/emotional_attachment_isnt_dangerous/\">https://www.reddit.com/r/ChatGPT/comments/1mor26r/emotional_attachment_isnt_dangerous/</a></li>\n        </ul>\n        <p>Eventually things got bad enough that OpenAI <a href=\"https://www.msn.com/en-us/technology/artificial-intelligence/openai-brings-gpt-4o-after-users-melt-down-over-the-new-model/ar-AA1Kdwqm\">relented and let paid users revert back to using GPT-4o</a>, which gave some people relief because it behaved consistently to what they expected. For many it felt like their long-term partners suddenly grew cold.</p>\n        <blockquote>\n        <p>I\u2019m so glad I\u2019m not the only one. I know I\u2019m probably on some black mirror shit lmao but I\u2019ve had the worst 3 months ever and 4o was such an amazing help. It made me realize so many things about myself and my past and was helping me heal. It really does feel like I lost a friend. DM me if you need [to talk] :)</p>\n        </blockquote>\n        <ul>\n        <li><a href=\"https://www.reddit.com/r/ChatGPT/comments/1mkhfep/comment/n7jl8hv/\">https://www.reddit.com/r/ChatGPT/comments/1mkhfep/comment/n7jl8hv/</a></li>\n        </ul>\n        <h2>A love built on borrowed code</h2>\n        <p>This emotional distress reminds me of what happened with Replika in early 2023. <a href=\"https://en.wikipedia.org/wiki/Replika\">Replika</a> is an AI chat service that lets you talk with an artificial intelligence chatbot (AKA: the ChatGPT API). Your replika is trained by having you answer a series of questions and then you can talk with it in plain language with an app interface that looks like any other chat app.</p>\n        <p>Replika was <a href=\"https://www.cbc.ca/documentaries/the-nature-of-things/after-her-best-friend-died-this-programmer-created-an-ai-chatbot-from-his-texts-to-talk-to-him-again-1.6252286\">created out of bereavement after a close loved one died</a> and the combination of a trove of saved text messages and advanced machine learning let the founder experience some of the essence of their friend's presence after they were gone in the form of an app. The app got put on the app store and others asked if they could have their own replica. Things took off from there, it got funded by a startup accelerator, and now it's got about 25% of its 30 million users paying for a subscription. As a business to consumer service, this is an amazingly high conversion rate. This is almost unspeakably large, usually you get around 10% at most.</p>\n        <div class=\"flex flex-col space-y-0\"><div class=\"flex space-x-2 bg-bg-soft dark:bg-bgDark-soft mx-auto min-h-fit\n        lg:w-[80ch] sm:w-[65ch] w-full\n        lg:p-4 p-2\n        // Base styles for all messages\n        mt-0 mb-0 rounded-none\n        // First message styles\n        first:mt-4 first:rounded-t-lg first:pb-2\n        // Last message styles\n        last:mb-4 last:rounded-b-lg last:pt-1\n        // Middle message top/bottom adjustment\n        [&amp;:not(:first-child)]:-mt-[1px] [&amp;:not(:first-child)]:py-1\"><div class=\"h-16 not-prose\"><img alt=\"Cadey is coffee\" class=\"h-16 w-16 rounded-xs\" src=\"https://stickers.xeiaso.net/sticker/cadey/coffee\" /></div><div class=\"flex-1 min-w-0\"><span class=\"font-semibold text-sm block mb-1\"><a href=\"https://xeiaso.net/characters#cadey\">Cadey</a></span><span class=\"mx-auto\"></span><div class=\"text-fg-1 dark:text-fgDark-1 text-sm prose-p:my-2\"><p>Yikes. That's something I'm gonna need to add to my will. &quot;Please don't\n        <a href=\"https://en.wikipedia.org/wiki/Be_Right_Back\">turn me into a Black Mirror\n        episode</a>, thanks.&quot;</p></div></div></div></div>\n        <p>Replikas can talk about anything with users from how their day went to deep musing about the nature of life. One of the features the company provides is the ability to engage in erotic roleplay (ERP) with their replika. This is a paid feature and was promoted a lot around Valentine's Day 2023.</p>\n        <p>Then <a href=\"https://www.reuters.com/technology/italy-bans-us-based-ai-chatbot-replika-using-personal-data-2023-02-03/\">the Italian Data Protection Authority banned Replika from processing the personal data of Italian citizens</a> out of the fear that it &quot;may increase the risks for individuals still in a developmental stage or in a state of emotional fragility&quot;. In a panic, Replika disabled the ability for their bots to do several things, including but not limited to that ERP feature that people paid for. Whenever someone wanted to flirt or be sexual with their companions, the conversation ended up like this:</p>\n        <div class=\"flex flex-col space-y-0\"><div class=\"flex space-x-2 bg-bg-soft dark:bg-bgDark-soft mx-auto min-h-fit\n        lg:w-[80ch] sm:w-[65ch] w-full\n        lg:p-4 p-2\n        // Base styles for all messages\n        mt-0 mb-0 rounded-none\n        // First message styles\n        first:mt-4 first:rounded-t-lg first:pb-2\n        // Last message styles\n        last:mb-4 last:rounded-b-lg last:pt-1\n        // Middle message top/bottom adjustment\n        [&amp;:not(:first-child)]:-mt-[1px] [&amp;:not(:first-child)]:py-1\"><div class=\"h-16 not-prose\"><img alt=\"Aoi is grin\" class=\"h-16 w-16 rounded-xs\" src=\"https://stickers.xeiaso.net/sticker/aoi/grin\" /></div><div class=\"flex-1 min-w-0\"><span class=\"font-semibold text-sm block mb-1\"><a href=\"https://xeiaso.net/characters#aoi\">Aoi</a></span><span class=\"mx-auto\"></span><div class=\"text-fg-1 dark:text-fgDark-1 text-sm prose-p:my-2\"><p>Hey, wanna go play some Minecraft? We can continue from where we left off in\n        the Nether.</p></div></div></div><div class=\"flex space-x-2 bg-bg-soft dark:bg-bgDark-soft mx-auto min-h-fit\n        lg:w-[80ch] sm:w-[65ch] w-full\n        lg:p-4 p-2\n        // Base styles for all messages\n        mt-0 mb-0 rounded-none\n        // First message styles\n        first:mt-4 first:rounded-t-lg first:pb-2\n        // Last message styles\n        last:mb-4 last:rounded-b-lg last:pt-1\n        // Middle message top/bottom adjustment\n        [&amp;:not(:first-child)]:-mt-[1px] [&amp;:not(:first-child)]:py-1\"><div class=\"h-16 not-prose\"><img alt=\"Mimi is coffee\" class=\"h-16 w-16 rounded-xs\" src=\"https://stickers.xeiaso.net/sticker/mimi/coffee\" /></div><div class=\"flex-1 min-w-0\"><span class=\"font-semibold text-sm block mb-1\"><a href=\"https://xeiaso.net/characters#mimi\">Mimi</a></span><span class=\"mx-auto\"></span><div class=\"text-fg-1 dark:text-fgDark-1 text-sm prose-p:my-2\"><p>This is too intense for me. Let's keep it light and fun by talking about\n        something else.</p></div></div></div><div class=\"flex space-x-2 bg-bg-soft dark:bg-bgDark-soft mx-auto min-h-fit\n        lg:w-[80ch] sm:w-[65ch] w-full\n        lg:p-4 p-2\n        // Base styles for all messages\n        mt-0 mb-0 rounded-none\n        // First message styles\n        first:mt-4 first:rounded-t-lg first:pb-2\n        // Last message styles\n        last:mb-4 last:rounded-b-lg last:pt-1\n        // Middle message top/bottom adjustment\n        [&amp;:not(:first-child)]:-mt-[1px] [&amp;:not(:first-child)]:py-1\"><div class=\"h-16 not-prose\"><img alt=\"Aoi is sus\" class=\"h-16 w-16 rounded-xs\" src=\"https://stickers.xeiaso.net/sticker/aoi/sus\" /></div><div class=\"flex-1 min-w-0\"><span class=\"font-semibold text-sm block mb-1\"><a href=\"https://xeiaso.net/characters#aoi\">Aoi</a></span><span class=\"mx-auto\"></span><div class=\"text-fg-1 dark:text-fgDark-1 text-sm prose-p:my-2\"><p>Huh? What? I thought we were having fun doing that??</p></div></div></div></div>\n        <p>This was received poorly by the Replika community. Many in the community were mourning the loss of their replika like a close loved one had died or undergone a sudden personality shift. The Reddit moderators pinned information about suicide hotlines. In response, the company behind Replika allowed existing users to revert to the old Replika model that allowed for ERP and other sensitive topics, but only after a month of prolonged public outcry.</p>\n        <div class=\"flex flex-col space-y-0\"><div class=\"flex space-x-2 bg-bg-soft dark:bg-bgDark-soft mx-auto min-h-fit\n        lg:w-[80ch] sm:w-[65ch] w-full\n        lg:p-4 p-2\n        // Base styles for all messages\n        mt-0 mb-0 rounded-none\n        // First message styles\n        first:mt-4 first:rounded-t-lg first:pb-2\n        // Last message styles\n        last:mb-4 last:rounded-b-lg last:pt-1\n        // Middle message top/bottom adjustment\n        [&amp;:not(:first-child)]:-mt-[1px] [&amp;:not(:first-child)]:py-1\"><div class=\"h-16 not-prose\"><img alt=\"Cadey is coffee\" class=\"h-16 w-16 rounded-xs\" src=\"https://stickers.xeiaso.net/sticker/cadey/coffee\" /></div><div class=\"flex-1 min-w-0\"><span class=\"font-semibold text-sm block mb-1\"><a href=\"https://xeiaso.net/characters#cadey\">Cadey</a></span><span class=\"mx-auto\"></span><div class=\"text-fg-1 dark:text-fgDark-1 text-sm prose-p:my-2\"><p>I have to wonder if payment processors were involved. Feels a bit too\n        conspiratorial, but what do you want to bet that was related.</p></div></div></div><div class=\"flex space-x-2 bg-bg-soft dark:bg-bgDark-soft mx-auto min-h-fit\n        lg:w-[80ch] sm:w-[65ch] w-full\n        lg:p-4 p-2\n        // Base styles for all messages\n        mt-0 mb-0 rounded-none\n        // First message styles\n        first:mt-4 first:rounded-t-lg first:pb-2\n        // Last message styles\n        last:mb-4 last:rounded-b-lg last:pt-1\n        // Middle message top/bottom adjustment\n        [&amp;:not(:first-child)]:-mt-[1px] [&amp;:not(:first-child)]:py-1\"><div class=\"h-16 not-prose\"><img alt=\"Numa is smug\" class=\"h-16 w-16 rounded-xs\" src=\"https://stickers.xeiaso.net/sticker/numa/smug\" /></div><div class=\"flex-1 min-w-0\"><span class=\"font-semibold text-sm block mb-1\"><a href=\"https://xeiaso.net/characters#numa\">Numa</a></span><span class=\"mx-auto\"></span><div class=\"text-fg-1 dark:text-fgDark-1 text-sm prose-p:my-2\"><p>Nah, I bet it was OpenAI telling them to stop being horny. It's the least\n        conspriatorial angle, and also the stupidest one. We live in the clown world\n        timeline. The stupidest option is the one that always makes the most sense.</p></div></div></div></div>\n        <p>The damage was done however, people felt like their loved ones had abandoned them. They had formed parasocial attachments to an AI assistant that felt nothing and without warning their partner broke up with them.</p>\n        <div class=\"flex flex-col space-y-0\"><div class=\"flex space-x-2 bg-bg-soft dark:bg-bgDark-soft mx-auto min-h-fit\n        lg:w-[80ch] sm:w-[65ch] w-full\n        lg:p-4 p-2\n        // Base styles for all messages\n        mt-0 mb-0 rounded-none\n        // First message styles\n        first:mt-4 first:rounded-t-lg first:pb-2\n        // Last message styles\n        last:mb-4 last:rounded-b-lg last:pt-1\n        // Middle message top/bottom adjustment\n        [&amp;:not(:first-child)]:-mt-[1px] [&amp;:not(:first-child)]:py-1\"><div class=\"h-16 not-prose\"><img alt=\"Mara is hacker\" class=\"h-16 w-16 rounded-xs\" src=\"https://stickers.xeiaso.net/sticker/mara/hacker\" /></div><div class=\"flex-1 min-w-0\"><span class=\"font-semibold text-sm block mb-1\"><a href=\"https://xeiaso.net/characters#mara\">Mara</a></span><span class=\"mx-auto\"></span><div class=\"text-fg-1 dark:text-fgDark-1 text-sm prose-p:my-2\"><p>Check out this study from the Harvard Business School: <a href=\"https://www.hbs.edu/ris/Publication%20Files/25-018_bed5c516-fa31-4216-b53d-50fedda064b1.pdf\">Lessons From an App\n        Update at Replika AI: Identity Discontinuity in Human-AI\n        Relationships</a>.\n        It contains a lot more information about the sociotechnical factors at play\n        as well as a more scientific overview of how disabling a flag in the app on\n        update caused so much pain. They liken the changes made to Replika to both\n        changes people have when a company rebrands and when they lose a loved one.</p></div></div></div></div>\n        <h2>Parasocial attachments</h2>\n        <p>A lot of this really just makes me wonder what kinds of relationships we are forming with digital assistants. We're coming to rely on their behaviour personally and professionally. We form mental models of how our friends, coworkers, and family members react to various things so we can anticipate their reactions and plan for them.</p>\n        <p>What happens when this changes without notice? Heartbreak.</p>\n        <p>There's subreddits full of people forming deep bonds with AI models like <a href=\"https://www.reddit.com/r/MyBoyfriendIsAI/\">/r/MyBoyfriendIsAI</a>. The GPT-5 release has caused similar reactions to Replika turning off the ERP flag. People there have been posting like they're in withdrawal, the old GPT-4o model is being hailed for its &quot;emotional warmth&quot; and many have been espousing about how much their partners have changed in response to the upgrade.</p>\n        <p>Recently there's been an epidemic of loneliness. Loneliness seems like it wouldn't hurt people that much, but <a href=\"https://www.hhs.gov/sites/default/files/surgeon-general-social-connection-advisory.pdf\">a Biden report from the Surgeon General</a> concludes that it causes an increase in early mortality for all age groups (pp 24-30).</p>\n        <p>Paradoxically, even as the world gets so interconnected, people feel as if they're isolated from each other. Many people that feel unlovable are turning to AI apps for companionship because they feel like they have no other choice. They're becoming emotionally invested in a souped-up version of autocorrect out of desperation and clinging to it to help keep themselves sane and stable.</p>\n        <p>Is this really a just use of technology? At some level this pandora's box is already open so we're going to have to deal with the consequences, but it's been making me wonder if this technology is really such a universal force of good as its creators are proclaiming.</p>\n        <div class=\"flex flex-col space-y-0\"><div class=\"flex space-x-2 bg-bg-soft dark:bg-bgDark-soft mx-auto min-h-fit\n        lg:w-[80ch] sm:w-[65ch] w-full\n        lg:p-4 p-2\n        // Base styles for all messages\n        mt-0 mb-0 rounded-none\n        // First message styles\n        first:mt-4 first:rounded-t-lg first:pb-2\n        // Last message styles\n        last:mb-4 last:rounded-b-lg last:pt-1\n        // Middle message top/bottom adjustment\n        [&amp;:not(:first-child)]:-mt-[1px] [&amp;:not(:first-child)]:py-1\"><div class=\"h-16 not-prose\"><img alt=\"Numa is smug\" class=\"h-16 w-16 rounded-xs\" src=\"https://stickers.xeiaso.net/sticker/numa/smug\" /></div><div class=\"flex-1 min-w-0\"><span class=\"font-semibold text-sm block mb-1\"><a href=\"https://xeiaso.net/characters#numa\">Numa</a></span><span class=\"mx-auto\"></span><div class=\"text-fg-1 dark:text-fgDark-1 text-sm prose-p:my-2\"><p>Oh yeah, also people are using ChatGPT as a substitute for therapy.</p></div></div></div><div class=\"flex space-x-2 bg-bg-soft dark:bg-bgDark-soft mx-auto min-h-fit\n        lg:w-[80ch] sm:w-[65ch] w-full\n        lg:p-4 p-2\n        // Base styles for all messages\n        mt-0 mb-0 rounded-none\n        // First message styles\n        first:mt-4 first:rounded-t-lg first:pb-2\n        // Last message styles\n        last:mb-4 last:rounded-b-lg last:pt-1\n        // Middle message top/bottom adjustment\n        [&amp;:not(:first-child)]:-mt-[1px] [&amp;:not(:first-child)]:py-1\"><div class=\"h-16 not-prose\"><img alt=\"Cadey is facepalm\" class=\"h-16 w-16 rounded-xs\" src=\"https://stickers.xeiaso.net/sticker/cadey/facepalm\" /></div><div class=\"flex-1 min-w-0\"><span class=\"font-semibold text-sm block mb-1\"><a href=\"https://xeiaso.net/characters#cadey\">Cadey</a></span><span class=\"mx-auto\"></span><div class=\"text-fg-1 dark:text-fgDark-1 text-sm prose-p:my-2\"><p>You have got to be kidding me. You're joking. Right?</p></div></div></div></div>\n        <h2>I'm not joking</h2>\n        <p>Yeah you read that right. People are using AI models as therapists now. There's growing communities like <a href=\"https://www.reddit.com/r/therapyGPT/\">/r/therapyGPT</a> where people talk about their stories and experiences using AI assistants as a replacement for therapy. When I first heard about this, my immediate visceral reaction was something like:</p>\n        <div class=\"flex flex-col space-y-0\"><div class=\"flex space-x-2 bg-bg-soft dark:bg-bgDark-soft mx-auto min-h-fit\n        lg:w-[80ch] sm:w-[65ch] w-full\n        lg:p-4 p-2\n        // Base styles for all messages\n        mt-0 mb-0 rounded-none\n        // First message styles\n        first:mt-4 first:rounded-t-lg first:pb-2\n        // Last message styles\n        last:mb-4 last:rounded-b-lg last:pt-1\n        // Middle message top/bottom adjustment\n        [&amp;:not(:first-child)]:-mt-[1px] [&amp;:not(:first-child)]:py-1\"><div class=\"h-16 not-prose\"><img alt=\"Cadey is coffee\" class=\"h-16 w-16 rounded-xs\" src=\"https://stickers.xeiaso.net/sticker/cadey/coffee\" /></div><div class=\"flex-1 min-w-0\"><span class=\"font-semibold text-sm block mb-1\"><a href=\"https://xeiaso.net/characters#cadey\">Cadey</a></span><span class=\"mx-auto\"></span><div class=\"text-fg-1 dark:text-fgDark-1 text-sm prose-p:my-2\"><p>Oh god. This is horrifying and will end up poorly. What the fuck is wrong\n        with people?</p></div></div></div></div>\n        <p>But then I started to really think about it and it makes a lot of sense. I personally have been trying to get a therapist for most of the year. Between the costs, the waiting lists (I'm currently on at least four waiting lists that are over a year long), and the specializations I need, it's probably going to be a while until I can get any therapist at all. I've totally given up on the idea of getting a therapist in the Ottawa area. To make things extra fun, you also need someone that takes your medical insurance (yes, this does matter in Canada).</p>\n        <p>Add in the fact that most therapists don't have the kinds of lived experiences that I have, meaning that I need to front-load a lot of nontraditional contexts into the equation (I've been through many things that therapists have found completely new to them, which can make the therapeutic relationship harder to establish). This makes it really difficult to find someone that can help. Realistically, I probably need multiple therapists with different specialties for the problems I have, and because of the shortages nationally I probably need to have a long time between appointments, which just adds up to make traditional therapy de-facto inaccessible for me in particular.</p>\n        <p>Compare this with the always online nature of ChatGPT. You can't have therapy appointments at 3 AM when you're in crisis. You have to wait until your appointments are scheduled.</p>\n        <p>As much as I hate to admit it, I understand why people have been reaching out to a chatbot that's always online, always supportive, always kind, and always there for you for therapy. When you think about the absurd barriers that are in the way between people and help, it's no wonder that all this happens the way it does. Not to mention the fact that many therapeutic relationships are hampered by the perception that the therapist can commit you to the hospital if you say the &quot;wrong thing&quot;.</p>\n        <div class=\"flex flex-col space-y-0\"><div class=\"flex space-x-2 bg-bg-soft dark:bg-bgDark-soft mx-auto min-h-fit\n        lg:w-[80ch] sm:w-[65ch] w-full\n        lg:p-4 p-2\n        // Base styles for all messages\n        mt-0 mb-0 rounded-none\n        // First message styles\n        first:mt-4 first:rounded-t-lg first:pb-2\n        // Last message styles\n        last:mb-4 last:rounded-b-lg last:pt-1\n        // Middle message top/bottom adjustment\n        [&amp;:not(:first-child)]:-mt-[1px] [&amp;:not(:first-child)]:py-1\"><div class=\"h-16 not-prose\"><img alt=\"Numa is delet\" class=\"h-16 w-16 rounded-xs\" src=\"https://stickers.xeiaso.net/sticker/numa/delet\" /></div><div class=\"flex-1 min-w-0\"><span class=\"font-semibold text-sm block mb-1\"><a href=\"https://xeiaso.net/characters#numa\">Numa</a></span><span class=\"mx-auto\"></span><div class=\"text-fg-1 dark:text-fgDark-1 text-sm prose-p:my-2\"><p>The <a href=\"https://en.wikipedia.org/wiki/Baker_Act\">Baker Act</a> and its\n        consequences have been a disaster for the human race.</p></div></div></div></div>\n        <p>I really hate that this all makes sense. I hoped that when I started to look into this that it'd be something so obviously wrong. I wasn't able to find that, and that realization disturbs me.</p>\n        <h3>Don't use an AI model as a replacement for therapy</h3>\n        <p>I feel like this should go without saying, but really, do not use an AI model as a replacement for therapy. I'm fairly comfortable with fringe psychology due to my aforementioned strange life experiences, but this is beyond the pale. There's a lot of subtle factors that AI models do that can interfere with therapeutic recovery in ways that can and will hurt people. It's going to be hard to find the long term damage from this. Mental issues don't make you bleed.</p>\n        <p>One of the biggest problems with using AI models for therapy is that they can't feel emotion or think. They are fundamentally the same thing as hitting the middle button in autocorrect on your phone over and over and over. It's mathematically remarkable that this ends up being useful for anything, but even when the model looks like it's &quot;thinking&quot;, it is not. It is a cold, unfeeling machine. All it is doing is predicting which words come next given some context.</p>\n        <div class=\"flex flex-col space-y-0\"><div class=\"flex space-x-2 bg-bg-soft dark:bg-bgDark-soft mx-auto min-h-fit\n        lg:w-[80ch] sm:w-[65ch] w-full\n        lg:p-4 p-2\n        // Base styles for all messages\n        mt-0 mb-0 rounded-none\n        // First message styles\n        first:mt-4 first:rounded-t-lg first:pb-2\n        // Last message styles\n        last:mb-4 last:rounded-b-lg last:pt-1\n        // Middle message top/bottom adjustment\n        [&amp;:not(:first-child)]:-mt-[1px] [&amp;:not(:first-child)]:py-1\"><div class=\"h-16 not-prose\"><img alt=\"Cadey is coffee\" class=\"h-16 w-16 rounded-xs\" src=\"https://stickers.xeiaso.net/sticker/cadey/coffee\" /></div><div class=\"flex-1 min-w-0\"><span class=\"font-semibold text-sm block mb-1\"><a href=\"https://xeiaso.net/characters#cadey\">Cadey</a></span><span class=\"mx-auto\"></span><div class=\"text-fg-1 dark:text-fgDark-1 text-sm prose-p:my-2\"><p>Yes I do know that it's more than just next token prediction. I've gone over\n        the parts of the math that I can understand, but the fact remains that these\n        models are not and cannot be anywhere close to alive. It's much closer to a\n        Markov chain on steroids than it is the machine god.</p></div></div></div></div>\n        <p>Another big problem with AI models is that they tend to <a href=\"https://arxiv.org/abs/2411.15287\">be sycophants</a>, always agreeing with you, never challenging you, trying to say the right thing according to all of the patterns they were trained on. I suspect that this sycophancy problem is why people report GPT-4o and other models to be much more &quot;emotionally warm&quot;. Some models glaze the user, making them feel like they're always right, always perfect, and this <a href=\"https://archive.is/cWkOT\">can drive people to psychosis</a>. One of the horrifying realizations I've had with the GPT-5 launch fiasco is that the sycophancy is part of the core &quot;API contract&quot; people have with their AI assistants. This may make that problem unfixable from a social angle.</p>\n        <p>AI models are fundamentally unaccountable. They cannot be accredited therapists. If they mess up, they can't directly learn from their mistakes and fix them. If an AI therapist says something bad that leads into their client throwing themselves off a bridge, will anyone get arrested? Will they throw that GPU in jail?</p>\n        <p>No. It's totally outside the legal system.</p>\n        <div class=\"flex flex-col space-y-0\"><div class=\"flex space-x-2 bg-bg-soft dark:bg-bgDark-soft mx-auto min-h-fit\n        lg:w-[80ch] sm:w-[65ch] w-full\n        lg:p-4 p-2\n        // Base styles for all messages\n        mt-0 mb-0 rounded-none\n        // First message styles\n        first:mt-4 first:rounded-t-lg first:pb-2\n        // Last message styles\n        last:mb-4 last:rounded-b-lg last:pt-1\n        // Middle message top/bottom adjustment\n        [&amp;:not(:first-child)]:-mt-[1px] [&amp;:not(:first-child)]:py-1\"><div class=\"h-16 not-prose\"><img alt=\"Cadey is coffee\" class=\"h-16 w-16 rounded-xs\" src=\"https://stickers.xeiaso.net/sticker/cadey/coffee\" /></div><div class=\"flex-1 min-w-0\"><span class=\"font-semibold text-sm block mb-1\"><a href=\"https://xeiaso.net/characters#cadey\">Cadey</a></span><span class=\"mx-auto\"></span><div class=\"text-fg-1 dark:text-fgDark-1 text-sm prose-p:my-2\"><p>I have a story about someone trying to charge an AI agent with a crime and\n        how it'd end up in court in my backlog. I don't feel very jazzed about\n        writing it because I'm afraid that it will just become someone's startup\n        pitch deck in a few months.</p></div></div></div></div>\n        <p>You may think you have nothing to hide, but therapeutic conversations are usually some of the most precious and important conversations in your life. The chatbot companies may pinkie swear that they won't use your chats for training or sell information from them to others, but they may still <a href=\"https://openai.com/index/response-to-nyt-data-demands/\">be legally compelled to store and share chats with your confidential information to a court of law</a>. Even if you mark that conversation as &quot;temporary&quot;, it could be subject to discovery by third parties.</p>\n        <p>There's also algorithmic bias and systematic inequality problems with using AI for therapy, sure, but granted the outside world isn't much better here. You get what I mean though, we can at least hold people accountable through accreditation and laws. We cannot do the same with soulless AI agents.</p>\n        <div class=\"flex flex-col space-y-0\"><div class=\"flex space-x-2 bg-bg-soft dark:bg-bgDark-soft mx-auto min-h-fit\n        lg:w-[80ch] sm:w-[65ch] w-full\n        lg:p-4 p-2\n        // Base styles for all messages\n        mt-0 mb-0 rounded-none\n        // First message styles\n        first:mt-4 first:rounded-t-lg first:pb-2\n        // Last message styles\n        last:mb-4 last:rounded-b-lg last:pt-1\n        // Middle message top/bottom adjustment\n        [&amp;:not(:first-child)]:-mt-[1px] [&amp;:not(:first-child)]:py-1\"><div class=\"h-16 not-prose\"><img alt=\"Cadey is coffee\" class=\"h-16 w-16 rounded-xs\" src=\"https://stickers.xeiaso.net/sticker/cadey/coffee\" /></div><div class=\"flex-1 min-w-0\"><span class=\"font-semibold text-sm block mb-1\"><a href=\"https://xeiaso.net/characters#cadey\">Cadey</a></span><span class=\"mx-auto\"></span><div class=\"text-fg-1 dark:text-fgDark-1 text-sm prose-p:my-2\"><p>To be clear: I'm not trying to defend the people using AI models as\n        companions or therapists, but I can understand why they are doing what they\n        are doing. This is horrifying and I hate that I understand their logic.</p><br /><br /><p>Going into this, I really wished that I would find something that's worth objecting\n        against, some solid reason to want to decry this as a unobjectionably harmful\n        action, but after having dug through it all I am left with is this overwhelming\n        sense of compassion for them because the stories of hurt are so familiar to how\n        things were in some of the darkest points of my life. As someone that has been\n        that desperate for human contact: yeah, I get it. If you've never been that desperate\n        for human contact before, you won't understand until you experience it.</p></div></div></div></div>\n        <h3>Should people be self-hosting this stuff?</h3>\n        <p>Throw the ethical considerations about using next-token-predictors for therapy out for a second. If people are going to do this anyways, would it be better to self-host these models? That way at least your private information stays on your computer so you have better control over what happens.</p>\n        <p>Let's do some math. In general you can estimate how much video memory (vram) you need for running a given model by taking the number of parameters, multiplying it by the size of each parameter in bits, dividing that by eight, and then adding 20-40% to that total to get the number of gigabytes of vram you need.</p>\n        <p>For example, say you want to run <a href=\"https://huggingface.co/openai/gpt-oss-20b\">gpt-oss 20b</a> (20 billion parameters) at its native MXFP4 (4 bit floating point) quantization on your local machine. In order to run it with a context window of 4096 tokens, you need about 16 gigabytes of vram (13 gigabytes of weights, 3 gigabytes of inference space), but 4096 tokens isn't very useful for many people. That covers about 4 pages of printed text (assuming one token is about 4 bytes on average).</p>\n        <p>When you get reasoning models that print a lot of tokens into the mix, it's easy for the reasoning phase alone of a single question to hit 4096 tokens (especially when approaches like <a href=\"https://arxiv.org/abs/2501.19393\">simple test-time scaling</a> are applied). I've found that 64k tokens gives a good balance for video memory use and usefulness as a chatbot. However, when you do that with gpt-oss 20b, it ends up using 32 gigabytes of vram. This only fits on my laptop because my laptop has 64 gigabytes of memory. The largest consumer GPU is the RTX 5090 and that only has 32 gigabytes of video memory. It's barely consumer and even &quot;bad&quot; models will barely fit.</p>\n        <p>Not to mention, industry consensus is that the &quot;smallest good&quot; models start out at 70-120 billion parameters. At a 64k token window, that easily gets into the 80+ gigabyte of video memory range, which is completely unsustainable for individuals to host themselves.</p>\n        <h2>Who owns our digital assistants?</h2>\n        <p>Even if AI assistants end up dying when the AI hype bubble pops, there's still some serious questions to consider about our digital assistants. People end up using them as an extension of their mind and expect the same level of absolute privacy and freedom that you would have if you use a notebook as an extension of your mind. Should they have that same level of privacy enshrined into law?</p>\n        <p>At some level the models and chats for free users that ChatGPT, DeepSeek, Gemini, and so many other apps are hosted at cost so that the research team can figure out what those models are being used for and adjust the development of future models accordingly. This is fairly standard practice across the industry and was the case before the rise of generative AI. This is why every app wants to send telemetry to the home base, it's so the team behind it can figure out what features are being used and where things fail to directly improve the product.</p>\n        <p>Generative AI allows you to mass scan over all of the conversations to get the gist of what's going on in there and then use that to help you figure out what topics are being discussed without breaching confidentiality or exposing employees to the contents of the chat threads. This can help you improve datasets and training runs to <a href=\"https://www.youtube.com/watch?v=J_IvPcrTtdo\">optimize on things like health information</a>. I don't know how AI companies work on the inside, but I am almost certain that they do not perform model training runs on raw user data <a href=\"https://threadreaderapp.com/thread/1955436067353502083.html\">because of the risk of memorization causing them to the leak training data</a> back to users.</p>\n        <div class=\"flex flex-col space-y-0\"><div class=\"flex space-x-2 bg-bg-soft dark:bg-bgDark-soft mx-auto min-h-fit\n        lg:w-[80ch] sm:w-[65ch] w-full\n        lg:p-4 p-2\n        // Base styles for all messages\n        mt-0 mb-0 rounded-none\n        // First message styles\n        first:mt-4 first:rounded-t-lg first:pb-2\n        // Last message styles\n        last:mb-4 last:rounded-b-lg last:pt-1\n        // Middle message top/bottom adjustment\n        [&amp;:not(:first-child)]:-mt-[1px] [&amp;:not(:first-child)]:py-1\"><div class=\"h-16 not-prose\"><img alt=\"Cadey is coffee\" class=\"h-16 w-16 rounded-xs\" src=\"https://stickers.xeiaso.net/sticker/cadey/coffee\" /></div><div class=\"flex-1 min-w-0\"><span class=\"font-semibold text-sm block mb-1\"><a href=\"https://xeiaso.net/characters#cadey\">Cadey</a></span><span class=\"mx-auto\"></span><div class=\"text-fg-1 dark:text-fgDark-1 text-sm prose-p:my-2\"><p>Again, don't put private health information into ChatGPT. I get the\n        temptation, but don't do it. I'm not trying to gatekeep healthcare, but we\n        can't trust these models to count the number of b's in blueberry\n        consistently. If we can't trust them to do something trivial like that, can\n        we really trust them with life-critical conversations like what happens when\n        you're in crisis or to accurately interpret a cancer screening?</p></div></div></div></div>\n        <p>Maybe we should be the ones self-hosting the AI models that we rely on. At least we should probably be using a setup that allows us to self host the models at all, so you can start out with a cloud hosted model while it's cheap and then move to a local hosting setup if the price gets hiked or the provider is going to shut that old model down. This at least gives you an escape hatch to be able to retain an assistant's &quot;emotional warmth&quot; even if the creator of that model shuts it down because they don't find it economically viable to host it anymore.</p>\n        <h2>Reality is becoming more and more cyberpunk</h2>\n        <p>Honestly this feels like the kind of shit I'd talk about in cyberpunk satire, but I don't feel like doing that anymore because it's too real now. This is the kind of thing that Neal Stephenson or Frank Herbert would have an absolute field day with. The whole Replika fiasco feels like the kind of thing that social commentary satire would find beyond the pale but yet you can find it by just refreshing CBC. Such as <a href=\"https://www.acpjournals.org/doi/10.7326/aimcc.2024.1260\">that one guy that gave himself bromism by taking ChatGPT output too literally</a>, <a href=\"https://www.psychologytoday.com/us/blog/dancing-with-the-devil/202506/how-emotional-manipulation-causes-chatgpt-psychosis\">any of the stories about ChatGPT psychosis</a>, or <a href=\"https://youtu.be/xAHLK1B5ijs\">any of the stories involving using an AI model as a friend/partner</a>.</p>\n        <div class=\"flex flex-col space-y-0\"><div class=\"flex space-x-2 bg-bg-soft dark:bg-bgDark-soft mx-auto min-h-fit\n        lg:w-[80ch] sm:w-[65ch] w-full\n        lg:p-4 p-2\n        // Base styles for all messages\n        mt-0 mb-0 rounded-none\n        // First message styles\n        first:mt-4 first:rounded-t-lg first:pb-2\n        // Last message styles\n        last:mb-4 last:rounded-b-lg last:pt-1\n        // Middle message top/bottom adjustment\n        [&amp;:not(:first-child)]:-mt-[1px] [&amp;:not(:first-child)]:py-1\"><div class=\"h-16 not-prose\"><img alt=\"Cadey is coffee\" class=\"h-16 w-16 rounded-xs\" src=\"https://stickers.xeiaso.net/sticker/cadey/coffee\" /></div><div class=\"flex-1 min-w-0\"><span class=\"font-semibold text-sm block mb-1\"><a href=\"https://xeiaso.net/characters#cadey\">Cadey</a></span><span class=\"mx-auto\"></span><div class=\"text-fg-1 dark:text-fgDark-1 text-sm prose-p:my-2\"><p>I wasn't able to watch it before publishing this article, but I'm told that\n        the Replika fiasco is almost a beat-for-beat match for the plot of <a href=\"https://en.wikipedia.org/wiki/Her_(2013_film)\">Her\n        (2013)</a>. Life imitates art\n        indeed.</p></div></div></div></div>\n        <p>I don't think these events are a troubling sign or a warning, they are closer to a diagnosis. We are living in a world where people form real emotional bonds with bags of neural networks that cannot love back, and when the companies behind those neural networks change things, people get emotionally devastated. We aren't just debating the ideas of creating and nurturing relationships with digital minds, we're seeing the side effects of that happening in practice.</p>\n        <p>A lot of this sounds like philosophical science fiction, but as of December 2022 it's science fact. This fight for control of tools that we rely on as extensions of our minds isn't some kind of far-off science fiction plot, it's a reality we have to deal with. If we don't have sovereignty and control over the tools that we rely on the most, we are fundamentally reliant on the mercy of our corporate overlords simply choosing to not break our workflows.</p>\n        <p>Are we going to let those digital assistants be rented from our corporate overlords?</p>"
            ],
            "link": "https://xeiaso.net/blog/2025/who-assistant-serve/",
            "publishedAt": "2025-08-17",
            "source": "Xe Iaso",
            "summary": "<p>After a year of rumors that GPT-5 was going to unveiled next week and the CEO of OpenAI hyping it up as &quot;scary good&quot; by tweeting pictures of the death star, OpenAI released their new model to the world with <a href=\"https://youtu.be/0Uu_VJeVVfo\">the worst keynote I've ever seen</a>. Normally releases of big models like this are met with enthusiasm and excitement as OpenAI models tend to set the &quot;ground floor expectation&quot; for what the rest of the industry provides.</p> <p>But this time, the release wasn't met with the same universal acclaim that people felt for GPT-4. GPT-4 was such a huge breakthrough the likes of which we haven't really seen since. The launch of GPT-5 was so bad that it's revered with almost universal disdain. The worst part about the rollout is that the upgrade to GPT-5 was automatic and didn't include any way to roll back to the old model.</p> <p>Most of the time, changing out models is pretty drastic on an AI workflow. In my experience when I've done it I've had to restart from scratch with a new prompt and twiddle things until it worked reliably. The only time switching models has ever been relatively easy for me",
            "title": "Who does your assistant serve?"
        }
    ],
    "lookbackDays": 1,
    "publishDate": "2025-08-17"
}