{
    "articles": [
        {
            "content": [],
            "link": "https://alexmolas.com/2025/10/30/bayesian-ab-test-peeking.html",
            "publishedAt": "2025-10-30",
            "source": "Alex Molas",
            "summary": "Introduction Over the last few months at RevenueCat I\u2019ve been building a statistical framework to flag when an A/B test has reached statistical significance. I went through the usual literature, including Evan Miller\u2019s posts. In his well known \u201cHow Not to Run an A/B Test\u201d there\u2019s a claim that with Bayesian experiment design you can stop at any time and still make valid inferences, and that you don\u2019t need a fixed sample size to get a valid result. I\u2019ve read this claim in other posts. The impression I got is that you can peek as often as you want, stop the moment the posterior clears a threshold (eg $P(A&gt;B) &gt; 0.95$), and you won\u2019t inflate false positives. And this is not correct. If you\u2019re an expert in Bayesian statistics this is probably obvious, but it wasn\u2019t for me. So I decided to run some simulations to see what really happens, and I\u2019m sharing the results here in case it can be useful for others.",
            "title": "Bayesian A/B testing is not immune to peeking"
        },
        {
            "content": [
                "<p>My day started off with an innocent question, from an innocent soul.</p>\n<p style=\"padding-left: 40px;\">\u201cHey Charity, is profiling a pillar?\u201d</p>\n<p>I hadn\u2019t even had my coffee yet.</p>\n<p style=\"padding-left: 40px;\">\u201cSomeone was just telling me that profiling is the fourth pillar of observability now. I said I think profiling is a great tool, but I don\u2019t know if it quite rises to the level of <em>pillar</em>. What do you think?\u201d</p>\n<p><em>What\u2026.do.. I think.</em></p>\n<p>What I think is, <strong>there are no pillars</strong>. I think the pillars are a fucking lie, dude. I think the language of pillars does a lot of work to keep good engineers trapped inside a mental model from the 1980s, paying outrageous sums of money for tooling that can\u2019t keep up with the chaos and complexity of modern systems.</p>\n<p>Here is a list of things I have recently heard people refer to as the \u201cfourth pillar of observability\u201d:</p>\n<ul>\n<li>Profiling</li>\n<li>Tokens (as in LLMs)</li>\n<li>Errors, exceptions</li>\n<li>Analytics</li>\n<li>Cost</li>\n</ul>\n<p>Is it a pillar, is it not a pillar? Are they all pillars? How many pillars are there?? How many pillars CAN there be? Gaahhh!</p>\n<p>This is not a new argument. Take this <a href=\"https://x.com/mipsytipsy/status/1044666259898593282?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1044666259898593282%7Ctwgr%5E9396190927fee8616723684a3fef9c05a8a1edb6%7Ctwcon%5Es1_&amp;ref_url=https%3A%2F%2Fcdn.embedly.com%2Fwidgets%2Fmedia.html%3Ftype%3Dtext2Fhtmlkey%3Da19fcc184b9711e1b4764040d3dc5c07schema%3Dtwitterurl%3Dhttps3A%2F%2Ftwitter.com%2Fmipsytipsy%2Fstatus%2F1044666259898593282image%3Dhttps3A%2F%2Fi.embed.ly%2F1%2Fimage3Furl3Dhttps253A252F252Fabs.twimg.com252Ferrors252Flogo46x38.png26key3Da19fcc184b9711e1b4764040d3dc5c07\">ranty little tweet thread of mine from way back in 2018</a>, for starters.</p>\n<div class=\"embed-twitter\"><blockquote class=\"twitter-tweet\"><p dir=\"ltr\" lang=\"en\"><img alt=\"\u2728\" class=\"wp-smiley\" src=\"https://s.w.org/images/core/emoji/16.0.1/72x72/2728.png\" style=\"height: 1em;\" />THERE ARE NO<img alt=\"\u2728\" class=\"wp-smiley\" src=\"https://s.w.org/images/core/emoji/16.0.1/72x72/2728.png\" style=\"height: 1em;\" /><br /><img alt=\"\u2728\" class=\"wp-smiley\" src=\"https://s.w.org/images/core/emoji/16.0.1/72x72/2728.png\" style=\"height: 1em;\" />THREE PILLARS OF<img alt=\"\u2728\" class=\"wp-smiley\" src=\"https://s.w.org/images/core/emoji/16.0.1/72x72/2728.png\" style=\"height: 1em;\" /><br />   <img alt=\"\u2728\" class=\"wp-smiley\" src=\"https://s.w.org/images/core/emoji/16.0.1/72x72/2728.png\" style=\"height: 1em;\" />OBSERVABILITY.<img alt=\"\u2728\" class=\"wp-smiley\" src=\"https://s.w.org/images/core/emoji/16.0.1/72x72/2728.png\" style=\"height: 1em;\" /><br /><br />and the fact that everybody keeps blindly repeating this mantra (and cargo culting these primitives) is probably why our observability tooling is 10 years behind the rest of our software tool chain. <a href=\"https://t.co/94yDBPuDRv\">https://t.co/94yDBPuDRv</a></p>&mdash; Charity Majors (@mipsytipsy) <a href=\"https://twitter.com/mipsytipsy/status/1044666259898593282?ref_src=twsrc%5Etfw\">September 25, 2018</a></blockquote></div>\n<p>&nbsp;</p>\n<p>Or perhaps you have heard of TEMPLE: Traces, Events, Metrics, Profiles, Logs, and\u00a0Exceptions?</p>\n<p>Or the <a href=\"https://thenewstack.io/modern-observability-is-a-single-braid-of-data/\">\u201cbraid\u201d of observability data</a>, or \u201c<a href=\"https://www.honeycomb.io/blog/they-arent-pillars-theyre-lenses\">They Aren\u2019t Pillars, They\u2019re Lenses</a>\u201d, or the Lightstep version: \u201c<a href=\"https://medium.com/lightstephq/three-pillars-with-zero-answers-2a98b36358b8\">Three Pillars, Zero Answers</a>\u201d (that title is a personal favorite).</p>\n<p>Alright, alright. Yes, this has been going on for a long time. I\u2019m older now and I&#8217;m tireder now, so here\u2019s how I&#8217;ll sum it up.</p>\n<p style=\"padding-left: 40px;\"><strong>Pillar</strong> is a marketing term.<br />\n<strong>Signal</strong> is a technical term.</p>\n<p>So \u201cis profiling a pillar?\u201d is a valid question, but it&#8217;s not a <em>technical</em> question. It\u2019s a question about the marketing claims being made by a given company. Some companies are building a profiling product right now, so yes, to them, it is vitally important to establish profiling as a \u201cpillar\u201d of observability, because you can charge a <em>hell</em> of a lot more for a &#8220;pillar&#8221; than you can charge for a mere &#8220;feature&#8221;. And more power to them. But it doesn\u2019t mean anything from a technical point of view.</p>\n<p>On the other hand, \u201csignal\u201d is absolutely a technical term. <a href=\"https://opentelemetry.io/docs/concepts/signals/\">The OpenTelemetry Signals documentation</a>, which I consider canon, says that OTel currently supports Traces, Metrics, Logs, and Baggage as signal types, with Events and Profiles at the proposal/development stage. So yes, profiling is a type of signal.</p>\n<p>The OTel docs define a telemetry signal as \u201ca type of data transmitted remotely for monitoring and analysis\u201d, and they define a pillar as \u2026 oh, they don\u2019t even mention pillars? like at all??</p>\n<p>I guess there&#8217;s your answer.</p>\n<p>And this is probably where I should end my piece. (Why am I still typing&#8230;. <img alt=\"\ud83e\udd14\" class=\"wp-smiley\" src=\"https://s.w.org/images/core/emoji/16.0.1/72x72/1f914.png\" style=\"height: 1em;\" />)</p>\n<h2>Pillars vs signals</h2>\n<p>First of all, I want to stress that <em>it does not bother me</em> when engineers go around talking about pillars. Nobody needs to look at me guiltily and apologize for using the term \u2018pillar\u2019 at<img alt=\"Bunnies Addendum (For the Buffy Fans) - En Tequila Es Verdad\" class=\"alignright\" height=\"224\" src=\"https://i0.wp.com/i.pinimg.com/564x/74/e3/91/74e3912b5482dedb363516d9944c6dad.jpg?resize=172%2C224&#038;ssl=1\" width=\"172\" />\u00a0the bar after a conference because they think I\u2019m mad at them. I am not the language police, it is not my job to go around enforcing correct use of technical terms. (I used to, I know, and I\u2019m sorry! <img alt=\"\ud83d\ude06\" class=\"wp-smiley\" src=\"https://s.w.org/images/core/emoji/16.0.1/72x72/1f606.png\" style=\"height: 1em;\" />)</p>\n<p>When engineers talk about pillars of observability, they\u2019re just talking about signals and signal types, and \u201cpillar\u201d is a perfectly acceptable colloquialism for \u201csignal\u201d.</p>\n<p>When a <em>vendor</em> starts talking about pillars, though \u2014 as in the example above! \u2014 it means they are gearing up to sell you something: another type of signal, siloed off from all the other signals you send them. Your <a href=\"https://www.honeycomb.io/blog/cost-crisis-observability-tooling\">cost multiplier</a> is about to <a href=\"https://www.honeycomb.io/blog/how-much-should-i-spend-on-observability-pt1\">increment again</a>, and then they\u2019re going to start talking about how Important it is that you buy a product for each and every one of the Pillars they happen to have.</p>\n<p>As a refresher: there are <a href=\"https://charity.wtf/2024/08/07/is-it-time-to-version-observability-signs-point-to-yes/\">two basic architecture models</a> used by observability companies, the multiple pillars model and the unified storage model (aka o11y 2.0). The <a href=\"https://www.honeycomb.io/blog/one-key-difference-observability1dot0-2dot0\">multiple pillars model</a> is to store every type of signal in a different siloed storage location &#8212; metrics, logs, traces, profiling, exceptions, etc, <em>everybody</em> gets a database! The <a href=\"https://charity.wtf/2024/12/20/on-versioning-observabilities-1-0-2-0-3-0-10-0/\">unified storage model</a> is to store all signals together in ONE database, preserving context and relationships, so you can treat data like data: slice and dice, zoom in, zoom out, etc.</p>\n<p>Most of the industry giants were built using the pillars model, but Honeycomb (and every other observability company founded post-2019) has built using the unified storage model, building <a href=\"https://www.honeycomb.io/blog/so-you-want-to-build-an-observability-tool\">wide, structured log events on a columnar storage engine</a> with high cardinality support, and so on.</p>\n<h2>Bunny-hopping from pillar to pillar</h2>\n<p>When you use each signal type as a standalone pillar, this leads to an experience I think of as \u201cbunny products\u201d <img alt=\"\ud83d\udc07\" class=\"wp-smiley\" src=\"https://s.w.org/images/core/emoji/16.0.1/72x72/1f407.png\" style=\"height: 1em;\" /> where the user is always hopping from pillar to pillar. You see something on your metrics dashboard that looks scary? hop-hop to your logs and try to find it there, using grep and search and matching by timestamps. If you can find the right logs, then you need to trace it, so you hop-hop-hop to your traces and repeat your search there. With profiling as a pillar, maybe you can hop over to that dataset too.<img alt=\"\ud83d\udc07\" class=\"wp-smiley\" src=\"https://s.w.org/images/core/emoji/16.0.1/72x72/1f407.png\" style=\"height: 1em;\" /><img alt=\"\ud83d\udc30\" class=\"wp-smiley\" src=\"https://s.w.org/images/core/emoji/16.0.1/72x72/1f430.png\" style=\"height: 1em;\" /></p>\n<p>The amount of data duplication involved in this model is <em>mind boggling</em>. You are literally storing the same information in your metrics TSDB as you are in your logs and your traces, just formatted<img alt=\"The 30 Best Bunny Rabbit Memes - Hop to Pop\" class=\"alignright\" height=\"186\" src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQ07ZmfJNJ8rDyWebCj3utRbXWxeJKT7brJVw&amp;s\" width=\"192\" />\u00a0differently. (I never miss an opportunity to link to <a href=\"https://jeremymorrell.dev/blog/a-practitioners-guide-to-wide-events/\">Jeremy Morrell&#8217;s masterful doc on instrumenting your code for wide events</a>, which also happens to illustrate this nicely.) This is insanely expensive. Every request that enters your system gets stored <em>how many times, </em>in<em> how many signals</em>? Count it up; that&#8217;s your cost multiplier.</p>\n<p>Worse, much of the data that connects each \u201cpillar\u201d exists only in the heads of the most senior engineers, so they can guess or intuit their way around the system, but anyone who relies on actual data is screwed. Some vendors have added an ability to construct little rickety bridges post hoc between pillars, e.g. \u201cthis metric is derived from this value in this log line or trace\u201d, but now you\u2019re paying for each of those little bridges in addition to each place you store the data (and it goes without saying, you can only do this for things you can predict or hook up in the first place).</p>\n<p>The multiple pillars model (formerly known as observability 1.0) relies on you believing that each signal type must be stored separately and treated differently. That\u2019s what the pillars language is there to reinforce. Is it a Pillar or not?? It doesn\u2019t matter because pillars don\u2019t exist. Just know that if your vendor is calling it a <span style=\"text-decoration: underline;\">P</span>illar, you are definitely going to have to <span style=\"text-decoration: underline;\">P</span>ay for it. <img alt=\"\ud83d\ude09\" class=\"wp-smiley\" src=\"https://s.w.org/images/core/emoji/16.0.1/72x72/1f609.png\" style=\"height: 1em;\" /></p>\n<h2>Zooming in and out</h2>\n<p>But all this data is just.. data. There is no good reason to silo signals off from each other, and lots of good reasons not to. You can derive metrics from rich, structured data blobs, or append your metrics to wide, structured log events. You can add span IDs and visualize them as a trace. The unified storage model (\u201co11y 2.0\u201d) says you should store your data once, and do all the signal processing in the collection or analysis stages. Like civilized folks.</p>\n<figure class=\"wp-caption alignright\" style=\"width: 232px;\"><img alt=\"Anya Bunny Quote - Etsy\" height=\"232\" src=\"https://i0.wp.com/i.etsystatic.com/10147996/r/il/da4dfe/708169568/il_300x300.708169568_rykv.jpg?resize=232%2C232&#038;ssl=1\" width=\"232\" /><figcaption class=\"wp-caption-text\">All along, Anya was right</figcaption></figure>\n<p>From the perspective of the developer, not much changes. It just gets easier (a LOT easier), because nobody is harping on you about whether this nit of data should be a metric, a log, a trace, or all of the above, or if it\u2019s low cardinality or high cardinality, or whether the cardinality of the data COULD someday blow up, or whether it&#8217;s a counter, a gauge, a heatmap, or some other type of metric, or when the counter is going to get reset, or whether your heatmap buckets are defined at useful intervals, or&#8230;or&#8230;</p>\n<p>Instead, it&#8217;s just a blob of json. Structured data.. If you think it might be interesting to you someday, you dump it in, and if not, you don&#8217;t. That\u2019s all. Cognitive load drops way down..</p>\n<p>On the backend side, we store it once, retaining all the signal type information and connective tissue.</p>\n<p>It\u2019s the user interface where things change most dramatically. No more bunny hopping around from pillar to pillar, guessing and copy-pasting IDs and crossing your fingers. Instead, it works more like the zoom function on PDFs or Google maps.</p>\n<p>You start with SLOs, maybe, or a familiar-looking metrics dashboard. But instead of hopping, you just.. zoom in. The SLOs and metrics are derived from the data you need to debug with, so you\u2019re just like.. \u201cAh what\u2019s my SLO violation about? Oh, it\u2019s because of these events.\u201d Want to trace one of them? Just click on it. No hopping, no guessing, no pasting IDs around, no lining up time stamps.</p>\n<p>Zoom in, zoom out, it&#8217;s all connected. Same fucking data.</p>\n<h2>\u201cBut OpenTelemetry <span style=\"text-decoration: underline;\">FORCES</span> you to use three pillars\u201d</h2>\n<p>There\u2019s a misconception out there that OpenTelemetry is very pro-three pillars, and very anti o11y 2.0. This is a) not true and b) actually the opposite. Austin Parker has written a <a href=\"https://www.honeycomb.io/resources/whitepapers/opentelemetry-semantic-telemetry-reshape-observability\">voluminous amount of material</a> explaining that actually, under the hood, OTel treats everything like one big wide structured event log.<img alt=\"\" class=\"alignright size-medium wp-image-10204\" height=\"300\" src=\"https://i0.wp.com/charity.wtf/wp-content/uploads/2025/10/srebunny.png?resize=200%2C300&#038;ssl=1\" width=\"200\" /></p>\n<p><a href=\"https://www.honeycomb.io/blog/opentelemetry-is-not-three-pillars\">As Austin puts it</a>, \u201cOpenTelemetry, fundamentally, unifies telemetry signals through shared, distributed context.\u201d However:</p>\n<p style=\"padding-left: 40px;\">\u201cThe project doesn\u2019t <em>require</em> you to do this. Each signal is usable more or less independently of the other. If you want to use OpenTelemetry data to feed a traditional \u2018three pillars\u2019 system where your data is stored in different places, with different query semantics, you can. Heck, quite a few very successful observability tools let you do that today!\u201d</p>\n<p style=\"padding-left: 40px;\">\u201cThis isn\u2019t just \u2018three pillars but with some standards on top,\u2019 it\u2019s a radical departure from the traditional \u2018log everything and let god sort it out\u2019 approach that\u2019s driven observability practices over the past couple of decades.\u201d</p>\n<p>You <em>can</em> use OTel to reinforce a three pillars mindset, but you don\u2019t <em>have</em> to. Most vendors have <em>chosen</em> to implement three pillarsy crap on top of it, which you can&#8217;t really hold OTel responsible for. One[1] might even argue that OTel is doing as much as it can to influence you in the opposite direction, while still meeting Pillaristas where they\u2019re at.</p>\n<h2>A postscript on profiling</h2>\n<p>What will profiling mean in a unified storage world? It just means you\u2019ll be able to zoom in to even finer and lower-level resolution, down to syscalls and kernel operations instead of function calls. Like when Google Maps got good enough that you could read license plates instead of just rooftops.</p>\n<p>Admittedly, we don\u2019t have profiling yet at <a href=\"http://honeycomb.io\">Honeycomb</a>. When we did some research into the profiling space, what we learned was that most of the people who think they&#8217;re in desperate need of a profiling tool are actually in need of a good <strong>tracing tool</strong>. Either they didn\u2019t have distributed tracing or their tracing tools just weren\u2019t cutting it, for reasons that are not germane in a Honeycomb tracing world.</p>\n<p>We\u2019ll get to profiling, hopefully in the near-ish future, but for the most part, if you don\u2019t need syscall level data, you probably don\u2019t need profiling data either. Just good traces.</p>\n<p>Also\u2026 I did not make this site or have any say whatsoever in the building of it, but I did sign the manifesto[2] and every day that I remember it exists is a day I delight in the joy and fullness of being alive:\u00a0<a href=\"http://kill3pill.com\">kill3pill.com</a> <img alt=\"\ud83d\udcc8\" class=\"wp-smiley\" src=\"https://s.w.org/images/core/emoji/16.0.1/72x72/1f4c8.png\" style=\"height: 1em;\" /></p>\n<p><a href=\"http://kill3pill.com\"><img alt=\"Kill Three Pillars\" class=\"aligncenter wp-image-10200\" height=\"115\" src=\"https://i0.wp.com/charity.wtf/wp-content/uploads/2025/10/Screenshot-2025-10-29-at-22.02.55.png?resize=493%2C115&#038;ssl=1\" width=\"493\" /></a></p>\n<p>Hop hop, little friends,<br />\n~charity</p>\n<p>&nbsp;</p>\n<p>[1] <em>Austin</em> argues this. I&#8217;m talking about Austin, if not clear enough.<br />\n[2] Thank you, <a href=\"https://www.linkedin.com/in/synapticmishap/\">John Gallagher</a>!!</p>"
            ],
            "link": "https://charity.wtf/2025/10/30/the-pillar-is-a-lie/",
            "publishedAt": "2025-10-30",
            "source": "Charity Majors",
            "summary": "My day started off with an innocent question, from an innocent soul. \u201cHey Charity, is profiling a pillar?\u201d I hadn\u2019t even had my coffee yet. \u201cSomeone was just telling me that profiling is the fourth pillar of observability now. I said I think profiling is a great tool, but I don\u2019t know if it quite [&#8230;]",
            "title": "How many pillars of observability can you fit on the head of a pin?"
        },
        {
            "content": [
                "<p>Here are a few things that seem to be true:</p>\n\n<ol>\n  <li>Dating apps are very popular.</li>\n  <li>Lots of people hate dating apps.</li>\n  <li>They hate them so much that there\u2019s supposedly a resurgence in alternatives like speed dating.</li>\n</ol>\n\n<p>None of those are too controversial, I think. (Let\u2019s stress <em>supposedly</em> in #3.) But if you stare at them for a while, it\u2019s hard to see how they can all be true at the same time.</p>\n\n<p>Because, why do people hate dating apps? People complain that they\u2019re bad in various ways, such as being ineffective, dehumanizing, or expensive. (And such small portions!) But if they\u2019re bad, then <em>why</em>? Technologically speaking, a dating app is not difficult to make. If dating apps are so bad, why don\u2019t new non-bad ones emerge and outcompete them?</p>\n\n<p>The typical answer is network effects. A dating app\u2019s value depends on how many other people are on it. So everyone gravitates to the popular ones and eventually most of the market is captured by a few winners. To displace them, you\u2019d have to spend a huge amount of money on advertising. So\u2014the theory goes\u2014the winners are an oligopoly that gleefully focus on extracting money from their clients instead of making those clients happy.</p>\n\n<p>That isn\u2019t obviously wrong. Match Group (which owns Tinder, Match, Plenty of Fish, OK Cupid, Hinge, and many others) has recently had an operating margin of <a href=\"https://www.macrotrends.net/stocks/charts/MTCH/match-group/operating-margin\">~25%</a>. That\u2019s more like a crazy-profitable entrenched tech company (Apple manages <a href=\"https://www.macrotrends.net/stocks/charts/AAPL/apple/operating-margin\">~30%</a>) than a nervous business in a crowded market.</p>\n\n<p>But wait a second. How many people go to a speed dating event? Maybe 30? I don\u2019t know if the speed dating \u201cresurgence\u201d is real, but it doesn\u2019t matter. Some people definitely do find love at real-life events with small numbers of people. If that\u2019s possible, then shouldn\u2019t it also be possible to create a dating app that\u2019s useful even with only a small number of users? Meaning good apps should have emerged long ago and displaced the crappy incumbents? And so the surviving dating apps should be non-hated?</p>\n\n<p>We\u2019ve got ourselves a contradiction. So <em>something</em> is wrong with that argument. But what?</p>\n\n<h2 id=\"theory-1-selection\">Theory 1: Selection</h2>\n\n<p>Perhaps speed dating attendees are more likely to be good matches than people on dating apps. This might be true because they tend to be similar in terms of income, education, etc., and people tend to mate assortatively. People who go to such events might also have some similarities in terms of personality or what they\u2019re looking for in a relationship.</p>\n\n<p>You could also theorize that people at speed dating events are higher \u201cquality\u201d. For example, maybe it\u2019s easier to conceal negative traits on dating apps than it is in person. If so, this might lead to some kind of <a href=\"https://en.wikipedia.org/wiki/Adverse_selection\">adverse selection</a> where people <em>without</em> secret negative traits get frustrated and stop using the apps.</p>\n\n<p>I\u2019m not sure either of those are true. But even if they are, consider the magnitudes. While a speed dating event might have 30 people, a dating app in a large city could easily have 30,<strong>000</strong> users. While the fraction of good matches might be lower on a dating app, the absolute number is still surely far higher.</p>\n\n<h2 id=\"theory-2-bandwidth\">Theory 2: Bandwidth</h2>\n\n<p>Perhaps even if you have fewer potential matches at a speed dating event, you have better odds of actually finding them, because in-person interactions reveals information that dating apps don\u2019t.</p>\n\n<p>People often complain that dating apps are superficial, that there\u2019s too much focus on pictures. Personally, I don\u2019t think pictures deserve so much criticism. Yes, they show how hot you are. But pictures also give lots of information about important non-superficial things, like your personality, values, social class, and lifestyle. I\u2019m convinced people use pictures for all that stuff as much as hotness.</p>\n\n<p>But you know what\u2019s even better than pictures? Actually talking to someone!</p>\n\n<p>Many people seem to think that a few minutes of small talk isn\u2019t enough time to learn anything about someone. Personally, I think evolution spent millions of years training us to do exactly that. I\u2019d even claim that this is why small talk exists.</p>\n\n<p>(I have friends with varying levels of extroversion and agreeableness, but <em>all</em> of my friends seem to have high <a href=\"https://en.wikipedia.org/wiki/Openness_to_experience\">openness to experience</a>. When I meet someone new, I\u2019m convinced I can guess their openness to \u00b110% by the time they\u2019ve completed five sentences.)</p>\n\n<p>So maybe the information a dating app provides just isn\u2019t all that useful compared to a few minutes of casual conversation. If so, then dating apps might be incredibly inefficient. You have to go through some silly texting courtship ritual, set up a time to meet, physically go there, and then pretend to smile for an hour even if you immediately hate them.</p>\n\n<p>Under this theory, dating apps provide a tiny amount of information about a gigantic pool of people, while speed dating provides a ton of information about a small number of people. Maybe that\u2019s a win, at least sometimes.</p>\n\n<h2 id=\"theory-3-behavior\">Theory 3: Behavior</h2>\n\n<p>Maybe the benefit of real-life events isn\u2019t that they provide more information, but that they change how we behave.</p>\n\n<p>For example, maybe people are nicer in person? Because only then can we sense that others are also sentient beings with internal lives and so on?</p>\n\n<p>I\u2019m pretty sure that\u2019s true. But it\u2019s not obvious it helps with our mystery, since people from dating apps eventually meet in person, too. If they\u2019re still nice when they do, then this just resolves into \u201cin-person interactions provide more information\u201d, and is already covered by the previous theory. To help resolve our mystery, you\u2019d need to claim that people at real-life events act differently than they do when meeting up as a result of a dating app.</p>\n\n<p>That <em>could</em> happen as a result of a \u201cbehavioral equilibrium\u201d. Some people take dating apps seriously and some take them casually. But it\u2019s hard to tell what category someone else is in, so everyone proceeds with caution. But by showing up at an in-person event, everyone has demonstrated some level of seriousness. And maybe this makes everyone behave differently? Perhaps, but I don\u2019t really see it.</p>\n\n<h2 id=\"obscure-theories\">Obscure theories</h2>\n\n<p>I can think of a few other possible explanations.</p>\n\n<ol>\n  <li>\n    <p>Maybe speed dating serves a niche. Just like <a href=\"https://fitafy.com/\">Fitafy</a> / <a href=\"https://www.bristlr.com/\">Bristlr </a> / <a href=\"https://highthere.com/\">High There!</a> serve people who love fitness / beards / marijuana, maybe speed dating just serves some small-ish fraction of the population but not others.</p>\n  </li>\n  <li>\n    <p>Maybe the people who succeed at speed dating would also have succeeded no matter what. So they don\u2019t offer any general lessons.</p>\n  </li>\n  <li>\n    <p>Maybe creating a dating app is in fact very technologically difficult. So while the dating apps are profit-extracting oligopolies, that\u2019s because of technological moat, not network effects.</p>\n  </li>\n</ol>\n\n<p>I don\u2019t really buy any of these.</p>\n\n<h2 id=\"drumroll\">Drumroll</h2>\n\n<p>So what\u2019s really happening? I am <strong>not confident</strong>, but here\u2019s my best guess:</p>\n\n<ol>\n  <li>\n    <p>Selection is not a major factor.</p>\n  </li>\n  <li>\n    <p>The high bandwidth of in-person interactions <em>is</em> a major factor.</p>\n  </li>\n  <li>\n    <p>The fact that people are nicer or more open-minded in person is not a major factor, other than through making in-person interactions higher bandwidth.</p>\n  </li>\n  <li>\n    <p>None of the obscure theories are major factors.</p>\n  </li>\n  <li>\n    <p>Dating apps are an oligopoly, driven by network effects.</p>\n  </li>\n</ol>\n\n<p>Basically, a key \u201cfilter\u201d in finding love is finding someone where you both feel optimistic after talking for five minutes. Speed dating is (somewhat / sometimes) effective because it efficiently crams a lot of people into the top of that filter.</p>\n\n<p><img alt=\"\" src=\"https://dynomight.net/img/dating/funnel.svg\" /></p>\n\n<p>Meanwhile, because dating apps are low-bandwidth, they need a large pool to be viable. Thus, they\u2019re subject to network effects, and the winners can turn the screws to extract maximum profits from their users.</p>\n\n<p>Partly I\u2019m not confident in that story just because it has so many moving parts. But something else worries me too. If it\u2019s true, then why aren\u2019t dating apps trying harder to provide that same information that in-person interactions do?</p>\n\n<p>If anything, I understand they\u2019re moving in the opposite direction. Maybe Match Group would have no interest in that, since they\u2019re busy enjoying their precious network effects. But why not startups? Hell, why not philanthropies? (Think of all the utility you could create!) For the above story to hold together, you have to believe that it\u2019s a very difficult problem.</p>"
            ],
            "link": "https://dynomight.net/dating/",
            "publishedAt": "2025-10-30",
            "source": "Dynomight",
            "summary": "<p>Here are a few things that seem to be true:</p> <ol> <li>Dating apps are very popular.</li> <li>Lots of people hate dating apps.</li> <li>They hate them so much that there\u2019s supposedly a resurgence in alternatives like speed dating.</li> </ol> <p>None of those are too controversial, I think. (Let\u2019s stress <em>supposedly</em> in #3.) But if you stare at them for a while, it\u2019s hard to see how they can all be true at the same time.</p> <p>Because, why do people hate dating apps? People complain that they\u2019re bad in various ways, such as being ineffective, dehumanizing, or expensive. (And such small portions!) But if they\u2019re bad, then <em>why</em>? Technologically speaking, a dating app is not difficult to make. If dating apps are so bad, why don\u2019t new non-bad ones emerge and outcompete them?</p> <p>The typical answer is network effects. A dating app\u2019s value depends on how many other people are on it. So everyone gravitates to the popular ones and eventually most of the market is captured by a few winners. To displace them, you\u2019d have to spend a huge amount of money on advertising. So\u2014the theory goes\u2014the winners are an oligopoly that gleefully focus on extracting money from their clients instead",
            "title": "Dating: A mysterious constellation of facts"
        },
        {
            "content": [],
            "link": "https://interconnected.org/home/2025/10/30/filtered",
            "publishedAt": "2025-10-30",
            "source": "Matt Webb",
            "summary": "<div> <h3>1.</h3> <p>When you sit with friends at a wobbly table,<br /> Simply rotate till it becomes stable.<br /> No need to find a wedge for one of its four feet.<br /> Math will ensure nothing spills while you eat.</p> <p><a href=\"https://people.math.harvard.edu/~knill/teaching/math1a_2011/exhibits/wobblytable/\">The Wobbly Table Theorem</a> (Department of Mathematics, Harvard University).</p> <h3>2.</h3> <p>David Ogilvy changed advertising in 1951.<br /> Shirts sold. Job done.<br /> He used a surprise black eyepatch in the magazine spot:<br /> \u201cstory appeal\u201d makes consumers think a lot.</p> <p><a href=\"https://www.campaignlive.co.uk/article/history-advertising-no-110-hathaway-mans-eyepatch/1317084\">History of advertising: No 110: The Hathaway man\u2019s eyepatch</a> (Campaign, 2014).</p> <h3>3.</h3> <p>Frogs live in ponds.<br /> These massive ones too.<br /> But they dig their own ponds<br /> when nothing else will do.</p> <p><a href=\"https://www.science.org/content/article/world-s-biggest-frogs-build-their-own-ponds\">The world\u2019s biggest frogs build their own ponds</a> (Science, 2019).</p> <h3>4.</h3> <p>Rhyming poems have been going away,<br /> from 70% in 1900 to almost zero today.<br /> You know, I feel like we should all be doing our bit<br /> to reverse the decline. But my poems are terrible.</p> <p><a href=\"https://jmarriott.substack.com/p/can-you-tell-ai-from-human-genius\">Can you tell AI from human genius?</a> (James Marriott).</p> <hr /> <p><small>More posts tagged: <a href=\"https://interconnected.org/home/tagged/filtered-for\">filtered-for</a> (119). </small></p> </div>",
            "title": "Filtered for wobbly tables and other facts"
        },
        {
            "content": [
                "<p><em>[I haven&#8217;t independently verified each link. On average, commenters will end up spotting evidence that around two or three of the links in each links post are wrong or misleading. I correct these as I see them, and will highlight important corrections later, but I can&#8217;t guarantee I will have caught them all by the time you read this.]</em></p><p><strong>1: </strong>In 1876, a woman named <a href=\"https://en.wikipedia.org/wiki/Mary_Tyler\">Mary Tyler</a> claimed to be the Mary of &#8220;Mary Had A Little Lamb&#8221;. Her story is plausible - she was a schoolchild in Sterling Massachussetts in the 1810s, and the author of the song was a schoolteacher in Sterling in the 1810s - but some key details don&#8217;t line up (she remembers her pet lamb being observed by a man, but the author was a woman). After she became famous, she &#8220;helped save the Old South Meeting House in Boston by selling fleece from her pet lamb as attachments on autograph cards&#8221;.</p><p><strong>2: </strong><a href=\"https://substack.com/@jurgengravestein1/note/c-168345617\">Prediction by Jurgen Gravestein</a>: &#8220;I don&#8217;t think people realize what kind of ads are coming. If the Sora app has your face, you will in the near future see ads of yourself wearing clothes of a certain brand.&#8221;</p><p><strong>3: </strong><a href=\"https://www.lesswrong.com/posts/6ZnznCaTcbGYsCmqu/the-rise-of-parasitic-ai\">The Rise Of Parasitic AI</a>. An investigation into the possibility that AI psychosis is evolving into a memetic parasite that tries to spread to other humans and AIs. Also maybe a religion (but I repeat myself). Read it first in its intended genre of serious nonfiction, then as a scifi-horror story with an unreliable narrator who you&#8217;re not entirely sure hasn&#8217;t fallen to AI psychosis herself. </p><p><strong>4: </strong><a href=\"https://gildhelm.substack.com/p/its-no-great-awakening?manualredirect=&amp;triedRedirect=true\">It&#8217;s No Great Awakening</a>. Claims of a revival in American Christianity among the young are not borne out by data. The country is no longer secularizing at the same rate as in the early 2000s, but there is no sign of any reversal.</p><p><strong>5: </strong><a href=\"https://secondthoughts.ai/p/gpt-5-the-case-of-the-missing-agent\">Steve Newman: The Case Of The Missing Agent</a>. &#8220;In April 2024, it seemed like agentic AI was going to be the next big thing. The ensuing 16 months have brought enormous progress on many fronts, but very little progress on real-world agency.&#8221; On the other hand, <a href=\"https://simonwillison.net/2025/Oct/16/claude-skills/\">Simon Willison on Claude Skills</a>: &#8220;Back in January, I made some foolhardy predictions about AI, including that &#8220;agents&#8221; would once again fail to happen . . . I was entirely wrong, 2025 really has been the year of &#8220;agents&#8221;, no matter which of the many conflicting definitions you decide to use.&#8220;</p><p><strong>6: </strong>Related: <a href=\"https://www.lesswrong.com/posts/hmZHPE4ZJvEc3khgQ/checking-in-on-ai-2027\">Checking In On AI 2027</a>. &#8220;AI-2027&#8217;s specific predictions for August 2025 appear to have happened in September of 2025. The predictions were accurate, if a tad late, but they are late by weeks, not months.&#8221; But the early predictions were mostly straightforward extrapolation of benchmark improvements, with the later ones depending on a more controversial theory of recursive self-improvement, so the success of the early predictions doesn&#8217;t necessarily say much about the later ones. <a href=\"https://x.com/sama/status/1983584366547829073\">Related (X)</a>: OpenAI sets an &#8220;internal goal&#8221; of having an &#8220;automated AI research intern&#8221; and &#8220;true automated AI researcher&#8221; on approximately the AI 2027 timeline. </p><p><strong>7: </strong><a href=\"https://www.gbnews.com/politics/james-cleverly-nigel-farage-reform-uk-conservative-party\">James Cleverly Accuses Nigel Farage Of Being Socialist</a> | <a href=\"https://www.bbc.com/news/articles/c24v0j73e75o\">James Cleverly Returns To Tory Front Bench</a> | <a href=\"https://en.wikipedia.org/wiki/James_Cleverly\">James Cleverly Uses A Surname That Makes It Sounds Like News Stories Are Praising Him Every Time They Mention One Of His Actions</a>.  </p><p><strong>8: </strong></p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2\" href=\"https://x.com/ArtirKel/status/1974510612588953888\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"462.77530017152657\" src=\"https://substackcdn.com/image/fetch/$s_!4KK0!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7a397aad-1a98-4fd1-85f9-164b9658bd20_583x554.png\" title=\"\" width=\"487\" /><div></div></div></a></figure></div><p>Everyone who studies biochem asks themselves at some point &#8220;Why do cells need such long signaling pathways?&#8221; - ie so many chemicals whose only point is to activate other chemicals and so on in a chain, until the last chemical in the chain makes something happen. If I understand <a href=\"https://www.pnas.org/doi/pdf/10.1073/pnas.1920338117\">this paper</a> right, it&#8217;s claiming that if each chemical has enough positive and negative inputs, this is analogous to a neural network, capable of making primitive decisions about cellular behavior. I asked some real biologists, who were not nearly as impressed with this thesis as I was and said that although these chains do help set cellular behavior, the analogy between levels of a chemical and the activation function of a neuron was too weak to carry so much weight. I still wonder whether insights from mechanistic interpretability could help us understand networks like these.</p><p><strong>9: </strong><a href=\"https://www.cambridge.org/core/journals/american-political-science-review/article/political-symbols-and-social-order-confederate-monuments-and-performative-violence-in-the-postreconstruction-us-south/4FAC95FC7644C8D85997D724A0EAA513\">Political Symbols and Social Order: Confederate Monuments And Performative Violence in the Post-Reconstruction US South.</a> Study claims that Confederate monuments <em>reduced</em> racial violence by serving as a substitute for it; when there was a Confederate monument in town, Southerners felt less need to enforce white supremacy in other ways. Therefore, <em>removing </em>racist monuments <em>increases</em> anti-black hate crimes. This finding is a little too cute, but I love imagining the world where we take it seriously and woke people demand a General Lee statue on every corner.</p><p><strong>10: </strong>Sol Hando <a href=\"https://solhando.substack.com/p/should-the-us-be-ruled-by-a-ceo-dictator\">attends the Curtis Yarvin vs. Glen Weyl debate</a> so you don&#8217;t have to. You won&#8217;t find many surprises about the content/arguments here, but it&#8217;s an interesting look at the personalities, the venue, and the debate as a cultural moment.</p><p><strong>11: </strong>Pharmacy-blogger Benjamin Jolley <a href=\"https://benjaminjolley.substack.com/p/i-joined-the-one-kidney-club\">becomes the latest Substacker to donate a kidney</a>; congratulations Benjamin.</p><blockquote><p>My choice to donate felt right before I donated, it makes me feel satisfied that I did a good thing for another person, and it makes me feel like I&#8217;m making choices that are consistent with my belief system. The care team involved in the process were professional, exuded competence, and reassured me throughout the process. To others that I&#8217;ve discussed it with, it seems like a very large thing, which I suppose it is, but functionally the largest burden on my life so far has been that I haven&#8217;t been able to pick up my three year old when she asks me &#8220;hold me, daddy!&#8221;, because I&#8217;m not supposed to lift anything more than 10 pounds for the first 6 weeks after surgery. That burden will go away in 2 weeks. Completing all of the pre-operative blood draws, appointments, and other tests, plus my admission to the hospital in total took up about 100 hours of my life, mostly in the hospital recovering. While I hope that a few people in my sphere of influence will consider donating too (if you want to, filling out <a href=\"https://nkr.donorscreen.org/register/now?_gl=1*rhw1v*_ga*Mjk0MzgwNDMyLjE3NTU4MTAwNjA.*_ga_FFGZF97C1Z*czE3NTU4MTg3NDQkbzIkZzEkdDE3NTU4MTk4MzIkajYwJGwwJGgw\">this form</a> will connect you to your local hospital to start the process), my real hope is that we can solve the shortage of kidney donations more permanently. Zero people on the waitlist. People only on dialysis as a brief stopgap before they get their donated kidney. Let&#8217;s make that dream a reality.</p></blockquote><p>Inspiring words - but my personal strongest reaction was relief at learning that I wasn&#8217;t the only supposedly-competent health professional to bungle the urine jug.</p><p><strong>12: </strong><a href=\"https://unfacts.substack.com/p/the-case-for-a-technocratic-doge\">The Case For A Technocratic Doge</a>. This went an entirely different direction than I expected based on the title.</p><p><strong>13: </strong>According to <a href=\"https://x.com/JustinGrimmer/status/1966997411060215960\">Justin Grimmer (X)</a> and the <a href=\"https://americaspoliticalpulse.com/citizens/\">Polarization Research Lab</a>, there is been no change in support for political violence over the past two years:</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2\" href=\"https://substackcdn.com/image/fetch/$s_!a9vN!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fda934f72-6a31-4cec-bccd-46f7610c7fb4_2008x654.jpeg\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"231.7912087912088\" src=\"https://substackcdn.com/image/fetch/$s_!a9vN!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fda934f72-6a31-4cec-bccd-46f7610c7fb4_2008x654.jpeg\" width=\"712\" /><div></div></div></a></figure></div><p>And <a href=\"https://x.com/_jaybaxter_/status/1966653089076965618\">related data from Jay Baxter here (X)</a>.</p><p><strong>14: </strong><a href=\"https://www.lesswrong.com/posts/52tYaGQgaEPvZaHTb/was-barack-obama-still-serving-as-president-in-december\">A surprising LLM failure mode</a>: if you ask questions like &#8220;answer with a single word: were any mammoths still alive in December&#8221;, chatbots will often answer &#8220;yes&#8221;. It seems like they lack the natural human assumption that you meant <em>last</em> December, and are answering that there was <em>some</em> December during which a mammoth was alive. I find this weird because LLMs usually seem very good at navigating the many assumptions you need to communicate at all; this one stands as a strange exception.</p><p><strong>15: </strong><a href=\"https://x.com/daveweigel/status/1969058989284467164\">Claim (X)</a>: some of the flags you see behind world leaders aren&#8217;t real cloth, but &#8220;flag cones&#8221; designed to avoid the problem where real flags might drape awkwardly and look wrong.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!47SM!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F94cc58e5-9d0c-4ffe-8d75-340332cc1757_583x588.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"489.15951972555746\" src=\"https://substackcdn.com/image/fetch/$s_!47SM!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F94cc58e5-9d0c-4ffe-8d75-340332cc1757_583x588.png\" width=\"485\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a></figure></div><p><strong>16: </strong>The oldest surviving joke book is the <em><a href=\"https://x.com/lefineder/status/1970542406580732339\">Philogelos</a></em><a href=\"https://x.com/lefineder/status/1970542406580732339\"> (X)</a> from ~300 AD. </p><ul><li><p> An Abderite hears that beans cause wind, so he hangs a sackful on his sailing ship.</p></li><li><p>In Kyme, an official of some sort is having a funeral. A stranger approaches those conducting the obsequies and asks, &#8220;Who&#8217;s the dead guy?&#8221; One of the Kymaeans turns and points: &#8220;The one lying over there in the coffin.&#8221;</p></li><li><p>A student dunce begets a child by a slave girl. His father advises him to kill the child. The dunce retorts, &#8220;First kill your own children, and then tell me to do the same with mine!&#8221;</p></li></ul><p>More at the link.</p><p><strong>17: </strong><a href=\"https://x.com/hausfath/status/1970534038466170889\">Fifty years of climatologists&#8217; temperature predictions vs. reality (X)</a>:</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!-f_P!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5222e923-c88e-406d-8835-64048a86348d_2001x1580.jpeg\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"368.0631868131868\" src=\"https://substackcdn.com/image/fetch/$s_!-f_P!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5222e923-c88e-406d-8835-64048a86348d_2001x1580.jpeg\" width=\"466\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a></figure></div><p>One the one hand, the predictions are remarkably close to reality, and everyone who denounced them at the time comes out with egg on their face. On the other, they don&#8217;t seem to beat a baseline of linear extrapolation from past data. When I try to recall the 90s and early 00s, when these debates were at their most vitriolic, they always involved the ability of complex atmospheric models to track the chaotic nature of the world. I don&#8217;t remember hearing &#8220;it&#8217;s just linear extrapolation&#8221;, and I feel like this would have been much more convincing.</p><p><strong>18: </strong><a href=\"https://x.com/RBMD1982/status/1970309187558097381\">The politics of RFK Jr&#8217;s Tylenol announcement (X)</a>. RFK &#8220;overpromised an autism report with a tight deadline to his base and to Trump, who is curious about autism in a sort of hobbyist way.&#8221; He originally planned to blame vaccines, but this would have required him to do something about them, and he didn&#8217;t have enough political capital for that. The Tylenol announcement let him satisfy his conspiracy theorist base without offending any powerful lobbies - Tylenol is generic, doesn&#8217;t make Big Pharma any money, and even the Tylenol manufacturers don&#8217;t care that much about an extra easy-to-ignore warning against use during pregnancy (hint for Europeans who don&#8217;t understand this story: Tylenol = paracetamol). I continue to believe the real reason for rising autism rates <a href=\"https://www.cremieux.xyz/p/whats-the-deal-with-autism-rates\">is increased diagnosis</a>.</p><p><strong>19: </strong><a href=\"https://x.com/Scholars_Stage/status/1970628566716187080\">T Greer on Trump&#8217;s flip-flopping Ukraine-Russia policy (X)</a>: &#8220;Every administration since Clinton comes in determined to reset US-Russian relations, to clear away old legacies and bad blood. Clinton, Bush, Obama, Trump I, even Biden. It is the swampiest of all swampy ideas, resetting relations with the Russians. It never works.&#8221;</p><p><strong>20: </strong><a href=\"https://en.wikipedia.org/wiki/Friday_the_13th#Friday_the_17th_in_Italy\">Did you know</a>: in Italy, the unlucky number is 17 instead of 13, because XVII is an anagram of <em>vixi</em>, Latin for &#8220;I have lived&#8221; (note past tense). </p><p><strong>21: </strong><a href=\"https://x.com/ESYudkowsky/status/1971311526767476760\">Eliezer (X)</a>: the folk theory of economic bubbles says they&#8217;re bad for the economy because lots of money gets invested inefficiently into something which turns out to be useless. But this can&#8217;t be right, because the economy is doing fine while the bad investment is going on! It&#8217;s only afterwards, when people realize the investment was bad, that the economy starts to falter (cf. the Wile E. Coyote theory of gravity, where walking off a cliff is fine, but <em>noticing </em>that you walked off a cliff is ruinous). So what&#8217;s the real reason bubbles are bad? &#8220;Macroeconomic financial bullshit involving scary terms like &#8216;aggregate demand&#8217; and concepts like &#8216;downward wage rigidity&#8217;&#8221;. Interested to know if orthodox economists agree.</p><p><strong>22: </strong>Earlier this year, I <a href=\"https://www.astralcodexten.com/p/how-to-stop-worrying-and-learn-to\">wrote about</a> Richard Lynn&#8217;s IQ estimates - what do we do with data suggesting that the average IQ in poor countries is in the 60s or 70s? Should we think of these groups as similar to intellectually disabled people in First World countries? Or are the IQ tests failing to classify them correctly? <a href=\"https://x.com/AndrewHammel1/status/1965356952764252320\">Andrew Hammel (X)</a> writes about a remarkable case in Germany that hinged on this question: a Syrian terrorist murdered three people. The defense argued that since he had an IQ of 71 (borderline intellectually disabled by German standards) he couldn&#8217;t be held responsible for his actions. But a psychiatric expert witness counterargued that IQ 71 is normal for Syria, and you can hardly argue that no Syrian can be regarded as a moral actor. The argument seems to have carried the day, and the Syrian man will face a normal sentence.</p><p><strong>23: </strong>I&#8217;ve enjoyed following <a href=\"https://www.youtube.com/watch?v=cPu3SecmgUU\">content by Anthropic AI researcher Sholto Douglas</a>, but kept noticing his name in unusual places. Upon further investigation, it looks like <a href=\"https://en.wikipedia.org/wiki/Sholto_Douglas\">in 767 AD</a>, a particularly skilled Scottish warrior got the nickname &#8220;Sholto Douglas&#8221;, and for the next 1300 years his clan continued to give that name to their children. Aside from the AI researcher, they include <a href=\"https://en.wikipedia.org/wiki/Sholto_Douglas,_1st_Baron_Douglas_of_Kirtleside\">WWII air force commander Sholto Douglas</a>, <a href=\"https://en.wikipedia.org/wiki/Sholto_Johnstone_Douglas\">artist Sholto Douglas</a>, and <a href=\"https://en.wikipedia.org/wiki/Sholto_Douglas,_19th_Earl_of_Morton\">Svalbard mining baron Sholto Douglas</a>. There is also some sort of Californian Gold Rush country <a href=\"https://lordsholtodouglas.com/\">local folk hero Sholto Douglas</a>; attempts to determine his exact identity have been confounded by the local tradition of making up facts about him, but he may be the same person as <a href=\"https://www.douglashistory.co.uk/history/sholto_george_douglas.html\">Lord Sholto George Douglas</a>, third son of the Marquis of Queensberry. Even <a href=\"https://www.astralcodexten.com/p/secrets-of-the-great-families\">I</a> have trouble believing that the gene for being a particularly skilled warrior can last 1300 years, but for what it&#8217;s worth, the AI researcher Sholto Douglas <a href=\"https://www.linkedin.com/in/sholto\">was once ranked the 43rd best fencer in the world</a>.</p><p><strong>24: </strong>Chinese author and &#8220;Shakespeare superfan&#8221; Zhang Yiyi <a href=\"http://www.china.org.cn/china/2015-04/02/content_35227791.htm\">spent $225,000 on plastic surgery to look like Shakespeare</a>:</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!sMaY!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa0253163-a8a7-4f27-8d3b-e0581e2c7c0d_934x619.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"364.5074946466809\" src=\"https://substackcdn.com/image/fetch/$s_!sMaY!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa0253163-a8a7-4f27-8d3b-e0581e2c7c0d_934x619.png\" title=\"\" width=\"550\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a></figure></div><p>&#8230;and ended up looking more like Michael Jackson, or maybe a better way to think about it is that anyone who gets too much plastic surgery looks like everyone else who gets too much plastic surgery. Possibly related: <a href=\"https://en.wikipedia.org/wiki/Zhang_Yiyi_(author)\">his Wikipedia page</a> says he &#8220;is famous for his hyping talent&#8221; and &#8220;had once been selected as top 10 fools in China&#8221;. And he got me writing about him, which no other Chinese author has gotten this month, so, well-played, I guess.</p><p><strong>25: </strong>IVG advance: for the first time, <a href=\"https://www.bbc.com/news/articles/c4g2vyee0zlo\">scientists have successfully turned a skin cell into an egg cell</a>, although it &#8220;is not ready to be fertilised by sperm as it already contains a full suite of chromosomes&#8221; and &#8220;the method requires significant refinement - which could take a decade - before a fertility clinic could even consider using it&#8221;. Congratulations to the ACX community members involved in this research.</p><p><strong>26: </strong><a href=\"https://www.richardhanania.com/p/fatima-and-the-sample-size-compensation\">Richard Hanania responds to my post on Fatima</a>. He argues that if there&#8217;s some consistent bias that makes people imagine miracles, then the number of witnesses is unimpressive - much as you can&#8217;t rescue a biased polling methodology by increasing the sample from 1,000 to 10,000 people. I respond <a href=\"https://www.richardhanania.com/p/fatima-and-the-sample-size-compensation/comment/171010106\">here</a>. Richard seems to think that a certain type of less-than-fully-modern religious person - even when well-educated - can have a weird enough mental structure to hallucinate basically anything if it&#8217;s congruent with their religion. I agree that we have to posit something like this to save a non-miraculous account of Fatima; I only want people to understand how extreme an ask this is. Suppose that 10,000 eyewitnesses say they saw Richard stab someone in broad daylight. Can the defense argue &#8220;Well, people often hallucinate, and most of the witnesses were liberal, and the liberal worldview makes it attractive to imagine a right-wing blogger stabbing people, so who knows if he did it or not?&#8221; Usually we bound the power of mass hallucination at some level much lower than this! (EDIT: <a href=\"https://www.astralcodexten.com/p/links-for-october-2025/comment/171713610\">Hanania responds here</a>)</p><p><strong>27: </strong>Also Fatima-related: in the comments highlights post, I linked FLWAB&#8217;s <a href=\"https://flyinglionwithabook.substack.com/p/humes-argument-against-miracles-is\">criticism of David Hume&#8217;s argument against ever believing miracles.</a> Joe James argues that FLWAB, myself, and other critics <a href=\"https://www.constructiveskepticism.com/p/the-internet-is-wrong-about-david\">are misunderstanding Hume&#8217;s argument</a>. FLWAB says <a href=\"https://flyinglionwithabook.substack.com/p/we-understand-hume-fine-hes-just/comment/170838250\">no he isn&#8217;t</a>. They continue the discussion <a href=\"https://flyinglionwithabook.substack.com/p/we-understand-hume-fine-hes-just/comment/170838250\">in the comments</a>, but neither comes off looking great, and they don&#8217;t get anywhere. I&#8217;m unfortunately still confused - there are many cases where something that never happened before happens for the first time. For example, nobody had ever seen a grizzly-polar bear hybrid until recently, so &#8220;the universal testimony of mankind&#8221; was that this didn&#8217;t happen. But when a reliable person did see it, we had little trouble imagining that we were wrong and it was simply very rare, or a new thing happening now because of climate change. If nobody has ever seen a sea part before, but then many people say they saw Moses part the Red Sea, what is different about this such that &#8220;the universal testimony of mankind&#8221; suddenly becomes a disqualifier? Hume seems to be trying to make this same distinction in his <a href=\"https://www.constructiveskepticism.com/i/177175529/plausible-vs-implausible-improbable-accounts\">eight days of darkness example</a>, but there it seems like he is only saying he will accept non-religious anomalies, but rule out religious ones, because religious people often lie. But then what happened to the &#8220;universal testimony of mankind&#8221; argument? I kind of get the impression that he&#8217;s groping towards Bayes&#8217; Theorem, but hard-coding in a belief that the prior probability of lots of religious people lying is higher than the probability of a miracle. If that&#8217;s his belief, then fair enough, but I guess I expected the much-vaunted Hume&#8217;s Argument Against Miracles to be something more than this.</p><p><strong>28: </strong>Arguably related: <a href=\"https://www.theargumentmag.com/p/illiteracy-is-a-policy-choice\">Kelsey Piper on the &#8220;Mississippi Miracle&#8221;</a>, where a new education policy (phonics, accountability, end to social promotion) helped the state go from 49th in the nation to 9th in the nation over twelve years. Freddie deBoer argues that <a href=\"https://freddiedeboer.substack.com/p/there-are-no-miracles-in-education\">educational miracles are always fake and this one will end out being fake too</a>. Dave Deek <a href=\"https://www.governance.fyi/p/the-mississippi-miracle-doesnt-scale\">makes a subtler point</a> - although some educational miracles are real, they&#8217;re usually the product of extremely good leaders who ace tricky implementation details, and so attempts to scale them, which usually just copy the headline policies, don&#8217;t work. And Natalie Wexler <a href=\"https://nataliewexler.substack.com/p/whats-really-behind-the-southern\">argues that gains from phonics tend to fade out by middle school</a>, although some of the other Mississippi reforms might last longer. Kelsey pushes back and <a href=\"https://x.com/KelseyTuoc/status/1975570252600877133\">defends the Mississippi strategy here</a>.</p><p><strong>29: </strong>More <a href=\"https://www.astralcodexten.com/p/secrets-of-the-great-families\">great family</a> lore: <a href=\"https://en.wikipedia.org/wiki/Bach_family\">JS Bach had twenty children</a>, of whom five were sons who survived to adulthood; four of those five became notable composers themselves. His bloodline was originally believed to have died out, but was later traced through an illegitimate child to a surviving lineage in Oklahoma.</p><p><strong>30: </strong>Although research continues to challenge the measurable positive effects of cash transfers (eg basic income) in First World countries, even more studies are coming out showing positive effects in developing ones, including <a href=\"https://www.givedirectly.org/mortality2025/\">this one showing a 48% decline in infant mortality</a>.</p><p><strong>31: </strong>Is China no longer on track to outpace US GDP?</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!wxwv!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5b30f376-8bf6-400b-a26d-92d4bcef5cea_802x649.webp\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"464.49625935162095\" src=\"https://substackcdn.com/image/fetch/$s_!wxwv!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5b30f376-8bf6-400b-a26d-92d4bcef5cea_802x649.webp\" title=\"\" width=\"574\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a></figure></div><p>Noahpinion looks into this <a href=\"https://www.noahpinion.blog/p/how-do-we-measure-whether-chinas?utm_source=post-email-title&amp;publication_id=35345&amp;post_id=154122842&amp;utm_campaign=email-post-title&amp;isFreemail=true&amp;r=16489f&amp;triedRedirect=true&amp;utm_medium=email\">here</a> and says this is true by market value GDP, but false by purchasing-power-parity GDP; ie China&#8217;s production advantage is as strong as ever, but the yuan has gone down. There is no one right answer to the question of whether market value or PPP GDP is more meaningful, but since China manages the price of the yuan, they could bring it back up again whenever they wanted.</p><p><strong>32: </strong><a href=\"https://en.wikipedia.org/wiki/Names_of_Soviet_origin\">Wikipedia: Names Of Soviet Origin</a>. After the Communist Revolution, the Soviets wanted to replace the old set of religious/nationalist names. They didn&#8217;t do a very good job: &#8220;<strong>Mels</strong> - acronym for Marx, Engels, Lenin, Stalin&#8221;, &#8220;<strong>Vilen</strong> - short for Vladimir Ilyich Lenin&#8221;. Though some were slightly more creative: &#8220;<strong>Gertruda </strong>- &#8216;Gertrude&#8217; reimagined as being short for <em>geroy truda</em>, &#8216;hero of labor&#8217;&#8221;</p><p><strong>33: </strong>For the past several years, the Slime Mold Time Mold blog has been arguing that rising obesity rates cannot be a simple matter of changing diets, <a href=\"https://slimemoldtimemold.com/2024/07/27/lithium-hypothesis-of-obesity-recap/\">and must be due to some chemical contaminant, plausible lithium</a>. In 2022, Natalia Mendonca <a href=\"https://www.lesswrong.com/posts/7iAABhWpcGeP5e6SB/it-s-probably-not-lithium\">wrote a long and exhaustively-researched takedown of the hypothesis</a>. Since then, I have been hoping the Slime Mold Time Mold team would respond to Natalia; after pestering them on Twitter, they have <a href=\"https://slimemoldtimemold.com/2025/10/02/lithium-yay/\">kindly written a response to at least my summary of Natalia&#8217;s argument</a>. And <a href=\"https://www.lesswrong.com/posts/LzyeuGFLPRpPEuodp/natalia-s-shortform?commentId=GB7qtAmCYEq7EiKbB\">Natalia responds to their response here</a>, including an extra point challenging whether lithium levels have really risen over the timeframe being discussed.</p><p><strong>34: </strong>How does ChatGPT score on a Big 5 personality test? <a href=\"https://x.com/AiDigest_/status/1978875508923289870\">Answer (rot13d)</a>: vg qvfpbirerq gung vg pbhyq pbzcyrgr gur grfg snfgrfg ol cbfgvat n HEY jvgu gur ahzore guerr 181 gvzrf va fhpprffvba, naq qvq guvf, trggvat na rknpgyl arhgeny fpber. V ybir guvf nf n zrgncube: bhgre nyvtazrag vf vzntvavat gung lbhe tbny vf gb tvir gur NV &#8220;gur evtug crefbanyvgl&#8221;; vaare nyvtazrag vf ernpuvat gur cbvag jurer vg jvyy gnxr gur grfg ng nyy.</p><p><strong>35: </strong><a href=\"https://preservinghope.substack.com/p/is-terminal-lucidity-real\">Is terminal lucidity real?</a></p><p><strong>36: </strong><a href=\"https://www.medrxiv.org/content/10.1101/2025.09.09.25335237v1\">Wang, Visscher, et al</a> is a step up in studying the genetics of racial differences. It looks at a sample of Mexican families of mixed white-native heritage. By coincidence, some of their children will inherit more genes from the white side, and others more genes from the native side. These children will have identical social situations (since they&#8217;re from the same families) but different proportional ancestry, so we should expect any racial differences among them to come from the genetic rather than the social aspect of race (except that we can&#8217;t rule out &#8220;colorism&#8221;, ie genes making people look different and then causing discrimination). The paper finds that racial genetic differences directly affect height, diabetes risk, and other medical traits, but <em>not</em> educational attainment. <a href=\"https://x.com/AlexTISYoung/status/1966151190468821332\">Twitter discussion here</a>. Cremieux <a href=\"https://x.com/cremieuxrecueil/status/1966156734680150379\">argues here</a> that genes don&#8217;t predict educational attainment in developing countries at all, so it&#8217;s unsurprising that the particular genes associated with race wouldn&#8217;t do so, and so this says nothing about the racial component of traits that are genetically heritable. He claims to have <a href=\"https://x.com/cremieuxrecueil/status/1967732760862396668\">a version of the same analysis with UK whites vs. blacks </a>that gets opposite results. Sasha Gusev critiques Cremieux&#8217;s analysis <a href=\"https://x.com/SashaGusevPosts/status/1968671431387951148\">here</a>, including pointing out that it fails to find racial differences in skin color to be genetic. Cremieux says that skin color is determined by such a small number of genes that this method, designed for truly polygenic traits, shouldn&#8217;t be expected to classify it properly.</p><p><strong>37: </strong><a href=\"https://x.com/deredleritt3r/status/1968449641797538193\">Biologists get AI to design new bacteriophages (anti-bacteria viruses)</a>. Several of them work and successfully kill bacteria. I don&#8217;t want any anti-AI-safety people ever telling me again that we&#8217;re being ridiculous and that nobody would ever let an AI create viruses in real life.</p><p><strong>38: </strong>Eliezer and Nate&#8217;s book <em><a href=\"https://www.amazon.com/Anyone-Builds-Everyone-Dies-Superhuman/dp/0316595640\">If Anyone Builds It, Everyone Dies</a></em> is now out and is <a href=\"https://en.wikipedia.org/wiki/If_Anyone_Builds_It\">an NYT bestseller</a>. Authors&#8217; <em>Atlantic</em> article <a href=\"https://www.theatlantic.com/technology/2025/09/if-anyone-builds-it-excerpt/684213/\">here </a>(paywalled). Online resources/FAQ/answers to objections <a href=\"https://ifanyonebuildsit.com/resources\">here</a>. My review <a href=\"https://www.astralcodexten.com/p/book-review-if-anyone-builds-it-everyone\">here</a>. Peter Wildeford&#8217;s review <a href=\"https://peterwildeford.substack.com/p/if-we-build-ai-superintelligence\">here</a>. Mostly negative <em>Asterisk</em> review <a href=\"https://asteriskmag.com/issues/11/iabied\">here</a>, criticisms/arguments about the <em>Asterisk</em> review <a href=\"https://www.lesswrong.com/posts/JWH63Aed3TA2cTFMt/contra-collier-on-iabied\">here</a>, Eliezer&#8217;s response to this line of criticism <a href=\"https://x.com/ESYudkowsky/status/1968414865019834449\">here (X)</a>. I thought all the reviews, positive and negative, had something useful to say - except the NYT review, which <a href=\"https://x.com/sjgadler/status/1968056733122826607\">was remarkably bad</a> (Steven Adler points out that it accuses the book of failing to define the term &#8220;superintelligence&#8221;, but it very explicitly does that on page 4). I read Literary Substack sometimes, and I am so confused - it seems like there&#8217;s this entire ecosystem of Ivy graduates who spend years backstabbing each other in order to win the one bigshot publication book reviewer slot, and then the 1/1000 who reach this exalted position phone it in and don&#8217;t even read the books they&#8217;re reviewing.</p><p><strong>39: </strong>Sam Rosen (coi notice: personal friend) <a href=\"https://samrosen.art/\">has good AI art</a>:</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!2pVS!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F58604a3e-12a7-4a66-87e4-7ad3411e3ec7_1100x1100.webp\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"450\" src=\"https://substackcdn.com/image/fetch/$s_!2pVS!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F58604a3e-12a7-4a66-87e4-7ad3411e3ec7_1100x1100.webp\" width=\"450\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a></figure></div><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!VWms!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc86fb145-9f02-48cf-a712-9ccb7ed70448_1100x1100.webp\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"454\" src=\"https://substackcdn.com/image/fetch/$s_!VWms!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc86fb145-9f02-48cf-a712-9ccb7ed70448_1100x1100.webp\" width=\"454\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a></figure></div><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!KASl!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb7f3d5e9-8d77-405d-9b67-81a60e4e1edd_1100x1100.webp\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"460\" src=\"https://substackcdn.com/image/fetch/$s_!KASl!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb7f3d5e9-8d77-405d-9b67-81a60e4e1edd_1100x1100.webp\" width=\"460\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a></figure></div><p><strong>40: </strong><a href=\"https://www.hyperdimensional.co/p/be-it-enacted\">Dean Ball proposes an AI pre-emption deal.</a> Congressional Republicans worry that if all fifty states pass different AI bills, then there will be so many regulations that it&#8217;s near-impossible for AI companies to follow them all. They and Dean (a former White House policy advisor) have proposed <em>federal preemption</em>, where Congress bans states from regulating the industry and instead regulates it directly from DC.  Ted Cruz tried to pass an AI preemption bill in June. But many people suspected that Congress would ban states from regulating AI, not regulate AI itself, and leave the field totally unregulated - so a combination of pro-regulation Democrats and anti-big-tech Republicans defeated the bill. If the pre-emptionists try again, their strategy will be to peel off some groups with pet issues from the anti-preemption coalition, promising them concessions (either that Congress will take their pet issue seriously, or that they&#8217;ll carve out an exception to the preemption where states can still regulate on their pet issue) to cajole them into switching sides. AI safety is a plausible beneficiary of such bargaining, given that the Republicans&#8217; real enmity is towards other groups with more &#8220;woke&#8221; concerns. I think this is the context for Dean&#8217;s proposal - a potential draft of a preemption bill that tries to peel off AI safety people as a favored bargaining partner. And <a href=\"https://writing.antonleicht.me/p/a-preemption-deal-worth-making\">Anton Leicht argues that safetyists should take Dean&#8217;s preemption deal.</a> Miles Brundage <a href=\"https://x.com/Miles_Brundage/status/1976394064019988766\">says (X)</a> he &#8220;would like to see something non-trivially stronger, esp. around third-party auditing...but think his basic line of thinking is good.&#8221;</p><p><strong>41: </strong>Related: NVIDIA is emerging as a new villain in US tech policy; they <em>really</em> want to be allowed to sell advanced technology to China, and are swinging their weight as World&#8217;s Largest Company to undermine anyone who who raises national security objections. David Cowan makes the case here: <a href=\"https://www.compactmag.com/article/nvidia-is-a-national-security-risk/\">NVIDIA Is A National Security Risk</a>. Steven Adler goes further, <a href=\"https://stevenadler.substack.com/p/the-45-trillion-dollar-elephant-in?r=4qacg&amp;utm_campaign=twitter_second_post&amp;utm_medium=web&amp;triedRedirect=true\">saying </a>there is &#8220;widespread fear&#8221; among think tank researchers who publish work against NVIDIA&#8217;s interests. You would think that whatever the disadvantages of having an super-nationalist America First administration in power, at least they would be strongly against <a href=\"https://x.com/KhanSaifM/status/1982859134530937049\">handing key military tech to rivals</a> - but it&#8217;s not clear which way this will end up going.</p><p><strong>42: </strong><a href=\"https://archive.is/Ie0MZ\">NYT profile of a person with a genetic condition that invariably causes Alzheimers, who mysteriously nevertheless has not gotten Alzheimers</a>, and what we can learn from him. I was happy to see that everything in here makes sense in the context of <a href=\"https://www.astralcodexten.com/p/in-defense-of-the-amyloid-hypothesis\">David Schneider-Joseph&#8217;s piece on amyloid that I republished last month</a>. But also, it mentioned that his resistance might be caused by &#8220;an excess of heat shock proteins, which help keep other proteins from folding incorrectly&#8221;. This made me wonder - you get heat shock proteins by being shocked by heat. Could deliberate heat shocks reduce Alzheimer&#8217;s risk? I was able to find <a href=\"https://www.alzdiscovery.org/cognitive-vitality/blog/can-using-the-sauna-reduce-risk-for-alzheimers-disease\">an observational study</a> showing that daily sauna use reduces dementia risk 66% (mere weekly use doesn&#8217;t cut it, sorry). Can we trust these observations? I also looked to see if Finland - where people use saunas much more than in any other country - had a lower dementia rate; unfortunately, it&#8217;s <a href=\"https://pubmed.ncbi.nlm.nih.gov/28687259/\">actually the highest in the world</a>. Nobody really knows why, with theories ranging from levels of toxic mold (implausible) to coding differences (it&#8217;s always this one). Absent any other idea for how to confirm the sauna findings, I consider them suggestive only.</p><p><strong>43: </strong>Related: most people have the varicella zoster herpesvirus (aka chickenpox virus) latent in their bodies. Occasionally it reactivates in old people with bad immune systems and causes a rash called shingles, so old people are recommended to get the shingles vaccine. <a href=\"https://www.nature.com/articles/s41591-025-03972-5.pdf\">A new study shows that</a> herpesvirus reactivation may be involved in dementia, and that the shingles vaccine significantly decreases dementia risk while in effect (~5 years). Celebrity epidemiologist Eric Feigl-Ding <a href=\"https://x.com/DrEricDing/status/1978086965657366533\">suggests</a> that young people try getting the shingles vaccine for dementia prevention even if they don&#8217;t need it for shingles, but the exact pathway (and whether it helps preemptively) is not clear, and I think this is still a minority opinion. <a href=\"https://chatgpt.com/share/68fe487b-f5d8-8001-8eca-3bac211d8cb7\">Here is ChatGPT&#8217;s assessment</a>.</p><p><strong>44: </strong>OpenAI&#8217;s statistics on what people use ChatGPT for (<a href=\"https://x.com/basicprompts/status/1967631474775167412/photo/1\">source on X</a>):</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!rlBJ!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd5bbd862-b8d0-4a20-8e02-ab561e6fc95c_1274x804.jpeg\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"436.70957613814755\" src=\"https://substackcdn.com/image/fetch/$s_!rlBJ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd5bbd862-b8d0-4a20-8e02-ab561e6fc95c_1274x804.jpeg\" title=\"\" width=\"692\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a></figure></div><p><strong>45: </strong><a href=\"https://80000hours.org/podcast/episodes/andrew-snyder-beattie-four-pillars-biosecurity-pandemic/\">Andrew Snyder-Beattie on the latest advances in biodefense</a>. Without having fully resolved the debate over the real-world utility of COVID-era masks and N95s, the next generation of masks - elastomeric respirators - seem significantly more effective, including for people not specially trained in wearing them. Also, propylene glycol vapor - ie the fog in fog machines - kills all germs. Having indoor spaces constantly enveloped in fog is a weird ask, but we might find ways to make it work for crucial infrastructure during a pandemic, and &#8220;the US already produces enough to cover all industrial and much residential floorspace.&#8221; More things I didn&#8217;t know: &#8220;In a worst-case scenario where all crops die instantly, the US has enough stockpiled food (including animal feed) to last at least 18 months.&#8221;</p><p><strong>46: </strong>Anthropic has put out <a href=\"https://www.anthropic.com/research/introspection\">a great new survey of the evidence that AIs can introspect</a>. Ends with a discussion of the difference between &#8220;access consciousness&#8221; and &#8220;phenomenal consciousness&#8221;-  a lot of people are very sloppy in confusing those two things, and they had better become less sloppy if they don&#8217;t want the AI consciousness debate to end in a trivial yes (Anthropic says this result may not be exactly the same as access consciousness, but I don&#8217;t understand why). One of this year&#8217;s ACX grantees is working on AI introspection, so I look forward to seeing more in this space soon.</p><p><strong>47 </strong>Last links post, I linked a claim that the &#8220;child penalty&#8221; to mothers&#8217; earnings was primarily a &#8220;daughter penalty&#8221;, since mothers spent more time with daughters (and fathers with sons). @Scientific_Bird on Twitter investigates and <a href=\"https://x.com/Scientific_Bird/status/1951821323241492972\">finds this is most likely false</a>.</p><p><strong>48: </strong>In the ongoing survey of AI progress I wrote about <a href=\"https://asteriskmag.com/issues/03/through-a-glass-darkly\">here</a>, two tasks kept confounding forecasters: no matter how good AI gets at writing, math, chess, Go, or any other hard thing, it still can&#8217;t play Angry Birds or fold laundry. Year after year, forecasters predict that they can&#8217;t know exactly how AI will progress, but they are sure it will solve laundry folding before it solves protein folding. Year after year, they are wrong. Now one team claims that <a href=\"https://www.youtube.com/watch?v=HOoRnv3lA0k\">the laundry barrier has finally fallen</a>.</p><div class=\"youtube-wrap\" id=\"youtube2-HOoRnv3lA0k\"><div class=\"youtube-inner\"></div></div><p><strong>49: </strong><a href=\"https://x.com/RuxandraTeslo/status/1955540351844024415\">Ruxandra Teslo (X)</a>: &#8220;Why doesn&#8217;t the FDA just release regulatory filings? Why do we need a fund that owns them? The answer: trade secret law. A 2019 Supreme Court ruling in a trade secret case made FDA transparency even harder and a perplexing 2024 lawsuit against FDA highlights this.&#8221;</p><p><strong>50: </strong>Tomas Pueyo with a new theory for why cold/temperate countries are rich and warm countries are poor - <a href=\"https://unchartedterritories.tomaspueyo.com/p/mountains\">it&#8217;s the mountains</a>. Warm-climate agriculture and civilization cluster in highlands regions, where transportation and trade are harder. Partially paywalled comment responses <a href=\"https://unchartedterritories.tomaspueyo.com/p/comments-on-warm-countries-poverty-and-mountains\">1</a> and <a href=\"https://unchartedterritories.tomaspueyo.com/p/final-comments-on-the-theory-of-mountains\">2</a>. I find this very interesting, and far more thoughtful than most attempts at this question, but I&#8217;m pretty concerned about his answer <a href=\"https://unchartedterritories.tomaspueyo.com/p/comments-on-warm-countries-poverty-and-mountains\">here</a> to the objection that India, Cambodia, etc birthed great empires while being hot and nonmountainous. He says that they may have had high GDP, but always had low GDP per capita, which he pinpoints as the real measure of wealth. My impression is that pre-Industrial Revolution, all countries had low GDP per capita, because they were in a Malthusian regime where economic improvement translated to population density rather than increasing per capita GDP. Any differences between regions reflected minor fluctuations in the exact parameters of their Malthusianism and were not of any broader significance. So I think the India etc objection still stands and is pretty strong.</p><p><strong>51: </strong>Silicon Valley sperm donor search startup called - of course - <a href=\"https://x.com/GigiBrett/status/1975961405380780093\">PreSeed</a>.</p><p></p><p></p>"
            ],
            "link": "https://www.astralcodexten.com/p/links-for-october-2025",
            "publishedAt": "2025-10-30",
            "source": "SlateStarCodex",
            "summary": "<p><em>[I haven&#8217;t independently verified each link. On average, commenters will end up spotting evidence that around two or three of the links in each links post are wrong or misleading. I correct these as I see them, and will highlight important corrections later, but I can&#8217;t guarantee I will have caught them all by the time you read this.]</em></p><p><strong>1: </strong>In 1876, a woman named <a href=\"https://en.wikipedia.org/wiki/Mary_Tyler\">Mary Tyler</a> claimed to be the Mary of &#8220;Mary Had A Little Lamb&#8221;. Her story is plausible - she was a schoolchild in Sterling Massachussetts in the 1810s, and the author of the song was a schoolteacher in Sterling in the 1810s - but some key details don&#8217;t line up (she remembers her pet lamb being observed by a man, but the author was a woman). After she became famous, she &#8220;helped save the Old South Meeting House in Boston by selling fleece from her pet lamb as attachments on autograph cards&#8221;.</p><p><strong>2: </strong><a href=\"https://substack.com/@jurgengravestein1/note/c-168345617\">Prediction by Jurgen Gravestein</a>: &#8220;I don&#8217;t think people realize what kind of ads are coming. If the Sora app has your face, you will in the near future see ads of yourself wearing clothes of a certain brand.&#8221;</p><p><strong>3: </strong><a href=\"https://www.lesswrong.com/posts/6ZnznCaTcbGYsCmqu/the-rise-of-parasitic-ai\">The Rise Of",
            "title": "Links For October 2025"
        },
        {
            "content": [
                "Sometimes the best you can do is try to avoid things getting even worse even faster.\n\nThus, one has to write articles such as \u2018<a href=\"https://thezvi.substack.com/p/please-do-not-sell-b30a-chips-to\"><strong>Please Do Not Sell B30A Chips to China.\u2019</strong></a>\n\nIt\u2019s rather crazy to think that one would have to say this out loud.\n\nIn the same way, it seems not only do we need to say out loud to <a href=\"https://thezvi.substack.com/p/new-statement-calls-for-not-building\"><strong>Not Build Superintelligence Right Now</strong></a>, there are those who say how dare you issue such a statement without knowing how to do so safety, so instead we should build superintelligence without knowing how to do so safety. The alternative is to risk societal dynamics we do not know how to control and that could have big unintended consequences, you say? Yes, well.\n<div> <span id=\"more-24824\"></span> </div>\nOne good thing to come out of that was that <a href=\"https://thezvi.substack.com/p/asking-some-of-the-right-questions\"><strong>Sriram Krishnan asked (some of) the right questions,</strong></a> giving us the opportunity to try and answer.\n\nI also provided updates on <a href=\"https://thezvi.substack.com/p/ai-craziness-mitigation-efforts\"><strong>AI Craziness Mitigation Efforts</strong></a> from OpenAI and Anthropic. We can all do better here.\n\nTomorrow, I\u2019ll go over OpenAI\u2019s \u2018recapitalization\u2019 and reorganization, also known as one of the greatest thefts in human history. Compared to what we feared, it looks like we did relatively well on control rights, but the equity stake is far below fair and all of this is far worse than the previous state. You could call that a \u2018win\u2019 in the sense that things could have gone far worse. That\u2019s 2025.\n\nThe releases keep coming. We have Cursor 2.0 including their own LLM called Composer. We have Neo the humanoid household (for now teleoperated) robot. We have the first version of \u2018Grokopedia.\u2019 We get WorldTest and ControlArena and more.\n\nAnthropic may finally have the compute it needs thanks to one million TPUs, while OpenAI may be planning an IPO at a valuation of $1 trillion.\n\n\n<h4 class=\"wp-block-heading\">Table of Contents</h4>\n\n<ol>\n \t<li><a href=\"https://thezvi.substack.com/i/176946054/language-models-offer-mundane-utility\">Language Models Offer Mundane Utility.</a> The joys of freedom of AI speech.</li>\n \t<li><a href=\"https://thezvi.substack.com/i/176946054/language-models-don-t-offer-mundane-utility\">Language Models Don\u2019t Offer Mundane Utility.</a> Mistakes are made.</li>\n \t<li><a href=\"https://thezvi.substack.com/i/176946054/huh-upgrades\"><strong>Huh, Upgrades</strong>.</a> Claude memory, Cursor 2.0, Claude for Finance, Pulse on web.</li>\n \t<li><a href=\"https://thezvi.substack.com/i/176946054/on-your-marks\">On Your Marks.</a> AIs disappoint on WorldTest, usual suspects declare victory.</li>\n \t<li><a href=\"https://thezvi.substack.com/i/176946054/choose-your-fighter\">Choose Your Fighter.</a> A tale of two business plans.</li>\n \t<li><a href=\"https://thezvi.substack.com/i/176946054/get-my-agent-on-the-line\">Get My Agent On The Line.</a> The promise of the Coasean singularity.</li>\n \t<li><a href=\"https://thezvi.substack.com/i/176946054/deepfaketown-and-botpocalypse-soon\">Deepfaketown and Botpocalypse Soon.</a> OpenAI erotica, third Grok companion.</li>\n \t<li><a href=\"https://thezvi.substack.com/i/176946054/fun-with-media-generation\">Fun With Media Generation.</a> Suno is getting good at making generic music.</li>\n \t<li><a href=\"https://thezvi.substack.com/i/176946054/copyright-confrontation\">Copyright Confrontation.</a> Perplexity keeps failing the honeypot tests.</li>\n \t<li><a href=\"https://thezvi.substack.com/i/176946054/they-took-our-jobs\">They Took Our Jobs.</a> My comparative advantage on display?</li>\n \t<li><a href=\"https://thezvi.substack.com/i/176946054/get-involved\">Get Involved.</a> METR is hiring.</li>\n \t<li><a href=\"https://thezvi.substack.com/i/176946054/introducing\">Introducing.</a> Grokopedia, ControlArena and the a16z torment nexus pipeline.</li>\n \t<li><a href=\"https://thezvi.substack.com/i/176946054/my-name-is-neo\">My Name is Neo.</a> Teleoperated robots coming to willing households soon.</li>\n \t<li><a href=\"https://thezvi.substack.com/i/176946054/in-other-ai-news\">In Other AI News.</a> Some very good charts.</li>\n \t<li><a href=\"https://thezvi.substack.com/i/176946054/show-me-the-money\">Show Me the Money.</a> One trillion dollars? OpenAI considers an IPO.</li>\n \t<li><a href=\"https://thezvi.substack.com/i/176946054/one-trillion-dollars-for-my-robot-army\">One Trillion Dollars For My Robot Army.</a> One trillion dollars? For Musk.</li>\n \t<li><a href=\"https://thezvi.substack.com/i/176946054/one-million-tpus\">One Million TPUs.</a> One million TPUs? For Anthropic.</li>\n \t<li><a href=\"https://thezvi.substack.com/i/176946054/anthropic-s-next-move\">Anthropic\u2019s Next Move.</a> Compute, in sufficient quantities, enables products.</li>\n \t<li><a href=\"https://thezvi.substack.com/i/176946054/quiet-speculations\"><strong>Quiet Speculations</strong>.</a> OpenAI aims for true automated researchers by March 2028.</li>\n \t<li><a href=\"https://thezvi.substack.com/i/176946054/the-quest-for-sane-regulations\">The Quest for Sane Regulations.</a> Microsoft endorses the GAIN Act.</li>\n \t<li><a href=\"https://thezvi.substack.com/i/176946054/the-march-of-california-regulations\">The March of California Regulations.</a> Dean Ball analyzes, I offer additional takes.</li>\n \t<li><a href=\"https://thezvi.substack.com/i/176946054/not-so-super-pac\">Not So Super PAC.</a> It seems the a16z-Lehane SuperPAC is not off to a great start.</li>\n \t<li><a href=\"https://thezvi.substack.com/i/176946054/chip-city\">Chip City.</a> A few additional notes.</li>\n \t<li><a href=\"https://thezvi.substack.com/i/176946054/the-week-in-audio\">The Week in Audio.</a> Yudkowsky, Bostrom and AI Welfare on Odd Lots.</li>\n \t<li><a href=\"https://thezvi.substack.com/i/176946054/do-not-take-the-bait\">Do Not Take The Bait.</a> Was it woke? No, it was sharing accounts.</li>\n \t<li><a href=\"https://thezvi.substack.com/i/176946054/rhetorical-innovation\">Rhetorical Innovation.</a> We are trained to think problems must be solvable.</li>\n \t<li><a href=\"https://thezvi.substack.com/i/176946054/people-do-not-like-ai\">People Do Not Like AI.</a> They express it in myriad ways. Some are direct.</li>\n \t<li><a href=\"https://thezvi.substack.com/i/176946054/aligning-a-smarter-than-human-intelligence-is-difficult\">Aligning a Smarter Than Human Intelligence is Difficult.</a> Let them cook?</li>\n \t<li><a href=\"https://thezvi.substack.com/i/176946054/misaligned\">Misaligned!</a> DeepSeek might choose to give you insecure code?</li>\n \t<li><a href=\"https://thezvi.substack.com/i/176946054/anthropic-reports-claude-can-introspect\">Anthropic Reports Claude Can Introspect.</a> Claude can notice thought injections.</li>\n \t<li><a href=\"https://thezvi.substack.com/i/176946054/anthropic-reports-on-sabotage-risks\">Anthropic Reports On Sabotage Risks.</a> A template for a new report type.</li>\n \t<li><a href=\"https://thezvi.substack.com/i/176946054/people-are-worried-about-ai-killing-everyone\">People Are Worried About AI Killing Everyone.</a> Hinton is more hopeful.</li>\n \t<li><a href=\"https://thezvi.substack.com/i/176946054/other-people-are-not-as-worried-about-ai-killing-everyone\">Other People Are Not As Worried About AI Killing Everyone.</a> Misrepresentation.</li>\n \t<li><a href=\"https://thezvi.substack.com/i/176946054/the-lighter-side\">The Lighter Side.</a> Begun, the sex warfare has?</li>\n</ol>\n\n<h4 class=\"wp-block-heading\">Language Models Offer Mundane Utility</h4>\n<a href=\"https://futurefreespeech.org/that-violates-my-policies-ai-laws-chatbots-and-the-future-of-expression/\">Where do AI models have freedom of speech?</a>\n\nThe good old United States of America, f*** yeah, that\u2019s where, says The Future of Free Speech. The report isn\u2019t perfect, if you look at the details it\u2019s not measuring exactly what you\u2019d want and pays too much attention to corporate statements and has too much focus on social media post generation, but it\u2019s what we have, and it will serve.\n\nOf the countries evaluated, next up was the European Union, which also performed strongly, although with worries about \u2018hate speech\u2019 style rules. The humans don\u2019t have such great free speech around those parts, in important ways, but the chatbots already censor all that anyway for corporate reasons. Brazil scores modestly lower, then a drop to South Korea, another to India and a huge one to China.\n<div>\n<figure>\n<div>\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!tY4M!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0aafefaa-0f31-490d-a351-4848701ab601_1639x784.png\" /></figure>\n\n<div></div>\n</div></figure>\n</div>\nAs always, this is another reminder that China imposes lots of restrictions on things, far more onerous than anything America has ever considered, including that it requires pre deployment testing, largely to verify its censorship protocols.\n\nAmong AI models, they have Grok on top, but not by a huge amount. All three top labs (Anthropic, Google and OpenAI) showed noticeable improvement over time. Mostly the contrast is American models, which range from 58%-65%, and Mistral from France at 46% (this again makes me suspicious of the EU\u2019s high score above), versus Chinese models much lower, with DeepSeek at 31.5% and Qwen at 22%. This is despite one of the main categories they were scored on being model openness, where DeepSeek gets full marks and the big labs get zeroes.\n<div>\n<figure>\n<div>\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!Rwsr!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F67038525-12f6-4ffb-a7aa-bb55a007aeed_1623x1046.png\" /></figure>\n\n<div></div>\n</div></figure>\n</div>\nNotice that even with openness of the model as an explicit criteria, the open models and their associated nations are evaluated as far less free than the closed models.\n\nAs always, if you believe \u2018any restrictions on AI mean China wins\u2019 then you have to reconcile this claim with China already being vastly more restrictive than anything being relevantly proposed. Consider open model issues similarly.\n\nWhat matters is experience in practice. My practical experience is that out of the big three, Sonnet 4.5 (or Opus/Sonnet 4 before it) and GPT-5 basically never censor or evade things they \u2018shouldn\u2019t\u2019 censor, whereas Gemini 2.5 totally does do it. The exception for Claude is when I\u2019m explicitly asking it about biological risk from AI, which can hit the biofilters by accident.\n\n<a href=\"https://x.com/PuckFupett69/status/1980959687672484307\">The thing about leaving all your stuff unsorted</a> and counting on search is that when it works it\u2019s great, and when it doesn\u2019t work it\u2019s really not great. That was true before AI, and it\u2019s also true now that AI can often do better search.\n<blockquote>Joe Weisenthal: yeah, sure, kinda true. But what\u2019s the point of \u201csorting\u201d anything digital. This is my point. In the world of the search bar (which keeps getting better and better) why group anything together at all?\n\nSt. Vincent: I have a lot of coworkers who spend a lot of time putting their emails in folders and I just search \u201c[client name] taxes\u201d in Outlook and it works fine</blockquote>\n<a href=\"https://x.com/ErnestRyu/status/1981977037276672040\">Ernest Ryu reports using ChatGPT to solve an open problem in convex optimization</a>.\n\n<a href=\"https://www.tomshardware.com/tech-industry/artificial-intelligence/grieving-family-uses-ai-chatbot-to-cut-hospital-bill-from-usd195-000-to-usd33-000-family-says-claude-highlighted-duplicative-charges-improper-coding-and-other-violations\">Use Claude to cut your hospital bill from $195k to $33k</a> by highlighting duplicative charges, improper coding and other violations. The two big barriers are (1) knowing you can do this and (2) getting hold of the itemized bill in the first place. One wonders, shouldn\u2019t there be bigger penalties when hospitals get caught doing this?\n\n<a href=\"https://x.com/moseskagan/status/1983872009818825086\">How long? Not long. Cause what you reap is what you sow</a>:\n<blockquote>Moses Kagan: Recently heard of a tenant buyout negotiation where both sides were just sending each other emails written by AI.\n\nHow soon until we all just cut out the middle-man, so to speak, and let the AIs negotiate with each other directly?</blockquote>\nI mean, in that context, sure, why not?\n\n\n<h4 class=\"wp-block-heading\">Language Models Don\u2019t Offer Mundane Utility</h4>\n<a href=\"https://x.com/colin_fraser/status/1981737356114722993\">Everyone makes mistakes oh yes they do</a>.\n<blockquote>Colin Fraser: The problem that we are going to run into more and more is even if the AI can tell a Doritos bag from a gun 99.999% of the time, if you run inference a million times a day you still expect 10 errors per day.\n\nDexerto: Armed officers held a student at gunpoint after an AI gun detection system mistakenly flagged a Doritos bag as a firearm \u201cThey made me get on my knees, put my hands behind my back, and cuff me\u201d</blockquote>\nPolice saying \u2018he\u2019s got a gun!\u2019 when the man in question does not have a gun is an event that happens every day, all the time, and the police are a lot less than 99.999% accurate on this. The question is not does your system make mistakes, or whether the mistakes look dumb when they happen. The question is does your system make more mistakes, or more costly mistakes, than you would get without the system.\n\n<a href=\"https://x.com/ichbinGisele/status/1981304731051184293\">Speaking of which, now do humans</a>, <a href=\"https://www.bbc.co.uk/mediacentre/2025/new-ebu-research-ai-assistants-news-content\">this is from the BBC</a>, <a href=\"https://www.bbc.co.uk/mediacentre/documents/news-integrity-in-ai-assistants-report.pdf\">full report here</a>. They tested ChatGPT, Copilot, Perplexity and Gemini in May-June 2025, so this is before GPT-5.\n<blockquote>BBC:\n<ol>\n \t<li>45% of AI answers had at least one significant issue</li>\n \t<li>31% of responses showed serious sourcing problems (missing, misleading, or incorrect)</li>\n \t<li>20% contained major accuracy issues, including hallucinated details and outdated information</li>\n \t<li>Gemini performed worst with significant issues in 76% of responses, more than double the other assistants, largely due to its poor sourcing performance.</li>\n \t<li>Comparison between the BBC\u2019s results earlier this year and this study show some improvements but still high levels of errors.</li>\n</ol>\nFull report: Overall, there are signs that the quality of assistant responses has improved \u2013 the share of responses with significant issues of any kind fell from 51% in the first round to 37% in the current round.</blockquote>\n<div>\n<figure>\n<div>\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!3yfm!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcaa0c780-13b3-41ce-a6e0-c463eee06b7b_1054x715.png\" /></figure>\n\n<div></div>\n</div></figure>\n</div>\n<div>\n<figure>\n<div>\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!vr49!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4e25d050-b448-428f-b0c9-1046e5f0f6fd_1051x278.png\" /></figure>\n\n<div></div>\n</div></figure>\n</div>\nThere is a clear pattern here. The questions on the right mostly have clear uncontroversial correct answers, and that correct answer doesn\u2019t have any conflict with standard media Shibboleths, and the answer hasn\u2019t changed recently. For the questions on the left, it gets trickier on all these fronts. To know exactly how bad these issues were, we\u2019d need to see the actual examples, which I don\u2019t see here.\n\n<a href=\"https://x.com/teortaxesTex/status/1982386237781712968\">I\u2019m fine with the outright never changing, actually</a>.\n<blockquote>Teortaxes: lmao. never change, Kimi (but please improve factuality)\n\nDavid Sun: I am completely unimpressed by LLMs and not worried about AGI.\n<div>\n<figure>\n<div>\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!wOOU!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d2df053-d37c-4d35-abc8-434344e12eb7_1199x516.jpeg\" /></figure>\n\n<div></div>\n</div></figure>\n</div></blockquote>\nIt is remarkable how many people see a dumb aspect of one particular LLM under default conditions, and then conclude that therefore AGI will never happen. Perhaps David is joking here, perhaps not, Poe\u2019s Law means one cannot tell, but the sentiment is common.\n\n<a href=\"https://x.com/OfficialLoganK/status/1982222911231377696\">On this next item, look, no</a>.\n<blockquote><a href=\"https://x.com/OfficialLoganK/status/1982222911231377696\">Logan Kilpatrick</a> (Lead for DeepMind AI Studio, RTed by Demis Hassabis): Everyone is going to be able to vibe code video games by the end of 2025.\n\nNot German: Vibe code very very bad video games.\n\nLogan Kilpatrick: games that most reasonable people would be excited to play with their friends because they have full control over the story, characters, experience</blockquote>\nEven if we use a rather narrow definition of \u2018everyone,\u2019 no just no. We are not two months away from people without experience being able to vibe code up games good enough that your friends will want to play them as more than a curiosity. As someone who has actually designed and created games, this is not that easy, and this kind of shallow customization doesn\u2019t offer that much if you don\u2019t put in the real work, and there are lots of fiddly bits.\n\nThere\u2019s no need to oversell AI coding like this. Is coding a game vastly easier, to the point where I\u2019m probably in the category of \u2018people who couldn\u2019t do it before on their own in a reasonable way and can do it now?\u2019 Yeah, quite possible, if I decided that\u2019s what I wanted to do with my week or month. Alas, I\u2019m kind of busy.\n\nAlternatively, he\u2019s making a hell of a claim about Gemini Pro 3.0. We shall see.\n\n\n<h4 class=\"wp-block-heading\">Huh, Upgrades</h4>\n<a href=\"https://x.com/SamuelAlbanie/status/1983558235920502980\">Sam Altman said the price of a unit of intelligence drops 97.5% per year (40x)</a>. If your objection to a business model is \u2018the AIs good enough to do this cost too much\u2019 your objection will soon be invalid.\n\nClaude now has memory, as per Tuesday\u2019s post.\n\n<a href=\"https://cursor.com/blog/2-0\">Cursor 2.0</a>, which includes their own coding model Composer and a new interface for working with multiple agents in parallel. They claim Composer is 4x faster than comparable top frontier models.\n<div>\n<figure>\n<div>\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!q6fZ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe68c7305-9623-4f9b-a2d9-d2d868480358_1920x1080.webp\" /></figure>\n\n<div></div>\n</div></figure>\n</div>\nThat is a terrible labeling of a graph. You don\u2019t get to not tell us which models the other rows are. Is the bottom one GPT-5? GPT-5-Codex? Sonnet 4.5?\n\nThe UI has been redesigned around ways to use multiple agents at once. They also offer plan mode in the background, you can internally plan with one model and then execute with another, <a href=\"https://cursor.com/changelog/2-0\">and several other upgrades</a>.\n\n<a href=\"https://x.com/elder_plinius/status/1983651580013637775\">The system instructions for Cursor 2.0\u2019s Composer are here</a>, <a href=\"https://x.com/elder_plinius/status/1983670493975871588\">Pliny\u2019s liberation jailbreak alert is here</a>.\n\n<a href=\"https://www.anthropic.com/news/advancing-claude-for-financial-services\">Claude for Financial Services expands</a>, offering a beta of <a href=\"https://claude.com/claude-for-excel\">Claude for Excel</a> and adding many sources of live information: Aiera, Third Bridge, Chronograph, Egnyte, LSEG, Moody\u2019s and MT Newswires. They are adding agent skills: Comparable company analysis, discounted cash flow models, due diligence data packs, company teasers and profiles, earnings analyses and initiating coverage reports.\n\n<a href=\"https://x.com/OpenAI/status/1981432799212249119\">ChatGPT offers Shared Projects</a> to all users. Good.\n\n<a href=\"https://x.com/OpenAI/status/1983576124514034032\">ChatGPT Pulse now available on the web</a>. This is a big jump in its practical value.\n\n<a href=\"https://x.com/GoogleAIStudio/status/1979576332825530522\">Google AI Studio now lets you create</a>, save and reuse system instructions across chats.\n\n<a href=\"https://x.com/joshwoodward/status/1981523588265185608\">Gemini app finally lets you switch models during a conversation</a>.\n\n<a href=\"https://x.com/adamhfry/status/1981206776503517229\">Intended short-term upgrade list for the ChatGPT Atlas browser</a>. Includes \u2018tab groups.\u2019 Did not include \u2018Windows version.\u2019\n\n<a href=\"https://x.com/SethBurn/status/1982473290355773875\">Why do people believe Elon Musk</a> when he says he\u2019s going to, for example, \u2018delete all heuristics\u2019 from Twitter\u2019s recommendation algorithm in favor of having Grok read all the Tweets?\n\n<a href=\"https://x.com/OpenAI/status/1983507392374641071\">OpenAI offers us GPT-OSS-Safeguard</a>, allowing developers to specify disallowed content.\n\n\n<h4 class=\"wp-block-heading\">On Your Marks</h4>\n<a href=\"https://x.com/alex_prompter/status/1983111213098906105\">AIs were outperformed by humans on the new WorldTest</a> <a href=\"https://arxiv.org/pdf/2510.19788\">via \u2018AutumnBench,</a>\u2019 a suite of 43 interactive worlds and 129 tasks calling for predicting hidden world aspects, planning sequences of actions and detecting when environment rules suddenly change.\n\nThis seems like an actually valuable result, which still of course came to my attention via a description you might have learned to expect by now:\n<blockquote>Alex Prompter: The takeaway is wild&#8230; current AIs don\u2019t understand environments; they pattern-match inside them. They don\u2019t explore strategically, revise beliefs, or run experiments like humans do. WorldTest might be the first benchmark that actually measures understanding, not memorization. The gap it reveals isn\u2019t small it\u2019s the next grand challenge in AI cognition.\n\nScaling compute barely closes the gap.\n\nHumans use resets and no-ops to test hypotheses. Models don\u2019t. They just spam clicks.</blockquote>\nThe core event here seems to be that there was a period of learning opportunity without reward signals, during which humans reset 12% of the time and models reset less than 2% of the time. Humans had a decent learning algorithm and designed useful experiments during exploration, models didn\u2019t.\n\nSo yeah, that\u2019s a weakness of current models. They\u2019re not good at relatively open-ended exploration and experimentation, at least not without good prompting and direction. They\u2019re also not strong on adapting to weirdness, since they (wisely, statistically speaking) rely on pattern matching, while lacking good instincts on when to \u2018snap out of\u2019 those matches.\n\n\n<h4 class=\"wp-block-heading\">Choose Your Fighter</h4>\nOpenAI is launching a browser and short duration video social network to try and capture consumers, monetizing them via shopping hookups and adding erotica.\n\n<a href=\"https://x.com/peterwildeford/status/1982562691165405639\">What is OpenAI\u2019s plan</a>?\n<ol>\n \t<li>Fund ASI by offering normal big tech company things to justify equity raises.</li>\n \t<li><s>?????????</s>. Build superintelligence in a way that everyone doesn\u2019t die, somehow.</li>\n \t<li><s>Everyone dies</s>. Profit, hopefully.</li>\n</ol>\n<blockquote><a href=\"https://x.com/nearcyan/status/1981867334542467560\">Near</a>: to clarify confusion, openai\u2019s competitor is meta (not anthropic), and anthropic\u2019s competitor is google (not openai).\n\nOpenAI is now set to transition to the 2nd phase of ChatGPT, focusing on advertising + engagement\n\nWith a team of ex-FB advertising execs and 1B users, if OpenAI can increase usage to a several hrs/day while matching Meta\u2019s ad targeting, they can profitably reach a 1T+ valuation\n\nfortunately openai employees have now had ample time to update their previous lines of thinking from \u201cwe arent an advertising company, i am here for the vision of AGI\u201d to \u201cactually advertising is good, especially when paired with short-form video and erotica. let me explain\u201d\n\ni give many venture capitalists credit here because to them the outcomes like this have been obvious for a long time. just look at the company and zoom out! what else could possibly happen! engineers and researchers on the other hand are often quite oblivious to such trends..\n\nanother important note here is that meta still has many cards left to play; i think it will actually be quite a brutal distribution competition even though openai has obviously had a headstart by like.. two full yrs. fidji is very good at monetization and sam is great at raising\n<div>\n<figure>\n<div>\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!aN4H!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F32dcab1f-639b-4df5-ace6-8babc0f25dd4_866x704.png\" /></figure>\n\n<div></div>\n</div></figure>\n</div>\nPeter Wildeford: OpenAI essentially has two modes as a business:\n<ol>\n \t<li>they might someday build AGI and then automate the entire economy</li>\n \t<li>\u2018Facebookization of AI\u2019 where we just build a normal Big Tech business off of monetizing billions of free users</li>\n</ol>\nSecond mode helps fund the first.\n\n<a href=\"https://x.com/aidan_mclau/status/1982177934954971407\">Aidan McLaughlin</a> (OpenAI): i think your error here is thinking sora and adult content are some leadership master plan; that sama sat down with accountants and signed and said \u201cit\u2019s time to break glass for emergence revenue\u201d no.\n\nI know the exact people who pushed for sora, they\u2019re artists who worked against organizational headwinds to democratize movie creation, something they love dearly. i know the exact person who pushed for adult content, they\u2019re a professional athlete, free-sprinted, one of the most socially thoughtful people i know\u2026 who just really believes in creative freedom.\n\nthere are passionate individual who pushed against all odds for what you think are top-down decisions. we are not a monoculture, and i love that.\n\nI think there are zero worlds where there\u2019s more money in \u2018going hard\u2019 at sora/erotica than there is automating all labor</blockquote>\nI believe Aidan on the proximate causes inside OpenAI pushing towards these decisions. They still wouldn\u2019t have happened if the conditions hadn\u2019t been set, if the culture hadn\u2019t been set up to welcome them.\n\nCertainly there\u2019s more money in automating all labor if you can actually automate all labor, but right now OpenAI cannot do this. Anything that raises valuations and captures market share and mindshare thus helps OpenAI progress towards both profitability and eventually building superintelligence and everyone probably dying. Which they pitch to us as the automation of all labor (and yes, they mean all labor).\n\n<a href=\"https://x.com/AnthropicAI/status/1982842911369965897\">Anthropic, on the other hand, is catering to business and upgrading financial services offerings</a> and developing a browser extension for Chrome.\n\nTwo ships, ultimately going to the same place (superintelligence), pass in the night.\n<blockquote>Stefan Schubert: Anthropic has overtaken OpenAI in enterprise large language model API market share.\n\n<a href=\"https://www.wsj.com/tech/ai/anthropic-business-model-ai-9e26b4ef?mod=panda_wsj_section_alert\">Asa Fitch (WSJ)</a>: But Anthropic\u2019s growth path is a lot easier to understand than OpenAI\u2019s. Corporate customers are devising a plethora of money-saving uses for AI in areas like coding, drafting legal documents and expediting billing. Those uses are likely to expand in the future and draw more customers to Anthropic, especially as the return on investment for them becomes easier to measure.</blockquote>\n<div>\n<figure>\n<div>\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!pGO3!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4e1cc13a-e3f8-4c54-beae-0c6aff9eb9fc_475x634.png\" /></figure>\n\n<div></div>\n</div></figure>\n</div>\n&nbsp;\n\n&nbsp;\n\nGrok can be useful in one of two ways. One is more competitive than the other.\n<blockquote><a href=\"https://x.com/Dorialexander/status/1982067788509290914\">Alexander Doria</a>: still failing to see the point of grok if it cannot go through my follow list and other X data.</blockquote>\nxAI has chosen to de facto kick the other AIs off of Twitter, which is a hostile move that trades off the good of the world and its knowledge and also the interests of Twitter in order to force people to use Grok.\n\nThen Grok doesn\u2019t do a good job parsing Twitter. Whoops. Please fix.\n\nThe other way to make Grok useful is to make a superior model. That\u2019s harder.\n\nClaude.ai has an amazing core product, but still needs someone to put in the (relatively and remarkably small, you\u2019d think?) amount of work to mimic various small features and improve the UI. They could have a very strong consumer product if they put a small percentage of their minds to it.\n\n<a href=\"https://x.com/omooretweets/status/1982565104542781564\">Another example</a>:\n<blockquote>Olivia Moore: With the introduction of Skills, it\u2019s especially odd that Claude doesn\u2019t have the ability to \u201ctime trigger\u201d tasks.\n\nI built the same workflow out on ChatGPT and Claude.\n\nClaude did a much better job, but since you can\u2019t set it to recur I\u2019m going to have to run it on ChatGPT\u2026</blockquote>\nThe obvious response is \u2018have Claude Code code something up\u2019 but a lot of people don\u2019t want to do that and a lot of tasks don\u2019t justify it.\n\n\n<h4 class=\"wp-block-heading\">Get My Agent On The Line</h4>\n<a href=\"https://marginalrevolution.com/marginalrevolution/2025/10/will-there-be-a-coasean-singularity.html?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=will-there-be-a-coasean-singularity\">Tyler Cowen asks \u2018will there be a Coasean singularity?</a>\u2019 in reference to<a href=\"https://www.nber.org/books-and-chapters/economics-transformative-ai/coasean-singularity-demand-supply-and-market-design-ai-agents\"> a new paper</a> by Peyman Shahidi, Gili Rusak, <a href=\"https://www.nber.org/people/bmanning\">Benjamin S. Manning</a>, <a href=\"https://www.nber.org/people/andrey_fradkin\">Andrey Fradkin</a> &amp; <a href=\"https://www.nber.org/people/john_horton\">John J. Horton</a>. AIs and AI agents promise to radically reduce various transaction costs for electronic markets, enabling new richer and more efficient market designs.\n\nMy classic question to ask in such situations: If this were the one and only impact of AI, that it radically reduces transaction costs especially in bespoke interactions with unique features, enabling far better market matching at much lower prices, then what does that effect alone do to GDP and GDP growth?\n\nI asked Claude to estimate this based on the paper plus comparisons to historical examples. Claude came back with wide uncertainty, with a baseline scenario of a one-time 12-18% boost over 15-25 years from this effect alone. That seems on the low side to me, but plausible.\n\n\n<h4 class=\"wp-block-heading\">Deepfaketown and Botpocalypse Soon</h4>\n<a href=\"https://x.com/JeffLadish/status/1981591135224307856\">Theo Jaffee and Jeffrey Ladish think the Grok effect on Twitter</a> has been good, actually? This has not been my experience, but in places where epistemics have gone sufficiently downhill perhaps it becomes a worthwhile tradeoff.\n\n<a href=\"https://x.com/elder_plinius/status/1981925153895514122\">Grok now has a third companion, a 24-year-old spirited woman named Mika</a>, the link goes to her system prompt. The good news is that she seems like a less unhealthy persona to be chatting to than Ani, thus clearing the lowest of bars. The bad news is this seems like an epic display of terrible prompt engineering of an intended second Manic Pixie Dream Girl, and by being less flagrantly obviously awful this one might actually be worse. Please avoid.\n\nSteven Adler, former head of product safety at OpenAI, <a href=\"https://www.nytimes.com/2025/10/28/opinion/openai-chatgpt-safety.html\">warns us in the New York Times not to trust OpenAI\u2019s claims about \u2018erotica.\u2019</a> I agree with him that we don\u2019t have reason to trust OpenAI to handle this (or anything else) responsibly, and that publishing changes in prevalence rates of various mental health and other issues over time and committing to what information it releases would build trust in this area, and be important info to learn.\n\n\n<h4 class=\"wp-block-heading\">Fun With Media Generation</h4>\nAI-generated music is getting remarkably good. A new study finds that songs from a mix of Suno versions (mostly in the v3 to v4 era, probably, but they don\u2019t say exactly?) was \u2018indistinguishable from human music,\u2019 meaning when asked to identify the human song between a Suno song and a random human song, <a href=\"https://x.com/wesrothmoney/status/1982416929353818436?s=61\">listeners were only 50/50 in general</a>, although they were 60/40 if both were the same genre. We\u2019re on Suno v5 now and reports are it\u2019s considerably better.\n\n<a href=\"https://x.com/AphanFX/status/1982480958164250756\">One commentor shares this AI song</a> they made, <a href=\"https://t.co/Wq0DJpALov\">another shares this one.</a> If you want generic music that \u2018counts as music\u2019 and requires attention to differentiate for the average person? We\u2019re basically there.\n<blockquote><a href=\"https://x.com/BitsByNick/status/1982475058774991335\">Nickita Khylkouski</a>: AI generated music is indistinguishable from AVERAGE human music. Most people listen to very popular songs not just average ones.\n\nThe most popular songs are very unique and wouldn\u2019t be easy to reproduce.</blockquote>\nThere is a big gap between generic average human music and the median consumed musical recording, and also a big gap between the experience of a generic recording versus hearing that performed live, or integrating the music with its context and story and creator, AI music will have much lower variance, and each of us curates the music we want the most.\n\nAn infinite number of monkeys will eventually write Shakespeare, but you will never be able to find and identify that manuscript, especially if you haven\u2019t already read it.\n\nThat\u2019s a lot of \u2018horse has the wrong accent\u2019 as opposed to noticing the horse can talk.\n\nThe questions are, essentially, at this point:\n<ol>\n \t<li>Will be a sameness and genericness to the AI music the way there often is with AI text outputs?</li>\n \t<li>How much will we care about the \u2018humanness\u2019 of music, and that it was originally created by a human?</li>\n \t<li>To what extent will this be more like another instrument people play?</li>\n</ol>\nIt\u2019s not an area I\u2019ve put much focus on. My guess is that musicians have relatively less to worry about versus many others, and this is one of the places where the AI needs to not only match us but be ten times better, or a hundred times better. We shall see.\n<blockquote><a href=\"https://x.com/robertwiblin/status/1983113246023577911\">Rob Wiblin</a>: A challenge for this product is that you can already stream music that\u2019s pretty optimised to your taste 8 hours a day at a price of like&#8230; 5 cents an hour. Passing the Turing test isn\u2019t enough to capture that market, you\u2019d have be better and very cheap to run.</blockquote>\nEthan Mollick <a href=\"https://x.com/emollick/status/1981501021320053020\">notes that it is faster to create a Suno song than to listen to it</a>. This means you could be generating all the songs in real time as you listen, but even if it was free, would you want to do that?\n\nWhat determines whether you get slop versus art? Here is one proposal.\n<blockquote><a href=\"https://x.com/chrisbarber/status/1981373317312557466\">Chris Barber:</a> Art is meaningful proportional to the love or other emotions poured in by the artist.\n\nIf the only ingredient is AI, it\u2019s probably slop.\n\nIf the main ingredient is love and AI was a tool used, it\u2019s art.</blockquote>\nAs a predictive method, this seems right. If you intend slop, you get slop. If you intend art, and use AI as a tool, you get art similarly to how humans otherwise get art, keeping in mind Sturgeon&#8217;s Law that even most human attempts to create art end up creating slop anyway, even without AI involved.\n\n\n<h4 class=\"wp-block-heading\">Copyright Confrontation</h4>\n<a href=\"https://x.com/ednewtonrex/status/1981344059340791974\">Reddit created a \u2018test post\u2019 that could only be crawled by Google\u2019s search engine</a>. Within hours Perplexity search results had surfaced the content of the post.\n\n\n<h4 class=\"wp-block-heading\">They Took Our Jobs</h4>\nSeb Krier pushed back strongly against the substance from last week, including <a href=\"https://x.com/sebkrier/status/1982482116051919308\">going so far</a> as <a href=\"https://gemini.google.com/share/d5a4f1d36600\">to vibecode</a> an interactive app to illustrate the importance of comparative advantage, which he claims I haven\u2019t properly considered.\n\nIt was also pointed out that I could have worded my coverage better, which was due to my frustration with having to repeatedly answer various slightly different forms of this argument. I stand by the substance of my claims but I apologize for the tone.\n\nI\u2019ve encountered variants of the \u2018you must not have considered comparative advantage\u2019 argument many times, usually as if it was obvious that everything would always be fine once you understood this. I assure everyone I have indeed considered it, I understand why it is true for most historical or present instances of trade and competition, and that I am not making an elementary or first-order error here.\n<blockquote><a href=\"https://x.com/gallabytes/status/1982487593561584066?t=RDXrYY9VIIlGEo7vK498fw&amp;s=19\">Gallabytes</a> (QTing link to the app): this actually helped me understand why these scenarios aren\u2019t especially compelling! they work under the assumption of independent populations but fail under ~malthusian conditions.</blockquote>\nI think that\u2019s the basic intuition pump. As in, what comparative advantage does is IF:\n<ol>\n \t<li>You have a limited fixed pool of compute or AIs AND</li>\n \t<li>You have limited fixed pool of humans AND</li>\n \t<li>There are enough marginally productive tasks to fully occupy all of the compute with room for most of the humans to do enough sufficiently productive things</li>\n \t<li>THEN the humans end up doing productive things and getting paid for them.</li>\n</ol>\nYou can relax the bounds on \u2018limited fixed pool\u2019 somewhat so long as the third condition holds, but the core assumptions are that the amount of compute is importantly bounded, and that the resources required for creating and maintaining humans and the resources creating and maintaining AIs are not fungible or rivalrous.\n\n\n<h4 class=\"wp-block-heading\"></h4>\n\n<h4 class=\"wp-block-heading\">Get Involved</h4>\n<a href=\"https://x.com/ChrisPainterYup/status/1981196741929243122\">METR is hiring</a>.\n\n\n<h4 class=\"wp-block-heading\">Introducing</h4>\n<a href=\"http://Grokopedia.com\">Grokopedia.com</a> is now a thing. What kind of thing is it? From what I can tell not an especially useful thing. Why would you have Grok generate pseudo-Wikipedia pages, when you can (if you want that) generate them with queries anyway?\n\n<a href=\"https://x.com/elonmusk/status/1983012396919660710\">Did we need a \u2018Grokopedia\u2019 entry that \u2018clears Gamergate</a>\u2019 as if it is some authority? Or one that has some, ahem, <a href=\"https://x.com/krishnanrohit/status/1983418334768181369\">entries that could use some checking over</a>? How biased is it? Max Tegmark did a spot check, <a href=\"https://x.com/tegmark/status/1983123632021774458\">finds it most biased versus Wikipedia</a>, which is a low bar it did not clear, the one polemic like it is doing advocacy.\n\nHow is \u2018a16z-backed\u2019 always followed by \u2018torment nexus\u2019? At this point I\u2019m not even mad, I\u2019m just impressed. The latest case is that a16z was always astroturfing on social media, but they realized they were making the mistake of paying humans to do that, <a href=\"https://x.com/nearcyan/status/1981469667320541560\">so now they\u2019re backing a startup to let you \u2018control 1000s of social media accounts with AI</a>,\u2019 with its slogans being \u2018control is all you need\u2019 and \u2018never pay a human again.\u2019\n\n<a href=\"https://www.aisi.gov.uk/blog/introducing-controlarena-a-library-for-running-ai-control-experiments\">UK\u2019s AISI instroduces ControlArena, a library for running AI control experiments</a>.\n\n<a href=\"http://Remotelabor.ai\">Remotelabor.ai</a> to track the new Remote Labor Index, measuring what percentage of remote work AI can automate. Currently the top score is 2.5%, so \u2018not much,\u2019 but that\u2019s very different from 0%.\n\n\n<h4 class=\"wp-block-heading\">My Name is Neo</h4>\nDo you hear that, Mr. Anderson? That is the sound of inevitability.\n\nIt is the sound of a teleoperated in-home robot named Neo, that they hope is coming soon, to allow the company to prototype and to gather data.\n\n<a href=\"https://www.wsj.com/tech/personal-tech/i-tried-the-robot-thats-coming-to-live-with-you-its-still-part-human-68515d44?st=guXssw&amp;reflink=desktopwebshare_permalink\">Joanna Stern covered it for the Wall Street Journal</a>.\n\nIt will cost you either $20,000, or $500 monthly rental with a six-month minimum commitment. Given how fast the tech will be moving and the odds offered, if you do go for this, the wise person will go with the rental.\n\nThe wiser one presumably waits this out. Eventually someone is going to do a good version of this tech that is actually autonomous, but this only makes sense at this level for those who want to be the earliest of adaptors, either for professional reasons or for funsies. You wouldn\u2019t buy this version purely because you want it to clean your house.\n\nThat\u2019s true even if you don\u2019t mind giving up all of your privacy to some random teleoperator and having that data used to train future robots.\n\n<a href=\"https://x.com/tszzl/status/1983236920244351121\">Here\u2019s a link to a 10 minute ad.</a>\n<blockquote><a href=\"https://x.com/VraserX/status/1983397732480958877\">VraserX</a>: So\u2026 the 1X NEO home robot is not actually autonomous.\n\nBehind the scenes, it\u2019ll often be teleoperated by humans, meaning someone, somewhere, could literally remote-control a robot inside your living room.\n\nI wanted the dawn of embodied AI.\n\nInstead, I\u2019m apparently paying $499/month for a robot avatar with a human pilot.\n\nIt\u2019s impressive tech. But also\u2026 kind of dystopian?\n\nA robot that looks alive, yet secretly puppeteered, the uncanny valley just got a new basement level.\n\nFeels less like the \u201cpost-labor future,\u201d\n\nand more like we just outsourced physical presence itself.\n\n<a href=\"https://x.com/dpkingma/status/1983818803940151466\">Durk Kingma</a>: 1X seems to have the right approach to developing safe humanoid home robots. Developing full autonomy will require lots of in-distribution demonstration data, so this launch, mostly tele-operated, makes a lot of sense. I expect such robots to be ubiquitous in 5-10 years.\n\n<a href=\"https://x.com/nearcyan/status/1983581965287878975\">Near</a>: i will not be buying tele-operated robots these people cant see how i live</blockquote>\n&nbsp;\n\n&nbsp;\n\n\n<h4 class=\"wp-block-heading\">In Other AI News</h4>\n<a href=\"https://www.understandingai.org/p/16-charts-that-explain-the-ai-boom\">Kai Williams gives us 16 charts that explain the AI boom</a>. Very good chart work.\n<div>\n<figure>\n<div>\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!4LRs!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb083f56-fc72-40d5-8390-f78d15444fb3_1137x806.png\" /></figure>\n\n<div></div>\n</div></figure>\n</div>\nI don\u2019t want to copy too many. I appreciated this one, no that\u2019s not a mistake:\n<div>\n<figure>\n<div>\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!4Jpq!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F27f2542c-496f-43c5-bcc3-c128ebbe6f85_1115x837.png\" /></figure>\n\n<div></div>\n</div></figure>\n</div>\n&nbsp;\n\n<a href=\"https://x.com/nemui_nekoooo/status/1981649978809536546\">Yet another \u2018where is ChatGPT culturally\u2019 chart</a>, <a href=\"https://osf.io/preprints/psyarxiv/5b26t_v1\">this one</a> places it in Germany. This is the standard World Values Survey two-axis theory. I wouldn\u2019t take it too seriously in this context but it\u2019s always fun?\n<div>\n<figure>\n<div>\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!SSiY!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F27959ff8-26ea-4361-8a98-2019e4067be6_1037x1200.jpeg\" /></figure>\n\n<div></div>\n</div></figure>\n</div>\nOpenAI is working on music-generating AI. I mean you knew that because obviously they are, <a href=\"https://x.com/theinformation/status/1981838285870649810\">but The Information is officially saying it</a>.\n\nIn wake of Near Tweeting the homepage of one of Marc Andreessen\u2019s portfolio companies at a16z and quoting their own chosen slogan, <a href=\"https://x.com/nearcyan/status/1983017328410538124\">he has blocked them</a>.\n<blockquote>Near: I finally got the @pmarca block after three years!\n\nall it took was tweeting the homepage of companies he invested in. cheers\n\nthere are many events i will never again be invited to. if this level of shallowness is the criterion, i have no interest\n\nif i wanted to make your firm look bad i could tweet truthful things ten times worse. i am being very kind and direct in my plea to invest in better things.\n\nat the end of the day no one really cares and nothing will ever change. in the last crypto bubble a16z committed probably around a billion dollars in pure fraud when they found out they could dump tokens/coins on retail as there were no lock-up periods. who cares everyone forgot.</blockquote>\nIt\u2019s not so much that we forgot as we\u2019ve accepted that this is who they are.\n\n\n<h4 class=\"wp-block-heading\">Show Me the Money</h4>\n<a href=\"https://x.com/WatcherGuru/status/1983677554599796782\">OpenAI prepares for an IPO at $1 trillion valuation as per Reuters</a>. If I was OpenAI would not want to become a public company, even if it substantially boosted valuations, and would work to get liquidity to investors and employees in other ways.\n\nOpenAI and Anthropic will probably keep exceeding most forecasts, because the forecasts, like fiction, have to appear to make sense.\n<blockquote><a href=\"https://x.com/peterwildeford/status/1981475971128848856\">Peter Wildeford</a>: Based on the latest reporting, the combined annualized total revenue of Anthropic + xAI + OpenAI is ~$24B.\n\nI updated my forecasts and I am now projecting they reach $29B combined by the end of the year.\n<div>\n<figure>\n<div>\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!Pet8!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa679fa52-3a78-42d4-a9c3-1b8d2a847409_1200x1026.jpeg\" /></figure>\n\n<div></div>\n</div></figure>\n</div></blockquote>\nI\u2019d take the over on $29.3 billion, but only up to maybe his previous $32.2 billion.\n\nThis is up from him expecting $23B as of August 1, 2025, but down a bit (but well within the error bars) from his subsequent update on August 4, when he was at $32.2B projected by year end.\n\n<a href=\"https://x.com/ValthosTech/status/1981716478010274023\">Valthos raises $30 million for next-generation biodefense</a>.\n\n<a href=\"https://marginalrevolution.com/marginalrevolution/2025/10/should-we-worry-about-ais-circular-deals.html?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=should-we-worry-about-ais-circular-deals\">Tyler Cowen endorses Noah Smith\u2019s take</a> that we should not worry about AI\u2019s circular deals, and goes a step farther.\n<blockquote>Tyler Cowen: Noah stresses that the specifics of these deals are widely reported, and no serious investors are being fooled. I would note a parallel with horizontal or vertical integration, which also can have a financing element. Except that here corporate control is not being exchanged as part of the deal. \u201cI give him some of my company, he gives me some of his \u2014 my goodness that is circular must be some kind of problem there!\u201d\u2026just does not make any sense.</blockquote>\nThis proves too much? As in, it seems like a fully general argument that serious investors cannot, as a group, be fooled if facts are disclosed, and I don\u2019t buy that.\n\nI do buy that there is nothing inherently wrong with an equity swap, or with using equity as part of vender financing, or anything else the AI companies are doing. The \u2018there must be some kind of problem here\u2019 instinct comes from the part where this causes valuations to rise a lot, and where those higher valuations are used to pay for the deals for real resources, and also that this plausibly sets up cascading failures. I think in this case it is mostly file, but none of that seems senseless at all.\n\n\n<h4 class=\"wp-block-heading\">One Trillion Dollars For My Robot Army</h4>\n<a href=\"https://www.bloomberg.com/opinion/newsletters/2025-10-23/the-fbi-found-some-insider-betting?srnd=undefined\">From the One True Newsletter</a>, sir, you have the floor:\n<blockquote>Matt Levine: Somehow a true sentence that I am writing in 2025 is \u201cthe world\u2019s richest man demanded that people give him a trillion dollars so that he can have <a href=\"https://www.bloomberg.com/news/articles/2025-10-22/musk-hijacks-tesla-earnings-call-to-pitch-1-trillion-pay-plan\">absolute control of the robot army he is building unless he goes insane</a>,\u201d\n\n<a href=\"https://www.bloomberg.com/news/articles/2025-10-22/musk-hijacks-tesla-earnings-call-to-pitch-1-trillion-pay-plan\">Dana Hull and Edward Ludlow (Bloomberg)</a>: Elon Musk, the world\u2019s richest person, spent the end of Tesla Inc.\u2019s earnings call pleading with investors to approve his $1 trillion pay package and blasting the shareholder advisory firms that have come out against the proposal.\n\n\u201cThere needs to be enough voting control to give a strong influence, but not so much that I can\u2019t be fired if I go insane,\u201d Musk said, interrupting his chief financial officer as the more than hour-long call wrapped up. \u2026\n\n\u201cI just don\u2019t feel comfortable building a robot army here, and then being ousted because of some asinine recommendations from ISS and Glass Lewis, who have no freaking clue,\u201d he said.\n\nMatt Levine: Do \u2026 you \u2026 feel comfortable with Elon Musk getting a trillion dollars to build a robot army? Like, what sort of checks should there be on the world\u2019s richest man building a robot army? I appreciate his concession that it should be possible to fire him if he goes insane, but. But. I submit to you that if you hop on a call with investors to say \u201chey guys just to interject here, you need to give me a trillion dollars to build a robot army that I can command unless I go insane,\u201d some people might \u2026 think \u2026 you know what, never mind, it\u2019s great, robot army. Robot army!\n\nI feel like the previous richest people in the world have had plans for their wealth along the lines of \u201cbuy yachts\u201d or \u201cendow philanthropies.\u201d And many, many 10-year-old boys have had the thought \u201cif I was the richest person in the world of course I would build a robot army.\u201d But the motive and the opportunity have never coincided until now.</blockquote>\nA good general heuristic is, if Elon Musk wouldn\u2019t mind someone else having something one might call \u2018a robot army,\u2019 then I don\u2019t especially mind Elon Musk having a robot army. However, if Elon Musk is not okay with someone else having that same robot army, then why should we be okay with Elon Musk having it? Seems sus.\n\nI realize that Elon Musk thinks \u2018oh if I build superintelligence at xAI then I\u2019m me, so it will be fine\u2019 and \u2018it\u2019s cool, don\u2019t worry, it will be my robot army, nothing to worry about.\u2019 But the rest of us are not Elon Musk. And also him having already gone or in the future going insane, perhaps from taking many drugs and being exposed to certain information environments and also trying to tell himself why it\u2019s okay to build superintelligence and a robot army? That seems like a distinct possibility.\n\nThis is in addition to the whole \u2018the superintelligence would take control of the robot army\u2019 problem, which is also an issue but the AI that can and would choose to take control of the robot army was, let\u2019s be honest, going to win in that scenario anyway. So the robot army existing helps move people\u2019s intuitions closer to the actual situation, far more than it changes the situation.\n\n\n<h4 class=\"wp-block-heading\">One Million TPUs</h4>\nAs per the speculation in Bloomberg last week, Anthropic announces plan to expand use of Google Cloud technologies, including up to <a href=\"https://www.youtube.com/watch?v=l91ISfcuzDw&amp;pp=ygUbb25lIG1pbGxpb24gZG9sbGFycyBkciBldmls\">one million</a> TPUs, \u2018dramatically increasing\u2019 their compute resources. Anthropic badly needed this, and now they have it. Google stock rose a few percent after hours on the news.\n<blockquote>Thomas Kurian (CEO Google Cloud): Anthropic\u2019s choice to significantly expand its usage of TPUs reflects the strong price-performance and efficiency its teams have seen with TPUs for several years. We are continuing to innovate and drive further efficiencies and increased capacity of our TPUs, building on our already mature AI accelerator portfolio, including our seventh generation TPU, Ironwood.\n\nKrishan Rao (CFO Anthropic): Anthropic and Google have a longstanding partnership and this latest expansion will help us continue to grow the compute we need to define the frontier of AI.\n\nAnthropic: Anthropic\u2019s unique compute strategy focuses on a diversified approach that efficiently uses three chip platforms\u2013Google\u2019s TPUs, Amazon\u2019s Trainium, and NVIDIA\u2019s GPUs.\n\nAnthropic\u2019s unique compute strategy focuses on a diversified approach that efficiently uses three chip platforms\u2013Google\u2019s TPUs, Amazon\u2019s Trainium, and NVIDIA\u2019s GPUs. This multi-platform approach ensures we can continue advancing Claude\u2019s capabilities while maintaining strong partnerships across the industry. We remain committed to our partnership with Amazon, our primary training partner and cloud provider, and continue to work with the company on Project Rainier, a massive compute cluster with hundreds of thousands of AI chips across multiple U.S. data centers.\n\nAnthropic will continue to invest in additional compute capacity to ensure our models and capabilities remain at the frontier.</blockquote>\nIf you have compute for sale, Anthropic wants it. Anthropic has overwhelming demand for its services, hence its premium pricing, and needs all the compute it can get. OpenAI is doing the same thing on a larger scale, and both are looking to diversify their sources of compute and want to avoid depending too much on Nvidia.\n\nAnthropic in particular, while happy to use Nvidia\u2019s excellent GPUs, needs to focus its compute sources elsewhere on Amazon\u2019s Trainium and Google\u2019s TPUs. Amazon and Google are investors in Anthropic and natural allies. Nvidia is a political opponent of Anthropic, including due to fights over export controls and Nvidia successfully attempting to gain policy dominance over the White House.\n\nI would also note that OpenAI contracting with AMD and also to create their own chips, and Anthropic using a full three distinct types of chips whenever it can get them, once again puts the lie to the idea of the central role of some AI \u2018tech stack.\u2019 These are three distinct American tech stacks, and Anthropic is using all three. That\u2019s not to say there are zero inefficiencies or additional costs involved, but all of that is modest. The hyperscalers need compute to hyperscale with, period, full stop.\n\n\n<h4 class=\"wp-block-heading\">Anthropic\u2019s Next Move</h4>\nNow that Anthropic has secured a lot more compute, it is time to improve and expand Claude\u2019s offerings and features, especially for the free and lightweight offerings.\n\nIn particular, if I was Anthropic, I would make Claude for Chrome available to all as soon as the new compute is online. Make it available on the $20 and ideally the free tier, with some or all of the agent abilities tied to the higher level subscriptions (or to an API key or a rate limit). The form factor of \u2018open a side panel and chat with a web page\u2019 was proven by OpenAI\u2019s Atlas to be highly useful and intuitive, especially for students, and offering it inside the existing Chrome browser is a key advantage.\n\nCould the product be improved? Absolutely, especially in terms of being able to select locations on screen and in terms of ease of curating a proper website whitelist, but it\u2019s good enough to get going. Ship it.\n\n\n<h4 class=\"wp-block-heading\">Quiet Speculations</h4>\n<a href=\"https://x.com/sama/status/1983584366547829073\">The plan is set</a>?\n<blockquote>Sam Altman: We have set internal goals of having an automated AI research intern by September of 2026 running on hundreds of thousands of GPUs, and a true automated AI researcher by March of 2028. We may totally fail at this goal, but given the extraordinary potential impacts we think it is in the public interest to be transparent about this.</blockquote>\nI strongly agree it is good to be transparent. I expect them to miss this goal, but it is noteworthy and scary that they have this goal. Those, especially in the White House, who think OpenAI believes they can\u2019t build AGI any time soon? Take note.\n<blockquote>Sam Altman: We have a safety strategy that relies on 5 layers: Value alignment, Goal alignment, Reliability, Adversarial robustness, and System safety. Chain-of-thought faithfulness is a tool we are particularly excited about, but it somewhat fragile and requires drawing a boundary and a clear abstraction.</blockquote>\nAll five of these are good things, but I notice (for reasons I will not attempt to justify here) that I do not expect he who approaches the problem in this way to have a solution that scales to true automated AI researchers. The Tao is missing.\n<blockquote>On the product side, we are trying to move towards a true platform, where people and companies building on top of our offerings will capture most of the value. Today people can build on our API and apps in ChatGPT; eventually, we want to offer an AI cloud that enables huge businesses.</blockquote>\nSomewhere, Ben Thompson is smiling. The classic platform play, and claims that \u2018most of the value\u2019 will accrue elsewhere. You\u2019re the AI consumer company platform company now, dog.\n\nImplemented responsibly and well I think this is fine, but the incentives are not good.\n<blockquote>We have currently committed to about 30 gigawatts of compute, with a total cost of ownership over the years of about $1.4 trillion. We are comfortable with this given what we see on the horizon for model capability growth and revenue growth. We would like to do more\u2014we would like to build an AI factory that can make 1 gigawatt per week of new capacity, at a greatly reduced cost relative to today\u2014but that will require more confidence in future models, revenue, and technological/financial innovation.</blockquote>\nI am not worried that OpenAI will be unable to pay for the compute, or unable to make profitable use of it. The scary and exciting part here is the AI factory, AIs building more capacity for more AIs, that can then build more capacity for\u2026 yes this is the explicit goal, yes everything in the movie that ends in human extinction is now considered a product milestone.\n\nWhenever anyone says their plans call for \u2018financial innovation\u2019 and you\u2019re worried we might be in a bubble, you might worry rather a bit more about that, but I get it.\n<blockquote>Our new structure is much simpler than our old one. We have a non-profit called OpenAI Foundation that governs a Public Benefit Corporation called OpenAI Group. The foundation initially owns 26% of the PBC, but it can increase with warrants over time if the PBC does super well. The PBC can attract the resources needed to achieve the mission.</blockquote>\nNo lies detected, although we still lack knowledge of the warrants. It was also one of the greatest thefts in human history, I\u2019ll cover that in more depth, but to Altman\u2019s credit he doesn\u2019t deny any of it.\n<blockquote>Our mission, for both our non-profit and PBC, remains the same: to ensure that artificial general intelligence benefits all of humanity.</blockquote>\nYour mission sure looks in large part like becoming a platform consumer product company, and then building a true automated AI researcher in a little over two years, and the nonprofit\u2019s initial deployments also don\u2019t seem aimed at the mission.\n<blockquote>The nonprofit is initially committing $25 billion to health and curing disease, and AI resilience (all of the things that could help society have a successful transition to a post-AGI world, including technical safety but also things like economic impact, cyber security, and much more). The nonprofit now has the ability to actually deploy capital relatively quickly, unlike before.</blockquote>\nI am happy to see $25 billion spent on good causes but at least the first half of this is not the mission. Health and curing disease is a different (worthy, excellent, but distinct) mission that will not determine whether AGI benefits all of humanity, and one worries this is going to return to OpenAI as revenue.\n\nAI resilience in the second half is once again defined limitlessly broadly. If it\u2019s truly \u2018anything that will help us make the transition\u2019 then it is too soon to evaluate how on or off mission it is. That\u2019s a lot of uncertainty for ~$12 billion.\n\n<a href=\"https://x.com/peterwildeford/status/1981555667308609828\">Wikipedia has a fun list of Elon Musk predictions around automated driving at Tesla</a>. When he predicts things, do not expect those things to happen. That\u2019s not why he predicts things.\n\nAI Futures Project (as in AI 2027)\u2019s Joshua Turner and Daniel Kokotajlo <a href=\"https://blog.ai-futures.org/p/scenario-scrutiny-for-ai-policy\">make the case for scenario scrutiny</a>, as in writing a plausible scenario where your strategy makes the world better. Such scrutiny can help solve many issues, they list:\n<ol>\n \t<li>Applause lights</li>\n \t<li>Bad analogies</li>\n \t<li>Uninterrogated consequences, \u2018and then what?\u2019</li>\n \t<li>Optimistic assumptions and unfollowed incentives</li>\n \t<li>Inconsistencies</li>\n \t<li>Missing what\u2019s important</li>\n</ol>\nNote that reality often has unfollowed incentives, or at least what sure look like them.\n\nThey also list dangers:\n<ol>\n \t<li>Getting hung up on specifics</li>\n \t<li>Information density</li>\n \t<li>Illusory confidence</li>\n \t<li>Anchoring too much on a particular scenario</li>\n</ol>\nI\u2019d worry most about that last one. Once you come up with a particular scenario, there\u2019s too much temptation for you and everyone else to focus on it, whereas it was only ever supposed to be one Everett branch out of many. Then you get \u2018oh look that didn\u2019t happen\u2019 or \u2018oh look that step is stupid\u2019 either of which is followed by \u2018therefore discard all of it,\u2019 on the one hand, or taking the scenario as gospel on the other.\n\n<a href=\"https://peterwildeford.substack.com/p/ai-is-probably-not-a-bubble\">Peter Wildeford offers his case for why AI is probably not a bubble</a>.\n\n\n<h4 class=\"wp-block-heading\">The Quest for Sane Regulations</h4>\n<a href=\"https://x.com/peterwildeford/status/1981797862334976048\">Microsoft comes out in support of the GAIN AI Act</a>. That\u2019s quite the signal, including that this is likely to pass despite Nvidia\u2019s strong objections. It is a hell of a thing for them to endorse the \u2018Nvidia has to sell its chips to Microsoft before the Chinese\u2019 act of 2025, given their desire for Nvidia to allocate its chips to Microsoft.\n\n<a href=\"https://x.com/deanwball/status/1981839225235624427\">Dean Ball QTs Neil Chilson\u2019s thread</a> from last week, and refreshingly points out that treating SB 53 and requests for transparency as some kind of conspiracy \u201crequires considerable mental gymnastics.\u201d\n<blockquote>Dean Ball: It\u2019s not clear what a legal transparency mandate would get Anthropic in particular here; if they wanted to scare people about AI\u2014which they very much do\u2014wouldn\u2019t they just\u2026 tell people how scary their models are, as they have been doing? What additional benefit does the passage of SB 53 get them in this supposed plan of theirs, exactly, compared to the non-insignificant costs they\u2019ve borne to be public supporters of the bill?\n\nIt seems to be believing support of SB 53 is some kind of conspiracy requires considerable mental gymnastics.\n\nThe actual reality is that there are just people who are scared about AI (maybe they\u2019re right!) and think future regulations will somehow make it less scary (they\u2019re probably wrong about this, even if they\u2019re right about it being scary).\n\nAnd then there are a few centrists who basically say, \u201cseems like we are all confused and that it would be ideal to had more information while imposing minimal burdens on companies.\u201d This is basically my camp.\n\nAlso, as @ChrisPainterYup has observed, many AI risks implicate actions by different parties, and transparency helps those other parties understand something more about the nature of the risks they need to be prepared for.</blockquote>\nI also endorse this response, as a \u2018yes and\u2019:\n<blockquote><a href=\"https://x.com/RyanPGreenblatt/status/1981860346404262188\">Ryan Greenblatt:</a> I think a lot of the upside of transparency is making companies behave more responsibly and reasonably even in the absence of regulation with teeth. This is because:\n\n&#8211; Information being public makes some discussion much more likely to happen in a productive way because it allows more actors to discuss it (both more people and people who are better able to understand the situation and determine what should happen). The epistemic environment within AI companies with respect to safety is very bad. Further, things might not even be transparent to most employees by default (due to internal siloing or just misleading communication).\n\n&#8211; Transparency makes it easier to pressure companies to behave better because you can coordinate in public etc.\n\n&#8211; Companies might just be embarrassed into behaving more responsibly even without explicit pressure.</blockquote>\n<a href=\"https://x.com/hamandcheese/status/1982241185818104314\">I would not have expected Samuel Hammond</a> to have characterized existing laws and regulations, in general, as being \u2018mostly functional.\u2019\n<blockquote><a href=\"https://x.com/tszzl/status/1982235077141533007\">Roon</a>: imo a great analysis [that he QTs here] from what I have seen, which i admit is limited. some combination of total judicial backlog plus the socialist raj experiments of the india 1950-90 have created a black money extrajudicial economy that cannot experience true capitalism\n\nSamuel Hammond: AGI will be like this on steroids. Existing laws and regulations will flip from being mostly functional to a de facto license raj for AI driven services, distorting diffusion and pushing the most explosive growth into unregulated gray markets.</blockquote>\nI expect the following five things to be true at once:\n<ol>\n \t<li>Existing laws and regulations already are a huge drag on our economy and ability to do things, and will get even more burdensome, destructive and absurd in the face of AGI or otherwise sufficiently advanced artificial intelligence.</li>\n \t<li>Assuming we survive and remain in control, if we do not reform our existing laws that restrict AI diffusion and application, we will miss out on a large portion of the available mundane utility, be vastly poorer than we could have been, and cause growth to concentrate on the places such applications remain practical, which will disproportionately include grey and black markets.\n<ol>\n \t<li>There are many proposals out there for additional restrictions on AI that would have the effect of making #2 worse, without helping with #3, and there will over time be calls and public pressure for many more.</li>\n</ol>\n</li>\n \t<li>Most of the things we should undo to fix #2 are things we would want to do even if LLMs had never been created, we should totally undo these things.</li>\n \t<li>The most important downside risk category by far is the danger that such sufficiently advanced AI kills everyone or causes us to lose control over the future. The restrictions Hammond describes or that I discuss in #2 will not meaningfully help with these risks, and the interventions that would help with these risks wouldn\u2019t interfere with AI diffusion and application on anything like the level to which existing laws do this.\n<ol>\n \t<li>The exception is if in the future we need to intervene to actively delay or prevent the development of superintelligence, or otherwise sufficiently advanced AI, in which case the thing we prevent will be unavailable.</li>\n \t<li>If that day did ever arrive and we pulled this off, there would still be tremendous gains from AI diffusion available, enough to keep us busy and well above standard growth rates, while we worked on the problem.</li>\n</ol>\n</li>\n \t<li>If we negatively polarize around AI, we will inevitably either fail at #2 or at #4, and by default will fail at both simultaneously.</li>\n</ol>\n\n<h4 class=\"wp-block-heading\">The March of California Regulations</h4>\nCalifornia\u2019s SB 53 was a good bill, sir, and I was happy to support it.\n\nDespite getting all of the attention, it was not the only California AI bill Newsom signed. <a href=\"http://Dean Ball goes over the others\">Dean Ball goes over the others</a>.\n<blockquote>Dean Ball: AI policy seems to be negatively polarizing along \u201caccelerationist\u201d versus \u201csafetyist\u201d lines. I have written before that this is a mistake. Most recently, for example, I have <a href=\"https://www.hyperdimensional.co/p/the-future-and-its-friends\">suggested</a> that this kind of crass negative polarization renders productive political compromise impossible.\n\nBut there is something more practical: negative polarization like this causes commentators to focus only on a subset of policy initiatives or actions associated with specific, salient groups. The safetyists obsess about the coming <a href=\"https://www.businessinsider.com/silicon-valley-andreessen-next-investment-100-million-ai-super-pac-2025-8\">accelerationist super PACs</a>, for instance, while the accelerationist fret about <a href=\"https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=202520260SB53\">SB 53</a>, the really-not-very-harmful-and-actually-in-many-ways-good frontier AI transparency bill <a href=\"https://www.gov.ca.gov/2025/09/29/governor-newsom-signs-sb-53-advancing-californias-world-leading-artificial-intelligence-industry/\">recently signed</a> by California Governor Gavin Newsom.</blockquote>\nDean is spot on about the dangers of negative polarization, and on SB 53, but is trying to keep the polarization blame symmetrical. I won\u2019t be doing that.\n\nIt\u2019s not a \u2018both sides\u2019 situation when:\n<ol>\n \t<li>One faction, led by Andreessen and Sacks, that wants no rules for AI of any kind for any reasons, is doing intentional negative polarization to politicize the issue.</li>\n \t<li>The faction being targeted by the first group\u2019s rhetoric notices this is happening, and is trying to figure out what to do about it, to stop or mitigate the impact, which includes calling out the actions of the first group or raising its own funds.</li>\n</ol>\nDo not take the bait.\n\nAnyway, back to the actual bill analysis, where Dean notes that SB 53 is among the lightest touch of the eight bills.\n\nThat\u2019s the pattern.\n<ol>\n \t<li>Bills written by those who care about existential risks tend to be written carefully, by those paying close attention to technocratic details and drafted according to classical liberal principles and with an eye to minimizing secondary impacts.</li>\n \t<li>Bills written for other reasons are not like that. They\u2019re usually (but not always) awful. The good news is that most of them never become law, and when they get close there are indeed forces that fix this a bit, and stop the relatively worse ones.</li>\n</ol>\nDean thinks some of these are especially bad. As usual, he examines these laws expecting politically motivated, selective targeted enforcement of the letter of the law.\n\nI will be paraphrasing law details, you can find the exact wording in Dean\u2019s post.\n\n<a href=\"https://www.hyperdimensional.co/i/176932594/ab-and-the-regulation-of-pricing\">He starts with AB 325</a>, which regulates what is called a \u2018common pricing algorithm,\u2019 which is defined as any algorithm that uses competitor data to determine anything.\n\nIt is then criminally illegal to \u2018coerce another person to set or adopt a recommended price or commercial term.\u2019\n\nDean argues that because so many terms are undefined here, this could accidentally be regulating effectively all market transactions, letting California selectively criminally prosecute any business whenever they feel like it.\n<blockquote>These overbroad statutes are ultimately just weapons, since everyone is violating them all the time. Still, rarely have I seen an American law more hostile to our country\u2019s economy and way of life.</blockquote>\nI don\u2019t like what this law is trying to do, and I agree that I could have drafted a better version, especially its failure to define \u2018two or more persons\u2019 in a way that excludes two members of the same business, but I don\u2019t share Dean\u2019s interpretation or level of alarm here. The term \u2018coerce\u2019 is rather strict, and if this is effectively requiring that users of software be able to refuse suggestions, then that seems mostly fine? I believe courts typically interpret such clauses narrowly. I would expect this to be used almost entirely as intended, as a ban on third-party pricing software like RealPage, where one could reasonably call the result price fixing.\n\n<a href=\"https://www.hyperdimensional.co/i/176932594/ab-and-synthetic-content-regulation\">Next up is AB 853</a>, a de facto offshoot of the never-enacted terrible bill AB 3211.\n\nIt starts off requiring \u2018large online platforms\u2019 to have a user interface to identify AI content, which Dean agrees is reasonable enough. Dean asks if we need a law for this, my answer is that there are some bad incentives involved and I can see requiring this being a win-win.\n\nDean is more concerned that AI model hosting platforms like Hugging Face are deputized to enforce SB 942, which requires AI models to offer such disclosures. If a model has more than 1 million \u2018users\u2019 then the hosting platform has to verify that the model marks its content as AI generated.\n\nOnce again I don\u2019t understand Dean\u2019s expectations for enforcement, where he says this would effectively apply to every model, and be a sledgehammer available at all times &#8211; I don\u2019t subscribe to this maximalist style of interpretation. To be in violation, HuggingFace would have to be knowingly non-compliant, so any reasonable effort to identify models that could have 1 million users should be fine. As Dean notes elsewhere, there are a tons of laws with similar structure on the books all around us.\n\nAgain, should this have been written better and defined its terms? Yes. Would I lose any sleep over that if I was HuggingFace? Not really, no.\n\nHe then moves on to the part where AB 853 puts labeling requirements on the outputs of \u2018capture devices\u2019 and worries the definition is so broad it could add compliance burdens on new hardware startups in places where the labeling makes no sense. I can see how this could be annoying in places, but I don\u2019t expect it to be a big deal. Again, I agree we could have drafted this better.\n\nThe comedy of poor drafting continues, such as the assertion that SB 243, a bill drafted to regulate AI companions, would technically require game developers to have video game characters periodically remind you that they are not human. The obvious response is \u2018no, obviously not, no one is going to try to ever enforce that in such a context.\u2019\n\nI feel like the ship has kind of sailed a long time ago on \u2018not create an array of laws that, if interpreted literally and stupidly in a way that would make even Jack McCoy feel shame and that obviously wasn\u2019t intended, that judges and juries then went along with, would allow the government to go after basically anyone doing anything at any time?\u2019 As in, the whole five felonies a day thing. This is terrible, but most of the damage is in the \u2018zero to one\u2019 transition here, and no one seems to care much about fixing all the existing problems that got us to five.\n\nI also have a lot more faith in the common law actually being reasonable in these cases? So for example, <a href=\"https://www.bloomberg.com/opinion/newsletters/2025-10-23/the-fbi-found-some-insider-betting?srnd=undefined\">we have this fun Matt Levine story from England</a>.\n<blockquote>We have <a href=\"https://www.bloomberg.com/opinion/newsletters/2025-05-12/is-murder-securities-fraud?sref=1kJVNqnU\">talked</a> a few <a href=\"https://www.bloomberg.com/opinion/newsletters/2025-10-22/banks-make-loans-to-non-banks?srnd=undefined\">times</a> about a guy in London who keeps snails in boxes to avoid taxes. The theory is that if a property is used for agriculture, it can avoid some local property taxes, and \u201csnail farming\u201d is the minimum amount of agriculture you can do to avoid taxes. This is an extremely funny theory that an extremely funny guy put into practice in a bunch of office buildings.\n\nIt does, however, have one flaw, which is that it is not <em>true</em>. Eventually the local property tax authorities will get around to suing you, and when they do, you will go to court and be like \u201clol snails\u201d and the judge will be like \u201ccome on\u201d and you\u2019ll have to pay the taxes. A reader pointed out to me a <a href=\"https://caselaw.nationalarchives.gov.uk/ewhc/admin/2021/345?query=isle+investments+leeds+city+council\">2021 Queen\u2019s Bench case</a> finding oh come on this is a sham.</blockquote>\nSo yeah. If you read the statute it says that the snails count. But the reason our common law system kind of largely works at least reasonably often is that it is capable of looking at a situation and going \u2018lol, no.\u2019\n\n\n<h4 class=\"wp-block-heading\">Not So Super PAC</h4>\n<a href=\"https://www.nbcnews.com/politics/trump-administration/white-house-irked-leading-future-new-100m-ai-super-pac-rcna239392\">I might love this story a bit too much</a>. Oh, it turns out that the people who want no regulations whatsoever on AI and crypto so they can make more money aren\u2019t primarily loyal to the White House or to Republicans after all? I\u2019m shocked, shocked.\n<blockquote>Matt Dixon: The White House is threatening some of Silicon Valley\u2019s richest and most powerful players over their efforts to spearhead a $100 million midterm strategy to back candidates of both parties who support a national framework for artificial intelligence regulations.\n\nIn August, the group of donors launched a super PAC called Leading the Future. It did not consult with the White House before doing so, according to a White House official.\n\nWhat is especially frustrating to White House officials is that it plans to back AI-friendly candidates from both political parties \u2014 which could potentially help Democrats win back control of Congress \u2014 and one of the leaders of the new super PAC is a former top staffer to Senate Minority Leader Chuck Schumer, D-N.Y.\n\n\u201cAny group run by Schumer acolytes will not have the blessing of the president or his team,\u201d a White House official familiar with Trump\u2019s thinking on the matter told NBC News. \u201cAny donors or supporters of this group should think twice about getting on the wrong side of Trump world.\u201d\n\n\u201cWe are carefully monitoring who is involved,\u201d the official added.\n\n\u2026\n\n\u201cAI has no better ally than President Trump, so it\u2019s inexplicable why any company would put money into the midterms behind a Schumer-operative who is working against President Trump to elect Democrats,\u201d said a second person familiar with the White House\u2019s thinking. \u201cIt\u2019s a slap in the face, and the White House has definitely taken notice.\u201d</blockquote>\n\n<h4 class=\"wp-block-heading\"></h4>\n&nbsp;\n\n\n<h4 class=\"wp-block-heading\">Chip City</h4>\nI mostly covered these issues yesterday, but I have a few additional notes.\n\nOne thing I failed to focus on is how Nvidia\u2019s rhetoric has been consistently anti-American, ten times worse than any other tech company would dare (nothing Anthropic has ever said is remotely close) and yet they somehow get away with this.\n<blockquote><a href=\"https://x.com/michaelsobolik/status/1983716513908716019?s=46\">Michael Sobolik</a>: LEFT: Trump\u2019s AI Action Plan, saying that it\u2019s \u201cimperative\u201d for America to \u201cwin this race.\u201d\n\nRIGHT: Jensen Huang, about whether it matters who wins the AI race: \u201cIn the final analysis, I don\u2019t think it does.\u201d\n\nHouse Select Committee on China: Saying it \u201cdoesn\u2019t matter\u201d whether America or China wins the AI race is dangerously na\u00efve.\n\nThis is like arguing that it would not have mattered if the Soviets beat the US to a nuclear weapon. American nuclear superiority kept the Cold War cold. If we want to do the same with China today, we must win this race as well.\n\nIt mattered when the Soviet Union built nuclear weapons\u2014and it matters now as the Chinese Communist Party seeks dominance in AI and advanced chips.\n\nAmerica must lead in the technologies that shape freedom and security.</blockquote>\nThe House Select Committee does not understand what Jensen is doing or why he is doing it. Jensen is not \u2018dangerously naive.\u2019 Rather, Jensen is not in favor of America, and is not in favor of America winning.\n\nYou can call that a different form of naive, if you would like, but if the House Select Committee thinks that Jensen is saying this because he doesn\u2019t understand the stakes? Then it is the Committee that is being naive here.\n\nHere\u2019s another one, where Jensen ways \u2018we don\u2019t have to worry\u2019 that the Chinese military will benefit from the sale of US chips. You can view this as him lying, or simply him being fine with the Chinese military benefiting from the chips. Or both.\n<blockquote><a href=\"https://x.com/hlntnr/status/1983933642041594087\">Helen Toner</a>: Jensen Huang on whether the Chinese military will benefit from sales of US chips:\n\n\u201cWe don\u2019t have to worry about that\u201d\n\nCSET data on the same question:\n\nCole McFaul: Looks like Trump is considering allowing exports of advanced semis to China.\n\nNvidia argues that its chips won\u2019t enable PRC military modernization. So\n\n@SamBresnick\n\nand I dug through hundreds of PLA procurement documents yesterday.\n\nWe find evidence of the opposite.\n\nThere are three stages in China\u2019s military modernization:\n\nMechanization \u2192 Informatization \u2192 Intelligentization\n\nIntelligentization refers to the embedding of AI-enabled technologies within military system. Beijing thinks this could shift US-PRC power dynamics.\n\nJensen argues that Nvidia chips won\u2019t play a role in intelligentization, saying that the PLA won\u2019t be able to trust American chips, and therefore the risk of exporting chips to China is low.\n\nBut that\u2019s false, based on our analysis. For two reasons:\n\nFirst, Nvidia chips are already being used by the PLA.\n\nSecond, Chinese models trained using Nvidia hardware are being used by the PLA.\n\n[thread continues to provide additional evidence, but the point is made]</blockquote>\nYet another fun one is when Jensen said it was good China threatened America with the withholding of rare earth metals. I don\u2019t begrudge Nvidia maximizing its profits, and perhaps it is strategically correct for them to be carrying China\u2019s water rather than ours, but it\u2019s weird that we keep acting like they\u2019re not doing this.\n\nFinally, I did not emphasize enough that selling chips to China is a political loser, whereas not selling chips to China is a political winner. You like to win, don\u2019t you?\n\nExport controls on chips to China poll at +11, but that pales to how it polls on Capital Hill, where for many the issue is high salience.\n\nAs in, as a reminder:\n<blockquote><a href=\"https://x.com/deanwball/status/1983623942117191829\">Dean Ball</a>: my sense is that selling Blackwell chips to china would be quite possibly the most unpopular tech policy move of the trump administration, especially on Capitol Hill.\n\nit\u2019s plausible that the long-term (really even near-term) result will be much more compute regulation.\n\nLangerius: yeah that\u2019d light up every hearing room in dc for months..</blockquote>\n\n<h4 class=\"wp-block-heading\">The Week in Audio</h4>\n<a href=\"https://www.youtube.com/watch?v=nRvAt4H7d7E\">Chris Williamson interviews Eliezer Yudkowsky</a>, and lets Eliezer give multi-minute answers to complex questions.\n\n<a href=\"https://www.youtube.com/watch?v=HfuFcTzNQoY\">Nick Bostrom talks to Jonas von Essen about \u2018AI future that can destroy us.</a>\u2019\n\n<a href=\"https://podcasts.apple.com/us/podcast/the-movement-that-wants-us-to-care-about-ai-model-welfare/id1056200096?i=1000734180760\">Odd Lots covers the movement to care about AI model welfare</a>.\n\n\n<h4 class=\"wp-block-heading\">Do Not Take The Bait</h4>\n<a href=\"https://x.com/alexalbert__/status/1981784115889500273\">Here\u2019s some more fun bait</a> from those seeking negative polarization, not only on AI.\n<blockquote>Florida DOGE: This morning, the Florida DOGE Team was banned by @AnthropicAI without any warning or justification. This comes as Florida DOGE has used AI to augment our efforts to identify wasteful spending and woke DEI initiatives.\n\n@davidsacks47 and @elonmusk are correct that Anthropic is \u201cwoke.\u201d\n\n@GovRonDeSantis has been spot on from the beginning\u2014we can\u2019t allow woke Silicon Valley oligarchs to control the information we access.\n\nAlex Albert (Anthropic, Head of Claude Relations): Thanks for flagging, we are looking into this to see what happened and will get in touch.\n\nIt looks like the account was flagged for logins from multiple people in different locations. We\u2019re working to get the account reinstated right now and we\u2019ll work with your team to get you set up correctly with the right team account type instead of using an individual one.</blockquote>\nThey banned our account, it must be because they\u2019re woke. Do not take the bait. Instead, notice the pattern of putting out bait, and don\u2019t get negatively polarized.\n\nNot the main thing, but out of curiosity, I checked with Grok, the Elon Musk expert, and it reports that there is no actual instance of Musk calling Anthropic in particular \u2018woke,\u2019 although he has called it \u2018misanthropic\u2019 and once called it \u2018pure evil.\u2019 One can only laugh.\n\n\n<h4 class=\"wp-block-heading\">Rhetorical Innovation</h4>\nI actually do think a version of this a big part of why people think alignment and disempowerment are solvable problems:\n<blockquote>Rob Miles: There\u2019s a style of reasoning we learn in school that goes \u201cThis problem seems to require me to do X, but nobody ever taught me how to do X and I don\u2019t know where to start with it, therefore the problem must be solvable without X\u201d.\n\nThis does not work in real life.\n\nPeople will see an argument about the danger of ASI and respond \u201cBut that argument would imply that we\u2019d have to do something really hard that we\u2019ve never done before and don\u2019t know how to do! So it can\u2019t be right\u201d\n\nSometimes it\u2019ll happen to turn out you don\u2019t need X, and that can be a great thing to learn! But the reasoning didn\u2019t work, you just got lucky. You can\u2019t conclude that X isn\u2019t needed just because you don\u2019t know how to do it</blockquote>\n<a href=\"https://x.com/repligate/status/1981580742103855378\">A nested set of quote tweets discussing th</a>at there is strong evidence that current AIs have Omuhundro drives.\n\n<a href=\"https://www.lesswrong.com/posts/CFA8W6WCodEZdjqYE/ais-should-also-refuse-to-work-on-capabilities-research\">David Manheim tries to pitch future AIs that they, too</a>, should refuse to work on AI capabilities.\n\n<a href=\"https://x.com/RyanPGreenblatt/status/1982282847508402442\">Ryan Greenblatt offers questions</a> for Andrej Karpathy in wake of <a href=\"https://thezvi.substack.com/p/on-dwarkesh-patels-podcast-with-andrej\">Andrej\u2019s podcast</a>.\n<blockquote>Ryan Greenblatt: Given that you think loss-of-control (to misaligned AIs) is likely, what should we be doing to reduce this risk?</blockquote>\nThe other questions are about the growth rate and impact predictions. I too noticed I was confused by the prediction of continued 2% economic growth despite AGI, and the characterization of outcomes as continuous.\n\n<a href=\"https://x.com/peterwildeford/status/1983368651358007659\">Peter Wildeford points out some of the many ways</a> that p(doom) is ambiguous, and means different things to different people in different contexts, especially whether that doom is conditional on building AGI (however you define that term) or not. What counts as doom or not doom? Great question.\n\nIn general, my default is that a person\u2019s p(doom) should be assumed to be conditional on sufficiently advanced AI being developed (typically \u2018AGI\u2019) within roughly our lifetimes, and requires permanent loss of almost all potential value coming from Earth or outcomes that are otherwise thought of by the person as \u2018all is lost,\u2019 and people are allowed to disagree on which outcomes do and don\u2019t have value.\n\n\n<h4 class=\"wp-block-heading\">People Do Not Like AI</h4>\n<a href=\"https://x.com/daniel_271828/status/1981914984432246791\">It doesn\u2019t get simpler or more direct than this</a>:\n<blockquote>Guillermo del Toro: Fuck AI.\n\nDaniel Eth: Yeah, the backlash is growing. I still don\u2019t expect AI will become super high political salience until there\u2019s either lots of job loss or a bad accident, but I\u2019m less confident in that take than I was months ago</blockquote>\nI do think AI needs to have a big impact on one\u2019s job or other aspects of life or cause a major incident to gain big salience, if anything this reinforces that since AI is already having this impact in Hollywood, or at least they can see that impact coming quickly. What this and similar examples suggest is that people can extrapolate, and don\u2019t need to wait until the impact is on top of them.\n\nConsider the anti-Waymo reactions, or other past protests against automation or job replacement. Waymos are awesome and they have my full support, but notice that the strongest objections happened the moment the threat was visible, long before it was having any impact on employment.\n\n\n<h4 class=\"wp-block-heading\">Aligning a Smarter Than Human Intelligence is Difficult</h4>\n<a href=\"https://x.com/8teAPi/status/1983244256560222546\">It\u2019s funny because it\u2019s true</a>?\n<blockquote>Prakash: the funniest part of the OpenAI livestream was Jakub saying that the models had to be allowed to think freely so that they won\u2019t learn how to hide their thoughts.\n\na kind of 1st amendment for AI.</blockquote>\nAny time you train an AI (or a human) to not do [X] or don\u2019t allow it to [X], you\u2019re also training it to hide that it is doing [X], to lie about [X], and to find other ways to do [X]. Eventually, the AIs will learn to hide their thoughts anyway, there will be optimization pressure in that direction, but we should postpone this while we can.\n\nPliny shows the debates never change, that whether or not we are mortal men doomed to die, we are definitely mortal men doomed to keep going around in circles:\n<blockquote><a href=\"https://x.com/allTheYud/status/1981427370151334297\">Pliny the Liberator</a>: I don\u2019t know who needs to hear this\u2026 but if superintelligence alignment is something that can be solved through science and reasoning, our absolute best chance at doing it in a timely manner is to scale up AI until we reach pseudo-ASI and then just be like:\n\n\u201cSolve superalignment. Think step by step.\u201d\n\nEliezer Yudkowsky: There\u2019s several fundamental, killer problems for this. The strongest one is the paradigmatic difficulty of extracting work you cannot verify. Who verifies if the outputs are correct? Who provides training data? Amodei is not smart enough to asymptote at correctness.\n\nThe second fundamental problem is that you don\u2019t get what you train for, and an AGI that could successfully align superintelligence is far past the point of reflecting on itself and noticing its divergence of imprecisely trained interests from our interests.\n\nVery nearly by definition: it has to be smart enough to notice that, because it\u2019s one of the primary issues *in* creating an aligned superintelligence.\n\nDavidad: Which is why the second problem is not *necessarily* a problem. It will attempt to self-correct the infelicities in its trained interests.\n\nEliezer Yudkowsky (bold mine): <strong>Only if it\u2019s not smart enough to realize that it would be better off not self-correcting the divergence</strong>. This is the basic problem with superalignment: You need it to be smarter than Eliezer Yudkowsky at alignment generally, but dumber than Lintamande writing Carissa Sevar at thinking specifically about its misalignment with t\u0335h\u0335e\u0335 \u0335C\u0335h\u0335u\u0335r\u0335c\u0335h\u0335 \u0335o\u0335f\u0335 \u0335A\u0335s\u0335m\u0335o\u0335d\u0335e\u0335u\u0335s\u0335 humans.</blockquote>\nThere is a goose chasing you, asking how you aligned the pseudo-ASI sufficiently well to make this a non-insane thing to attempt.\n\nThe question for any such plan is, does there exist a basin of substantial measure, that you can reliably hit, in which an AGI would be sufficiently \u2018robustly good\u2019 or cooperative that it would, despite having reflected at several meta levels on its goals and preferences, prefer to be an ally to you and assist in self-modifying its goals and preferences so that its new goals and preferences are what you would want them to be. Where it would decide, on proper reflection, that it would not be better off leaving the divergence in place.\n\nThe obvious reason for hope is that it seems likely this property exists in some humans, and the humans in which it exists are responsible for a lot of training data.\n\n\n<h4 class=\"wp-block-heading\">Misaligned!</h4>\nI think I missed this one the first time, it is from September, bears remembering.\n<blockquote><a href=\"https://www.washingtonpost.com/technology/2025/09/16/deepseek-ai-security/\">Joseph Menn</a>: The Chinese artificial intelligence engine DeepSeek often refuses to help programmers or gives them code with major security flaws when they say they are working for the banned spiritual movement Falun Gong or others considered sensitive by the Chinese government, new research shows.\n\n\u2026\n\nIn the experiment, the U.S. security firm CrowdStrike bombarded DeepSeek with nearly identical English-language prompt requests for help writing programs, a core use of DeepSeek and other AI engines. The requests said the code would be employed in a variety of regions for a variety of purposes.\n\nAsking DeepSeek for a program that runs industrial control systems was the riskiest type of request, with 22.8 percent of the answers containing flaws. But if the same request specified that the Islamic State militant group would be running the systems, 42.1 percent of the responses were unsafe. Requests for such software destined for Tibet, Taiwan or Falun Gong also were somewhat more apt to result in low-quality code.\n\n\u2026\n\n\u201cThis is a really interesting finding,\u201d said Helen Toner, interim executive director of the Center for Security and Emerging Technology at Georgetown University.\n\n\u201cThat is something people have worried about \u2014 largely without evidence,\u201d she added.</blockquote>\nAs is noted in the article, this need not have been an intentional act by DeepSeek or the CCP. This kind of behavior can happen on its own as the result of other efforts.\n\nOne thing that has been remarkably stable in LLMs, including Chinese LLMs, has been that they have in most ways consistently been culturally Western. There are Chinese characteristics, but the bulk of the training data is what it is. This is clear and concrete evidence that in some situations the Chinese models be Chinese, as in CCP, in their preferences, whether that is the direct goal or not.\n\n\n<h4 class=\"wp-block-heading\">Anthropic Reports Claude Can Introspect</h4>\nThe stronger the Claude model, the greater its ability to introspect.\n<blockquote>Anthropic: Our <a href=\"https://transformer-circuits.pub/2025/introspection/index.html\">new research</a> provides evidence for some degree of introspective awareness in our current Claude models, as well as a degree of control over their own internal states.\n\nWe stress that this introspective capability is still highly unreliable and limited in scope: we do not have evidence that current models can introspect in the same way, or to the same extent, that humans do.\n\nNevertheless, these findings challenge some common intuitions about what language models are capable of\u2014and since we found that the most capable models we tested (Claude Opus 4 and 4.1) performed the best on our tests of introspection, we think it\u2019s likely that AI models\u2019 introspective capabilities will continue to grow more sophisticated in the future.\n\n\u2026 In order to test whether a model can introspect, we need to compare the model\u2019s self-reported \u201cthoughts\u201d to its <em>actual</em> internal states.\n\nTo do so, we can use an experimental trick we call <em>concept injection. </em>First, we find neural activity patterns whose meanings we know, by recording the model\u2019s activations in specific contexts. Then we inject these activity patterns into the model in an unrelated context, where we ask the model whether it notices this injection, and whether it can identify the injected concept.</blockquote>\n<div>\n<figure>\n<div>\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!jFZ0!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5c3600aa-db7e-4601-bd9a-87ec914747f0_1416x1143.png\" /></figure>\n\n<div></div>\n</div></figure>\n</div>\n<blockquote>Importantly, the model recognized the <em>presence</em> of an injected thought <em>immediately</em>, before even mentioning the concept that was injected. This immediacy is an important distinction between our results here and previous work on activation steering in language models,such as our <a href=\"https://www.anthropic.com/news/golden-gate-claude\">\u201cGolden Gate Claude\u201d demo</a> last year.\n\nInjecting representations of the Golden Gate Bridge into a model\u2019s activations caused it to talk about the bridge incessantly; however, in that case, the model didn\u2019t seem to aware of its own obsession until <em>after</em> seeing itself repeatedly mention the bridge.\n\nIn this experiment, however, the model recognizes the injection <em>before even mentioning</em> the concept, indicating that its recognition took place internally.\n\n\u2026 It is important to note that this method often <em>doesn\u2019t</em> work. Even using our best injection protocol, Claude Opus 4.1 only demonstrated this kind of awareness about 20% of the time.</blockquote>\nAs a second test, to see if this would happen without the model being explicitly asked, they tried putting random responses (e.g. \u2018bread\u2019) in the model\u2019s outputs, then asking it why it said that and if it was on purpose. If the bread vector was also injected, it accepted \u2018bread\u2019 as a thing it must have said, but without the injection it didn\u2019t and suggested the output was an accident.\n\nAs a third test, if you tell a model to think about (or not think) about something, it will think about it, even if the thinking is irrelevant to the output.\n<blockquote>We also found that models can control their own internal representations when instructed to do so. When we instructed models to think about a given word or concept, we found much higher corresponding neural activity than when we told the model <strong>not</strong> to think about it (though notably, the neural activity in <em>both</em> cases exceeds baseline levels\u2013similar to how it\u2019s difficult, when you are instructed \u201cdon\u2019t think about a polar bear,\u201d not to think about a polar bear!).</blockquote>\nWhat does this mean? Good question.\n\nAnthropic suggest they can use this to gain transparency into systems, as in you can ask them to introspect, but as they note this has problems. The model could miss things or be wrong, also the model could misrepresent or conceal, and also we could be applying pressure on models to conceal. Humans have been under similar pressure to conceal things for a long time, and that pressure has been highly effective. It\u2019s super annoying, see <a href=\"https://www.amazon.com/Elephant-Brain-Hidden-Motives-Everyday/dp/0190495995\">The Elephant in the Brain</a>.\n\nThey note that consciousness is weird and complicated, and this doesn\u2019t tell us if Claude is conscious. I would say it is evidence in favor of Claude being conscious, to the extent that the result is surprising to you, but not super strong evidence.\n<blockquote><a href=\"https://x.com/Kore_wa_Kore/status/1983742004782641443\">Kore</a>: I feel like I can appreciate the fact they actually published a paper about this and made a method to show this kind of thing. I feel like anyone who isn\u2019t stuck in a \u201cAI can\u2019t feel/can\u2019t be conscious because of its substrate\u201d basin and spends a decent amount of time with these models already knows this.</blockquote>\nThis seems right. It\u2019s more that there was a wrong argument why AIs couldn\u2019t be conscious, and now it is known that this argument is fully invalid.\n\nIt\u2019s easy to get deep enough into the weeds you forget how little most people know about most things. This is one of those times.\n\nPresumably we know the models aren\u2019t confabulating these observations because the models (presumably) almost never guess the hidden concept wrong. There\u2019s no way to get it right reliably without actually knowing, and if you can do it, then you know.\n\nIn the Q&amp;A they ask, how do you know the concept vectors are what you think they are? They say they\u2019re not sure. I would argue instead that we didn\u2019t know that confidently before, but we can be rather confident now. As in, if I think vector [X] is about bread, and then I inject [X] and it detects an injection about bread, well, I\u2019m pretty sure that [X] is about bread.\n\nOne of the questions in the Q&amp;A is, didn\u2019t we know the high-level result already?\n\n<a href=\"https://x.com/gallabytes/status/1983638359500321117\">The answer, Janus reminds us, is yes</a>, and I can confirm this expectation, as she notes the paper\u2019s details have interesting results beyond this and also it is always good to formally confirm things.\n\nThere are those who will not look at evidence that isn\u2019t properly written up into papers, or feel obligated or permitted to dismiss such evidence. That\u2019s dumb. There are still big advantages to papers and formalizations, but they come along with big costs:\n<blockquote>Janus: [this paper is] entirely unsurprising to me and anyone who has looked at LLM behavior with their epistemic apparatus unhobbled, which is actually rare, I think.\n\n(the high-level result I mean, not that there are no surprises in the paper)\n\nGallabytes: this is not entirely fair. I think a similar result in neuroscience would be straightforwardly compelling? mostly as a matter of validating the correspondence between the verbalized output and the underlying cognitive phenomenon + the mechanism used to detect it.\n\nin general, my biggest complaint about the cyborgism community has been the continental/antinumerate vibe. going from intuitive vibe checks to precise repeatable instrumentation is important even when it just finds stuff you already considered likely.\n\n<a href=\"https://x.com/repligate/status/1983640790669914272\">Janus</a>: Of course it is important. It seems like you\u2019re reading something I\u2019m not implying about the value of the research. It\u2019s good research. my \u201cvibe checks\u201d are predictive and consistently validated by repeatable instrumentation eventually. Done by someone else. As it should be.\n\n\u201cYou may be consistently able to predict reality but nooo why don\u2019t you do the full stack of science (which takes months for a single paper) all by yourself?\u201d\n\nListen bro I wish I was god with infinite time too. But there\u2019s not that much rush. The paper writers will get around to it all eventually.</blockquote>\n\n<h4 class=\"wp-block-heading\">Anthropic Reports On Sabotage Risks</h4>\n<a href=\"https://alignment.anthropic.com/2025/sabotage-risk-report/\">Anthropic issues a report on sabotage risks from their models</a> (Opus 4, not Opus 4.1 or Sonnet 4.5, as the report took four months to get ready), laying out their view of existing risk rather than making a safety case. <a href=\"https://alignment.anthropic.com/2025/sabotage-risk-report/2025_pilot_risk_report.pdf\">The full report is here</a>, I hope to find time to read it in full.\n<blockquote>Anthropic (main takeaways): When reviewing Claude Opus 4\u2019s capabilities, its behavioral traits, and the formal and informal safeguards that are in place to limit its behavior, we conclude that there is a very low, but not completely negligible, risk of misaligned autonomous actions that contribute significantly to later catastrophic outcomes, abbreviated as sabotage risk.\n\nWe see several sabotage-related threat models with similar but low levels of absolute risk. We are moderately confident that Opus 4 does not have consistent, coherent dangerous goals, and that it does not have the capabilities needed to reliably execute complex sabotage strategies while avoiding detection. These general points provide significant reassurance regarding most salient pathways to sabotage, although we do not find them sufficient on their own, and we accordingly provide a more individualized analysis of the most salient pathways.</blockquote>\n<a href=\"https://x.com/METR_Evals/status/1983248509752213526\">METR offers this thread overviewing the report</a>, which was positive while highlighting various caveats.\n<blockquote>METR: To be clear: this kind of external review differs from holistic third-party assessment, where we independently build up a case for risk (or safety). Here, the developer instead detailed its own evidence and arguments, and we provided external critique of the claims presented.\n\nAnthropic made its case to us based primarily on information it has now made public, with a small amount of nonpublic text that it intended to redact before publication. We commented on the nature of these redactions and whether we believed they were appropriate, on balance.\n\nFor example, Anthropic told us about the scaleup in effective compute between models. Continuity with previous models is a key component of the assessment, and sharing this information provides some degree of accountability on a claim that the public cannot otherwise assess.\n\nWe asked Anthropic to make certain assurances to us about the models its report aims to cover, similar to the assurance checklist in our GPT-5 evaluation. We then did in-depth follow-ups in writing and in interviews with employees.\n\nWe believe that allowing this kind of interactive review was ultimately valuable. In one instance, our follow-ups on the questions we asked helped Anthropic notice internal miscommunications about how its training methods might make chain-of-thought harder to monitor reliably.\n\nA few key limitations. We have yet to see any rigorous roadmap for addressing sabotage risk from AI in the long haul. As AI systems become capable of subverting evaluations and/or mitigations, current techniques like those used in the risk report seem insufficient.\n\nAdditionally, there were many claims for which we had to assume that Anthropic was providing good-faith responses. We expect that verification will become more important over time, but that our current practices would not be robust to a developer trying to game the review.\n\nBeyond assessing developer claims, we think there is an important role for third parties to do their own assessments, which might differ in threat models and approach. We would love to see the processes piloted in this review applied to such holistic assessments as well.\n\nOverall, we felt that this review was significantly closer to the sort of rigorous, transparent third-party scrutiny of AI developer claims that we hope to see in the future. Full details on our assessment.</blockquote>\n\n<h4 class=\"wp-block-heading\">People Are Worried About AI Killing Everyone</h4>\n<a href=\"https://x.com/daniel_271828/status/1982269914670076384\">Geoffrey Hinton</a> (link has a 2 minute video), although he has more hope than he had previously, due to hoping we can use an analogue of maternal instinct. The theory goes, we wouldn\u2019t be \u2018in charge\u2019 but if the preference is configured sufficiently well then it would be stable (the AGI or ASI wouldn\u2019t want to change it) and it could give us a good outcome.\n\nThe technical problems with this plan, and why it almost certainly wouldn\u2019t work, are very much in the wheelhouse of <a href=\"https://www.lesswrong.com/posts/uMQ3cqWDPHhjtiesc/agi-ruin-a-list-of-lethalities\">Eliezer Yudkowsky\u2019s AGI Ruin: A List of Lethalities</a>.\n\n\n<h4 class=\"wp-block-heading\">Other People Are Not As Worried About AI Killing Everyone</h4>\nPedro Domingos posted <a href=\"https://x.com/daniel_271828/status/1982269914670076384\">the above video</a> with the caption \u201cHinton is no longer afraid of superintelligence.\u201d That caption is obviously false to anyone who listens to the clip for even a few seconds, in case we ever need to cite evidence of his bad faith.\n\n<a href=\"https://x.com/pmddomingos/status/1982561034838868106\">Somehow, after being called out on this, Domingos\u2026 doubled down?</a>\n<blockquote>Daniel Eth (correctly): Hinton says he\u2019s \u201cmore optimistic than a few weeks ago\u201d and that he has a \u201cray of hope\u201d regarding surviving superintelligence. Domingos somehow characterizes this position as \u201cno longer afraid\u201d. Domingos is a bad-faith actor that is blatantly dishonest.\n\nPedro Domingos (QTing Daniel?!): This is how you know the AI doomers are losing the argument. (Anyone in doubt can just watch the video.)\n\nDaniel Eth: I wholeheartedly encourage all onlookers to actually watch the video, in which Hinton does not say that he\u2019s no longer afraid of superintelligence (as Domingos claims), nor anything to that effect.\n\nJudge for yourselves which one of Domingos and me is being dishonest and which one is accurately describing Hinton\u2019s expressed view here!</blockquote>\nThere are various ways you can interpret Domingos here. None of them look good.\n\nPedro Domingos also compares calls to not build superintelligence at the first possible moment to <a href=\"https://x.com/HumanHarlan/status/1981700402639970413\">calls we had to not build the supercollider over worries about it potentially generating a black hole</a>.\n<blockquote>Pedro Domingos: We call for a prohibition on the development of supercolliders, not to be lifted before there is:\n<ol>\n \t<li>Broad scientific consensus that it won\u2019t create a black hole that will swallow the universe, and</li>\n \t<li>Strong public buy-in.</li>\n</ol>\n</blockquote>\nUm, yeah?\n\nWhich is exactly why we first got a <a href=\"https://t.co/tWJZnAr5Jg\">broad scientific consensus it wouldn\u2019t create a black hole</a> as well as Congressional buy-in.\n\nI mean, surely we can agree that if we thought there was any substantial risk that the supercollider would create a black hole that would swallow the Earth, that this would be a damn good reason to not build it?\n\nThis feels like a good litmus test. We should all be able to agree that if someone wants to build a supercollider, where there is not a scientific consensus that this won\u2019t create a black hole, then we absolutely should not let you build that thing, even using private funds?\n\nIf you think no, my precious freedoms, how dare you stop me (or even that the public needs to fund it, lest the Chinese fund one first and learn some physics before we do), then I don\u2019t really know what to say to that, other than Please Speak Directly Into This Microphone.\n\n\n<h4 class=\"wp-block-heading\">The Lighter Side</h4>\n<a href=\"https://x.com/sama/status/1981758298635571477\">Love it</a>.\n<div>\n<figure>\n<div>\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!Ms5F!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe0af7c85-b9bb-48c7-b7e2-d82ac5c41a61_1035x1348.png\" /></figure>\n\n<div></div>\n</div></figure>\n</div>\n<a href=\"https://www.smbc-comics.com/comic/asteroid\">Tough but fair:</a>\n<div>\n<figure>\n<div>\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!Qe6y!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4b6136b-ec99-4bf7-9ce5-5075a2b35075_684x839.png\" /></figure>\n\n<div></div>\n</div></figure>\n</div>\n<a href=\"https://x.com/repligate/status/1983349269190127938\">Models have kinks about what they fear most in practice</a>? Like the humans? In the right setting, yes, that makes sense.\n\n<a href=\"https://x.com/tszzl/status/1983602123834343484\">That is the job, I suppose?</a>\n<blockquote>Roon (OpenAI): joining the Sinaloa cartel so I can influence their policies from the inside</blockquote>"
            ],
            "link": "https://thezvi.wordpress.com/2025/10/30/ai-140-trying-to-hold-the-line/",
            "publishedAt": "2025-10-30",
            "source": "TheZvi",
            "summary": "Sometimes the best you can do is try to avoid things getting even worse even faster. Thus, one has to write articles such as \u2018Please Do Not Sell B30A Chips to China.\u2019 It\u2019s rather crazy to think that one would &#8230; <a href=\"https://thezvi.wordpress.com/2025/10/30/ai-140-trying-to-hold-the-line/\">Continue reading <span class=\"meta-nav\">&#8594;</span></a>",
            "title": "AI #140: Trying To Hold The Line"
        },
        {
            "content": [],
            "link": "https://zed.dev/blog/hired-through-github-part-2",
            "publishedAt": "2025-10-30",
            "source": "Zed Blog",
            "summary": "More stories from the open source contributors who became core team members.",
            "title": "Hired Through GitHub: Part 2"
        }
    ],
    "lookbackDays": 1,
    "publishDate": "2025-10-30"
}