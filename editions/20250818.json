{
    "articles": [
        {
            "content": [
                "<p>This is the weekly visible open thread. Post about anything you want, ask random questions, whatever. ACX has an unofficial <a href=\"https://www.reddit.com/r/slatestarcodex/\">subreddit</a>, <a href=\"https://discord.gg/RTKtdut\">Discord</a>, and <a href=\"https://www.datasecretslox.com/index.php\">bulletin board</a>, and <a href=\"https://www.lesswrong.com/community?filters%5B0%5D=SSC\">in-person meetups around the world</a>. Most content is free, some is subscriber only; you can subscribe <strong><a href=\"https://astralcodexten.substack.com/subscribe\">here</a></strong>. Also:</p><div><hr /></div><p><strong>1: </strong>Thanks to everyone who applied to ACX Grants. I still hope to inform winners by October 1. This remains a goal but not a promise.</p><p><strong>2: </strong>I am wondering about the prevalence of a certain thing and would like to run a survey on it. But if I tell you what it is, then there will be selection bias, since people involved with the thing will be more likely to take a survey about it. So please decide whether you feel like taking a survey, and if so <a href=\"https://forms.gle/5jVuToiYh4hcjnmy5\">take this one</a>. Once you click on the link you&#8217;re committed to taking it whether you think it&#8217;s relevant to you or not, and you can&#8217;t tell anyone else what it&#8217;s about. Don&#8217;t worry, it will take less than five minutes, maybe less than one minute if it&#8217;s not relevant to you. Yes, I am aware that selection bias is still possible, and I have some hare-brained plans to get around it.</p><p><strong>3: </strong>Thanks to everyone who posted comments on <a href=\"https://www.astralcodexten.com/p/your-review-dating-men-in-the-bay\">the dating review</a> (except for people who posted bad comments, who I have banned). I think the prize for the most ACX-stereotype-fulfilling response is <a href=\"https://x.com/arundsharma/status/1956510644167192743\">this person who is using it as an AI benchmark</a>. Since there was a spirited debate about the author, I&#8217;ve created a prediction market <a href=\"https://manifold.markets/ScottAlexander/dating-men-in-sf-acx-review-written\">here</a>.</p><p><strong>4: </strong>Thanks to everyone who posted comments on <a href=\"https://www.astralcodexten.com/p/in-defense-of-the-amyloid-hypothesis\">the amyloid review</a>. Chris Strutheo has created a prediction market <a href=\"https://manifold.markets/strutheo/will-david-schneiderjosephs-bet-abo\">here</a> about whether the author&#8217;s bet will pan out. This time the most ACX-stereotype-fulfilling response is the nominative determinism angle:</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2\" href=\"https://substackcdn.com/image/fetch/$s_!Kb-7!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F25e2b3e7-0869-47a0-acf7-ccc1a036ec01_1309x537.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"217.42551566080976\" src=\"https://substackcdn.com/image/fetch/$s_!Kb-7!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F25e2b3e7-0869-47a0-acf7-ccc1a036ec01_1309x537.png\" width=\"530\" /><div></div></div></a></figure></div><p></p>"
            ],
            "link": "https://www.astralcodexten.com/p/open-thread-395",
            "publishedAt": "2025-08-18",
            "source": "SlateStarCodex",
            "summary": "<p>This is the weekly visible open thread. Post about anything you want, ask random questions, whatever. ACX has an unofficial <a href=\"https://www.reddit.com/r/slatestarcodex/\">subreddit</a>, <a href=\"https://discord.gg/RTKtdut\">Discord</a>, and <a href=\"https://www.datasecretslox.com/index.php\">bulletin board</a>, and <a href=\"https://www.lesswrong.com/community?filters%5B0%5D=SSC\">in-person meetups around the world</a>. Most content is free, some is subscriber only; you can subscribe <strong><a href=\"https://astralcodexten.substack.com/subscribe\">here</a></strong>. Also:</p><div><hr /></div><p><strong>1: </strong>Thanks to everyone who applied to ACX Grants. I still hope to inform winners by October 1. This remains a goal but not a promise.</p><p><strong>2: </strong>I am wondering about the prevalence of a certain thing and would like to run a survey on it. But if I tell you what it is, then there will be selection bias, since people involved with the thing will be more likely to take a survey about it. So please decide whether you feel like taking a survey, and if so <a href=\"https://forms.gle/5jVuToiYh4hcjnmy5\">take this one</a>. Once you click on the link you&#8217;re committed to taking it whether you think it&#8217;s relevant to you or not, and you can&#8217;t tell anyone else what it&#8217;s about. Don&#8217;t worry, it will take less than five minutes, maybe less than one minute if it&#8217;s not relevant to you. Yes, I am aware that selection bias is still possible,",
            "title": "Open Thread 395"
        },
        {
            "content": [
                "<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!if9g!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2e752c67-72c2-46cd-b977-fa9e5e19cda5_1536x1024.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>Everyone agrees that the release of GPT-5 was botched. Everyone can also agree that the direct jump from GPT-4o and o3 to GPT-5 was not of similar size to the jump from GPT-3 to GPT-4, that it was not the direct quantum leap we were hoping for, and that the release was overhyped quite a bit.</p>\n<p>GPT-5 still represented the release of at least three distinct models: GPT-5-Fast, GPT-5-Thinking and GPT-5-Pro, at least two and likely all three of which are SoTA (state of the art) within their class, along with GPT-5-Auto.</p>\n<p>The problem is that the release was so botched that OpenAI is now experiencing a Reverse DeepSeek Moment &#8211; all the forces that caused us to overreact to DeepSeek\u2019s r1 are now working against OpenAI in reverse.</p>\n<div>\n\n\n<span id=\"more-24657\"></span>\n\n\n</div>\n<p>This threatens to give Washington DC and its key decision makers a very false impression of a lack of AI progress, especially progress towards AGI, that could lead to some very poor decisions, and it could do the same for corporations and individuals.</p>\n<p><a href=\"https://thezvi.substack.com/p/gpt-5s-are-alive-outside-reactions?r=67wny\"><strong>I spent</strong></a> <a href=\"https://thezvi.substack.com/publish/posts/detail/170709047?referrer=%2Fpublish%2Fposts%2Fpublished\"><strong>last week covering</strong></a> <a href=\"https://thezvi.substack.com/publish/posts/detail/170467419?referrer=%2Fpublish%2Fposts%2Fpublished\"><strong>the release of GPT-5</strong></a>. This puts GPT-5 in perspective.</p>\n\n\n<h4 class=\"wp-block-heading\">GPT-5: The Reverse DeepSeek Moment</h4>\n\n\n<p>In January DeepSeek released r1, and <a href=\"https://thezvi.substack.com/p/deepseek-r1-0528-did-not-have-a-moment\">we had a \u2018DeepSeek moment</a>\u2019 when everyone panicked about how China had \u2018caught up.\u2019 <a href=\"https://thezvi.substack.com/i/165339410/we-had-a-moment\">As the link explains</a> in more detail, r1 was a good model, sir, but only an ordinary good model, substantially behind the frontier.</p>\n<p>We had the DeepSeek Moment because of a confluence of factors misled people:</p>\n<ol>\n<li>The \u2018<a href=\"https://thezvi.substack.com/p/deekseek-v3-the-six-million-dollar\">six million dollar model</a>\u2019 narrative gave a false impression on cost.</li>\n<li>They offered a good clean app with visible chain of thought, it went viral.</li>\n<li>The new style caused an overestimate of model quality.</li>\n<li>Timing was impeccable, both in order of model releases and within the tech tree.</li>\n<li>Safety testing and other steps were skipped, leaving various flaws, and this was a pure fast follow, but in our haste no one took any of that into account.</li>\n<li>A false impression of \u2018momentum\u2019 and stories about Chinese momentum.</li>\n<li>The \u2018always insist open models will win\u2019 crowd amplified the vibes.</li>\n<li>The stock market was highly lacking in situational awareness, suddenly realizing various known facts and also misunderstanding many important factors.</li>\n</ol>\n<p>GPT-5 is now having a Reverse DeepSeek Moment, including many direct parallels.</p>\n<ol>\n<li>GPT-5 is evaluated as if it was scaling up compute in a way that it doesn\u2019t. In various ways people are assuming it \u2018cost\u2019 far more than it did.</li>\n<li>They offered a poor initial experience with rate caps and lost models and missing features, a broken router, and complaints about losing 4o\u2019s sycophancy went viral.</li>\n<li>The new style, and people evaluating GPT-5 when they should have been evaluating GPT-5-Thinking, caused an underestimate of model quality.</li>\n<li>Timing was directly after Anthropic, and previous releases had already eaten the most impressive recent parts of the tech tree, so gains incorrectly looked small.\n<ol>\n<li>In particular, gains from reasoning models, and from the original GPT-4 \u2192 GPT-4o, are being ignored when considering the GPT-4 \u2192 GPT-5 leap.</li>\n</ol>\n</li>\n<li>GPT-5 is a refinement of previous models optimized for efficiency, and is breaking new territory, and that is not being taken into account.</li>\n<li>A false impression of hype and a story about a loss of momentum.</li>\n<li>The \u2018OpenAI is flailing\u2019 crowd and the open model crowd amplified the vibes.</li>\n<li>The stock market actually was smart this time and shrugged it off, that\u2019s a hint.</li>\n</ol>\n<p>Unlike r1 at the time of its release, GPT-5-Thinking and GPT-5-Pro are clearly the current SoTA models in their classes, and GPT-5-Auto is probably SoTA at its level of compute usage, modulo complaints about personality that OpenAI will doubtless \u2018fix\u2019 soon.</p>\n<p>OpenAI\u2019s model usage was way up after GPT-5\u2019s release, not down.</p>\n<p>The release was botched, but this is very obviously a good set of models.</p>\n<p>Washington DC, however, is somehow rapidly deciding that GPT-5 is a failure, and that AI capabilities won\u2019t improve much and AGI is no longer a worry. This is presumably in large part due to the \u2018race to market share\u2019 faction pushing this narrative rather hardcore, and having this be super convenient for that.</p>\n<blockquote><p><a href=\"https://x.com/David_Kasten/status/1957221177283264604\">Dave Kasten</a>: It\u2019s honestly fascinating how widely \u201cwhat is gonna happen now that GPT-5 is a failure\u201d has already percolated in the DC world \u2014 tons of people who barely use AI asking me about this in the past week as their AI policy friend. (I don\u2019t think GPT-5 was a failure)</p>\n<p>Stylized anecdote: person tells me they aren&#8217;t allowed to use LLM Y at job ABC because regulatory considerations. So they only use LLM Z at home because that&#8217;s what they started to use first and don&#8217;t have much experience on Y.</p>\n<p>(This is true in both private and public sector)</p>\n<p><a href=\"https://x.com/daniel_271828/status/1957254189077381448\">Daniel Eth</a>: So what happens when another lab releases a model that surpasses GPT-5? Narrative could quickly change from \u201cAI is hitting a wall\u201d to \u201cOpenAI has lost the Mandate of Heaven, and it\u2019s shifted to [Anthropic/DeepMind/xAI]\u201d</p>\n<p>Honestly that probably makes the near future a particularly valuable time for another lab to release a SOTA model.</p></blockquote>\n<p>What is even scarier is, what happens if DeepSeek drops r2, and it\u2019s not as good as GPT-5-Thinking, but it is \u2018pretty good\u2019?</p>\n<p>So let us be clear: (American) AI is making rapid progress, including at OpenAI.</p>\n\n\n<h4 class=\"wp-block-heading\">Did You Know AI Is Making Rapid Progress?</h4>\n\n\n<p>How much progress have we been making?</p>\n<blockquote><p><a href=\"https://x.com/deanwball/status/1956456797159506157\">Dean Ball</a>: The jump in the performance and utility of frontier models between April 2024 (eg gpt-4 turbo) and April 2025 (o3) is bigger than the jump between gpt-3 and gpt-4</p>\n<p>People alleging a slowdown in progress due to gpt-5 are fooling themselves.</p>\n<p><a href=\"https://x.com/Simeon_Cps/status/1956519485277684219\">Simeon</a>: I have this theory that we are in a period of increasing marginal utility of capabilities. GPT-2 to GPT-3 jump was a bigger jump than 3 to 4, which was bigger than 4 to 5. But the utility jumps have been increasing.</p>\n<p>My core thesis for why is that most use cases are bottlenecked by edge cases and 9s of reliability that are not as visible as the raw capabilities, but that unlock a growing set of use cases all bottlenecked by these same few missing pieces.</p></blockquote>\n<p>This is only one measure among many, from Artificial Analysis (there is much it doesn\u2019t take into account, which is why Gemini Pro 2.5 looks so good), yes GPT-5 is a relatively small advance despite being called GPT-5 but that is because o1 and o3 already covered a lot of ground, it\u2019s not like the GPT-4 \u2192 GPT-5 jump isn\u2019t very big.</p>\n<blockquote><p><a href=\"https://x.com/scaling01/status/1957168153202761740\">Lisan al-Gaib:</a> AI Progress since GPT-3.5</p>\n<p>OpenAI seems to be slowing down with GPT-5</p>\n<p>Anthropic incredibly steady progress</p>\n<p>Google had it&#8217;s breakthrough with Gemini 2.5 Pro</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!gxiP!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2a071a8a-5b20-499e-be47-90c9258792e8_1200x740.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>based on the Artificial Analysis Index. don&#8217;t read to much into the numbers just look at the slope. line going up = good line. going up more steeply=better.</p></blockquote>\n<p>AI is making rapid progress. It keeps getting better. We seem headed for AGI.</p>\n<p>Yet people continuously try to deny all of that. And because this could impact key policy, investment and life decisions, each time we must respond.</p>\n\n\n<h4 class=\"wp-block-heading\">No We Are Not Yet Hitting A Wall</h4>\n\n\n<p>As in, the Financial Times asks the eternal question we somehow have to ask every few months: <a href=\"https://www.ft.com/content/d01290c9-cc92-4c1f-bd70-ac332cd40f94\">Is AI \u2018hitting a wall\u2019</a>?</p>\n<p><a href=\"https://chatgpt.com/share/68a32827-a170-8002-b9af-cdbcde71de24\">(For fun, here is GPT-5-Pro listing many previous times AI supposedly \u2018hit a wall.\u2019)</a></p>\n<p><a href=\"https://arxiv.org/abs/1801.00631\">If</a> <a href=\"https://arxiv.org/abs/2007.05558\">you</a> <a href=\"https://arxiv.org/abs/2104.12871\">would</a><a href=\"https://nautil.us/deep-learning-is-hitting-a-wall-238440/\"> like</a> <a href=\"https://epoch.ai/blog/will-we-run-out-of-ml-data-evidence-from-projecting-dataset\">links</a>, <a href=\"https://techxplore.com/news/2024-06-ai-gold-chatbot-human-written.html\">here</a> <a href=\"https://time.com/7006382/ai-training-data-oil/\">are</a> <a href=\"https://www.wsj.com/tech/ai/the-ai-revolution-is-already-losing-steam-a93478b1\">some</a> <a href=\"https://www.sequoiacap.com/article/inference-18/\">links</a> <a href=\"https://www.businessinsider.com/meta-yann-lecun-scaling-ai-wont-make-it-smarter-2025-4\">for</a> <a href=\"https://www.businessinsider.com/cohere-ceo-aiden-gomez-ai-race-meta-openai-microsoft-2024-8\">all</a> <a href=\"https://www.reuters.com/technology/artificial-intelligence/openai-rivals-seek-new-path-smarter-ai-current-methods-hit-limitations-2024-11-11/\">that</a>.</p>\n<p><a href=\"https://www.economist.com/interactive/ (Economist cover story: \u201cTwo years after ChatGPT\u2026 hit a roadblock\u201d)\">The</a> <a href=\"https://www.vox.com/future-perfect/389997/artificial-intelligence-openai-google-microsoft-chatgpt-progress-scaling\">justification</a> <a href=\"https://time.com/7178328/is-ai-progress-slowing-down/\">for</a> <a href=\"https://spectrum.ieee.org/chain-of-thought-prompting\">this</a> <a href=\"https://www.ft.com/content/d01290c9-cc92-4c1f-bd70-ac332cd40f94\">supposed</a> <a href=\"https://www.washingtonpost.com/technology/2025/08/17/openai-gpt5-chatgpt-superintelligence/\">hitting</a> <a href=\"https://www.newyorker.com/news/the-financial-page/is-the-ai-boom-turning-into-an-ai-bubble\">of</a> <a href=\"https://www.theguardian.com/technology/2025/jan/09/elon-musk-data-ai-training-artificial-intelligence\">a</a> <a href=\"https://stratechery.com/2024/microsoft-ignite-satya-nadella-and-kevin-scott-interview/\">wall</a> <a href=\"https://stratechery.com/2024/the-genai-bridge-to-the-future/\">is</a> <a href=\"https://www.businessinsider.com/generative-ai-wall-scaling-laws-training-data-chatgpt-gemini-claude-2024-11\">even</a> stupider than usual.</p>\n<blockquote><p>FT (Various): \u201cThe vibes of this model are really good, and I think that people are really going to feel that,\u201d said Nick Turley, head of ChatGPT at OpenAI.</p>\n<p>Except the vibes were not good.</p></blockquote>\n<p>Yes, users wanted GPT-4o\u2019s sycophancy back, and they even got it. What does that have to do with a wall? They do then present the actual argument.</p>\n<blockquote><p>FT: \u201cFor GPT-5\u2009.\u2009.\u2009.\u2009people expected to discover something totally new,\u201d says Thomas Wolf, co-founder and chief scientific officer of open source AI start-up Hugging Face. \u201cAnd here we didn\u2019t really have that.\u201d</p></blockquote>\n<p>True. We didn\u2019t get something totally new. But, again, that was OpenAI:</p>\n<ol>\n<li>Botching the rollout.</li>\n<li>Using the name GPT-5.</li>\n<li>Having made many incremental releases since GPT-4, especially 4o, o1 and o3.</li>\n</ol>\n<p>They hit the classic notes.</p>\n<p>We have Gary Marcus talking about this being a \u2018central icon of the entire scaling approach to get to AGI, and it didn\u2019t work,\u2019 so if this particular scaling effort wasn\u2019t impressive we\u2019re done, no more useful scaling ever.</p>\n<p>We have the harkening back to the 1980s \u2018AI bubble\u2019 that \u2018burst.\u2019</p>\n<p>My lord, somehow they are still quoting Yann LeCun.</p>\n<p>We have warnings that we have run out of capacity with which to scale. We haven\u2019t.</p>\n<p>Their best point is this Altman quote I hadn\u2019t seen:</p>\n<blockquote><p>Sam Altman: [Chatbots like ChatGPT] are not going to get much better.</p></blockquote>\n<p>I believe he meant that in the \u2018for ordinary casual chat purposes there isn\u2019t much room for improvement left\u2019 sense, and that this is contrasting mass consumer chatbots with other AI applications, including coding and agents and reasoning models, as evidenced by the other half of the quote:</p>\n<blockquote><p>Sam Altman: [AI models are] still getting better at a rapid rate.</p></blockquote>\n<p>That is the part that matters for AGI.</p>\n<p>That doesn\u2019t mean we will get to AGI and then ASI soon, where soon is something like \u2018within 2-10 years.\u2019 It is possible things will stall out before that point, perhaps even indefinitely. But \u2018we know we won\u2019t get AGI any time soon\u2019 is crazy. And \u2018last month I thought we might well get AGI anytime soon but now we know we won\u2019t\u2019 is even crazier.</p>\n<p>Alas, a variety of people are reacting to GPT-5 being underwhelming on the margin, the rapid set of incremental AI improvements, and the general fact that we haven\u2019t gotten AGI yet, and reached the conclusion that Nothing Ever Changes applies and we can assume that AGI will never come. That would be a very serious mistake.</p>\n<p><a href=\"https://x.com/Miles_Brundage/status/1956777848523641016\">Miles Brundage, partly to try and counter and make up for the FT article and his inadvertent role in it, does a six minute rant</a> explaining one reason for different perceptions of AI progress. The key insight here is that AI at any given speed and cost and level of public availability continues to make steady progress, but rates of that progress look very different depending on what you are comparing. Progress looks a progressively faster if you are looking at Thinking-style models, or Pro-style models, or internal-only even more expensive models.</p>\n\n\n<h4 class=\"wp-block-heading\">Models Making Money And Being Useful Does Not Mean Less Progress</h4>\n\n\n<p>Progress in the rapid models like GPT-5-Fast also looks slower than it is because for the particular purposes of many users at current margins, it is true that intelligence is no longer an important limiting factor. Simple questions and interactions often have \u2018correct\u2019 answers if you only think about the local myopic goals, so all you can do is asymptotically approach that answer while optimizing on compute and speed. Intelligence still helps but in ways that are less common, more subtle and harder to notice.</p>\n<p>One reason people update against AGI soon is that they treat OpenAI\u2019s recent decisions as reflecting AGI not coming soon. It\u2019s easy to see why one would think that.</p>\n<blockquote><p><a href=\"https://x.com/CharlesD353/status/1955560634118005243\">Charles:</a> It seems to me like OpenAI&#8217;s behaviour recently, steering more towards becoming a consumer company rather than trying to build AGI, is incongruent with them believing in AGI/significant worker displacement coming soon (say &lt;5 years).</p>\n<p>Do others disagree with me on this?</p>\n<p>Anthropic on the other hand do seem to be behaving in a way consistent with believing in AGI coming soon.</p>\n<p><a href=\"https://x.com/ns123abc/status/1956364341839569009\">Sam Altman</a>: We had this big GPU crunch. We could go make another giant model. We could go make that, and a lot of people would want to use it, and we would disappoint them. And so we said, let\u2019s make a really smart, really useful model, but also let\u2019s try to optimize for inference cost. And I think we did a great job with that.</p></blockquote>\n<p>I am not going to say they did a \u2018great job with that.\u2019 They botched the rollout, and I find GPT-5-Auto (the model in question) to not be exciting especially for my purposes, but it does seem to clearly be on the cost-benefit frontier, as are 5-Thinking and 5-Pro? And when people say things like this:</p>\n<blockquote><p>FT: Rather than being markedly inferior, GPT-5\u2019s performance was consistently mid-tier across different tasks, they found. \u201cThe place where it really shines is it\u2019s quite cost effective and also much quicker than other models,\u201d says Kapoor.</p></blockquote>\n<p>They are talking about GPT-5-Auto, the version targeted at the common user. So of course that is what they created for that.</p>\n<p>OpenAI rightfully thinks of itself as essentially multiple companies. They are an AI frontier research lab, and also a consumer product company, and a corporate or professional product company, and also looking to be a hardware company.</p>\n<p>Most of those customers want to pay $0, at least until you make yourself indispensable. Most of the rest are willing to pay $20/month and not interested in paying more. You want to keep control over this consumer market at Kleenex or Google levels of dominance, and you want to turn a profit.</p>\n<p>So of course, yes, you are largely prioritizing for what you can serve your customers.</p>\n<p>What are you supposed to do, not better serve your customers at lower cost?</p>\n<p>That doesn\u2019t mean you are not also creating more expensive and smarter models. Thinking and Pro exist, and they are both available and quite good. Other internal models exist and by all reports are better if you disregard cost and don\u2019t mind rough around the edges.</p>\n<blockquote><p>FT: It may not have been OpenAI\u2019s intention, but what the launch of GPT-5 makes clear is that the nature of the AI race has changed.</p>\n<p>Instead of merely building shiny bigger models, says Sayash Kapoor, a researcher at Princeton University, AI companies are \u201cslowly coming to terms with the fact that they are building infrastructure for products\u201d.</p></blockquote>\n<p>There is an ordinary battle for revenue and market share and so on that looks like every other battle for revenue and market share. And yes, of course when you have a product with high demand you are going to build out a bunch of infrastructure.</p>\n<p>That has nothing to do with the more impactful \u2018race\u2019 to AGI. The word \u2018race\u2019 has simply been repurposed and conflated by such folks in order to push their agenda and rhetoric in which the business of America is to be that of ordinary private business.</p>\n<blockquote><p>Miles Brundage (from the FT article): It makes sense that as AI gets applied in a lot of useful ways, people would focus more on the applications versus more abstract ideas like AGI.</p>\n<p>But it\u2019s important to not lose sight of the fact that these are indeed extremely general purpose technologies that are still proceeding very rapidly, and that what we see today is still very limited compared to what\u2019s coming.</p></blockquote>\n<p>Initially FT used only the first sentence from Miles and not the second one, which is very much within <a href=\"https://thezvi.substack.com/p/how-to-bounded-distrust\">Bounded Distrust</a> rules but very clearly misleading, but to their credit FT did then fix it to add the full quote although most clicks will have seen the misleading version.</p>\n<blockquote><p><a href=\"https://x.com/Miles_Brundage/status/1956488256843059583\">Miles Brundage</a>: I thought it was clear that the first sentence was just me being diplomatic and \u201cthroat clearing\u201d rather than a full expression of my take on the topic, but lesson learned!</p>\n<p><a href=\"https://x.com/nickcammarata/status/1956491402231062818\">Nick Cammarata</a>: I\u2019ve talked to reporters and then directly after finishing my sentence I\u2019m like can you only quote that in full if you do and they\u2019re like no lol</p></blockquote>\n<p>It is crazy to site \u2018companies are Doing Business\u2019 as an argument for why they are no longer building or racing to AGI, or why that means what matters is the ordinary Doing of Business. Yes, of course companies are buying up inference compute to sell at a profit. Yes, of course they are building marketing departments and helping customers with deployment and so on. Why shouldn\u2019t they? Why would one consider this an either-or? Why would you think AI being profitable to sell makes it less likely that AGI is coming soon, rather than more likely?</p>\n<blockquote><p>FT: GPT-5 may have underwhelmed but with Silicon Valley running more on \u201cvibes\u201d than scientific benchmarks, there are few indications that the AI music will stop anytime soon. \u201cThere\u2019s still a lot of cool stuff to build,\u201d Wolf of Hugging Face says, \u201ceven if it\u2019s not AGI or crazy superintelligence [ASI].\u201d</p></blockquote>\n<p>That is, as stated, exactly correct from Wolf. There is tons of cool stuff to build that is not AGI or ASI. Indeed I would love it if we built all that other cool stuff and mysteriously failed to build AGI or ASI. But that cool stuff doesn\u2019t make it less likely we get AGI, nor does not looking at the top labs racing to AGI, and having this as their stated goal, make that part of the situation go away.</p>\n<p>As a reminder, OpenAI several times during their GPT-5 presentation talked about how they were making progress towards AGI or superintelligence, and how this remained the company\u2019s primary goal.</p>\n<p>Mark Zuckerberg once said about Facebook, \u2018we don\u2019t make better services to make money. We make money to make better services.\u2019 Mark simply has a very strange opinion on what constitutes better services. Consider that the same applies here.</p>\n<p>Also note that we are now at the point where if you created a truly exceptional coding and research model, and you are already able to raise capital on great terms, it is not at all obvious you should be in a rush to release your coding and research model. Why would you hand that tool to your competitors?</p>\n<p>As in, not only does it help them via distillation and reverse engineering, it also directly can be put to work. Anthropic putting out Claude Code gave them a ton more revenue and market share and valuation, and thus vital capital and mindshare, and helps them recruit, but there was a nontrivial price to pay that their rivals get to use the product.</p>\n\n\n<h4 class=\"wp-block-heading\">We Could Massively Screw This All Up</h4>\n\n\n<p>One huge problem with this false perception that GPT-5 failed, or that AI capabilities aren\u2019t going to improve, and that AGI can now be ignored as a possibility, <a href=\"https://www.ft.com/content/d01290c9-cc92-4c1f-bd70-ac332cd40f94\">is that this could actually fool the government into ignoring that possibility</a>.</p>\n<blockquote><p>Peter Wildeford:<img alt=\"\ud83e\udd26\u200d\u2642\ufe0f\" class=\"wp-smiley\" src=\"https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f926-200d-2642-fe0f.png\" style=\"height: 1em;\" /></p></blockquote>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!a9xv!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63094ecc-a309-4066-af4b-08a992030ebf_1199x687.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>Not only would that mean we wouldn\u2019t prepare for what is coming, the resulting decisions would make things vastly worse. As in, after quoting David Sacks saying the same thing he\u2019s been saying ever since he joined the administration, and noting recent disastrous decisions on the H20 chip, we see this:</p>\n<blockquote><p>FT: Analysts say that with AGI no longer considered a risk, Washington\u2019s focus has switched to ensuring that US-made AI chips and models rule the world.</p></blockquote>\n<p>Even if we disregard the turn of of phrase here &#8211; \u2018AI chips and models rule the world\u2019 is exactly the scenario some of us are warning about and trying to prevent, and those chips and models having been created by Americans does not mean Americans or humans have a say in what happens next, instead we would probably all die &#8211; pursuing chip market share uber alles with a side of model market share was already this administration\u2019s claimed priority months ago.</p>\n<p>We didn\u2019t strike the UAE deal because GPT-5 disappointed. We didn\u2019t have Sacks talking endlessly about an \u2018AI race\u2019 purely in terms of market share &#8211; mostly that of Nvidia &#8211; because GPT-5 disappointed. Causation doesn\u2019t run backwards in time. These are people who were already determined to go down this path. GPT-5 and its botched rollout is the latest talking point, but it changes nothing.</p>\n<p>In brief, I once again notice that the best way to run Chinese AI models, or to train Chinese AI models is to use American AI chips. <a href=\"https://x.com/StefanFSchubert/status/1955893320024047628\">Why haven\u2019t we seen</a> <a href=\"https://www.ft.com/content/eb984646-6320-4bfe-a78d-a1da2274b092\">DeepSeek release v4 or r2 yet</a>? Because the CCP made them use Huawei Ascend chips and it didn\u2019t work. What matters is who owns and uses the compute, not who manufactures the compute.</p>\n<p>But that is an argument for another day. What matters here is that we not fool ourselves into a Reverse DeepSeek Moment, in three ways:</p>\n<ol>\n<li>America is still well out in front, innovating and making rapid progress in AI.</li>\n<li>AGI is still probably coming and we need to plan accordingly.</li>\n<li>Export controls on China are still vital.\n<p>&nbsp;</li>\n</ol>\n<p>&nbsp;</p>"
            ],
            "link": "https://thezvi.wordpress.com/2025/08/18/gpt-5-the-reverse-deepseek-moment/",
            "publishedAt": "2025-08-18",
            "source": "TheZvi",
            "summary": "Everyone agrees that the release of GPT-5 was botched. Everyone can also agree that the direct jump from GPT-4o and o3 to GPT-5 was not of similar size to the jump from GPT-3 to GPT-4, that it was not the &#8230; <a href=\"https://thezvi.wordpress.com/2025/08/18/gpt-5-the-reverse-deepseek-moment/\">Continue reading <span class=\"meta-nav\">&#8594;</span></a>",
            "title": "GPT-5: The Reverse DeepSeek Moment"
        },
        {
            "content": [],
            "link": "https://xkcd.com/3130/",
            "publishedAt": "2025-08-18",
            "source": "XKCD",
            "summary": "<img alt=\"I dropped my phone while trying to search, and I tried to unlock it from up here, so can you also search for screen repair places?\" src=\"https://imgs.xkcd.com/comics/predicament.png\" title=\"I dropped my phone while trying to search, and I tried to unlock it from up here, so can you also search for screen repair places?\" />",
            "title": "Predicament"
        }
    ],
    "lookbackDays": 1,
    "publishDate": "2025-08-18"
}