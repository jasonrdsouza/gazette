{
    "articles": [
        {
            "content": [
                "<p>I grew up alongside social media, as it was changing from nerd curiosity to mainstream culture.\nI\u00a0joined Twitter and Tumblr in the early 2010s, and I stayed there for over a decade.\nThose spaces shaped my adult life: I met friends and partners, found a career in cultural heritage, and discovered my queer identity.</p>\n\n<p>That impact will last a long time.\nThe posts themselves?\nNot so much.</p>\n\n<p>Social media is fragile, and it can disappear quickly.\nSites get <a href=\"https://arstechnica.com/tech-policy/2022/10/elon-musk-completes-twitter-purchase-immediately-fires-ceo-and-other-execs/\">sold</a>, <a href=\"https://web.archive.org/web/20240909195207/https://cohost.org/staff/post/7611443-cohost-to-shut-down\">shut down</a> or <a href=\"https://www.bbc.co.uk/news/articles/c4gzxv5gy3qo\">blocked</a>.\nPeople close their accounts or <a href=\"https://en.wikipedia.org/wiki/Mark_Pilgrim#%22Disappearance%22_from_the_Internet\">flee the Internet</a>.\nPosts get <a href=\"https://alexwlchan.net/2024/i-deleted-all-my-tweets/\">deleted</a>, <a href=\"https://www.theverge.com/2018/12/6/18127869/tumblr-livejournal-porn-ban-strikethrough\">censored</a> or <a href=\"https://www.bbc.co.uk/news/technology-47610936\">lost</a> by platforms that don\u2019t care about permanence.\nWe live in an era of abundant technology and storage, but the everyday record of our lives is disappearing before our eyes.</p>\n\n<p>I want to remember social media, and not just as a vague memory.\nI\u00a0want to remember exactly what I read, what I saw, what I wrote.\nIf I was born 50\u00a0years ago, I\u2019m the sort of person who\u2019d keep a scrapbook full of letters and postcards \u2013 physical traces of the people who mattered to me.\nToday, those traces are digital.</p>\n\n<p>I don\u2019t trust the Internet to remember for me, so I\u2019ve built my own scrapbook of social media.\nIt\u2019s a place where I can save the posts that shaped me, delighted me, or just stuck in my mind.</p>\n\n<figure>\n  \n\n<source type=\"image/png\" /><img alt=\"Four-columns of cards laid out, each with a coloured border and a snippet from a social media site. The screenshot includes tweets, photos, a some videos, and some art.\" class=\"screenshot\" src=\"https://alexwlchan.net/images/2025/social-media-scrapbook_1x.png\" width=\"750\" />\n\n\n  <figcaption>\n    Each conversation appears as a little card, almost like a clipping from a magazine or newspaper.\n    Most of my conversations are from Twitter, but I also have sites like Tumblr, YouTube, and Bluesky.\n  </figcaption>\n</figure>\n\n<p>It\u2019s a static site where I can save conversations from different services, enjoy them in my web browser, and search them using my own tags.\nIt\u2019s less than two years old, but it already feels more permanent than many social media sites.\nThis post is the first in a three-part series about preserving social media, based on both my professional and personal experience.</p>\n\n<blockquote class=\"table_of_contents\">\n  <h3>Table of contents</h3>\n\n  <ul>\n    \n      <li>\n        <a href=\"https://alexwlchan.net/2025/social-media-scrapbook/#the-long-road-to-a-lasting-archive\">The long road to a lasting archive</a>\n\n        \n      </li>\n      <li>\n        <a href=\"https://alexwlchan.net/2025/social-media-scrapbook/#how-it-works\">How it works</a>\n\n        \n          <ul>\n            \n            <li><a href=\"https://alexwlchan.net/2025/social-media-scrapbook/#a-static-site-viewed-in-the-browser\">A static site, viewed in the browser</a></li>\n            \n            <li><a href=\"https://alexwlchan.net/2025/social-media-scrapbook/#conversations-as-the-unit-of-storage\">Conversations as the unit of storage</a></li>\n            \n            <li><a href=\"https://alexwlchan.net/2025/social-media-scrapbook/#a-different-data-model-and-renderer-for-each-site\">A different data model and renderer for each site</a></li>\n            \n            <li><a href=\"https://alexwlchan.net/2025/social-media-scrapbook/#keyword-tagging-on-every-conversation\">Keyword tagging on every conversation</a></li>\n            \n            <li><a href=\"https://alexwlchan.net/2025/social-media-scrapbook/#metadata-in-jsonjavascript-interpreted-as-a-graph\">Metadata in JSON/JavaScript, interpreted as a graph</a></li>\n            \n            <li><a href=\"https://alexwlchan.net/2025/social-media-scrapbook/#a-large-suite-of-tests\">A large suite of tests</a></li>\n            \n          </ul>\n        \n      </li>\n      <li>\n        <a href=\"https://alexwlchan.net/2025/social-media-scrapbook/#inspirations-and-influences\">Inspirations and influences</a>\n\n        \n          <ul>\n            \n            <li><a href=\"https://alexwlchan.net/2025/social-media-scrapbook/#the-static-website-in-twitters-first-party-archives\">The static website in Twitter\u2019s first-party archives</a></li>\n            \n            <li><a href=\"https://alexwlchan.net/2025/social-media-scrapbook/#data-lifeboat-at-the-flickr-foundation\">Data Lifeboat at the Flickr Foundation</a></li>\n            \n            <li><a href=\"https://alexwlchan.net/2025/social-media-scrapbook/#my-web-bookmarks\">My web bookmarks</a></li>\n            \n            <li><a href=\"https://alexwlchan.net/2025/social-media-scrapbook/#tapestry-by-the-iconfactory\">Tapestry, by the Iconfactory</a></li>\n            \n            <li><a href=\"https://alexwlchan.net/2025/social-media-scrapbook/#social-media-embeds-on-this-site\">Social media embeds on this site</a></li>\n            \n          </ul>\n        \n      </li>\n      <li>\n        <a href=\"https://alexwlchan.net/2025/social-media-scrapbook/#you-can-make-your-own-scrapbook-too\">You can make your own scrapbook, too</a>\n\n        \n      </li>\n</ul>\n</blockquote>\n\n\n\n<h2 id=\"the-long-road-to-a-lasting-archive\">The long road to a lasting archive</h2>\n\n<p>Before I ever heard the phrase \u201cdigital preservation\u201d, I knew I wanted to keep my social media.\nI\u00a0wrote scripts to capture my conversations and stash them away on storage I controlled.</p>\n\n<p>Those scripts worked, technically, but the end result was a mess.\nI\u00a0focusing on saving data, and organisation and presentation were an afterthought.\nI\u00a0was left with disordered folders full of JSON and XML files \u2013 archives I couldn\u2019t actually use, let along search or revisit with any joy.</p>\n\n<p>I\u2019ve tried to solve this problem more times than I can count.\nI\u00a0have screenshots of at least a dozen different attempts, and there are probably just as many I\u2019ve forgotten.</p>\n\n<p>For the first time, though, I think I have a sustainable solution.\nI\u00a0can store conversations, find them later, and the tech stack is simple enough to keep going for a long time.\nSaying something will last always has a whiff of hubris, especially if software is involved, but I have a good feeling.</p>\n\n<p>Looking back, I realise my previous attempts failed because I focused too much on my tools.\nI\u00a0kept thinking that if I just picked the right language, or found a better framework, or wrote cleaner code, I\u2019d finally land on a permanent solution.\nThe tools do matter \u2013 and a static site will easily outlive my hacky Python web apps \u2013 but other things are more important.</p>\n\n<p>What I really needed was a good data model.\nEvery earlier version started with a small schema that could hold simple conversations, which worked until I tried to save something more complex.\nWhenever that happened, I\u2019d make a quick fix, thinking about the specific issue rather than the data model as a whole.\nToo many one-off changes and everything would become a tangled mess, which is usually when I\u2019d start the next rewrite.</p>\n\n<p>This time, I thought carefully about the shape of the data.\nWhat\u2019s worth storing, and what\u2019s the best way to store it?\nHow do I clean, validate, and refine my data?\nHow do I design a data schema that can evolve in a more coherent way?\nMore than any language or framework choice, I think this is what will finally give this project some sticking power.</p>\n\n<hr />\n\n<h2 id=\"how-it-works\">How it works</h2>\n\n<h3 id=\"a-static-site-viewed-in-the-browser\">A static site, viewed in the browser</h3>\n\n<p>I store metadata in a machine-readable JSON/JavaScript file, and present it as a website that I can open in my browser.\nStatic sites give me a lightweight, flexible way to save and view my data, in a format that\u2019s widely supported and likely to remain usable for a long time.</p>\n\n<p>This is a topic I\u2019ve <a href=\"https://alexwlchan.net/2024/static-websites/\">written about at length</a>, including a <a href=\"https://alexwlchan.net/2025/mildly-dynamic-websites/\">detailed explanation</a> of my code.</p>\n\n<h3 id=\"conversations-as-the-unit-of-storage\">Conversations as the unit of storage</h3>\n\n<p>Within my scrapbook, the unit of storage is a <em>conversation</em> \u2013 a set of one or more posts that form a single thread.\nIf I save one post in a conversation, I save them all.\nThis is different to many other social media archives, which only save one post at a time.</p>\n\n<p>The surrounding conversation is often essential to understanding a post.\nWithout it, posts can be difficult to understand and interpret later.\nFor example, a tweet where I said <em>\u201cthat\u2019s a great idea!\u201d</em> doesn\u2019t make sense unless you know what I was replying to.\nStoring all the posts in a conversation together means I always have that context.</p>\n\n<h3 id=\"a-different-data-model-and-renderer-for-each-site\">A different data model and renderer for each site</h3>\n\n<p>A big mistake I made in the past was trying to shoehorn every site into the same data model.</p>\n\n<p>The consistency sounds appealing, but different sites are different.\nA\u00a0tweet is a short fragment of plain text, sometimes with attached media.\nTumblr posts are longer, with HTML and inline styles.\nOn Flickr the photo is the star, with text-based metadata as a secondary concern.</p>\n\n<p>It\u2019s hard to create a single data model that can store a tweet and a Tumblr post and a Flickr picture and the dozen other sites I want to support.\nTrying to do so always led me to a reductive model that over-simplified the data.</p>\n\n<p>For my scrapbook, I\u2019m avoiding this problem by creating a different data model for each site I want to save.\nI\u00a0can define the exact set of fields used by that site, and I can match the site\u2019s terminology.</p>\n\n<p>Here\u2019s one example: a thread from Twitter, where I saved a tweet and one of the replies.\nThe <code>site</code>, <code>id</code>, and <code>meta</code> are common to the data model across all sites, then there are site-specific fields in the <code>body</code> \u2013 in this example, the <code>body</code> is an array of tweets.</p>\n<pre><code><span class=\"p\">{</span><span class=\"w\">\n  </span><span class=\"nl\">\"site\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"twitter\"</span><span class=\"p\">,</span><span class=\"w\">\n  </span><span class=\"nl\">\"id\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"1574527222374977559\"</span><span class=\"p\">,</span><span class=\"w\">\n  </span><span class=\"nl\">\"meta\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"p\">{</span><span class=\"w\">\n    </span><span class=\"nl\">\"tags\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"p\">[</span><span class=\"s2\">\"trans joy\"</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"s2\">\"gender euphoria\"</span><span class=\"p\">],</span><span class=\"w\">\n    </span><span class=\"nl\">\"date_saved\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"2025-10-31T07:31:01Z\"</span><span class=\"p\">,</span><span class=\"w\">\n    </span><span class=\"nl\">\"url\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"https://www.twitter.com/alexwlchan/status/1574527222374977559\"</span><span class=\"w\">\n  </span><span class=\"p\">},</span><span class=\"w\">\n  </span><span class=\"nl\">\"body\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"p\">[</span><span class=\"w\">\n    </span><span class=\"p\">{</span><span class=\"w\">\n      </span><span class=\"nl\">\"id\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"1574527222374977559\"</span><span class=\"p\">,</span><span class=\"w\">\n      </span><span class=\"nl\">\"author\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"alexwlchan\"</span><span class=\"p\">,</span><span class=\"w\">\n      </span><span class=\"nl\">\"text\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"prepping for bed, I glanced in a mirror</span><span class=\"se\">\\n\\n</span><span class=\"s2\">and i was struck by an overwhelming sense of feeling beautiful</span><span class=\"se\">\\n\\n</span><span class=\"s2\">just from the angle of my face and the way my hair fell around over it</span><span class=\"se\">\\n\\n</span><span class=\"s2\">i hope i never stop appreciating the sense of body confidence and comfort i got from Transition \ud83e\udd70\"</span><span class=\"p\">,</span><span class=\"w\">\n      </span><span class=\"nl\">\"date_posted\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"2022-09-26T22:31:57Z\"</span><span class=\"w\">\n    </span><span class=\"p\">},</span><span class=\"w\">\n    </span><span class=\"p\">{</span><span class=\"w\">\n      </span><span class=\"nl\">\"id\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"1574527342470483970\"</span><span class=\"p\">,</span><span class=\"w\">\n      </span><span class=\"nl\">\"author\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"oldenoughtosay\"</span><span class=\"p\">,</span><span class=\"w\">\n      </span><span class=\"nl\">\"text\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"@alexwlchan you ARE beautiful!!\"</span><span class=\"p\">,</span><span class=\"w\">\n      </span><span class=\"nl\">\"date_posted\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"2022-09-26T22:32:26Z\"</span><span class=\"p\">,</span><span class=\"w\">\n      </span><span class=\"nl\">\"entities\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"p\">{</span><span class=\"w\">\n          </span><span class=\"nl\">\"hashtags\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"p\">[],</span><span class=\"w\">\n          </span><span class=\"nl\">\"media\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"p\">[],</span><span class=\"w\">\n          </span><span class=\"nl\">\"urls\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"p\">[],</span><span class=\"w\">\n          </span><span class=\"nl\">\"user_mentions\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"p\">[</span><span class=\"s2\">\"alexwlchan\"</span><span class=\"p\">]</span><span class=\"w\">\n        </span><span class=\"p\">},</span><span class=\"w\">\n        </span><span class=\"nl\">\"in_reply_to\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"p\">{</span><span class=\"w\">\n          </span><span class=\"nl\">\"id\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"1574527222374977559\"</span><span class=\"p\">,</span><span class=\"w\">\n          </span><span class=\"nl\">\"user\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"alexwlchan\"</span><span class=\"w\">\n        </span><span class=\"p\">}</span><span class=\"w\">\n      </span><span class=\"p\">}</span><span class=\"w\">\n    </span><span class=\"err\">}</span><span class=\"w\">\n  </span><span class=\"p\">]</span><span class=\"w\">\n</span><span class=\"p\">}</span><span class=\"w\">\n</span></code></pre>\n<p>If this was a conversation from a different site, say Tumblr or Instagram, you\u2019d see something different in the <code>body</code>.</p>\n\n<p>I store all the data as JSON, and I keep the data model small enough that I can fill it in by hand.</p>\n\n<p>I\u2019ve been trying to preserve my social media for over a decade, so I have a good idea of what fields I look back on and what I don\u2019t.\nFor example, many social media websites have metrics \u2013 how many times a post was viewed, starred, or retweeted \u2013 but I don\u2019t keep them.\nI\u00a0remember posts because they were fun, thoughtful, or interesting, not because they hit a big number.</p>\n\n<p>Writing my own data model means I know exactly when it changes.\nIn previous tools, I only stored the raw API response I received from each site.\nThat sounds nice \u2013 I\u2019m saving as much information as I possibly can! \u2013 but APIs change and the model would subtly shift over time.\nThe variation made searching tricky, and in practice I only looked at a small fraction of the saved data.</p>\n\n<p>I try to reuse data structures where appropriate.\nConversations from every site have the same <code>meta</code> scheme; conversations from microblogging services are all the same (Twitter, Mastodon, Bluesky, Threads); I have a common data structure for images and videos.</p>\n\n<p>Each data model is accompanied by a rendering function, which reads the data and returns a snippet of HTML that appears in one of the \u201ccards\u201d in my web browser.\nI\u00a0have a long switch statement that just picks the right rendering function, something like:</p>\n<pre><code><span class=\"kd\">function</span> <span class=\"n\">renderConversation</span><span class=\"p\">(</span><span class=\"n\">props</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n    switch<span class=\"p\">(</span>props<span class=\"p\">.</span>site<span class=\"p\">)</span> <span class=\"p\">{</span>\n        case <span class=\"dl\">'</span><span class=\"s1\">flickr</span><span class=\"dl\">'</span><span class=\"p\">:</span>\n            return <span class=\"n\">renderFlickrPicture</span><span class=\"p\">(</span>props<span class=\"p\">);</span>\n        case <span class=\"dl\">'</span><span class=\"s1\">twitter</span><span class=\"dl\">'</span><span class=\"p\">:</span>\n            return <span class=\"n\">renderTwitterThread</span><span class=\"p\">(</span>props<span class=\"p\">);</span>\n        case <span class=\"dl\">'</span><span class=\"s1\">youtube</span><span class=\"dl\">'</span><span class=\"p\">:</span>\n            return <span class=\"n\">renderYouTubeVideo</span><span class=\"p\">(</span>props<span class=\"p\">);</span>\n        <span class=\"err\">\u2026</span>\n    <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n</code></pre>\n<p>This approach makes it easy for me to add support for new sites, without breaking anything I\u2019ve already saved.\nIt\u2019s already scaled to twelve different sites\n(Twitter, Tumblr, Bluesky, Mastodon, Threads, Instagram, YouTube, Vimeo, TikTok, Flickr, Deviantart, Dribbble), and I\u2019m going to add WhatsApp and email in future \u2013 which look and feel very different to public social media.</p>\n\n<p>I also have a \u201cgeneric media\u201d data model, which is a catch-all for images and videos I\u2019ve saved from elsewhere on the web.\nThis lets me save something as a one-off from a blog or a forum without writing a whole new data model or rendering function.</p>\n\n<h3 id=\"keyword-tagging-on-every-conversation\">Keyword tagging on every conversation</h3>\n\n<p>I tag everything with keywords as I save it.\nIf I\u2019m looking for a conversation later, I think of what tags I would have used, and I can filter for them in the web app.\nThese tags mean I can find old conversations, and allows me to add my own interpretation to the posts I\u2019m saving.</p>\n\n<p>This is more reliable than full text search, because I can search a consistent set of terms.\nSocial media posts don\u2019t always mention their topic in a consistent, easy-to-find phrase \u2013 either because it just didn\u2019t fit into the wording, or because they\u2019re deliberately keeping it as subtext.\nFor example, not all cat pictures <a href=\"https://x.com/supergirl_sass/status/1392589896116699137\">include the word \u201ccat\u201d</a>, but I tag them all with \u201ccats\u201d so I can find them later.</p>\n\n<p>I use <a href=\"https://alexwlchan.net/2020/using-fuzzy-string-matching-to-find-duplicate-tags/\">fuzzy string matching</a> to find and fix mistyped tags.</p>\n\n<h3 id=\"metadata-in-jsonjavascript-interpreted-as-a-graph\">Metadata in JSON/JavaScript, interpreted as a graph</h3>\n\n<p>Here\u2019s a quick sketch of how my data and files are laid out on disk:</p>\n<pre><code>scrapbook/\n \u251c\u2500 avatars/\n \u251c\u2500 media/\n \u2502   \u251c\u2500 a/\n \u2502   \u2514\u2500 b/\n \u2502      \u2514\u2500 bananas.jpg\n \u251c\u2500 posts.js\n \u2514\u2500 users.js\n</code></pre>\n<p>This metadata forms a little graph:</p>\n\n<figure>\n  \n<svg class=\"dark_aware\" viewBox=\"0 0 503 103\" xmlns=\"http://www.w3.org/2000/svg\">\n  <defs>\n    \n    \n    <marker id=\"arrowhead\" markerHeight=\"4.9\" markerWidth=\"7\" orient=\"auto\" refX=\"0\" refY=\"2.45\">\n      <polygon points=\"0 0, 7 2.45, 0 4.9\"></polygon>\n    </marker>\n  </defs>\n  \n  <g transform=\"translate(0 30)\">\n    <rect height=\"40\" width=\"100\" x=\"1.5\" y=\"1.5\"></rect>\n    <text x=\"51.5\" y=\"21.5\">posts.js</text>\n  </g>\n  \n  <line marker-end=\"url(#arrowhead)\" x1=\"101.5\" x2=\"185\" y1=\"51.5\" y2=\"21.5\"></line>\n  <line marker-end=\"url(#arrowhead)\" x1=\"101.5\" x2=\"185\" y1=\"51.5\" y2=\"81.5\"></line>\n  \n  <line marker-end=\"url(#arrowhead)\" x1=\"201.5\" x2=\"386.5\" y1=\"81.5\" y2=\"81.5\"></line>\n  \n  <g transform=\"translate(200 0)\">\n    <rect height=\"40\" width=\"100\" x=\"1.5\" y=\"1.5\"></rect>\n    <text x=\"51.5\" y=\"21.5\">media</text>\n  </g>\n  \n  <g transform=\"translate(200 60)\">\n    <rect height=\"40\" width=\"100\" x=\"1.5\" y=\"1.5\"></rect>\n    <text x=\"51.5\" y=\"21.5\">users.js</text>\n  </g>\n  \n  <g transform=\"translate(400 60)\">\n    <rect height=\"40\" width=\"100\" x=\"1.5\" y=\"1.5\"></rect>\n    <text x=\"51.5\" y=\"21.5\">avatars</text>\n  </g>\n</svg>\n\n</figure>\n\n<p>All of my post data is in <code>posts.js</code>, which contains objects like the Twitter example above.</p>\n\n<p>Posts can refer to media files, which I store in the <code>media/</code> directory and group by the first letter of their filename \u2013 this keeps the number of files in each subdirectory manageable.</p>\n\n<p>Posts point to their author in <code>users.js</code>.\nMy user model is small \u2013 the path of an avatar image in <code>avatars/</code>, and maybe a display name if the site supports it.</p>\n\n<p>Currently, users are split by site, and I can\u2019t correlate users across sites.\nFor example, I have no way to record that <code>@alexwlchan</code> on Twitter and <code>@alex@alexwlchan.net</code> on Mastodon are the same person.\nThat\u2019s something I\u2019d like to do in future.</p>\n\n<h3 id=\"a-large-suite-of-tests\">A large suite of tests</h3>\n\n<p>I have a test suite written in Python and <a href=\"https://docs.pytest.org/en/stable/\">pytest</a> that checks the consistency and correctness of my metadata.\nThis includes things like:</p>\n\n<ul>\n  <li>My metadata files match my data model</li>\n  <li>Every media file described in the metadata is saved on disk, and every media file saved on disk is described in the metadata</li>\n  <li>I have a profile image for the author of every post that I\u2019ve saved</li>\n  <li>Every timestamp uses <a href=\"https://alexwlchan.net/2025/messy-dates-in-json/\">a\u00a0consistent format</a>\n</li>\n  <li>None of my videos are <a href=\"https://alexwlchan.net/2025/detecting-av1-videos/\">encoded in AV1</a> (which can\u2019t play on my iPhone)</li>\n</ul>\n\n<p>I\u2019m doing a lot of manual editing of metadata, and these tests give me a safety net against mistakes.\nThey\u2019re pretty fast, so I run them every time I make a change.</p>\n\n<hr />\n\n<h2 id=\"inspirations-and-influences\">Inspirations and influences</h2>\n\n<h3 id=\"the-static-website-in-twitters-first-party-archives\">The static website in Twitter\u2019s first-party archives</h3>\n\n<p>Pretty much every social media website has a way to export your data, but some exports are better than others.\nSome sites clearly offer it reluctantly \u2013 a zip archive full of JSON files, with minimal documentation or explanation.\nEnough to comply with <a href=\"https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/individual-rights/individual-rights/right-to-data-portability/\">data export laws</a>, but nothing more.</p>\n\n<p>Twitter\u2019s archive was much better.\nWhen you downloaded your archive, the first thing you\u2019d see was an HTML file called <code>Your archive.html</code>.\nOpening this would launch a static website where you could browse your data, including full-text search for your tweets:</p>\n\n\n\n<figure id=\"twitter_archive\">\n  \n\n\n<a href=\"https://alexwlchan.net/images/2025/twitter_archive1.png\"><source type=\"image/png\" /><img alt=\"Homepage of the Twitter archive. It says \u2018Hi @alexwlchan. Here is the information from your archive which may be most useful to you.\u2019 Below that are summary metrics \u2013 40.3K tweets, 54.2K likes, 2,727 blocked accounts, and so on \u2013 which link to a page where I can see the tweets/likes/blocked accounts.\" class=\"screenshot\" src=\"https://alexwlchan.net/images/2025/twitter_archive1_1x.png\" width=\"375\" />\n</a>\n\n\n  \n\n\n<a href=\"https://alexwlchan.net/images/2025/twitter_archive2.png\"><source type=\"image/png\" /><img alt=\"Search results in the Twitter archive. I\u2019ve searched for the hashtag #digipres and it\u2019s showing me three of my tweets, which more beyond the end of the page. I\u00a0can also filter by replies or retweets, and there are controls for more sophisticated filtering.\" class=\"screenshot\" src=\"https://alexwlchan.net/images/2025/twitter_archive2_1x.png\" width=\"375\" />\n</a>\n\n\n  <figcaption>\n    Fun fact: although Elon Musk has <a href=\"https://www.theverge.com/2023/7/23/23804629/twitters-rebrand-to-x-may-actually-be-happening-soon\">rebranded Twitter as X</a>, the old name survives in these archive exports.\n    If you <a href=\"https://help.x.com/en/managing-your-account/accessing-your-x-data\">download your archive</a> today, it still talks about Twitter!\n  </figcaption>\n</figure>\n\n<p>This approach was a big inspiration for me, and put me on the path of <a href=\"https://alexwlchan.net/2024/static-websites/\">using static websites for tiny archives</a>.\nIt\u2019s a remarkably robust piece of engineering, and these archives will last long after Twitter or X have disappeared from the web.</p>\n\n<p>The Twitter archive isn\u2019t exactly what I want, because it only has my tweets.\nMy favourite moments on Twitter were back-and-forth conversations, and my personal archive only contains my side of the conversation.\nIn my custom scrapbook, I can capture both people\u2019s contributions.</p>\n\n<h3 id=\"data-lifeboat-at-the-flickr-foundation\">Data Lifeboat at the Flickr Foundation</h3>\n\n<p><a href=\"https://www.flickr.org/programs/content-mobility/data-lifeboat/\">Data Lifeboat</a> is a project by the <a href=\"https://www.flickr.org\">Flickr Foundation</a> to create archival slivers of Flickr.\nI\u00a0worked at the Foundation for nearly two years, and I built the first prototypes of Data Lifeboat.\nI\u00a0joined because of my interest in archiving social media, and the ideas flowed in both directions: personal experiments informed my work, and vice versa.</p>\n\n<p>Data Lifeboat and my scrapbook differ in some details, but the underlying principles are the same.</p>\n\n<p>One of my favourite parts of that work was pushing <a href=\"https://alexwlchan.net/2024/static-websites/\">static websites for tiny archives</a> further than I ever have before.\nEach Data Lifeboat package includes <a href=\"https://www.flickr.org/the-data-lifeboat-viewer-circa-2024/\">a\u00a0viewer app</a> for browsing the contents, which is a static website built in vanilla JavaScript \u2013 very similar to the Twitter archive.\nIt\u2019s the most complex static site I\u2019ve ever built, so much so that I had to write a test suite using <a href=\"https://playwright.dev/\">Playwright</a>.</p>\n\n<p>That experience made me more ambitious about what I can do with static, self-contained sites.</p>\n\n<h3 id=\"my-web-bookmarks\">My web bookmarks</h3>\n\n<p>Earlier this year I wrote about <a href=\"https://alexwlchan.net/2025/bookmarks-static-site/\">my bookmarks collection</a>, which I also store in a static site.\nMy bookmarks are mostly long-form prose and video \u2013 reference material with private notes.\nThe scrapbook is typically short-form content, often with visual media, often with conversations I was a part of.\nBoth give me searchable, durable copies of things I don\u2019t want to lose.</p>\n\n<p>I built my own bookmarks site because I didn\u2019t trust a bookmarking service to last; I built my social media scrapbook because I don\u2019t trust social media platforms to stick around.\nThey\u2019re two different manifestations of the same idea.</p>\n\n<h3 id=\"tapestry-by-the-iconfactory\">Tapestry, by the Iconfactory</h3>\n\n<p><a href=\"https://usetapestry.com/\">Tapestry</a> is an iPhone app that combines posts from multiple platforms into a single unified timeline \u2013 social media, RSS feeds, blogs.\nThe app pulls in content using site-specific <a href=\"https://usetapestry.com/connectors/\">\u201cconnectors\u201d</a>, written with basic web technologies like JavaScript and JSON.</p>\n\n<source type=\"image/png\" /><img alt=\"Tapestry screenshot. This is the All Feeds view, where you can see a post from Tumblr, Bluesky, Mastodon, and my blog, all in the same timeline.\" class=\"screenshot\" src=\"https://alexwlchan.net/images/2025/tapestry_1x.png\" width=\"375\" />\n\n\n<p>Although I don\u2019t use Tapestry myself, I was struck by the design, especially the connectors.\nThe idea that each site gets its own bit of logic is what inspired me to consider different data models for each site \u2013 and of course, I love the use of  vanilla web tech.</p>\n\n<h3 id=\"social-media-embeds-on-this-site\">Social media embeds on this site</h3>\n\n<p>When I embed social media posts on this site, I don\u2019t use the native embeds offered by platforms, which pull in megabytes of of JavaScript and tracking.\nInstead, I use <a href=\"https://alexwlchan.net/2025/good-embedded-toots/\">lightweight HTML snippets</a> styled with my own CSS, an idea I first saw on Dr Drang\u2019s site <a href=\"https://leancrew.com/all-this/2012/07/good-embedded-tweets/\">over thirteen years ago</a>.</p>\n\n<p>The visual appearance of these snippets isn\u2019t a perfect match for the original site, but they\u2019re close enough to be usable.\nThe CSS and HTML templates were a good starting point for my scrapbook.</p>\n\n<hr />\n\n<h2 id=\"you-can-make-your-own-scrapbook-too\">You can make your own scrapbook, too</h2>\n\n<p>I\u2019ve spent a lot of time and effort on this project, and I had fun doing it, but you can build something similar with a fraction of the effort.\nThere are lots of simpler ways to save an offline backup of an online page \u2013 a screenshot, a text file, a printout.</p>\n\n<p>If there\u2019s something online you care about and wouldn\u2019t want to lose, save your own copy.\nThe history of the Internet tells us that it will almost certainly disappear at some point.</p>\n\n<p>The Internet forgets, but it doesn\u2019t have to take your memories with it.</p>\n\n\n    <p>[If the formatting of this post looks odd in your feed reader, <a href=\"https://alexwlchan.net/2025/social-media-scrapbook/?ref=rss\">visit the original article</a>]</p>"
            ],
            "link": "https://alexwlchan.net/2025/social-media-scrapbook/?ref=rss",
            "publishedAt": "2025-12-08",
            "source": "Alex Chan",
            "summary": "<p>I grew up alongside social media, as it was changing from nerd curiosity to mainstream culture. I joined Twitter and Tumblr in the early 2010s, and I stayed there for over a decade. Those spaces shaped my adult life: I met friends and partners, found a career in cultural heritage, and discovered my queer identity.</p> <p>That impact will last a long time. The posts themselves? Not so much.</p> <p>Social media is fragile, and it can disappear quickly. Sites get <a href=\"https://arstechnica.com/tech-policy/2022/10/elon-musk-completes-twitter-purchase-immediately-fires-ceo-and-other-execs/\">sold</a>, <a href=\"https://web.archive.org/web/20240909195207/https://cohost.org/staff/post/7611443-cohost-to-shut-down\">shut down</a> or <a href=\"https://www.bbc.co.uk/news/articles/c4gzxv5gy3qo\">blocked</a>. People close their accounts or <a href=\"https://en.wikipedia.org/wiki/Mark_Pilgrim#%22Disappearance%22_from_the_Internet\">flee the Internet</a>. Posts get <a href=\"https://alexwlchan.net/2024/i-deleted-all-my-tweets/\">deleted</a>, <a href=\"https://www.theverge.com/2018/12/6/18127869/tumblr-livejournal-porn-ban-strikethrough\">censored</a> or <a href=\"https://www.bbc.co.uk/news/technology-47610936\">lost</a> by platforms that don\u2019t care about permanence. We live in an era of abundant technology and storage, but the everyday record of our lives is disappearing before our eyes.</p> <p>I want to remember social media, and not just as a vague memory. I want to remember exactly what I read, what I saw, what I wrote. If I was born 50 years ago, I\u2019m the sort of person who\u2019d keep a scrapbook full of letters and postcards \u2013 physical traces of the people who mattered to me. Today, those traces are digital.</p> <p>I don\u2019t trust",
            "title": "The Internet forgets, but I don\u2019t want to"
        },
        {
            "content": [
                "<img alt=\"llm weights vs the papercuts of corporate\" src=\"https://ghuntley.com/content/images/2025/12/universal_upscale_0_6a2d76dd-41e0-42a4-8529-bf43d0280256_0.jpg\" /><p>In woodworking, there&apos;s a saying that you should work with the grain, not against the grain and I&apos;ve been thinking about how this concept may apply to large language models. </p><p>These large language models are built by training on existing data. This data forms the backbone which creates output based upon the preferences of the underlying model weights. </p><p>We are now one year in where a new category of companies has been founded whereby the majority of the software behind that company was code-generated. </p><p>From here on out I&#x2019;m going to call  to these companies as model weight first. This category of companies can be defined as any company that is building with the data (&#x201c;grain&#x201d;) that has been baked into the large language models. </p><p>Model weight first companies do not require as much context engineering. They&#x2019;re not stuffing the context window with  rules to try  attempt to override and change the base models to fit a pre-existing corporate standard and conceptualisation of how software should be.</p><p>The large language model has decided on what to call a method name or class name because that method or classs name is what the large language model prefers thus, when code is adapted, modified, and re-read into the context window, it is consuming its preferred choice of tokens. </p><p>Model-weight-first companies do not have the dogma of snake_case vs PascalCase vs kebab-case policies that many corporate companies have. Such policies were created for humans to create consistency so humans can comprehend the codebase. Something that is of a lesser concern now that AI is here. </p><p>Now variable naming is a contrived example, but I suspect in the years to come if a study was done to compare the velocity/productivity/success rates with AI of a model weight first company vs. a corporate company, I suspect a model weight company have vastly better outcomes because they&apos;re not trying to do context engineering to force the LLM to follow some pre-existing dogma.\n\nThere is one universal truth with LLMs as they are now: the less that you use, the better the outcomes you get. </p><p>The less that you allocate (i.e., cursor rules or what else have you), then you&apos;ll have more context window available for actually implementing requirements of the software that needs to be built. </p><p>So if we take this thought experiment about the models having preferences for tokens and expand it out to another use case, let&apos;s say that you needed to build a Docker container at a model weight first company. </p><p>You could just ask an LLM to build a Docker container, and it knows how to build a Docker container for say Postgres, and it just works.\n\nBut in the corporate setting, if you ask it to build a Docker container, and in that corporate you have to configure HTTPS, squid proxy, or some sort of artifactory and outbound internet access is restricted, that same simple thing becomes very comical. </p><p>You&apos;ll see an agent fill up with lots of failed tool calls unless you do context engineering to say &quot;no, if you want to build a docker container, you got to follow these particular allocations of company conventions&#x201d; in a crude attempt to override the preferences of the inbuilt model weights. </p><p>At a model weight first company, building a docker image is easy but at a corporate the agent will have one hell of a time and end up with a suboptimal/disappointing outcome. </p><p>So, perhaps this is going to be a factor that needs to be considered when talking and comparing the success rates of AI at one company versus another company, or across industries. </p><p>If a company is having problems with AI and getting outcomes from AI, are they a model weight first company or are they trying to bend AI to their whims? </p><p>Perhaps the corporates who succeed the most with the adoption of AI will be those who shed their dogma that no longer applies and start leaning into transforming to become model-weight-first companies.</p><p>ps. socials. </p><figure class=\"kg-card kg-embed-card\"><blockquote class=\"twitter-tweet\"><p dir=\"ltr\" lang=\"en\">&#x1f5de;&#xfe0f; llm weights vs the papercuts of corporate<br /><br />(link in next post)<br /><br />&#x201c;If a company is having problems with AI and getting outcomes from AI, are they a model weight first company or are they trying to bend AI to their whims?&#x201d; <a href=\"https://t.co/WLMGF4HYa1?ref=ghuntley.com\">pic.twitter.com/WLMGF4HYa1</a></p>&#x2014; geoff (@GeoffreyHuntley) <a href=\"https://twitter.com/GeoffreyHuntley/status/1998059600780865979?ref_src=twsrc%5Etfw&amp;ref=ghuntley.com\">December 8, 2025</a></blockquote>\n</figure>"
            ],
            "link": "https://ghuntley.com/papercuts/",
            "publishedAt": "2025-12-08",
            "source": "Geoffrey Huntley",
            "summary": "<p>In woodworking, there&apos;s a saying that you should work with the grain, not against the grain and I&apos;ve been thinking about how this concept may apply to large language models. </p><p>These large language models are built by training on existing data. This data forms the backbone</p>",
            "title": "llm weights vs the papercuts of corporate"
        },
        {
            "content": [
                "<p>This is the weekly visible open thread. Post about anything you want, ask random questions, whatever. ACX has an unofficial <a href=\"https://www.reddit.com/r/slatestarcodex/\">subreddit</a>, <a href=\"https://discord.gg/RTKtdut\">Discord</a>, and <a href=\"https://www.datasecretslox.com/index.php\">bulletin board</a>, and <a href=\"https://www.lesswrong.com/community?filters%5B0%5D=SSC\">in-person meetups around the world</a>. Most content is free, some is subscriber only; you can subscribe <strong><a href=\"https://astralcodexten.substack.com/subscribe\">here</a></strong>. Also:</p><div><hr /></div><p><strong>1: </strong>If you&#8217;re wondering what Lars Doucet (ACX grantee, <a href=\"https://www.astralcodexten.com/p/your-book-review-progress-and-poverty\">Georgism writer</a>) has been up to lately, his Center for Land Economics has an <a href=\"https://drive.google.com/file/d/1VKHs11svKFdlP415gtMw3d_u-6l4XpP0/view\">End Of Year Report</a>. Or if you prefer video, his <a href=\"https://progressandpoverty.substack.com/p/land-value-return-is-needed-pragmatic\">Land Value Tax Live presentation</a>.</p><p><strong>2: </strong>Q&amp;A with California legislator and Congressional candidate Scott Wiener this Thursday, focusing on his AI safety agenda. Mox co-working space in SF, doors open at 5, open to the general public. Get tickets <a href=\"https://luma.com/jxsanwtn\">here</a> if you&#8217;re interested.</p><p><strong>3: </strong>Another December charity fundraiser, <a href=\"https://www.againstmalaria.com/FundraiserGroup.aspx?FundraiserID=9418\">Philosophers Against Malaria</a>.</p><p><strong>4: </strong>The <a href=\"https://www.astralcodexten.com/p/the-fatima-sun-miracle-much-more\">Fatima discussion</a> successfully nerd-sniped ACX reader Nikita Sokolsky, who&#8217;s been doing great work finding, digitizing, and translating other sources I didn&#8217;t have access to. Here&#8217;s his version of <a href=\"https://drive.google.com/drive/folders/1FYdv665U8sqwISCHLnpLUymqKkU8ojO-\">Critical Documentation Volume 4</a> (he wanted Volume 3, but they sent him 4 by mistake; he hopes to get 3 later). Here are his <a href=\"https://drive.google.com/drive/folders/1oCxlzzfWpP1-qzTvdgaXE_bVwAen2fAP\">versions of some Portuguese-language books</a>. And here is (an AI-assisted version of) <a href=\"https://drive.google.com/file/d/11Ono_hMPjhRHy8Xe1IjJGhcSUpQE89Il/view\">his own speculations</a>.</p><p></p>"
            ],
            "link": "https://www.astralcodexten.com/p/open-thread-411",
            "publishedAt": "2025-12-08",
            "source": "SlateStarCodex",
            "summary": "<p>This is the weekly visible open thread. Post about anything you want, ask random questions, whatever. ACX has an unofficial <a href=\"https://www.reddit.com/r/slatestarcodex/\">subreddit</a>, <a href=\"https://discord.gg/RTKtdut\">Discord</a>, and <a href=\"https://www.datasecretslox.com/index.php\">bulletin board</a>, and <a href=\"https://www.lesswrong.com/community?filters%5B0%5D=SSC\">in-person meetups around the world</a>. Most content is free, some is subscriber only; you can subscribe <strong><a href=\"https://astralcodexten.substack.com/subscribe\">here</a></strong>. Also:</p><div><hr /></div><p><strong>1: </strong>If you&#8217;re wondering what Lars Doucet (ACX grantee, <a href=\"https://www.astralcodexten.com/p/your-book-review-progress-and-poverty\">Georgism writer</a>) has been up to lately, his Center for Land Economics has an <a href=\"https://drive.google.com/file/d/1VKHs11svKFdlP415gtMw3d_u-6l4XpP0/view\">End Of Year Report</a>. Or if you prefer video, his <a href=\"https://progressandpoverty.substack.com/p/land-value-return-is-needed-pragmatic\">Land Value Tax Live presentation</a>.</p><p><strong>2: </strong>Q&amp;A with California legislator and Congressional candidate Scott Wiener this Thursday, focusing on his AI safety agenda. Mox co-working space in SF, doors open at 5, open to the general public. Get tickets <a href=\"https://luma.com/jxsanwtn\">here</a> if you&#8217;re interested.</p><p><strong>3: </strong>Another December charity fundraiser, <a href=\"https://www.againstmalaria.com/FundraiserGroup.aspx?FundraiserID=9418\">Philosophers Against Malaria</a>.</p><p><strong>4: </strong>The <a href=\"https://www.astralcodexten.com/p/the-fatima-sun-miracle-much-more\">Fatima discussion</a> successfully nerd-sniped ACX reader Nikita Sokolsky, who&#8217;s been doing great work finding, digitizing, and translating other sources I didn&#8217;t have access to. Here&#8217;s his version of <a href=\"https://drive.google.com/drive/folders/1FYdv665U8sqwISCHLnpLUymqKkU8ojO-\">Critical Documentation Volume 4</a> (he wanted Volume 3, but they sent him 4 by mistake; he hopes to get 3 later). Here are his <a href=\"https://drive.google.com/drive/folders/1oCxlzzfWpP1-qzTvdgaXE_bVwAen2fAP\">versions of some Portuguese-language books</a>. And here is",
            "title": "Open Thread 411"
        },
        {
            "content": [
                "<p>I believe that we will win.</p>\n<p>An echo of <a href=\"https://www.youtube.com/watch?v=7bz6UMwCquM\">an old ad for the 2014 US men\u2019s World Cup team</a>. It did not win.</p>\n<p>I was in Berkeley for the 2025 Secular Solstice. We gather to sing and to reflect.</p>\n<p>The night\u2019s theme was the opposite: \u2018I don\u2019t think we\u2019re going to make it.\u2019</p>\n<p>As in: Sufficiently advanced AI is coming. We don\u2019t know exactly when, or what form it will take, but it is probably coming. When it does, we, humanity, probably won\u2019t make it. It\u2019s a live question. Could easily go either way. We are not resigned to it. There\u2019s so much to be done that can tilt the odds. But we\u2019re not the favorite.</p>\n<div> <span id=\"more-24938\"></span> </div>\n<p>Raymond Arnold, who ran the event, believes that. I believe that.</p>\n<p>Yet in the middle of the event, the echo was there. Defiant.</p>\n<p>I believe that we will win.</p>\n<p><a href=\"https://www.youtube.com/watch?v=pfotEo7pVqc\"><strong>There is a recording of the event</strong></a>. I highly encourage you to set aside three hours at some point in December, to listen, and to participate and sing along. Be earnest.</p>\n<p>If you don\u2019t believe it, I encourage this all the more. If you don\u2019t understand the mindset, or the culture behind it, or consider it an opponent or dislike it, and especially if yours is a different fight? I encourage this all the more than that. You can also <a href=\"https://rationalistmegameetup.com/\"><strong>attend New York\u2019s Solstice on the 20th</strong></a>.</p>\n<p>You will sing songs you know, and songs you don\u2019t. You will hear tales of struggles, of facing impossible odds or unbearable loss and fighting anyway, of how to face it all and hopefully stay sane. To have the end, if it happens, find us doing well.</p>\n<p>I live a wonderful life.</p>\n<p>I am crying as I write this. But when I am done, I will open a different Chrome window. I will spend the day with friends I love dearly and watching football games. This evening my wife and I will attend a not wedding of two of them, that is totally a wedding. We will fly home to our wonderful kids, and enjoy endless wonders greater than any king in the beating heart of the world. I want for nothing other than time.</p>\n<p>Almost every day, I will mostly reject those wonders. I will instead return to my computer. I will confront waves of events and information. The avalanche will accelerate. Release after release, argument after argument, policies, papers, events, one battle after another. People will be determined to handle events with <a href=\"https://www.lesswrong.com/posts/j9Q8bRmwCgXRYAgcJ/miri-announces-new-death-with-dignity-strategy\">less dignity than one could imagine</a>, despite having read this sentence. I fight to not be driven into rages. I will triage. I will process. I will change my mind. I will <a href=\"https://www.youtube.com/watch?v=h3h--K5928M&amp;pp=ygUVY2FuJ3QgZXhwbGFpbiB0aGUgd2hv\">try to explain</a>, just one more time. I will move pieces around multiple chessboards.</p>\n<p><a href=\"https://en.wikipedia.org/wiki/Clair_Obscur:_Expedition_33\">We continue</a>. <a href=\"https://www.youtube.com/watch?v=gLFWRDsx5AI\">Don\u2019t tell me to stop</a>. <a href=\"https://unsongbook.com/\">Someone has to, and no one else will</a>.</p>\n<p>I know if I ignored it, <a href=\"https://thezvi.substack.com/p/ai-practical-advice-for-the-worried\">anything else would soon turn to ash in my mouth</a>.</p>\n<p>I will look at events, and say to myself as I see the moves unfolding, the consequences of choices I made or influenced, for good and ill: <a href=\"https://www.youtube.com/watch?v=iBqBWleWW0U&amp;pp=ygUZdGhpcyBpcyB0aGUgd29ybGQgd2UgbWFkZQ%3D%3D\">This is the world we made</a>.</p>\n<p><a href=\"https://www.bbc.com/news/magazine-34324865\">It aint over till its over</a>. <a href=\"https://www.espn.com/blog/sweetspot/post/_/id/11816/why-you-never-leave-a-baseball-game-early\">Never leave a ballgame early</a>. Leave it all on the field, for <a href=\"https://www.youtube.com/watch?v=FpV1laFvF_g\">when the dust covers the sun and all you hope for is undone</a>. <a href=\"https://thezvi.substack.com/p/you-play-to-win-the-game\">You play to win the game</a>.</p>\n<p><a href=\"https://www.youtube.com/watch?v=fmdV3ypR3tA\">The odds are against us and the situation is grim</a>. By default, we lose. I act accordingly, and <a href=\"https://www.lesswrong.com/posts/isSBwfgRY6zD6mycc/eliezer-s-unteachable-methods-of-sanity\">employ some of the unteachable methods of sanity</a> and the mirror version of others, all of which are indeed unteachable but do totally work.</p>\n<p>Yet the echo is there. In my head. It doesn\u2019t care.</p>\n<p>I believe that we will win.</p>"
            ],
            "link": "https://thezvi.wordpress.com/2025/12/08/little-echo/",
            "publishedAt": "2025-12-08",
            "source": "TheZvi",
            "summary": "I believe that we will win. An echo of an old ad for the 2014 US men\u2019s World Cup team. It did not win. I was in Berkeley for the 2025 Secular Solstice. We gather to sing and to reflect. &#8230; <a href=\"https://thezvi.wordpress.com/2025/12/08/little-echo/\">Continue reading <span class=\"meta-nav\">&#8594;</span></a>",
            "title": "Little Echo"
        },
        {
            "content": [],
            "link": "https://xkcd.com/3178/",
            "publishedAt": "2025-12-08",
            "source": "XKCD",
            "summary": "<img alt=\"Our models fall apart where the three theories overlap; we're unable to predict what happens when a nanometer-sized squirrel eats a grapefruit with the mass of the sun.\" src=\"https://imgs.xkcd.com/comics/hyperacute_interdynamics.png\" title=\"Our models fall apart where the three theories overlap; we're unable to predict what happens when a nanometer-sized squirrel eats a grapefruit with the mass of the sun.\" />",
            "title": "Hyperacute Interdynamics"
        }
    ],
    "lookbackDays": 1,
    "publishDate": "2025-12-08"
}