{
    "articles": [
        {
            "content": [
                "<p>Last month I dropped a desperate little <a href=\"https://charity.wtf/2025/09/19/are-you-an-experienced-software-buyer-i-could-use-some-help/\">plea for help</a> in this space, asking people to email me any good advice and/or strong opinions they happened to have on the topic of buying software.</p>\n<p>I wasn\u2019t really sure what to expect \u2014 desperate times, desperate measures \u2014 but holy crap, you guys delivered. To the many people who took the time to write up your experiences and expertise for me, and suffer through rounds of questions and drafts: <img alt=\"\u2728\" class=\"wp-smiley\" src=\"https://s.w.org/images/core/emoji/16.0.1/72x72/2728.png\" style=\"height: 1em;\" /><strong>thank you</strong><img alt=\"\u2728\" class=\"wp-smiley\" src=\"https://s.w.org/images/core/emoji/16.0.1/72x72/2728.png\" style=\"height: 1em;\" />. And thank you, too, to those of you who forwarded my queries along to experts in your network and asked for help on my behalf.</p>\n<p>I learned a LOT about buying software and managing vendor relationships in the process of writing this. Honestly, this chapter is shaping up to be one of the things I\u2019m most excited about for the second edition of the book.</p>\n<h2>Why I&#8217;m excited about the software buying chapter (&amp; you should be too)</h2>\n<p>I\u2019m imagining you reading this with a skeptical expression and an arched eyebrow. \u201c<em>Really</em>, Charity\u2026\u2018how to buy software\u2019 doesn\u2019t exactly suggest peak engineering prowess.\u201d</p>\n<p>Au contraire, my friends. I\u2019ve come to believe that vendor engineering is one of the subtlest and most powerful practical applications of deep subject matter expertise, and some of the highest leverage work an engineer can do. How often do you get to make decisions that leverage the labor of hundreds or thousands of engineers per year, for fractions of pennies on the dollar? How many of the decisions you make will have an impact on every single engineer you work with and their ability to do their jobs well, as well as the experience of every single customer?</p>\n<p>If you think I&#8217;m hyperventilating a bit, nah; this is entry level shit. In the book, I tell the story of the best engineer I ever worked with, and how I watched him alter the trajectory of multiple other companies, <em>none of which he was working for, buying from, or formally connected to in any way</em> \u2014 in the space of a few conversations. It upended my entire worldview about what it can look like for an engineer to wield great power.</p>\n<p>Doing this stuff well takes both technical depth and technical breadth, in addition to systems thinking and knowledge of the business. It is one of the <em>only</em> ways a staff+ engineer can acquire and develop executive-level communication, strategy, and execution skills while remaining an individual contributor.</p>\n<p>I\u2019ve been wanting to write about this for YEARS. Anyway \u2014 ergh! \u2014 I\u2019m rambling now. That was not what I came here to talk about, I\u2019m just excited. Back to the point.</p>\n<h2>My second (and final) round of questions</h2>\n<p>I got <em>so much</em> out of your thoughtful responses that I thought I\u2019d press my luck and put a few more questions out to the universe, before it&#8217;s too late.</p>\n<p>These questions speak to areas where I worry that my writing may be a little weak or uninformed, or too far away from the world where people are using the \u201cthree pillars\u201d model (<a href=\"https://charity.wtf/2025/03/24/another-observability-3-0-appears-on-the-horizon/\">aka multiple pillars</a> or o11y 1.0) and <em>happy</em> about it. I don\u2019t know many (any??) of those people, which suggests some pretty heavy selection bias.</p>\n<p>I don&#8217;t expect anyone to answer <em>all</em>\u00a0the questions; if one or two resonate with you, write about those and ignore the rest. If there\u2019s something I didn\u2019t ask that I should have asked, answer that. Something I&#8217;ve written in the past that bugged you that you hope I won&#8217;t say again? Tell me! We are almost out of time <img alt=\"\u231b\" class=\"wp-smiley\" src=\"https://s.w.org/images/core/emoji/16.0.1/72x72/231b.png\" style=\"height: 1em;\" /> so gimme what you got. <img alt=\"\ud83d\ude4c\" class=\"wp-smiley\" src=\"https://s.w.org/images/core/emoji/16.0.1/72x72/1f64c.png\" style=\"height: 1em;\" /></p>\n<h3>On migrations:</h3>\n<p><img alt=\"\ud83d\udcc8\" class=\"wp-smiley\" src=\"https://s.w.org/images/core/emoji/16.0.1/72x72/1f4c8.png\" style=\"height: 1em;\" /> Have you ever migrated from one observability vendor to another? If so, what did you learn? What was the hardest part, what took you by surprise? What do you wish you could go back in time and tell your self at the start?</p>\n<p><img alt=\"\ud83d\udcc8\" class=\"wp-smiley\" src=\"https://s.w.org/images/core/emoji/16.0.1/72x72/1f4c8.png\" style=\"height: 1em;\" /> If you ran (or were involved in) a large scale migration or tool change\u2026 how did you structure the process? Like, was it team by team, service by service, product by product? Did you have a playbook? What did you do to make it fun or push through organizational inertia? How long did it take?</p>\n<h3>On managing costs for the traditional three pillars:</h3>\n<p><img alt=\"\ud83d\udcc8\" class=\"wp-smiley\" src=\"https://s.w.org/images/core/emoji/16.0.1/72x72/1f4c8.png\" style=\"height: 1em;\" /> For orgs that are using Datadog, Grafana, Chronosphere, or another traditional three pillars architecture.. How would you describe your approach to cutting and controlling costs? Pro tips and/or comprehensive strategy.</p>\n<p><img alt=\"\ud83d\udcc8\" class=\"wp-smiley\" src=\"https://s.w.org/images/core/emoji/16.0.1/72x72/1f4c8.png\" style=\"height: 1em;\" /> Alternately, if there are particular blog posts with advice you have followed and can personally vouch for, would you send me a link?</p>\n<p><img alt=\"\ud83d\udcc8\" class=\"wp-smiley\" src=\"https://s.w.org/images/core/emoji/16.0.1/72x72/1f4c8.png\" style=\"height: 1em;\" /> How do you guide your software engineers on which data to send to which place \u2014 metrics, logs, traces, errors/exceptions, profiling, etc? How do you manage cardinality? How do you work to keep the pillars in sync, or are there any particular tips and tricks you have for linking / jumping between the data sources?</p>\n<p><img alt=\"\ud83d\udcc8\" class=\"wp-smiley\" src=\"https://s.w.org/images/core/emoji/16.0.1/72x72/1f4c8.png\" style=\"height: 1em;\" /> How many ongoing engineering cycles does it take to manage and maintain costs, once you\u2019ve gotten them to a sustainable place?</p>\n<h3>On managing costs at massive scale:</h3>\n<p>(Especially for people who work at a large enterprise, the kind with multiple business units, but others welcome too!):</p>\n<ul>\n<li>Do you use tiers of service for managing costs? How do you define those?</li>\n<li>How do new tools get taken for a spin? (Like, sometimes there is an office of the CTO with carte blanche to try new things and evaluate them for the rest of the org)</li>\n<li>How do you use telemetry pipelines?</li>\n</ul>\n<h3>\nObservability teams (quick poll):</h3>\n<p><img alt=\"\ud83d\udcc8\" class=\"wp-smiley\" src=\"https://s.w.org/images/core/emoji/16.0.1/72x72/1f4c8.png\" style=\"height: 1em;\" /> If you have an observability team, how big is it? What part of the org does it report up into? Roughly how many engineers does that team support?</p>\n<p><img alt=\"\ud83d\udcc8\" class=\"wp-smiley\" src=\"https://s.w.org/images/core/emoji/16.0.1/72x72/1f4c8.png\" style=\"height: 1em;\" /> If you don\u2019t have an observability team \u2014 and you have more than, say, 300 engineers \u2014 who owns observability? Platform? SRE? Other?</p>\n<h3>A grab bag:</h3>\n<p><img alt=\"\ud83d\udcc8\" class=\"wp-smiley\" src=\"https://s.w.org/images/core/emoji/16.0.1/72x72/1f4c8.png\" style=\"height: 1em;\" /> <strong>Build vs Buy: </strong>If you built your own observability tool(s)&#8230;. What were the reasons? What does it do? Would you make the same decision today?</p>\n<p><img alt=\"\ud83d\udcc8\" class=\"wp-smiley\" src=\"https://s.w.org/images/core/emoji/16.0.1/72x72/1f4c8.png\" style=\"height: 1em;\" /> <strong>OpenTelemetry: </strong>If your team has weighed the pros and cons of adopting OTel and ultimately decided not to, for technical or philosophical reasons (i.e. not just \u201cwe\u2019re too busy\u201d) \u2014 what are those reasons?</p>\n<p><img alt=\"\ud83d\udcc8\" class=\"wp-smiley\" src=\"https://s.w.org/images/core/emoji/16.0.1/72x72/1f4c8.png\" style=\"height: 1em;\" /> <strong>Instrumentation:</strong>\u00a0what do you do to try and remove cognitive overhead for engineers? How much have you been able to make automatic and magical, and where has the magic failed?</p>\n<p><img alt=\"\ud83d\udcc8\" class=\"wp-smiley\" src=\"https://s.w.org/images/core/emoji/16.0.1/72x72/1f4c8.png\" style=\"height: 1em;\" /> <strong>Consolidation: </strong>I would love to hear any thoughts on tool consolidation vs tool proliferation. Is this primarily driven by execs, or do technical users care too? Is it driven by cost concerns, usability, or something else?</p>\n<h2>Send it to me in an email</h2>\n<p>Please send me your opinions or answers in an email, to my first name at honeycomb dot io, with the subject line \u201cObservability questions\u201d.</p>\n<p>If I end up cribbing from your material, it okay for me to print your name? (As in, \u201cthanks to the people who informed my thinking on this subject, abc xyz etc\u201d). I will not mention your employer or where you work, don\u2019t worry.</p>\n<p>If you send it to me more than a week from now, I probably won\u2019t be able to use it. Augh, I wish I had thought of this in JUNE!!! #ragrets</p>\n<h2><img alt=\"\u2728\" class=\"wp-smiley\" src=\"https://s.w.org/images/core/emoji/16.0.1/72x72/2728.png\" style=\"height: 1em;\" />THANK YOU<img alt=\"\u2728\" class=\"wp-smiley\" src=\"https://s.w.org/images/core/emoji/16.0.1/72x72/2728.png\" style=\"height: 1em;\" /></h2>\n<p>I know this is an incredibly time consuming thing to ask of someone, and I can&#8217;t express how much I appreciate your help.</p>\n<p>P.S. Yes, the title is absolutely a reference to the Buffy musical. Hey, I had to give you guys something fun to read along with my second bleg in less than a month (do people still say &#8220;bleg&#8221;??).</p>\n<p><img alt=\"6 Musical Episodes of TV Shows That Deserve an Encore\" class=\"\" height=\"192\" src=\"https://i0.wp.com/www.tvinsider.com/wp-content/uploads/2015/04/Buffy-Musical-S06E07-1421081425.jpg?resize=342%2C192&#038;ssl=1\" width=\"342\" /></p>\n<p>P.P.S. <strong>Grammar quiz of the day</strong>: should my title read &#8220;opinions ABOUT observability&#8221; or &#8220;opinions ON observability&#8221; ??</p>\n<p>GREAT QUESTION &#8212; and, as it turns out, the preposition you choose may reveal more than you realized.</p>\n<p>&#8220;About&#8221; is used to introduce a topic or subject in a broad, vague, or approximate sense, while &#8220;on&#8221; is used to signal more detailed, specific, formal or serious subject matter (as well as physical objects). &#8220;Let&#8217;s talk about dinner&#8221; vs &#8220;she delivered a lecture on why AI is trying to kill babies.&#8221;</p>\n<p>Or as Xander says, &#8220;To read makes our English speaking good.&#8221;</p>\n<p>The earth is doomed,<br />\n~charity</p>"
            ],
            "link": "https://charity.wtf/2025/10/13/got-opinions-on-observability-i-could-use-your-help-once-more-with-feeling/",
            "publishedAt": "2025-10-13",
            "source": "Charity Majors",
            "summary": "Last month I dropped a desperate little plea for help in this space, asking people to email me any good advice and/or strong opinions they happened to have on the topic of buying software. I wasn\u2019t really sure what to expect \u2014 desperate times, desperate measures \u2014 but holy crap, you guys delivered. To the [&#8230;]",
            "title": "Got opinions on observability? I could use your help (once more, with feeling)"
        },
        {
            "content": [
                "<p>I read an article yesterday, stating that on average, people spend 4 hours and 37 minutes on their phones per day<sup><a href=\"https://explodingtopics.com/blog/smartphone-usage-stats/#time-spent-using-smartphones-annually\" target=\"_blank\">1</a></sup>, with South Africans coming in fourth highest in the world at a whopping 5 hours and 11 minutes<sup><a href=\"https://explodingtopics.com/blog/smartphone-usage-stats/#time-spent-using-smartphones-by-region\" target=\"_blank\">2</a></sup>.</p>\n<p>This figure seems really high to me. If we assume people sleep roughly 8 hours per day, that means that one third of their day is spent on their phones. If we also assume people work 8 hours per day (ignoring the fact that they may be using their phones during work hours), that suggests that people spend over half of their free time (and up to 65% of it) glued to their screens.</p>\n<p>I never wanted to carry the internet around in my pocket. It's too distracting and pulls me out of the present moment, fracturing my attention. I've tried switching to old-school black and white phones before, but always begrudgingly returned to using a smartphone due to the utility of it. The problem, however, is that it comes with too many attention sinks tucked in alongside the useful tools.</p>\n<p>I care about living an intentional and meaningful life, nurturing relationships, having nuanced conversations, and enjoying the world around me. I don't want to spend this limited time I have on earth watching short form video and getting into arguments on Twitter.</p>\n<p><img alt=\"Scarborough\" src=\"https://bear-images.sfo2.cdn.digitaloceanspaces.com/herman/img_1438.webp\" />\n<small style=\"color: grey;\">This is what I enjoy. Picture taken yesterday in Scarborough, South Africa.</small></p>\n<p>I've written at length about how I manage my digital consumption, from <a href=\"https://herman.bearblog.dev/notifications/\">turning off notifications</a> to <a href=\"https://herman.bearblog.dev/slow-social-media/\">forgoing social media entirely</a>. The underlying premise here is that if you're trying to lose weight, you shouldn't carry cookies around in your pockets. And my phone is the bag of cookies in this metaphor.</p>\n<p>We're wired to seek out distraction, novel information, and entertainment, and avoid boredom at all costs. But boredom is where creativity and self-reflection do their best work. It's why \"all the best ideas come when you're in the shower\"\u2014we don't usually take our phones with us into the shower (yet).</p>\n<p>According to Screen Time on my iPhone, on average I spend 30 minutes per day on it, which I think is reasonable, especially considering the most-used apps are by-and-large utility apps like banking and messages. This isn't because I have more self-control than other people. I don't think I do. It's because I know myself, and have set up my digital life to be a positive force, and not an uninspired time-sink.</p>\n<p>There are many apps and systems to incentivise better relationships with our phones, mostly based around time limits. But these are flawed in three ways:</p>\n<ol>\n<li>I'm an adult, I know how to circumvent these limits, and I will if motivation is low.</li>\n<li>Time limits don't affect the underlying addiction. You don't quit smoking by only smoking certain hours of the day.</li>\n<li>The companies that build these apps have tens of thousands of really smart people (and billions of dollars) trying to get me hooked and keep me engaged. The only way to win this game isn't by trying to beat them (I certainly can't), but by not playing.</li>\n</ol>\n<p>The only way I've found to have a good relationship with my phone is to make it as uninteresting as possible. The first way is to not have recommendation media (think Instagram, TikTok, and all the rest). I'm pro deleting these accounts completely, because it's really easy to re-download the apps on a whim, or visit them in-browser. However some people have found that having them on a dedicated device works by isolating those activities. Something like a tablet at home that is \"the only place you're allowed to use Instagram\". I can't comment too much on this route, but it seems reasonable.</p>\n<p>My biggest time sink over the past few years has been YouTube. The algorithm knew me too well and would recommend video after engaging, but ultimately useless video. I could easily burn an entire evening watching absolute junk\u2014leaving me feeling like I'd just wasted what could have otherwise been a beautiful sunset or a tasty home-cooked lasagne. However, at the beginning of this year I learnt that you can turn off your YouTube watch history entirely, which means no recommendations. Here's what my YouTube home screen now looks like:</p>\n<p><img alt=\"Screenshot 2025-10-11 at 08\" src=\"https://bear-images.sfo2.cdn.digitaloceanspaces.com/herman/45-1.webp\" /></p>\n<p>Without the recommendations I very quickly run out of things to watch from the channels I'm subscribed to. It's completely changed my relationship with YouTube since I only watch the videos I actually want to watch, and none of the attention traps. You can turn off your YouTube watch history <a href=\"https://www.youtube.com/feed/history\">here</a>, and auto delete your other Google history (like historic searches and navigation) <a href=\"https://myactivity.google.com/activitycontrols/\">here</a>, which I think is just good practice.</p>\n<p>I also used my adblocker, AdGuard on Safari which has a useful \"block element\" feature, to block the recommended videos on the right of YouTube videos. I use this feature to hide shorts as well, since I have no interest in watching them either, and YouTube intentionally makes them impossible to remove. If you're interested in a similar setup, here are the selectors I use to block those elements:</p>\n<div class=\"highlight\"><pre><span></span>youtube.com###items &gt; ytd-item-section-renderer.style-scope.ytd-watch-next-secondary-results-renderer:last-child\nyoutube.com###sections\nyoutube.com##[is-shorts]\nyoutube.com###secondary\n</pre></div>\n<p>The only media that I do sometimes consume on my phone are my RSS feeds, but it's something I'm completely comfortable with since it's explicitly opt-in by design and low volume.</p>\n<p>While I still have the twitch to check my phone when I'm waiting for a coffee, or in-between activities\u2014because my brain's reward system has been trained to do this\u2014I'm now rewarded with nothing. Over time, I find myself checking my phone less and less. Sometimes I notice the urge, and just let it go, instead focusing on the here and now.</p>\n<p>I think that while the attention-span-degrading effects of recommendation media are getting most of the headlines, what isn't spoken about as much is the sheer number of hours lost globally to our phones (3.8 million years per day, according to my back-of-the-napkin-math). And while people may argue that this could involve productive work or enjoyable leisure, I suspect that the vast (vast!) majority of that time is short-form entertainment.</p>\n<p>My solution may sound overkill to many people, but I can say with absolute certainty that it has turned me into a more present, less distracted, and more optimistic person. I have much more time to spend in nature, with friends, or on my hobbies and projects. I can't imagine trading it in for a tiny screen, ever.</p>\n<p>Give it a try.</p>\n<p><img alt=\"Scarborough\" src=\"https://bear-images.sfo2.cdn.digitaloceanspaces.com/herman/img_1439.webp\" />\n<small style=\"color: grey;\">Happily on the beach for sunset.</small></p>"
            ],
            "link": "https://herman.bearblog.dev/being-present/",
            "publishedAt": "2025-10-13",
            "source": "Herman Martinus",
            "summary": "<p>I read an article yesterday, stating that on average, people spend 4 hours and 37 minutes on their phones per day<sup><a href=\"https://explodingtopics.com/blog/smartphone-usage-stats/#time-spent-using-smartphones-annually\" target=\"_blank\">1</a></sup>, with South Africans coming in fourth highest in the world at a whopping 5 hours and 11 minutes<sup><a href=\"https://explodingtopics.com/blog/smartphone-usage-stats/#time-spent-using-smartphones-by-region\" target=\"_blank\">2</a></sup>.</p> <p>This figure seems really high to me. If we assume people sleep roughly 8 hours per day, that means that one third of their day is spent on their phones. If we also assume people work 8 hours per day (ignoring the fact that they may be using their phones during work hours), that suggests that people spend over half of their free time (and up to 65% of it) glued to their screens.</p> <p>I never wanted to carry the internet around in my pocket. It's too distracting and pulls me out of the present moment, fracturing my attention. I've tried switching to old-school black and white phones before, but always begrudgingly returned to using a smartphone due to the utility of it. The problem, however, is that it comes with too many attention sinks tucked in alongside the useful tools.</p> <p>I care about living an intentional and meaningful life, nurturing relationships, having nuanced conversations, and enjoying",
            "title": "Smartphones and being present"
        },
        {
            "content": [
                "<div class=\"trix-content\">\n  <div>New products don\u2019t need to be revolutionary, life-changing, or disruptive breakthroughs to succeed.<br /><br />Entire categories can roll downhill, gathering complexity as they go. Each product one-upping the next until more becomes too much. The cycle feeds itself, never satiated. Competitors locked in a loop of mutual destruction through perpetual over-improvement.<br /><br />When that happens, the door cracks open for something new.<br /><br />The newcomer doesn\u2019t have to meet the others where they are. It just has to feel right \u2014 like someone opened the curtains and let the sun back in. The type of product that lets people exhale and say, \u201cfinally!\u201d<br /><br />Not groundbreaking. Just grounded. Standing where everyone else forgot to.<br /><br /></div><div>-Jason</div>\n</div>"
            ],
            "link": "https://world.hey.com/jason/the-next-product-42d6eaf9",
            "publishedAt": "2025-10-13",
            "source": "Jason Fried",
            "summary": "<div class=\"trix-content\"> <div>New products don\u2019t need to be revolutionary, life-changing, or disruptive breakthroughs to succeed.<br /><br />Entire categories can roll downhill, gathering complexity as they go. Each product one-upping the next until more becomes too much. The cycle feeds itself, never satiated. Competitors locked in a loop of mutual destruction through perpetual over-improvement.<br /><br />When that happens, the door cracks open for something new.<br /><br />The newcomer doesn\u2019t have to meet the others where they are. It just has to feel right \u2014 like someone opened the curtains and let the sun back in. The type of product that lets people exhale and say, \u201cfinally!\u201d<br /><br />Not groundbreaking. Just grounded. Standing where everyone else forgot to.<br /><br /></div><div>-Jason</div> </div>",
            "title": "The next product"
        },
        {
            "content": [
                "<p>&quot;It's not this \u2014 it's that.&quot;</p>\n<p>AI writing is a scourge on the internet. Often it just hurts to read.</p>\n<p>I do not enjoy using AI to write anything &quot;as me&quot; or anything where I am trying to make the reader feel something or believe something. I <em>do</em> usually have an agent or two proofread my posts. And they do not pull their punches.</p>\n<p>There are plenty of documents that I <em>do</em> let AI write. Technical documents, READMEs and the like aren't writing that I want to influence a reader's emotions. And I often find writing them to be a chore.</p>\n<p>Unfortunately, most LLMs write in a way that I find to be more than a little bit grating.</p>\n<p>You've probably heard about this standard technique that you can use to make an LLM sound more like you: include some of your own writing in the prompt as an example.</p>\n<p>But I don't actually want the sorts of docs I'm talking about to sound like me. My written style is often...fairly casual and a little meandering.</p>\n<p>I <em>can</em> write in a crisp, clear, concise voice. But writing well takes effort. More often than not, when it feels like a chore, it's what stops me from releasing a hack or a project.</p>\n<p>When I started to think about how to cajole the model into writing like I was taught in my high school English and journalism classes, I figured that the way I learned might work for an LLM, too.</p>\n<p><a class=\"glightbox\" href=\"https://blog.fsck.com/assets/2025/10/strunk-and-white.jpg\"><img alt=\"strunk and white\" src=\"https://blog.fsck.com/assets/2025/10/strunk-and-white.jpg\" /></a></p>\n<p>I ended up with the Project Gutenberg digitization of <a href=\"https://www.gutenberg.org/files/37134/37134-h/37134-h.htm\">Strunk's out-of-copyright 1920 edition</a>.</p>\n<p>My original intent was to turn this into a skill for <a href=\"https://blog.fsck.com/2025/10/09/superpowers/\">Superpowers</a>, but I'm not quite there yet.</p>\n<p>I hauled down the HTML, converted it to Markdown and asked Claude to start to cut out sections (like spelling) that are less necessary for an LLM.</p>\n<p>Claude refused.</p>\n<p>Well, more accurately, Anthropic's IP-protection filter on Claude threw a fit and refused to allow it to summarize, edit or rewrite this clearly out of copyright work.</p>\n<p>Thankfully, GPT-5 Codex had no such reservations.</p>\n<p>Here's a trivial example of Claude writing the first part of the README for an upcoming project.</p>\n<p>Prompt: <code>Please study this project and write a README.md for it.</code></p>\n<p><a class=\"glightbox\" href=\"https://blog.fsck.com/assets/2025/10/scr-20251013-qwxw.png\"><img alt=\"SCR 20251013 qwxw\" src=\"https://blog.fsck.com/assets/2025/10/scr-20251013-qwxw.png\" /></a></p>\n<p>Here's the same example, with exactly the same prompt. The only difference is that I had Claude read <a href=\"https://github.com/obra/the-elements-of-style/blob/main/elements-of-style.md\">The Elements Of Style</a> first:</p>\n<p><a class=\"glightbox\" href=\"https://blog.fsck.com/assets/2025/10/scr-20251013-qwzl-2.png\"><img alt=\"SCR 20251013 qwzl 2\" src=\"https://blog.fsck.com/assets/2025/10/scr-20251013-qwzl-2.png\" /></a></p>\n<p>The whole thing ended up about 30% shorter and I like the style more.</p>\n<p>My current Markdown version of <a href=\"https://github.com/obra/the-elements-of-style/\">The Elements Of Style</a> clocks in at about 12,000 words. That's enough tokens that I wouldn't include in every session, but having my robot buddy read it before creating prose docs for human consumption is something I find quite useful.</p>\n<p>If you try this technique and it works well for you, drop me a line. If it goes completely off the rails, <em>definitely</em> drop me a line.</p>"
            ],
            "link": "https://blog.fsck.com/2025/10/13/this-one-weird-trick-makes-the-ai-a-better-writer/",
            "publishedAt": "2025-10-13",
            "source": "Jesse Vincent",
            "summary": "<p>&quot;It's not this \u2014 it's that.&quot;</p> <p>AI writing is a scourge on the internet. Often it just hurts to read.</p> <p>I do not enjoy using AI to write anything &quot;as me&quot; or anything where I am trying to make the reader feel something or believe something. I <em>do</em> usually have an agent or two proofread my posts. And they do not pull their punches.</p> <p>There are plenty of documents that I <em>do</em> let AI write. Technical documents, READMEs and the like aren't writing that I want to influence a reader's emotions. And I often find writing them to be a chore.</p> <p>Unfortunately, most LLMs write in a way that I find to be more than a little bit grating.</p> <p>You've probably heard about this standard technique that you can use to make an LLM sound more like you: include some of your own writing in the prompt as an example.</p> <p>But I don't actually want the sorts of docs I'm talking about to sound like me. My written style is often...fairly casual and a little meandering.</p> <p>I <em>can</em> write in a crisp, clear, concise voice. But writing well takes effort. More often than not, when it feels like a chore,",
            "title": "This one weird trick makes the AI a better writer."
        },
        {
            "content": [],
            "link": "https://interconnected.org/home/2025/10/13/dichotomy",
            "publishedAt": "2025-10-13",
            "source": "Matt Webb",
            "summary": "<div> <p>Loosely I can see two visions for the future of how we interact with computers: cyborgs and rooms.</p> <p>The first is where the industry is going today; I\u2019m more interested in the latter.</p> <h3>Cyborgs</h3> <p>Near-term, cyborgs means wearables.</p> <p>The original definition of cyborg by Clynes and Kline in 1960 was of <em>a human adapting its body to fit a new environment</em> (<a href=\"https://interconnected.org/home/home/2020/05/20/cyborgs_and_emotions\">as previously discussed</a>).</p> <p>Apple AirPods are cyborg enhancements: transparency mode helps you hear better.</p> <p><a href=\"https://www.meta.com/gb/ai-glasses/\">Meta AI glasses</a> augment you with better memory and the knowledge of the internet \u2013 you mutter your questions and the answer is returned in audio, side-loaded into your working memory. Cognitively this feels just like thinking hard to remember something.</p> <p>I can see a future being built out where I have a smart watch that gives me a sense of direction, a smart ring for biofeedback, smart earphones and glasses for perfect recall and anticipation\u2026 Andy Clark\u2019s <a href=\"https://www.edge.org/conversation/andy_clark-natural-born-cyborgs\">Natural Born Cyborgs</a> (2003) lays out why this is perfectly impedance-matched to how our brains work already.</p> <p>Long term? I\u2019ve joked before about <a href=\"https://interconnected.org/home/2020/12/23/turpentine\">a transcranial magnetic stimulation helmet that would walk my legs to work</a> and this is the cyborg direction of",
            "title": "Cyborgs vs rooms, two visions for the future of computing"
        },
        {
            "content": [],
            "link": "https://www.ssp.sh/blog/beyond-basic-etl/",
            "publishedAt": "2025-10-13",
            "source": "Simon Spati",
            "summary": "<p>Most data teams spend 80% of their time wrestling with infrastructure\u2014writing custom UPSERT logic, building incremental loading from scratch, or debugging why their Airflow DAGs failed again at 2 AM. Meanwhile, the business is still waiting for those critical data insights.</p> <p>This article is a follow-up to <a href=\"https://www.ssp.sh/blog/declarative-data-stack-enterprise/\" rel=\"\">Part 1</a>, where we explored declarative data stacks. Here, we dive into the specific capabilities that let you skip most of the engineering challenges and focus on delivering business value. You&rsquo;ll discover how to extract and load data from multiple sources with built-in quality controls, configure complex write strategies like SCD2 and UPSERT with simple configuration changes, and transform data using SQL that transpiles seamlessly across BigQuery, Snowflake, Databricks, and DuckDB. We&rsquo;ll also explore how to generate production-ready orchestration workflows without writing custom code, all while testing locally before deploying to production.</p>",
            "title": "Beyond Basic ETL: Enterprise Data Capabilities Without the Complexity"
        },
        {
            "content": [
                "<p>Thanks to everyone who participated in ACX Grants, whether as an applicant, an evaluator, or a funder.</p><p>We received 654 applications this year, and were able to fund 42. To the other 612: sorry! Many of you had great ideas that we couldn&#8217;t fund for contingent reasons - sometimes because we couldn&#8217;t evaluate them at the level of depth it would have taken to feel comfortable supporting them, or because we had complicated conflicts of interest, or just because we didn&#8217;t have enough money. Some of you had ideas that were good but not a match for our particular grantmaking philosophy. Finally, a few of you were suffering from LLM psychosis. Please get help.</p><p>Of the 42 grantees, 40 have answered our email asking for confirmation that they still want the grant. I&#8217;m still waiting for confirmation emails from Lewis Wall and Nishank B. If you&#8217;re reading this and don&#8217;t think you got a confirmation email, check your spam folder. If it&#8217;s not in your spam folder, email me at scott@slatestarcodex.com. If you can&#8217;t reach me or I don&#8217;t respond, DM me on Substack or Twitter. I&#8217;ll give you until November 1 to get in touch, after which point the grant will be withdrawn. There are also a few projects so deep in stealth I don&#8217;t have permission to share their existence; I will mention these as they become public.</p><p>More information, and the all-important thanks to contributors, are after the list, which is:</p><p><strong>Kasey Markel, $10K</strong>, for genetically engineered corn. Kasey and his team at Semilla Nueva use prime editing, a new genetic technology, to create corn which is rich in zinc, iron, essential amino acids, and other nutrients frequently deficient in corn-heavy poor country diets. Our grant helps fund greenhouse space, enzymes, DNA synthesis, and scientist time, and will let them expand faster into new regions that require corn with different genetic backgrounds.</p><p><strong>Maximillian Seunik, $50K</strong>, for <a href=\"https://screwworm.org/\">Screwworm Free Future</a>. The screwworm is a nasty flesh-eating worm that infests cattle and occasionally humans. It was laboriously eliminated from the US in the 1960s, from Mexico and Central America in the 90s, and finally fought to a standstill along the defensible chokepoint of the Panama isthmus in 2006. Since then, the US has regularly dropped sterile male screwworms over Panama; these distract the females and prevent them from advancing back north. During COVID, the parasite breached the barrier; it&#8217;s now back as far as Mexico, and likely to re-enter the US soon. SFF wants to encourage the development and testing of genetic biocontrol approaches, alongside other technology, to rapidly suppress screwworm populations. If these techniques work in screwworms, they could later be applied to mosquitoes, ticks, and other pests.</p><p><strong>Markus Englund, $50K</strong>, for software to detect data fabrication. This kind of thing is a perennial ACX Grants favorite, and we don&#8217;t always expect it to go anywhere, but Markus got our attention by saying that he&#8217;s already built the tool, already scanned 92 published papers, and found &#8220;irregularities&#8221; in five of them, inspiring two corrigenda and one likely upcoming retraction. Five out of ninety-two is a crazy result, and we&#8217;re almost scared to see what happens when he applies his program to a further 20,000 papers, which is the amount that our grant will be paying for. <em>If you&#8217;re interested in helping verify cases of suspected data fabrication and presenting the evidence in Pubpeer comments or emails to journal editors, please contact Markus at <a href=\"mailto:markus@englund.dev\">markus@englund.dev</a>, especially if you have solid knowledge of statistics or biology.</em></p><p><strong>Micaella Rogers and</strong> <strong>Tom Daniels, $50K</strong>, for lead-acid battery recycling. Unsafe lead-acid battery recycling is a major contributor to global lead burden; it&#8217;s hard to figure out how literally and causally to take the highest estimates of damage, but they suggest up to 350,000 deaths per year and $170 billion in lost productivity. Some governments have curtailed this problem by making customers pay a deposit along with a new battery, which they get back when they return the battery to a safe recycling facility. <a href=\"https://www.labrecyclinginitiative.com/\">Micaella and Tom&#8217;s organization</a> wants to advise the Philippines government on how to do the same.</p><p><strong>Aaron Silverbook, $5K</strong>, for approximately five thousand novels about AI going well. This one requires some background: critics claim that since AI absorbs text as training data and then predicts its completion, talking about dangerous AI too much might &#8220;hyperstition&#8221; it into existence. Along with the rest of the AI Futures Project, I wrote <a href=\"https://blog.ai-futures.org/p/against-misalignment-as-self-fulfilling\">a skeptical blog post</a>, which ended by asking - if this were true, it would be great, right? You could just write a few thousand books about AI behaving well, and alignment would be solved! At the time, I thought I was joking. Enter Aaron, who you may remember from his previous adventures in <a href=\"https://www.astralcodexten.com/p/defying-cavity-lantern-bioworks-faq\">mad dental science</a>. He and a cofounder have been working on an &#8220;AI fiction publishing house&#8221; that considers itself state-of-the-art in producing slightly-less-sloplike AI slop than usual. They offered to literally produce several thousand book-length stories about AI behaving well and ushering in utopia, on the off chance that this helps. Our grant will pay for compute. We&#8217;re still working on how to get this included in training corpuses. <em>He <a href=\"https://www.hyperstitionai.com/\">would appreciate </a>any plot ideas you could give him to use as prompts.</em></p><p><strong>Charlie Mothrop, $5K</strong>, for &#8220;normie-friendly prediction market interfaces&#8221;. Charlie has already made some tools for visualizing Manifold and Polymarket results; for example, a bot that tweets sudden dramatic changes on important Manifold questions.</p><p><strong>Ben Engebreth, $6K</strong>, for a new asteroid-hunting algorithm. Modern telescopes produce massive databases of how the sky looks at different times. Ben has developed an improved algorithm for searching these databases, linking detections in different images, and determining whether the detections match the profile of a previously-undiscovered asteroid. He wants money to buy enough compute to run his algorithm on the Rubin Observatory&#8217;s Legacy Survey of Space and Time dataset.</p><p><strong>Lewis Wall, $50K</strong>, for therapeutic food in Ethiopia. After years of drought, war, and locusts, the Tigray region of Ethiopia is experiencing a major famine. Lewis and the Fewsi Foundation will produce a special peanut butter optimized to relieve the worst effects of childhood malnutrition. This grant will fund a giant commercial mixer to help produce the peanut butter, plus some of the raw material and distribution cost.</p><p><strong>Daniela Shuman, $100K</strong>, to improve eligibility for organ donation. Many people want to donate an organ during their lifetime, but are turned away for minor health problems (e.g. being overweight, being a smoker). Daniela&#8217;s org, <a href=\"https://www.projectdonor.org/\">Project Donor</a>, gives these people free high-quality medical assistance to solve their problems (e.g. lose weight, quit smoking), then encourages them to reapply. They report having caused &gt;100 successful donations so far, but are growing fast and think there&#8217;s a &#8220;market&#8221; to enable as many as 2,000 extra transplants per year. I was excited by them not only because of <a href=\"https://www.astralcodexten.com/p/my-left-kidney\">my own</a> frustrating experience with organ donation, but because they claim incredible cost-effectiveness numbers - maybe as little as $2,500 per life saved.</p><p><strong>David Rozado, $50K</strong>, to study truth-seeking and bias in LLMs. Suppose you ask a chatbot about minimum wages, and it summarizes economic research on the topic. Or suppose it&#8217;s 2030, GPT-7 has outpaced human economists, and you want it to do original analysis. How can you be sure that it&#8217;s not falling victim to the same political biases that might plague the rest of us? Professor Rozado studies this question in depth, working on tools that measure bias (for example, whether the AI will evaluate study methodologies consistently when the results favor different political views) and trying to determine what interventions (prompts, fine-tuning, etc) best ensure AI neutrality. Philip Tetlock, of superforecasting fame, will assist with this research.</p><p><strong>Adam Morris, $15K</strong>, to train LLMs to honestly report their internal decision processes via introspection. Conventional wisdom says AIs can&#8217;t introspect - they&#8217;re not even consistently aware they&#8217;re chatbots unless you prompt them to remember. But Adam and his collaborators <a href=\"https://arxiv.org/abs/2505.17120\">have found</a> some glimmers of surprisingly good introspective ability into decision-making processes - for example, ability to explain how past fine-tuning affects the relative values of different goods - and has some evidence that this can improve with training. He wants to create an introspection benchmark, and to see what happens when you train AIs to succeed on that benchmark. This could supplement other forms of interpretability, improve chain of thought faithfulness, and help us answer questions about AI consciousness. <em>Adam is excited to chat with potential collaborators who have experience in technical AI safety work (especially in interpretability, CoT faithfulness, and fine-tuning frontier open models); reach out to him at <a href=\"mailto:thatadammorris@gmail.com\">thatadammorris@gmail.com</a>.</em></p><p><strong>Alexander (Olek) Pisera, $50K</strong>, for yeast-based manufacturing. Producing &#8220;biologics&#8221; - protein-based drugs like insulin or monoclonal antibodies - is often very expensive. One technique is to genetically engineer yeast to secrete the protein you want, but the yeast doesn&#8217;t always cooperate, and yields can be low. Alexander is building a platform that automates the evolution of output-increasing genes, eventually resulting in strains better optimized for this sort of production. If this works, it could help poor countries do their own biologics manufacturing, bypassing expensive middlemen and tricky logistics.</p><p><strong>Nino O&#8217;Shea-Nejad, $5K</strong>, to investigate electrical stunning in shrimp and other crustaceans. Shrimp welfare&#8217;s inherent weirdness turned it first into a meme, then a celebrity EA cause, and finally a serious field of charity. The idea that stunning shrimp before killing them improves welfare is intuitively appealing, but the evidence base remains limited. Nino will review the scientific literature across decapod crustaceans, and identify what future research would help determine whether electrical stunning reliably renders them insensible.</p><p><strong>David Carel, $150K</strong>, to help put air purifiers in schools. Pure air is an easy sell, but an increasing body of research suggests it may have <a href=\"https://cleanschoolair.org/\">unexpected advantages</a>, including raising test scores in classrooms. This might just be because students with fewer respiratory diseases take fewer absences, or there might be more interesting connections between air pollution, respiratory health, focus, and achievement. Many schools bought air purifiers during COVID but forgot about them afterwards, or turned them off because they were too noisy; now they languish in closets, fully functional but unused. David wants to lobby schools to use the devices they have, and to develop quieter devices that are better suited for classrooms. <em>If you&#8217;re a school, potential funder, or other would-be collaborator, please contact him <a href=\"https://cleanschoolair.org/contact\">here</a>.</em></p><p><strong>Misha Gurevich, $50K,</strong> to manufacture far-UVC lamps. Far-UVC is a type of ultraviolet light that kills germs rapidly; in a room with correctly-installed far-UVC lighting, viruses and bacteria die before they can reach another host, and the spread of contagious diseases plummets. In a world where this technology reached its full potential, respiratory pandemics like flu and coronavirus would cease to occur. Until now, these lamps have been limited to a few research prototypes. Last year, an ACXG-sponsored study worked to establish that they are safe for human use; results were reassuring. The next step is to produce them at scale as a consumer product for use in schools, daycares, and houses. <em>Misha&#8217;s company Aerolamp has<a href=\"https://aerolamp.net/products/devkit\"> an early developer&#8217;s kit lamp on sale now</a>, and is looking to hire an industrial designer experienced in safety and compliance who can help them transition to a mass-manufacturable version. If that&#8217;s you, get in touch with them <a href=\"https://aerolamp.net/pages/contact\">here</a>.</em> <em>Misha is a personal friend and a longtime ACXG evaluator; due to conflict of interest, this grant is being covered in conjunction with an outside funder.</em> </p><p><strong>Dan Elton, $25K</strong>, for a &#8220;<a href=\"https://metascienceobservatory.org/\">metascience observatory</a>&#8221;. Dan wants to use AI to &#8220;generate metrics that shed light on the health of science&#8221; - what percent of studies in different fields are retracted, challenged, successfully reproduced, etc. Although many people are monitoring reproducibility, Dan thinks he can develop an AI pipeline to do it at massive scale, eventually expanding to all of science.</p><p><strong>Elaine Perlman, $94K</strong>, to continue lobbying for kidney donation incentives. Elaine works with Waitlist Zero and the Coalition To Modify NOTA to promote the <a href=\"https://www.endkidneydeathsact.org/\">End Kidney Deaths Act</a>, which offers valuable tax credits to kidney donors. They estimate this bill could save 100,000 lives over the next decade, and save the government $50 billion/year (dialysis is very expensive, Medicare currently covers it, and transplantees would no longer need it). Since our previous grant last year, the EKDA has been cosponsored by 29 members of Congress, discussed in the <a href=\"https://jamanetwork.com/journals/jama/article-abstract/2836689\">Journal of the American Medical Association</a>, and profiled in <a href=\"https://www.latimes.com/opinion/story/2023-07-09/kidney-donation-disease-transplant-ethics-national-organ-transplant-law\">the LA Times</a>. The prediction markets are down to only <a href=\"https://manifold.markets/patbl/will-the-end-kidney-deaths-act-or-s\">25% chance it gets passed this year</a>, but I&#8217;m optimistic about 2026 - 2027</p><p><strong>Manoj Nathwani, $12K</strong>, for <a href=\"https://telemedicineabc.com/allo-munganga\">Allo Munganga</a>, a telemedicine platform for the DRC. There is ongoing conflict in East Congo, and &#8220;all physicians have fled after armed groups took over&#8221;. But there are still some working pharmacies and labs, and Manoj wants to pull together telemedicine infrastructure so patients can continue getting diagnoses, lab tests, and prescriptions. He has partnered with a local medical group and will be using our money to buy technology, pay salaries and offer free consultations to patients over the phone.</p><p><strong>Jacob Witten, $80K</strong>, to research mRNA for pulmonary disease. We are proud to fund Jacob&#8217;s effort, but his work is still in stealth and we can&#8217;t provide further details.</p><p><strong>Thomas Briggs, $5K</strong>, for the Center for Educational Progress. <a href=\"https://www.educationprogress.org/\">CEP</a> was founded by Jack Despain Zhou, who you may know better by his blogging pseudonym <a href=\"https://www.tracingwoodgrains.com/\">TracingWoodgrains</a>; he is currently on leave as he pursues his legal training, but will return next year. The Center advocates effective pedagogy, especially ability tracking, ie letting faster and slower students each move at their own pace. In practice, this seems to mean a lot of legal briefs telling San Francisco why they shouldn&#8217;t ban algebra in middle schools. We support their work and are happy to fill their suspiciously-low funding request.</p><p><strong>Simon Chen, $25K</strong>, for automated forecasting work. There are already LLMs that are pretty good at forecasting; Simon wants to do the &#8220;unfun&#8221; work of optimizing them. In his proposal, different model parameters like prompt, temperature, AI model, etc, &#8220;form coalitions&#8221; based on past performance, with the exact details optimized against past successes. Our grant pays for his time and compute, and he hopes that once he has a working prototype he can get more money by winning forecasting tournaments.</p><p><strong>Felix Nwose, $10K, </strong>for fish welfare in Nigeria. Felix is an aquaculture specialist who plans to hold workshops to train local fish farmers in techniques that improve conditions and lower mortality.</p><p><strong>Jorge Bastos, $70K</strong>, for AI that curates bio datasets. There are exabytes (= 1 billion gigabytes) of high quality biology data; most of it goes unused because it&#8217;s not compatible with other datasets or tools. Jorge&#8217;s startup, Covalent, uses AI to put these in standard machine-readable format. At the very least, this would save biologists thousands of hours per year; in a best-case scenario, it could bring forward the golden age of AI-assisted biology predicted by people like Dario Amodei.</p><p><strong>Greg Sadler, $65K</strong>, for <a href=\"https://www.goodancestors.org.au/\">Good Ancestors Australia</a>. Our first grants round in 2021 supported ACX commenter Nathan Ashby beginning policy work in Australia. His work eventually evolved (it&#8217;s complicated) into GAA -now one of Australia&#8217;s most influential AI safety organizations, working with the public, MPs and their staffers to incorporate the x-risk/alignment perspective into Australian AI policy and legislation. We are excited to fund their continued operation. Australia is also a key base for building influence in tiny Pacific Island nations; although these may not have cutting-edge AI industries, they collectively form a powerful bloc in one-country-one-vote forums like the UN.</p><p><strong>Yonatan Grad, $78K</strong>, for research and advocacy on antibiotic resistance. Recently, pharma has developed new antibiotics. Standard practice suggests that doctors hold these in reserve, deploying them only against bacteria that have develop resistance to all the old ones. Yonatan, a professor of immunology at Harvard, has models suggesting that the optimal strategy is more complicated, and might differ by disease: in some cases, you should hit the pathogen with everything you have all at once, to prevent resistance from developing in the first place. Our grant funds his work improving his models and building connections with medical policy-makers.</p><p><strong>Matthew Loftus, $45K</strong>, for an HIV/TB clinic in Kenya. As a doctor working &#8220;on the ground&#8221; in developing world medical care, <a href=\"https://matthewandmaggie.org/\">Matthew </a>was a key voice in the recent campaign to save PEPFAR funding. This campaign ended in partial victory, with most key programs maintained but some infrastructure and support funding scaled back. Matthew will spend most of our grant integrating his local hospital&#8217;s HIV/TB clinic with their main operations (futureproofing them against infrastructure/support cuts), and the rest of it to continue his role as an influencer and educator about foreign aid and developing-world medicine.</p><p><strong>Chetan Kharbanda, $30K</strong>, to help build <a href=\"https://www.impactfulgiving.in/advisory\">an effective altruist ecosystem in India</a>. Although some rich people like Bill Gates start with strong opinions on what they want to fund, much of the HNWI philanthropy space depends on people who go around to wealth management firms and help the rich understand their charitable options. Chetan and his cofounder want to make sure that India&#8217;s millionaires - 33,000 of whom get minted every year - are exposed to EA principles and opportunities. <em>Their current project is an animal welfare funding circle; if you&#8217;re in India and interested in participating, please let them know.</em></p><p><strong>Kurtis Lockhart, $85K</strong>, to continue research into African urbanism. Africa suffers from a sort of malignant anarcho-tyrannical NIMBYism, where the ability to build good urban infrastructure like roads, sanitation systems, or apartment buildings is gated behind an impossible series of permits and applications that the government never grants, but it&#8217;s easy to build endless illegal shantytowns. Kurtis runs the <a href=\"https://www.aul.city/\">African Urban Lab</a>, a joint project of the African School of Economics in Zanzibar and the <a href=\"https://chartercitiesinstitute.org/\">Charter Cities Institute</a>. They hope to build an &#8220;African YIMBY movement&#8221; within African academia/government to improve the situation in time to help the 900 million new people predicted to move to African cities in the next 25 years. Our grant will fund road planning advocacy, a satellite-based land tax system, and improvements to African universities&#8217; urban planning curricula. Read more about Kurtis&#8217; agenda in his Asterisk article, <a href=\"https://asteriskmag.com/issues/11/yes-in-my-bamako-yard\">Yes In My Bamako Yard</a>.</p><p><strong>Bryan Davis, $50K</strong>, for software tools that speed FDA applications. Critics often focus on the expensive studies required for FDA approval, but those at least have a public interest benefit; a less-well-known hurdle is the logistics of the application itself, which use &#8220;an opaque, Adobe-only file in a deprecated format that resists integration into collaborative workflows&#8221;; most companies hire expensive consultants to explain the software to them rather than risk ruinous errors. Bryan and his team are working on open-source software that integrates with the FDA&#8217;s preferred format and automate the &#8220;application consultant&#8221; role. Our grant pays for their MVP.</p><p><strong>Eli Elster, $13K</strong>, to research traditional psilocybin use in Africa. Psilocybin, aka magic mushrooms, is in the process of being integrated into mainstream psychiatric practice; it is already approved for treatment-resistant depression in Australia, and undergoing (currently promising) FDA trials in the United States. Much of what we know about the preparation and administration of psilocybin - including widespread ideas about &#8220;set and setting&#8221; and &#8220;integration&#8221; - comes from traditional use by the Mazaetec Indians. In 2023, anthropologists discovered that traditional healers in Lesotho, Africa also use psilocybin mushrooms - the first time such a practice has been found in the Old World  - and that they seem to prepare and administer it differently from the Native Americans. <a href=\"https://www.eselster.org/\">Eli</a> and his collaborator Betsy Sethathi conducted the first in-depth fieldwork on the topic earlier this year; our grant funds a return trip to Lesotho to further investigate their ethnobotanical practices and see if we can learn anything from them.</p><p><strong>JD Bauman, $40K</strong>, to help fund <a href=\"https://www.christiansforimpact.org/\">Christians For Impact</a>. Christians are a large and charitably-inclined demographic, but tend to bounce off the effective altruist movement after we start talking about becoming bodiless immortal machine-gods. JD and his team of Christian EAs network with churches and introduce them to everything else - all the ideas about how to realign one&#8217;s life around helping people in need. They have a <a href=\"https://christandcounterfactuals.substack.com/\">blog</a>, a <a href=\"https://www.christiansforimpact.org/get-1-on-1-advice\">career counseling network</a>, and a <a href=\"https://www.christiansforimpact.org/2025-conference\">conference</a> that recently scored a guest appearance by the Archbishop of Canterbury. Our grant helps them publicize and expand their career counseling work.</p><p><strong>Bengusu Ozcan, $30K</strong>, to raise awareness on AGI among EU policymakers. We were encouraged by the reception of the AI 2027 scenario in the United States. Bengusu&#8217;s team at the Center for Future Generations works on producing similar scenarios in Europe and explaining them to EU policy-makers. Our grant helps pay for their facilities, administrative overhead, and a quantitative dashboard add-on to the scenario presentations.</p><p><strong>Sam Glover, $60K</strong>, to fight for free speech in the UK. These are dark times for UK speech on both sides of the aisle: the left is upset that speaking in support of Palestine Action is now considered an act of terrorism, and the right is upset about arrests for racist tweets. So far, pushback has been siloed by cause and partisan affiliation. Sam and his two co-founders are early-career bloggers and aspiring public intellectuals who want to build a united nonpartisan free speech movement. They&#8217;re still in stealth, but I&#8217;ll promote their website as soon as it becomes public.</p><p><strong>Saeed Ahmad, $10K</strong>, to build an epidemic reporting system in Liberia. Liberia has been on the forefront of some recent pandemics, including Ebola and monkeypox. Saeed is currently based in Liberia, and wants to build infrastructure to translate local rumors about unusual diseases into reports to the national health authorities, including community reporters, phone hotlines, and social media.</p><p><strong>Subhash Sadhu, $23K</strong>, for low-cost ultrasound scanners. Unlike fancier imaging modalities like CT, ultrasounds are safe and portable; there&#8217;s no reason to gate them behind hospital access, and broader ultrasound data could improve understanding of diseases from acid reflux to reproductive issues. Subhash and cofounder Siva Swaminathan are building a cheap wearable ultrasound &#8220;patch&#8221; potentially suitable for developing countries, people in inaccessible regions, researchers, or biohackers, plus an AI interpretation system. Our grant helps pay for components and a preliminary study to build a prototype.</p><p><strong>Nuno Sempere, $50K</strong>, for disaster forecasting and response. Nuno runs Sentinel, a team of superforecasters which tracks incipient disasters (pandemics, wars, etc) and brainstorms pre-hoc and post-hoc responses. Their model for response are groups like VaccinateCA, a small team of Californians who noticed that the state&#8217;s COVID vaccine policy was disorganized and made a site that helped connect people with spare vaccination capacity. You can see their blog <a href=\"https://xrisk.fyi/\">here</a>. <em>Nuno is an ACX Grants evaluator; due to conflict of interest, this grant is being covered in conjunction with an outside funder.</em></p><p><strong>Alejandro Acelas, $24K</strong>, automated customer screening for DNA orders. When researchers or biotech companies need DNA, they send the sequence to a synthesis company, which then sends them back a finished product. But terrorists can also use these companies to make bioweapons on demand. Some (not all) companies check whether the  sequence looks like a bioweapon first, and if so, spend hours manually trying to figure out if the customer has a legitimate reason to want such a thing. Alejandro and his cofounder are working on an AI screening tool to automate the latter part of this process.</p><p><strong>G, $50K, </strong>for a secret project involving snakes. Of all factory-farmed animals, one of the worst lots goes to the hundreds of millions of mice raised each year as snake food. During life, they are confined in plastic bins with minimal enrichment and no ventilation; after reaching maturity, they are killed by crude methods like gassing or freezing, or transported directly to a a brutal death at the fangs of one of nature&#8217;s scariest predators. G is working on a techno-solution, but her effort is still in stealth and we can&#8217;t provide further details.</p><p><strong>Harry Warne, $25K</strong>, for AI assisted speech amplification. Millions of people, including Harry, have vocal cord diseases that prevent them from speaking above a whisper. Microphones can make their voices louder, but not clearer - an amplified whisper sounds nothing like normal speech. But this type of problem is a good fit for AI, which can be trained to recognize dysphonic speech and match it to its normal equivalent. Harry has a prototype battery-powered voice converter which outputs normal-sounding speech almost fast enough to be useful. Our grant will help him clear the last few hurdles and bring it to market.</p><p>I&#8217;m still working on shopping a few more projects to VCs, and I haven&#8217;t gotten to the impact certificates yet. I&#8217;ll announce those once they happen.</p><h2>Credits</h2><p>A huge thanks to everyone who supported ACX Grants. </p><p>First and most important, our funders: Craig Falls, Calvin French-Owen, Shauna Kravec, Anton Makiievskyi, Geoff Price, Adam Winkel, and several people who asked to remain anonymous.</p><p>Second, the <a href=\"https://manifund.com\">Manifund</a> team. Manifund, a charitable spinoff of Manifold Markets, handled our funds, disbursement, infrastructure, and miscellaneous coding needs. Special thanks to Austin Chen for taking point on this.</p><p>Third, the many expert evaluators who volunteered their time to look over shortlisted grants, discuss them with the rest of the team, and help us settle on a final list. I still haven&#8217;t finished getting everyone&#8217;s permission to list their names, and will be expanding the &#8220;et al&#8221;s as these come in. By subject:</p><ul><li><p><em>Generalist:</em> Austin Chen, Misha Gurevich, et al</p></li><li><p><em>Biology:</em> Metacelsus, Sarah Constantin, Ruth Hook</p></li><li><p><em>Health:</em> Simon Grimm, Trevor Klee, Eryney Marrogi</p></li><li><p><em>Animal:</em> Ozy Brennan, et al.</p></li><li><p><em>Forecasting:</em> Austin Chen, Nuno Sempere</p></li><li><p><em>Development:</em> Meir Brooks, Andrew Martin, et al</p></li><li><p><em>AI:</em> Oli Habryka, et al</p></li><li><p><em>Metascience:</em> Stuart Buck</p></li><li><p><em>Meta: </em>Clara Collier, et al</p></li><li><p><em>External consultants:</em> Paige Brocidiacono, Jay Lubow, Neel Nanda, John Schilling, Alex Turner, Robert Yaman, et al</p></li></ul><p>Fourth, everyone who deserves credit but whom I failed to thank above, for various reasons. These include:</p><ul><li><p>The 100 or so (!) people who offered to help as evaluators/consultants, but who we didn&#8217;t end up calling on because there weren&#8217;t any grants that were a clear match for their area of expertise.</p></li><li><p>The many people who offered to give special services like accounting and consulting to ACX grantees. I&#8217;ve gathered this into a directory and put it in the grantees Discord server. If you should have access but don&#8217;t, email me.</p></li><li><p>The people who offered funding after I stopped checking the funding offers form (sorry!) or who were considering offering funding but asked me technical questions about Manifund that I failed to follow up on appropriately.</p></li><li><p>Evaluators who didn&#8217;t answer my short-notice question about whether I had permission to list their names here.</p></li><li><p>The lawyers who worked with us or recommended colleagues to work with us, - in some cases pro bono, in others more-than-earning their fees.</p></li><li><p>VCs, representatives of other philanthropic foundations, and friendly professionals who I&#8217;m still gradually working on following up with.</p></li></ul><p>Finally, thanks to all applicants. It&#8217;s a joy to see how many people are still coming up with big ideas, even if I can only fund a small fraction.</p><p>If any of you are unhappy with how you have been credited or not-credited, please email me at scott@slatestarcodex.com.</p><p>The next ACX Grants round will probably begin late 2026 or early 2027.</p>"
            ],
            "link": "https://www.astralcodexten.com/p/acx-grants-results-2025",
            "publishedAt": "2025-10-13",
            "source": "SlateStarCodex",
            "summary": "<p>Thanks to everyone who participated in ACX Grants, whether as an applicant, an evaluator, or a funder.</p><p>We received 654 applications this year, and were able to fund 42. To the other 612: sorry! Many of you had great ideas that we couldn&#8217;t fund for contingent reasons - sometimes because we couldn&#8217;t evaluate them at the level of depth it would have taken to feel comfortable supporting them, or because we had complicated conflicts of interest, or just because we didn&#8217;t have enough money. Some of you had ideas that were good but not a match for our particular grantmaking philosophy. Finally, a few of you were suffering from LLM psychosis. Please get help.</p><p>Of the 42 grantees, 40 have answered our email asking for confirmation that they still want the grant. I&#8217;m still waiting for confirmation emails from Lewis Wall and Nishank B. If you&#8217;re reading this and don&#8217;t think you got a confirmation email, check your spam folder. If it&#8217;s not in your spam folder, email me at scott@slatestarcodex.com. If you can&#8217;t reach me or I don&#8217;t respond, DM me on Substack or Twitter. I&#8217;ll give you until November 1 to get in touch, after which point the grant will",
            "title": "ACX Grants Results 2025"
        },
        {
            "content": [
                "<p>This is the weekly visible open thread. Post about anything you want, ask random questions, whatever. ACX has an unofficial <a href=\"https://www.reddit.com/r/slatestarcodex/\">subreddit</a>, <a href=\"https://discord.gg/RTKtdut\">Discord</a>, and <a href=\"https://www.datasecretslox.com/index.php\">bulletin board</a>, and <a href=\"https://www.lesswrong.com/community?filters%5B0%5D=SSC\">in-person meetups around the world</a>. Most content is free, some is subscriber only; you can subscribe <strong><a href=\"https://astralcodexten.substack.com/subscribe\">here</a></strong>. Also:</p><p><strong>1: </strong>Meetups this week include Auckland, Hamburg, Houston, Lviv, Oxford, and Warsaw - see <a href=\"https://www.astralcodexten.com/p/meetups-everywhere-2025-times-and\">the meetup post</a> for more information.</p><p><strong>2: </strong>The following people still haven&#8217;t responded to my email asking them to accept their ACX grant - Lewis W, Alejandro A, Nishank B. If you tried to respond but it didn&#8217;t reach me, DM me on Substack or Twitter. Do it quick, or I will include / not include you on the announcement post based on your original privacy preferences.</p><p><strong>3: </strong>All Non-Book Review finalists and honorable mentions (<a href=\"https://www.astralcodexten.com/p/open-thread-387\">list at #3 here</a>) should have gotten an email asking you to send me your bios for the announcement post. But I have only gotten 6/20 responses. If you didn&#8217;t get it, check your spam folder for scott@slatestarcodex.com. If you still didn&#8217;t get it, email me. If I don&#8217;t answer, DM me on Substack or Twitter.</p><p><strong>4</strong>:<strong> </strong>Related: today, Monday, is your last chance <a href=\"https://www.astralcodexten.com/p/vote-in-the-2025-non-book-review\">to vote on contest winners</a>.</p><p><strong>5: </strong>Advertisement: MATS (AI safety training camp) is hiring for new roles, including senior research manager, community manager, ops, compute administrator, and executive assistant. More info <a href=\"https://www.matsprogram.org/careers\">here</a>.</p><p><strong>6: </strong>Several people have asked me if I will be responding to various responses to <a href=\"https://www.astralcodexten.com/p/the-fatima-sun-miracle-much-more\">my Fatima post</a>. I&#8217;m working on a Highlights From The Comments post, but it might be another week or so before it&#8217;s ready. In the meantime, repeat miracles have been known to occur on the anniversary of the original, which is today (Monday). I still disrecommend staring at the sun - but if you see anything unusual, <a href=\"https://forms.gle/9Tckvtemv19KnXuJ8\">the form is still open</a>.</p><p></p>"
            ],
            "link": "https://www.astralcodexten.com/p/open-thread-403",
            "publishedAt": "2025-10-13",
            "source": "SlateStarCodex",
            "summary": "<p>This is the weekly visible open thread. Post about anything you want, ask random questions, whatever. ACX has an unofficial <a href=\"https://www.reddit.com/r/slatestarcodex/\">subreddit</a>, <a href=\"https://discord.gg/RTKtdut\">Discord</a>, and <a href=\"https://www.datasecretslox.com/index.php\">bulletin board</a>, and <a href=\"https://www.lesswrong.com/community?filters%5B0%5D=SSC\">in-person meetups around the world</a>. Most content is free, some is subscriber only; you can subscribe <strong><a href=\"https://astralcodexten.substack.com/subscribe\">here</a></strong>. Also:</p><p><strong>1: </strong>Meetups this week include Auckland, Hamburg, Houston, Lviv, Oxford, and Warsaw - see <a href=\"https://www.astralcodexten.com/p/meetups-everywhere-2025-times-and\">the meetup post</a> for more information.</p><p><strong>2: </strong>The following people still haven&#8217;t responded to my email asking them to accept their ACX grant - Lewis W, Alejandro A, Nishank B. If you tried to respond but it didn&#8217;t reach me, DM me on Substack or Twitter. Do it quick, or I will include / not include you on the announcement post based on your original privacy preferences.</p><p><strong>3: </strong>All Non-Book Review finalists and honorable mentions (<a href=\"https://www.astralcodexten.com/p/open-thread-387\">list at #3 here</a>) should have gotten an email asking you to send me your bios for the announcement post. But I have only gotten 6/20 responses. If you didn&#8217;t get it, check your spam folder for scott@slatestarcodex.com. If you still didn&#8217;t get it, email me. If I don&#8217;t answer, DM me on Substack or Twitter.</p><p><strong>4</strong>:<strong> </strong>Related: today, Monday, is your last chance",
            "title": "Open Thread 403"
        },
        {
            "content": [
                "<p>A little over a month ago, I documented how OpenAI had descended into paranoia and bad faith lobbying surrounding California\u2019s SB 53.</p>\n<p>This included <a href=\"https://thezvi.substack.com/i/172792035/openais-latest-bad-faith-lobbying-attempt\">sending a deeply bad faith letter to Governor Newsom</a>, which sadly is par for the course at this point.</p>\n<p>It also <a href=\"https://thezvi.substack.com/i/172792035/openai-descends-into-paranoia-and-legally-attacks-nonprofits\">included lawfare attacks against bill advocates, including Nathan Calvin</a> and others, using Elon Musk\u2019s unrelated lawsuits and vendetta against OpenAI as a pretext, accusing them of being in cahoots with Elon Musk.</p>\n<p>Previous reporting of this did not reflect well on OpenAI, but it sounded like the demand was limited in scope to a supposed link with Elon Musk or Meta CEO Mark Zuckerberg, links which very clearly never existed.</p>\n<div>\n\n\n<span id=\"more-24784\"></span>\n\n\n<p>Accusing essentially everyone who has ever done anything OpenAI dislikes of having united in a hallucinated \u2018vast conspiracy\u2019 is all classic behavior for OpenAI\u2019s Chief Global Affairs Officer Chris Lehane, the inventor of the original term \u2018vast right wing conspiracy\u2019 back in the 1990s to dismiss the (true) allegations against Bill Clinton by Monica Lewinsky. It was presumably mostly or entirely an op, a trick. And if they somehow actually believe it, that\u2019s way worse.</p>\n<p>We thought that this was the extent of what happened.</p>\n<blockquote>\n<p><a href=\"https://sfstandard.com/2025/09/02/openai-sam-altman-elon-musk-ai-regulation/\">Emily Shugerman</a> (SF Standard): Nathan Calvin, who joined Encode in 2024, two years after graduating from Stanford Law School, was being subpoenaed by OpenAI. \u201cI was just thinking, \u2018Wow, they\u2019re really doing this,\u2019\u201d he said. \u201c\u2018This is really happening.\u2019\u201d</p>\n<p>The subpoena was filed as part of the ongoing lawsuits between Elon Musk and OpenAI CEO Sam Altman, in which Encode had filed an amicus brief supporting some of Musk\u2019s arguments. It asked for any documents relating to Musk\u2019s involvement in the founding of Encode, as well as any communications between Musk, Encode, and Meta CEO Mark Zuckerberg, whom Musk <a href=\"https://fortune.com/2025/08/22/elon-musk-mark-zuckerberg-openai-takeover/\">reportedly</a> tried to involve in his OpenAI takeover bid in February.</p>\n<p>Calvin said the answer to these questions was easy: The requested documents didn\u2019t exist.</p>\n</blockquote>\n<p>Now that SB 53 has passed, Nathan Calvin is now free to share the full story.</p>\n<p>It turns out it was substantially worse than previously believed.</p>\n<p>And then, in response, OpenAI CSO Jason Kwon doubled down on it.</p>\n\n\n<h4 class=\"wp-block-heading\">What OpenAI Tried To Do To Nathan Calvin</h4>\n\n\n<blockquote>\n<p><a href=\"https://x.com/_NathanCalvin/status/1976649051396620514\">Nathan Calvin</a>: One Tuesday night, as my wife and I sat down for dinner, a sheriff\u2019s deputy knocked on the door to serve me a subpoena from OpenAI.</p>\n<p>I held back on talking about it because I didn\u2019t want to distract from SB 53, but Newsom just signed the bill so&#8230; here\u2019s what happened:</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!_L2T!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F505f7fc5-9113-46d1-9b91-372a92056e11_1154x1024.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>You might recall a story in the SF Standard that talked about OpenAI retaliating against critics. Among other things, OpenAI asked for all my private communications on SB 53 &#8211; a bill that creates new transparency rules and whistleblower protections at large AI companies.</p>\n<p>Why did OpenAI subpoena me? Encode has criticized OpenAI\u2019s restructuring and worked on AI regulations, including SB 53.</p>\n<p>I believe OpenAI used the pretext of their lawsuit against Elon Musk to intimidate their critics and imply that Elon is behind all of them.</p>\n<p>There\u2019s a big problem with that idea: Elon isn\u2019t involved with Encode. Elon wasn\u2019t behind SB 53. He doesn\u2019t fund us, and we\u2019ve never spoken to him.</p>\n<p>OpenAI went beyond just subpoenaing Encode about Elon. OpenAI could (and did!) send a subpoena to Encode\u2019s corporate address asking about our funders or communications with Elon (which don\u2019t exist).</p>\n<p>If OpenAI had stopped there, maybe you could argue it was in good faith.</p>\n<p>But they didn\u2019t stop there.</p>\n<p>They also sent a sheriff\u2019s deputy to my home and asked for me to turn over private texts and emails with CA legislators, college students, and former OAI employees.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!9dtN!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe075f092-0f4d-4780-b1f5-5786aa2cba65_1200x335.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>This is not normal. OpenAI used an unrelated lawsuit to intimidate advocates of a bill trying to regulate them. While the bill was still being debated.</p>\n<p>OpenAI had no legal right to ask for this information. So we submitted an objection explaining why we would not be providing our private communications. (They never replied.)</p>\n<p>A magistrate judge even chastised OpenAI more broadly for their behavior in the discovery process in their case against Musk.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!mqZC!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe96eb740-ddcb-41e1-979a-a26f4331c405_936x146.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>This wasn\u2019t the only way OpenAI behaved poorly on SB 53 before it was signed. They also sent Governor Newsom a letter trying to gut the bill by waiving all the requirements for any company that does any evaluation work with the federal government.</p>\n<p>There is more I could go into about the nature of OAI\u2019s engagement on SB 53, but suffice to say that when I saw OpenAI\u2019s so-called \u201cmaster of the political dark arts\u201d Chris Lehane claim that they \u201cworked to improve the bill,\u201d I literally laughed out loud.</p>\n<p>Prior to OpenAI, Chris Lehane\u2019s PR clients included Boeing, the Weinstein Company, and Goldman Sachs. One person who worked on a campaign with Lehane said to the New Yorker \u201cThe goal was intimidation, to let everyone know that if they fuck with us they\u2019ll regret it\u201d</p>\n<p>I have complicated feelings about OpenAI &#8211; I use and get value from their products, and they conduct and publish AI safety research that is worthy of genuine praise.</p>\n<p>I also know many OpenAI employees care a lot about OpenAI being a force for good in the world.</p>\n<p>I want to see that side of OAI, but instead I see them trying to intimidate critics into silence.</p>\n<p>This episode was the most stressful period of my professional life. Encode has 3 FTEs &#8211; going against the highest-valued private company in the world is terrifying.</p>\n<p>Does anyone believe these actions are consistent with OpenAI\u2019s nonprofit mission to ensure that AGI benefits humanity? OpenAI still has time to do better. I hope they do.</p>\n</blockquote>\n<p>Here is the key passage from the Chris Lehane statement Nathan quotes, which shall we say does not correspond to the reality of what happened (<a href=\"https://thezvi.substack.com/i/172792035/openais-latest-bad-faith-lobbying-attempt\">as I documented last time</a>, Nathan\u2019s highlighted passage is bolded):</p>\n<blockquote>\n<p>Chris Lehane (Officer of Global Affairs, OpenAI): In that same spirit, <strong>we worked to improve SB 53.</strong> The final version lays out a clearer path to harmonize California\u2019s standards with federal ones. That\u2019s also why we support a single federal approach\u2014potentially through the emerging CAISI framework\u2014rather than a patchwork of state laws.</p>\n</blockquote>\n\n\n<h4 class=\"wp-block-heading\">It Doesn\u2019t Look Good</h4>\n\n\n<blockquote>\n<p><a href=\"https://x.com/GaryMarcus/status/1976682749089186262\">Gary Marcus</a>: OpenAI, which has chastised @elonmusk for waging lawfare against them, gets chastised for doing the same to private citizens.</p>\n<p>Only OpenAI could make me sympathize with Elon.</p>\n</blockquote>\n<p>Let\u2019s not get carried away. Elon Musk has been engaging in lawfare against OpenAI, r where many (but importantly not all, the exception being challenging the conversion to a for-profit) of his lawsuits have lacked legal merit, and making various outlandish claims. OpenAI being a bad actor against third parties does not excuse that.</p>\n<blockquote>\n<p><a href=\"https://x.com/hlntnr/status/1976668356586676254\">Helen Toner:</a> Every so often, OpenAI employees ask me how I see the co now.</p>\n<p>It\u2019s always tough to give a simple answer. Some things they\u2019re doing, eg on CoT monitoring or building out system cards, are great.</p>\n<p>But the dishonesty &amp; intimidation tactics in their policy work are really not.</p>\n<p>Steven Adler: Really glad that Nathan shared this. I suspect almost nobody who works at OpenAI has a clue that this sort of stuff is going on, &amp; they really ought to know</p>\n<p><a href=\"https://x.com/hamandcheese/status/1976730220196659518\">Samuel Hammond</a>: OpenAI\u2019s legal tactics should be held to a higher standard if only because they will soon have exclusive access to fleets of long-horizon lawyer agents. If there is even a small risk the justice system becomes a compute-measuring contest, they must demo true self-restraint.</p>\n<p><a href=\"https://x.com/hamandcheese/status/1976717175562875055\">Disturbing tactics</a> that ironically reinforce the need for robust transparency and whistleblower protections. Who would\u2019ve guessed that the coiner of \u201cvast right-wing conspiracy\u201d is the paranoid type.</p>\n<p>The most amusing thing about this whole scandal is the premise that Elon Musk funds AI safety nonprofits. The Musk Foundation is notoriously tightfisted. I think the IRS even penalized them one year for failing to donate the minimum.</p>\n</blockquote>\n<p>OpenAI and Sam Altman do a lot of very good things that are much better than I would expect from the baseline (replacement level) next company or next CEO up, such as a random member or CEO of the Mag-7.</p>\n<p>They will need to keep doing this and further step up, if they remain the dominant AI lab, and we are to get through this. As Samuel Hammond says, OpenAI must be held to a higher standard, not only legally but across the board.</p>\n<p>Alas, not only is that not a high enough standard for the unique circumstances history has thrust upon them, especially on alignment, OpenAI and Sam Altman also do a lot of things that are highly not good, and in many cases actively worse than my expectations for replacement level behavior. These actions example of that. And in this and several other key ways, especially in terms of public communications and lobbying, OpenAI and Altman\u2019s behaviors have been getting steadily worse.</p>\n<p>&nbsp;</p>\n\n\n<h4 class=\"wp-block-heading\">OpenAI\u2019s Jason Kwon Responds</h4>\n\n\n<p>Rather than an apology, this response is what we like to call \u2018doubling down.\u2019</p>\n<blockquote>\n<p>Jason Kwon (CSO OpenAI): There\u2019s quite a lot more to the story than this.</p>\n<p>As everyone knows, we are actively defending against Elon in a lawsuit where he is trying to damage OpenAI for his own financial benefit.</p>\n</blockquote>\n<p>Elon Musk has indeed repeatedly sued OpenAI, and many of those lawsuits are without legal merit, but if you think the primary purpose of him doing that is his own financial benefit, you clearly know nothing about Elon Musk.</p>\n<blockquote>\n<p>Encode, the organization for which @_NathanCalvin serves as the General Counsel, was one of the first third parties &#8211; whose funding has not been fully disclosed &#8211; that quickly filed in support of Musk. For a safety policy organization to side with Elon (?), that raises legitimate questions about what is going on.</p>\n</blockquote>\n<p>No, it doesn\u2019t, because this action is overdetermined once you know what the lawsuit is about. OpenAI is trying to pull off one of the greatest thefts in human history, the \u2018conversion\u2019 to a for-profit in which it will attempt to expropriate the bulk of its non-profit arm\u2019s control rights as well as the bulk of its financial stake in the company. This would be very bad for AI safety, so AI safety organizations are trying to stop it, and thus support this particular Elon lawsuit against OpenAI, which the judge noted had quite a lot of legal merit, with the primary question being whether Musk has standing to sue.</p>\n<blockquote>\n<p>We wanted to know, and still are curious to know, whether Encode is working in collaboration with third parties who have a commercial competitive interest adverse to OpenAI.</p>\n</blockquote>\n<p>This went well beyond that, and you were admonished by the judge for how far beyond that your attempts at such discoveries went. It takes a lot to get judges to use such language.</p>\n<blockquote>\n<p>The stated narrative makes this sound like something it wasn\u2019t.</p>\n<ol>\n<li>Subpoenas are to be expected, and it would be surprising if Encode did not get counsel on this from their lawyers. When a third party inserts themselves into active litigation, they are subject to standard legal processes. We issued a subpoena to ensure transparency around their involvement and funding. This is a routine step in litigation, not a separate legal action against Nathan or Encode.</li>\n<li>Subpoenas are part of how both sides seek information and gather facts for transparency; they don\u2019t assign fault or carry penalties. Our goal was to understand the full context of why Encode chose to join Elon\u2019s legal challenge.</li>\n</ol>\n</blockquote>\n<p>Again, this does not at all line up with the requests being made.</p>\n<blockquote>\n<ol>\n<li>We\u2019ve also been asking for some time who is funding their efforts connected to both this lawsuit and SB53, since they\u2019ve publicly linked themselves to those initiatives. If they don\u2019t have relevant information, they can simply respond that way.</li>\n<li>This is not about opposition to regulation or SB53. We did not oppose SB53; we provided comments for harmonization with other standards. We were also one of the first to sign the EU AIA COP, and still one of a few labs who test with the CAISI and UK AISI. We\u2019ve also been clear with our own staff that they are free to express their takes on regulation, even if they disagree with the company, like during the 1047 debate (see thread below).</li>\n</ol>\n</blockquote>\n<p>You opposed SB 53. What are you even talking about. <a href=\"https://thezvi.substack.com/i/172792035/openais-latest-bad-faith-lobbying-attempt\">Have you seen the letter you sent to Newsom</a>? Doubling down on this position, and drawing attention to this deeply bad faith lobbying by doing so, is absurd.</p>\n<blockquote>\n<ol>\n<li>We checked with our outside law firm about the deputy visit. The law firm used their standard vendor for service, and it\u2019s quite common for deputies to also work as part-time process servers. We\u2019ve been informed that they called Calvin ahead of time to arrange a time for him to accept service, so it should not have been a surprise.</li>\n<li>Our counsel interacted with Nathan\u2019s counsel and by all accounts the exchanges were civil and professional on both sides. Nathan\u2019s counsel denied they had materials in some cases and refused to respond in other cases. Discovery is now closed, and that\u2019s that.</li>\n</ol>\n<p>For transparency, below is the excerpt from the subpoena that lists all of the requests for production. People can judge for themselves what this was really focused on. Most of our questions still haven\u2019t been answered.</p>\n</blockquote>\n<p>He provides PDFs, here is the transcription:</p>\n<blockquote>\n<p><strong>Request For Production No. 1:</strong><br />All Documents and Communications concerning any involvement by Musk or any Musk-Affiliated Entity (or any Person or entity acting on their behalves, including Jared Birchall or Shivon Zilis) in the anticipated, contemplated, or actual formation of ENCODE, including all Documents and Communications exchanged with Musk or any Musk-Affiliated Entity (or any Person or entity acting on their behalves) concerning the foregoing.</p>\n<p><strong>Request For Production No. 2:</strong><br />All Documents and Communications concerning any involvement by or coordination with Musk, any Musk-Affiliated Entity, FLI, Meta Platforms Inc., or Mark Zuckerberg (or any Person or entity acting on their behalves, including Jared Birchall or Shivon Zilis) in Your or ENCODE\u2019s activities, advocacy, lobbying, public statements, or policy positions concerning any OpenAI Defendant or the Action.</p>\n<p><strong>Request For Production No. 3:</strong><br />All Communications exchanged with Musk, any Musk-Affiliated Entity, FLI, Meta Platforms Inc., or Mark Zuckerberg (or any Person or entity acting on their behalves, including Jared Birchall or Shivon Zilis) concerning any OpenAI Defendant or the Action, and all Documents referencing or relating to such Communications.</p>\n<p><strong>Request For Production No. 4:</strong><br />All Documents and Communications concerning any actual, contemplated, or potential charitable contributions, donations, gifts, grants, loans, or investments to You or ENCODE made, directly or indirectly, by Musk or any Musk-Affiliated Entity.</p>\n<p><strong>Request For Production No. 5:</strong><br />Documents sufficient to show all of ENCODE\u2019s funding sources, including the identity of all Persons or entities that have contributed any funds to ENCODE and, for each such Person or entity, the amount and date of any such contributions.</p>\n<p><strong>Request For Production No. 6:</strong></p>\n<p>All Documents and Communications concerning the governance or organizational structure of OpenAI and any actual, contemplated, or potential change thereto.</p>\n<p><strong>Request For Production No. 7:</strong><br />All Documents and Communications concerning SB 53 or its potential impact on OpenAI, including all Documents and Communications concerning any involvement by or coordination with Musk or any Musk-Affiliated Entity (or any Person or entity acting on their behalves, including Jared Birchall or Shivon Zilis) in Your or ENCODE\u2019s activities in connection with SB 53.</p>\n<p><strong>Request For Production No. 8:</strong><br />All Documents and Communications concerning any involvement by or coordination with any Musk or any Musk-Affiliated Entity (or any Person or entity acting on their behalves) with the open letter titled \u201cAn Open Letter to OpenAI,\u201d available at <a href=\"https://www.openai-transparency.org/\" rel=\"nofollow\">https://www.openai-transparency.org/</a>, including all Documents or Communications exchanged with any Musk or any Musk-Affiliated Entity (or any Person or entity acting on their behalves) concerning the open letter.</p>\n<p><strong>Request For Production No. 9:</strong><br />All Documents and Communications concerning the February 10, 2025 Letter of Intent or the transaction described therein, any Alternative Transaction, or any other actual, potential, or contemplated bid to purchase or acquire all or a part of OpenAI or its assets.</p>\n</blockquote>\n<p>(<a href=\"https://x.com/jasonkwon/status/1976762553805291880\">He then shares a tweet about SB 1047</a>, where OpenAI tells employees they are free to sign a petition in support of it, which raises questions answered by the Tweet.)</p>\n<p>Excellent. Thank you, sir, for the full request.</p>\n<p>There is a community note:</p>\n<div>\n<figure>\n<div>\u00a0</div>\n</figure>\n</div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!GegM!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd7329946-867f-4465-9a5e-d8bda323c6c2_1020x522.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n\n\n<h4 class=\"wp-block-heading\">A Brief Amateur Legal Analysis Of The Request</h4>\n\n\n<p>Before looking at others reactions to Kwon\u2019s statement, here\u2019s how I view each of the nine requests, <a href=\"https://chatgpt.com/share/68eabc8f-1a48-8002-8d41-7ec81606f8d7\">with the help of OpenAI\u2019s own GPT-5 Thinking</a> (I like to only use ChatGPT when analyzing OpenAI in such situations, to ensure I\u2019m being fully fair), but really the confirmed smoking gun is #7:</p>\n<ol>\n<li>Musk related, I see why you\u2019d like this, but associational privilege, overbroad, non-party burden, and such information could be sought from Musk directly.</li>\n<li>Musk related, but this also includes FLI (and for some reason Meta), also a First Amendment violation under Perry/AFP v. Bonta, insufficiently narrowly tailored. Remarkably sweeping and overbroad.</li>\n<li>Musk related, but this also includes FLI (and for some reason Meta). More reasonable but still seems clearly too broad.</li>\n<li>Musk related, relatively well-scoped, I don\u2019t fault them for the ask here.</li>\n<li>Global request for all funding information, are you kidding me? Associational privilege, overbreadth, undue burden, disproportionate to needs. No way.</li>\n<li>Why the hell is this any of your damn business? As GPT-5 puts it, if OpenAI wants its own governance records, it has them. Is there inside knowledge here? Irrelevance, better source available, undue burden, not a good faith ask.</li>\n<li>You have got to be f***ing kidding me, you\u2019re defending this for real? \u201cAll Documents and Communications concerning SB 53 or its potential impact on OpenAI?\u201d This is the one that is truly insane, and He Admit It.</li>\n<li>I do see why you want this, although it\u2019s insufficiently narrowly tailored.</li>\n<li>Worded poorly (probably by accident), but also that\u2019s confidential M&amp;A stuff, so would presumably require a strong protective order. Also will find nothing.</li>\n</ol>\n<p>Given that Calvin quoted #7 as the problem and he\u2019s confirming #7 as quoted, I don\u2019t see how Kwon thought the full text would make it look better, but I always appreciate transparency.</p>\n<p>Oh, also, <a href=\"https://x.com/TylerJnstn/status/1976765346440004068\">there is another</a>.</p>\n\n\n<h4 class=\"wp-block-heading\">What OpenAI Tried To Do To Tyler Johnston</h4>\n\n\n<blockquote>\n<p><a href=\"https://x.com/TylerJnstn/status/1976765346440004068\">Tyler Johnson</a>: Even granting your dubious excuses, what about my case?</p>\n<p>Neither myself nor my organization were involved in your case with Musk. But OpenAI still demanded every document, email, and text message I have about your restructuring\u2026</p>\n<p>I, too, made the mistake of *checks notes* taking OpenAI\u2019s charitable mission seriously and literally.</p>\n<p>In return, got a knock at my door in Oklahoma with a demand for every text/email/document that, in the \u201cbroadest sense permitted,\u201d relates to OpenAI\u2019s governance and investors.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!zjw9!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F67118e65-96df-4ec2-aaac-52b593870180_1200x790.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>(My organization, @TheMidasProj, also got an identical subpoena.)</p>\n<p>As with Nathan, had they just asked if I\u2019m funded by Musk, I would have been happy to give them a simple \u201cman I wish\u201d and call it a day.</p>\n<p>Instead, they asked for what was, practically speaking, a list of every journalist, congressional office, partner organization, former employee, and member of the public we\u2019d spoken to about their restructuring.</p>\n<p>Maybe they wanted to map out who they needed to buy off. Maybe they just wanted to bury us in paperwork in the critical weeks before the CA and DE attorneys general decide whether to approve their transition from a public charity to a $500 billion for-profit enterprise.</p>\n<p>In any case, it didn\u2019t work. But if I was just a bit more green, or a bit more easily intimidated, maybe it would have.</p>\n<p><a href=\"https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees\">They once tried silencing their own employees with similar tactics</a>. Now they\u2019re broadening their horizons, and charities like ours are on the chopping block next.</p>\n<p>In public, OpenAI has bragged about the \u201clistening sessions\u201d they\u2019ve conducted to gather input on their restructuring from civil society. But, when we organized an open letter with many of those same organizations, they sent us legal demands about it.</p>\n</blockquote>\n<p>My model of Kwon\u2019s response to this was it would be \u2018if you care so much about the restructuring that means we suspect you\u2019re involved with Musk\u2019? And thus that they\u2019re entitled to ask for everything related to OpenAI.</p>\n<p>We now have Jason Kwon\u2019s actual response to the Johnson case, which is that Tyler \u2018backed Elon\u2019s opposition to OpenAI\u2019s restructuring.\u2019 So yes, nailed it.</p>\n<p>Also, yep, he\u2019s tripling down.</p>\n<blockquote>\n<p><a href=\"https://x.com/jasonkwon/status/1977151380948500625\">Jason Kwon</a>: I\u2019ve seen a few questions here about how we\u2019re responding to Elon\u2019s lawsuits against us. After he sued us, several organizations, some of them suddenly newly formed like the Midas Project, joined in and ran campaigns backing his opposition to OpenAI\u2019s restructure. This raised transparency questions about who was funding them and whether there was any coordination. It\u2019s the same theme noted in my prior response.</p>\n<p>Some have pointed out that the subpoena to Encode requests \u201call\u201d documents related to SB53, implying that the focus wasn\u2019t Elon. As others have mentioned in the replies, this is standard language as each side\u2019s counsel negotiates and works through to narrow what will get produced, objects, refuses, etc. Focusing on one word ignores the other hundreds that make it clear what the object of concern was.</p>\n<p>Since he\u2019s been tweeting about it, here\u2019s our subpoena to Tyler Johnston of the Midas Project, which does not mention the bill, which we did not oppose.</p>\n</blockquote>\n<p>If you find yourself in a hole, sir, the typical advice is to stop digging.</p>\n<p>He also helpfully <a href=\"https://x.com/jasonkwon/status/1977151380948500625\">shared the full subpoena</a> given to Tyler Johnston. I won\u2019t quote this one <a href=\"https://chatgpt.com/share/68ebb2c2-580c-8002-a15e-f2b4ea943006\">in full</a> as it is mostly similar to the one given to Calvin. It includes (in addition to various clauses that aim more narrowly at relationships to Musk or Meta that don\u2019t exist) a request for all funding sources of the Midas Project, all documents concerning the governance or organizational structure of OpenAI or any actual, contemplated, or potential change thereto, or concerning any potential investment by a for-profit entity in OpenAI or any affiliated entity, or any such funding relationship of any kind.</p>\n\n\n<h4 class=\"wp-block-heading\">Nathan Compiles Responses to Kwon</h4>\n\n\n<p>Rather than respond himself to Kwon\u2019s first response, Calvin instead quoted many people responding to the information similarly to how I did. This seems like a very one sided situation. The response is damning, if anything substantially more damning than the original subpoena.</p>\n<blockquote>\n<p><a href=\"https://x.com/jeremyphoward/status/1976805257922719851\">Jeremy Howard (no friend to AI safety advocate</a>s): Thank you for sharing the details. They do not support seem to support your claims above.</p>\n<p>They show that, in fact, the subpoena is *not* limited to dealings with Musk, but is actually *all* communications about SB 53, or about OpenAI\u2019s governance or structure.</p>\n<p>You seem confused at the idea that someone would find this situation extremely stressful. That seems like an extraordinary lack of empathy or basic human compassion and understanding. Of COURSE it would be extremely stressful.</p>\n<p>Oliver Habryka: If it\u2019s not about SB53, why does the subpoena request all communication related to SB53? That seems extremely expansive!</p>\n<p>Linch Zhang: \u201cANYTHING related to SB 53, INCLUDING involvement or coordination with Musk\u201d does not seem like a narrowly target[ed] request for information related to the Musk lawsuit.\u201d</p>\n<p><a href=\"https://x.com/Michael05156007/status/1976770286696685879\">Michael Cohen</a>: He addressed this \u201cOpenAI went beyond just subpoenaing Encode about Elon. OpenAI could &#8230; send a subpoena to Encode\u2019s corporate address asking about &#8230; communications with Elon &#8230; If OpenAI had stopped there, maybe you could argue it was in good faith.</p>\n<p>And also [Tyler Johnston\u2019s case] falsifies your alleged rationale where it was just to do with the Musk case.</p>\n<p><a href=\"https://x.com/dhadfieldmenell/status/1976864567834849309\">Dylan Hadfield Menell</a>: Jason\u2019s argument justifies the subpoena because a \u201csafety policy organization siding with Elon (?)\u2026 raises legitimate questions about what is going on.\u201d This is ridiculous \u2014 skepticism for OAI\u2019s transition to for-profit is the majority position in the AI safety community.</p>\n<p>I\u2019m not familiar with the specifics of this case, but I have trouble understanding how that justification can be convincing. It suggests that internal messaging is scapegoating Elon for genuine concerns that a broad coalition has. In practice, a broad coalition has been skeptical of the transition to for profit as @OpenAI reduces non-profit control and has consolidated corporate power with @sama.</p>\n<p>There\u2019s a lot @elonmusk does that I disagree with, but using him as a pretext to cast aspersions on the motives of all OAI critics is dishonest.</p>\n</blockquote>\n<p>I\u2019ll also throw in this one:</p>\n<blockquote>\n<p><a href=\"https://x.com/NeelNanda5/status/1977043654477742239\">Neel Nanda</a> (DeepMind): Weird how OpenAI\u2019s damage control doesn\u2019t actually explain why they tried using an unrelated court case to make a key advocate of a whistleblower &amp; transparency bill (SB53) share all private texts/emails about the bill (some involving former OAI employees) as the bill was debated.</p>\n<p>Worse, it\u2019s a whistleblower and transparency bill! I\u2019m sure there\u2019s a lot of people who spoke to Encode, likely including both current and former OpenAI employees, who were critical of OpenAI and would prefer to not have their privacy violated by sharing texts with OpenAI.</p>\n</blockquote>\n<p>How unusual was this?</p>\n<blockquote>\n<p>Timothy Lee: <a href=\"https://x.com/binarybits/status/1977450129004073065\">There\u2019s something poetic</a> about OpenAI using scorched-earth legal tactics against nonprofits to defend their effort to convert from a nonprofit to a for-profit.</p>\n<p>Richard Ngo: to call this a scorched earth tactic is extremely hyperbolic.</p>\n<p>Timothy Lee: Why? I\u2019ve covered cases like this for 20 years and I\u2019ve never heard of a company behaving like this.</p>\n</blockquote>\n<p>I think \u2018scorched Earth tactics\u2019 seems to me like it is pushing it, but I wouldn\u2019t say it was extremely hyperbolic, the never having heard of a company behaving like this seems highly relevant.</p>\n\n\n<h4 class=\"wp-block-heading\">The First Thing We Do</h4>\n\n\n<p>Lawyers will often do crazy escalations by default any time you\u2019re not looking, and need to be held back. Insane demands can be, in an important sense, unintentional.</p>\n<p>That\u2019s still on you, especially if (as in the NDAs and threats over equity that Daniel Kokotajlo exposed) you have a track record of doing this. If it keeps happening on your watch, then you\u2019re choosing to have that happen on your watch.</p>\n<blockquote>\n<p><a href=\"https://x.com/binarybits/status/1977104136752841114\">Timothy Lee:</a> It\u2019s plausible that the explanation here is \u201cOpenAI hired lawyers who use scorched-earth tactics all the time and didn\u2019t supervise them closely\u201d rather than \u201cOpenAI leaders specifically wanted to harass SB 53 opponents or AI safety advocates.\u201d I\u2019m not sure that\u2019s better though!</p>\n<p>One time a publication asked me (as a freelancer) to sign a contract promising that I\u2019d pay for their legal bills if they got sued over my article for almost any reason. I said \u201cwtf\u201d and it seemed like their lawyers had suggested it and nobody had pushed back.</p>\n<p>Some lawyers are maximally aggressive in defending the interests of their clients all the time without worrying about collateral damage. And sometimes organizations hire these lawyers without realizing it and then are surprised that people get mad at them.</p>\n<p>But if you hire a bulldog lawyer and he mauls someone, that\u2019s on you! It\u2019s not an excuse to say \u201cthe lawyer told me mauling people is standard procedure.\u201d</p>\n</blockquote>\n<p>The other problem with this explanation is Kwon\u2019s response.</p>\n<p>If Kwon had responded with, essentially, \u201coh whoops, sorry, that was a bulldog lawyer mauling people, our bad, we should have been more careful\u201d then they still did it and it was still not the first time it happened on their watch but I\u2019d have been willing to not make it that big a deal.</p>\n<p>That is very much not what Kwon said. Kwon doubled down that this was reasonable, and that this was \u2018a routine step.\u2019</p>\n<blockquote>\n<p><a href=\"https://x.com/binarybits/status/1976774325924700554\">Timothy Lee</a>: Folks is it \u201ca routine step\u201d for a party to respond to a non-profit filing an amicus brief by subpoenaing the non-profit with a bunch of questions about its funding and barely related lobbying activities? That is not my impression.</p>\n</blockquote>\n<p>My understanding is that \u2018send subpoenas at all\u2019 is totally a routine step, but that the scope of these requests within the context of an amicus brief is quite the opposite.</p>\n<p><a href=\"https://x.com/michaelhpage/status/1977732457941058038\">Michael Page also strongly claims this is not normal</a>.</p>\n<blockquote>\n<p>Michael Page: In defense of OAI\u2019s subpoena practice, @jasonkwon claims this is normal litigation stuff, and since Encode entered the Musk case, @_NathanCalvin can\u2019t complain.</p>\n<p>As a litigator-turned-OAI-restructuring-critic, I interrogate this claim.</p>\n<p>This is not normal. Encode is not \u201csubject to standard legal processes\u201d of a party because it\u2019s NOT a party to the case. They submitted an amicus brief (\u201cfriend of the court\u201d) on a particular legal question \u2013 whether enjoining OAI\u2019s restructuring would be in the public interest.</p>\n<p>Nonprofits do this all the time on issues with policy implications, and it is HIGHLY unusual to subpoena them. The DE AG (<a href=\"https://x.com/KathyJenningsDE\">@KathyJenningsDE</a>) also submitted an amicus brief in the case, so I expect her subpoena is forthcoming.</p>\n<p>If OAI truly wanted only to know who is funding Encode\u2019s effort in the Musk case, they had only to read the amicus brief, which INCLUDES funding information.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!KsHP!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2c1bc60c-4e76-40e9-9429-eae5c7521c69_1005x154.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>Nor does the Musk-filing justification generalize. Among the other subpoenaed nonprofits of which I\u2019m aware \u2013 LASST (@TylerLASST), The Midas Project (@TylerJnstn), and Eko (@EmmaRubySachs) \u2013 none filed an amicus brief in the Musk case.</p>\n<p>What do the subpoenaed orgs have in common? They were all involved in campaigns criticizing OAI\u2019s restructuring plans:</p>\n<p><a href=\"https://t.co/7T4frO8rCg\">openaifiles.org</a> (TMP)</p>\n<p><a href=\"http://openai-transparency.org\">http://openai-transparency.org</a> (Encode; TMP)</p>\n<p><a href=\"https://t.co/cHXxUkEehz\">http://action.eko.org/a/protect-openai-s-non-profit-mission</a> (Eko)</p>\n<p><a href=\"http://notforprivategain.org\">http://notforprivategain.org</a> (Encode; LASST)</p>\n<p>So the Musk-case hook looks like a red herring, but Jason offers a more-general defense: This is nbd; OAI simply wants to know whether any of its competitors are funding its critics.</p>\n</blockquote>\n<p>It would be a real shame if, as a result of Kwon\u2019s rhetoric, we shared these links a lot. If everyone who reads this were to, let\u2019s say, familiarize themselves with what content got all these people at OpenAI so upset.</p>\n<blockquote>\n<p>Let\u2019s be clear: There\u2019s no general legal right to know who funds one\u2019s critics, for pretty obvious First Amendment reasons I won\u2019t get into.</p>\n<p>Musk is different, as OAI has filed counterclaims alleging Musk is harassing them. So OAI DOES have a legal right to info from third-parties relevant to Musk\u2019s purported harassment, PROVIDED the requests are narrowly tailored and well-founded.</p>\n<p>The requests do not appear tailored at all. They request info about SB 53 [Encode], SB 1047 [LASST], AB 501 [LASST], all documents about OAI\u2019s governance [all; Eko in example below], info about ALL funders [all; TMP in example below], etc.</p>\n<p>Nor has OAI provided any basis for assuming a Musk connection other than the orgs\u2019 claims that OAI\u2019s for-profit conversion is not in the public\u2019s interest \u2013 hardly a claim implying ulterior motives. Indeed, ALL of the above orgs have publicly criticized Musk.</p>\n<p>From my POV, this looks like either a fishing expedition or deliberate intimidation. The former is the least bad option, but the result is the same: an effective tax on criticism of OAI. (Attorneys are expensive.)</p>\n<p>Personal disclosure: I previously worked at OAI, and more recently, I collaborated with several of the subpoenaed orgs on the Not For Private Gain letter. None of OAI\u2019s competitors know who I am. Have I been subpoenaed? I\u2019m London-based, so Hague Convention, baby!!</p>\n</blockquote>\n\n\n<h4 class=\"wp-block-heading\">OpenAI Head of Mission Alignment Joshua Achiam Speaks Out</h4>\n\n\n<p><a href=\"https://x.com/jachiam0/status/1976690339546112098\">We all owe Joshua Achiam a large debt of gratitude for speaking out about this</a>.</p>\n<blockquote>\n<p>Joshua Achiam (QTing Calvin): At what is possibly a risk to my whole career I will say: this doesn\u2019t seem great. Lately I have been describing my role as something like a \u201cpublic advocate\u201d so I\u2019d be remiss if I didn\u2019t share some thoughts for the public on this.</p>\n<p>All views here are my own.</p>\n<p>My opinions about SB53 are entirely orthogonal to this thread. I haven\u2019t said much about them so far and I also believe this is not the time. But what I have said is that I think whistleblower protections are important. In that spirit I commend Nathan for speaking up.</p>\n<p>I think OpenAI has a rational interest and technical expertise to be an involved, engaged organization on questions like AI regulation. We can and should work on AI safety bills like SB53.</p>\n<p>Our most significant crisis to date, in my view, was the nondisparagement crisis. I am grateful to Daniel Kokotajlo for his courage and conviction in standing up for his beliefs. Whatever else we disagree on &#8211; many things &#8211; I think he was genuinely heroic for that. When that crisis happened, I was reassured by everyone snapping into action to do the right thing. We understood that it was a mistake and corrected it.</p>\n<p>The clear lesson from that was: if we want to be a trusted power in the world we have to earn that trust, and we can burn it all up if we ever even *seem* to put the little guy in our crosshairs.</p>\n<p>Elon is certainly out to get us and the man has got an extensive reach. But there is so much that is public that we can fight him on. And for something like SB53 there are so many ways to engage productively.</p>\n<p>We can\u2019t be doing things that make us into a frightening power instead of a virtuous one. We have a duty to and a mission for all of humanity. The bar to pursue that duty is remarkably high.</p>\n<p>My genuine belief is that by and large we have the basis for that kind of trust. We are a mission-driven organization made up of the most talented, humanist, compassionate people I have ever met. In our bones as an org we want to do the right thing always.</p>\n<p>I would not be at OpenAI if we didn\u2019t have an extremely sincere commitment to good. But there are things that can go wrong with power and sometimes people on the inside have to be willing to point it out loudly.</p>\n<p>The dangerously incorrect use of power is the result of many small choices that are all borderline but get no pushback; without someone speaking up once in a while it can get worse. So, this is my pushback.</p>\n</blockquote>\n<p>Well said. I have strong disagreements with Joshua Achiam about the expected future path of AI and difficulties we will face along the way, and the extent to which OpenAI has been a good faith actor fighting for good, but I believe these to be sincere disagreements, and this is what it looks like to call out the people you believe in, when you see them doing something wrong.</p>\n<blockquote>\n<p><a href=\"https://x.com/CharlesD353/status/1976727250641862935\">Charles</a>: Got to hand it to @jachiam0 here, I\u2019m quite glad, and surprised, that the person doing his job has the stomach to take this step.</p>\n<p>In contrast to Eric and many others, I disagree that it says something bad about OpenAI that he feels at risk by saying this. The norm of employees not discussing the company\u2019s dirty laundry in public without permission is a totally reasonable one.</p>\n<p>I notice some people saying \u201cdon\u2019t give him credit for this\u201d because they think it\u2019s morally obligatory or meaningless. I think those people have bad world models.</p>\n</blockquote>\n<p>I agree with Charles on all these fronts.</p>\n<p>If you could speak out this strongly against your employer, from Joshua\u2019s position, with confidence that they wouldn\u2019t hold it against you, that would be remarkable and rare. It would be especially surprising given what we already know about past OpenAI actions, very obviously Joshua is taking a risk here.</p>\n\n\n<h4 class=\"wp-block-heading\">It Could Be Worse</h4>\n\n\n<p>At least OpenAI (and xAI) are (at least primarily) using the courts to engage in lawfare over actual warfare or other extralegal means, or any form of trying to leverage their control over their own AIs. Things could be so much worse.</p>\n<blockquote>\n<p><a href=\"https://x.com/AndrewCritchPhD/status/1977163147531501743\">Andrew Critch</a>: OpenAI and xAI using HUMAN COURTS to investigate each other exposes them to HUMAN legal critique. This beats random AI-leveraged intimidation-driven gossip grabs.</p>\n<p>@OpenAI, it seems you overreached here. But thank you for using courts like a civilized institution.</p>\n</blockquote>\n<p>In principle, if OpenAI is legally entitled to information, there is nothing wrong with taking actions whose primary goal is to extract that information. When we believed that the subpoenas were narrowly targeted at items directly related to Musk and Meta, I still felt this did not seem like info they were entitled to, and it seemed like some combination of intimidation (\u2018the process is the punishment\u2019), paranoia and a fishing expedition, but if they did have that paranoia I could understand their perspective in a sympathetic way. Given the full details and extent, I can no longer do that.</p>\n\n\n<h4 class=\"wp-block-heading\">Chris Lehane Is Who We Thought He Was</h4>\n\n\n<p>Wherever else and however deep the problems go, they include Chris Lehane. Chris Lehane is also the architect of a16z\u2019s $100 million+ dollar Super PAC dedicated to opposing any and all regulation of AI, of any kind, anywhere, for any reason.</p>\n<blockquote>\n<p><a href=\"https://x.com/jachiam0/status/1976690339546112098\">Simeon</a>: I appreciate the openness Joshua, congrats.</p>\n<p>I unfortunately don\u2019t expect that to change for as long as Chris Lehane is at OpenAI, whose fame is literally built on bullying.</p>\n<p>Either OpenAI gets rid of its bullies or it will keep bullying its opponents.</p>\n<p><a href=\"https://x.com/Simeon_Cps/status/1976771136605372821\">Simeon (responding to Kwon</a>): [OpenAI] hired Chris Lehane with his background of bullying people into silence and submission. As long as [OpenAI] hire career bullies, your stories that bullying is not what you\u2019re doing won\u2019t be credible. If you weren\u2019t aware and are genuine in your surprise of the tactics used, <a href=\"https://t.co/NB5mTK0Oid\">you can read here about the world-class bully who leads your policy team</a>.</p>\n<p>[<a href=\"https://t.co/lVfBpWcoHA\">Silicon Valley, the New Lobbying Monster</a>] is more to the point actually.</p>\n</blockquote>\n<p>If OpenAI wants to convince us that it wants to do better, it can fire Chris Lehane. Doing so would cause me to update substantially positively on OpenAI.</p>\n\n\n<h4 class=\"wp-block-heading\">A Matter of Distrust</h4>\n\n\n<p>There have been various incidents that suggest we should distrust OpenAI, or that they are not being a good faith legal actor.</p>\n<p>Joshua Achiam highlights one of those incidents. He points out one thing that is clearly to OpenAI\u2019s credit in that case: Once Daniel Kokotajlo went public with what was going on with the NDAs and threats to confiscate OpenAI equity, OpenAI swiftly moved to do the right thing.</p>\n<p>However much you do or do not buy their explanation for how things got so bad in that case, making it right once pointed out mitigated much of the damage.</p>\n<p>In other major cases of damaging trust, OpenAI has simply stayed silent. They buried the investigation into everything related to Sam Altman being briefly fired, including Altman\u2019s attempts to remove Helen Toner from the board. They don\u2019t talk about the firings and departures of so many of their top AI safety researchers, or of Leopold. They buried most mention of existential risk or even major downsides or life changes from AI in public communications. They don\u2019t talk about their lobbying efforts (as most companies do not, for similar and obvious reasons). They don\u2019t really attempt to justify the terms of their attempted conversion to a for-profit, which would largely de facto disempower the non-profit and be one of the biggest thefts in human history.</p>\n<p>Silence is par for the course in such situations. It\u2019s the default. It\u2019s expected.</p>\n<p>Here Jason Kwon is, in what seems like an official capacity, not only not apologizing or fixing the issue, he is repeatedly doing the opposite of what they did in the NDA case, and doubled down on OpenAI\u2019s actions. He is actively defending OpenAI\u2019s actions as appropriate, justified and normal, and continuing to misrepresent what OpenAI did regarding SB 53 and to imply that anyone opposing them should be suspected of being in league with Elon Musk, or worse Mark Zuckerberg.</p>\n<p>OpenAI, via Jason Kwon, has said, yes, this was the right thing to do. One is left with the assumption this will be standard operating procedure going forward.</p>\n<p>There was a clear opportunity, and to some extent still is an opportunity, to say \u2018upon review we find that our bulldog lawyers overstepped in this case, we should have prevented this and we are sorry about that. We are taking steps to ensure this does not happen again.\u2019</p>\n<p>If they had taken that approach, this incident would still have damaged trust, especially since it is part of a pattern, but far less so than what happened here. If that happens soon after this post, and it comes from Altman, from that alone I\u2019d be something like 50% less concerned about this incident going forward, even if they retain Chris Lehane.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>"
            ],
            "link": "https://thezvi.wordpress.com/2025/10/13/openai-15-more-on-openais-paranoid-lawfare-against-advocates-of-sb-53/",
            "publishedAt": "2025-10-13",
            "source": "TheZvi",
            "summary": "A little over a month ago, I documented how OpenAI had descended into paranoia and bad faith lobbying surrounding California\u2019s SB 53. This included sending a deeply bad faith letter to Governor Newsom, which sadly is par for the course &#8230; <a href=\"https://thezvi.wordpress.com/2025/10/13/openai-15-more-on-openais-paranoid-lawfare-against-advocates-of-sb-53/\">Continue reading <span class=\"meta-nav\">&#8594;</span></a>",
            "title": "OpenAI #15: More on OpenAI\u2019s Paranoid Lawfare Against Advocates of SB 53"
        },
        {
            "content": [],
            "link": "https://xkcd.com/3154/",
            "publishedAt": "2025-10-13",
            "source": "XKCD",
            "summary": "<img alt=\"When Galileo dropped two weights from the Leaning Tower of Pisa, they put him in the history books. But when I do it, I get 'detained by security' for 'injuring several tourists.'\" src=\"https://imgs.xkcd.com/comics/physics_insight.png\" title=\"When Galileo dropped two weights from the Leaning Tower of Pisa, they put him in the history books. But when I do it, I get 'detained by security' for 'injuring several tourists.'\" />",
            "title": "Physics Insight"
        }
    ],
    "lookbackDays": 1,
    "publishDate": "2025-10-13"
}