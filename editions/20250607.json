{
    "articles": [
        {
            "content": [
                "<img alt=\"I dream of roombas - thousands of automated AI robots that autonomously maintain codebases\" src=\"https://ghuntley.com/content/images/2025/06/A-vibrant--retro-styled-tattoo-print-showcasing-numerous-Roombas-meticulously-maintaining-abstract-file-structures.--Employing-a-chiaroscuro-lighting-technique--the-image-is-rich-with-warm-autumnal-colors-and-complex-ornamental-details---1-.jpg\" /><p>Just yesterday morning, I was writing a conference talk on best practices for maintaining the LLM context window, which was quite detailed. It contained the then best practices from the two blog posts below.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://ghuntley.com/gutter/\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">autoregressive queens of failure</div><div class=\"kg-bookmark-description\">Have you ever had your AI coding assistant suggest something so off-base that you wonder if it&#x2019;s trolling you? Welcome to the world of autoregressive failure. LLMs, the brains behind these assistants, are great at predicting the next word&#x2014;or line of code&#x2014;based on what&#x2019;s been fed into</div><div class=\"kg-bookmark-metadata\"><img alt=\"I dream of roombas - thousands of automated AI robots that autonomously maintain codebases\" class=\"kg-bookmark-icon\" src=\"https://ghuntley.com/content/images/icon/android-chrome-192x192-33.png\" /><span class=\"kg-bookmark-author\">Geoffrey Huntley</span><span class=\"kg-bookmark-publisher\">Geoffrey Huntley</span></div></div><div class=\"kg-bookmark-thumbnail\"><img alt=\"I dream of roombas - thousands of automated AI robots that autonomously maintain codebases\" src=\"https://ghuntley.com/content/images/thumbnail/A-vibrant-retro-style-traditional-tattoo-art-print-on-a-white-background-depicting-a-bowling-ball-careening-down-a-gutter--surrounded-by-complex-ornamental-designs-and-a-light-ethereal-aura--conveying-a-mystical-spirit.jpg\" /></div></a></figure><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://ghuntley.com/redlining/\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">if you are redlining the LLM, you aren&#x2019;t headlining</div><div class=\"kg-bookmark-description\">It&#x2019;s an old joke in the DJ community about upcoming artists having a bad reputation for pushing the audio signal into the red. Red is bad because it results in the audio signal being clipped and the mix sounding muddy. It&#x2019;s a good analogy that applies to software</div><div class=\"kg-bookmark-metadata\"><img alt=\"I dream of roombas - thousands of automated AI robots that autonomously maintain codebases\" class=\"kg-bookmark-icon\" src=\"https://ghuntley.com/content/images/icon/android-chrome-192x192-35.png\" /><span class=\"kg-bookmark-author\">Geoffrey Huntley</span><span class=\"kg-bookmark-publisher\">Geoffrey Huntley</span></div></div><div class=\"kg-bookmark-thumbnail\"><img alt=\"I dream of roombas - thousands of automated AI robots that autonomously maintain codebases\" src=\"https://ghuntley.com/content/images/thumbnail/redline-digital-dj-tips-2.webp\" /></div></a></figure><p>Yet sections of that talk - just 4 hours later - are now redundant if you use <a href=\"https://ampcode.com/?ref=ghuntley.com\" rel=\"noreferrer\">Amp</a> and are in the early access pilot. Somewhat of a self-own but it&apos;s kind of nice not to have to work at that low-level of abstraction. It&apos;s really nice to work at higher abstractions. In the stream below, you will see a prototype of subagents. Yep, it&apos;s real. It&apos;s here. </p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://ghuntley.com/subagents/\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">I dream about AI subagents; they whisper to me while I&#x2019;m asleep</div><div class=\"kg-bookmark-description\">In a previous post, I shared about &#x201c;real context window&#x201d; sizes and &#x201c;advertised context window sizes&#x201d; Claude 3.7&#x2019;s advertised context window is 200k, but I&#x2019;ve noticed that the quality of output clips at the 147k-152k mark. Regardless of which agent is used, when clipping occurs, tool call to</div><div class=\"kg-bookmark-metadata\"><img alt=\"I dream of roombas - thousands of automated AI robots that autonomously maintain codebases\" class=\"kg-bookmark-icon\" src=\"https://ghuntley.com/content/images/icon/android-chrome-192x192-34.png\" /><span class=\"kg-bookmark-author\">Geoffrey Huntley</span><span class=\"kg-bookmark-publisher\">Geoffrey Huntley</span></div></div><div class=\"kg-bookmark-thumbnail\"><img alt=\"I dream of roombas - thousands of automated AI robots that autonomously maintain codebases\" src=\"https://ghuntley.com/content/images/thumbnail/A-traditional-tattoo-art-print-of-AI-subagents--computer-programming-agents--a-butler-for-an-AI-agent--symbolic-imagery--vibrant-colors--retro-flair--complex-ornamental-details--white-background--diffused-shadows--bold.jpg\" /></div></a></figure><p>Instead of allocating everything to the main context window and then overflowing it, you spawn a subagent, which has its brand-new context window for doing the meaty stuff, like building, testing, or whatever you can imagine. Whilst that is happening the main thread is paused and suspended, waiting until competition. </p><blockquote>It&apos;s kind of like async, await state machines, or futures for LLMs.</blockquote><figure class=\"kg-card kg-embed-card\"></figure><p>It was pretty hard to get to bed last night. Truth be told, I stayed up just watching it in fascination. Instead of running an infinite loop where it would blow up the main context window (which would result in the code base ending up in an incomplete state) resulting in me having to jump back in and gets hands on to do other things with prompting to try and rescue it, now the main thread, the context window, it barely even increments and every loop completes.</p><p>Thank you, <a href=\"https://x.com/thorstenball?ref=ghuntley.com\">Thorsten</a>, for making my dreams a reality. Now I&apos;ve another dream, but since I&apos;ve joined the Amp team, I suppose the responsibility for making the dream a reality now falls directly upon me. The buck stops with me to get it done.</p><p>Across the industry, software engineers are continually spending time on tasks of low business value. Some companies even refer to it as KTLO, or &quot;Keep the Lights On&quot;. If these tasks are neglected, however, they present a critical risk to the business. Yet they don&apos;t get done because the product is more important. So it&apos;s always a risk-reward trade-off.</p><p>So here&apos;s the pitch. All those tasks will soon be automated. Now that we have automated context management through subagents, the next step is to provide primitives that allow for the automation and removal of classes of KTLO, or, as Mr. 10 likes to describe in Factorio terms, we need quality modules.</p><h2 id=\"the-path-to-ticket-to-production\">the path to ticket to production</h2><p>To be frank, the industry and foundation models aren&apos;t yet advanced enough to fully automate software development without engineers being in or out of the loop. </p><p>Any vendor out there selling that dream <em>right now</em> is selling you magic beans of bullshit but AI moves fast and perhaps in the next couple of months it&apos;ll be a solved problem. Don&apos;t get me wrong - we&apos;re close. The continual evolution of Cursed (above), a brand-new programming language that is completely vibe-coded and hands-free, is proof to me that it will be possible in time. You see, a compiler isn&apos;t like a Vercel v0 website. No, it&apos;s serious stuff. It isn&apos;t a toy. Compilers have symbolic meaning and substance. </p><p>Building that compiler has been some of the best personal development I have done this year. </p><ul><li>It has taught me many things about managing the context window.</li><li>It has taught me to be less controlling of AI agents and more hands-free.</li><li>It has taught me latent behaviours in each of the LLMs and how to tickle the latent space to achieve new outcomes or meta-level insights. </li></ul><p>You see, there&apos;s no manual for <a href=\"https://ghuntley.com/dothings\" rel=\"noreferrer\">the transformation</a> that&apos;s happening in our industry yet. I strive to document all my observations on this website. Still, it&apos;s only through <a href=\"https://ghuntley.com/play\" rel=\"noreferrer\">serious, intentional play and experimentation</a> that these new emerging behaviours become apparent and can be <a href=\"https://ghuntley.com/mirrors\" rel=\"noreferrer\">turned into patterns that can be taught</a>.</p><h2 id=\"but-it-starts-by-starting-in-the-small\">but, it starts by starting in the small</h2><p>In the private Amp repository on GitHub, there is this mermaid diagram. This mermaid diagram articulates how our GitHub Actions workflows work for releasing <a href=\"https://ampcode.com/?ref=ghuntley.com\" rel=\"noreferrer\">Amp</a> to you. It exists to make onboarding our staff into the project easier.</p><figure class=\"kg-card kg-image-card\"><img alt=\"I dream of roombas - thousands of automated AI robots that autonomously maintain codebases\" class=\"kg-image\" height=\"1168\" src=\"https://ghuntley.com/content/images/2025/06/CleanShot-2025-06-07-at-12.56.43@2x.png\" width=\"1792\" /></figure><p>The following prompt generated it:</p><pre><code class=\"language-Markdown\"># Prompt to Regenerate GitHub Actions Mermaid Diagram\n\n## Objective\n\nCreate a comprehensive mermaid diagram for the README.md that visualizes all GitHub Actions workflows in the `.github/workflows/` directory and their relationships.\n\n## Requirements\n\n1. **Analyze all workflow files** in `.github/workflows/`:\n\n   - `ci.yml` - Main CI workflow\n   - `release-cli.yml` - CLI release automation\n   - `release-vscode.yml` - VS Code extension release\n   - `scip-typescript.yml` - Code intelligence analysis\n   - `semgrep.yml` - Security scanning\n   - `slack-notify.yml` - Global notification system\n   - Any other workflow files present\n\n2. **Show workflow triggers clearly**:\n\n   - Push/PR events\n   - Scheduled releases\n   - Main branch specific events\n   - TypeScript file changes\n\n3. **Include complete workflow flows**:\n\n   - CI: Build &amp; Test &#x2192; TypeScript Check &#x2192; Linting &#x2192; Test Suite\n   - Server Build: Docker Build &#x2192; Goss Tests &#x2192; Push to Registry &#x2192; MSP Deploy\n   - CLI Release: Version Generation &#x2192; Build &amp; Test &#x2192; NPM Publish\n   - VS Code Release: Version Generation &#x2192; Build &amp; Package &#x2192; VS Code Marketplace &#x2192; Open VSX Registry\n   - SCIP Analysis: Code Intelligence Upload &#x2192; Multiple Sourcegraph instances\n   - Semgrep: Security Scan &#x2192; Custom Rules &#x2192; Results Processing\n\n4. **Slack notifications must be specific**:\n\n   - `alerts-amp-build-main` channel for general main branch workflow success/failure notifications\n   - `soul-of-a-new-machine` channel for CLI and VS Code release failure notifications\n   - All Slack notification nodes should be styled in yellow (`#ffeb3b`)\n\n5. **Color coding for workflow types**:\n\n   - CI Workflow: Light blue (`#e1f5fe`)\n   - Server Image Build: Light purple (`#f3e5f5`)\n   - CLI Release: Light green (`#e8f5e8`)\n   - VS Code Release: Light orange (`#fff3e0`)\n   - SCIP Analysis: Light pink (`#fce4ec`)\n   - Semgrep SAST: Light red (`#ffebee`)\n   - All Slack notifications: Yellow (`#ffeb3b`)\n\n6. **Global notification system**:\n   - Show that `slack-notify.yml` monitors ALL workflows on main branch\n   - Connect all main branch workflows to the central `alerts-amp-build-main` notification\n\n## Task Output\n\nCreate mermaid `graph TD` diagram which is comprehensive yet readable, showing the complete automation pipeline from code changes to deployments and notifications.\n\n## Task\n\n1. Read the README.md\n2. Update the README.md with the mermaid `graph TD` diagram</code></pre><p>Cool, so now we&apos;ve got a prompt that generated a mermaid diagram, but now we&apos;ve also got KTLO problems. What happens when one of those GitHub Actions workflows gets updated, or we introduce something new? Well, incorrect documentation is worse than no documentation.</p><p>One thing I&apos;ve noticed through staring into the latent space is that these prompts and markdown are a weird pseudo-DSL. They&apos;re almost like shell scripts. If you&apos;ve read my <a href=\"https://ghuntley.com/stdlib\" rel=\"noreferrer\">standard library blog post</a>, you know by now that you can chain these DSLs together to achieve desired outcomes.</p><p>If the right approach is taken, I suspect the pattern for fixing KTLO for enterprise will also be the same as that used for enterprise code migrations. Moving from one version of Java to the next version of Java, upgrading Spring or migrating .NET 4.8 to a newer version of .NET Core, aka .NET 8.</p><p>It&apos;s time to build. It&apos;s time to make the future beautiful.</p><figure class=\"kg-card kg-embed-card\"></figure><h2 id=\"ps-socials\">ps. socials</h2><ul><li>X - <a href=\"https://x.com/GeoffreyHuntley/status/1931192949611827568?ref=ghuntley.com\">https://x.com/GeoffreyHuntley/status/1931192949611827568</a></li><li>BlueSky - <a href=\"https://bsky.app/profile/ghuntley.com/post/3lqyg7facxc2g?ref=ghuntley.com\">https://bsky.app/profile/ghuntley.com/post/3lqyg7facxc2g</a></li><li>LinkedIn - <a href=\"https://www.linkedin.com/posts/geoffreyhuntley_i-dream-of-roombas-thousands-of-automated-activity-7336959517479358466-D-3T?utm_source=share&amp;utm_medium=member_desktop&amp;rcm=ACoAAABQKuUB2AJ059keUcRUVLbtmoa6miLVlTI\">https://www.linkedin.com/posts/geoffreyhuntley_i-dream-of-roombas-thousands-of-automated-activity-7336959517479358466-D-3T</a></li></ul>"
            ],
            "link": "https://ghuntley.com/ktlo/",
            "publishedAt": "2025-06-07",
            "source": "Geoffrey Huntley",
            "summary": "<p>Just yesterday morning, I was writing a conference talk on best practices for maintaining the LLM context window, which was quite detailed. It contained the then best practices from the two blog posts below.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://ghuntley.com/gutter/\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">autoregressive queens of failure</div><div class=\"kg-bookmark-description\">Have you ever had your AI coding assistant suggest something so off-base</div></div></a></figure>",
            "title": "I dream of roombas - thousands of automated AI robots that autonomously maintain codebases"
        },
        {
            "content": [],
            "link": "https://harper.blog/notes/2025-06-07_af505711117e_final-drop-of-friends-from-las/",
            "publishedAt": "2025-06-07",
            "source": "Harper Reed",
            "summary": "<p>Final drop of friends from last weekend. Lee, Ani, and Mohammad</p> <figure> <img alt=\"image_1.jpg\" height=\"1350\" src=\"https://harper.blog/notes/2025-06-07_af505711117e_final-drop-of-friends-from-las/image_1.jpg\" width=\"1800\" /> </figure> <figure> <img alt=\"image_2.jpg\" height=\"1800\" src=\"https://harper.blog/notes/2025-06-07_af505711117e_final-drop-of-friends-from-las/image_2.jpg\" width=\"1800\" /> </figure> <figure> <img alt=\"image_3.jpg\" height=\"1800\" src=\"https://harper.blog/notes/2025-06-07_af505711117e_final-drop-of-friends-from-las/image_3.jpg\" width=\"1800\" /> </figure> <hr /> <p>Thank you for using RSS. I appreciate you. <a href=\"mailto:harper&#64;modest.com\">Email me</a></p>",
            "title": "Note #257"
        },
        {
            "content": [],
            "link": "https://simonwillison.net/2025/Jun/7/comma/#atom-entries",
            "publishedAt": "2025-06-07",
            "source": "Simon Willison",
            "summary": "<p>It's been a long time coming, but we finally have some promising LLMs to try out which are trained entirely on openly licensed text!</p> <p>EleutherAI released <a href=\"https://arxiv.org/abs/2101.00027\">the Pile</a> four and a half years ago: \"an 800GB dataset of diverse text for language modeling\". It's been used as the basis for many LLMs since then, but much of the data in it came from <a href=\"https://commoncrawl.org/\">Common Crawl</a> - a crawl of the public web which mostly ignored the licenses of the data it was collecting.</p> <p><a href=\"https://huggingface.co/blog/stellaathena/common-pile\">The Common Pile v0.1</a> is EleutherAI's successor to the original Pile, in collaboration with a large group of other organizations with whom they have been \"meticulously curating a 8 TB corpus of openly licensed and public domain text for training large language models\".</p> <p>The dataset is exciting, but on top of that they've released two new LLMs that have been trained on it: Comma v0.1 1T and 2T, both with 7 billion parameters, the first trained on 1 trillion tokens and the second on 2 trillion tokens.</p> <p>These are available on Hugging Face as <a href=\"https://huggingface.co/common-pile/comma-v0.1-1t\">common-pile/comma-v0.1-1t</a> and <a href=\"https://huggingface.co/common-pile/comma-v0.1-2t\">common-pile/comma-v0.1-2t</a>.</p> <p>EleutherAI claim that these new models perform \"comparably to leading models trained in the same",
            "title": "Comma v0.1 1T and 2T - 7B LLMs trained on openly licensed text"
        },
        {
            "content": [],
            "link": "https://lethain.com/desk-setup-2025/",
            "publishedAt": "2025-06-07",
            "source": "Will Larson",
            "summary": "<p>Since 2020, I&rsquo;ve been working on my desk setup, and I think I finally have it mostly pulled together at this point. I don&rsquo;t <em>really</em> think my desk setup is very novel, and I&rsquo;m sure there are better ways to pull it together, but I will say that it finally works the way I want since I added the <a href=\"https://www.caldigit.com/thunderbolt-5-dock-ts5-plus/\">CalDigit TS5 Plus</a>, which has been a long time coming.</p> <p>My requirements for my desk are:</p> <ol> <li>Has support for 2-3 Mac laptops</li> <li>Has support for a Windows gaming desktop with a dedicated GPU</li> <li>Has a dedicated microphone</li> <li>Has good enough lighting</li> <li>Is not too messy</li> <li>I can switch between any laptop and desktop with a single Thunderbolt cable</li> </ol> <p>Historically the issue here has been the final requirement, where switching required moving two cables&ndash;a Thunderbolt and a cable for the dedicated graphics card&ndash;but with my new dock this finally works with just one cable.</p> <p><img alt=\"\" src=\"https://lethain.com/static/blog/2025/desktop-far.jpg\" /></p> <p>The equipment shown here, and my brief review of each piece, is:</p> <ol> <li> <p><a href=\"https://www.upliftdesk.com/uplift-v2-standing-desk-v2-or-v2-commercial/?4275=4857&amp;4276=4657&amp;4279=3821&amp;27944=4849&amp;4280=11854&amp;10958=8704&amp;14905=11667\">UPLIFT v2 Standing Desk</a> &ndash; is the standing desk I use. I both have a lot of stuff on my desk, and also want my desk",
            "title": "My desk setup in 2025."
        }
    ],
    "lookbackDays": 1,
    "publishDate": "2025-06-07"
}