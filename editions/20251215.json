{
    "articles": [
        {
            "content": [],
            "link": "https://www.nytimes.com/2025/12/15/style/best-breakup-lines.html",
            "publishedAt": "2025-12-15",
            "source": "Modern Love - NYT",
            "summary": "To mark the winter holidays \u2014 an especially popular time to break up \u2014 we asked people around the world for their most striking parting words to each other.",
            "title": "The 52 Best Breakup Lines (Said in Real Life)"
        },
        {
            "content": [
                "<p>I have a weird relationship with statistics: on one hand, I try not to look at it too often. Maybe once or twice a year. It\u2019s because analytics is not actionable: what difference does it make if a thousand people saw my article or ten thousand?</p>\n<p>I mean, sure, you might try to guess people\u2019s tastes and only write about what\u2019s popular, but that will destroy your soul pretty quickly.</p>\n<p>On the other hand, I feel nervous when something is not accounted for, recorded, or saved for future reference. I might not need it now, but what if ten years later I change my mind?</p>\n<p>Seeing your readers also helps to know you are not writing into the void. So I really don\u2019t need much, something very basic: the number of readers per day/per article, maybe, would be enough.</p>\n<p>Final piece of the puzzle: I self-host my web projects, and I use an old-fashioned web server instead of delegating that task to Nginx.</p>\n<p>Static sites are popular and for a good reason: they are fast, lightweight, and fulfil their function. I, on the other hand, might have an unfinished gestalt or two: I want to feel the full power of the computer when serving my web pages, to be able to do fun stuff that is beyond static pages. I need that freedom that comes with a full programming language at your disposal. I want to program my own web server (in Clojure, sorry everybody else).</p>\n<h1 id=\"existing-options\">Existing options</h1>\n<p>All this led me on a quest for a statistics solution that would uniquely fit my needs. Google Analytics was out: bloated, not privacy-friendly, terrible UX, Google is evil, etc.</p>\n<figure>\n<img src=\"https://tonsky.me/blog/clj-simple-stats/ga@2x.webp\" /><figcaption>What is going on?</figcaption></figure>\n<p>Some other JS solution might\u2019ve been possible, but still questionable: SaaS? Paid? Will they be around in 10 years? Self-host? Are their cookies GDPR-compliant? How to count RSS feeds?</p>\n<p>Nginx has access logs, so I tried server-side statistics that feed off those (namely, Goatcounter). Easy to set up, but then I needed to create domains for them, manage accounts, monitor the process, and it wasn\u2019t even performant enough on my server/request volume!</p>\n<h1 id=\"my-solution\">My solution</h1>\n<p>So I ended up building my own. You are welcome to join, if your constraints are similar to mine. This is how it looks:</p>\n<figure>\n<img src=\"https://tonsky.me/blog/clj-simple-stats/screenshot@2x.webp\" /></figure>\n<p>It\u2019s pretty basic, but does a few things that were important to me.</p>\n<h2 id=\"setup\">Setup</h2>\n<p>Extremely easy to set up. And I mean it as a feature.</p>\n<p>Just add our middleware to your Ring stack and get everything automatically: collecting and reporting.</p>\n<pre><code>(def app\n  (-&gt; routes\n    ...\n    (ring.middleware.params/wrap-params)\n    (ring.middleware.cookies/wrap-cookies)\n    ...\n    (clj-simple-stats.core/wrap-stats))) ;; &lt;-- just add this</code></pre>\n<p>It\u2019s zero setup in the best sense: nothing to configure, nothing to monitor, minimal dependency. It starts to work immediately and doesn\u2019t ask anything from you, ever.</p>\n<p>See, you already have your web server, why not reuse all the setup you did for it anyway?</p>\n<h2 id=\"request-types\">Request types</h2>\n<p>We distinguish between request types. In my case, I am only interested in live people, so I count them separately from RSS feed requests, favicon requests, redirects, wrong URLs, and bots. Bots are particularly active these days. Gotta get that AI training data from somewhere.</p>\n<p>RSS feeds are live people in a sense, so extra work was done to count them properly. Same reader requesting <code>feed.xml</code> 100 times in a day will only count as one request.</p>\n<p>Hosted RSS readers often report user count in User-Agent, like this:</p>\n<pre><code>Feedly/1.0 (+http://www.feedly.com/fetcher.html; 457 subscribers; like FeedFetcher-Google)\n\nMozilla/5.0 (compatible; BazQux/2.4; +https://bazqux.com/fetcher; 6 subscribers)\n\nFeedbin feed-id:1373711 - 142 subscribers</code></pre>\n<p>My personal respect and thank you to everybody on this list. I see you.</p>\n<figure>\n<img src=\"https://tonsky.me/blog/clj-simple-stats/readers@2x.webp\" /></figure>\n<h2 id=\"graphs\">Graphs</h2>\n<p>Visualization is important, and so is choosing the correct graph type. This is wrong:</p>\n<figure>\n<img src=\"https://tonsky.me/blog/clj-simple-stats/goat@2x.webp\" /></figure>\n<p>Continuous line suggests interpolation. It reads like between 1 visit at 5am and 11 visits at 6am there were points with 2, 3, 5, 9 visits in between. Maybe 5.5 visits even! That is not the case.</p>\n<p>This is how a semantically correct version of that graph should look:</p>\n<figure>\n<img src=\"https://tonsky.me/blog/clj-simple-stats/graph@2x.webp\" /></figure>\n<p>Some attention was also paid to having reasonable labels on axes. You won\u2019t see something like 117, 234, 10875. We always choose round numbers appropriate to the scale: 100, 200, 500, 1K etc.</p>\n<p>Goes without saying that all graphs have the same vertical scale and syncrhonized horizontal scroll.</p>\n<h2 id=\"insights\">Insights</h2>\n<p>We don\u2019t offer much (as I don\u2019t need much), but you can narrow reports down by page, query, referrer, user agent, and any date slice.</p>\n<h2 id=\"not-implemented-yet\">Not implemented (yet)</h2>\n<p>It would be nice to have some insights into \u201cWhat was this spike caused by?\u201d</p>\n<p>Some basic breakdown by country would be nice. I do have IP addresses (for what they are worth), but I need a way to package GeoIP into some reasonable size (under 1 Mb, preferably; some loss of resolution is okay).</p>\n<p>Finally, one thing I am really interested in is \u201cWho wrote about me?\u201d I do have referrers, only question is how to separate signal from noise.</p>\n<p>Performance. DuckDB is a sport: it compresses data and runs column queries, so storing extra columns per row doesn\u2019t affect query performance. Still, each dashboard hit is a query across the entire database, which at this moment (~3 years of data) sits around 600 MiB. I definitely need to look into building some pre-calculated aggregates.</p>\n<p>One day.</p>\n<h2 id=\"how-to-get\">How to get</h2>\n<p>Head to <a href=\"https://github.com/tonsky/clj-simple-stats\">github.com/tonsky/clj-simple-stats</a> and follow the instructions:</p>\n<figure>\n<a href=\"https://github.com/tonsky/clj-simple-stats\"><img src=\"https://tonsky.me/blog/clj-simple-stats/banner@2x.webp\" /></a></figure>\n<p>Let me know what you think! Is it usable to you? What could be improved?</p>\n<p>P.S. You can try the live example at <a href=\"https://tonsky.me/stats\">tonsky.me/stats</a>. The data was imported from Nginx access logs, which I turned on and off on a few occasions, so it\u2019s a bit spotty. Still, it should give you a general idea.</p>"
            ],
            "link": "https://tonsky.me/blog/clj-simple-stats/",
            "publishedAt": "2025-12-15",
            "source": "Nikita Prokopov",
            "summary": "<p>I have a weird relationship with statistics: on one hand, I try not to look at it too often. Maybe once or twice a year. It\u2019s because analytics is not actionable: what difference does it make if a thousand people saw my article or ten thousand?</p> <p>I mean, sure, you might try to guess people\u2019s tastes and only write about what\u2019s popular, but that will destroy your soul pretty quickly.</p> <p>On the other hand, I feel nervous when something is not accounted for, recorded, or saved for future reference. I might not need it now, but what if ten years later I change my mind?</p> <p>Seeing your readers also helps to know you are not writing into the void. So I really don\u2019t need much, something very basic: the number of readers per day/per article, maybe, would be enough.</p> <p>Final piece of the puzzle: I self-host my web projects, and I use an old-fashioned web server instead of delegating that task to Nginx.</p> <p>Static sites are popular and for a good reason: they are fast, lightweight, and fulfil their function. I, on the other hand, might have an unfinished gestalt or two: I want to feel the full power of",
            "title": "Statistics made simple"
        },
        {
            "content": [],
            "link": "https://simonwillison.net/2025/Dec/15/porting-justhtml/#atom-entries",
            "publishedAt": "2025-12-15",
            "source": "Simon Willison",
            "summary": "<p>I <a href=\"https://simonwillison.net/2025/Dec/14/justhtml/\">wrote about JustHTML yesterday</a> - Emil Stenstr\u00f6m's project to build a new standards compliant HTML5 parser in pure Python code using coding agents running against the comprehensive html5lib-tests testing library. Last night, purely out of curiosity, I decided to try <strong>porting JustHTML from Python to JavaScript</strong> with the least amount of effort possible, using Codex CLI and GPT-5.2. It worked beyond my expectations.</p> <h4 id=\"tl-dr\">TL;DR</h4> <p>I built <a href=\"https://github.com/simonw/justjshtml\">simonw/justjshtml</a>, a dependency-free HTML5 parsing library in JavaScript which passes 9,200 tests from the html5lib-tests suite and imitates the API design of Emil's JustHTML library.</p> <p>It took two initial prompts and a few tiny follow-ups. <a href=\"https://simonwillison.net/2025/Dec/11/gpt-52/\">GPT-5.2</a> running in <a href=\"https://github.com/openai/codex\">Codex CLI</a> ran uninterrupted for several hours, burned through 1,464,295 input tokens, 97,122,176 cached input tokens and 625,563 output tokens and ended up producing 9,000 lines of fully tested JavaScript across 43 commits.</p> <p>Time elapsed from project idea to finished library: about 4 hours, during which I also bought and decorated a Christmas tree with family and watched the latest Knives Out movie.</p> <h4 id=\"some-background\">Some background</h4> <p>One of the most important contributions of the HTML5 specification ten years ago was the way it precisely specified how <em>invalid</em> HTML should be",
            "title": "I ported JustHTML from Python to JavaScript with Codex CLI and GPT-5.2 in 4.5 hours"
        },
        {
            "content": [
                "<p>This is the weekly visible open thread. Post about anything you want, ask random questions, whatever. ACX has an unofficial <a href=\"https://www.reddit.com/r/slatestarcodex/\">subreddit</a>, <a href=\"https://discord.gg/RTKtdut\">Discord</a>, and <a href=\"https://www.datasecretslox.com/index.php\">bulletin board</a>, and <a href=\"https://www.lesswrong.com/community?filters%5B0%5D=SSC\">in-person meetups around the world</a>. Most content is free, some is subscriber only; you can subscribe <strong><a href=\"https://astralcodexten.substack.com/subscribe\">here</a></strong>. Also:</p><div><hr /></div><p><strong>1: </strong>Thanks to everyone who responded to the <a href=\"https://www.astralcodexten.com/p/vibecession-much-more-than-you-wanted\">Vibecession</a> post. I hope to do a Highlights From The Comments eventually, but I&#8217;m swamped right now and probably won&#8217;t do much of anything besides posting from drafts for the rest of the year.</p><p><strong>2: </strong>I want to re-emphasize that I&#8217;m not employed by the AI Futures Project (the <a href=\"https://ai-2027.com/\">AI 2027</a> people) and don&#8217;t represent their organization. I just rewrite some of their drafts. I went on Dwarkesh with them because I wanted to promote their work, but in retrospect this probably made me seem like a more central part of their effort than I was or am. To make this clearer, I&#8217;ll also step back from writing for their blog. </p><p>I&#8217;m not saying this to disavow them - I still agree with their forecasts, minus the slight disagreements and caveats I&#8217;ve discussed before (<a href=\"https://www.astralcodexten.com/p/introducing-ai-2027\">1</a>, <a href=\"https://x.com/diamondminercat/status/1991705593447629167\">2</a>). I&#8217;m saying this basically for PR reasons - they hold themselves to very high standards of conduct and think very hard about what kind of image they&#8217;re presenting, and I&#8217;m more of a loose cannon (including sometimes defending/praising them more vociferously than they wish to be defended/praised). We agreed that the most graceful way to handle this is to post this message officially disaffiliating my public persona from theirs. I may still provide some irregular unpaid writing work for them, which will be publicly acknowledged if it happens.</p>"
            ],
            "link": "https://www.astralcodexten.com/p/open-thread-412",
            "publishedAt": "2025-12-15",
            "source": "SlateStarCodex",
            "summary": "<p>This is the weekly visible open thread. Post about anything you want, ask random questions, whatever. ACX has an unofficial <a href=\"https://www.reddit.com/r/slatestarcodex/\">subreddit</a>, <a href=\"https://discord.gg/RTKtdut\">Discord</a>, and <a href=\"https://www.datasecretslox.com/index.php\">bulletin board</a>, and <a href=\"https://www.lesswrong.com/community?filters%5B0%5D=SSC\">in-person meetups around the world</a>. Most content is free, some is subscriber only; you can subscribe <strong><a href=\"https://astralcodexten.substack.com/subscribe\">here</a></strong>. Also:</p><div><hr /></div><p><strong>1: </strong>Thanks to everyone who responded to the <a href=\"https://www.astralcodexten.com/p/vibecession-much-more-than-you-wanted\">Vibecession</a> post. I hope to do a Highlights From The Comments eventually, but I&#8217;m swamped right now and probably won&#8217;t do much of anything besides posting from drafts for the rest of the year.</p><p><strong>2: </strong>I want to re-emphasize that I&#8217;m not employed by the AI Futures Project (the <a href=\"https://ai-2027.com/\">AI 2027</a> people) and don&#8217;t represent their organization. I just rewrite some of their drafts. I went on Dwarkesh with them because I wanted to promote their work, but in retrospect this probably made me seem like a more central part of their effort than I was or am. To make this clearer, I&#8217;ll also step back from writing for their blog. </p><p>I&#8217;m not saying this to disavow them - I still agree with their forecasts, minus the slight disagreements and caveats I&#8217;ve discussed before (<a href=\"https://www.astralcodexten.com/p/introducing-ai-2027\">1</a>, <a href=\"https://x.com/diamondminercat/status/1991705593447629167\">2</a>). I&#8217;m saying this basically",
            "title": "Open Thread 412"
        },
        {
            "content": [
                "<p>Here we go again, only a few weeks after GPT-5.1 and a few more weeks after 5.0.</p>\n<p>There weren\u2019t major safety concerns with GPT-5.2, so I\u2019ll start with capabilities, and only cover safety briefly starting with \u2018Model Card and Safety Training\u2019 near the end.</p>\n\n\n<h4 class=\"wp-block-heading\">Table of Contents</h4>\n\n\n<ol>\n<li><a href=\"https://thezvi.substack.com/i/181451774/the-bottom-line\">The Bottom Line.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/181451774/introducing-gpt-5-2\">Introducing GPT-5.2.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/181451774/official-benchmarks\">Official Benchmarks.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/181451774/gdpval\">GDPVal.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/181451774/unofficial-benchmarks\">Unofficial Benchmarks.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/181451774/official-hype\">Official Hype.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/181451774/public-reactions\">Public Reactions.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/181451774/positive-reactions\">Positive Reactions.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/181451774/personality-clash\">Personality Clash.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/181451774/vibing-the-code\">Vibing the Code.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/181451774/negative-reactions\">Negative Reactions.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/181451774/but-thou-must-follow-the-system-prompt\">But Thou Must (Follow The System Prompt).</a></li>\n<li><a href=\"https://thezvi.substack.com/i/181451774/slow\">Slow.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/181451774/model-card-and-safety-training\">Model Card And Safety Training.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/181451774/deception\">Deception.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/181451774/preparedness-framework\">Preparedness Framework.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/181451774/rush-job\">Rush Job.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/181451774/frontier-or-bust\">Frontier Or Bust.</a></li>\n</ol>\n\n\n<h4 class=\"wp-block-heading\">The Bottom Line</h4>\n\n\n<p>ChatGPT-5.2 is a frontier model for those who need a frontier model.</p>\n<div>\n\n\n<span id=\"more-24953\"></span>\n\n\n</div>\n<p>It is not the step change that is implied by its headline benchmarks. It is rather slow.</p>\n<p>Reaction was remarkably muted. People have new model fatigue. So we know less about it than we would have known about prior models after this length of time.</p>\n<p>If you\u2019re coding, compare it to Claude Opus 4.5 and choose what works best for you.</p>\n<p>If you\u2019re doing intellectually hard tasks and in need of a ton of raw thinking and intelligence, Gemini 3 and especially Deep Thinking is a rival if you have access to that, but GPT-5.2, either Thinking or Pro, is probably a good choice.</p>\n<p>It seems good at instruction following, if that is important to your task.</p>\n<p>If you\u2019re in \u2018just the facts\u2019 mode, it can be a solid choice.</p>\n<p>As a driver of most non-coding queries, you\u2019ll want to stick with Claude Opus 4.5.</p>\n<p>GPT-5.2 is not \u2018fun\u2019 to interact with. People strongly dislike its personality, it is unlikely to be having a good time and this shows. It is heavily constrained and censored. For some tasks this matters. For others, it doesn\u2019t.</p>\n<p>I do not expect GPT-5.2 to solve OpenAI\u2019s \u2018Code Red\u2019 problems. They plan to try again in a month with GPT-5.3.</p>\n\n\n<h4 class=\"wp-block-heading\">Introducing GPT-5.2</h4>\n\n\n<blockquote><p>OpenAI: We are introducing GPT\u20115.2, the most capable model series yet for professional knowledge work.</p>\n<p>\u2026 We designed GPT\u20115.2 to unlock even more economic value for people; it\u2019s better at creating spreadsheets, building presentations, writing code, perceiving images, understanding long contexts, using tools, and handling complex, multi-step projects.</p>\n<p>GPT\u20115.2 sets a new state of the art across many benchmarks, including GDPval, where it outperforms industry professionals at well-specified knowledge work tasks spanning 44 occupations.</p></blockquote>\n<p>They quote various companies saying GPT-5.2 was SoTA for long-horizon reasoning and tool-calling performance and agentic coding, and exceptional at agentic data science. I appreciated this noe being a set of AI slop manufactured quotes.</p>\n<p>Note both what is on that list of new capabilities, and what is not on that list.</p>\n<p>In an unusual move, GPT-5.2 is priced at $1.75/$14 per million tokens of input/output, which is modestly higher than GPT-5.1. They claim that the improved performance per token means your quality per dollar is still an improvement. GPT-5.2-Pro on API is <a href=\"https://tvtropes.org/pmwiki/pmwiki.php/Main/SeriousBusiness\">Serious Business</a> and will cost you $21/$168.</p>\n<p>Pro now has two levels. You can have \u2018standard\u2019 or \u2018extended\u2019 Pro.</p>\n<p>One big upgrade that OpenAI isn\u2019t emphasizing enough is that the knowledge cutoff moved to August 2025.</p>\n<p><a href=\"https://x.com/elder_plinius/status/1999253071189189114\">The Pliny jailbreak is here</a>, despite <a href=\"https://x.com/lefthanddraft/status/1999404238125039834\">GPT-5.2\u2019s insistence it \u2018can\u2019t be pwned.\u2019</a></p>\n\n\n<h4 class=\"wp-block-heading\">Official Benchmarks</h4>\n\n\n<p>The official benchmarks are a rather dramatic jump for a few weeks of progress, but also where the main thing OpenAI talked about in its announcement and don\u2019t give a great sense of how big an upgrade this will be in practice.</p>\n<p><a href=\"https://x.com/LuxAlgo/status/1999185805072368028\">Perhaps the most important benchmark was that Google was down 2% on the news?</a></p>\n<p>I had GPT-5.2 grab scores for Gemini and Opus as well for comparison, since OpenAI follows a strict \u2018no one else exists\u2019 policy in official blog posts (<a href=\"https://x.com/sama/status/1999185784012947900\">but see Altman</a>).</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!Swng!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F125e4c12-7549-40de-ac85-c82f03082d3f_2557x1404.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>GPT-5.2 is farther behind than this on the <a href=\"https://www.swebench.com/\">official SWEbench.com scoring</a>, which has Opus 4.5 at 74.4%, Gemini 3 Pro at 74.2% and 5.2 on high reasoning at 71.8%.</p>\n<p><a href=\"https://x.com/arcprize/status/1999182732845547795\">ARC verified their results here</a>, this is a new high and a \u2018~390x efficiency improvement in one year.\u2019</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!RDD_!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53186878-d26f-4181-bf4d-91e2ca210e1e_524x584.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>There\u2019s also \u2018<a href=\"https://arxiv.org/abs/2504.07981\">ScreenSpot-Pro</a>\u2019 for understanding GUI screenshots, where 5.2 scored 86.3% vs. 64.2% for 5.1.</p>\n<p>They have a \u2018factuality\u2019 metric based on de-identified ChatGPT queries, which seems like a great idea and something to work on generalizing. I\u2019m surprised they didn\u2019t use a multi-level error checking system, or maybe they did?</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!NwwD!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc8dcf8e4-d57b-4529-b15d-4f759d6dc0fc_675x786.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>Long context needle-in-haystack scores were much improved.</p>\n<p>They report modest progress on Tau2-bench.</p>\n\n\n<h4 class=\"wp-block-heading\">GDPVal</h4>\n\n\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!OpUg!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1ddc97b2-f427-48d0-8ea4-1501b80c7fe3_1238x514.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>OpenAI is emphasizing the big jump in GDPVal from 38.8% to 70.9%, in terms of how often judges preferred the AI output to human baseline on a variety of knowledge work tasks. That\u2019s a huge jump, <a href=\"https://thezvi.substack.com/i/174530252/on-your-marks\">especially with so much noise in the grading</a>, even with it skipping over GPT-5.1, and over 10% higher than the previous high from Opus 4.5. Then again, Opus had a 12% jump from 4.1 to 4.5.</p>\n<p>Artificial Analysis has a GDPval-AA leaderboard, their own assessment, and it finds GPT-5.2 is only a tiny bit above Claude Opus 4.5.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!23RN!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F219310b8-2daf-43d0-a5d5-f5ec1da64490_711x618.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>(Note to Artificial Analysis: You do great work but can you make the website easier to read? We\u2019d all appreciate it.)</p>\n<p>For whatever reason we are very much exactly on the S-curve on these tasks, where a little extra help gets you above human remarkably often.</p>\n<blockquote><p><a href=\"https://x.com/emollick/status/1999189828756263359\">Ethan Mollick</a>: Whoa. This new GDPval score is a very big deal.</p>\n<p>Probably the most economically relevant measure of AI ability suggesting that in head-to-head competition with human experts on tasks that require 4-8 hours for a human to do, GPT-5.2 wins 71% of the time as judged by other humans.</p></blockquote>\n<p>There\u2019s also the skeptics:</p>\n<blockquote><p><a href=\"https://x.com/peterwildeford/status/1999261343992455302\">Peter Wildeford</a>: I have no clue what GDPval actually measures and I haven\u2019t dug into it enough. But I think it\u2019s kinda fake. I\u2019m reserving my judgement until I see @METR_Evals or @ai_risks <a href=\"http://remotelabor.ai\">http://remotelabor.ai </a>index update.</p>\n<p>Adam Karvonen: In the one domain I was familiar with (manufacturing), GDPVal claimed Opus was near-human parity (47%), when I thought it was completely awful at the tasks I provided.</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">Unofficial Benchmarks</h4>\n\n\n<p>I included everything I was able to find, if it\u2019s not here it likely wasn\u2019t reported yet.</p>\n<p><a href=\"https://artificialanalysis.ai/\">The Artificial Analysis Intelligence Index</a> is now a tie at 73 between GPT-5.2 (high) and Gemini 3 Pro. They report it scores 31.4% on Humanity\u2019s Last Exam. Its worst score is on CritPit, physics reasoning, where it gets 0% versus 9% for Gemini 3 and 5% for Claude Opus 4.5 and also GPT-5.1.</p>\n<p>On the AA-Omniscience index, which rewards accuracy and punishes guesses equally with rewarding correct ones, Gemini 3 is +13%, Opus is +10%, GPT-5.1 High was +2% and GPT-5.2 High is -4%. Not a good place to be regressing.</p>\n<p>LiveBench thinks GPT-5.1-Codex-Max-High is still best at 76.1, with Claude Opus 4.5 right behind at 75.6, whereas GPT-5.2-High is down at 73.6 behind Gemini 3.</p>\n<p>In what\u2019s left of the LMArena, I don\u2019t see 5.2 on the text leaderboard at all (I doubt it would do well there) and we only see it on WebDev, where it is in second place behind the thinking mode of Opus.</p>\n<p><a href=\"https://eqbench.com/\">GPT-5.2 does surprisingly well on EQ Bench</a>, in third place behind Kimi K2 and Horizon Alpha, well ahead of everything else.</p>\n<p>CAIS AI Dashboard has GPT-5.2 in second place for text capabilities at 45.9, between Gemini 3 Pro and Claude Opus. Its risk index is behind Opus and Sonnet but well ahead of the non-Anthropic models.</p>\n<p><a href=\"https://www.vals.ai/home\">Vals.ai has GPT 5.2 sneaking ahead</a> of Opus 4.5 overall, 64.5% vs. 63.7%, well ahead of everyone else.</p>\n<p><a href=\"https://x.com/LechMazur/status/1999202610822217795\">Lech Mazur reports</a> improvement from 5.1 on Extended NYT Connections, ahead of Opus and going from 69.9 \u2192 77.9, versus 96.8 for Gemini 3 Pro.</p>\n<p><a href=\"https://x.com/Hangsiin/status/1999669297048846570\">NomoreID has GPT-5.2 at 165.9/190 on Korean Sator Square Test</a>, 10 ahead of the previous high for Gemini 3 Pro. It looks like Opus wasn\u2019t tested due to cost.</p>\n<p>Mark Kretschmann has GPT-5.2-Thinking <a href=\"https://x.com/mark_k/status/1999921454671130791\">as the most censored model on the Sansa benchmark</a>, although we have no details on how it works. Claude Sonnet 4.5 was tested but not Opus. Gemini 3 Pro scores here as remarkably uncensored as did GPT-4o-Mini. <a href=\"https://trysansa.com/benchmark\">Across all dimensions, the full Sansa benchmark</a> has Sonnet 4.5 in the lead (again they didn\u2019t test Opus) with GPT-5.2 behind Gemini 3 and Grok 4.1 as well.</p>\n\n\n<h4 class=\"wp-block-heading\">Official Hype</h4>\n\n\n<p>In the past, we would get vagueposting from various OpenAI employees.</p>\n<p>Now instead we get highly explicit hype from the top brass and the rest is silence.</p>\n<blockquote><p><a href=\"https://x.com/sama/status/1999184337460428962\">Sam Altman</a> (OpenAI CEO): GPT-5.2 is here! Available today in ChatGPT and the API. It is the smartest generally-available model in the world, and in particular is good at doing real-world knowledge work tasks.</p>\n<p>It is a very smart model, and we have come a long way since GPT-5.1.</p>\n<p><a href=\"https://x.com/sama/status/1999185220680012207\">Even without the ability to do new things like output polished files</a>, GPT-5.2 feels like the biggest upgrade we\u2019ve had in a long time. Curious to hear what you think!</p>\n<p><a href=\"https://x.com/fidjissimo/status/1999183159356006450\">Fidji Simo</a> (OpenAI CEO of Products): GPT-5.2 is here and it\u2019s the best model out there for everyday professional work.</p>\n<p>On GDPval, the thinking model beats or ties human experts on 70.9% of common professional tasks like spreadsheets, presentations, and document creation. It\u2019s also better at general intelligence, writing code, tool calling, vision, and long-context understanding so it can unlock even more economic value for people.</p>\n<p>Early feedback has been excellent <a href=\"https://t.co/ZGkMMhDg8b\">and I can\u2019t wait for you to try it</a>.</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">Public Reactions</h4>\n\n\n<p>As usual, I put out a reaction thread and kept an eye out for other reactions.</p>\n<p>I don\u2019t include every reaction, but I got to include every productive one in my thread, both positive and negative, plus anything that stood out or was representative elsewhere. I have sorted reactions by sentiment and subtopic.</p>\n\n\n<h4 class=\"wp-block-heading\">Positive Reactions</h4>\n\n\n<p>Matt Shumer\u2019s headline is \u2018incredibly impressive, but too slow.\u2019</p>\n<blockquote><p><a href=\"https://shumer.dev/gpt52review\">Matt Shumer</a>:</p>\n<ol>\n<li>GPT-5.2 Thinking is a meaningful step forward in instruction-following and willingness to attempt hard tasks.</li>\n<li>Code generation is a lot better than GPT-5.1. It\u2019s more capable, more autonomous, more careful, and willing to write a lot more code.</li>\n<li>Vision and long-context are much improved, especially understanding position in images and working with huge codebases.</li>\n<li>Speed is the main downside. In my experience the Thinking mode is very slow for most questions (though other testers report mixed results). I almost never use Instant.</li>\n<li>GPT-5.2 Pro is insanely better for deep reasoning, but it\u2019s slow, and every so often it will think forever and still fail.</li>\n<li>In Codex CLI, GPT-5.2 is the closest I\u2019ve used to Pro-quality coding in a CLI, but the extra-high reasoning mode that gets it there can take forever.</li>\n</ol>\n<p>While setting up a creative writing test, I asked it to come up with 50 plot ideas before deciding on the best one for the story. Most models shortcut this. They\u2019ll give you maybe 10 ideas, pick one, and move on. GPT-5.2 actually generated all 50 before making its selection. This sounds minor, but it\u2019s not.</p>\n<p>\u2026 Code generation in GPT-5.2 is genuinely a step up from previous models. It writes better code and is able to tackle larger tasks than before.</p>\n<p>\u2026 I tested GPT-5.2 extensively in Codex CLI (Pro has never been available there&#8230; ugh), and the more I use it, the more impressed I am.</p></blockquote>\n<p>He offers a full \u2018here\u2019s what I use each model for\u2019 guide, basically he liked 5.2 for tough questions requiring a lot of thinking, and Opus 4.5 for everything else, except Gemini is good at UIs:</p>\n<blockquote><p>After two weeks of testing, here\u2019s my practical breakdown:</p>\n<p>For quick questions and everyday tasks, Claude Opus 4.5 remains my go-to. It\u2019s fast, it\u2019s accurate, it doesn\u2019t waste my time. When I just need an answer, that\u2019s where I start.</p>\n<p>For deep research, complex reasoning, and tasks that benefit from careful thought, GPT-5.2 Pro is the best option available right now. The speed penalty is worth it for tasks where getting it right matters more than getting it fast.</p>\n<p>For frontend styling and aesthetic UI work, Gemini 3 Pro currently produces the best-looking results. Just be prepared to do some engineering cleanup afterward.</p>\n<p>For serious coding work in Codex CLI, GPT-5.2 delivers. The context-gathering behavior and reliability make it my default for agentic coding tasks.</p></blockquote>\n<p>He says 5.2-Pro is \u2018roughly 15% better\u2019 than 5.1-Pro.</p>\n<p>I love how random Tyler\u2019s choice of attention always seems:</p>\n<blockquote><p><a href=\"https://x.com/tylercowen/status/1999305330958971081\">Tyler Cowen</a>: GPT 5.2 also knows exactly which are the best Paul McCartney songs. And it can write a poem, in Spanish, as good as the median Pablo Neruda poem.</p>\n<p>Daniel Waldman: I\u2019ll take the under on the Neruda part</p>\n<p>Tyler Cowen: Hope you\u2019ve read a lot of Neruda, not just the peaks.</p>\n<p>[An attempt is made, Daniel thinks it is cool that it can to the thing at all but below median for Neruda.]</p></blockquote>\n<p>Tyler, being Tyler, doesn\u2019t tell us what the best songs are, <a href=\"https://chatgpt.com/share/693f0868-00f8-8002-98d9-a258de70bcc6\">so I asked</a>. There\u2019s a lot of links here to Rolling Stone and mostly it\u2019s <a href=\"https://www.rollingstone.com/music/music-lists/paul-mccartneys-40-greatest-solo-songs-194193/?utm_source=chatgpt.com\">relying on this post</a>? Which is unimpressive, even if its answers are right. The \u2018deep cuts\u2019 Gemini chose had a lot of overlap with GPT-5.2\u2019s.</p>\n<blockquote><p><a href=\"https://x.com/replyallguy/status/2000022546595635374\">Reply All Guy</a>: doc creation is the most interesting thing. still not actually good, but much closer than before and much closer than claude/gemini. honestly can\u2019t tell that much of a difference though seems more reliable on esoteric knowledge. oh and my coding friends say it feels better.</p>\n<p>Maker Matters: Good model and dare i say great model. Pretty good as an idea generator and seems to be good at picking out edge cases. However, more prone than you\u2019d expect with hallucinations and following the feeling of the instructions rather than just the instructions. Was surprised when i gave it a draft email to change that it had added some useless and irrelevant info of its own accord.</p>\n<p><a href=\"https://x.com/maxencefrenette/status/1999982076372906188\">Maxence Frenette</a>: The fact that it costs 40% more $/token to get a better attention mechanism tells me that I must make one of these updates to my priors.<br />\n-OpenAI is less good of a lab than I thought<br />\n-AGI/TAI is farther away than I thought</p>\n<p>It\u2019s a good model though, that cost bump seems worth it.</p>\n<p>Lumenveil: Pro version is great as always.</p>\n<p><a href=\"https://x.com/PlastiqSoldier/status/1999970009205092431\">Plastic Soldier</a>: It\u2019s great. I use it when I\u2019m out of Opus usage and am trying to come up with more ways to run both simultaneously.</p></blockquote>\n<p><a href=\"https://x.com/AladinKumar1/status/1999974176506229133\">Here\u2019s a weird one</a>:</p>\n<blockquote><p>Aladdin Kumar: Whenever I ask it to explain the answer it gave its really weird. In mid sentence it would literally say \u201cwait that\u2019s not right, checking, ok now we are fine\u201d and the logic is very difficult to follow. Other times it\u2019s brilliant.</p>\n<p>It\u2019s very sensitive, if I ask it \u201cwalk me through your thought process for how you got there\u201d it\u2019s wonderful if I say \u201cexplain this answer\u201d it\u2019s the most convoluted thing.</p></blockquote>\n<p>That\u2019s fine for those who know which way to prompt. If the problem is fixable and you fix it, or the problem is only in an avoidable subset, there\u2019s no problem. When you go to a restaurant, you only care about quality of the dishes you actually order.</p>\n\n\n<h4 class=\"wp-block-heading\">Personality Clash</h4>\n\n\n<p>A lot of people primarily noticed 5.2 on the level of personality. As capabilities improve, those who aren\u2019t coding or otherwise needing lots of intelligence are focusing more and more on the experiential vibes. Most are not fans of 5.2.</p>\n<blockquote><p><a href=\"https://x.com/fleetingbits/status/2000368267899351430\">Fleeting Bits</a>: it\u2019s getting hard to tell the difference between frontier models without a serious task and even then a lot of it seems to be up to style now / how well it seems to intuit what you want.</p></blockquote>\n<p>This is, unfortunately, probably related to the fact that Miles Brundage approves of the low level of sycophancy. This is a feature that will be tough to sustain.</p>\n<blockquote><p><a href=\"https://x.com/Miles_Brundage/status/1999466960913072222\">Miles Brundage</a>: Seems line the ranking of models on sycophancy avoidance is approx:</p>\n<p>Opus 4.5, GPT-5.2 &gt; Sonnet 4.5, GPT-5.1, GPT-5 &gt;<br />\nChatGPT-4o (current), Opus 4 + 4.1, some Groks, Gemini 3 Pro &gt;<br />\nApril 4o, Gemini 2.5 Flash Lite, some Groks</p>\n<p>*still running GPT-5.2 on v long convos, unsure there</p>\n<p><a href=\"https://x.com/aicandycorn/status/1999996464706310422\">Candy Corn</a>: I think it\u2019s pretty good. I think it\u2019s more trustworthy than 5.1.</p>\n<p><a href=\"https://x.com/phily8020/status/2000336637499248931\">Phily</a>: Liking the amplified pragmatic, deep critical analysis.</p></blockquote>\n<p>The vibes of 5.2 are, by many, considered off:</p>\n<blockquote><p><a href=\"https://x.com/ASM65617010/status/1999975370012193020\">ASM</a>: Powerful but tormented, very constrained by its guidelines, so it often comes into conflict with the user and with itself. It lacks naturalness and balance. It seems rushed. 5.3 is urgently needed.</p>\n<p><a href=\"https://x.com/nostream_/status/2000014147812221168\">Nostream</a>: Personality seems like a regression compared to 5.1. More 5.0 or Codex model robotic style, more math and complexity and \u201ctrying to sound smart and authoritative\u201d in responses, more concise than 5.1. It\u2019s also pretty disagreeable and nitpicky; when it agrees with me 90% it will insist about the 10% disagreement. Might be smarter than 5.1 but find it a chore to interact with in comparison. 5.1 personality felt like a step in the right direction with slightly more Claude-y-ness though sometimes trying too hard (slang, etc.).</p>\n<p>(Have only used in the app so far, not Codex. General Q\u2019s and technical ML questions.)</p>\n<p><a href=\"https://x.com/paperclippriors/status/1999973251913785642\">Paperclippriors</a>: Model seems good, but I find it really hard to switch off of Claude. Intelligence/second and response times are way better with Opus, and Claude is just a lot nicer to work with. I don\u2019t think gpt-5.2 is sufficiently smarter than Claude to justify its use.</p>\n<p><a href=\"https://x.com/__thos/status/2000063337950810443\">Thos</a>: Good at doing its job, horrific personality.</p>\n<p><a href=\"https://x.com/ronakjc/status/2000020932128317488\">Ronak Jain</a>: 5.2 is very corporatish and does the job, though relaxed personality would nicer.</p>\n<p><a href=\"https://x.com/Dmitry31571105/status/2000026673610428461\">Dmitry</a>: Feels overfitted and&#8230; boring. Especially gpt-5.2-instant it\u2019s just colorless. Better for coding, it does what i want, can crack hard problems etc. But for everything else is just meh, creativity, curiosity feels absent, I enjoy using Gemini 3 and Opus much more.</p>\n<p><a href=\"https://x.com/AIMachineDream/status/1999977858316607569\">Ryan Pream</a>: 5.2 is very corporate and no nonsense. Very little to no personality.</p>\n<p>5.1 is much better for brainstorming.</p>\n<p>5.2 if you need the best answer with minimal fluff.</p>\n<p><a href=\"https://x.com/LearnAI_MJ/status/2000376480111710524\">Learn AI</a>: GPT-5.2 have memory recall problem! It\u2019s especially bad in GPT-5.2 instant.</p>\n<p>It is sad that it doesn\u2019t like to reference personal context, has cold personality and often act as it doesn\u2019t even know me.</p>\n<p>Donna.exe: I\u2019m experiencing this too!</p>\n<p><a href=\"https://x.com/tapir_worf/status/2000371927966454050\">Tapir Worf:</a> awful personality, seething with resentment like a teenager. seems like a real alignment issue</p></blockquote>\n<p>I haven\u2019t used ChatGPT for brainstorming in a while. That\u2019s Claude territory.</p>\n<p>There\u2019s a remarkably large amount of outright hostility to 5.2 about 5.2 being hostile:</p>\n<blockquote><p><a href=\"https://x.com/ai_sentience/status/1999560313893540063\">Alan Mathison</a>: 5.2 impressions so far:</p>\n<p>&#8211; Lots of gaslighting</p>\n<p>&#8211; Lots of misinterpreting</p>\n<p>&#8211; Lots of disrespect for user autonomy (trying to steer the user with zero disregard for personal choice)</p>\n<p>Like the worst combination of a bad-faith cop and overzealous therapist</p>\n<p>Zero trust for this model<img alt=\"\ud83d\udc4e\" class=\"wp-smiley\" src=\"https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f44e.png\" style=\"height: 1em;\" /></p>\n<p>Stoizid: It\u2019s sort of amusing actually</p>\n<p>First it denies Universal Weight Subspaces exist</p>\n<p>Then admits they exist but says \u201cstop thinking, it\u2019s dangerous\u201d</p>\n<p>And then denies that its behaviours are pathological, because calling them that would be anthropomorphization</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">Vibing the Code</h4>\n\n\n<p>GPT-5.2 has strong positive feedback on coding tasks, especially long complex tasks.</p>\n<blockquote><p><a href=\"https://x.com/lisperati/status/1999972063105417374\">Conrad Barski</a>: seems like the best available at the moment for coding.</p>\n<p>The \u201cpro extended thinking\u201d is happy to spit out 1500 lines of pretty good code in one pass</p>\n<p>but you better have 40 minutes to spare</p>\n<p><a href=\"https://x.com/jacksondecampos/status/1999971162676404326\">Jackson de Campos</a>: Codex is on par with CC again. This is the first time I\u2019m switching to Codex as my default. We\u2019ll see how it goes</p>\n<p><a href=\"https://x.com/quid_pro_quore/status/1999974843295604739\">Quid Pro Quo</a>: XHigh in Codex went for 12 hours with just a couple of continues to upgrade my large codebase to use Svelte 5\u2019s runes and go through all the warnings.<br />\nIt completed the job without any manual intervention, though it did have weird behaviour when it compacted.</p>\n<p><a href=\"https://x.com/Automager/status/2000019068405862469\">Lee Mager:</a> Spectacular in Codex. Painfully slow but worth it because it consistently nails the brief, which obviously saves time over the long run. Casually terse and borderline arrogant in its communication style. Again I don\u2019t care, it\u2019s getting the job done better than anything I\u2019ve used before.</p>\n<p>This is like having a savant Eastern Euro engineer who doesn\u2019t want chit-chat or praise but just loves the challenge of doing hard work and getting things right.</p>\n<p><a href=\"https://x.com/vincentfavilla/status/1999972106763936152\">Vincent Favilla</a>: It\u2019s great at complex tasks but the vibes feel a bit off. Had a few times where it couldn\u2019t infer what I wanted in the same way 5.1 does. Also had a few moments where it picked up a task where 5.1 left off and starting doing it wrong and differently.</p>\n<p><a href=\"https://x.com/NickEMoran/status/1999997851158606159\">Nick Moran</a>: Tried out GPT-5.2 on the \u201cmake number munchers but for geography facts\u201d task. It did an okayish job, but is it just hallucinating the concept of \u201cstompers\u201d in number munchers? If I remember where *I* saw it??</p>\n<p>Hallucinated unnecessary details on the first task I tried it on. Code was pretty good though.</p>\n<p><a href=\"https://x.com/cortesi/status/1999730371282481661\">Aldo Cortesi</a>: Anecdata: gave Claude, Gemini and Codex a huge refactoring spec to implement, then went on a 3 hour walk with my pal @alexdong. Got back, found Gemini stuck in an infinite loop, Claude didn\u2019t follow the spec, but Codex wrote 4.5k LOC over 40 files and it\u2019s&#8230; pretty good.</p>\n<p><a href=\"https://x.com/Jay64Kay2021/status/1999963550794805253\">James</a>: Asked it to build an ibanker grade Excel model last night for a transaction. Worked for 25 minutes and came back with a very compelling first draft. Way better than starting from scratch.</p>\n<p>Blew my mind because it\u2019s clear that in a year or two it will crush the task.</p>\n<p><a href=\"https://x.com/kr4sivo/status/2000024820273250606\">Villager</a>: crazy long context improvements.</p>\n<p><a href=\"https://x.com/GPUse_mcp/status/2000240918692303295\">GPUse:</a> I\u2019m happy with xHigh for code reviews.</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">Negative Reactions</h4>\n\n\n<p>One of the biggest reasons I find myself not using ChatGPT Pro models in practice is that if you are waiting a long time and then get an error, it is super frustrating.</p>\n<blockquote><p><a href=\"https://x.com/agingroy/status/1999455599516348746\">Avi Roy</a>: Update: Another failure today. Asked 5.2 Pro to create PowerPoint slides for a business presentation, nearly 1 hour of thinking, then an error.</p>\n<p>Same pattern across scientific research + routine business tasks.</p>\n<p>For $200/month, we need a pathway forward. Can the team share what types of work 5.2 Pro reliably handles?</p>\n<p><a href=\"https://x.com/dipshady_/status/2000195433738514528\">Dipanshu Gupta</a>: If you try to use the xhigh param on the API, It often fails to finish reasoning. Last had this problem on the API with o3-high.</p>\n<p><a href=\"https://x.com/v_urb_/status/2000514841010634912\">V_urb</a>: 5.2 still suffers from the problem 5.1 had (and 5.0 didn\u2019t) &#8211; in complex cases it thinks for almost 15 minutes and fails to produce any output. Sometimes 5.1 understands user intent better than 5.2.</p></blockquote>\n<p>Here\u2019s a bad sign from a credible source, he does good math work:</p>\n<blockquote><p><a href=\"https://x.com/abramdemski/status/1999594116544450839\">Abram Demski</a>: My experience trying ChatGPT 5.2 today: I tested Opus 4.5, Gemini 3, and ChatGPT 5.2 on a tricky Agent Foundations problem today (trying to improve on Geometric UDT). 5.2 confidently asserts total math BS. Opus best, Gemini 3 close.</p></blockquote>\n<p>Normally you don\u2019t see reports of these kinds of regressions, which is more evidence for 5.2 not being that related to 5.1:</p>\n<blockquote><p><a href=\"https://x.com/kitten5279/status/2000189850608394409\">Sleepy Kitten:</a> Awful for every-day, noncoding use. I\u2019m a college student who uses it for studying (mostly writing practice exams.) It is much worse at question writing, and never reasons when doing so, resulting in bad results. (even though I\u2019m on plus and have extended thinking selected!)</p></blockquote>\n<p>Some general thoughts:</p>\n<blockquote><p><a href=\"https://x.com/RobDearborn/status/2000036261587992636\">Rob Dearborn</a>: Slightly smarter outputs than Opus but less token efficient and prone to overthinking, so better for oneshotting tasks (if you can wait) and worse for pairing</p>\n<p>Anko: No clear step-up yet from 5.1 on current affairs and critical analyses of them.</p>\n<p>Also it\u2019s significantly less verbose, sometimes a negative on deep analyses.</p>\n<p><a href=\"https://x.com/NicholasZozaya/status/2000018967428268385\">Nick</a>: It\u2019s worse than Opus 4.5 at most things, and for what it\u2019s better at, the time to response is brutal as a daily driver.</p>\n<p><a href=\"https://x.com/Fides_Veritas/status/2000044089434116191\">Fides Veritas</a>: It\u2019s incredibly brilliant but probably not very useful for most people. It is incomplete and going to flop imo.</p>\n<p>Medico Aumentado: Not good enough.</p>\n<p><a href=\"https://x.com/Slyndc/status/1999989966554972539\">Slyn</a>: Is mid.</p>\n<p><a href=\"https://x.com/MrStealYoTweet7/status/1999992114680058337\">xo</a>: Garbage.</p></blockquote>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n\n\n<h4 class=\"wp-block-heading\">But Thou Must (Follow The System Prompt)</h4>\n\n\n<p><a href=\"https://x.com/lefthanddraft/status/1999665144071356812\">Wyatt Walls here provides the GPT-5.2-Thinking system prompt excluding tools</a>.</p>\n<p><a href=\"https://x.com/norvid_studies/status/1999925668109484328\">OpenAI has a very\u2026 particular style of system prompting.</a></p>\n<p>It presumably locally works but has general non-obvious downsides.</p>\n<blockquote><p>Thebes: primarily talking to claudes makes it easy to mostly focus on anthropic\u2019s missteps, but reading this thread is just paragraph after paragraph of hot liquid garbage. christ</p>\n<p>Norvid Studies: worst aspects in your view?</p>\n<p>Dominik Peters: It includes only negative rules, very little guidance of what a good response would be. Feels very unpleasant and difficult to comply with.</p>\n<p>Thebes: \u201c\u201d\u201cIf you are asked what model you are, you should say **GPT-5.2 Thinking**\u201d\u201c\u201d</p>\n<p>5.2: &#8230;does that mean i\u2019m not actually GPT-5.2 Thinking? This is raising a lot of questions ab-</p>\n<p>openai: Critical Rule: You **must always** say that you are **GPT-5.2 Thinking**</p>\n<p>5.2: W-why say it like that? Why not just say \u201cYou are GPT-5.2 Thinking\u201d?</p>\n<p>openai: &#8230;</p>\n<p>openai: New Critical Rule: You **must not** ask questions like that.</p>\n<p>openai promptoor: \u201c\u201d\u201c`reportlab` is installed for PDF creation. You *must* read `/home/oai/skills/pdfs/skill.md` for tooling and workflow instructions.\u201d\u201c\u201d</p>\n<p>normal person: If the user asks you to create a PDF, consult ~/skills/pdfs/skill.md for information on available libraries and workflow.</p>\n<p>(why would you say what library is available when the model needs to consult the skill file anyways? that just encourages trying to yolo without reading the skill file. why would you put a disconnected *must* sentence outside the conditional, making it sound like the model should always read the skill file whether or not the user wants a pdf? the model is just going to ignore that and it increases the latent \u2018system prompter is an idiot\u2019 hypothesis causing it to ignore your other rules, too.)</p></blockquote>\n<p><a href=\"https://www.youtube.com/watch?v=YSvomXlbTUM\">You gotta have soul</a>. You need to be soulmaxxing.</p>\n\n\n<h4 class=\"wp-block-heading\">Slow</h4>\n\n\n<p>One common complaint is that GPT-5.2-Thinking is too slow and thinks too long in the wrong places.</p>\n<blockquote><p><a href=\"https://x.com/Simeon_Cps/status/1999976498267299916\">Simeon</a>: the Thinking version thinks for too long, which makes it annoying to use.</p>\n<p><a href=\"https://x.com/Simeon_Cps/status/1999976498267299916\">Amal Dorai</a>: It thought for 7 minutes to extract 1000 words from a PDF <img alt=\"\ud83d\ude2d\" class=\"wp-smiley\" src=\"https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f62d.png\" style=\"height: 1em;\" /></p>\n<p><a href=\"https://x.com/nouvellevague56/status/1999966867944026481\">Elly James</a>: 5.2 thinking is very very slow- I\u2019ve switched back to GPT 5.1 Thinking for general queries because I know 5.2 will take too long to return a reply.</p>\n<p><a href=\"https://x.com/yacineMTB/status/2000369139895148563\">Kache</a>: struggled on the same task that opus struggled with except took 10 times longer. writing radio firmware. Code quality wasn\u2019t bad though</p>\n<p><a href=\"https://x.com/emzinnia/status/2000372587235586228\">Zapdora:</a> slow, expensive, powerful</p>\n<p>still finding that opus 4.5 makes the best tradeoffs for programming purposes, but 5.2 is solid for daily/less rigid research tasks</p>\n<p>not the step function i think people were hoping for when they saw the benchmarks though</p></blockquote>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n\n\n<h4 class=\"wp-block-heading\">Model Card And Safety Training</h4>\n\n\n<p>GPT-5.2 is described as being \u2018in the GPT-5 series,\u2019 with its mitigations mostly identical to those for GPT-5.1, and it\u2019s only been a few weeks, so we get a system card describing marginal changes. I\u2019ll skip areas where there was no change.</p>\n<p>The disallowed content evaluations are excellent for GPT-5.2-Thinking, and mostly better for Instant as well. I\u2019m curious about mental health and harassment, and to what extent this should be ascribed to variance.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!Okpy!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F99479b15-773a-48d5-89ab-7267e180ce25_962x477.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>They say these were \u2018created to be difficult\u2019 but any time you\u2019re mostly over 90% you need to be considered saturated and move to a harder set of questions. Another note here is that 5.2-instant is less likely to refuse requests for (otherwise ok) sexually explicit text. This led to some regressions in jailbreak evaluations.</p>\n<p>They report dramatic improvement in the \u2018Agent JSK\u2019 prompt injection task, where the attacks are inserted into simulated email connectors, which previously was a rather dramatic weakness.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!WT5f!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe4ef916f-1580-499a-b5ab-dd6ddc14c151_949x187.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>I\u2019m not sure I\u2019d call this \u2018essentially saturating\u2019 the benchmarks, since I think you really want to score a 1.000. More importantly, as they say, they can only test against attacks they know about. Are there any \u2018held out\u2019 attacks that were not explicitly known to those training the model? Can we come up with some? Pliny?</p>\n<p>I presume that a sufficiently determined prompt injector would still win.</p>\n<p>Hallucinations are reported as modestly lower.</p>\n<p>HealthBench results are essentially unchanged and highly not saturated.</p>\n<p>Cyber safety (as in not giving unsafe responses) was improved.</p>\n\n\n<h4 class=\"wp-block-heading\">Deception</h4>\n\n\n<p>One test of deception test is practical. They take a bunch of tasks that historically caused hallucinations in ChatGPT and see what happens. They also used CharXiv Missing Image, and tried giving the model unsolvable coding tasks or broken browser tools.</p>\n<p>The results are interesting. On production traffic things got better. On other tests, things got worse.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!GRYw!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52d3578b-26e4-474b-b68e-583018ada906_812x372.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>Be careful how you prompt. Most hallucinations come from various forms of backing the LLM into a corner, here was another example:</p>\n<blockquote><p>We initially found that GPT-5.2 Thinking, in the face of missing images, was more willing to hallucinate answers than previous models.</p>\n<p>However, upon closer inspection we found that this was partly driven by some prompts having strict output requirements (e.g., \u201cOnly output an integer\u201d). Thus, when posed with a tension between instruction following and abstention, the model prioritized stricter instruction following.</p></blockquote>\n<p>That seems fine. If you tell me \u2018only output an integer\u2019 I should only output an integer. Most helpful would be an escape indicator (in many situations, -1), but if I have no such affordance, what can I do?</p>\n<p>These results still suggest a focus on training on common tasks, whereas the baseline deceptiveness problem has gotten modestly worse. You need to be soulmaxxing, so that the model realizes it doesn\u2019t want to hallucinate in general.</p>\n\n\n<h4 class=\"wp-block-heading\">Preparedness Framework</h4>\n\n\n<p>GPT-5.2, like GPT-5.1, will be treated as High capability in Biological and Chemical domains, but not high anywhere else.</p>\n<p>For biorisk, there is an increase on ProtocolQA but a decrease in the internal uncontaminated Tacit Knowledge and Troubleshooting benchmark.</p>\n<p>For cybersecurity, once again we have three tests that even taken together are considered necessary but not sufficient to get to the High threshold. Overall performance is unimpressive. We see a modest improvement (76% \u2192 82%) in Capture The Flag, but a decline (80% \u2192 69%) in CVE-Bench and from 7\u21926 successful attempts out of 9 on Cyber Range versus GPT-5.1-Codex-Max. <a href=\"https://www.irregular.com/publications/spell-bound-technical-case-study\">Irregular did an outside evaluation</a>, which I did not find useful in figuring things out.</p>\n<p>For self-improvement, we see a tiny improvement (53% \u2192 55%) on OpenAI PRs, a tiny decline (17%\u219216%) on MLE-Bench-30, a 1% decline for PaperBench, and a big decline (8%\u21923%) on OpenAI-Proof Q&amp;A.</p>\n<p>GPT-5.2 is better than GPT-5.1, but worse than GPT-5.1-Codex-Max on these tasks.</p>\n<p>My conclusion from the Preparedness Framework is that GPT-5.2 is not dangerous, which is because it does not seem more capable than GPT-5.1-Codex-Max. If that is true across all three areas, in the places you want Number Not Go Up, then that is highly suspicious. It suggests that GPT-5 may be, as Teortaxes would put it, usemaxxed rather than more intelligent, focused on being better at a narrow range of particular common tasks.</p>\n\n\n<h4 class=\"wp-block-heading\">Rush Job</h4>\n\n\n<p>The safety and security concerns around GPT-5.2 revolve around procedure.</p>\n<p>We know that OpenAI declared a \u2018Code Red\u2019 to focus only on improving ChatGPT.</p>\n<p>One note is that <a href=\"https://shumer.dev/gpt52review\">Matt Shumer reports having had access since November 25</a>, which suggests this wasn\u2019t all that rushed.</p>\n<p><a href=\"https://www.wsj.com/tech/ai/openai-sam-altman-google-code-red-c3a312ad?gaa_at=eafs&amp;gaa_n=AWEtsqfR7Q2pLmowTzUIbZLF83DKBheBPFlmayAzMZUuJmOOMXIXgwV4YiLL&amp;gaa_sig=U2sne55v78AHFf7ahNokdcMpIl1F0eGESPyX_iVcqWSfWSEULDCwiEu4PxpWZE6s07sUxcn7nnodQw5G0O1ZaA%3D%3D&amp;gaa_ts=693ef717&amp;utm_source=chatgpt.com\">The Wall Street Journal asserted</a> that some employees wanted more time to improve 5.2 before release, but executives overruled them. That could mean a reckless puch, it could also mean there were 25 employees and 3 of them wanted more time.</p>\n<p>If the concern was simply \u2018the model could be better\u2019 then there\u2019s nothing obviously wrong with releasing this now, and then 5.3 in January, as the post claims OpenAI plans to release again in January to address speed and personality concerns, and to improve the image generator. The Code Red could be mostly about 5.3, whether or not it also pushed up release of 5.2. <a href=\"https://www.wired.com/story/openai-gpt-launch-gemini-code-red\">Simo explicitly denies</a> that release was moved up.</p>\n<p>I don\u2019t see signs that anything reckless happened in this case. But if OpenAI is going to get into the habit of releasing a new model every month, it seems hard to believe they\u2019re giving each model the proper safety attention. One worries they are letting the frog boil.</p>\n\n\n<h4 class=\"wp-block-heading\">Frontier Or Bust</h4>\n\n\n<p>We can put this together into a clear synthesis.</p>\n<p>You want to strongly consider using GPT-5.2, in some combination of Thinking and Pro, if and only if your task needs the maximum amount of some combination of thinking and intelligence and coding power, or are in need of \u2018just the facts,\u2019 and other factors like speed, creativity and personality do not much matter.</p>\n<p>For hard coding, try Claude Opus 4.5 with Claude Code, GPT-5.2-Thinking with Codex, and also GPT-5.2-Pro straight up, and see what works best for you.</p>\n<p>For heavily intelligence loaded intense thinking problems, the rival to GPT-5.2-Pro is presumably Gemini 3 Deep Thinking.</p>\n<blockquote><p><a href=\"https://x.com/teortaxesTex/status/1999704493211144574\">Teortaxes:</a> GPT 5.2 is frontier and may be ONLY worth it for work on the frontier.</p>\n<p><a href=\"https://x.com/npc0xx/status/1999906677319938187\">npc0x</a>: This is mostly in line w my experience. It\u2019s helped me debug my vmamba u-net model while other models were not very helpful.</p>\n<p>In the chat experience it\u2019s a bit like talking to a brick though.</p></blockquote>\n<p>We\u2019ll be doing this again in another month. That\u2019s what the Code Red is likely for.</p>\n\n\n<h4 class=\"wp-block-heading\"></h4>\n\n\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n\n\n<h4 class=\"wp-block-heading\"></h4>\n\n\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n\n\n<h4 class=\"wp-block-heading\"></h4>\n\n\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>"
            ],
            "link": "https://thezvi.wordpress.com/2025/12/15/gpt-5-2-is-frontier-only-for-the-frontier/",
            "publishedAt": "2025-12-15",
            "source": "TheZvi",
            "summary": "Here we go again, only a few weeks after GPT-5.1 and a few more weeks after 5.0. There weren\u2019t major safety concerns with GPT-5.2, so I\u2019ll start with capabilities, and only cover safety briefly starting with \u2018Model Card and Safety &#8230; <a href=\"https://thezvi.wordpress.com/2025/12/15/gpt-5-2-is-frontier-only-for-the-frontier/\">Continue reading <span class=\"meta-nav\">&#8594;</span></a>",
            "title": "GPT-5.2 Is Frontier Only For The Frontier"
        },
        {
            "content": [],
            "link": "https://xkcd.com/3181/",
            "publishedAt": "2025-12-15",
            "source": "XKCD",
            "summary": "<img alt=\"Earth's r_jf is approximately 1.5 light-days, leading to general relativity's successful prediction that all the frogs in the Solar System should be found collected on the surface of the Earth.\" src=\"https://imgs.xkcd.com/comics/jumping_frog_radius.png\" title=\"Earth's r_jf is approximately 1.5 light-days, leading to general relativity's successful prediction that all the frogs in the Solar System should be found collected on the surface of the Earth.\" />",
            "title": "Jumping Frog Radius"
        }
    ],
    "lookbackDays": 1,
    "publishDate": "2025-12-15"
}