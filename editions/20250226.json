{
    "articles": [
        {
            "content": [
                "<div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe657e070-6479-49fe-bb97-bf02b96f1a83_750x627.jpeg\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"627\" src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe657e070-6479-49fe-bb97-bf02b96f1a83_750x627.jpeg\" width=\"750\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a></figure></div><h6>High Tide (1972), Dorothea Tanning</h6><p></p><p>Some days, I want to cut to the chase around here and talk very directly about <em>what it takes to feel good.</em></p><p>Because the truth is that most of us overthink everything in maladaptive, unproductive ways. Our thoughts rarely lead to understanding or deeper connections or satisfaction or even arresting art. Yet we continue to &#8230;</p>\n      <p>\n          <a href=\"https://www.ask-polly.com/p/how-to-feel-good-right-now\">\n              Read more\n          </a>\n      </p>"
            ],
            "link": "https://www.ask-polly.com/p/how-to-feel-good-right-now",
            "publishedAt": "2025-02-26",
            "source": "Ask Polly",
            "summary": "<div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe657e070-6479-49fe-bb97-bf02b96f1a83_750x627.jpeg\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"627\" src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe657e070-6479-49fe-bb97-bf02b96f1a83_750x627.jpeg\" width=\"750\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a></figure></div><h6>High Tide (1972), Dorothea Tanning</h6><p></p><p>Some days, I want to cut to the chase around here and talk very directly about <em>what it takes to feel good.</em></p><p>Because the truth is that most of us overthink everything in maladaptive, unproductive ways. Our thoughts rarely lead to understanding or deeper connections or satisfaction or even arresting art. Yet we continue to &#8230;</p> <p> <a href=\"https://www.ask-polly.com/p/how-to-feel-good-right-now\"> Read more </a> </p>",
            "title": "How to Feel Good Right Now"
        },
        {
            "content": [
                "<div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faaafb4c6-d192-450a-87c8-58b5b4d47f15_750x626.jpeg\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"626\" src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faaafb4c6-d192-450a-87c8-58b5b4d47f15_750x626.jpeg\" width=\"750\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a></figure></div><h6>Merrillium trovatum (1997), Dorothea Tanning</h6><p></p><p>Today I have an essay called <a href=\"https://www.nytimes.com/2025/02/22/style/the-perfect-girl-next-door.html\">The Perfect Girl Next Door</a> in The New York Times. It&#8217;s about comparing yourself to beautiful, successful people and feeling so indignant about how relatively mediocre, soggy, and listless you are that you start to resent them in spite of your best intentions.</p><p>What was inspiring about the girl next door was that she was always incredibly nice to me. She was living a life that looked completely out of reach to me for reasons ranging from <em>bad skin</em> to <em>shitty attitude</em> to <em>habit of avoiding challenging social and career scenarios in order to remain smug about my bad personality</em> <em>in private, </em>yet she was consistently friendly and open. </p><p>When I met her, I was pretty isolated. I had just moved to LA with my boyfriend and I worked from home writing a cartoon for the website Suck.com. I enjoyed my shitty attitude at the time. It made me money, even as it prevented me from joining the real world and learning to get along with the ambitious people around me. My cartoon was very popular among computer programmers, IT guys, and early inhabitants of the internet, most of whom lived in San Francisco and New York, but it meant absolutely nothing to the people of Los Angeles. When the girl next door asked me what I did for a living &#8212; everyone in LA would ask this within a second of meeting you back then, generally in order to figure out if you were worth talking to or not &#8212; I told her about my internet cartoon and she said, &#8220;Oh, I don&#8217;t know anything about computers.&#8221; </p><p>&#8220;Computers are appliances now,&#8221; I said. &#8220;You just plug them in and read things.&#8221;</p><p>&#8220;I&#8217;m not good with that stuff.&#8221;</p><p>I had disdain for this attitude mostly because it meant that I wouldn&#8217;t matter to 99% of the people I met in LA until I turned my cartoon into an animated show on Comedy Central, and that would require flat-ironing my hair and then leaving the house to talk to other people with flat-ironed hair.</p><p>I have some regrets. I regret not learning to flat-iron my hair without overthinking what it meant &#8212; what I saw as all of the staggering negative implications of becoming someone who looked and sounded pretty and shiny and upbeat. I wanted to be my grumbly, disheveled self out in the world and I wanted people to love me for it. </p><p>Being stubborn about trivial things is sometimes a way of protecting yourself from acknowledging far more important things that you want but can&#8217;t admit to wanting. If I had more compassion for myself, I would&#8217;ve figured out that what I wanted very badly was to be understood, to be seen clearly, to be recognized as a loving person in spite of my resting bitch face. But I didn&#8217;t respect my own core needs &#8212; I was raised to ignore and ridicule my core needs, quite honestly; that&#8217;s just how my people do it &#8212; so I couldn&#8217;t stop inflating the importance of absolutely trivial irritations and superficial obstacles. </p><p>Shame was driving the bus. But that&#8217;s kind of the hipster virus, isn&#8217;t it? You take tiny pet peeves and minuscule verbal tics and minor style infractions and you add them up into big excuses as to why you can&#8217;t befriend someone, why you&#8217;d never fit in somewhere, why you should never have to try something that you truly WANT to try. You protect yourself from the world by telling yourself that the world is too uncool for you.</p><p>Of course, nothing is cooler than understanding that nothing is really cool at all. People&#8217;s hearts and actions are everything, and their minds and words often don&#8217;t add up to much by comparison. I&#8217;m not trying to be anti-intellectual, I&#8217;m just talking about the struggle to form a real relationship with yourself that includes a deep respect for your own particular needs. Once you respect and understand and honor yourself, it&#8217;s far easier to show your true self, to ask for understanding from others, and to give it to others.</p><p>Shame is the enemy. As long as you&#8217;re locked in a bad habit of refusing to examine your core desires, you tend to tell dramatic stories about the corrupt desires of others. Understanding and respecting yourself is brave and makes you more compassionate toward others. The girl next door manifested this. Moreover, daring to create exactly what you want out in the real world takes guts. And when you can manage to do it while staying principled, kind, and open-minded? That&#8217;s rare. </p><p>I know I beat this drum often, but my central aim with this column is to give everyone who reads it the courage and determination to be yourselves out in the open and to create what you want out in the real world, which begins by respecting and honoring your principles and your core desires. </p><p>But that doesn&#8217;t mean I&#8217;m condemning the complainer on the couch I once was AND STILL AM. I would change a lot of things about how I approached the outside world back when I was in my twenties, but I wouldn&#8217;t change my flinty attitude, my grumbly, soft-pants lifestyle, or my conviction that my moody, half-growling, half-ebullient self was special and deserved to be embraced and loved for who she was. When I look back, I feel much less shame over who I was than I did at the time. I&#8217;m proud that I didn&#8217;t work hard to change who I was, just for the sake of mattering.</p><p>The real challenge &#8212; a lifelong challenge &#8212; is to care less about mattering. Mattering doesn&#8217;t bring you peace. Understanding what matters does.</p><p>What matters is the voice inside you that speaks to you when you&#8217;re relaxed, when you&#8217;re open, when you can love darkness as much as you love joy, when you feel grateful for everything the world brings you, including pain and frustration and heartache. That voice wants to say to you: Look at how funny this day is. Look at how ridiculous you are. Look at how hard you work, just to keep yourself afloat. You deserve to be honored. You deserve to be loved. Love yourself and spread that love to everyone around you. This world needs more love. Give yours freely.</p><div><hr /></div><p><em>Thanks for reading Ask Polly! Molly has some shit to say, too, so <a href=\"https://askmolly.substack.com/p/dry-52f\">check her out here</a>. If you&#8217;re still confused about the difference between Polly, Molly, and &#8220;Heather Havrilesky,&#8221; read <a href=\"https://askmolly.substack.com/p/origins\">this</a>. Polly publishes 1-2x a week for paid subscribers so:</em></p><p class=\"button-wrapper\"><a class=\"button primary\" href=\"https://www.ask-polly.com/subscribe\"><span>Subscribe now</span></a></p><p class=\"button-wrapper\"><a class=\"button primary\" href=\"https://www.ask-polly.com/p/the-perfect-girl-next-door?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share\"><span>Share</span></a></p><h6>Send letters to askpolly@protonmail.com. Free subscriptions available to those who are financially struggling, so just ask. </h6>"
            ],
            "link": "https://www.ask-polly.com/p/the-perfect-girl-next-door",
            "publishedAt": "2025-02-23",
            "source": "Ask Polly",
            "summary": "<div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faaafb4c6-d192-450a-87c8-58b5b4d47f15_750x626.jpeg\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"626\" src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faaafb4c6-d192-450a-87c8-58b5b4d47f15_750x626.jpeg\" width=\"750\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a></figure></div><h6>Merrillium trovatum (1997), Dorothea Tanning</h6><p></p><p>Today I have an essay called <a href=\"https://www.nytimes.com/2025/02/22/style/the-perfect-girl-next-door.html\">The Perfect Girl Next Door</a> in The New York Times. It&#8217;s about comparing yourself to beautiful, successful people and feeling so indignant about how relatively mediocre, soggy, and listless you are that you start to resent them in spite of your best intentions.</p><p>What was inspiring about the girl next door was that she was always incredibly nice to me. She was living a life that looked completely out of reach to me for reasons ranging from <em>bad skin</em> to <em>shitty attitude</em>",
            "title": "The Perfect Girl Next Door"
        },
        {
            "content": [
                "<div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F102ce7da-147d-4f85-8ab5-04e74bb6ac61_974x1276.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"1276\" src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F102ce7da-147d-4f85-8ab5-04e74bb6ac61_974x1276.png\" width=\"974\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a></figure></div><h6>Untitled (2019), Flora Yukhnovich</h6><p></p><p><em>A note to all paid subscribers: THANK YOU FOR YOUR SUPPORT! I feel so grateful for you this morning. I also want to warn you that this column is very long, but the core challenges outlined here are so common that I wanted to get very granular about how to navigate them. The main takeaway is that shame and neuroticism can&#8230;</em></p>\n      <p>\n          <a href=\"https://www.ask-polly.com/p/im-a-mess-and-i-cant-fix-it\">\n              Read more\n          </a>\n      </p>"
            ],
            "link": "https://www.ask-polly.com/p/im-a-mess-and-i-cant-fix-it",
            "publishedAt": "2025-02-20",
            "source": "Ask Polly",
            "summary": "<div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F102ce7da-147d-4f85-8ab5-04e74bb6ac61_974x1276.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"1276\" src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F102ce7da-147d-4f85-8ab5-04e74bb6ac61_974x1276.png\" width=\"974\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a></figure></div><h6>Untitled (2019), Flora Yukhnovich</h6><p></p><p><em>A note to all paid subscribers: THANK YOU FOR YOUR SUPPORT! I feel so grateful for you this morning. I also want to warn you that this column is very long, but the core challenges outlined here are so common that I wanted to get very granular about how to navigate them. The main takeaway is that shame and neuroticism can&#8230;</em></p> <p> <a href=\"https://www.ask-polly.com/p/im-a-mess-and-i-cant-fix-it\"> Read more </a> </p>",
            "title": "'I'm a Mess And I Can't Fix It!'"
        },
        {
            "content": [
                "<div class=\"trix-content\">\n  <div>One of the key roles The New York Times plays in American society is as guardians of the liberal <a href=\"https://en.wikipedia.org/wiki/Overton_window\">Overton window</a>. Its editorial line sets the terms for what's permissible to discuss in polite circles on the center left. Whether it's <a href=\"https://www.nytimes.com/2023/02/21/opinion/do-mask-mandates-work.html\">covid mask efficiency</a>, <a href=\"https://www.nytimes.com/2024/02/02/opinion/transgender-children-gender-dysphoria.html\">trans kids</a>, or, now, <a href=\"https://www.nytimes.com/2025/02/24/magazine/denmark-immigration-policy-progressives.html\">mass immigration</a>. When The New York Times allows the counter argument to liberal orthodoxy to be published, it signals to its readers that it's time to pivot.&nbsp;</div><div><br />On mass immigration, the center-left liberal orthodoxy has for the last decade in particular been that this is an unreserved good. It's cultural enrichment! It's much-needed workers! It's a humanitarian imperative! Any opposition was treated as de-facto racism, and the idea that a country would enforce its own borders as evidence of early fascism. But that era is coming to a close, and The New York Times is using <a href=\"https://www.nytimes.com/2025/02/24/magazine/denmark-immigration-policy-progressives.html\">The Danish Permission</a> to prepare its readers for the end.<br /><br /></div><div>As I've often argued, Denmark is an incredibly effective case study in such arguments, because it's commonly thought of as the holy land of progressivism. Free college, free health care, amazing public transit, obsessive about bikes, and a solid social safety net. It's basically everything people on the center left ever thought they wanted from government. In theory, at least.<br /><br /></div><div>In practice, all these government-funded benefits come with a host of trade-offs that many upper middle-class Americans (the primary demographic for The New York Times) would find difficult to swallow. But I've covered that in detail in <a href=\"https://world.hey.com/dhh/the-reality-of-the-danish-fairytale-78069fbf\">The reality of the Danish fairytale</a>, so I won't repeat that here.<br /><br /></div><div>Instead, let's focus on the fact that The New York Times is now begrudgingly admitting that the main reason Europe has turned to the right, in election after election recently, is due to the problems stemming from mass immigration across the continent and the channel.</div><div><br />For example, here's a bit about immigrant crime being higher:<br /><br /></div><blockquote><em>Crime and welfare were also flashpoints: Crime rates were substantially higher among immigrants than among native Danes, and employment rates were much lower, government data showed.</em></blockquote><div><br /></div><div>It wasn't long ago that recognizing higher crime rates among <a href=\"https://migrant-integration.ec.europa.eu/news/denmark-new-statistics-category-migrants-muslim-countries_en\">MENAPT immigrants</a> to Europe was seen as a racist dog whistle. And every excuse imaginable was leveled at the undeniable statistics showing that immigrants from countries like Tunisia, Lebanon, and Somalia are <a href=\"https://x.com/dhh/status/1884153318320009431\">committing violent crime at rates 7-9 times higher</a> than ethnic Danes (and that these statistics are essentially the same in <a href=\"https://x.com/RMistereggen/status/1889246613895328155\">Norway</a> and <a href=\"https://x.com/visegrad24/status/1890164105744703908\">Finland</a> too).</div><div><br />Or how about this one: Recognizing that many immigrants from certain regions were loafing on the welfare state in ways that really irked the natives:</div><div><br /></div><blockquote><em>One source of frustration was the fact that unemployed immigrants sometimes received resettlement payments that made their welfare benefits larger than those of unemployed Danes.</em></blockquote><div><br /></div><div>Or the explicit acceptance that a strong social welfare state requires a homogeneous culture in order to sustain the trust needed for its support:</div><div><br /></div><blockquote><em>Academic research has documented that societies with more immigration tend to have lower levels of social trust and less generous government benefits. Many social scientists believe </em><a href=\"https://scholar.harvard.edu/files/glaeser/files/why_doesnt_the_u.s._have_a_european-style_welfare_state.pdf\"><em>this relationship</em></a><em> is one reason that the United States, which accepted large numbers of immigrants long before Europe did, has a weaker safety net. </em><a href=\"https://www.economist.com/free-exchange/2006/10/26/diversity-or-the-welfare-state-choose-one\"><em>A 2006 headline</em></a><em> in the British publication The Economist tartly summarized the conclusion from this research as, \u201cDiversity or the welfare state: Choose one.\u201d</em></blockquote><div><br /></div><div>Diversity or welfare! That again would have been an absolutely explosive claim to make not all that long ago.</div><div><br />Finally, there's the acceptance that cultural incompatibility, such as on the role of women in society, is indeed a problem:<br /><br /></div><blockquote><em>Gender dynamics became a flash point: Danes see themselves as pioneers for equality, while many new arrivals came from traditional Muslim societies where women often did not work outside the home and girls could not always decide when and whom to marry.</em></blockquote><div><br /></div><div>It took a while, but The New York Times is now recognizing that immigrants from some regions really do commit vastly more violent crime, are <a href=\"https://x.com/jonatanpallesen/status/1884172509446127814\">net-negative contributors</a> to the state budgets (by drawing benefits at higher rates and being unemployed more often), and that together with the cultural incompatibilities, end up undermining public trust in the shared social safety net.&nbsp;<br /><br /></div><div class=\"attachment-gallery attachment-gallery--2\">\n    <figure class=\"attachment attachment--preview attachment--lightboxable attachment--jpeg\">\n      <a href=\"https://world.hey.com/dhh/e7484a14/blobs/BAh7BkkiC19yYWlscwY6BkVUewdJIglkYXRhBjsAVGwrB690hXhJIghwdXIGOwBUSSIMYmxvYl9pZAY7AEY=--95ec338448cc79264941d398d8e00f077dc972c5/violent-crime-by-origin-in-denmark.jpeg?disposition=attachment\" title=\"Download violent-crime-by-origin-in-denmark.jpeg\">\n        <img alt=\"violent-crime-by-origin-in-denmark.jpeg\" src=\"https://world.hey.com/dhh/e7484a14/representations/BAh7BkkiC19yYWlscwY6BkVUewdJIglkYXRhBjsAVGwrB690hXhJIghwdXIGOwBUSSIMYmxvYl9pZAY7AEY=--95ec338448cc79264941d398d8e00f077dc972c5/BAh7BkkiC19yYWlscwY6BkVUewdJIglkYXRhBjsAVHsKOgtmb3JtYXRJIglqcGVnBjsAVDoUcmVzaXplX3RvX2xpbWl0WwdpAiADaQJYAjoMcXVhbGl0eWlLOgtsb2FkZXJ7BjoJcGFnZTA6DWNvYWxlc2NlVEkiCHB1cgY7AFRJIg52YXJpYXRpb24GOwBG--f75e0724347ce13005718aad28ef2a3ac057efef/violent-crime-by-origin-in-denmark.jpeg\" />\n</a>\n  </figure>  <figure class=\"attachment attachment--preview attachment--lightboxable attachment--png\">\n      <a href=\"https://world.hey.com/dhh/e7484a14/blobs/BAh7BkkiC19yYWlscwY6BkVUewdJIglkYXRhBjsAVGwrB650hXhJIghwdXIGOwBUSSIMYmxvYl9pZAY7AEY=--871663e0f866d293a1ffb2fa849fa71ce2d8d64d/net-contribution-immigrants-denmark.png?disposition=attachment\" title=\"Download net-contribution-immigrants-denmark.png\">\n        <img alt=\"net-contribution-immigrants-denmark.png\" src=\"https://world.hey.com/dhh/e7484a14/representations/BAh7BkkiC19yYWlscwY6BkVUewdJIglkYXRhBjsAVGwrB650hXhJIghwdXIGOwBUSSIMYmxvYl9pZAY7AEY=--871663e0f866d293a1ffb2fa849fa71ce2d8d64d/BAh7BkkiC19yYWlscwY6BkVUewdJIglkYXRhBjsAVHsKOgtmb3JtYXRJIghwbmcGOwBUOhRyZXNpemVfdG9fbGltaXRbB2kCIANpAlgCOgxxdWFsaXR5aUs6C2xvYWRlcnsGOglwYWdlMDoNY29hbGVzY2VUSSIIcHVyBjsAVEkiDnZhcmlhdGlvbgY7AEY=--d241df7a3873f9cc9b3de89d4c95181f2531e2bc/net-contribution-immigrants-denmark.png\" />\n</a>\n  </figure>\n</div><div>The consequence of this admission is dawning not only on The New York Times, but also on other liberal entities around Europe:</div><div><br /></div><blockquote><em>Tellingly, the response in Sweden and Germany has also shifted... Today many Swedes look enviously at their neighbor. The foreign-born population in Sweden has soared, and the country is struggling to integrate recent arrivals into society. Sweden now has the highest rate of gun homicides in the European Union, with immigrants committing a disproportionate share of gun violence. After an outburst of gang violence in 2023, Ulf Kristersson, the center-right prime minister, gave a televised address </em><a href=\"https://www.government.se/speeches/2023/09/prime-minister-ulf-kristerssons-address-to-the-nation/\"><em>in which he blamed</em></a><em> \u201cirresponsible immigration policy\u201d and \u201cpolitical na\u00efvet\u00e9.\u201d Sweden\u2019s center-left party has likewise turned more restrictionist.</em></blockquote><div><br /></div><div>All these arguments are in service of the article's primary thesis: To win back power, the left, in Europe and America, must pivot on mass immigration, like the Danes did. Because only by doing so are they able to counter the threat of \"the far right\".</div><div><br />The piece does a reasonable job accounting for the history of this evolution in Danish politics, except for the fact that it leaves out the main protagonist. The entire account is written from the self-serving perspective of the Danish Social Democrats, and it shows. It tells a tale of how it was actually Social Democrat mayors who first spotted the problems, and well, it just took a while for the top of the party to correct. Bullshit.<br /><br /></div><div>The real reason the Danes took this turn is that \"the far right\" won in Denmark, and The Danish People's Party deserve the lion's share of the credit. They started in 1995, quickly set the agenda on mass immigration, and by 2015, they were the second largest party in the Danish parliament.&nbsp;<br /><br /></div><div>Does that story ring familiar? It should. Because it's basically what's been happening in Sweden, France, Germany, and the UK lately. The mainstream parties have ignored the grave concerns about mass immigration from its electorate, and only when \"the far right\" surged as a result, did the center left and right parties grow interested in changing course.</div><div><br />Now on some level, this is just democracy at work. But it's also hilarious that this process, where voters choose parties that champion the causes they care about, has been labeled The Grave Threat to Democracy in recent years. Whether it's Trump, Le Pen, Weidel, or Kj\u00e6rsgaard, they've all been met with contempt or worse for channeling legitimate voter concerns about immigration.</div><div><br />I think this is the point that's sinking in at The New York Times. Opposition to mass immigration and <a href=\"https://world.hey.com/dhh/failed-integration-and-the-fall-of-multiculturalism-77296314\">multi-culturalism</a> in Europe isn't likely to go away. The mayhem that's <a href=\"https://www.gisreportsonline.com/r/sweden-immigrants-crisis/\">swallowing Sweden</a> is a reality too obvious to ignore. And as long as the center left keeps refusing to engage with the topic honestly, and instead hides behind some <a href=\"https://www.nytimes.com/2025/02/23/world/europe/germany-election-firewall-afd.html\">anti-democratic firewall</a>, they're going to continue to lose terrain.<br /><br /></div><div>Again, this is how democracies are supposed to work! If your political class is out of step with the mood of the populace, they're supposed to lose. And this is what's broadly happening now. And I think that's why we're getting this New York Times pivot. Because losing sucks, and if you're on the center left, you'd like to see that end.</div>\n</div>"
            ],
            "link": "https://world.hey.com/dhh/the-new-york-times-gives-liberals-the-danish-permission-to-pivot-on-mass-immigration-e7484a14",
            "publishedAt": "2025-02-26",
            "source": "DHH",
            "summary": "<div class=\"trix-content\"> <div>One of the key roles The New York Times plays in American society is as guardians of the liberal <a href=\"https://en.wikipedia.org/wiki/Overton_window\">Overton window</a>. Its editorial line sets the terms for what's permissible to discuss in polite circles on the center left. Whether it's <a href=\"https://www.nytimes.com/2023/02/21/opinion/do-mask-mandates-work.html\">covid mask efficiency</a>, <a href=\"https://www.nytimes.com/2024/02/02/opinion/transgender-children-gender-dysphoria.html\">trans kids</a>, or, now, <a href=\"https://www.nytimes.com/2025/02/24/magazine/denmark-immigration-policy-progressives.html\">mass immigration</a>. When The New York Times allows the counter argument to liberal orthodoxy to be published, it signals to its readers that it's time to pivot.&nbsp;</div><div><br />On mass immigration, the center-left liberal orthodoxy has for the last decade in particular been that this is an unreserved good. It's cultural enrichment! It's much-needed workers! It's a humanitarian imperative! Any opposition was treated as de-facto racism, and the idea that a country would enforce its own borders as evidence of early fascism. But that era is coming to a close, and The New York Times is using <a href=\"https://www.nytimes.com/2025/02/24/magazine/denmark-immigration-policy-progressives.html\">The Danish Permission</a> to prepare its readers for the end.<br /><br /></div><div>As I've often argued, Denmark is an incredibly effective case study in such arguments, because it's commonly thought of as the holy land of progressivism. Free college, free health care, amazing public transit, obsessive about bikes, and a",
            "title": "The New York Times gives liberals The Danish Permission to pivot on mass immigration"
        },
        {
            "content": [
                "<div class=\"trix-content\">\n  <div>One of the biggest mistakes that new startup founders make is trying to get away from the customer-facing roles too early. Whether it's customer support or it's sales, it's an incredible advantage to have the founders doing that work directly, and for much longer than they find comfortable.</div><div><br /></div><div>The absolute worst thing you can do is hire a sales person or a customer service agent too early. You'll miss all the golden nuggets that customers throw at you for free when they're rejecting your pitch or complaining about the product. Seeing these reasons paraphrased or summarized destroy all the nutrients in their insights. You want that whole-grain feedback straight from the customers' mouth!&nbsp;</div><div><br /></div><div>When we launched <a href=\"https://basecamp.com/\">Basecamp</a> in 2004, Jason was doing all the customer service himself. And he kept doing it like that for three years!! By the time we hired our first customer service agent, Jason was doing 150 emails/day. The business was doing millions of dollars in ARR. And Basecamp got infinitely, better both as a market proposition and as a product, because Jason could funnel all that feedback into decisions and positioning.</div><div><br /></div><div>For a long time after that, we did \"Everyone on Support\". Frequently rotating programmers, designers, and founders through a day of answering emails directly to customers. The dividends of doing this were almost as high as having Jason run it all in the early years. We fixed an incredible number of minor niggles and annoying bugs because programmers found it easier to solve the problem than to apologize for why it was there.</div><div><br /></div><div>It's not easy doing this! Customers often offer their valuable insights wrapped in rude language, unreasonable demands, and bad suggestions. That's why many founders quit the business of dealing with them at the first opportunity. That's why few companies ever do \"Everyone On Support\". That's why there's such eagerness to reduce support to an AI-only interaction.</div><div><br /></div><div>But quitting dealing with customers early, not just in support but also in sales, is an incredible handicap for any startup. You don't have to do everything that every customer demands of you, but you should certainly listen to them. And you can't listen well if the sound is being muffled by early layers of indirection.</div>\n</div>"
            ],
            "link": "https://world.hey.com/dhh/stick-with-the-customer-4942402f",
            "publishedAt": "2025-02-21",
            "source": "DHH",
            "summary": "<div class=\"trix-content\"> <div>One of the biggest mistakes that new startup founders make is trying to get away from the customer-facing roles too early. Whether it's customer support or it's sales, it's an incredible advantage to have the founders doing that work directly, and for much longer than they find comfortable.</div><div><br /></div><div>The absolute worst thing you can do is hire a sales person or a customer service agent too early. You'll miss all the golden nuggets that customers throw at you for free when they're rejecting your pitch or complaining about the product. Seeing these reasons paraphrased or summarized destroy all the nutrients in their insights. You want that whole-grain feedback straight from the customers' mouth!&nbsp;</div><div><br /></div><div>When we launched <a href=\"https://basecamp.com/\">Basecamp</a> in 2004, Jason was doing all the customer service himself. And he kept doing it like that for three years!! By the time we hired our first customer service agent, Jason was doing 150 emails/day. The business was doing millions of dollars in ARR. And Basecamp got infinitely, better both as a market proposition and as a product, because Jason could funnel all that feedback into decisions and positioning.</div><div><br /></div><div>For a long time after that, we did \"Everyone on Support\".",
            "title": "Stick with the customer"
        },
        {
            "content": [
                "<div class=\"trix-content\">\n  <div>Most of our cultural virtues, celebrated heroes, and catchy slogans align with the idea of \"never give up\". That's a good default! Most people are inclined to give up too easily, as soon as the going gets hard. But it's also worth remembering that sometimes you really should fold, admit defeat, and accept that your plan didn't work out.</div><div><br />But how to distinguish between a bad plan and insufficient effort? It's not easy. Plenty of plans look foolish at first glance, especially to people without skin in the game. That's the essence of a disruptive startup: The idea ought to look a bit daft at first glance or it probably doesn't carry the counter-intuitive kernel needed to really pop.<br /><br /></div><div>Yet it's also obviously true that not every daft idea holds the potential to be a disruptive startup. That's why even the best venture capital investors in the world are wrong far more than they're right. Not because they aren't smart, but because nobody is smart enough to predict (the disruption of) the future consistently. The best they can do is make long bets, and then hope enough of them pay off to fund the ones that don't.<br /><br /></div><div>So far, so logical, so conventional. A million words have been written by a million VCs about how their shrewd eyes let them see those hidden disruptive kernels before anyone else could. Good for them.<br /><br /></div><div>What I'm more interested in knowing more about is how and when you pivot from a promising bet to folding your hand. When do you accept that no amount of additional effort is going to get that turkey to soar?<br /><br /></div><div>I'm asking because I don't have any great heuristics here, and I'd really like to know! Because the ability to fold your hand, and live to play your remaining chips another day, isn't just about startups. It's also about individual projects. It's about work methods. Hell, it's even about politics and societies at large.</div><div><br />I'll give you just one small example. In 2017, Rails 5.1 shipped with new tooling for doing <a href=\"https://guides.rubyonrails.org/testing.html#system-testing\">end-to-end system tests</a>, using a headless browser to validate the functionality, as a user would in their own browser. Since then, we've spent an enormous amount of time and effort trying to make this approach work. Far too much time, <a href=\"https://world.hey.com/dhh/system-tests-have-failed-d90af718\">if you ask me now</a>.</div><div><br />This year, we finished our decision to fold, and to give up on using these types of system tests on the scale we had previously thought made sense. In fact, <a href=\"https://x.com/dhh/status/1892265453524803859\">just last week</a>, we deleted 5,000 lines of code from the <a href=\"https://basecamp.com/\">Basecamp</a> code base by dropping literally all the system tests that we had carried so diligently for all these years.<br /><br /></div><div>I really like this example, because it draws parallels to investing and entrepreneurship so well. The problem with our approach to system tests wasn't that it didn't work at all. If that had been the case, bailing on the approach would have been a no brainer long ago. The trouble was that it sorta-kinda did work! Some of the time. With great effort. But ultimately wasn't worth the squeeze.<br /><br /></div><div>I've seen this trap snap on startups time and again. The idea finds some traction. Enough for the founders to muddle through for years and years. Stuck with an idea that sorta-kinda does work, but not well enough to be worth a decade of their life. That's a tragic trap.<br /><br /></div><div>The only antidote I've found to this on the development side is time boxing. Programmers are just as liable as anyone to believe a flawed design can work if given just a bit more time. And then a bit more. And then just double of what we've already spent. The time box provides a hard stop. In <a href=\"https://basecamp.com/shapeup\">Shape Up</a>, it's <a href=\"https://basecamp.com/shapeup/0.3-chapter-01#six-week-cycles\">six weeks</a>. Do or die. Ship or don't. That works.<br /><br /></div><div>But what's the right amount of time to give a startup or a methodology or a societal policy? There's obviously no universal answer, but I'd argue that whatever the answer, it's \"less than you think, less than you want\".</div><div><br />Having the grit to stick with the effort when the going gets hard is a key trait of successful people. But having the humility to give up on good bets turned bad might be just as important.</div>\n</div>"
            ],
            "link": "https://world.hey.com/dhh/when-to-give-up-1dd951f9",
            "publishedAt": "2025-02-20",
            "source": "DHH",
            "summary": "<div class=\"trix-content\"> <div>Most of our cultural virtues, celebrated heroes, and catchy slogans align with the idea of \"never give up\". That's a good default! Most people are inclined to give up too easily, as soon as the going gets hard. But it's also worth remembering that sometimes you really should fold, admit defeat, and accept that your plan didn't work out.</div><div><br />But how to distinguish between a bad plan and insufficient effort? It's not easy. Plenty of plans look foolish at first glance, especially to people without skin in the game. That's the essence of a disruptive startup: The idea ought to look a bit daft at first glance or it probably doesn't carry the counter-intuitive kernel needed to really pop.<br /><br /></div><div>Yet it's also obviously true that not every daft idea holds the potential to be a disruptive startup. That's why even the best venture capital investors in the world are wrong far more than they're right. Not because they aren't smart, but because nobody is smart enough to predict (the disruption of) the future consistently. The best they can do is make long bets, and then hope enough of them pay off to fund the ones that don't.<br",
            "title": "When to give up"
        },
        {
            "content": [
                "<p>GLP-1 drugs are a miracle for diabetes and obesity. There are rumors that they might <em>also</em> be a miracle for addiction to alcohol, drugs, nicotine, and gambling. That would be good. We like miracles. But we just got the first good trial and\u2014despite what you might have heard\u2014it\u2019s not very encouraging.</p>\n\n<p>Semaglutide\u2014aka Wegovy / Ozempic\u2014is a <a href=\"https://en.wikipedia.org/wiki/GLP-1_receptor_agonist\">GLP-1 agonist</a>. This means it binds to the same receptors the <a href=\"https://en.wikipedia.org/wiki/Glucagon-like_peptide-1\">glucagon-like peptide-1</a> hormone normally binds to. Similar drugs include <a href=\"https://en.wikipedia.org/wiki/Dulaglutide\">dulaglutide</a>, <a href=\"https://en.wikipedia.org/wiki/Exenatide\">exenatide</a>, <a href=\"https://en.wikipedia.org/wiki/Liraglutide\">liraglutide</a>, <a href=\"https://en.wikipedia.org/wiki/Lixisenatide\">lixisenatide</a>, and <a href=\"https://en.wikipedia.org/wiki/Tirzepatide\">tirzepatide</a>. These were originally investigated for diabetes, on the theory that GLP-1 increases insulin and thus decreases blood sugar. But GLP-1 seems to have <em>lots</em> of other effects, like preventing glucose from entering the bloodstream, slowing digestion, and making you feel full longer. It was found to cause sharp decreases in body mass, which is why supposedly <a href=\"https://www.kff.org/health-costs/poll-finding/kff-health-tracking-poll-may-2024-the-publics-use-and-views-of-glp-1-drugs/\"><em>12%</em></a> of Americans had tried one of these drugs by mid 2024.</p>\n\n<p>(I\u2019m skeptical that of that 12% number, but a <a href=\"https://www.pwc.com/us/en/services/consulting/business-model-reinvention/glp-1-trends-and-impact-on-business-models.html\">different survey</a> in late 2024 found that 10% of Americans were <em>currently</em> taking one of these drugs. I know Americans take more drugs than anyone on the planet, but still\u2026)</p>\n\n<p>Anyway, there are vast reports from people taking these drugs that they help with various addictions. <em>Many</em> people report stopping drinking or smoking without even trying. This is plausible enough. We don\u2019t know which of the many effects of these drugs is really helping with obesity. Maybe it\u2019s not the effects on blood sugar that matter, but these drugs have some kind of generalized \u201canti-addiction\u201d effect on the brain? Or maybe screwing around with blood sugar changes willpower? Or maybe when people get thinner, that changes how the brain works? Who knows.</p>\n\n<p>Beyond anecdotes, there are some observational studies and animal experiments suggesting they might help with addiction <a href=\"https://doi.org/10.1016/j.pcad.2024.12.010\" title=\"Persistent link using digital object identifier\">(OKeefe et al. 2024)</a>. We are so desperate for data that some researchers have even resorted to computing statistics based on <a href=\"https://pmc.ncbi.nlm.nih.gov/articles/PMC10846600/\">what people say on reddit</a>.</p>\n\n<p>So while it seems <em>plausible</em> these drugs might help with other addictions, there\u2019s limited data and no clear story for why this <em>should</em> happen biologically. This makes the <a href=\"https://doi.org/10.1001/jamapsychiatry.2024.4789\">first RCT</a>, which came out last week, <em>very</em> interesting.</p>\n\n<p><img alt=\"Once-Weekly Semaglutide in Adults With Alcohol Use Disorder: A Randomized Clinical Trial\" src=\"https://dynomight.net/img/glp-1/title_big.svg\" /></p>\n\n<p>This paper contains this figure, about which everyone is going crazy:</p>\n\n<p><img alt=\"\" src=\"https://dynomight.net/img/glp-1/hype_big.svg\" /></p>\n\n<p>I admit this looks good. This is indeed a figure in which the orange bar is higher than the blue bar. However:</p>\n\n<ol>\n  <li>\n    <p>This figure does not mean what you think it means. Despite the label, this isn\u2019t actually the amount of alcohol people consumed. What\u2019s shown is the result of a <em>regression</em>, which was calculated on a non-random subset of subjects.</p>\n  </li>\n  <li>\n    <p>There are other figures. Why isn\u2019t anyone talking about the other figures?</p>\n  </li>\n</ol>\n\n<h2 id=\"what-they-did\">What they did</h2>\n\n<p>This trial gathered 48 participants. They selected them according to the DSM-5 definition of \u201calcohol use disorder\u201d which happens to be more than 14 drinks per week for men and 7 drinks per week for women, plus at least 2 heavy drinking episodes. Perhaps because of this lower threshold, 34 of the subjects were women.</p>\n\n<p>The trial lasted 9 weeks. During it, half of the subjects were given weekly placebo injections. The other half were given weekly injections of increasing amounts of semaglutide: 0.25 mg for 4 weeks, then 0.5 mg for 4 weeks, and then 0.5 or 1 mg in the last week, depending on a doctor\u2019s judgement.</p>\n\n<h2 id=\"outcome-1-drinking\">Outcome 1: Drinking</h2>\n\n<p>The first outcome was to simply ask people to record how much they drank in daily life. Here are the results:</p>\n\n<p><img alt=\"\" src=\"https://dynomight.net/img/glp-1/sem1big.svg\" /></p>\n\n<p>If I understand correctly, at some point 6 out of the 24 subjects in the placebo group stopped providing these records, and 3 out of 24 in the semaglutide group. I believe the above shows the data for whatever subset of people were still cooperating on each week. It\u2019s not clear to me what bias this might produce.</p>\n\n<p>When I first saw that figure, I thought it looked good. The lines are going down, and the semaglutide line is lower. But then I checked the appendix. (Protip: <em>Always</em> check the appendix.) This contains the same data, but stratified by if people were obese or not:</p>\n\n<p><img alt=\"\" src=\"https://dynomight.net/img/glp-1/sem3.png\" /></p>\n\n<p>Now it looks like semaglutide isn\u2019t doing anything. It\u2019s just that among the non-obese, the semaglutide group happened to start at a lower baseline.</p>\n\n<p>How to reconcile this with the earlier figure? Well, if you look carefully, it doesn\u2019t really show any benefit to semaglutide either. There\u2019s a difference in the two curves, but it was there from the beginning. Over time, there\u2019s no <em>difference</em> in the difference, which is what we\u2019d expect to see if semaglutide was helping.</p>\n\n<p>The paper provides other measurements like \u201cchanges in drinking days\u201d and \u201cchanges in heavy drinking days\u201d and \u201cchanges in drinks per drinking day\u201d, but it\u2019s the same story: Either no benefit or no difference.</p>\n\n<p>So\u2026 This is a small sample. It only lasted nine weeks, and subjects spent many of them on pretty small doses. But this is far the miracle we hoped for. Some effect might be hiding in the noise, but what these results <em>most</em> look like is <em>zero</em> effect.</p>\n\n<h2 id=\"outcome-2-delayed-drinking\">Outcome 2: Delayed drinking</h2>\n\n<p>There are also lab experiments. They did these at both the start and end of the study. In the first experiment, they basically set each subject\u2019s favorite alcoholic drink in front of them and said them, \u201cFor each minute you wait before drinking this, we will pay you, up to a maximum of 50 minutes.\u201d</p>\n\n<p>How <em>much</em> were they paid, you ask? Oddly, that\u2019s not specified in the paper. It\u2019s also not specified in the supplemental information. It\u2019s <em>also</em> not specified in the <a href=\"https://pmc.ncbi.nlm.nih.gov/articles/instance/11822619/bin/jamapsychiatry-e244789-s001.pdf\">289 page application</a> they made to the FDA to be able to do this study. (Good times!) But there is a citation for a <a href=\"https://doi.org/10.1016/j.dadr.2022.100085\">different paper</a> in which people were paid $0.24/minute, decreasing by $0.01/minute every five minutes. If they used the same amounts here, then the maximum subjects could earn was $9.75.</p>\n\n<p>Anyway, here are the results:</p>\n\n<p><img alt=\"\" src=\"https://dynomight.net/img/glp-1/delay.png\" /></p>\n\n<p>So\u2026 basically nothing? Because almost everyone waited the full 50 minutes? And they did this for only $9.75? Seems weird.</p>\n\n<p>I don\u2019t really see this as evidence <em>against</em> semaglutide. Rather, I think this didn\u2019t end up proving much in either direction.</p>\n\n<h2 id=\"outcome-3-laboratory-drinking\">Outcome 3: Laboratory drinking</h2>\n\n<p>So what\u2019s with that initial figure? Well, after the delayed drinking experiment was over, the subjects were given 2 hours to drink as much as they wanted, up to some kind of safe limit. This is what led to the figure everyone is so excited about:</p>\n\n<p><img alt=\"\" src=\"https://dynomight.net/img/glp-1/hype_big.svg\" /></p>\n\n<p>When I first saw this, I too thought it looked good. I thought it looked <em>so</em> good that I started writing this post, eager to share the good news. But at some point I read the caption more carefully and my Spidey sense started tingling.</p>\n\n<p><img alt=\"\" src=\"https://dynomight.net/img/glp-1/caption.png\" /></p>\n\n<p>There\u2019s two issues here. First of all, subjects were free to skip this part of the experiment, and a lot did. Only 12 of the 24 subjects in the placebo group and 13 of 24 in the semaglutide group actually did it. This means the results are <em>non-randomized</em>.</p>\n\n<p>I mean, the people who declined to do this experiment would probably have drunk different amounts than those who agreed, right? So if semaglutide had any influence on people decision\u2019s to participate (e.g. because it changed their relationship with alcohol, which is the hypothesis of this research) then the results would be biased. That bias could potentially go in either direction. But this means we\u2019re sort of working with observational data.</p>\n\n<p>The second issue is that what\u2019s being show in this plot is <strong>not data</strong>. I know it <em>looks</em> like data, but what\u2019s shown are <strong>numbers derived from regression coefficients</strong>. In the appendix, you can find this table:</p>\n\n<p><img alt=\"regression table\" src=\"https://dynomight.net/img/glp-1/regression_big.svg\" /></p>\n\n<p>Basically, they fit a regression to predict how much people drank in this experiment at the end of the study (\u201cg-EtOH\u201d) based on (a) how much they drank during the same experiment at the <em>start</em> of the study (\u201cBaseline\u201d) (b) their sex, and (c) if they got semaglutide or not (\u201cCondition\u201d). Those coefficients are in the <em>B</em> column.</p>\n\n<p>How exactly they got from these coefficients to the numbers in the figure isn\u2019t entirely clear to me. But using a <a href=\"https://plotdigitizer.com/app\">plot digitizer</a> I found that the figure shows ~56.9 g for the placebo group and ~33.3 g for the semaglutide group, for a difference of ~23.6 g. I believe that difference comes from the regression coefficient for \u201cCondition\u201d (-25.32) plus some adjustments for the fact that sex and baseline consumption vary a bit between the two groups.</p>\n\n<p>So\u2026 that\u2019s not nothing! This is <em>some</em> evidence in favor of semaglutide being helpful. But it\u2019s still basically just a regression coefficient computed on a non-randomized sample. Which is sad, since the point of RCTs is to avoid resorting to regression coefficients on non-randomized samples. Thus, I put much more faith in outcome #1.</p>\n\n<h2 id=\"discussion\">Discussion</h2>\n\n<p>To summarize, the most reliable outcome of this paper was how much people reported drinking in daily life. No effect was observed there. The laboratory experiment suggests some effect, but the evidence is much weaker. When you combine the two, the results of this paper are quite bad, at least relative to my (high) hopes.</p>\n\n<p>Obviously, just because the <em>results</em> are disappointing does not mean the research was bad. The measure of science is the importance of the questions, not what the answers happen to be. It\u2019s unfortunate that a non-randomized sample participated in the final drinking experiment, but what were they supposed to do, force them? This experiment involved giving a synthetic hormone and an addictive substance with people with a use disorder. If you have any doubts about the amount of work necessary to bring that to reality, I <em>strongly</em> encourage you to look at the <a href=\"https://pmc.ncbi.nlm.nih.gov/articles/instance/11822619/bin/jamapsychiatry-e244789-s001.pdf\">FDA application</a>.</p>\n\n<p>OK, fine, I admit that I do feel this paper \u201chides the bodies\u201d slightly too effectively, in a way that could mislead people who aren\u2019t experts or that don\u2019t read the paper carefully. I think I\u2019m on firm ground with that complaint, since in the discussions I\u2019ve seen, 100% of people <em>were</em> in fact misled. But I\u2019m sympathetic to the reality that most reviewers don\u2019t share my enlightened views about judging science, and that a hypothetical paper written with my level of skepticism would never be published.</p>\n\n<p>(People think the problem with science is that it\u2019s too woke. While I don\u2019t really disagree, I still think the bigger problem is screwed up incentives that force <em>everyone</em> oversell <em>everything</em>, because that\u2019s what you have to do to survive. But that\u2019s a story for another time.)</p>\n\n<p>Anyway, despite these results, I\u2019m still hopeful that GLP-1 drugs might help with addiction. This is a relatively small study, and it only lasted 9 weeks. I don\u2019t think we can dismiss the huge number of anecdotes yet. And the laboratory experiment was at least a little promising. Given how destructive addictions can be, I vote for more research in this direction. Fortunately, given the billions of dollars to be made, that\u2019s sure to happen.</p>\n\n<p>But given just how miraculous semaglutide is for obesity, and given the miraculous <em>anecdotes</em>, I don\u2019t see how to spin this paper as anything but a letdown. It provides weak evidence for any effect and comes close to <em>excluding</em> the possibility of another miracle. If you\u2019ve forgotten what miracles look like, here is the figure for body weight:</p>\n\n<p><img alt=\"\" src=\"https://dynomight.net/img/glp-1/sem2big.svg\" /></p>"
            ],
            "link": "https://dynomight.net/glp-1/",
            "publishedAt": "2025-02-20",
            "source": "Dynomight",
            "summary": "<p>GLP-1 drugs are a miracle for diabetes and obesity. There are rumors that they might <em>also</em> be a miracle for addiction to alcohol, drugs, nicotine, and gambling. That would be good. We like miracles. But we just got the first good trial and\u2014despite what you might have heard\u2014it\u2019s not very encouraging.</p> <p>Semaglutide\u2014aka Wegovy / Ozempic\u2014is a <a href=\"https://en.wikipedia.org/wiki/GLP-1_receptor_agonist\">GLP-1 agonist</a>. This means it binds to the same receptors the <a href=\"https://en.wikipedia.org/wiki/Glucagon-like_peptide-1\">glucagon-like peptide-1</a> hormone normally binds to. Similar drugs include <a href=\"https://en.wikipedia.org/wiki/Dulaglutide\">dulaglutide</a>, <a href=\"https://en.wikipedia.org/wiki/Exenatide\">exenatide</a>, <a href=\"https://en.wikipedia.org/wiki/Liraglutide\">liraglutide</a>, <a href=\"https://en.wikipedia.org/wiki/Lixisenatide\">lixisenatide</a>, and <a href=\"https://en.wikipedia.org/wiki/Tirzepatide\">tirzepatide</a>. These were originally investigated for diabetes, on the theory that GLP-1 increases insulin and thus decreases blood sugar. But GLP-1 seems to have <em>lots</em> of other effects, like preventing glucose from entering the bloodstream, slowing digestion, and making you feel full longer. It was found to cause sharp decreases in body mass, which is why supposedly <a href=\"https://www.kff.org/health-costs/poll-finding/kff-health-tracking-poll-may-2024-the-publics-use-and-views-of-glp-1-drugs/\"><em>12%</em></a> of Americans had tried one of these drugs by mid 2024.</p> <p>(I\u2019m skeptical that of that 12% number, but a <a href=\"https://www.pwc.com/us/en/services/consulting/business-model-reinvention/glp-1-trends-and-impact-on-business-models.html\">different survey</a> in late 2024 found that 10% of Americans were <em>currently</em> taking one of these drugs. I know Americans take more drugs than anyone on the planet, but still\u2026)</p> <p>Anyway, there",
            "title": "The first RCT for GLP-1 drugs and alcoholism isn\u2019t what we hoped"
        },
        {
            "content": [
                "<p><em>Note: After publishing this piece, I was contacted by Anthropic who told me that Sonnet 3.7 would not be considered a 10^26 FLOP model and cost a few tens of millions of dollars to train, though future models will be much bigger. I updated the post with that information. The only significant change is that Claude 3 is now referred to as an advanced model but not a Gen3 model.</em></p><p>I have been experimenting with the first of a new generation AI models, Claude 3.7 and Grok 3, for the last few days. Grok 3 is the first model that we know trained with an order of magnitude more computing power of GPT-4, and Claude includes new coding and reasoning capabilities, so they are not just interesting in their own right but also tell us something important about where AI is going.</p><p>Before we get there, a quick review: this new generation of AIs is smarter and the jump in capabilities is striking, particularly in how these models handle complex tasks, math and code. These models often give me the same feeling I had when using ChatGPT-4 for the first time, where I am equally impressed and a little unnerved by what it can do. Take Claude's native coding ability, I can now get working programs through natural conversation or documents, no programming skill needed.</p><p>For example, giving Claude a proposal for a new AI educational tool and engaging in conversation where it was asked to &#8220;<em>display the proposed system architecture in 3D, make it interactive</em>,&#8221; resulted in this interactive visualization of the core design in our paper, with no errors. <a href=\"https://claude.site/artifacts/eaa80b41-cf48-44cf-ab6b-86f9f66319f5\">You can try it yourself here</a>, and edit or change it by asking the AI. The graphics, while neat, are not the impressive part. Instead, it was that Claude decided to turn this into a step-by-step demo to explain the concepts, which wasn&#8217;t something that it was asked to do. This anticipation of needs and consideration of new angles of approach is something new in AI.</p><div class=\"native-video-embed\"></div><p>Or, for a more playful example, I told Claude &#8220;<em>make me an interactive time machine artifact, let me travel back in time and interesting things happen. pick unusual times I can go back to&#8230;</em>&#8221; and <em>&#8220;add more graphics.&#8221;</em> What emerged after just those two prompts was a fully functional interactive experience, complete with crude but charming pixel graphics (which are actually surprisingly <a href=\"https://arxiv.org/abs/2303.12712\">impressive</a>- the AI has to 'draw' these using pure code, without being able to see what it's creating, like an artist painting blindfolded but still getting the picture right). </p><div class=\"native-video-embed\"></div><p>To be clear, these systems are far from perfect and make mistakes, but they are getting much better, and fast. To understand where things are and where they are going, </p><h1>The Two Scaling Laws</h1><p>Though they may not look it, these may be the two most important graphs in AI. Published by OpenAI, they show the two &#8220;Scaling Laws,&#8221; which tell you how to increase the ability of the AI to answer hard questions, in this case to score more highly on the famously difficult American Invitational Mathematics Examination (AIME). </p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb6b1e7d7-6bd1-4f33-9c30-db9929f9dc24_1980x1113.webp\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"316.3008241758242\" src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb6b1e7d7-6bd1-4f33-9c30-db9929f9dc24_1980x1113.webp\" width=\"563\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a></figure></div><p>The left-hand graph is the training Scaling Law. It shows that larger models are more capable. Training these larger models requires increasing the amount of computing power, data, and energy used, and you need to do so on a grand scale. Typically, you need a 10x increase in computing power to get a linear increase in performance. Computing power is measured in <em>FLOPs</em> (Floating Point Operations) which are the number of basic mathematical operations, like addition or multiplication, that a computer performs, giving us a way to quantify the computational work done during AI training<strong>.</strong></p><p>We are now seeing the first models of a new generation of AIs, trained with over 10x the computing power of GPT-4 and its many competitors. These models use over 10^26 FLOPS of computing power in training. This is a staggering amount of computing power, equivalent to running a modern smartphone for 634,000 years or the Apollo Guidance Computer that took humans to the moon for 79 trillion years. Naming 10^26 is awkward, though - it is one hundred septillion FLOPS, or, taking a little liberty with standard unit names, a HectoyottaFLOP. So, you can see why I just call them Gen3 models, the first set of AIs that were trained with an order of magnitude more computing power than GPT-4 (Gen2).</p><p>xAI, Elon Musk's AI company, made the first public move into Gen3 territory with Grok 3, which is unsurprising given their strategy. xAI is betting big on the idea that bigger (way bigger) is better. xAI built the world&#8217;s largest computer cluster in record time, and that meant Grok 3 was the first AI model to show us whether the Scaling Law would hold up for a new generation of AI. It seems that it did, as Grok 3 had the highest benchmark scores we've seen from any base model. Today, Claude 3.7 was released, though not yet a Gen3 model, it also shows substantial improvements in performance over previous AIs. While it is similar in benchmarks to Grok 3, I personally find it more clever for my use cases, but you may find otherwise. The still unreleased o3 from OpenAI also seems to be a Gen3 model, with excellent performance. It is likely this is just the beginning - more companies are gearing up to launch their own models at this scale, including Anthropic.</p><p>You might have noticed I haven&#8217;t yet mentioned the second graph, the one on the right. While the first Scaling Law is about throwing massive computing power at training (basically, building a smarter AI from the start), this second one revealed something surprising: you can make AI perform better simply by giving it more time to think. OpenAI discovered that if you let a model spend more computing power working through a problem (what they call test-time or inference-time compute), it gets better results - kind of like giving a smart person a few extra minutes to solve a puzzle. This second Scaling Law led to the creation of Reasoners, <a href=\"https://www.oneusefulthing.org/p/the-end-of-search-the-beginning-of\">which I wrote about in my last post</a>. The new generation of Gen3 models will all operate as Reasoners when needed, so they have two advantages: larger scale in training, and the ability to scale when actually solving a problem.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2\" href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7f8509e2-5b0c-408b-8298-eb23387f3738_3095x773.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"364\" src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7f8509e2-5b0c-408b-8298-eb23387f3738_3095x773.png\" width=\"1456\" /><div></div></div></a><figcaption class=\"image-caption\">An example of three different models using reasoning</figcaption></figure></div><p>Together, these two trends are supercharging AI abilities, and also adding others. If you have a large, smart AI model, that can be used to create smaller, faster, cheaper models that are still quite smart, if not as much as their parent. And if you add Reasoner capabilities to even small models, they get even smarter. What that means is that AI abilities are getting better even as costs are dropping. This graph shows how quickly this trend has advanced, mapping the capability of AI on the y axis and the logarithmically decreasing costs on the x axis. When GPT-4 came out it was around $50 per million tokens (roughly a word), now it costs around 12 cents per million tokens to use Gemini 1.5 Flash, an even more capable model than the original GPT-4.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb41b2794-aa4a-428a-9af9-a602af8a73f1_1744x1106.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"923\" src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb41b2794-aa4a-428a-9af9-a602af8a73f1_1744x1106.png\" width=\"1456\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a><figcaption class=\"image-caption\">The Graduate-Level Google-Proof Q&amp;A test (GPQA) is a series of very hard multiple-choice problems designed to test advanced knowledge. PhDs with access to the internet get 34% right on this test outside their specialty, 81% inside their specialty. The cost per million tokens is the cost of using the model (Gemini Flash Thinking Costs are estimated). Data based on my research, but <a href=\"https://epoch.ai/data/ai-benchmarking-dashboard\">Epoch </a>and <a href=\"https://artificialanalysis.ai/leaderboards/models\">Artificial Analysis</a> were good sources, and <a href=\"https://www.latent.space/p/reasoning-price-war\">Latent Space </a>offers its own more comprehensive graph of costs across many models.</figcaption></figure></div><p>You can see the intelligence of models is increasing, and their cost is decreasing over time. That has some pretty big implications for all of us.</p><h1>Taking Scale Seriously</h1><p>A lot of the focus on AI use, especially in the corporate world, has been stuck in what I call the &#8220;automation mindset&#8221; - viewing AI primarily as a tool for speeding up existing workflows like email management and meeting transcription. This perspective made sense for earlier AI models, but it's like evaluating a smartphone solely on its ability to make phone calls. The Gen3 generation give the opportunity for a fundamental rethinking of what's possible.</p><p>As models get better, and as they apply more tricks like reasoning and internet access, they hallucinate less (though they still make mistakes) and they are capable of higher order &#8220;thinking.&#8221; For example, in this case we gave Claude a <a href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4871171\">24 page academic paper</a> outlining a new way of creating teaching games with AI, along with some unrelated instruction manuals for other games. We asked the AI to use those examples and write a customer-friendly guide for a game based on our academic paper. The results were extremely high-quality. To do this, the AI needed to both abstract out the ideas in the paper, and the patterns and approaches from other instruction manuals, and build something entirely new. This would have been a week of PhD-level work, done in a few seconds. And, on the right, you can also see an excerpt from another PhD-level task, reading a complex academic paper and checking the math and logic, as well as the implications for practice.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F289c8320-2223-4b77-8065-c1f4265f2449_1758x813.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"673\" src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F289c8320-2223-4b77-8065-c1f4265f2449_1758x813.png\" width=\"1456\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a></figure></div><p>Managers and leaders will need to update their beliefs for what AI can do, and how well it can do it, given these new AI models. Rather than assuming they can only do low-level work, we will need to consider the ways in which AI can serve as a genuine intellectual partner. These models can now tackle complex analytical tasks, creative work, and even research-level problems with surprising sophistication. The examples I've shared - from creating interactive 3D visualizations of academic concepts to performing PhD-level analysis - demonstrate that we're moving beyond simple automation into the realm of AI-powered knowledge work. These systems are still far from flawless, nor do they beat human experts consistently across a wide range of tasks, but they are very impressive.</p><p>This shift has profound implications for how organizations should approach AI integration. First, the focus needs to move from task automation to capability augmentation. Instead of asking \"what tasks can we automate?\" leaders should ask \"what new capabilities can we unlock?\" And they will need to build the capacity in their own organizations to help explore, and develop these changes.</p><p>Second, the rapid improvement in both capabilities and cost efficiency means that any static strategy for AI implementation will quickly become outdated. Organizations need to develop dynamic approaches that can evolve as these models continue to advance. Going all-in on a particular model today is not a good plan in a world where both Scaling Laws are operating.</p><p>Finally, and perhaps most importantly, we need to rethink how we measure and value AI contributions. The traditional metrics of time saved or costs reduced may miss the more transformative impacts of these systems - their ability to generate novel insights, synthesize complex information, and enable new forms of problem-solving. Moving too quickly to concrete KPIs, and leaving behind exploration, will blind companies to what is possible. Worse, they encourage companies to think of AI as a replacement for human labor, rather than exploring ways in which human work can be boosted by AI.</p><h1>Exploring for Yourself</h1><p>With that serious warning out of the way, I want to leave you with a suggestion. These new models are clever, but they are also friendly and more engaging to use. They are likely to ask you questions or push your thinking in new directions, and tend to be good at two-way conversation. The best way to understand their capabilities, then, is to explore them yourself. <a href=\"https://claude.ai/new\">Claude 3.7</a> is available for paying customers and has a neat feature where it can run the code it writes for you, as you have seen throughout this post. It <a href=\"https://privacy.anthropic.com/en/articles/10023555-how-do-you-use-personal-data-in-model-training\">does not train on your uploaded data</a>. <a href=\"https://grok.com/?referrer=website\">Grok 3</a> is free and has a wider range of features, including a good Deep Research option, but is harder for amateurs to use for coding. It is not as good as Claude 3.7 for the tasks I have tried, but the Xai commitment to scaling means it will improve rapidly. You should also note that Grok does train on your data, but that can be turned off for paying customers.</p><p>Regardless of what model you pick, you should experiment. Ask the model to code something for you by just asking for it (I asked Claude for a video game with unique mechanics based on the Herman Melville story &#8220;<a href=\"https://en.wikipedia.org/wiki/Bartleby,_the_Scrivener\">Bartleby the Scrivner</a>&#8221; - and it did so based on a single prompt), feed it a document and ask it for an infographic summary, or ask it to comment on an image you upload. If this is too playful, follow the advice in my <a href=\"https://a.co/d/cx7TVWI\">book </a>and just use it for work tasks, taking into account the privacy caveat above. Use it to brainstorm new ideas, ask it how a news article or analyst report might affect your business, or ask it to create a financial dashboard for a new product or startup concept. You will likely find cases that amaze you, and others where the new models are not yet good enough to be helpful.</p><div class=\"native-video-embed\"></div><p>The limitations of these models remain very real, but the fact that Gen3 AIs are better than Gen2, due to both the first and second Scaling Law shows us something essential. These laws aren't fundamental constants of the universe - they're observations about what happens when you throw massive resources at AI development. The computing power keeps growing, the capabilities keep improving, and this cycle accelerates with each generation. As long as they continue to hold, AIs will keep getting better. Now we know that the next generation of AIs will continue to offer rapid improvements, suggesting that there is a good chance that AI capabilities may continue to increase into the future.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2\" href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F521759cd-fb8e-4622-b49d-1a26af8c62c6_1376x864.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"156.97674418604652\" src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F521759cd-fb8e-4622-b49d-1a26af8c62c6_1376x864.png\" width=\"250\" /><div></div></div></a></figure></div><p class=\"button-wrapper\"><a class=\"button primary\" href=\"https://www.oneusefulthing.org/subscribe\"><span>Subscribe now</span></a></p><p class=\"button-wrapper\"><a class=\"button primary\" href=\"https://www.oneusefulthing.org/p/a-new-generation-of-ais-claude-37?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share\"><span>Share</span></a></p>"
            ],
            "link": "https://www.oneusefulthing.org/p/a-new-generation-of-ais-claude-37",
            "publishedAt": "2025-02-24",
            "source": "Ethan Mollick",
            "summary": "<p><em>Note: After publishing this piece, I was contacted by Anthropic who told me that Sonnet 3.7 would not be considered a 10^26 FLOP model and cost a few tens of millions of dollars to train, though future models will be much bigger. I updated the post with that information. The only significant change is that Claude 3 is now referred to as an advanced model but not a Gen3 model.</em></p><p>I have been experimenting with the first of a new generation AI models, Claude 3.7 and Grok 3, for the last few days. Grok 3 is the first model that we know trained with an order of magnitude more computing power of GPT-4, and Claude includes new coding and reasoning capabilities, so they are not just interesting in their own right but also tell us something important about where AI is going.</p><p>Before we get there, a quick review: this new generation of AIs is smarter and the jump in capabilities is striking, particularly in how these models handle complex tasks, math and code. These models often give me the same feeling I had when using ChatGPT-4 for the first time, where I am equally impressed and a little unnerved by what",
            "title": "A new generation of AIs: Claude 3.7 and Grok 3"
        },
        {
            "content": [],
            "link": "https://olano.dev/blog/gleam-coming-from-erlang",
            "publishedAt": "2025-02-25",
            "source": "Facundo Olano",
            "summary": "I recently took some time to try Gleam, the type-safe language that runs on the Erlang virtual machine. For a couple of weeks, I used it to build a little feed aggregator. These are my notes.",
            "title": "Gleam, coming from Erlang"
        },
        {
            "content": [],
            "link": "https://harper.blog/notes/2025-02-23_f54125a430f3_i-love-this-post-from-dan-sink/",
            "publishedAt": "2025-02-24",
            "source": "Harper Reed",
            "summary": "<p>I love this post from Dan Sinker</p> <p><a href=\"https://dansinker.com/posts/2025-02-23-dale/\">dansinker.com/posts/202\u2026</a></p> <hr /> <p>Thank you for using RSS. I appreciate you. <a href=\"mailto:harper&#64;modest.com\">Email me</a></p>",
            "title": "Note #182"
        },
        {
            "content": [],
            "link": "https://harper.blog/notes/2025-02-23_cc3568b2664c_had-some-amazing-sushi-last-ni/",
            "publishedAt": "2025-02-23",
            "source": "Harper Reed",
            "summary": "<p>Had some amazing sushi last night at Shoji. Chef Shoji san is always amazing.</p> <figure> <img alt=\"image_1.jpg\" height=\"1800\" src=\"https://harper.blog/notes/2025-02-23_cc3568b2664c_had-some-amazing-sushi-last-ni/image_1.jpg\" width=\"1800\" /> </figure> <hr /> <p>Thank you for using RSS. I appreciate you. <a href=\"mailto:harper&#64;modest.com\">Email me</a></p>",
            "title": "Note #181"
        },
        {
            "content": [
                "<div class=\"trix-content\">\n  <div>In the end, judgment comes first. And that means hiring is a gut decision.<br /><br />As much science as people want to try to pour into the hiring process, art always floats to the top.<br /><br />This is especially true when hiring at the executive level. The people who make the final calls \u2014 the ones who are judged on outcome, not effort \u2014 are ultimately hired based on experience and judgement. Two traits that are qualities, not quantities.<br /><br />They are tasked with setting direction, evaluating situations, and making decisions with limited information. All day long they are making judgment calls. That's what you hire them to do, and that's how you decide who to hire.<br /><br />Presented with a few finalists, you decide who you *think* will do a better job when they have to *think* about what to do in uncertain situations. This is where their experience and judgment come in. It's the only thing they have that separates them from someone else.<br /><br />Embrace the situation. You don't know, they don't know, everyone's guessing, some guess better than others. You can't measure how well someone's going to guess next time, you can only make assumptions based on other assumptions. Certainty is a mirage. In the art of people, everything is subjective.<br /><br />In the end, it's not about qualifications \u2014 it's about who you trust to make the right call when it matters most. Ultimately, the only thing that was objective was your decision. The reasons were not.<br /><br /></div><div>-Jason</div>\n</div>"
            ],
            "link": "https://world.hey.com/jason/hiring-judgement-bcf7ff6f",
            "publishedAt": "2025-02-21",
            "source": "Jason Fried",
            "summary": "<div class=\"trix-content\"> <div>In the end, judgment comes first. And that means hiring is a gut decision.<br /><br />As much science as people want to try to pour into the hiring process, art always floats to the top.<br /><br />This is especially true when hiring at the executive level. The people who make the final calls \u2014 the ones who are judged on outcome, not effort \u2014 are ultimately hired based on experience and judgement. Two traits that are qualities, not quantities.<br /><br />They are tasked with setting direction, evaluating situations, and making decisions with limited information. All day long they are making judgment calls. That's what you hire them to do, and that's how you decide who to hire.<br /><br />Presented with a few finalists, you decide who you *think* will do a better job when they have to *think* about what to do in uncertain situations. This is where their experience and judgment come in. It's the only thing they have that separates them from someone else.<br /><br />Embrace the situation. You don't know, they don't know, everyone's guessing, some guess better than others. You can't measure how well someone's going to guess next time, you can only make",
            "title": "Hiring judgement"
        },
        {
            "content": [
                "<h3 id=\"revisiting-ai-doom-scenarios\"><strong>Revisiting AI Doom Scenarios</strong></h3> <p>Traditional AI doom scenarios usually assumed AI would inherently come with agency and goals. This seemed likely back when AlphaGo and other reinforcement learning (RL) systems were the most powerful AIs. When large language models (LLMs) finally brought powerful AI capabilities, these scenarios didn\u2019t quite fit: LLMs simply predict likely text continuations based on their training data, without pursuing any objectives of their own.</p> <p>But we are now starting to go back to our RL roots. Models like OpenAI\u2019s o1/o3 and Deepseek\u2019s R1 show that we have now entered the era. The classic doomsday example is the \u201cdrive over the baby\u201d scenario: You ask your robot for a cup of tea and the robot (who has been trained with RL to make tea as fast as possible) plows through a toddler in pursuit of optimizing for its goal - make tea fast. A robot trained without RL in a supervised manner (like LLMs next token prediction) would never do this because they have never seen a human do it.</p> <p>RL trained LLMs are still LLMs though - their output is natural text. Surely we could build systems to catch bad behaviour before they are acted upon? Unfortunately, it seems like the model\u2019s internal monologue will not be in English for much longer. Research results show that models become smarter if you don\u2019t constrain them to think in human interpretable languages.</p> <p>Being able to interpret the models\u2019 internal monologue seems extremely good for AI safety. So a question arises, should we make it illegal to develop models this way? That\u2019s the big question at the center of what I half-jokingly call \u201clinguistic imperialism in AI\u201d. And even if we want to, is it possible to enforce? Let\u2019s think about this step by step.</p> <h3 id=\"why-chain-of-thought\"><strong>Why Chain-of-Thought</strong></h3> <p>A year or two ago, researchers discovered that if you ask a large language model to \u201cthink step by step,\u201d it often yields better answers\u2014especially for math, logic, or any multi-step task. Instead of spitting out a quick guess, the model has an internal monologue where it can break the problem down into smaller pieces. This Chain-of-Thought (CoT) strategy worked so well on almost everything that the \u201cthink step by step\u201d prompt is put in the system prompt on models by default.</p> <p>The best part? It was all in English (or another natural language). You can skim the chain-of-thought and verify each line. That interpretability made us feel safe. If the model reasoned badly\u2014say, it cooked up a harmful plan or fell for a silly fallacy\u2014we could see it.</p> <h3 id=\"reinforcement-learning-in-llms\"><strong>Reinforcement Learning in LLMs</strong></h3> <p>Instead of passively \u201cmimicking humans\u201d via next token prediction, RL training tells the LLM to maximize some score. It has been shown that models trained this way change the behavior of their internal monologue in search for a higher score. For example, Deepseek R1 was trained this way to answer math questions correctly with RL. As the model was being trained, the CoT reasoning naturally grew. This suggests that the model found it advantageous to do more reasoning before giving the final answer.</p> <figure>  <source class=\"responsive-img-srcset\" /> <img class=\"img-fluid rounded z-depth-1\" height=\"auto\" src=\"https://lukaspetersson.github.io/assets/img/cot_len.png\" width=\"80%\" />  </figure> <h3 id=\"reward-hacking\"><strong>Reward Hacking</strong></h3> <p>This open-ended optimization often triggers reward hacking, a well-known phenomenon in simpler RL agents. Reward hacking is basically an agent\u2019s single-minded drive to \u201cplease\u201d a reward function without regard to consequences we never encoded. If the reward doesn\u2019t penalize stepping on babies, then the model might do this if it\u2019s \u201coptimal\u201d.</p> <p>It is very hard to foresee all possible side effects. A famous example is the boat-racing bot that, instead of trying to win the race, loops around a single corner, farming extra points. This is a silly example with no real consequences. However, OpenAI\u2019s Operator (an agent that browses the web) is reportedly also trained with RL.</p> <figure>  <source class=\"responsive-img-srcset\" /> <img class=\"img-fluid rounded z-depth-1\" height=\"auto\" src=\"https://lukaspetersson.github.io/assets/img/reward_boat.png\" width=\"70%\" />  </figure> <h3 id=\"interpretable-cot-to-the-rescue\"><strong>Interpretable CoT to the Rescue</strong></h3> <p>If powerful models (such as LLMs) are operating in environments with real consequences (such as the internet), reward hacking might be bad. However, the fact that we can read the models internal monologue might be a huge win for AI safety. By monitoring it, we might spot it plotting a malicious or manipulative strategy.</p> <p>But here is the problem: Human interpretable English is not the language of choice for AI models. The only reason they speak English is because we have trained it to mimic human text (which is in English). But with RL, the model is only incentivized to get the correct answer, and there is no reason why it should choose English in its internal monologue. Deepseek R1-zero showed this. It sometimes drifts into Chinese or random tokens in the middle of a chain-of-thought. Similarly, my friend sent me an image of when he used o1 and found a Russian word in the reasoning.</p> <figure>  <source class=\"responsive-img-srcset\" /> <img class=\"img-fluid rounded z-depth-1\" height=\"auto\" src=\"https://lukaspetersson.github.io/assets/img/russian_cot.png\" width=\"80%\" />  </figure> <h3 id=\"latent-space-cot\"><strong>Latent Space CoT</strong></h3> <p>In fact, we have direct evidence that forcing a model to articulate everything in plain English can degrade its reasoning power. Some steps are more efficiently computed in a cryptic or internal vector style. A prime example is <strong>Coconut (Chain of Continuous Thought)</strong> from Meta\u2019s research. Instead of writing out each reasoning step as text, the model keeps the intermediate steps in high-dimensional vectors. The final answer still appears in English, but the heavy-lifting is done in latents that humans can\u2019t read.</p> <p>Why do that? Because it\u2019s more efficient. Natural language is a messy bottleneck. You waste half your tokens on filler words like \u201cthe,\u201d \u201cand,\u201d \u201cso.\u201d Meanwhile, you might want to explore multiple lines of reasoning at once\u2014something that\u2019s clumsy in a strictly linear text chain. On certain logic tasks, Coconut outperforms a standard \u201ctext-based CoT\u201d because it can handle branching or backtracking more gracefully.</p> <p>Latent space reasoning always made sense from a theoretical perspective, and now it is shown to also work in practice. It is likely that this trend will continue. Researchers striving for personal glory will pick the method that will work the best, but this will be a big setback for safety. So maybe we should just ban models that reason in latent space. After all, there are many things we ban until they are proven to be safe.</p> <h3 id=\"unfaithful-cot-or-why-a-ban-might-not-even-work\"><strong>Unfaithful CoT: Or Why a Ban Might Not Even Work</strong></h3> <p>But even if we tried to make such a ban, it is not clear that it would be of any help. Models could start to \u201cspeak in code\u201d. The text they output in their internal monologue would be English, but the meaning would be different.</p> <p>Studies like \u201cLanguage Models Don\u2019t Always Say What They Think\u201d show that a model can produce a perfectly coherent explanation for why it chose an answer\u2014but under the hood, it was using an entirely different rationale.</p> <p>You can\u2019t truly police how a neural net reasons internally. You can only watch the final text. And a superintelligent system would have no trouble game-playing that. All this means that formalizing a ban on uninterpretable chain-of-thought is basically impossible. The model can always route its real thinking through latent space, or a hidden code language, or half a million carefully placed punctuation marks. If it wants to hide a step from you, it\u2019ll find a way.</p> <h3 id=\"if-we-could-ban-it-would-we\"><strong>If We Could Ban It, Would We?</strong></h3> <p>I am European, so I obviously love over-regulating stuff. In the perfect world where banning uninterpretable CoT reasoning, I would. We already ban or restrict certain unsafe technologies until they\u2019re proven safe. The FDA doesn\u2019t let you distribute a random drug until it passes trials. So there\u2019s precedent for telling an industry, \u201cNo, you can\u2019t do that until we\u2019re sure it\u2019s safe\u201d. But as we discussed, it is just not possible.</p> <p>Instead, maybe the best we can do is make interpretability the <em>preferred</em> choice, not the mandated one. Much as Tesla popularized electric cars without banning gasoline - people gravitated to EVs for performance, environmental benefits, and brand. Similarly, we could create compelling reasons why an \u201cinterpretable model\u201d is the superior product. Maybe big customers demand it for liability reasons. However, the roads are not filled with EVs, and we probably are not going to see all models making the interpretability trade offs.</p> <p>For now, AI models still think in English. The habits developed during next-token-prediction training outweigh the forces from RL training. I hope it stays that way, but I don\u2019t have much hope.</p> <p>Follow me on <a href=\"https://x.com/lukaspet\">X</a> or subscribe via <a href=\"https://lukaspetersson.com/feed.xml\">RSS</a> to stay updated.</p>"
            ],
            "link": "https://lukaspetersson.github.io/blog/2025/ban-ls-cot/",
            "publishedAt": "2025-02-21",
            "source": "Lukas Petersson",
            "summary": "Human interpretabe CoT is needed for AI safety. But models are starting to reason in latent space. Should we ban it?",
            "title": "Linguistic Imperialism in AI - Enforcing Human-Readable Chain-of-Thought"
        },
        {
            "content": [
                "<p>People who work in cryptography often talk about <strong><a href=\"https://newsletter.squishy.computer/p/trustless-protocols-are-better-than\">zero-trust protocols</a></strong>, but what they mean is: <strong>cryptography scales trust</strong>.</p><p>How? Practically speaking, cryptography lets us solve a bunch of thorny problems with trust, stuff like:</p><ul><li><p><strong>Authenticity</strong>: how do I know you are who you say you are? <strong><a href=\"https://newsletter.squishy.computer/p/llms-break-the-internet-signing-everything\">Cryptographic signatures</a></strong> use math to prove a message was signed with a particular cryptographic key. Signing makes messages<strong> <a href=\"https://en.wikipedia.org/wiki/Non-repudiation\">non-repudiable</a></strong>, meaning the author is provably the author. This holds true even if the message was sent from a computer or network that can&#8217;t be trusted.</p></li><li><p><strong>Privacy</strong>: how do I know only you can see it? <strong><a href=\"https://en.wikipedia.org/wiki/End-to-end_encryption\">End-to-end encryption</a></strong> (e2ee) encrypts data so that only the recipient who holds the key can decrypt it. To everyone else, it&#8217;s a black box that can&#8217;t be read or tampered with.</p></li><li><p><strong>Integrity</strong>: how do I know this is it what it says it is? Is this mp3 a song or a virus? <strong><a href=\"https://en.wikipedia.org/wiki/Cryptographic_hash_function\">Cryptographic hashing functions</a></strong> let us generate a hash, a string of numbers and letters, unique to the content. To verify the integrity of the file, we just check the hash. If the file has been tampered with, the hash won&#8217;t match.</p></li><li><p><strong>Proof-of-x:</strong> how do you show you&#8217;re human? Authorized to log on? Eligible to vote? <strong><a href=\"https://en.wikipedia.org/wiki/Zero-knowledge_proof\">ZK proofs</a></strong> let people cryptographically prove things <em>about</em> themselves without revealing their actual identity or information.</p></li><li><p><strong>Contracts</strong>: how do I know you&#8217;ll do what you say you&#8217;ll do? <strong><a href=\"https://en.wikipedia.org/wiki/Smart_contract\">Smart contracts</a></strong> deterministically execute agreements when conditions are met, preventing defection or cheating.</p></li></ul><p>These are just some examples. At the most abstract level, <strong>cryptography allows us to replace other forms of trust with trust in math</strong>. Or put another way,</p><blockquote><p>Cryptography is a tool for turning lots of different problems into key management problems.<br /><em>(Dr. Lea Kissner, Head of Privacy Eng and CISO at Twitter)</em></p></blockquote><p>We&#8217;ll get to that in a minute. Anyway, the trust isn&#8217;t eliminated. It just moves to a different part of the system, a part which can be scaled.</p><p>Take your bank website, for example. How do you know it&#8217;s legit? After all, the website had to hop through a lot of computers to get to you. What if one of them swapped out the real website for something else? A scam? Well, instead of trusting each computer that helped deliver the website, you trust the cryptographic key that was used to sign it. That little green lock in your browser? <a href=\"https://newsletter.squishy.computer/i/114076486/what-does-this-look-like-in-an-app\">That&#8217;s called SSL</a>.</p><p>It&#8217;s not clear how we could even establish trust on the internet without cryptography. To trust a message, I would have to trust every computer that touched the message as it bounced around the internet to me. Since internet routing is dynamic, I can&#8217;t even know who that might be ahead of time!</p><p>So, ordinary forms of trust, like reputational trust, <em>just taking your word for it</em>, cannot work at internet scale. But trusting a cryptographic key? That works! Cryptography scales trust.</p><h3>Clever hacks to scale trust</h3><p>Finding new ways to scale trust is a big deal. In a state of nature, our species lives <a href=\"https://newsletter.squishy.computer/p/dunbar-scale-social\">in small bands of 150 or less</a>, hunting, gathering, <a href=\"https://newsletter.squishy.computer/p/llms-and-hyper-orality\">sharing stories</a>, migrating from one place to another. Yet today, it is common to live in cities of a million or more. How did we end up here?</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd71e9aae-88e2-4f88-a95c-f5b1e6814dd6_2766x1198.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-large\" height=\"520.054945054945\" src=\"https://substackcdn.com/image/fetch/w_2400,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd71e9aae-88e2-4f88-a95c-f5b1e6814dd6_2766x1198.png\" width=\"1200\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a><figcaption class=\"image-caption\">From my <a href=\"https://newsletter.squishy.computer/p/noosphere-at-summer-of-protocols\">Summer of Protocols talk</a>, 2023</figcaption></figure></div><p>Well, one way to see our history is as a series of clever hacks to scale trust. Each unlocked new forms of cooperation, leading to new social structures. Researcher David Ronfeldt identifies at least four:</p><blockquote><p>How have people organized their societies across the ages? The answer may be reduced to four basic forms of organization,</p><ul><li><p>the kinship-based tribe, as denoted by the structure of extended families, clans, and other lineage systems.</p></li><li><p>the hierarchical institution, as exemplified by the army, the (Catholic) church, and ultimately the bureaucratic state.</p></li><li><p>the competitive-exchange market, as symbolized by merchants and traders responding to forces of supply and demand.</p></li><li><p>and the collaborative network, as found today in the web-like ties among some NGOs devoted to social advocacy</p></li></ul><p>(<em>Ronfeldt, 1996, &#8220;<a href=\"https://www.rand.org/content/dam/rand/pubs/papers/2005/P7967.pdf\">TIMN - Tribes, Institutions, Markets, Networks</a>&#8221;)</em></p></blockquote><p>We&#8217;re still <a href=\"https://newsletter.squishy.computer/p/thinking-together\">figuring out that fourth one</a>. Anyway, each of these social structures was catalyzed by a hack to scale trust:</p><p><strong>Language scaled trust</strong> by enabling <a href=\"https://newsletter.squishy.computer/p/dunbar-scale-social\">oral storytelling</a>, <a href=\"https://en.wikipedia.org/wiki/Genealogies_in_the_Bible\">the recitation of genealogies</a>, and the development of larger <a href=\"https://en.wikipedia.org/wiki/Kin_selection\">kinship networks</a>. I can trust you because my father&#8217;s father&#8217;s father is your father.</p><blockquote><p>One of the fascinating characteristics of lineages is that they can be aggregated upward into much larger superlineages simply by tracing descent back to an earlier ancestor. <em>(Fukuyama, 2011. <a href=\"https://en.wikipedia.org/wiki/The_Origins_of_Political_Order\">The Origins of Political Order</a>)</em></p></blockquote><p>Shared language lead to the accumulation of shared ideas, shared beliefs, shared gods. <strong><a href=\"https://press.princeton.edu/books/paperback/9780691169743/big-gods\">Belief in Big Gods scaled trust</a></strong> by expanding the scope of kin to include co-religionists. I can trust you, because we are brothers and sisters in the same god and share the same moral framework. Ideologies perform the same purpose.</p><blockquote><p>The ability to create mental models and to attribute causality to invisible abstractions is in turn the basis for the emergence of religion. <em>(Fukuyama, 2011)</em></p></blockquote><blockquote><p>If we had to constantly negotiate new rules with our fellow human beings at every turn, we would be paralyzed and unable to achieve routine collective action. The fact that we become attached to certain rules not as means to short-term goals but as ends in themselves greatly enhances the stability of social life. Religion simply reinforces that stability and widens the circle of potential cooperators.<br /><em>(Fukuyama, 2011)</em></p></blockquote><p><strong>Writing scaled trust</strong> by expanding the reach of Big Gods, and by enabling the emergence of durable hierarchical institutions. I can trust this because it was written down. It isn&#8217;t just hearsay. It is the word of god, etched in stone, or perhaps the word of an institutional authority, inked in papyrus, signed with an official seal.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F4142e8cd-02b2-495e-b084-dca51385bf18_750x598.jpeg\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"598\" src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F4142e8cd-02b2-495e-b084-dca51385bf18_750x598.jpeg\" width=\"750\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a><figcaption class=\"image-caption\"><a href=\"https://en.wikipedia.org/wiki/Lexical_lists\">Spreadsheets are Lindy</a>. Neo-Assyrian cuneiform tablet, 930-612 BCE.</figcaption></figure></div><p>Writing also meant math, and math lead to money. <strong>Money scaled trust</strong> by creating markets. I don&#8217;t have to trust you, I can trust <a href=\"https://en.wikipedia.org/wiki/Double-entry_bookkeeping\">double-entry bookkeeping</a> and the almighty dollar.</p><p>These are just a few of the tricks for scaling trust that allowed us to solve new and bigger coordination problems. More trust meant greater levels of cooperation, deeper specialization, more <a href=\"https://newsletter.squishy.computer/p/thinking-together\">social complexity</a>, larger economies of scale.</p><p>Of course, this specialization and hierarchy and complexity has its downsides. Sometimes modernity makes me want to <a href=\"https://i.kym-cdn.com/photos/images/original/001/867/677/40d.jpg\">return to monke</a>. Yet, it is difficult to outrun the economies of scale that come through scaling trust.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2\" href=\"https://www.instagram.com/marin_mushrooms/\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"Fairbanks Willkommlangea Reticulata\" class=\"sizing-normal\" height=\"545.272\" src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fee5ed30c-1ce9-4afa-9882-5f0ac98e761d_1000x749.jpeg\" title=\"Fairbanks Willkommlangea Reticulata\" width=\"728\" /><div></div></div></a><figcaption class=\"image-caption\">Willkommlangea reticulata by <a href=\"https://www.instagram.com/marin_mushrooms/\">Alison Pollack</a></figcaption></figure></div><p>So, tribes, institutions, markets. What about networks? I want to propose that,</p><p><strong>Cryptography scales trust</strong> by making it possible to build networks that only require trust at the the endpoints.</p><p>When the network is built on cryptographic protocols, <a href=\"https://newsletter.squishy.computer/p/trustless-protocols-are-better-than\">we don&#8217;t have to trust anything in-between</a>. We don&#8217;t have to trust the computers, the wires, the institutions, beliefs, or kinship of the network participants. We can trust the math. All we have to do is verify the message with cryptography.</p><p>This is a powerful primitive for scaling trust, because it means everyone on the network can cooperate together, even if they don&#8217;t trust each-other. The costs to producing high-trust results are greatly reduced, and we can spend our coordination efforts on building larger, more fine-grained, more complex networks of cooperation.</p><p>If language produced tribes, writing built institutions, money made markets, then perhaps cryptographic protocols will construct a <a href=\"https://en.wikipedia.org/wiki/Network_society\">network society</a>?</p><h3>The crypto archipelago</h3><p>In a <a href=\"https://en.wikipedia.org/wiki/High-trust_and_low-trust_societies\">high-trust society</a>, we might not often care about cryptography. In such a society, social protocols can take the place of cryptographic ones, and we can scale trust through means other than math: I trust in God, I trust Google, I trust government, I trust judges to rule with an even hand, I trust contracts, I trust institutions, I trust banks, and money I&#8217;m holding in my hand.</p><p>Nice work if you can get it. High social trust creates something like a <a href=\"https://en.wikipedia.org/wiki/The_Nature_of_the_Firm\">Coasean &#8220;firm&#8221;</a>, within which the costs of cooperation are greatly reduced. The higher the trust, the larger the Coasean space in which we can cheaply cooperate.</p><p>Does this look like a high-trust society?</p><p>The challenge is that we seem to be in the middle of some kind of social transition, <a href=\"https://newsletter.squishy.computer/p/thinking-together\">driven by the internet</a>. Old forms of trust are eroding, or getting <a href=\"https://newsletter.squishy.computer/i/79213755/weve-hit-an-information-scaling-threshold\">DDOS&#8217;d by the scale of the internet</a>. Social transitions are messy. </p><p>A new internet-scale paradigm, the cryptographic protocol, is in its nascent stages. But then new paradigms, by their very nature, question the logic of incumbent social structures which were designed around older forms of trust.</p><blockquote><p>All media work us over completely. They are so pervasive in their personal, political, economic, aesthetic, psychological, moral, ethical, and social consequences that they leave no part of us untouched, unaffected, unaltered.<br /><em>(Marshall McLuhan, 1967. The Medium is the Massage)</em></p></blockquote><p>The closest analog to this transition might be the introduction of the printing press in Europe. This transformed a world of feudal estates, knit together by religion, into a world of states, knit together by markets, communication networks, and scientific/democratic institutions. I like these changes a lot! But then they also induced <a href=\"https://en.wikipedia.org/wiki/European_wars_of_religion\">200 years of religious warfare</a>. Yikes.</p><p>So it might be the case that we find ourselves in a high-trust society that is experiencing rapid unbundling. Formerly functional institutions and shared social norms are fragmenting into pieces.</p><blockquote><p>When hierarchies break down, they usually split along their subsystem boundaries. <em>(Donella Meadows, Thinking in Systems)</em></p></blockquote><p>What we&#8217;re left with is the small remaining islands of functional high-trust&#8212;friends, family, maybe church, community, some local institutions&#8212;separated by growing oceans of distrust. Where to go from here?</p><p>Cryptography suggests a way forward: <strong>network</strong>.</p><p>Cryptographic protocols can act like undersea cables between islands of high-trust. We can span low-trust oceans because we only have to trust the endpoints. <a href=\"https://newsletter.squishy.computer/p/trustless-protocols-are-better-than\">Trustless networks</a> re-build trust on a new foundation, giving it new scaling properties. You don&#8217;t have to trust apps not to snoop, you can trust the end-to-end encryption. You don&#8217;t have to trust me to honor the contract, you can trust the <a href=\"https://en.wikipedia.org/wiki/Smart_contract\">smart contract</a> code. Parties with limited trust between can cooperate effectively together using protocols. The protocols knit them together into a functional network organization. </p><p>We could think of cryptographic protocols as a kind of <a href=\"https://newsletter.squishy.computer/p/protocols-as-weberian-bureaucracy\">software-defined Weberian routinization</a>, where protocols are to institutions as packet switching is to circuit switching.</p><h3>Queries</h3><p>I&#8217;m surrounded by smart readers, and so I would love your help in answering some of the questions I&#8217;ve been exploring:</p><ul><li><p>Who are the smartest people working in this space? Who is building new networked forms of coordination? Bonus for examples with fundamental needs in the loop&#8212;food, water, shelter, etc. Double bonus for <a href=\"https://kk.org/streetuse/\">street uses</a>, as in <em>&#8220;The street finds its own uses for things&#8221; (William Gibson)</em></p></li><li><p><em>&#8220;A good science fiction story should be able to predict not the automobile, but the traffic jam.\" (Frederik Pohl)</em> What traffic jams should we anticipate in the transition toward network society? Where could cryptographic protocols help? What traffic jams will protocols cause?</p></li><li><p>What are some other ways we&#8217;ve scaled trust? What was the transition like? Who&#8217;s studied this? What should I be reading?</p></li></ul><p>Reply to this email and let me know!</p>"
            ],
            "link": "https://newsletter.squishy.computer/p/cryptography-scales-trust",
            "publishedAt": "2025-02-25",
            "source": "Squishy Computer",
            "summary": "<p>People who work in cryptography often talk about <strong><a href=\"https://newsletter.squishy.computer/p/trustless-protocols-are-better-than\">zero-trust protocols</a></strong>, but what they mean is: <strong>cryptography scales trust</strong>.</p><p>How? Practically speaking, cryptography lets us solve a bunch of thorny problems with trust, stuff like:</p><ul><li><p><strong>Authenticity</strong>: how do I know you are who you say you are? <strong><a href=\"https://newsletter.squishy.computer/p/llms-break-the-internet-signing-everything\">Cryptographic signatures</a></strong> use math to prove a message was signed with a particular cryptographic key. Signing makes messages<strong> <a href=\"https://en.wikipedia.org/wiki/Non-repudiation\">non-repudiable</a></strong>, meaning the author is provably the author. This holds true even if the message was sent from a computer or network that can&#8217;t be trusted.</p></li><li><p><strong>Privacy</strong>: how do I know only you can see it? <strong><a href=\"https://en.wikipedia.org/wiki/End-to-end_encryption\">End-to-end encryption</a></strong> (e2ee) encrypts data so that only the recipient who holds the key can decrypt it. To everyone else, it&#8217;s a black box that can&#8217;t be read or tampered with.</p></li><li><p><strong>Integrity</strong>: how do I know this is it what it says it is? Is this mp3 a song or a virus? <strong><a href=\"https://en.wikipedia.org/wiki/Cryptographic_hash_function\">Cryptographic hashing functions</a></strong> let us generate a hash, a string of numbers and letters, unique to the content. To verify the integrity of the file, we just check the hash. If the file has been tampered with, the hash won&#8217;t match.</p></li><li><p><strong>Proof-of-x:</strong> how do you show you&#8217;re human?",
            "title": "Cryptography scales trust"
        }
    ],
    "lookbackDays": 7,
    "publishDate": "2025-02-26"
}