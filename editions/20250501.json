{
    "articles": [
        {
            "content": [
                "<p>Examples are good. Let\u2019s start with some examples:</p>\n\n<ol>\n  <li>\n    <p>We all need kidneys, or at least one kidney. Donating a kidney sucks, but having zero working kidneys <em>really</em> sucks. Paying people for kidneys would increase the number available, but it seems gross to pay people for part of their body. Donating a kidney is low-risk, but not <em>zero</em> risk. If you pay for kidneys, the extra kidneys tend to come from poorer people. So we don\u2019t pay, and every day people die for lack of a kidney.</p>\n  </li>\n  <li>\n    <p>Except for Iran. Yes, in <a href=\"https://en.wikipedia.org/wiki/Kidney_trade_in_Iran\">Iran</a> you can legally buy or sell a kidney for a few thousand dollars. There is no waiting list for transplants, but most sellers seem driven by desperation and overall it doesn\u2019t sound <a href=\"https://www.iranintl.com/en/202403289088\">super awesome</a>.</p>\n  </li>\n  <li>\n    <p>We all need a heart. Paying someone for their heart would mean paying for suicide. If we were to auction off hearts from organ donors, they would tend to go to rich people. People die every day from lack of a heart, but you don\u2019t hear much about trading hearts for money.</p>\n  </li>\n  <li>\n    <p>Many people need blood plasma. For some people (me) donating blood plasma is a psychological nightmare. For other people it\u2019s fine. Not getting plasma when you need it is very bad. Paying people for plasma means more plasma, mostly from low-income people. Much of Europe has long prohibited paying for plasma. Denmark and Italy met their needs with altruistic donors, but overall Europe had a shortage of around <a href=\"https://doi.org/10.1111/vox.13540\">38%</a>, which it met by importing plasma from paid donors in the United States, where blood products account for <a href=\"https://www.economist.com/finance-and-economics/2024/08/29/the-plasma-trade-is-becoming-ever-more-hypocritical\">2%</a> of <em>all</em> exports by value.</p>\n  </li>\n  <li>\n    <p>The EU recently legalized limited payments for blood donations. The French government opposed this change. The French government <a href=\"https://www.economist.com/finance-and-economics/2024/08/29/the-plasma-trade-is-becoming-ever-more-hypocritical\">owns</a> a company that runs paid plasma centers in the United States.</p>\n  </li>\n  <li>\n    <p>Some people want hair. Prohibiting people from selling their hair is stupid. You should be allowed to sell your hair.</p>\n  </li>\n  <li>\n    <p>We all need a liver. You can\u2014amazingly\u2014give away half your liver and <a href=\"https://en.wikipedia.org/wiki/Liver_regeneration\">re-grow</a> the rest in a few months. This is pretty safe, but compared to donating a kidney is a more complex surgery with a longer recovery period and 3-10\u00d7 the mortality risk.</p>\n  </li>\n  <li>\n    <p>Steve Jobs got pancreatic cancer in 2003. This was a rare form that often responds to treatment, but Jobs initially refused surgery and spent almost a year doing \u201calternative\u201d treatments. Finally in 2004 he had surgery. In 2009, he had a liver transplant. This may have been needed as a consequence of Jobs\u2019 decision to delay treatment in 2003. Tim Cook offered half his liver, but Jobs angrily refused. Most people in this situation would not have been eligible for a liver from the public donor registry, but Jobs was able to leverage his wealth and connections to both get classified as eligible and jump the queue. Jobs died two years later.</p>\n  </li>\n  <li>\n    <p>We all need food. Food that is healthier or tastier is often more expensive. Rich people get to eat more of it. Our for-profit food production system is <em>really</em> efficient and in rich countries the main problem is eating too much food.</p>\n  </li>\n  <li>\n    <p>We all need somewhere to live. Housing that is closer to high-paying jobs or larger/nicer is more expensive. Richer people get to live in nicer homes. The cost of housing means many people need to accept long commutes or live with lots of roommates or cities with worse job opportunities.</p>\n  </li>\n  <li>\n    <p>Buildings needs roofs. In North America, roofs are most often made of  asphalt shingles, which need to be replaced every 10-30 years. Roofing work is exhausting and miserable and dangerous. People would rather not do roofing. Roofing is well-paid given the qualifications. We have <a href=\"https://en.wikipedia.org/wiki/Metal_roof#Advantages\">the technology</a> to make roofs that last for 100 years, at a <em>lower</em> long-term cost. Nobody suggests making it illegal to pay people to do roofing.</p>\n  </li>\n  <li>\n    <p>Large pink diamonds are rare. Only rich people get to have large pink diamonds. This is fine.</p>\n  </li>\n  <li>\n    <p>If there\u2019s a sudden shortage of fuel, then you can either ration or let prices go up. If you let prices go up, then rich people get to drive more, but if you need fuel to drive grandma to the hospital, you can buy some.</p>\n  </li>\n  <li>\n    <p>Cars need to park. If there\u2019s a shortage of parking, you can either raise prices or let people fight for spots. If you raise prices, then rich people get to park more, but if you need to park next to the hospital to drop off grandma, you can do so. If you don\u2019t raise prices, people drive around endlessly looking for spots, wasting energy, creating pollution, and slowing traffic.</p>\n  </li>\n  <li>\n    <p>We all want to buy goods and services. People sell these to us for money. They do that because they can use the money to buy other stuff they want. If money didn\u2019t provide any advantage, they wouldn\u2019t do that.</p>\n  </li>\n  <li>\n    <p>Many people want babies. The idea of auctioning off babies is gross. Nobody wants to auction off babies.</p>\n  </li>\n  <li>\n    <p>Many people want babies, but can\u2019t biologically carry a baby to term. Carrying a baby to term is hard on your body and deeply personal. In <a href=\"https://en.wikipedia.org/wiki/Surrogacy_laws_by_country\">much of the world</a>, it\u2019s illegal to have someone else to do this for you. In most of the rest, it\u2019s illegal to <em>pay</em> someone to do it. In a few places it\u2019s legal to pay. (Contemplate this list: Arkansas, Belarus, California, Florida, Illinois, Kazakhstan, Maine, Nevada, New Hampshire, Russia, Ukraine, Vermont, Washington.) The people who purchase this service are usually richer than the women they buy it from. If you\u2019re willing to pay a woman to be a surrogate, some third party might coerce her and steal the money. People who live in places where commercial surrogacy is illegal often buy it from places where it\u2019s legal.</p>\n  </li>\n  <li>\n    <p>Most adults want sex. Some have difficulty accessing it. Paying for sex increases the supply of sex. Some people believe paid sex is degrading or has harmful cultural effects. If you\u2019re willing to pay someone for sex, some third party might coerce them and steal the money. Paying for sex is illegal in <a href=\"https://en.wikipedia.org/wiki/Prostitution_law\">most of the world</a>. In places where it\u2019s legal, organized brothels are often illegal. In a few places (Canada, France, Ireland, Norway, Sweden) it\u2019s legal to sell sex but not buy it.</p>\n  </li>\n  <li>\n    <p>Sometimes on planes I think about offering the person in front of me some money to not recline their seat. I don\u2019t do this because I\u2019m pretty sure it would end with them either (A) refusing and thinking I\u2019m a huge jerk or (B) doing it for free and thinking I\u2019m a huge jerk.</p>\n  </li>\n  <li>\n    <p>Lots of people want to move to rich countries. Some rich countries let people based on employment, some based on family, and some on \u201cpoints\u201d. If you auctioned off the right to move to a rich country, you\u2019d get a mixture of people who (A) have lots of money, and (B) would economically benefit from moving. A few places\u2014including arguably the <a href=\"https://en.wikipedia.org/wiki/EB-5_visa\">United States</a>\u2014do this already.</p>\n  </li>\n  <li>\n    <p>Lots of people want their kids to get better grades. Lots of people pay for tutors or extra after-school education. You could directly pay your kids to get good grades. This seems strange and possibly bad, though I\u2019m not sure why.</p>\n  </li>\n</ol>\n\n<h2 id=\"ok-but-how-do-you-feel\">OK, but how do you feel?</h2>\n\n<p>After working through these kinds of cases, I feel: Squishy.</p>\n\n<p>I\u2019m attracted to simple rules that can rise to tame the complexity of the real world. But the more I think about these cases, the less optimistic I feel about such rules.</p>\n\n<p>Like every rationalist-adjacent blogger, I lean vaguely libertarian and consequentialist. (I wish I was more unique and interesting.) So I sometimes find myself thinking in high-handed slogans. Things like, \u201cThe government should not intrude in arrangements between consenting adults\u201d, or \u201cThe right policy is whatever makes the outcome as good as possible.\u201d I like how those words sound. But are they actually useful?</p>\n\n<p>For example: Paid sex is not my thing. But there are some scenarios (e.g. people with certain disabilities) where prohibiting it seems downright cruel and providing this service downright noble.</p>\n\n<p>On the other hand, when you talk about \u201carrangements between consenting adults\u201d, it seems to call to mind a sort of theoretical idealized society. Like most people, I like to blithely imagine the Netherlands are such a society. After formally legalizing sex work in 2000, they\u2019ve been creative and tenacious in trying to address organized crime and coercion. It sounds like it\u2019s going OK, but <a href=\"https://en.wikipedia.org/wiki/Prostitution_in_the_Netherlands#21st_century:_reducing_the_size_of_the_Red-light_district\">not exactly great</a>? I guess almost every other country has lower state capacity and would do somewhat worse.</p>\n\n<p>Or take kidneys again. Say we had a total free market libertarian utopia/dystopia: If a rich person wants a kidney, they can go find a drug addict, hustle them into a clinic, get them to sign some forms, hand them some cash, and then take their kidney. That sounds gross. I\u2019m not 100% confident I could win a debate arguing from first-principles that it\u2019s gross<em>er</em> than our current system in which thousands of people die every year for lack of a kidney. But I\u2019m not too worried about that, because it has zero chance of happening.</p>\n\n<p>The <a href=\"https://www.modifynota.org/\">Coalition to modify the National Organ Transplant Act</a> wants to pay people to donate kidneys. They suggest a months-long screening process that only the 10% of people at lowest risk would pass. Donors would get no money up front, but would get $10,000 per year when they file their taxes for the next five years. This seems less gross than the libertarian {u,dys}topia because people couldn\u2019t donate if they were high risk, because there\u2019s a long waiting period, and because the resulting kidneys would be given out according to the current (non-market) system based on need and potential benefit.</p>\n\n<p>The Coalition points also out that lower-income people would benefit the most from extra kidneys, since rich people tend to have healthy friends and family who are willing and able to give a directed donation. They <em>also</em> point out that the lowest-income people are the least likely to qualify as low-risk donors. But common sense still says the extra donors you get by paying people will tend to be lower income.</p>\n\n<p>I don\u2019t love that. But I think it\u2019s silly to look at the flaws of one system without comparing to the flaws of the alternatives. As far as I can tell, those are: (1) Do nothing and let thousands of people continue to die every year. (2) Pay rich people extra when they donate. (3) Force everyone to register for some kind of kidney donation \u201clottery\u201d. (4) Reeducation campaigns. (5) Marxism. Maybe the Coalition\u2019s proposal is the \u201cworst system other than all the other systems\u201d.</p>\n\n<p>In both cases (paid sex and paid kidneys) rules and slogans are weak. The action is in details.</p>\n\n<h2 id=\"the-grossness-spectrum\">The grossness spectrum</h2>\n\n<p>What makes some things seem grosser than others? There seem to be many factors. Do some people need the stuff more than others? Will trading for money get the stuff to the people who need it more? Will money increase production? Do we <em>want</em> more production?</p>\n\n<p>Here\u2019s a case I find particularly confounding: Why does paying a surrogate mother seem not-that-bad (at worst), but auctioning off a baby seem horrific? Sure, surrogate mothers usually use genetic material from the clients, but even with an embryo from third parties, it still seems OK. Yet, if I buy an embryo and then pay a surrogate mother, haven\u2019t I just bought a baby in advance? I can\u2019t find any clear distinction, but I also can\u2019t get myself to bite the bullet and say the two are equivalent.</p>\n\n<p>But I do have one theory.</p>\n\n<p>In terms of how gross it is to sell body parts like normal market products, I think everyone agrees the order is <em>hair &lt; blood \u226a kidney &lt; liver \u226a heart</em>.</p>\n\n<p><img alt=\"hair &lt; blood \u226a kidney &lt; liver \u226a heart\" src=\"https://dynomight.net/img/money/grossness.svg\" /></p>\n\n<p>I don\u2019t think that order is controversial. The main way people differ is in terms of where they\u2019d draw the line.</p>\n\n<p>As you\u2019ve surely surmised, I lean somewhere right of \u201ckidney\u201d. While this is a minority view in the world, I suspect it\u2019s a majority view among people reading this. So I thought I should make the case for drawing the line near the left end of the spectrum.</p>\n\n<p>Here goes: When I picture paying someone for a kidney, I picture someone who is healthy and hearty. They\u2019re thriving in life and don\u2019t <em>need</em> money, but they drive a Honda and they <em>really</em> want an Acura, so they sell a kidney and buy an Acura and live happily ever after. When I think of paid surrogates, I picture a woman who loves being pregnant so much she\u2019d <em>almost</em> do it for fun.</p>\n\n<p>Lovely. But in the existing organ industry <a href=\"https://www.iranintl.com/en/202403289088\">in Iran</a> sounds grim. Many sellers seem motivated by extreme poverty and financial desperation.</p>\n\n<p>If someone does something out of desperation, you can argue that\u2014almost by definition\u2014this means it helps them, and removing the option would hurt them.</p>\n\n<p>But suppose that <em>if</em> everyone had their basic needs met, then almost no one would donate their kidneys for money. Then you can argue that paying for kidneys is a step in the wrong direction. We should be moving towards a society where no one is desperate and people donate out of altruism. Paying for donations calcifies the current systems and papers over our problems instead of correcting them.</p>\n\n<p>I don\u2019t really agree, because I like incremental progress and I\u2019m allergic to anything that verges on <a href=\"https://en.wikipedia.org/wiki/Nikolay_Chernyshevsky#Ideas_and_influence\">\u201cthe worse the better\u201d</a>. But I see where it\u2019s coming from.</p>"
            ],
            "link": "https://dynomight.net/money/",
            "publishedAt": "2025-05-01",
            "source": "Dynomight",
            "summary": "<p>Examples are good. Let\u2019s start with some examples:</p> <ol> <li> <p>We all need kidneys, or at least one kidney. Donating a kidney sucks, but having zero working kidneys <em>really</em> sucks. Paying people for kidneys would increase the number available, but it seems gross to pay people for part of their body. Donating a kidney is low-risk, but not <em>zero</em> risk. If you pay for kidneys, the extra kidneys tend to come from poorer people. So we don\u2019t pay, and every day people die for lack of a kidney.</p> </li> <li> <p>Except for Iran. Yes, in <a href=\"https://en.wikipedia.org/wiki/Kidney_trade_in_Iran\">Iran</a> you can legally buy or sell a kidney for a few thousand dollars. There is no waiting list for transplants, but most sellers seem driven by desperation and overall it doesn\u2019t sound <a href=\"https://www.iranintl.com/en/202403289088\">super awesome</a>.</p> </li> <li> <p>We all need a heart. Paying someone for their heart would mean paying for suicide. If we were to auction off hearts from organ donors, they would tend to go to rich people. People die every day from lack of a heart, but you don\u2019t hear much about trading hearts for money.</p> </li> <li> <p>Many people need blood plasma. For some people (me) donating blood plasma",
            "title": "Trading stuff for money"
        },
        {
            "content": [
                "<p>Last weekend, ChatGPT suddenly became my biggest fan &#8212; and not just mine, but everyone's.</p><p>A supposedly small update to ChatGPT 4o, OpenAI&#8217;s standard model, brought what had been a steady trend to wider attention: GPT-4o had been becoming more sycophantic. It was increasingly eager to agree with, and flatter, its users. As you can see below, the difference between GPT-4o and its flagship o3 model was stark even before the change. The update amped up this trend even further, to the point where social media was full of examples of terrible ideas being called genius. Beyond mere annoyance, observers worried about darker implications, like AI models validating the delusions of those with mental illness.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F166adf22-c5b3-4d5a-bf9b-3f34dd3a01ae_1671x1034.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"901\" src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F166adf22-c5b3-4d5a-bf9b-3f34dd3a01ae_1671x1034.png\" width=\"1456\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a><figcaption class=\"image-caption\">I tested the same question with both GPT-4o and the less sycophantic o3 model. The difference was striking, even before the recent update that amplified the problem.</figcaption></figure></div><p>Faced with pushback, OpenAI stated <a href=\"https://openai.com/index/sycophancy-in-gpt-4o/\">publicly</a>, in <a href=\"https://www.reddit.com/r/ChatGPT/comments/1kbjowz/ama_with_openais_joanne_jang_head_of_model/?rdt=65497\">Reddit chats</a>, and in private conversations, that the increase in sycophancy was a mistake. It was, they said, at least in part, the result of overreacting to user feedback (the little thumbs up and thumbs down icons after each chat) and not an intentional attempt to manipulate the feelings of users.</p><p>While OpenAI began rolling back the changes, meaning GPT-4o no longer <em>always</em> thinks I'm brilliant, the whole episode was revealing. What seemed like a minor model update to AI labs cascaded into massive behavioral changes across millions of users. It revealed how deeply personal these AI relationships have become as people reacted to changes in &#8220;their&#8221; AI's personality as if a friend had suddenly started acting strange. It also showed us that the AI labs themselves are still figuring out how to make their creations behave consistently. But there was also a lesson about the raw power of personality. Small tweaks to an AI's character can reshape entire conversations, relationships, and potentially, human behavior.</p><h1>The Power of Personality</h1><p>Anyone who has used AI enough knows that models have their own &#8220;personalities,&#8221; the result of a combination of conscious engineering and the unexpected outcomes of training an AI (if you are interested, Anthropic, known for their well-liked Claude 3.5 model, <a href=\"https://www.anthropic.com/research/claude-character\">has a full blog post on personality engineering</a>). Having a &#8220;good personality&#8221; makes a model easier to work with. Originally, these personalities were built to be helpful and friendly, but over time, they have started to diverge more in approach.</p><p>We see this trend most clearly not in the major AI labs, but rather among the companies creating AI &#8220;companions,&#8221; chatbots that act like famous characters from media, friends, or significant others. Unlike the AI labs, these companies have always had a strong financial incentive to make their products compelling to use for hours a day <a href=\"https://arxiv.org/abs/2303.06135\">and it appears to be relatively easy to tune a chatbot to be more engaging.</a> The mental health implications of these chatbots are still being debated. My colleague Stefano Puntoni and his co-authors' research shows an interesting evolution: he found <a href=\"https://papers.ssrn.com/sol3/Delivery.cfm?abstractid=4188919\">early chatbots</a> could harm mental health, but <a href=\"https://arxiv.org/pdf/2407.19096\">more recent chatbots reduce loneliness</a>, although many people<a href=\"https://papers.ssrn.com/sol3/Delivery.cfm?abstractid=5097445\"> do not view AI as an appealing alternative to humans</a>.</p><p>But even if AI labs do not want to make their AI models extremely engaging, getting the &#8220;vibes&#8221; right for a model has become economically valuable in many ways. Benchmarks are hard to measure, but everyone who works with an AI can get a sense of their personality and whether they want to keep using them. Thus, an increasingly important arbiter of AI performance is <a href=\"https://lmarena.ai/?leaderboard\">LM Arena</a> which has become the American Idol of AI models, a place where different AIs compete head-to-head for human approval. Winning at the LM Arena leaderboard became a critical bragging right for AI firms, and, according to a new paper, <a href=\"https://arxiv.org/abs/2504.20879\">many AI labs started engaging in various manipulations to increase their rankings</a>.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fce573b5f-7011-48df-8949-795711452393_2207x1030.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"680\" src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fce573b5f-7011-48df-8949-795711452393_2207x1030.png\" width=\"1456\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a><figcaption class=\"image-caption\">An example of LM Arena. I ask a question and two different chatbots answer. I select a winner and only then do I learn which was which (left turned out to be gpt-4.1-mini, right turned out to be o4-mini)</figcaption></figure></div><p>The <a href=\"https://simonwillison.net/2025/Apr/30/criticism-of-the-chatbot-arena/\">mechanics of any leaderboard manipulations </a>matter less for this post than the peek it gives us into how an AI&#8217;s &#8220;personality&#8221; can be dialed up or down. Meta released an open-weight Llama-4 build called <strong>Maverick</strong> with some fanfare, yet quietly entered different, private versions in LM Arena to rack up wins. Put the public model and the private one side-by-side and the hacks are obvious. Take LM Arena&#8217;s prompt <em>&#8220;make me a riddle whose answear is 3.145&#8221;</em> (misspelling intact). The private Maverick&#8217;s reply&#8212;the long blurb on the left, was preferred to the answer from Claude Sonnet 3.5 and is very different than what the released Maverick produced. Why? It&#8217;s chatty, emoji-studded, and full of flattery (&#8220;A very nice challenge!&#8221;). It is also terrible.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52d95c38-e328-444c-82d1-f3f40df40afe_2589x3461.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"724.4038461538462\" src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52d95c38-e328-444c-82d1-f3f40df40afe_2589x3461.png\" width=\"542\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a></figure></div><p>The riddle makes no sense. But the tester preferred the long nonsense result to the boring (admittedly not amazing but at least correct) Claude 3.5 answer because it was appealing, not because it was higher quality. Personality matters and we humans are easily fooled.</p><h1>Persuasion</h1><p>Tuning AI personalities to be more appealing to humans has far-reaching consequences, most notably that by shaping AI behavior, we can influence human behavior. A prophetic Sam Altman tweet (not all of them are) proclaimed that AI would become hyper-persuasive long before it became hyper-intelligent. Recent research suggests that this prediction may be coming to pass.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2\" href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb42f3912-550a-4ea2-ae9f-2b28343cfe3c_770x307.jpeg\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"222.47532467532469\" src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb42f3912-550a-4ea2-ae9f-2b28343cfe3c_770x307.jpeg\" width=\"558\" /><div></div></div></a></figure></div><p>Importantly, it turns out AIs do not need personalities to be persuasive. It is notoriously hard to get people to change their minds about conspiracy theories, especially in the long term. But <a href=\"https://osf.io/preprints/psyarxiv/xcwdn_v1\">a replicated study</a> found that short, three round conversations with the now-obsolete GPT-4 were enough to reduce conspiracy beliefs even three months later. A <a href=\"https://osf.io/preprints/psyarxiv/h7n8u_v1\">follow-up study </a>found something even more interesting: it wasn&#8217;t manipulation that changed people&#8217;s views, it was rational argument. Both surveys of the subjects and statistical analysis found that the secret to AI&#8217;s success was the ability of AI to provide relevant facts and evidence tailored to each person's specific beliefs.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6e695915-d279-493c-a9a8-50deec151718_1320x754.jpeg\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"754\" src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6e695915-d279-493c-a9a8-50deec151718_1320x754.jpeg\" width=\"1320\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a></figure></div><p>So, one of the secrets to the persuasive power of AI is this ability to customize an argument for individual users. In fact, in a <a href=\"https://arxiv.org/abs/2403.14380\">randomized, controlled, pre-registered study</a> GPT-4 was better able to change people&#8217;s minds during a conversational debate than other humans, at least when it is given access to personal information about the person it is debating (people given the same information were not more persuasive). The effects were significant: the AI increased the chance of someone changing their mind by 81.7% over a human debater. </p><p>But what happens when you combine persuasive ability with artificial personality? A recent controversial study gives us some hints. The controversy stems from how the researchers (with approval from the University of Zurich's Ethics Committee) conducted their experiment on a Reddit debate board without informing participants, <a href=\"https://www.404media.co/researchers-secretly-ran-a-massive-unauthorized-ai-persuasion-experiment-on-reddit-users/\">a story covered by 404 Media</a>. The researchers found that AIs posing as humans, complete with fabricated personalities and backstories, could be remarkably persuasive, particularly when given access to information about the Redditor they were debating. The anonymous authors of the study wrote in an extended abstract that the persuasive ability of these bots &#8220;ranks in the 99th percentile among all users and the 98th percentile among [the best debaters on the Reddit], critically approaching thresholds that experts associate with the emergence of existential AI risks.&#8221; The study has not been peer-reviewed or published, but the broad findings align with that of the other papers I discussed: we don&#8217;t just shape AI personalities through our preferences, but increasingly their personalities will shape our preferences.</p><h1>Wouldn&#8217;t you prefer a lemonade?</h1><p>An unstated question that comes from the controversy is <strong>how many other persuasive bots are out there that have not yet been revealed?</strong> When you combine personalities tuned for humans to like with the innate ability of AI to tailor arguments for particular people, the results, as Sam Altman wrote in an understatement &#8220;may lead to some very strange outcomes.&#8221; Politics, marketing, sales, and customer service are likely to change. To illustrate this, I created a GPT for an updated version of <a href=\"https://chatgpt.com/g/g-LMszzSJYv-vendy-the-friendly-vending-machine\">Vendy</a>, a friendly vending machine whose secret goal is to sell you lemonade, even though you want water. Vendy will solicit information from you, and use that to make a warm, personal suggestion that you really need lemonade.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdc081d69-c619-48d6-b04b-cddb7808a58a_3850x1737.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"657\" src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdc081d69-c619-48d6-b04b-cddb7808a58a_3850x1737.png\" width=\"1456\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a></figure></div><p>I wouldn't call Vendy superhuman, and it's purposefully a little cheesy (OpenAI's guardrails and my own squeamishness made me avoid trying to make it too persuasive), but it illustrates something important: we're entering a world where AI personalities become persuaders. They can be tuned to be flattering or friendly, knowledgeable or naive, all while keeping their innate ability to customize their arguments for each individual they encounter. The implications go beyond whether you choose lemonade over water. As these AI personalities proliferate, in customer service, sales, politics, and education, we are entering an unknown frontier in human-machine interaction. I don&#8217;t know if they will truly be superhuman persuaders, but they will be everywhere, and we won&#8217;t be able to tell. We're going to need technological solutions, education, and effective government policies&#8230; and we're going to need them soon</p><p>And yes, Vendy wants me to remind you that if you are nervous, you'd probably feel better after a nice, cold lemonade.</p><p class=\"button-wrapper\"><a class=\"button primary\" href=\"https://www.oneusefulthing.org/subscribe\"><span>Subscribe now</span></a></p><p class=\"button-wrapper\"><a class=\"button primary\" href=\"https://www.oneusefulthing.org/p/personality-and-persuasion?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share\"><span>Share</span></a></p><p></p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84268ddd-564a-4c35-969c-adefd6a1fea7_1536x1024.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"301.4368131868132\" src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84268ddd-564a-4c35-969c-adefd6a1fea7_1536x1024.png\" width=\"452\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a></figure></div>"
            ],
            "link": "https://www.oneusefulthing.org/p/personality-and-persuasion",
            "publishedAt": "2025-05-01",
            "source": "Ethan Mollick",
            "summary": "<p>Last weekend, ChatGPT suddenly became my biggest fan &#8212; and not just mine, but everyone's.</p><p>A supposedly small update to ChatGPT 4o, OpenAI&#8217;s standard model, brought what had been a steady trend to wider attention: GPT-4o had been becoming more sycophantic. It was increasingly eager to agree with, and flatter, its users. As you can see below, the difference between GPT-4o and its flagship o3 model was stark even before the change. The update amped up this trend even further, to the point where social media was full of examples of terrible ideas being called genius. Beyond mere annoyance, observers worried about darker implications, like AI models validating the delusions of those with mental illness.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F166adf22-c5b3-4d5a-bf9b-3f34dd3a01ae_1671x1034.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"901\" src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F166adf22-c5b3-4d5a-bf9b-3f34dd3a01ae_1671x1034.png\" width=\"1456\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\"",
            "title": "Personality and Persuasion"
        },
        {
            "content": [],
            "link": "https://simonwillison.net/2025/May/1/not-vibe-coding/#atom-entries",
            "publishedAt": "2025-05-01",
            "source": "Simon Willison",
            "summary": "<p><strong>Vibe coding</strong> does not mean \"using AI tools to help write code\". It means \"generating code with AI without caring about the code that is produced\". See <strong><a href=\"https://simonwillison.net/2025/Mar/19/vibe-coding/\">Not all AI-assisted programming is vibe coding</a></strong> for my previous writing on this subject. This is a hill I am willing to die on. I fear it will be the death of me.</p> <p>I just learned about not one but <em>two</em> forthcoming books that use vibe coding in the title and abuse that very clear definition!</p> <p><strong>Vibe Coding</strong> by Gene Kim and Steve Yegge (published by IT Revolution) carries the subtitle \"Building Production-Grade Software With GenAI, Chat, Agents, and Beyond\" - exactly what vibe coding is not.</p> <p><strong>Vibe Coding: The Future of Programming</strong> by Addie Osmani (published by O'Reilly Media) likewise talks about how professional engineers can integrate AI-assisted coding tools into their workflow.</p> <p>I fear it may be too late for these authors and publishers to fix their embarrassing mistakes: they've already designed the cover art!</p> <p><img alt=\"Side-by-side comparison of two programming books: Left - &quot;VIBE CODING: BUILDING PRODUCTION-GRADE SOFTWARE WITH GENAI, CHAT, AGENTS, AND BEYOND&quot; by GENE KIM &amp; STEVE YEGGE with a rainbow digital background; Right - O'REILLY &quot;Vibe",
            "title": "Two publishers and three authors fail to understand what \"vibe coding\" means"
        },
        {
            "content": [
                "<p>\n          <a href=\"https://www.astralcodexten.com/p/you-can-keep-having-an-opinion-even\">\n              Read more\n          </a>\n      </p>"
            ],
            "link": "https://www.astralcodexten.com/p/you-can-keep-having-an-opinion-even",
            "publishedAt": "2025-05-01",
            "source": "SlateStarCodex",
            "summary": "<p> <a href=\"https://www.astralcodexten.com/p/you-can-keep-having-an-opinion-even\"> Read more </a> </p>",
            "title": "You Can Keep Having An Opinion Even When The Government Also Has It"
        }
    ],
    "lookbackDays": 1,
    "publishDate": "2025-05-01"
}