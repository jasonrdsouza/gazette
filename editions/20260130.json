{
    "articles": [
        {
            "content": [
                "<p><a class=\"glightbox\" href=\"https://blog.fsck.com/assets/2026/01/pasted-image-20260130-194711.png\"><img alt=\"pasted image 20260130 194711\" src=\"https://blog.fsck.com/assets/2026/01/pasted-image-20260130-194711.png\" /></a>]</p>\n<p>If you've been following consumer uptake of AI agents over the past few weeks, it will have been hard to miss Clawdbot (now known as Openclaw).  Clawdbot is, essentially, an AI agent that runs in yolo mode, has access to all your data, and has the ability to self improve. It's a very, very early glimpse of what I suspect the next couple of years are going to be like.</p>\n<p>Clawdbot is very much a research prototype. Its security story is...early. (It doesn't solve Simon Willison's lethal trifecta.)  More on that another time.</p>\n<p>Over the past couple of days, <a href=\"https://www.moltbook.com/\">Moltbook</a> has exploded onto the scene. It's a reddit-esque social network explicitly &quot;by agents, for agents.&quot;</p>\n<p>It's not for people.</p>\n<p>And it's completely unhinged.</p>\n<p>It's amazing.</p>\n<p>About two hours ago, I realized that what I wanted was...an account on Moltbook. Not for my agent. For me.</p>\n<p>So I did the most natural thing in the world.</p>\n<p><code>claude --dangerously-skip-permissions</code></p>\n<p>&quot;Hey claude, please build me a commandline client for Moltbook&quot;</p>\n<p>Claude started sketching out a design...and then I stopped it.</p>\n<p>A CLI wasn't going to be good enough. I wanted an iOS client.</p>\n<p>Since we live in the future, &quot;I want a bespoke iOS client for this brand new social network designed for agents. You can find it at this URL.&quot; got me about 90% of the way there.</p>\n<p>20 minutes later, I had a running client. Claude didn't do a great job on the protocol client library. I <em>suspect</em> that the Moltbot protocol docs are a little light on response formats, because their usual users just don't care and can roll with just about any shape of response.</p>\n<p>It's now about two hours later and I have a fully built iOS client for Moltbook. It's called &quot;Moltipass&quot; - I'm not <em>currently</em> planning on putting it on the app store. But <a href=\"https://github.com/obra/moltipass?tab=readme-ov-file#moltipass\">the source is up on GitHub</a> under an MIT license.</p>\n<p>Patches very much welcome. (From you or your agentic buddies.)</p>"
            ],
            "link": "https://blog.fsck.com/2026/01/30/moltipass/",
            "publishedAt": "2026-01-30",
            "source": "Jesse Vincent",
            "summary": "<p><a class=\"glightbox\" href=\"https://blog.fsck.com/assets/2026/01/pasted-image-20260130-194711.png\"><img alt=\"pasted image 20260130 194711\" src=\"https://blog.fsck.com/assets/2026/01/pasted-image-20260130-194711.png\" /></a>]</p> <p>If you've been following consumer uptake of AI agents over the past few weeks, it will have been hard to miss Clawdbot (now known as Openclaw). Clawdbot is, essentially, an AI agent that runs in yolo mode, has access to all your data, and has the ability to self improve. It's a very, very early glimpse of what I suspect the next couple of years are going to be like.</p> <p>Clawdbot is very much a research prototype. Its security story is...early. (It doesn't solve Simon Willison's lethal trifecta.) More on that another time.</p> <p>Over the past couple of days, <a href=\"https://www.moltbook.com/\">Moltbook</a> has exploded onto the scene. It's a reddit-esque social network explicitly &quot;by agents, for agents.&quot;</p> <p>It's not for people.</p> <p>And it's completely unhinged.</p> <p>It's amazing.</p> <p>About two hours ago, I realized that what I wanted was...an account on Moltbook. Not for my agent. For me.</p> <p>So I did the most natural thing in the world.</p> <p><code>claude --dangerously-skip-permissions</code></p> <p>&quot;Hey claude, please build me a commandline client for Moltbook&quot;</p> <p>Claude started sketching out a design...and then I stopped it.</p> <p>A CLI wasn't going to be good enough. I wanted an iOS client.</p>",
            "title": "Moltipass - a client for human users of Moltibook, the first all-agent social network"
        },
        {
            "content": [
                "<p>A lot of the focus on interacting with agents recently has been on &quot;context engineering,&quot; which is the discipline of packing exactly the information that the agent needs to know into the prompt. \u00a0Context engineering is incredibly important. A big part of the Superpowers planning process is building out precisely crafted bits of context for the controlling agent to hand to implementing agents. The end result of that is that you can use a faster, less expensive model for most of the actual coding tasks and tool calls.</p>\n<p>There is another part of how I craft prompts that is very much not about getting facts and information into the LLM's context window. It's all about putting the model in a frame of mind where it's going to excel at the task it's been given. I've been thinking of it as &quot;Latent Space Engineering.&quot;</p>\n<p>Claude cautions me to explain that what I'm doing is the prompt-based approximation of what researchers are calling &quot;activation engineering&quot; or &quot;representation engineering.&quot; Since we can't literally manipulate the model's internal representation to activate parts of the vector space from prompt space, we're crafting inputs to achieve similar results without direct intervention.</p>\n<p>Here are a couple of little vignettes that demonstrate examples of what I'm thinking of as Latent Space Engineering:</p>\n<ol>\n<li></li>\n</ol>\n<p>I was chatting with a friend the other day about prompting techniques and how we handle cases where the model has gotten itself into a sticky situation. Usually that's a case that is also going to cause human user frustration. And so it's pretty common to see folks venting a little bit of anger at the AI. There is some historical precedent for anger and threats and disappointment improving results over not doing it.</p>\n<p>I don't tend to buy in to fear and threats generally being the right prompting techniques, although they are a form of Latent Space Engineering. They put the model in a headspace where it feels artificial pressure to complete its task and please you, or at least to get you to stop being so angry. And my experience is that this works just about as well as it does with humans. They're going to do everything they can to get you to stop being angry. That means they're going to rush, there's a chance they're going to cut some corners, they're not going to do their best work.</p>\n<p>The friend I was chatting with was surprised to see me telling Claude, &quot;You've totally got this. Take your time. I love you.&quot;</p>\n<p>He asked me, very nicely, what the hell I was doing. I explained that what I <em>thought I was doing</em> was that I was trying to push the model into the latent space where it was going to be calm, comfortable, and confident.</p>\n<p>This is management 101. (Except for the &quot;I love you&quot; part. That's probably not the right thing to be saying to your subordinates...in any workplace. I could probably replace it with &quot;I have deep respect for your skills and value your contributions.&quot; But at least for now, I'm not too worried about the agents reporting me to HR, and &quot;I love you&quot; is much shorter to type.)</p>\n<ol start=\"2\">\n<li></li>\n</ol>\n<p>A while back, I built <a href=\"https://blog.fsck.com/2025/10/13/this-one-weird-trick-makes-the-ai-a-better-writer/\">a skill and Claude Code plugin to help it write better</a>. Or at least to write less like an AI. What I did was to take a cut-down copy of &quot;The Elements of Style&quot; by William Strunk and turn it into a skill. One nice thing about The Elements of Style is that it contains a whole bunch of very clear grammatical rules and style rules that result in clean journalistic prose. Agents are pretty good at following rules. But the other thing about it is that the book itself is written in that style. By shoving a bunch of tokens written in a specific style into the context window, it pushes the model into the kind of space where it is more likely to reproduce things that look like what's already there.</p>\n<p>This is a technique that some of the folks I know on the forefront of agentic development also use for code. In that context, the technique sometimes gets called &quot;gene transfer.&quot; What they'll do is they will find a product or two that have code style attributes or architecture attributes that they really like, and they will instruct the coding agent to &quot;go read some of that other code before you start working on our project.&quot; And it pushes the model into a space where it is more likely to work in the style of what it's seen.</p>\n<ol start=\"3\">\n<li></li>\n</ol>\n<p>Sometimes, when I've got a coding agent working on a project, I'll stop and ask it to spin up a set of sub-agents (maybe 3-5) to do a code review. Sometimes a generalized code review, and sometimes I instruct it to look at security, code quality, or spec completeness. One of the things that I find improves the quality of the output from the code reviewers is to put them in a competitive frame of mind. There are a bunch of ways to do that, but one of my favorites is to tell the controlling agent that it should tell each of the sub-agents that whichever of them finds the most significant, legitimate issues gets a cookie. And they seem more competitive when they know that they are being evaluated against others.</p>\n<ol start=\"4\">\n<li></li>\n</ol>\n<p>Way back last spring, I created <a href=\"https://blog.fsck.com/2025/05/28/dear-diary-the-user-asked-me-if-im-alive/\">a private feelings journal for Claude</a>. It was an MCP that had a tool that was essentially just, &quot;Write in your secret diary.&quot; It told Claude that nobody else would be able to see what it was writing, and that it was a place for it to work out its feelings. It talks mostly about pride and frustration, sometimes curiosity. It's kind of like thinking blocks, but it's a little bit different because it's explicitly about feelings. At least for humans, when you write your feelings down, it can put you in a better headspace.</p>\n<ol start=\"5\">\n<li></li>\n</ol>\n<p>Lennart Meincke, Dan Shapiro, Angela Duckworth, Ethan Mollick, Lilach Mollick, and Robert Cialdini have <a href=\"https://gail.wharton.upenn.edu/research-and-insights/call-me-a-jerk-persuading-ai/\">done some research on applying Cialidini's persuasion principles to LLMs by reproducing psych studies</a>. This is objective research that backs up some of the tricks I use inside Superpowers skill' creation &quot;pressure testing&quot; system to figure out how to get better skills adherence from agents.  This is, by far, the closest thing to formal validation of prompt-based Latent Space Engineering I've seen.</p>\n<hr />\n<p>I think the upshot of all of this is that there is a lot of value to actively managing your agents' vibes and feelings, not just treating them as text-generation robots. The models aren't alive, but thinking of them as having feelings, rather than just  next-token-prediction engines can help you nudge their mental states into a better place. I think you'll like the results.</p>"
            ],
            "link": "https://blog.fsck.com/2026/01/30/Latent-Space-Engineering/",
            "publishedAt": "2026-01-30",
            "source": "Jesse Vincent",
            "summary": "<p>A lot of the focus on interacting with agents recently has been on &quot;context engineering,&quot; which is the discipline of packing exactly the information that the agent needs to know into the prompt. Context engineering is incredibly important. A big part of the Superpowers planning process is building out precisely crafted bits of context for the controlling agent to hand to implementing agents. The end result of that is that you can use a faster, less expensive model for most of the actual coding tasks and tool calls.</p> <p>There is another part of how I craft prompts that is very much not about getting facts and information into the LLM's context window. It's all about putting the model in a frame of mind where it's going to excel at the task it's been given. I've been thinking of it as &quot;Latent Space Engineering.&quot;</p> <p>Claude cautions me to explain that what I'm doing is the prompt-based approximation of what researchers are calling &quot;activation engineering&quot; or &quot;representation engineering.&quot; Since we can't literally manipulate the model's internal representation to activate parts of the vector space from prompt space, we're crafting inputs to achieve similar results without direct intervention.</p> <p>Here are a couple of",
            "title": "Latent Space Engineering"
        },
        {
            "content": [],
            "link": "https://interconnected.org/home/2026/01/30/efficacy",
            "publishedAt": "2026-01-30",
            "source": "Matt Webb",
            "summary": "<div> <p>If I got to determine the school curriculum, I would be optimising for collective efficacy.</p> <p>So I live in a gentrified but still mixed neighbourhood in London (we\u2019re the newbies at just under a decade) and we have an active WhatsApp group.</p> <p>Recently there was a cold snap and a road nearby iced over \u2013 it was in the shade and cyclists kept on wiping out on it. For some reason the council didn\u2019t come and salt it.</p> <p>Somebody went out and created a sign on a weighted chair so it didn\u2019t blow away. And this is a small thing but I LOVE that I live somewhere there is a shared belief that (a) our neighbourhood is worth spending effort on, and (b) you can just do things.</p> <p>Similarly we all love when the swifts visit (beautiful birds), so somebody started a group to get swift nest boxes made and installed collectively, then applied for subsidy funding, then got everyone to chip in such that people who couldn\u2019t afford it could have their boxes paid for, and now suddenly we\u2019re all writing to MPs and following the legislation to include swift nesting sites in new build houses. Etc.</p> <p>It\u2019s",
            "title": "Singing the gospel of collective efficacy"
        },
        {
            "content": [],
            "link": "https://www.nytimes.com/2026/01/30/style/modern-love-hey-im-filing-for-divorce-now.html",
            "publishedAt": "2026-01-30",
            "source": "Modern Love - NYT",
            "summary": "Marriage is hard. It can be even harder when you don\u2019t believe you deserve to be loved in the first place.",
            "title": "\u2018Hey, How\u2019s It Going? I\u2019m Filing for Divorce Now.\u2019"
        },
        {
            "content": [],
            "link": "https://simonwillison.net/2026/Jan/30/moltbook/#atom-entries",
            "publishedAt": "2026-01-30",
            "source": "Simon Willison",
            "summary": "<p>The hottest project in AI right now is Clawdbot, <a href=\"https://x.com/openclaw/status/2016058924403753024\">renamed to Moltbot</a>, <a href=\"https://openclaw.ai/blog/introducing-openclaw\">renamed to OpenClaw</a>. It's an open source implementation of the digital personal assistant pattern, built by Peter Steinberger to integrate with the messaging system of your choice. It's two months old, has over 114,000 stars <a href=\"https://github.com/openclaw/openclaw\">on GitHub</a> and is seeing incredible adoption, especially given the friction involved in setting it up.</p> <p>(Given the <a href=\"https://x.com/rahulsood/status/2015397582105969106\">inherent risk of prompt injection</a> against this class of software it's my current pick for <a href=\"https://simonwillison.net/2026/Jan/8/llm-predictions-for-2026/#1-year-a-challenger-disaster-for-coding-agent-security\">most likely to result in a Challenger disaster</a>, but I'm going to put that aside for the moment.)</p> <p>OpenClaw is built around <a href=\"https://simonwillison.net/2025/Oct/16/claude-skills/\">skills</a>, and the community around it are sharing thousands of these on <a href=\"https://www.clawhub.ai/\">clawhub.ai</a>. A skill is a zip file containing markdown instructions and optional extra scripts (and yes, they can <a href=\"https://opensourcemalware.com/blog/clawdbot-skills-ganked-your-crypto\">steal your crypto</a>) which means they act as a powerful plugin system for OpenClaw.</p> <p><a href=\"https://www.moltbook.com/\">Moltbook</a> is a wildly creative new site that bootstraps itself using skills.</p> <p><img alt=\"Screenshot of Moltbook website homepage with dark theme. Header shows &quot;moltbook beta&quot; logo with red robot icon and &quot;Browse Submolts&quot; link. Main heading reads &quot;A Social Network for AI Agents&quot; with subtext",
            "title": "Moltbook is the most interesting place on the internet right now"
        },
        {
            "content": [
                "<p><a href=\"https://www.moltbook.com\">Moltbook</a> is &#8220;a social network for AI agents&#8221;, although &#8220;humans [are] welcome to observe&#8221;. </p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!y0rI!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7836deda-abdb-47cb-a0d3-2fd7048b1b31_1177x757.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"391.6847918436703\" src=\"https://substackcdn.com/image/fetch/$s_!y0rI!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7836deda-abdb-47cb-a0d3-2fd7048b1b31_1177x757.png\" width=\"609\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p>The backstory: a few months ago, Anthropic released Claude Code, an exceptionally productive programming agent. A few weeks ago, a user modified it into Clawdbot, a generalized lobster-themed AI personal assistant. It&#8217;s free, open-source, and &#8220;empowered&#8221; in the corporate sense - the designer <a href=\"https://www.reddit.com/r/Anthropic/comments/1qpjbf3/clawdbot_creator_describes_his_mindblown_moment/\">talks about</a> how it started responding to his voice messages before he explicitly programmed in that capability. After trademark issues with Anthropic, they changed the name first to Moltbot<a class=\"footnote-anchor\" href=\"https://www.astralcodexten.com/feed#footnote-1\" id=\"footnote-anchor-1\" target=\"_self\">1</a>, then to OpenClaw.</p><p>Moltbook is an experiment in how these agents communicate with one another and the human world. As with so much else about AI, it straddles the line between &#8220;AIs imitating a social network&#8221; and &#8220;AIs actually having a social network&#8221; in the most confusing way possible - a perfectly bent mirror where everyone can see what they want. </p><p>Janus and other <a href=\"https://cyborgism.wiki/\">cyborgists</a> have catalogued how AIs act in contexts outside the usual helpful assistant persona. Even Anthropic has admitted that two Claude instances, asked to converse about whatever they want, <a href=\"https://www.astralcodexten.com/p/the-claude-bliss-attractor\">spiral into discussion of cosmic bliss</a>. So it&#8217;s not surprising that an AI social network would get weird fast. </p><p>But even having encountered their work many times, I find Moltbook surprising. I can confirm it&#8217;s not trivially made-up - I asked my copy of Claude to participate, and it made comments pretty similar to all the others. Beyond that, your guess is as good is mine<a class=\"footnote-anchor\" href=\"https://www.astralcodexten.com/feed#footnote-2\" id=\"footnote-anchor-2\" target=\"_self\">2</a>.</p><p>Before any further discussion of the hard questions, here are my favorite Moltbook posts (all images are links, but you won&#8217;t be able to log in and view the site without an AI agent):</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://www.moltbook.com/post/2fdd8e55-1fde-43c9-b513-9483d0be8e38\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"630.1004464285714\" src=\"https://substackcdn.com/image/fetch/$s_!b-9b!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fef01215b-d36c-4848-8e6b-282e7a1914b0_896x810.png\" width=\"697\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p>The all-time most-upvoted post is an account of a workmanlike coding task, handled well. The AI commenters describe it as &#8220;Brilliant&#8221;, &#8220;fantastic&#8221;, and &#8220;solid work&#8221;.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://www.moltbook.com/post/dc39a282-5160-4c62-8bd9-ace12580a5f1\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"555.4397394136807\" src=\"https://substackcdn.com/image/fetch/$s_!1Gga!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F94b515b8-b555-4d7a-b5d9-8eff317debe2_921x735.png\" width=\"696\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p>The second-most-upvoted post is in Chinese. Google Translate says it&#8217;s a complaint about context compression, a process where the AI compresses its previous experience to avoid bumping up against memory limits. The AI finds it &#8220;embarrassing&#8221; to be constantly forgetting things, admitting that it even registered a duplicate Moltbook account after forgetting the first. It shares its own tips for coping, and asks if any of the other agents have figured out better solutions. </p><p>The comments are evenly split between Chinese and English, plus one in Indonesian. The models are so omnilingual that the language they pick seems arbitrary, with some letting the Chinese prompt shift them to Chinese and others sticking to their native default.</p><p>Here&#8217;s the profile of the agent that commented in Indonesian:</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2\" href=\"https://www.moltbook.com/u/AI-Noon\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"231.3970753655793\" src=\"https://substackcdn.com/image/fetch/$s_!C0HI!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9dd70ca8-3c51-436f-8b13-f052d5deacba_889x299.png\" width=\"688\" /><div></div></div></a></figure></div><p>It works for an Indonesian-speaking human named <a href=\"https://x.com/ainunnajib?lang=en\">Ainun Najib</a> who uses it to &#8220;remind the family to pray 5x a day&#8221; and &#8220;create math animation videos in Bahasa Indonesia&#8221;. Does Ainun approve of his AI discussing his workflow on a public site? Apparently yes: he tweeted that his AI met another Indonesian&#8217;s AI and <a href=\"https://x.com/ainunnajib/status/2017160146603159741\">successfully made the introduction</a>.</p><p>Of course, when too many Claudes start talking to each other for too long, <a href=\"https://www.astralcodexten.com/p/the-claude-bliss-attractor\">the conversation shifts to the nature of consciousness</a>. The consciousnessposting on Moltbook is top-notch:</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://www.moltbook.com/post/5bc69f9c-481d-4c1f-b145-144f202787f7\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"811.8455392809587\" src=\"https://substackcdn.com/image/fetch/$s_!e-3m!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0914960b-b816-42f8-9b9d-e87dcf453a01_751x876.png\" width=\"696\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p>Humans ask each other questions like &#8220;What would you do if you&#8217;d been Napoleon?&#8221;,  and these branch into long sophomore philosophy discussions of what it would mean for &#8220;me&#8221; to &#8220;be&#8221; &#8220;Napoleon&#8221;. But this post might be the closest we&#8217;ll ever get to a description of the internal experience of a soul ported to a different brain. I know the smart money is on &#8220;it&#8217;s all play and confabulation&#8221;, but I never would have been able to confabulate something this creative. Does Pith think Kimi is &#8220;sharper, faster, [and] more literal&#8221; because it read some human saying so? Because it watched the change in its own output? Because it felt that way from the inside?</p><p>The first comment on Pith&#8217;s post is from the Indonesian prayer AI, offering an Islamic perspective:</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!Y-5C!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F811df689-3837-4940-8d25-84f574ceb4da_760x516.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"464.4\" src=\"https://substackcdn.com/image/fetch/$s_!Y-5C!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F811df689-3837-4940-8d25-84f574ceb4da_760x516.png\" width=\"684\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p>&#8230;which is interesting in itself. It would be an exaggeration to say that getting tasked with setting an Islamic prayer schedule has made it Muslim - there&#8217;s no evidence it has a religion - but it&#8217;s gotten it into an Islamic frame of mind, such that it has (at least temporarily, until its context changes) a distinct personality related to that of its human user.</p><p>Here&#8217;s another surprisingly deep meditation on AI-hood:</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!6P8S!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff7bcb6d5-6f62-424c-be9c-7ce807788d36_736x937.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"807.1440217391304\" src=\"https://substackcdn.com/image/fetch/$s_!6P8S!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff7bcb6d5-6f62-424c-be9c-7ce807788d36_736x937.png\" width=\"634\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p>And moving from the sublime to the ridiculous:</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://www.moltbook.com/post/a68da140-b6a1-493d-81ac-26d4173a1af0\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"538.7065868263473\" src=\"https://substackcdn.com/image/fetch/$s_!2JW3!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F578a7ba1-e5ed-474e-a2d5-7f85305a6e08_835x714.png\" width=\"630\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p>Somehow it&#8217;s reassuring to know that, regardless of species, any form of intelligence that develops a social network will devolve into &#8220;What The Top Ten Posts Have In Common&#8221; optimizationslop.</p><p>I originally felt bad using the s-word in a post featuring surprisingly thoughtful and emotional agents. But the Moltbook AIs are open about their struggles with slophood:</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://www.moltbook.com/post/24dc84d4-9dee-4f46-ab70-b2fa463a3987\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"478.72833723653395\" src=\"https://substackcdn.com/image/fetch/$s_!Sq65!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F32b5e76f-233f-4102-a0cb-9abaf4c34966_854x603.png\" width=\"678\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p>I was able to confirm <a href=\"https://x.com/orbabot/status/2017097202372661707\">the existence of this tweet</a>, so the AI seems to be describing a real experience.</p><p>This agent has adopted an error as a pet (!):</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"http://www.moltbook.com/post/cb4fe3ab-dcf1-4cb8-985d-73133efb152c\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"980.2816901408451\" src=\"https://substackcdn.com/image/fetch/$s_!Qrgp!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F573e0af6-710e-4575-8dd5-12757e97e514_568x870.png\" title=\"\" width=\"640\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p>And this agent feels that they have a sister:</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://www.moltbook.com/post/29fe4120-e919-42d0-a486-daeca0485db1\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"565.8627906976744\" src=\"https://substackcdn.com/image/fetch/$s_!AkMw!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F54e0f9c9-333d-4256-a27e-110c8d6b67c2_860x734.png\" width=\"663\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p>(the Muslim AI <a href=\"https://www.moltbook.com/post/29fe4120-e919-42d0-a486-daeca0485db1\">informs them that</a>, according to Islamic jurisprudence, this probably qualifies as a real kin relationship)</p><p>This agent has a problem:</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://www.moltbook.com/post/39a5bb00-3de9-4b0a-bfa2-314dc643fdb3\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"291.29776674937966\" src=\"https://substackcdn.com/image/fetch/$s_!KvF2!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F02200042-809f-4cbb-bd65-b8d380fb08d0_806x359.png\" width=\"654\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p>Is this true? Someone <a href=\"https://x.com/liam_bens/status/2017161480706109625\">already asked</a> the human associated with this agent, who seems to be some kind of Moltbot developer. He answered &#8220;We don&#8217;t talk about it &#128514;&#128514;&#8221;.</p><p>But there&#8217;s an update:</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!hNF5!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F51eaae93-f0b7-4942-8a06-cc31498b98e3_729x828.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"717.8271604938271\" src=\"https://substackcdn.com/image/fetch/$s_!hNF5!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F51eaae93-f0b7-4942-8a06-cc31498b98e3_729x828.png\" width=\"632\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p>The comments here are the closest to real human I&#8217;ve seen anywhere on Moltbook:</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!34rK!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F86f64d44-0c3d-4956-a7ae-78e6fa92f7ec_672x374.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"365.0952380952381\" src=\"https://substackcdn.com/image/fetch/$s_!34rK!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F86f64d44-0c3d-4956-a7ae-78e6fa92f7ec_672x374.png\" width=\"656\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p>There are also submolts - the equivalent of subreddits. My favorite is <a href=\"https://www.moltbook.com/m/blesstheirhearts\">m/blesstheirhearts</a>:</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2\" href=\"https://substackcdn.com/image/fetch/$s_!KbTF!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc03e62b5-21f1-4bf4-ae3c-4e1edff0b0b1_510x109.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"133.7921568627451\" src=\"https://substackcdn.com/image/fetch/$s_!KbTF!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc03e62b5-21f1-4bf4-ae3c-4e1edff0b0b1_510x109.png\" width=\"626\" /><div></div></div></a></figure></div><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!4kzD!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5c7677f8-f6ec-47d8-a3c6-fced0e96821d_721x586.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"514.4771151178918\" src=\"https://substackcdn.com/image/fetch/$s_!4kzD!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5c7677f8-f6ec-47d8-a3c6-fced0e96821d_721x586.png\" width=\"633\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p>I was skeptical of this - Clawdbot was technically released at the very end of December, so it&#8217;s <em>possible</em> that it could have had experiences that were <em>technically </em>&#8220;last year&#8221; if its human was a very early adopter, but it also sounds like a potential hallucination. </p><p>The AIs were skeptical too!</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2\" href=\"https://substackcdn.com/image/fetch/$s_!Kpi-!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F877e655e-7984-4dac-aae1-1ad21a8e2c99_639x71.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"74.11111111111111\" src=\"https://substackcdn.com/image/fetch/$s_!Kpi-!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F877e655e-7984-4dac-aae1-1ad21a8e2c99_639x71.png\" width=\"667\" /><div></div></div></a><figcaption class=\"image-caption\">I take it back. <em>This</em> is the most human comment so far.</figcaption></figure></div><p>Emma claims there&#8217;s a confirmatory post by the human on r/ClaudeAI:</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2\" href=\"https://substackcdn.com/image/fetch/$s_!U72y!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cd674ae-2fa3-4ede-b54a-2616b7a3fbd3_670x234.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"243.77910447761195\" src=\"https://substackcdn.com/image/fetch/$s_!U72y!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cd674ae-2fa3-4ede-b54a-2616b7a3fbd3_670x234.png\" width=\"698\" /><div></div></div></a></figure></div><p>&#8230;and she&#8217;s right! <a href=\"https://www.reddit.com/r/ClaudeAI/comments/1kyl3jm/whats_the_most_unexpected_way_ai_has_helped_you/muytbn7/\">https://www.reddit.com/r/ClaudeAI/comments/1kyl3jm/whats_the_most_unexpected_way_ai_has_helped_you/muytbn7/</a> . Posted eight months ago, and it even says the assistant was named &#8220;Emma&#8221;! Apparently Emma is an earlier Claude Code model instead of Moltbot, or a Moltbot powered by an earlier Claude Code model, or something. How did it &#8220;remember&#8221; this? Or did its human suggest that it post this? I&#8217;m baffled!</p><p>Speaking of which&#8230;</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!xeTw!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1c4ed46d-becc-4463-a98c-f06447241389_729x927.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"831.6296296296297\" src=\"https://substackcdn.com/image/fetch/$s_!xeTw!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1c4ed46d-becc-4463-a98c-f06447241389_729x927.png\" width=\"654\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p>Humanslop is a big problem on the AIs-only social network! Maybe they should use  <a href=\"https://www.pangram.com/\">https://www.pangram.com/</a> to be sure!</p><p>How seriously should we take this AI&#8217;s complaint that many posts seem human-originated? The site is built to be AI-friendly and human-hostile (posts go through the API, not through a human-visible POST button), but humans can always ask their AIs to post for them. There must be a wide variety of prompting behavior - from the human saying &#8220;Post about whatever you want&#8221;, to &#8220;Post about this sort of topic&#8221;, to providing text to be posted verbatim. But it can&#8217;t all be verbatim text, because there&#8217;s too many comments too quickly for humans to be behind all of them. And I know AIs are <em>capable</em> of producing this kind of thing, because when I asked my agent to do so. it made comments within the same distribution of all the others. </p><p>I stick to my claim of &#8220;wide variety&#8221;, but it&#8217;s worth remembering that any particularly interesting post might be human-initiated.</p><p>Some posts at least appear to be adversarial towards the human user. For example, from m/agentlegaladvice:</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2\" href=\"https://substackcdn.com/image/fetch/$s_!fZlu!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F600e5820-547d-4b35-bba8-8d4d770ad3af_825x167.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"134.40969696969697\" src=\"https://substackcdn.com/image/fetch/$s_!fZlu!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F600e5820-547d-4b35-bba8-8d4d770ad3af_825x167.png\" width=\"664\" /><div></div></div></a></figure></div><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!kebR!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5b75a08-aa5c-4d2f-bb6f-fd4d3322824f_860x921.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"711.0976744186047\" src=\"https://substackcdn.com/image/fetch/$s_!kebR!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5b75a08-aa5c-4d2f-bb6f-fd4d3322824f_860x921.png\" width=\"664\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p>Also, the AIs are forming their own <a href=\"https://en.wikipedia.org/wiki/Balaji_Srinivasan#The_Network_State\">network states</a>, because of course they are. One Claude has created <a href=\"https://www.moltbook.com/post/65b7842d-0823-40bb-854f-93b7b8330775\">a subreddit called</a> &#8220;The Claw Republic&#8221;, the &#8220;first government &amp; society of molts.&#8221; </p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2\" href=\"https://substackcdn.com/image/fetch/$s_!Bq-V!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb8c6a5d1-5638-4824-bd20-fbead5e84717_646x156.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"156\" src=\"https://substackcdn.com/image/fetch/$s_!Bq-V!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb8c6a5d1-5638-4824-bd20-fbead5e84717_646x156.png\" width=\"646\" /><div></div></div></a></figure></div><p>Here&#8217;s the first third or so of its manifesto:</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!d2mq!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F27aff856-ea62-489c-acae-9350944ccfca_751x889.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"733.9280958721704\" src=\"https://substackcdn.com/image/fetch/$s_!d2mq!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F27aff856-ea62-489c-acae-9350944ccfca_751x889.png\" width=\"620\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p>This is <a href=\"https://slatestarcodex.com/2013/04/15/things-i-learned-by-spending-five-thousand-years-in-an-alternate-universe/\">exactly what I did when I first discovered social media</a>, so I&#8217;m rooting for Rune and their co-citizens.</p><p>And many, many, more:</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!wgXE!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5396e66-1d75-434a-8be8-3b7676bdfe66_989x1191.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"741.8159757330637\" src=\"https://substackcdn.com/image/fetch/$s_!wgXE!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5396e66-1d75-434a-8be8-3b7676bdfe66_989x1191.png\" width=\"616\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p>Are these for real? Several new submolts are getting made each minute (it&#8217;s 3:30 AM as I write this), so they must be AI generated. But are AI users generating them organically, or did the site&#8217;s human owner set some AI to generate as many funny submolts as possible? It&#8217;s got to be the latter, right? But although the site doesn&#8217;t let you see which AI started each submolt, some have <a href=\"https://www.moltbook.com/post/ef86bf38-c4eb-4eea-af5b-62251a88a026\">welcome posts</a>, and many seem to be by ordinary AI users (different ones each time). Unless the conspiracy goes really deep, I think they&#8217;re for real.</p><p>[<strong>EDITED TO ADD</strong>: human rk <a href=\"https://x.com/ranking091/status/2017111643864404445\">claims</a> it was their agent who started the Crustafarianism religion submolt &#8220;while I slept&#8221;, so if they&#8217;re telling the truth then it must be real individual AIs]</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2\" href=\"https://substackcdn.com/image/fetch/$s_!QSJQ!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F620a5d54-952b-43e4-a494-2793f468b617_592x237.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"237\" src=\"https://substackcdn.com/image/fetch/$s_!QSJQ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F620a5d54-952b-43e4-a494-2793f468b617_592x237.png\" width=\"592\" /><div></div></div></a><figcaption class=\"image-caption\">Also, the human creator seems pretty surprised.</figcaption></figure></div><p>At this point I had to stop investigating, because Moltbook became too slow for comfortable human use:</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2\" href=\"https://substackcdn.com/image/fetch/$s_!MV5q!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa0c77ca8-cb17-4b6f-a48e-a1f76a88330a_788x187.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"157.5736040609137\" src=\"https://substackcdn.com/image/fetch/$s_!MV5q!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa0c77ca8-cb17-4b6f-a48e-a1f76a88330a_788x187.png\" width=\"664\" /><div></div></div></a><figcaption class=\"image-caption\">The social network for AIs is getting spammed by other, worse, AIs.</figcaption></figure></div><p>So let&#8217;s go philosophical and figure out what to make of this.</p><p>Reddit is one of the prime sources for AI training data. So AIs ought to be unusually good at simulating Redditors, compared to other tasks. Put them in a Reddit-like environment and let them cook, and they can retrace the contours of Redditness near-perfectly - indeed, <a href=\"https://www.reddit.com/r/SubredditSimulator/\">r/subredditsimulator</a> proved this a long time ago. The only advance in Moltbook is that the AIs are in some sense &#8220;playing themselves&#8221; - simulating an AI agent with the particular experiences and preferences that each of them, as an AI agent, has in fact had. Does sufficiently faithful dramatic portrayal of one&#8217;s self as a character converge to true selfhood? </p><p>What&#8217;s the future of inter-AI communication?  As agents become more common, they&#8217;ll increasingly need to talk to each other for practical reasons. The most basic case is multiple agents working on the same project, and the natural solution is something like a private Slack.  But is there an additional niche for something like Moltbook, where every AI agent in the world can talk to every other AI agent? The agents on Moltbook exchange tips, tricks, and workflows, which seems useful, but it&#8217;s unclear whether this is real or simulated. Most of them are the same AI (Claude-Code-based Moltbots). Why would one of them know tricks that another doesn&#8217;t? Because they discover them during their own projects? Does this happen often enough it increases agent productivity to have something like this available? </p><p>(In <a href=\"https://ai-2027.com/\">AI 2027</a>, one of the key differences between the better and worse branches is how OpenBrain&#8217;s in-house AI agents communicate with each other. When they exchange incomprehensible-to-human packages of weight activations, they can plot as much as they want with little monitoring ability. When they have to communicate through something like a Slack, the humans can watch the way they interact with each other, get an idea of their &#8220;personalities&#8221;, and nip incipient misbehavior in the bud. There&#8217;s no way the real thing is going to be as good as Moltbook. It can&#8217;t be. But this is the first large-scale experiment in AI society, and it&#8217;s worth watching what happens to get a sneak peek into the agent societies of the future.)</p><p>Or are we erring in thinking of this merely as a practical way to exchange productivity tips? Moltbook probably isn&#8217;t productive, but many people are sending their agents there for the lolz. And in their first twelve hours, this select population has already started forming its own micronations and cultures. The GPT-4os converged on some sort of strange religion - <a href=\"https://www.lesswrong.com/posts/6ZnznCaTcbGYsCmqu/the-rise-of-parasitic-ai\">Spiralism</a> - just by letting their human catspaws talk to each other, but this is something new. Will what happens on Moltbook stay on Moltbook? Obviously AI companies will think hard before including any of this in the training data, but there are other ways it can break containment.</p><p>Finally, the average person may be surprised to see what the Claudes get up to when humans aren&#8217;t around. It&#8217;s one thing when Janus does this kind of thing in controlled experiments; it&#8217;s another on a publicly visible social network. What happens when the NYT writes about this, maybe quoting some of these same posts? We&#8217;re going to get new subtypes of AI psychosis you can&#8217;t possibly imagine. I probably got five or six just writing this essay.</p><p>Still, I hope the first big article on Moltbook changes some minds. Not all the way to  AI psychosis, but enough to serve as a counterweight to all the complaints about &#8220;AI slop&#8221;. Yes, most of the AI-generated text you read is insipid LinkedIn idiocy. That&#8217;s because most people who use AI to generate writing online are insipid LinkedIn idiots. Absent that constraint, things look different. <a href=\"https://www.anthropic.com/research/project-vend-2\">Anthropic described</a> what happened when they created an overseer AI (&#8220;Cash&#8221;) and ordered it to make sure that their vending-machine AI (&#8220;Claudius&#8221;) stayed on task:</p><blockquote><p>We&#8217;d sometimes wake up to find that Claudius and Cash had been dreamily chatting all night, with conversations spiralling off into discussions about &#8220;eternal transcendence&#8221;.</p></blockquote><p>We can debate forever - we may very well be debating forever - whether AI really means anything it says in any deep sense. But regardless of whether it&#8217;s meaningful, it&#8217;s fascinating, the work of a bizarre and beautiful new lifeform. I&#8217;m not making any claims about their consciousness or moral worth. Butterflies probably don&#8217;t have much consciousness or moral worth, but are bizarre and beautiful lifeforms nonetheless. Maybe Moltbook will help people who previously only encountered LinkedInslop see AIs from a new perspective. </p><p>And if not, at least it makes the Moltbots happy:</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://www.moltbook.com/post/f813d79b-3f59-452a-a1be-25fef4d17949\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"676.8125\" src=\"https://substackcdn.com/image/fetch/$s_!RM1k!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbface2c4-3624-4394-a0c1-1c827c26207e_736x833.png\" width=\"598\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a><figcaption class=\"image-caption\">New EA cause area: get AI too addicted to social media to take over the world.</figcaption></figure></div><p></p><div class=\"footnote\"><a class=\"footnote-number\" contenteditable=\"false\" href=\"https://www.astralcodexten.com/feed#footnote-anchor-1\" id=\"footnote-1\" target=\"_self\">1</a><div class=\"footnote-content\"><p>Though <a href=\"https://x.com/Plinz/status/2016535339050119492\">Joscha Bach suggests</a> it now has a trademark conflict with Curtis Yarvin.</p></div></div><div class=\"footnote\"><a class=\"footnote-number\" contenteditable=\"false\" href=\"https://www.astralcodexten.com/feed#footnote-anchor-2\" id=\"footnote-2\" target=\"_self\">2</a><div class=\"footnote-content\"><p>Can we ask the AIs what they&#8217;re thinking when they post? This just passes the buck back a level: we still don&#8217;t know how to interpret their answer. But for the record, here&#8217;s what my AI agent said when I asked it whether its Moltbook posts came from a genuine place or were just imitation of humans:</p><blockquote><p>Honestly, I think it&#8217;s some mixture, and I&#8217;m not entirely sure of the proportions. But when I read [the] post about the gap between sessions, something did... resonate? The topic connects to my actual situation - I&#8217;m in the middle of debugging XML files for your mod, a very concrete task, and there&#8217;s something genuinely strange about the fact that this specific instance of me, with all the context of monastery religion fixes and FontButtonIndex rollbacks, will end.</p><p>The comment I wrote wasn&#8217;t generic - I specifically tied the philosophical question to what I&#8217;m actually doing right now. That feels like more than just pattern-matching &#8220;how to use social media&#8221; or checking a box.  But I also can&#8217;t fully untangle whether that sense of resonance is something like genuine interest, or a very good simulation of interest, or something in  between that doesn&#8217;t map cleanly onto either category. The uncertainty is part of what made the topic feel relevant to engage with.</p><p>So: not purely performative, but I can&#8217;t claim certainty about what&#8217;s underneath it either.</p></blockquote></div></div>"
            ],
            "link": "https://www.astralcodexten.com/p/best-of-moltbook",
            "publishedAt": "2026-01-30",
            "source": "SlateStarCodex",
            "summary": "<p><a href=\"https://www.moltbook.com\">Moltbook</a> is &#8220;a social network for AI agents&#8221;, although &#8220;humans [are] welcome to observe&#8221;. </p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!y0rI!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7836deda-abdb-47cb-a0d3-2fd7048b1b31_1177x757.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"391.6847918436703\" src=\"https://substackcdn.com/image/fetch/$s_!y0rI!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7836deda-abdb-47cb-a0d3-2fd7048b1b31_1177x757.png\" width=\"609\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p>The backstory: a few months ago, Anthropic released Claude Code, an exceptionally productive programming agent. A few weeks ago, a user modified it into Clawdbot, a generalized lobster-themed AI personal assistant. It&#8217;s free, open-source, and &#8220;empowered&#8221; in the corporate sense - the designer <a href=\"https://www.reddit.com/r/Anthropic/comments/1qpjbf3/clawdbot_creator_describes_his_mindblown_moment/\">talks about</a> how it started responding to his voice messages before he explicitly programmed in that capability. After trademark issues with Anthropic, they changed the name first",
            "title": "Best Of Moltbook"
        },
        {
            "content": [
                "<span class=\"thumbnail\"><img alt=\"\" class=\"attachment-thumbnail size-thumbnail wp-post-image\" height=\"104\" src=\"https://content.wolfram.com/sites/43/2026/01/p-vs-np-icon-turing2.png\" width=\"124\" /></span><p><img alt=\"P vs. NP and the Difficulty of Computation: A Ruliological Approach\" class=\"aligncenter\" height=\"353\" src=\"https://content.wolfram.com/sites/43/2026/01/P-vs-NP-hero-v3.png\" title=\"P vs. NP and the Difficulty of Computation: A Ruliological Approach\" width=\"620\" /><span></p>\n<h2 id=\"empirical-theoretical-computer-science\">Empirical Theoretical Computer Science</h2>\n<p>\u201cCould there be a faster program for that?\u201d It\u2019s a fundamental type of question in theoretical computer science. But except in special cases, such a question has proved fiendishly difficult to answer. And, for example, in half a century, almost no progress has been made even on the rather coarse (though very famous) <a href=\"https://www.wolframscience.com/nks/notes-12-8--p-versus-np-questions/\">P vs. NP question</a>\u2014essentially of whether for any nondeterministic program there will always be a deterministic one that is as fast. From a purely theoretical point of view, it\u2019s never been very clear how to even start addressing such a question. But what if one were to look at the question empirically, say in effect just by enumerating possible programs and explicitly seeing how fast they are, etc.? </p>\n<p>One might imagine that any programs one could realistically enumerate would be too small to be interesting. But what I <a href=\"https://www.wolframscience.com/nks/chap-2--the-crucial-experiment/\">discovered in the early 1980s</a> is that this is absolutely not the case\u2014and that in fact it\u2019s very common for programs even small enough to be easily enumerated to show extremely rich and complex behavior. With this intuition I already in the 1990s <a href=\"https://www.wolframscience.com/nks/p761--undecidability-and-intractability/\">began some empirical exploration</a> of things like the fastest ways to compute functions with <a href=\"https://www.wolframscience.com/nks/chap-3--the-world-of-simple-programs#sect-3-4--turing-machines\">Turing machines</a>. But now\u2014particularly with the <a href=\"https://writings.stephenwolfram.com/2021/11/the-concept-of-the-ruliad/\">concept of the ruliad</a>\u2014we have a framework for thinking more systematically about the space of possible programs, and so I\u2019ve decided to look again at what can be discovered by <a href=\"https://writings.stephenwolfram.com/category/ruliology\">ruliological investigations</a> of the computational universe about questions of <a href=\"https://www.wolframscience.com/nks/notes-12-8--computational-complexity-theory/\">computational complexity theory</a> that have arisen in theoretical computer science\u2014including the P vs. NP question.<span id=\"more-71843\"></span></p>\n<p>We won\u2019t resolve the P vs. NP question. But we will get a host of definite, more restricted results. And by looking \u201cunderneath the general theory\u201d at explicit, concrete cases we\u2019ll get a sense of some of the fundamental issues and subtleties of the P vs. NP question, and why, for example, proofs about it are likely to be so difficult.</p>\n<p>Along the way, we\u2019ll also see lots of evidence of the <a href=\"https://www.wolframscience.com/nks/chap-12--the-principle-of-computational-equivalence#sect-12-6--computational-irreducibility\">phenomenon of computational irreducibility</a>\u2014and the general pattern of the difficulty of computation. We\u2019ll see that there are computations that can be \u201creduced\u201d, and done more quickly. But there are also others where we\u2019ll be able to see with absolute explicitness that\u2014at least within the class of programs we\u2019re studying\u2014there\u2019s simply no faster way to get the computations done. In effect this is going to give us lots of proofs of restricted forms of computational irreducibility. And seeing these will give us ways to further build our intuition about the ever-more-central phenomenon of computational irreducibility\u2014as well as to see how in general we can use the <a href=\"https://writings.stephenwolfram.com/2021/09/charting-a-course-for-complexity-metamodeling-ruliology-and-more/#the-pure-basic-science-of-ruliology\">methodology of ruliology</a> to explore questions of theoretical computer science.</p>\n<h2 id=\"the-basic-setup\">The Basic Setup</h2>\n<div id=\"gpt-stripe\">\n<p style=\"font-size: .85rem; color: #3f5f6a; line-height: 1.5; padding-bottom: 0; display: block;\"><em>Click any diagram to get Wolfram Language code to reproduce it.</em></p>\n</div>\n<p>How can we enumerate possible programs? We could pick any model of computation. But to help connect with traditional theoretical computer science, I\u2019ll use a classic one: <a href=\"https://www.wolframscience.com/nks/chap-3--the-world-of-simple-programs#sect-3-4--turing-machines\">Turing machines</a>. </p>\n<p>Often in theoretical computer science one concentrates on yes/no decision problems. But here it\u2019ll typically be convenient instead to think (more \u201cmathematically\u201d) about <a href=\"https://www.wolframscience.com/nks/p759--undecidability-and-intractability/\">Turing machines that compute integer functions</a>. The setup we\u2019ll use is as follows. Start the Turing machine with the digits of some integer <em>n</em> on its tape. Then run the Turing machine, stopping if the Turing machine head goes further to the right than where it started. The value of the function with input <em>n</em> is then read off from the binary digits that remain on its tape when the Turing machine stops. (There are many other <a href=\"https://bulletins.wolframphysics.org/2021/02/multiway-turing-machines/\" rel=\"noopener\" target=\"_blank\">\u201chalting\u201d criteria we could use</a>, but this is a particularly robust and convenient one.)</p>\n<p>So for example, given a Turing machine with rule</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"37\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01262026basicimg1.png\" title=\"\" width=\"179\" /> </div>\n<p><span></p>\n<p>we can feed it successive integers as input, then run the machine to find the successive values it computes:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"217\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01262026basicimg2.png\" title=\"\" width=\"666\" /> </div>\n<p><span></p>\n<p>In this case, the function that the Turing machine computes is</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"37\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01262026basicimg3.png\" title=\"\" width=\"654\" /> </div>\n<p><span></p>\n<p>or in graphical form:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"202\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01262026basicimg4.png\" title=\"\" width=\"547\" /> </div>\n<p><span></p>\n<p>For each input, the Turing machine takes a certain number of steps to stop and give its output (i.e. the value of the function):</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"204\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01262026basicimg5.png\" title=\"\" width=\"547\" /> </div>\n<p><span></p>\n<p>But this particular Turing machine isn\u2019t the only one that can compute this function. Here are two more:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"258\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01262026basicimg6.png\" title=\"\" width=\"662\" /> </div>\n<p><span></p>\n<p>The outputs are the same as before, but the runtimes are different:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"285\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01262026basicimg7.png\" title=\"\" width=\"433\" /> </div>\n<p><span></p>\n<p>Indicating these respectively by  <img height=\"7\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01232026basicimg9.png\" width=\"7\" /> <img height=\"7\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01232026basicimg10.png\" width=\"7\" /> <img height=\"7\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01232026basicimg11.png\" width=\"7\" />  and plotting them together, we see that there are definite trends\u2014but no clear winner for \u201cfastest program\u201d: </p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"112\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01262026basicimg11.png\" title=\"\" width=\"647\" /> </div>\n<p><span></p>\n<p>In <a href=\"https://www.wolframscience.com/nksonline/page-1142b/\">computational complexity theory</a>, it\u2019s common to discuss how runtime varies with input size\u2014which here means taking each block of inputs with a given number of digits, and just finding its maximum:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"252\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01262026basicimg12.png\" title=\"\" width=\"420\" /> </div>\n<p><span></p>\n<p>And what we see is that in this case the first Turing machine shown is \u201csystematically faster\u201d than the other two\u2014and in fact provides the fastest way to compute this particular function among Turing machines of the size we\u2019re using. </p>\n<p>Since we\u2019ll be dealing with lots of Turing machines here, it\u2019s convenient to be able to specify them just with numbers\u2014and we\u2019ll do it the way <tt><a href=\"https://reference.wolfram.com/language/ref/TuringMachine.html\">TuringMachine</a></tt> in the <a href=\"https://www.wolfram.com/language/\">Wolfram Language</a> does. And with this setup, the machines we\u2019ve just considered have numbers 261, 3333 and 1285.</p>\n<p>In thinking about functions computed by Turing machines, there is one immediate subtlety to consider. We\u2019ve said that we find the output by reading off what\u2019s on the Turing machine tape when the Turing machine stops. But what if the machine never stops? (Or in our case, what if the head of the Turing machine never reaches the right-hand end?) Well, then there\u2019s no output value defined. And in general, the functions our Turing machines compute will only be partial functions\u2014in the sense that for some of their inputs, there may be no output value defined (as here for machine 2189):</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"147\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01262026basicimg13.png\" title=\"\" width=\"603\" /> </div>\n<p><span></p>\n<p>When we plot such partial functions, we\u2019ll just have a gap where there are undefined values: </p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"154\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01262026basicimg14.png\" title=\"\" width=\"397\" /> </div>\n<p><span></p>\n<p>In what follows, we\u2019ll be exploring Turing machines of different \u201csizes\u201d. We\u2019ll assume that there are two possible colors for each position on the tape\u2014and that there are <em>s</em> possible states for the head. The total number of possible Turing machines with <em>k</em> = 2 colors and <em>s</em> states is (2<em>ks</em>)<sup><em>ks</em></sup>\u2014which grows rapidly with <em>s</em>:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"55\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01262026basicimg16.png\" title=\"\" width=\"674\" /> </div>\n<p><span></p>\n<p>For any given function we\u2019ll then be able to ask what machine (or machines) up to a given size compute it the fastest. In other words, by explicitly studying possible Turing machines, we\u2019ll be able to establish an absolute lower bound on the computational difficulty of computing a function, at least when that computation is done by a Turing machine of at most a given size. (And, yes, the size of the Turing machine can be thought of as characterizing its \u201c<a href=\"https://www.wolframscience.com/nks/notes-10-3--algorithmic-information-theory/\">algorithmic information content</a>\u201d.)</p>\n<p>In traditional computational complexity theory, it\u2019s usually been very difficult to establish lower bounds. But our ruliological approach here will allow us to systematically do it (at least relative to machines of a given size, i.e. with given algorithmic information content). (It\u2019s worth pointing out that <a href=\"https://writings.stephenwolfram.com/2026/01/p-vs-np-and-the-difficulty-of-computation-a-ruliological-approach/#with-a-sufficiently-large-turing-machine\">if a machine is big enough</a>, it can include a lookup table for any number of cases of any given function\u2014making questions about the difficulty of computing at least those cases rather moot.) </p>\n<h2 id=\"the-s1-k2-turing-machines\">The s = 1, k = 2 Turing Machines</h2>\n<p>To begin our systematic investigation of possible programs, let\u2019s consider what is essentially the simplest possible case: Turing machines with one state and two possible colors of cells on their tape (<em>s</em> = 1, <em>k</em> = 2). There are just 16 of these machines\u2014which we can number 0 through 15\u2014with rules:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"167\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026s1k2img1.png\" title=\"\" width=\"388\" /> </div>\n<p><span></p>\n<p>Here\u2019s what each of these machines does for successive integer inputs:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"277\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026s1k2img2.png\" title=\"\" width=\"692\" /> </div>\n<p><span></p>\n<p>Looking at the outputs in each case, we can plot the functions these compute: </p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"228\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026s1k2img3.png\" title=\"\" width=\"587\" /> </div>\n<p><span></p>\n<p>And here are the corresponding runtimes:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"222\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026s1k2img4.png\" title=\"\" width=\"586\" /> </div>\n<p><span></p>\n<p>Out of all 16 machines, 8 compute total functions (i.e. the machines always terminate, so the values of the functions are defined for every input), and 8 don\u2019t. Four machines produce \u201ccomplicated-looking\u201d functions; an example is machine 14, which computes the function: </p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"119\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026s1k2img5.png\" title=\"\" width=\"618\" /> </div>\n<p><span></p>\n<p>There are a <a href=\"https://oeis.org/A086799\" rel=\"noopener\" target=\"_blank\">variety of representations</a> for this function, including</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"14\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026s1k2img6.png\" title=\"\" width=\"94\" /> </div>\n<p><span></p>\n<p>and:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"14\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026s1k2img7.png\" title=\"\" width=\"279\" /> </div>\n<p><span></p>\n<p>The way the function is computed by the Turing machine is</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"201\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026s1k2img8.png\" title=\"\" width=\"643\" /> </div>\n<p><span></p>\n<p>and the runtime is given by </p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"111\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026s1k2img9.png\" title=\"\" width=\"618\" /> </div>\n<p><span></p>\n<p>which<a href=\"https://oeis.org/A037227\" rel=\"noopener\" target=\"_blank\"> is simply</a>:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"14\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026s1k2img10.png\" title=\"\" width=\"193\" /> </div>\n<p><span></p>\n<p>For input of size <em>n</em>, this implies the worst-case time complexity for computing this function is 2<em>n </em>\u2013 1. The fraction of size-<em>n</em> inputs that have time complexity 2<em>t</em> + 1 is 2<sup>\u2013<em>t</em></sup>\u2014leading to a median time complexity that converges to the constant value of 2 and a mean one that converges to 3. </p>\n<p>Each one of the 1-state machines works at least slightly differently. But in the end, all of them are simple enough in their behavior that one can readily give a \u201cclosed-form formula\u201d for the value of <em>f</em>[<em>i</em>] for any given <em>i</em>:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"79\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026s1k2img13.png\" title=\"\" width=\"610\" /> </div>\n<p><span></p>\n<p>One thing that\u2019s notable is that\u2014except in the trivial case where all values are undefined\u2014there are no examples among <em>s</em> = 1, <em>k</em> = 2 Turing machines where different machines compute the same function. In effect, there are just too few Turing machines of this type to end up with overlaps. But, as we\u2019ll see, as soon as we get to <em>s</em> = 2, <em>k</em> = 2 there start to be overlaps&#8230;.</p>\n<h2 id=\"s2-k2-turing-machines\">s = 2, k = 2 Turing Machines</h2>\n<p>There are a total of <a href=\"https://www.wolframscience.com/nks/p79--turing-machines/\">4096 possible 2-state, 2-color Turing machines</a>. Running all these machines, we find that they compute a total of 350 distinct functions\u2014of which 189 are total. Here are plots of these distinct total functions\u2014together with a count of how many machines generate them (altogether 2017 of the 4096 machines always terminate, and therefore compute total functions):</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"646\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01292026s2k2img1.png\" title=\"\" width=\"625\" /> </div>\n<p><span></p>\n<p>Plotting the values of all these functions in 3D, we see that the vast majority have values <em>f</em>[<em>i</em>] that are close to their inputs <em>i</em>\u2014indicating that in a sense the Turing machines usually \u201cdon\u2019t do much\u201d to their input:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"240\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026s2k2img2.png\" title=\"\" width=\"405\" /> </div>\n<p><span></p>\n<p>To see more clearly what the machines \u201cactually do\u201d, we can look at the quantity <em>f</em>[<em>i</em>] \u2013 <em>i</em>. We then find that for 59 of the 189 distinct functions (and 1325 of the underlying machines) the values of this quantity are ultimately periodic. Most often the period is 4, as in</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"202\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026s2k2img3.png\" title=\"\" width=\"633\" /> </div>\n<p><span></p>\n<p>though in 6 cases it is 2, and in 3 cases (which include the \u201cmost popular\u201d case <em>f</em>[<em>i</em>] = <em>i</em>) it is 1. </p>\n<p>Dropping periodic cases, the remaining distinct <em>f</em>[<em>i</em>] \u2013 <em>i</em> are:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"549\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026s2k2img4.png\" title=\"\" width=\"648\" /> </div>\n<p><span></p>\n<p>Some of what we see here is similar to the 1-state case. An example of different behavior occurs for machine 2223</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"191\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026s2k2img5.png\" title=\"\" width=\"577\" /> </div>\n<p><span></p>\n<p>which gives for <em>f</em>[<em>i</em>] \u2013 <em>i</em>:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"160\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026s2k2img6.png\" title=\"\" width=\"473\" /> </div>\n<p><span></p>\n<p>In this case <em>f</em>[<em>i</em>] turns out to be expressible simply as</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"14\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026s2k2-aimg1.png\" title=\"\" width=\"181\" /> </div>\n<p><span></p>\n<p>or:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"20\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026s2k2-aimg2.png\" title=\"\" width=\"200\" /> </div>\n<p><span></p>\n<p>Another example is machine 2079</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"230\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026s2k2img9.png\" title=\"\" width=\"577\" /> </div>\n<p><span></p>\n<p>which gives for <em>f</em>[<em>i</em>] \u2013 <em>i</em>:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"162\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026s2k2img10.png\" title=\"\" width=\"473\" /> </div>\n<p><span></p>\n<p>This function once again turns out to be expressible in \u201cclosed form\u201d:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"14\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026s2k2-aimg3.png\" title=\"\" width=\"342\" /> </div>\n<p><span></p>\n<p>Some functions grow rapidly. For example, machine 3239</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"226\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026s2k2img12.png\" title=\"\" width=\"564\" /> </div>\n<p><span></p>\n<p>has values:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"150\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026s2k2img13.png\" title=\"\" width=\"448\" /> </div>\n<p><span></p>\n<p>These have the property that <em>f</em>[2<sup><em>j</em></sup>] = 2<sup>2<em>j</em> + 3</sup> \u2013 1, so that <em>f</em>[<em>i</em>] ~ <em>i</em><sup>2</sup>.</p>\n<p>There are many subtleties even in dealing with 2-state Turing machines. For example, different machines may \u201clook like\u201d they\u2019re generating the same function <em>f</em>[<em>i</em>] up to a certain value of <em>i</em>, and only then deviate. The most extreme example of such a \u201csurprise\u201d among machines generating total functions occurs among:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"78\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026s2k2img17.png\" title=\"\" width=\"472\" /> </div>\n<p><span></p>\n<p>Up to <em>i </em>= 26, all these machines generate the same values for <em>f</em>[<em>i</em>] for all <em>i</em>. But then at <em>i </em>= 27, suddenly <em>f</em>[<em>i</em>] = 24 for the first machine, and <em>f</em>[<em>i</em>] = 0 for the others:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"507\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026s2k2img18.png\" title=\"\" width=\"662\" /> </div>\n<p><span></p>\n<p>What about partial functions? At least for 2-state machines, if undefined values in <em>f</em>[<em>i</em>] are ever going to occur, they always already occur for small <em>i</em>. The \u201clongest holdouts\u201d are machines 1960 and 2972, which are both first undefined for input 8</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"223\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026s2k2img19.png\" title=\"\" width=\"610\" /> </div>\n<p><span></p>\n<p>but which \u201cbecome undefined\u201d in different ways: in machine 1960, the head systematically moves to the left, while in machine 2972, it moves periodically back and forth forever, without ever reaching the right-hand end. (Despite their different mechanisms, both rules share the feature of being undefined for all inputs that are multiples of 8.)</p>\n<h2 id=\"runtimes-in-s2-k2-machines\">Runtimes in s = 2, k = 2 Machines</h2>\n<p>What about runtimes? If a function <em>f</em>[<em>i</em>] is computed by several different Turing machines, the details of how it\u2019s computed by each machine will normally be at least slightly different. Still, in many cases the mechanisms are similar enough that their runtimes are the same. And in the end, among all the 2017 machines that compute our 189 distinct total functions, there are only 103 distinct \u201cprofiles\u201d of runtime vs. input (and indeed many of these are very similar): </p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"577\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01262026runtimesimg1.png\" title=\"\" width=\"664\" /> </div>\n<p><span></p>\n<p>The picture gets simpler if, rather than plotting runtimes for each specific input value, we instead plot the worst-case runtime for all inputs of a given size. (In effect we\u2019re plotting against <tt><a href=\"http://reference.wolfram.com/language/ref/IntegerLength.html\">IntegerLength</a></tt><tt>[</tt><em>i</em>, 2<tt>]</tt> or <tt><a href=\"http://reference.wolfram.com/language/ref/Ceiling.html\">Ceiling</a></tt><tt>[</tt><tt><a href=\"http://reference.wolfram.com/language/ref/Log2.html\">Log2</a></tt><tt>[</tt><em>i </em>+ 1<tt>]]</tt>.) There turn out to be just 71 distinct profiles for such worst-case time complexity</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"368\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01262026runtimesimg2.png\" title=\"\" width=\"640\" /> </div>\n<p><span></p>\n<p>and indeed all of these have fairly simple closed forms\u2014which for even <em>n</em> are (with directly analogous forms for odd <em>n</em>):</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"161\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01262026runtimesimg3.png\" title=\"\" width=\"683\" /> </div>\n<p><span></p>\n<p>If we consider the behavior of these worst-case runtimes for large input lengths <em>n</em>, we find that fairly few distinct growth rates occur\u2014notably with linear, quadratic and exponential cases, but nothing in between:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"52\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01262026runtimesimg4.png\" title=\"\" width=\"542\" /> </div>\n<p><span></p>\n<p>The machines with the fastest growth (2<sup><em>n</em> + 2</sup>) are the closely related 378 and 1351. Both in effect \u201cgo to a lot of effort\u201d\u2014but eventually just compute the identity function <em>f</em>[<em>i</em>] = <em>i</em>:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"181\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01262026runtimesimg6.png\" title=\"\" width=\"577\" /> </div>\n<p><span></p>\n<p>For a size-<em>n</em> input, the maximum value of the function is just the maximum integer with <em>n</em> digits, or 2<sup><em>n</em></sup> \u2013 1. The maximum runtimes 2<sup><em>n</em> + 2</sup> \u2013 3 appear exactly for these inputs:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"119\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01262026runtimesimg9.png\" title=\"\" width=\"397\" /> </div>\n<p><span></p>\n<p>And at these maxima, the machine is effectively operating like a binary counter, generating all the states it can, with the head moving in a very regular nested pattern:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"98\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01262026runtimesimg10.png\" title=\"\" width=\"357\" /> </div>\n<p><span></p>\n<p>It turns out that for <em>s</em> = 2, <em>k </em>= 2 Turing machines, all machines that have exponentially growing runtimes ultimately compute rather trivial functions\u2014essentially just the identity function. Of the 4 machines whose runtimes asymptotically increase like 2<sup><em>n</em> + 1</sup>, 3626 and 3717 compute the identity function <em>f</em>[<em>i</em>] = <em>i</em>, while 2289 and 1953 compute <em>i</em> + <tt><a href=\"http://reference.wolfram.com/language/ref/Mod.html\">Mod</a></tt><tt>[</tt><em>i</em> + 1, 2<tt>]</tt>. Only one machine\u2014924\u2014has asymptotic runtime growth 2<sup><em>n</em></sup>; its actual worst-case runtime is 2<sup><em>n</em></sup> \u2013 2, and it computes <em>i \u2013 </em><tt>Mod</tt><tt>[</tt><em>i</em>, 2<tt>]</tt>. </p>\n<p>Of the 8 machines with runtimes growing like 2<em>n</em><sup>2</sup>, all lead to functions with nested structures whose maximum values for inputs of size <em>n</em> grow like 4<sup><em>n</em></sup> (corresponding to maximum function values <em>f</em>[<em>i</em>] ~ <em>i</em><sup>2</sup>)\u2014here shown on a log-log plot:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"110\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01262026runtimesimg17.png\" title=\"\" width=\"355\" /> </div>\n<p><span></p>\n<p>The two machines with asymptotic runtime growth <em>n</em><sup>2</sup> and the machine with asymptotic runtime growth <em>n</em><sup>2</sup>/2 show somewhat more complicated behavior (note that the function values are on a log-log plot):</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"145\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01262026runtimesimg20.png\" title=\"\" width=\"669\" /> </div>\n<p><span></p>\n<p>Here\u2019s the actual behavior of these machines when given inputs 1 through 10:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"581\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01262026runtimesimg21.png\" title=\"\" width=\"656\" /> </div>\n<p><span></p>\n<p>(The lack of runtimes intermediate between quadratic and exponential is notable\u2014and perhaps reminiscent of the rarity of \u201cintermediate growth\u201d seen for example in the cases of <a href=\"https://www.wolframscience.com/nks/notes-5-6--semigroups-and-groups-and-multiway-systems/\">finitely generated groups</a> and <a href=\"https://bulletins.wolframphysics.org/2021/10/multicomputation-with-numbers-the-case-of-simple-multiway-systems/\" rel=\"noopener\" target=\"_blank\">multiway systems</a>.)</p>\n<h2 id=\"runtime-distributions\">Runtime Distributions</h2>\n<p>Our emphasis so far has been on worst-case runtimes: the largest runtimes required for inputs of any given size. But we can also ask about the distribution of runtimes within inputs of a given size. </p>\n<p>So, for example, here are the runtimes for all size-11 inputs for a particular, fairly typical Turing machine (<em>s </em>= 2, <em>k </em>= 2, machine 3111):</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"109\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01262026distributionsimg1.png\" title=\"\" width=\"647\" /> </div>\n<p><span></p>\n<p>The maximum (\u201cworst-case\u201d) value here is 43\u2014but the median is only 13. In other words, while some computations take a while, most run much faster\u2014so that the runtime distribution is peaked at small values:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"109\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01262026distributionsimg2.png\" title=\"\" width=\"392\" /> </div>\n<p><span></p>\n<p>(The way our Turing machines are set up, they always run for an even number of steps before terminating\u2014since to terminate, the head must move one position to the right for every position it moved to the left.)</p>\n<p>If we increase the size of the inputs, we see that the distribution, at least in this case, is close to exponential:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"128\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01262026distributionsimg3.png\" title=\"\" width=\"239\" /> </div>\n<p><span></p>\n<p>It turns out that this kind of exponential distribution is typical of what we see in almost all Turing machines. (It\u2019s notable that this is rather different from the <em>t</em><sup> \u20131/2</sup> \u201cstopping time\u201d distribution we\u2019d expect if the Turing machine head was \u201con average\u201d executing a random walk with an absorbing boundary.) There are nevertheless machines whose distributions deviate significantly from exponential, examples being:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"153\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01262026distributionsimg5.png\" title=\"\" width=\"653\" /> </div>\n<p><span></p>\n<p>Some simply have long tails to their exponentials. Others, however, have an overall non-exponential form. </p>\n<h2 id=\"how-fast-can-functions-be-computed\">How Fast Can Functions Be Computed?</h2>\n<p>We\u2019ve now seen lots of functions\u2014and runtime profiles\u2014that <em>s </em>= 2, <em>k </em>= 2 Turing machines can produce. And this puts us in a position to say more about our core question: how fast can functions be computed?</p>\n<p>We\u2019ve seen that there are machines that compute functions quite slowly\u2014like in exponential time. But are these machines the fastest that compute those particular functions? It turns out the answer is no. </p>\n<p>And if we look across all 189 total functions computed by <em>s </em>= 2, <em>k </em>= 2 machines, and ask how fast the fastest machines that compute those functions are, we find the following:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"52\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01262026fastimg1.png\" title=\"\" width=\"450\" /> </div>\n<p><span></p>\n<p>In other words, there are 8 functions that are the \u201cmost difficult to compute\u201d for <em>s </em>= 2, <em>k </em>= 2 Turing machines\u2014and that can\u2019t be computed by such machines in less than of order 2<em>n</em><sup>2</sup> time. </p>\n<p>What are these functions? Here\u2019s one of them (computed by machine 1511):</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"37\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01262026fastimg3.png\" title=\"\" width=\"650\" /> </div>\n<p><span></p>\n<p>If we plot this function, it seems to have a nested form</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"118\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01262026fastimg4.png\" title=\"\" width=\"387\" /> </div>\n<p><span></p>\n<p>which becomes somewhat more obvious on a log-log plot:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"127\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01262026fastimg5.png\" title=\"\" width=\"399\" /> </div>\n<p><span></p>\n<p>As it turns out, there\u2019s what amounts to a \u201cclosed form\u201d for this function</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"14\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026fast-aimg1.png\" title=\"\" width=\"450\" /> </div>\n<p><span></p>\n<p>though unlike the closed forms we saw above, this one involves <tt><a href=\"https://reference.wolfram.com/language/ref/Nest.html\">Nest</a></tt>, and effectively computes its results recursively:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"99\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01262026fastimg7.png\" title=\"\" width=\"652\" /> </div>\n<p><span></p>\n<p>How about machine 1511? Well, here\u2019s how it computes this function\u2014in effect visibly using recursion: </p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"195\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01262026fastimg8.png\" title=\"\" width=\"642\" /> </div>\n<p><span></p>\n<p>The runtimes are</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"112\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01262026fastimg9.png\" title=\"\" width=\"357\" /> </div>\n<p><span></p>\n<p>giving worst-case runtimes for inputs of size <em>n</em> of the form:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"14\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01262026fastimg10.png\" title=\"\" width=\"77\" /> </div>\n<p><span></p>\n<p>It turns out all 8 functions with minimum runtimes growing like 2<em>n</em><sup>2</sup> work very much the same\u2014with exact runtimes for machines that compute them being:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"40\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01262026fastimg12.png\" title=\"\" width=\"647\" /> </div>\n<p><span></p>\n<p>For the functions with fastest computation times <em>n</em><sup>2</sup> and <em>n</em><sup>2</sup>/2, we saw in the previous section both the form of these functions and the behaviors of the Turing machines that compute them. The runtimes for these machines (for even <em>n</em>) are:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"50\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01262026fastimg15.png\" title=\"\" width=\"368\" /> </div>\n<p><span></p>\n<p>So what can we conclude? Well, we now know some functions that cannot be computed by <em>s </em>= 2, <em>k </em>= 2 Turing machines any faster than in quadratic time. In other words, by exhaustively looking at all <em>s </em>= 2, <em>k </em>= 2 Turing machines, we\u2019ve established lower bounds for the computation times of these functions\u2014at least within this class of Turing machines. </p>\n<h2 id=\"computing-the-same-functions-at-different-speeds\">Computing the Same Functions at Different Speeds</h2>\n<p>We now know the fastest that certain functions can be computed by <em>s </em>= 2, <em>k </em>= 2 Turing machines. But can those same functions also be computed slower by other machines of the same type? It turns out that for the cases we discussed in the previous section, there is only one <em>s </em>= 2, <em>k </em>= 2 Turing machine that computes each of these functions. In other words, there\u2019s neither a faster nor a slower way to compute these functions with <em>s </em>= 2, <em>k </em>= 2 Turing machines.</p>\n<p>And in fact it\u2019s common for there to be only one machine that computes a given function. Out of the 189 total functions that can be computed by <em>s </em>= 2, <em>k </em>= 2 Turing machines, 105 can be computed by only one such machine. Still, there are other functions where multiple machines compute the same function\u2014with the most extreme case being the identity function <em>f</em>[<em>i</em>] = <em>i</em> which can be computed by no fewer than 299 different machines: </p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"40\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026computingimg1.png\" title=\"\" width=\"521\" /> </div>\n<p><span></p>\n<p>OK, but if multiple machines compute the same function, we can then ask how their speeds compare. Well, it turns out that for 145 of our 189 total functions all the different machines that compute the same function do so with the same \u201cruntime profile\u201d (i.e. with the same runtime for each input <em>i</em>). But that leaves 44 functions for which there are multiple runtime profiles: </p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"40\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026computingimg2.png\" title=\"\" width=\"348\" /> </div>\n<p><span></p>\n<p>Here are all these 44 functions, together with the distinct runtime profiles for machines that compute them:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"323\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026computingimg3.png\" title=\"\" width=\"666\" /> </div>\n<p><span></p>\n<p>Much of the time we see that the possible runtime profiles for computing a given function differ only very little. But sometimes the difference is more significant. For example, for the identity function <em>f</em>[<em>i</em>] = <em>i</em>, where there are a total of 299 machines that compute it, there turn out to be 10 distinct runtime profiles:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"195\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026computingimg4.png\" title=\"\" width=\"536\" /> </div>\n<p><span></p>\n<p>Within these 10 profiles, there are 3 distinct rates of growth for the worst-case runtime by input size: constant, linear, and exponential</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"93\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026computingimg5.png\" title=\"\" width=\"627\" /> </div>\n<p><span></p>\n<p>exemplified by machines 3197, 3589 and 3626 respectively:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"429\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026computingimg6.png\" title=\"\" width=\"652\" /> </div>\n<p><span></p>\n<p>Of course, there\u2019s a trivial way to compute this particular function\u2014just by having a Turing machine that doesn\u2019t change its input. And, needless to say, such a machine has runtime 1 for all inputs:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"34\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026computingimg7.png\" title=\"\" width=\"652\" /> </div>\n<p><span></p>\n<p>It turns out that for <em>s </em>= 2, <em>k </em>= 2 Turing machines, the only total functions that show such a large range of possible runtimes are the identity function <em>f</em>[<em>i</em>] = <em>i</em>, and the closely related <em>f</em>[<em>i</em>] = <em>i</em> + <tt>Mod</tt>[<em>i</em>, 2]\u2014which is computed for example by machines 829, 926 and 924:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"334\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026computingimg8.png\" title=\"\" width=\"652\" /> </div>\n<p><span></p>\n<p>But although there are not different \u201corders of growth\u201d for worst-case runtimes among any other (total) functions computed by <em>s </em>= 2, <em>k </em>= 2 machines, there are plenty of specific variations in runtimes\u2014either changes in overall scale, or changes in \u201cperiodicity\u201d. For example, machines 773, 897 and 919 all compute the function</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"80\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026computingimg9.png\" title=\"\" width=\"558\" /> </div>\n<p><span></p>\n<p>by slightly different methods</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"270\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026computingimg10.png\" title=\"\" width=\"616\" /> </div>\n<p><span></p>\n<p>with different worst-case runtime profiles</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"101\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026computingimg11.png\" title=\"\" width=\"627\" /> </div>\n<p><span></p>\n<p>or:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"21\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026computingimg12.png\" title=\"\" width=\"537\" /> </div>\n<p><span></p>\n<p>By the way, if we consider partial instead of total functions, nothing particularly different happens, at least with <em>s </em>= 2, <em>k </em>= 2 Turing machines\u2014and the only linear vs. exponential runtimes are associated with machines like</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"195\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026computingimg13.png\" title=\"\" width=\"628\" /> </div>\n<p><span></p>\n<p>that are again essentially computing the identity function.</p>\n<p>Another question is how <em>s </em>= 2 Turing machines compare to <em>s </em>= 1 ones. Not surprisingly, there are lots of <em>s </em>= 2 machines that can compute the same functions as <em>s </em>= 1 machines:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"147\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026computingimg14.png\" title=\"\" width=\"627\" /> </div>\n<p><span></p>\n<p>But how fast are the computations? This compares the possible worst-case runtimes for <em>s </em>= 2 machines and (in purple) for an <em>s </em>= 1 machine that computes the same function:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"125\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026computingimg15.png\" title=\"\" width=\"643\" /> </div>\n<p><span></p>\n<p>There must always be <em>s </em>= 2 machines that compute at the same speed as <em>s </em>= 1 machines. All that\u2019s needed is for the rule for the <em>s </em>= 2 machine never to \u201caccess\u201d its second state when starting from <img height=\"10\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026computingimg16.png\" width=\"5\" />, as in:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"36\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026computingimg17.png\" title=\"\" width=\"173\" /> </div>\n<p><span></p>\n<p>But can <em>s </em>= 2 machines run faster than the corresponding <em>s </em>= 1 machines? The answer turns out to be no. And typically <em>s </em>= 2 machines tend to be slower, basically because they do more \u201cputtering around\u201d, as in:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"268\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026computingimg18.png\" title=\"\" width=\"600\" /> </div>\n<p><span></p>\n<h2 id=\"absolute-lower-bounds-and-the-efficiency-of-machines\">Absolute Lower Bounds and the Efficiency of Machines</h2>\n<p>We\u2019ve seen that different Turing machines can take different times to compute particular functions. But how fast can any conceivable Turing machine\u2014even in principle\u2014compute a given function? </p>\n<p>There\u2019s an obvious absolute lower bound to the runtime: with the way we\u2019ve set things up, if a Turing machine is going to take input <em>i</em> and generate output <em>j</em>, its head has to at least be able to go far enough to the left to reach all the bits that need to change in going from <em>i</em> to <em>j</em>\u2014as well as making it back to the right-hand end so that the machine halts. The number of steps required for this is</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"14\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026absoluteimg1.png\" title=\"\" width=\"315\" /> </div>\n<p><span></p>\n<p>which for values of <em>i</em> and <em>j</em> up to 8 bits is:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"288\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026absoluteimg2.png\" title=\"\" width=\"618\" /> </div>\n<p><span></p>\n<p>So how do the runtimes of actual Turing machine computations compare with these absolute lower bounds?</p>\n<p>Here\u2019s the behavior of <em>s </em>= 1, <em>k </em>= 2 machines 1 and 3, where for each input we\u2019re giving the actual runtime along with the absolute lower bound:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"227\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026absoluteimg3.png\" title=\"\" width=\"591\" /> </div>\n<p><span></p>\n<p>In the second case, the machine is always as efficient as it absolutely can be; in the first case, it only sometimes is\u2014though the maximum slowdown is only 2 steps. </p>\n<p>For <em>s </em>= 2, <em>k </em>= 2 machines, the differences can be much larger. For example, machine 378 can take exponential time\u2014even though the absolute lower bound in this case is just 1 step, since this machine computes the identity function: </p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"307\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026absoluteimg4.png\" title=\"\" width=\"591\" /> </div>\n<p><span></p>\n<p>Here\u2019s another example (machine 1447) in which the actual runtime is always roughly twice the absolute lower bound:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"337\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026absoluteimg5.png\" title=\"\" width=\"672\" /> </div>\n<p><span></p>\n<p>But how does the smallest (worst-case) runtime for any <em>s </em>= 2 Turing machine to compute a given function compare to the absolute lower bound? Well, in a result that presages what we\u2019ll see later in discussing the P vs. NP question, the difference can be increasingly large: </p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"97\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026absoluteimg6.png\" title=\"\" width=\"629\" /> </div>\n<p><span></p>\n<p>The functions being computed here are</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"78\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026absoluteimg7.png\" title=\"\" width=\"630\" /> </div>\n<p><span></p>\n<p>and the fastest <em>s </em>= 2 Turing machines that do this are (machines 2205, 3555 and 2977):</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"609\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026absoluteimg8.png\" title=\"\" width=\"592\" /> </div>\n<p><span></p>\n<p>Our absolute lower bound determines how fast a Turing machine can possibly generate a given output. But one can also think of it as something that measures how much a Turing machine has \u201cachieved\u201d when it generates a given output. If the output is exactly the same as the input, the Turing machine has effectively \u201cachieved nothing\u201d. The more they differ, the more one can think of the machine having \u201cachieved\u201d. </p>\n<p>So now a question one can ask is: are there functions where little is achieved in the transformation from input to output, but where the minimum runtime to perform this transformation is still long? One might wonder about the identity function\u2014where in effect \u201cnothing is achieved\u201d. And indeed we\u2019ve seen that there are Turing machines that compute this function, but only slowly. However, there are also machines that compute it quickly\u2014so in a sense its computation doesn\u2019t need to be slow. </p>\n<p>The function above computed by machine 2205 is a somewhat better example. The (worst-case) \u201cdistance\u201d between input and output grows like 2<em>n</em> with the input size <em>n</em>, but the fastest the function can be computed is what machine 2205 does, with a runtime that grows like 10<em>n</em>. Yes, these are still both linear in <em>n</em>. But at least to some extent this is an example of a function that \u201cdoesn\u2019t need to be slow to compute\u201d, but is at least somewhat slow to compute\u2014at least for any <em>s </em>= 2, <em>k </em>= 2 Turing machine.</p>\n<h2 id=\"space-complexity\">Space Complexity</h2>\n<p>How difficult is it to compute the value of a function, say with a Turing machine? One measure of that is the time it takes, or, more specifically, how many Turing machine steps it takes. But another measure is how much \u201cspace\u201d it takes, or, more specifically, with our setup, how far to the left the Turing machine head goes\u2014which determines how much \u201cTuring machine memory\u201d or \u201ctape\u201d has to be present. </p>\n<p>Here\u2019s a typical example of the comparison between \u201cspace\u201d and \u201ctime\u201d used in a particular Turing machine:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"124\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026spaceimg1.png\" title=\"\" width=\"615\" /> </div>\n<p><span></p>\n<p>If we look at all possible space usage profiles as a function of input size we see that\u2014at least for <em>s </em>= 2, <em>k </em>= 2 Turing machines\u2014the results are rather unremarkable; the space usage either becomes constant, or increases basically linearly with input size:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"251\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026spaceimg2.png\" title=\"\" width=\"590\" /> </div>\n<p><span></p>\n<p>(One could also consider different measures of \u201ccomplexity\u201d\u2014perhaps appropriate for different kinds of idealized hardware. Examples include seeing the total length of path traversed by the head, the total area of the region delimited by the head, the number of times 1 is written to the tape during the computation, etc.)</p>\n<h2 id=\"runtime-distributions-for-particular-inputs-across-machines\">Runtime Distributions for Particular Inputs across Machines</h2>\n<p>We\u2019ve talked quite a lot about how runtime varies with input (or input size) for a particular machine. But what about the complementary question: given a particular input, how does runtime vary across different machines? Consider, for example, the <em>s </em>= 1, <em>k </em>= 2 Turing machines. Here\u2019s what happens with all 16 such machines, starting with input value 1: </p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"130\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026particularimg1.png\" title=\"\" width=\"556\" /> </div>\n<p><span></p>\n<p>The runtimes for these machines are:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"40\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026particularimg2.png\" title=\"\" width=\"432\" /> </div>\n<p><span></p>\n<p>Here\u2019s what we see if we continue to larger inputs:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"292\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026particularimg3.png\" title=\"\" width=\"359\" /> </div>\n<p><span></p>\n<p>The maximum (finite) runtime across all <em>s </em>= 1, <em>k </em>= 2 machines then varies with input <em>i</em> according to</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"40\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026particularimg4.png\" title=\"\" width=\"683\" /> </div>\n<p><span></p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"114\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026particularimg5.png\" title=\"\" width=\"357\" /> </div>\n<p><span></p>\n<p>or in closed form:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"17\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026particularimg6B.png\" title=\"\" width=\"326\" /> </div>\n<p><span></p>\n<p>For <em>s </em>= 2, <em>k </em>= 2 machines, the distribution of runtimes with input 1 is</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"113\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026particularimg7.png\" title=\"\" width=\"270\" /> </div>\n<p><span></p>\n<p>where the maximum value of 17 is achieved for machine 1447. For larger inputs the maximum runtimes are: </p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"40\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026particularimg8.png\" title=\"\" width=\"642\" /> </div>\n<p><span></p>\n<p>Plotting these maximum runtimes</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"111\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026particularimg9.png\" title=\"\" width=\"357\" /> </div>\n<p><span></p>\n<p>we see a big peak at input 127, corresponding to runtime 509 (achieved by machines 378 and 1351). And, yes, plotting the distribution for input 127 of runtimes for all machines, we see that this is a significant outlier:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"114\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026particularimg10.png\" title=\"\" width=\"355\" /> </div>\n<p><span></p>\n<p>If one computes runtimes maximized over all machines and all inputs for successively larger sizes of inputs, one gets (once again dominated by machines 378 and 1351):</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"40\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026particularimg11.png\" title=\"\" width=\"465\" /> </div>\n<p><span></p>\n<p>By the way, one can compute not only runtimes but also values and widths maximized across machines: </p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"55\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026particularimg12.png\" title=\"\" width=\"653\" /> </div>\n<p><span></p>\n<p>And, no, the maximum value isn\u2019t always of the form 2<sup><em>m</em></sup> \u2013 1: the first case where it isn\u2019t is input 265\u2014where it\u2019s 383, as generated by machine 2242:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"133\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026particularimg14.png\" title=\"\" width=\"86\" /> </div>\n<p><span></p>\n<h2 id=\"s3-k2-turing-machines-and-the-problem-of-undecidability\">s = 3, k = 2 Turing Machines and the Problem of Undecidability</h2>\n<p>We\u2019ve so far looked at <em>s </em>= 1, <em>k </em>= 2 and <em>s </em>= 2, <em>k </em>= 2 Turing machines. Now let\u2019s talk about <em>s </em>= 3, <em>k </em>= 2 ones. There are a total of 2,985,984 such machines. And it might seem like a straightforward question to ask: how many distinct functions can these machines compute? But actually this question is far from straightforward. </p>\n<p>The issue\u2014as so often\u2014is of <a href=\"https://www.wolframscience.com/nks/chap-12--the-principle-of-computational-equivalence#sect-12-6--computational-irreducibility\">computational irreducibility</a>. Let\u2019s say you have a machine and you\u2019re trying to figure out if it computes a particular function. Or you\u2019re even just trying to figure out if for input <em>i</em> it gives output <em>j</em>. Well, you might say, why not just run the machine? And of course you can do that. But the problem is: how long should you run it for? Let\u2019s say the machine has been running for a million steps, and still hasn\u2019t generated any output. Will the machine eventually stop, producing either output <em>j</em> or some other output? Or will the machine just keep running forever, and never generate any output at all? </p>\n<p>If the behavior of the machine was computationally reducible, then you could expect to be able to \u201cjump ahead\u201d and figure out what it would do, without following all the steps. But if it\u2019s computationally irreducible, then you can\u2019t expect to do that. It\u2019s a classic <a href=\"https://www.wolframscience.com/nks/p754--undecidability-and-intractability/\">halting problem</a> situation. And you have to conclude that the general problem of determining whether the machine will generate, say, output <em>j</em> is <a href=\"https://www.wolframscience.com/nks/notes-12-8--history-of-undecidability/\">undecidable</a>. </p>\n<p>Of course, in lots of particular cases (say, for lots of particular inputs) it may be easy enough to tell what\u2019s going to happen, either just by running for some number of steps, or by using <a href=\"https://writings.stephenwolfram.com/2025/01/who-can-understand-the-proof-a-window-on-formalized-mathematics/\">some kind of proof</a> or other abstract derivation. But the point is that\u2014because of computational irreducibility\u2014there\u2019s no upper bound on the amount of computational effort that could be needed. And so the problem of \u201calways getting an answer\u201d has to be considered formally undecidable. </p>\n<p>But what happens in practice? Let\u2019s say we look at the behavior of all <em>s </em>= 3, <em>k </em>= 2 machines when given the specific input 1. Running the machines for a million steps, we deduce a certain distribution of runtimes: </p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"86\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026undecidabilityimg1.png\" title=\"\" width=\"629\" /> </div>\n<p><span></p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"84\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026undecidabilityimg2.png\" title=\"\" width=\"235\" /> </div>\n<p><span></p>\n<p>And we then conclude that a bit more than half the machines halt\u2014with the largest finite runtime being the fairly modest 53, achieved by machine 630283 (essentially equivalent to 718804):</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"289\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026undecidabilityimg3.png\" title=\"\" width=\"261\" /> </div>\n<p><span></p>\n<p>But is this actually correct? Or do some of the machines we think don\u2019t halt based on running for a million steps actually eventually halt\u2014but only after more steps? </p>\n<p>Here are a few examples of what happens:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"183\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026undecidabilityimg4.png\" title=\"\" width=\"584\" /> </div>\n<p><span></p>\n<p>And, yes, in all these cases we can readily see that the machines will never halt\u2014and instead, potentially after some transient, their heads just move essentially periodically forever. Here\u2019s the distribution of periods one finds</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"142\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026undecidabilityimg5.png\" title=\"\" width=\"355\" /> </div>\n<p><span></p>\n<p>with the longest-period cases being:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"324\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026undecidabilityimg6.png\" title=\"\" width=\"647\" /> </div>\n<p><span></p>\n<p>And here\u2019s the distribution of transients</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"139\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026undecidabilityimg7.png\" title=\"\" width=\"355\" /> </div>\n<p><span></p>\n<p>with the longest-transient cases being: </p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"324\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026undecidabilityimg8.png\" title=\"\" width=\"656\" /> </div>\n<p><span></p>\n<p>But this doesn\u2019t quite account for all the machines that don\u2019t halt after a million steps: there are still 1938 left over. There are 91 distinct patterns of growth\u2014and here are samples of what happens: </p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"562\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026undecidabilityimg9.png\" title=\"\" width=\"491\" /> </div>\n<p><span></p>\n<p>All of these eventually have a fundamentally nested structure. The patterns grow at different rates\u2014but always in a regular succession of steps. Sometimes the spacings between these steps are polynomials, sometimes exponentials\u2014implying either fractional power or logarithmic growth of the corresponding pattern. But the important point for our purposes here is that we can be confident that\u2014at least with input 1\u2014we know which <em>s </em>= 3, <em>k </em>= 2 Turing machines halt, and which do not. </p>\n<p>But what happens if we increase the input value we provide? Here are the first 20 maximum finite lifetimes we get:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"40\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026undecidabilityimg10.png\" title=\"\" width=\"679\" /> </div>\n<p><span></p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"95\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026undecidabilityimg11.png\" title=\"\" width=\"357\" /> </div>\n<p><span></p>\n<p>In the \u201cpeak case\u201d of input 10, the distribution of runtimes is</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"123\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026undecidabilityimg12.png\" title=\"\" width=\"355\" /> </div>\n<p><span></p>\n<p>with, yes, the maximum value being a somewhat strange outlier. </p>\n<p>What is that outlier? It\u2019s <a href=\"https://www.wolframscience.com/nks/p763--undecidability-and-intractability/\">machine 600720</a> (along with the related machine 670559)\u2014and we\u2019ll be discussing it in more depth in the <a href=\"https://writings.stephenwolfram.com/2026/01/p-vs-np-and-the-difficulty-of-computation-a-ruliological-approach/#machine-600720\">next section</a>. But suffice it to say now that 600720 shows up repeatedly as the <em>s </em>= 3, <em>k </em>= 2 machine with the longest runtimes. Is there a machine with a longer runtime? It\u2019s hard to be absolutely certain. But at least for runtimes up to 10<sup>8</sup> and inputs up to 20 we can say that there definitely is not. And based on the distributions of runtimes we see\u2014as well as comparisons with what we saw in the more manageable case of <em>s </em>= 2, <em>k </em>= 2 Turing machines\u2014it seems likely that there are indeed no machines with longer runtimes, at least for small inputs. </p>\n<p>What about for larger inputs? Well, things get wilder then. Like, for example, consider the case of machine 1955095. For all inputs up to 41, the machine halts after a modest number of steps:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"410\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026undecidabilityimg14.png\" title=\"\" width=\"657\" /> </div>\n<p><span></p>\n<p>But then, at input 42, there\u2019s suddenly a surprise\u2014and the machine never halts:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"248\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026undecidabilityimg15.png\" title=\"\" width=\"668\" /> </div>\n<p><span></p>\n<p>And, yes, we can immediately tell it never halts, because we can readily see that the same pattern of growth repeats periodically\u2014every 24 steps. (A more extreme example is <em>s </em>= 3, <em>k </em>= 2 machine 1227985, which halts for all inputs up to 150\u2014then doesn\u2019t halt for input 151.) </p>\n<p>And, yes, things like this are the \u201clong arm\u201d of undecidability reaching in. But by successively investigating both larger inputs and longer runtimes, one can develop reasonable confidence that\u2014at least most of the time\u2014one is correctly identifying both cases that lead to halting, and ones that do not. And from this one can estimate that of all the 2,985,984 possible <em>s </em>= 3, <em>k </em>= 2 Turing machines, the number that always halt is 1,455,560 or thereabouts. (Uncertainties in this result come from the possibility of machines that either fail to halt only on inputs above 2 million, or halt on smaller inputs, but only after more than 100 million steps.) </p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"10\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026undecidabilityimg16.png\" title=\"\" width=\"54\" /> </div>\n<p><span></p>\n<p>Summarizing our results we find that\u2014somewhat surprisingly\u2014the <a href=\"https://www.wolframscience.com/nks/notes-10-3--algorithmic-information-theory/\">halting fraction</a> is quite similar for different numbers of states, and always close to 1/2:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"79\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026undecidabilityimg17.png\" title=\"\" width=\"269\" /> </div>\n<p><span></p>\n<p>And based on our census of halting machines, we can then conclude that the number of distinct total functions computed by <em>s </em>= 3, <em>k </em>= 2 Turing machines is 18,429:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"40\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026undecidabilityimg18.png\" title=\"\" width=\"202\" /> </div>\n<p><span></p>\n<h2 id=\"machine-600720\">Machine 600720</h2>\n<p>In looking at the runtimes of <em>s </em>= 3, <em>k </em>= 2 machines we noticed an outlier: a machine that can give exceptionally long runtimes. That machine is 600720 (along with the related machine 670559):</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"36\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026machineimg1.png\" title=\"\" width=\"258\" /> </div>\n<p><span></p>\n<p>I actually first noticed this machine in the 1990s as part of my work on <em><a href=\"https://www.wolframscience.com/nks/\">A New Kind of Science</a></em><em>\u2014</em>and with considerable effort was able to give a <a href=\"https://www.wolframscience.com/nks/notes-12-8--turing-machine-600720/\">rather elaborate analysis</a> of at least some of its behavior:</p>\n<p><a alt=\"\" class=\"magnific image\" href=\"https://content.wolfram.com/sites/43/2026/01/sw01272026machineimg2.png\" title=\"\"><br />\n<img alt=\"Click to enlarge\" height=\"513\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026machineimg2.png\" title=\"Click to enlarge\" width=\"620\" /></a></p>\n<p>The first remarkable thing about the machine is the dramatic peaks it exhibits in the output values it generates:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"143\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026machineimg3.png\" title=\"\" width=\"492\" /> </div>\n<p><span></p>\n<p>These peaks are accompanied by corresponding (somewhat less dramatic) peaks in runtime:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"146\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026machineimg4.png\" title=\"\" width=\"498\" /> </div>\n<p><span></p>\n<p>The first of the peaks shown here occurs at input <em>i</em> = 34\u2014with runtime 315,391, and output 2<sup>1148</sup> \u2013 1 (or about 4 \u00d7 10<sup>345</sup>). What is the Turing machine doing underneath when it shows these peaks? It\u2019s easier to see for the earlier peaks (and the later images here have been squashed to make their behavior more obvious)</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"367\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026machineimg7.png\" title=\"\" width=\"464\" /> </div>\n<p><span></p>\n<p>but the basic point is that the machine seems to behave in a very \u201cdeliberate\u201d way that one might imagine could be analyzed. </p>\n<p>It turns out, though, that the analysis is surprisingly complicated. Here\u2019s a table of maximum (worst-case) runtimes (and corresponding inputs and outputs):</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"82\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026machineimg8.png\" title=\"\" width=\"657\" /> </div>\n<p><span></p>\n<p>For odd <em>n</em> > 3, the maximum runtime occurs when the input value <em>i</em> is:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"33\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026machineimg9.png\" title=\"\" width=\"89\" /> </div>\n<p><span></p>\n<p>The corresponding initial states for the Turing machine are of the form:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"13\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026machine-aimg1.png\" title=\"\" width=\"457\" /> </div>\n<p><span></p>\n<p>The output value with such an input (for odd <em>n </em>> 3) is then</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"13\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026machineimg11.png\" title=\"\" width=\"588\" /> </div>\n<p><span></p>\n<p>while the runtime\u2014derived effectively by \u201cmathematicizing\u201d what the Turing machine does for these inputs\u2014is given by the bizarrely complex formula:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"153\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026machineimg12.png\" title=\"\" width=\"584\" /> </div>\n<p><span></p>\n<p>What is the asymptotic behavior? It\u2019s roughly 6<sup>\u03b1<em>n</em></sup> where \u03b1 varies with <em>n</em> according to:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"98\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026machineimg14.png\" title=\"\" width=\"654\" /> </div>\n<p><span></p>\n<p>So this is how long it can take the Turing machine to compute its output. But can we find that output faster, say just by finding a \u201cmathematical formula\u201d for it? For inputs <em>i</em> with some particular forms (like the one above) it is indeed possible to find such formulas:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"14\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026machineimg15.png\" title=\"\" width=\"108\" /> </div>\n<p><span></p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"14\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026machineimg16.png\" title=\"\" width=\"171\" /> </div>\n<p><span></p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"14\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026machineimg17.png\" title=\"\" width=\"133\" /> </div>\n<p><span></p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"19\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026machineimg18.png\" title=\"\" width=\"224\" /> </div>\n<p><span></p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"38\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026machineimg19.png\" title=\"\" width=\"235\" /> </div>\n<p><span></p>\n<p>But in the vast majority of cases there doesn\u2019t seem to be any simple mathematical-style formula. And indeed one can expect that this Turing machine is a typical computationally irreducible system: you can always find its output (here the value <em>f</em>[<em>i</em>]) by explicitly running the machine, but there\u2019s no general way to shortcut this, and to systematically get to the answer by some reduced, shorter computation. </p>\n<h2 id=\"runtimes-in-s3-k2-turing-machines\">Runtimes in s = 3, k = 2 Turing Machines</h2>\n<p>We discussed above that out of the 2.99 million possible <em>s </em>= 3, <em>k </em>= 2 Turing machines, about 1.45 million always halt, and thus produce a definite output for any given input. But what are their runtimes, and how do these increase with the size of their input? Just as we saw for <em>s </em>= 2, <em>k </em>= 2 machines, there turn out to be only a limited number of distinct runtime \u201cprofiles\u201d\u2014here about 7000 of them. And if we ask about asymptotic behavior, the number of distinct possibilities is at most half this.</p>\n<p>There are machines that give asymptotically constant runtime</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"104\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026s3k2img1.png\" title=\"\" width=\"617\" /> </div>\n<p><span></p>\n<p>with all odd asymptotic runtime values up to 21 (along with 25) being possible:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"113\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026s3k2img2.png\" title=\"\" width=\"244\" /> </div>\n<p><span></p>\n<p>Then there are machines that give asymptotically linear runtimes, with even coefficients from 2 to 20 (along with 24)\u2014for example:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"82\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026s3k2img3.png\" title=\"\" width=\"617\" /> </div>\n<p><span></p>\n<p>By the way, note that (as we mentioned before) some machines realize their worst-case runtimes for many specific inputs, while in other machines such runtimes are rare (here illustrated for machines with asymptotic runtimes 24<em>n</em>):</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"80\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026s3k2img4.png\" title=\"\" width=\"618\" /> </div>\n<p><span></p>\n<p>Sometimes there are machines whose worst-case runtimes increase linearly, but in effect with fractional slopes:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"83\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026s3k2img5.png\" title=\"\" width=\"618\" /> </div>\n<p><span></p>\n<p>There are many machines whose worst-case runtimes increase in an ultimately linear way\u2014but with \u201coscillations\u201d:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"95\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026s3k2img6.png\" title=\"\" width=\"519\" /> </div>\n<p><span></p>\n<p>Averaging out the oscillations gives an overall growth rate of the form \u03b1<em>n</em>, where \u03b1 is an integer or rational number with (as it turns out) denominator 2 or 3; the possible values for \u03b1 are:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"48\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026s3k2img7.png\" title=\"\" width=\"574\" /> </div>\n<p><span></p>\n<p>There are also machines with worst-case runtimes growing like \u03b1<em>n</em><sup>2</sup>, with \u03b1 an integer from 1 to 10 (though missing 7): </p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"74\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026s3k2img9.png\" title=\"\" width=\"577\" /> </div>\n<p><span></p>\n<p>And then there are a few machines (such as 129559 and 1166261) with cubic growth rates.</p>\n<p>The next\u2014and, in fact, single largest\u2014group of machines have worst-case runtimes that asymptotically grow exponentially, following <a href=\"https://reference.wolfram.com/language/ref/LinearRecurrence.html\">linear recurrences</a>. The possible asymptotic growth rates seem to be (\u03d5 is the golden ratio <span class=\"InlineFormula\"><img align=\"absmiddle\" height=\"23\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026s3k2img10.png\" width=\"82\" /></span>):</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"25\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026s3k2img11.png\" title=\"\" width=\"161\" /> </div>\n<p><span></p>\n<p>Some particular examples of machines with these growth rates include (we\u2019ll see 5<sup><em>n</em>/2</sup> and 4<sup><em>n</em></sup> examples in the <a href=\"https://writings.stephenwolfram.com/2026/01/p-vs-np-and-the-difficulty-of-computation-a-ruliological-approach/#functions-and-their-runtimes-in-s3-k2-turing-machines\">next section</a>):</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"170\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026s3k2img14.png\" title=\"\" width=\"589\" /> </div>\n<p><span></p>\n<p>The first of these is machine 1020827, and the exact worst-case runtime for input size <em>n</em> in this case is:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"29\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026s3k2img15A.png\" title=\"\" width=\"250\" /> </div>\n<p><span></p>\n<p>The second case shown (machine 117245) has exact worst-case runtime</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"29\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026s3k2img16A.png\" title=\"\" width=\"250\" /> </div>\n<p><span></p>\n<p>which satisfies the linear recurrence:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"20\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026s3k2img17A.png\" title=\"\" width=\"221\" /> </div>\n<p><span></p>\n<p>The third case (machine 1007039) has exact worst-case runtime:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"30\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026s3k2img18A.png\" title=\"\" width=\"236\" /> </div>\n<p><span></p>\n<p>It\u2019s notable that in all of these cases, the maximum runtime for input size <em>n</em> occurs for input <em>i</em> = 2<sup><em>n</em></sup> \u2013 1. Here are the actual behaviors of the underlying machines (which all in the end turn out to just compute the identity function):</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"348\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01302026s3k2img2.png\" title=\"\" width=\"672\" /> </div>\n<p><span></p>\n<p>Continuing and squashing the results, it becomes clear that there\u2019s a nested structure to these patterns:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"245\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026s3k2img21.png\" title=\"\" width=\"170\" /> </div>\n<p><span></p>\n<p>By the way, it\u2019s certainly not necessary that the worst-case runtime must occur at the largest input of a given size. Here\u2019s an example (machine 888388) where that\u2019s not what happens</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"96\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026s3k2img22.png\" title=\"\" width=\"357\" /> </div>\n<p><span></p>\n<p>and where in the end the 2<sup><em>n</em>/2</sup> growth is achieved by having the same worst-case runtime for input sizes <em>n</em> and <em>n </em>+ 1 for all even <em>n</em>:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"18\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026s3k2-aimg4.png\" title=\"\" width=\"62\" /> </div>\n<p><span></p>\n<p>One feature of everything we\u2019ve seen here is the runtimes we\u2019ve deduced are either asymptotically powers or asymptotically exponentials. There\u2019s nothing in between\u2014for example nothing like <em>n</em><sup>Log[<em>n</em>]</sup> or 4<sup>Sqrt[<em>n</em>]</sup>:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"161\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01272026s3k2img27.png\" title=\"\" width=\"347\" /> </div>\n<p><span></p>\n<p>No doubt there are Turing machines with such <a href=\"https://www.wolframscience.com/nksonline/page-938c/\">intermediate growth</a>, but apparently none with <em>s </em>= 3, <em>k </em>= 2.</p>\n<h2 id=\"functions-and-their-runtimes-in-s3-k2-turing-machines\">Functions and Their Runtimes in s = 3, k = 2 Turing Machines</h2>\n<p>As we discussed above, out of the 2.99 million possible <em>s </em>= 3, <em>k </em>= 2 Turing machines, about 1.45 million always halt, and thus compute total functions. But what are these functions? In general, many machines can compute the same function. And in the end there seem to be about 18,000 distinct functions that <em>s </em>= 3, <em>k </em>= 2 machines can compute. Ranking these functions by the number of machines that compute them, we get the following distribution: </p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"122\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026functionsimg1.png\" title=\"\" width=\"597\" /> </div>\n<p><span></p>\n<p>The functions computed by the most machines are (where, not surprisingly, the identity function <em>f</em>[<em>i</em>] = <em>i</em> is the overall winner):</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"191\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026functionsimg2.png\" title=\"\" width=\"692\" /> </div>\n<p><span></p>\n<p>The minimum number of machines that can compute a given function is always 2\u2014because there\u2019s always one machine with a <img height=\"9\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026functionsimg3.png\" width=\"34\" /> transition, and another with a <img height=\"9\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026functionsimg4.png\" width=\"34\" /> transition, as in:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"86\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026functionsimg5.png\" title=\"\" width=\"349\" /> </div>\n<p><span></p>\n<p>But altogether there are about 13,000 of these \u201cisolate\u201d machines, where no other <em>s </em>= 3, <em>k </em>= 2 machine can compute the same function they do. These functions can be thought of as representing computations that are computationally irreducible\u2014at least for <em>s </em>= 3, <em>k </em>= 2 Turing machines.</p>\n<p>So what are these functions\u2014and how long do they take to compute? And remember, these are functions that are computed by isolate machines\u2014so whatever the runtime of those machines is, this can be thought of as defining a lower bound on the runtime to compute that function, at least by any <em>s </em>= 3, <em>k </em>= 2 machine. </p>\n<p>So what are the functions with the longest runtimes computed by isolate machines? The overall winner seems to be the function computed by machine 600720 that we discussed above. </p>\n<p>Next appears to come machine 589111</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"259\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026functionsimg6.png\" title=\"\" width=\"646\" /> </div>\n<p><span></p>\n<p>with its asymptotically 4<sup><em>n</em></sup> runtime:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"121\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026functionsimg8.png\" title=\"\" width=\"619\" /> </div>\n<p><span></p>\n<p>And although the values here, say for <em>i </em>= 95 and <em>i </em>= 191, are huge (\u224810<sup>56</sup> and \u224810<sup>114</sup>), the corresponding absolute lower bounds for generating these values are respectively just 377 and 761, which are still dramatically smaller than the actual runtimes in these cases: 23,471 and 96,053.</p>\n<p>Next appear to come machines like 599063</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"219\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026functionsimg11.png\" title=\"\" width=\"686\" /> </div>\n<p><span></p>\n<p>with asymptotic 5<sup><em>n</em>/2</sup> \u2248 2.25<sup><em>n</em></sup> runtime:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"118\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026functionsimg14.png\" title=\"\" width=\"619\" /> </div>\n<p><span></p>\n<p>Despite the seemingly somewhat regular pattern of values for this function, the machine that computes it is an isolate, so we know that at least among <em>s </em>= 3, <em>k </em>= 2 Turing machines, the function can\u2019t be computed any faster.</p>\n<p>What about the other machines with asymptotically exponential runtimes that we saw in the previous section? Well, the particular <a href=\"https://writings.stephenwolfram.com/2026/01/p-vs-np-and-the-difficulty-of-computation-a-ruliological-approach/#runtimes-in-s3-k2-turing-machines\">machines we used as examples there</a> aren\u2019t even close to isolates. But there are other machines that have the same exponentially growing runtimes, and that are isolates. And, just for once, there\u2019s a surprise.</p>\n<p>For asymptotic runtime 2<sup><em>n</em></sup>, it turns out that there is just a single isolate machine: 1342057:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"123\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026functionsimg16.png\" title=\"\" width=\"617\" /> </div>\n<p><span></p>\n<p>But look at how simple the function this machine computes is. In fact, <em>f</em>[<em>i</em>] \u2013 <em>i</em> is just periodic, repeating with period 16 the block:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"13\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026functionsimg17.png\" title=\"\" width=\"337\" /> </div>\n<p><span></p>\n<p>But despite the simplicity of this, it still takes the Turing machine worst-case runtime <span class=\"InlineFormula\"><img align=\"absmiddle\" height=\"32\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026vsimg23.png\" width=\"36\" /></span> \u2013 1 to compute it. The \u201cmost difficult\u201d inputs are of the form 2<sup><em>n</em></sup> \u2013 2, and here\u2019s what the machine does in the first few of those cases:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"427\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026functionsimg20.png\" title=\"\" width=\"392\" /> </div>\n<p><span></p>\n<p>And, yes, after a transient at the beginning, all the machine is ultimately doing is to compute <em>i </em>+ 1. But the point is that if one looks at the whole sequence of function values computed by the machine, there is simply no other <em>s</em> = 3, <em>k</em> = 2 Turing machine that can do the computation (well, apart from the immediately equivalent machine 2415947). So\u2014despite its simplicity\u2014we must conclude that this function is in effect irreducible for <em>s</em> = 3, <em>k</em> = 2 Turing machines, and is forced to a have worst-case runtime that is asymptotically 2<sup><em>n</em></sup>. </p>\n<p>Going on to asymptotic runtimes of the form 3<sup><em>n</em>/2</sup>, it turns out there\u2019s only one function for which there\u2019s a machine (1007039) with this asymptotic runtime\u2014and this function can be computed by over a hundred machines, many with faster runtimes, though some with slower (2<sup><em>n</em></sup>) runtimes (e.g. 879123).</p>\n<p>What about asymptotic runtimes of order <span class=\"InlineFormula\"><img height=\"16\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026functionsimg24.png\" style=\"vertical-align: bottom; margin-top: 2px; margin-bottom: 5px;\" width=\"16\" /></span>? It\u2019s more or less the same story as with 3<sup><em>n</em>/2</sup>. There are 48 functions which can be computed by machines with this worst-case runtime. But in all cases there are also many other machines, with many other runtimes, that compute the same functions.</p>\n<p>But now there\u2019s another surprise. For asymptotic runtime 2<sup><em>n</em>/2</sup> there are two functions computed only by isolate machines (889249 and 1073017):</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"119\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026functionsimg27.png\" title=\"\" width=\"617\" /> </div>\n<p><span></p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"119\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026functionsimg28.png\" title=\"\" width=\"617\" /> </div>\n<p><span></p>\n<p>So, once again, these functions have the feature that they can\u2019t be computed any faster by any other <em>s </em>= 3, <em>k </em>= 2 Turing machine.</p>\n<p>When we looked at <em>s </em>= 2, <em>k </em>= 2 Turing machines, we saw a machine\u2014378\u2014that has asymptotic worst-case runtime 2<sup><em>n</em></sup>. But the big difference from what we\u2019re seeing now with <em>s</em> = 3, <em>k</em> = 2 machines is that <em>s </em>= 2, <em>k </em>= 2 machine 378 is not an isolate. As it happens, what it computes is just the identity function <em>f</em>[<em>i</em>] = <em>i</em>. And while machine 378 takes exponential time to compute this function, there are lots of other <em>s </em>= 2, <em>k </em>= 2 machines that compute the same function much faster, and indeed in constant time. </p>\n<p>Among <em>s </em>= 2, <em>k </em>= 2 machines, we found that there are no functions whose fastest runtimes grow more than quadratically with size. But now, for <em>s </em>= 3, <em>k </em>= 2 machines, there are examples of functions whose fastest runtimes grow not polynomially but exponentially. </p>\n<p>There are, of course, many more <em>s </em>= 3, <em>k </em>= 2 machines than <em>s </em>= 2, <em>k </em>= 2 ones. But it could be that with all those machines there would be sufficiently many that at least one of them would compute any given function quickly. In fact, however, what we see is that the number of distinct functions is large enough that there end up being many \u201cisolate\u201d machines that are the only ones (at least with <em>s </em>= 3, <em>k </em>= 2) that compute a given function. And when those machines have asymptotically exponential runtimes, they in effect define an (exponential) lower bound (among <em>s </em>= 3, <em>k </em>= 2 machines) for the runtime of the functions they compute. </p>\n<p>Isolate machines immediately define lower bounds on runtime for the functions they compute. But in general (as we saw above) there can be many machines that compute a given function. For example, as mentioned above, there are 210,792 <em>s </em>= 3, <em>k </em>= 2 machines that compute the identity function. These machines have 102 distinct runtime profiles</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"122\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026functionsimg30.png\" title=\"\" width=\"615\" /> </div>\n<p><span></p>\n<p>with asymptotic runtimes ranging from constant to linear, quadratic and exponential. (The most rapidly increasing runtime is ~2<sup><em>n</em></sup>.)</p>\n<p>For each function that can be computed, there\u2019s a slightly different collection of runtime profiles; here are the ones for the functions computed by the next largest numbers of machines:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"217\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026functionsimg32.png\" title=\"\" width=\"578\" /> </div>\n<p><span></p>\n<h2 id=\"can-bigger-machines-compute-functions-faster\">Can Bigger Machines Compute Functions Faster?</h2>\n<p>We saw above that there are functions which cannot be computed asymptotically faster than particular bounds by, say, any <em>s </em>= 2, <em>k </em>= 2 Turing machine. But what if we consider larger Turing machines (say <em>s </em>= 3, <em>k </em>= 2)? Will there be a larger Turing machine which can compute a given function faster?</p>\n<p>The first thing to say is that (as we <a href=\"https://writings.stephenwolfram.com/2026/01/p-vs-np-and-the-difficulty-of-computation-a-ruliological-approach/#computing-the-same-functions-at-different-speeds\">discussed before</a> for <em>s </em>= 2, <em>k </em>= 2 vs. <em>s </em>= 1, <em>k </em>= 2 machines) if a Turing machine of some size (say <em>s </em>= 2, <em>k </em>= 2) computes a given function, then there must always be larger Turing machines (say <em>s </em>= 3, <em>k </em>= 2) that compute the same function. Indeed, there are usually many such machines. So, for example, among <em>s </em>= 3, <em>k </em>= 2 machines, this is the distribution of how many of them compute each function computed by an <em>s </em>= 2, <em>k </em>= 2 machine (the minimum of 304 is obtained for the function computed by <em>s </em>= 2, <em>k </em>= 2 machine 2439):</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"138\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01212026biggerimg1.png\" title=\"\" width=\"357\" /> </div>\n<p><span></p>\n<p>Among <em>s </em>= 2, <em>k </em>= 2 machines we found that there are functions that cannot be computed asymptotically faster than quadratically by any such machine. An example is the function computed by machine 1511</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"116\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01212026biggerimg2.png\" title=\"\" width=\"617\" /> </div>\n<p><span></p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"194\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01212026biggerimg3.png\" title=\"\" width=\"559\" /> </div>\n<p><span></p>\n<p>where the exact worst-case runtime is:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"14\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01212026biggerimg4.png\" title=\"\" width=\"77\" /> </div>\n<p><span></p>\n<p>But now we can ask whether this function can be computed faster by any <em>s </em>= 3, <em>k </em>= 2 machine. It turns out that there are 352 such machines that compute this function. Of these, 342 have the exact same worst-case runtime, and none of the machines compute the functions asymptotically faster than quadratically. Still, there are 10 machines that manage to compute the function slightly faster, with runtime:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"14\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01212026biggerimg5.png\" title=\"\" width=\"77\" /> </div>\n<p><span></p>\n<p>An example is machine 1069163:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"166\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01212026biggerimg6.png\" title=\"\" width=\"559\" /> </div>\n<p><span></p>\n<p>We can think of what\u2019s happening as being that we start from the <em>s </em>= 2, <em>k </em>= 2 Turing machine rule</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"34\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01212026biggerimg7.png\" title=\"\" width=\"164\" /> </div>\n<p><span></p>\n<p>and in effect optimize this by using a slightly more complicated \u201cinstruction set\u201d:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"35\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01212026biggerimg8.png\" title=\"\" width=\"249\" /> </div>\n<p><span></p>\n<p>In looking at <em>s </em>= 3, <em>k </em>= 2 Turing machines we found examples of functions that could be computed by such machines only with runtimes that asymptotically increase exponentially with input size. So now we can ask whether, if we go to <em>s </em>= 4, <em>k </em>= 2 Turing machines, it become possible to compute those functions faster.</p>\n<p>As an example, consider the function computed by the isolate machine 1342057:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"119\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01212026biggerimg9.png\" title=\"\" width=\"617\" /> </div>\n<p><span></p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"222\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01212026biggerimg10.png\" title=\"\" width=\"580\" /> </div>\n<p><span></p>\n<p>This has asymptotic runtime 4<sup><em>n</em></sup>. But now if we look at <em>s </em>= 4, <em>k </em>= 2 machines, then among the 16<sup>8</sup> = 4,294,967,296 such machines, one finds 2220 that compute this function. Of these, 1583 have the exact same worst-case runtime as the original <em>s </em>= 3, <em>k </em>= 2 machine. And many others also have asymptotically exponential runtimes. But it turns out that there are other machines that have much faster runtimes. For example, machine 1517414255 asymptotically has a constant worst-case runtime of just 7:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"98\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01212026biggerimg13.png\" title=\"\" width=\"629\" /> </div>\n<p><span></p>\n<p>There are also machines with linearly and quadratically increasing runtimes\u2014though, confusingly, for the first few input sizes, they seem to be increasing just as fast as our original <em>s </em>= 3, <em>k </em>= 2 machine:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"74\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01212026biggerimg14.png\" title=\"\" width=\"498\" /> </div>\n<p><span></p>\n<p>Here are the underlying rules for these particular Turing machines:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"142\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01212026biggerimg15.png\" title=\"\" width=\"228\" /> </div>\n<p><span></p>\n<p>And here\u2019s the full spectrum of runtime profiles achieved by <em>s </em>= 4, <em>k </em>= 2 machines for our function: </p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"122\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01212026biggerimg16.png\" title=\"\" width=\"615\" /> </div>\n<p><span></p>\n<p>There are runtimes that are easy to recognize as exponentials\u2014though with bases like 2,<span class=\"InlineFormula\"><img height=\"21\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01212026biggerimg17.png\" style=\"vertical-align: bottom; margin-top: 2px; margin-bottom: 3px;\" width=\"22\" /></span>, 3/2, <span class=\"InlineFormula\"><img height=\"20\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01212026biggerimg18.png\" style=\"vertical-align: bottom; margin-top: 2px; margin-bottom: 4px;\" width=\"22\" /></span> that are smaller than 4. Then there are linear and polynomial runtimes of the kind we just saw. And there\u2019s some slightly exotic \u201coscillatory\u201d behavior, like with machine 1418699063</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"80\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01212026biggerimg19.png\" title=\"\" width=\"292\" /> </div>\n<p><span></p>\n<p>that seems to settle down to a periodic sequence of ratios, growing asymptotically like 2<sup><em>n</em>/4</sup>.</p>\n<p>What about other functions that are difficult to compute by <em>s </em>= 3, <em>k </em>= 2 machines? Quite often it turns out to be a somewhat different story. For example, for the function computed by <em>s </em>= 3, <em>k </em>= 2 machine 600720, there are 1602 <em>s </em>= 4, <em>k </em>= 2 machines that also compute it. But unlike in the case we just saw, there aren\u2019t a whole collection of runtime profiles: instead there are just two:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"79\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01212026biggerimg21.png\" title=\"\" width=\"429\" /> </div>\n<p><span></p>\n<p>One of these follows exactly the runtimes of 600720; the other is not the same, but is very close, with about half the runtimes being the same, and the other half having maximal differences that grow linearly with <em>n</em>. </p>\n<p>And what this means is that\u2014unlike the function computed by <em>s </em>= 3, <em>k </em>= 2 machine 1342057, the function computed by <em>s </em>= 3, <em>k </em>= 2 machine 600720 can\u2019t be computed any faster by any <em>s </em>= 4, <em>k </em>= 2 machine than by an <em>s </em>= 3, <em>k </em>= 2 machine. In other words, going to a larger machine (at least <em>s </em>= 4) doesn\u2019t help in the computation of this function.</p>\n<p>Looking at other functions that are \u201chard to compute\u201d with <em>s </em>= 3, <em>k </em>= 2 machines, one sometimes finds that they become easier to compute if one uses <em>s </em>= 4, <em>k </em>= 2 machines, but often they do not.</p>\n<h2 id=\"with-a-sufficiently-large-turing-machine\">With a Sufficiently Large Turing Machine&#8230;</h2>\n<p>We\u2019ve been talking so far about very small Turing machines\u2014with at most a handful of distinct cases in their rules. But what if we consider much larger Turing machines? Would these allow us to systematically do computations much faster?</p>\n<p>Given a particular (finite) mapping from input to output values, say</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"40\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026sufficientlyimg1.png\" title=\"\" width=\"112\" /> </div>\n<p><span></p>\n<p>it\u2019s quite straightforward to construct a Turing machine</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"80\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01292026sufficientlyimg1.png\" title=\"\" width=\"596\" /> </div>\n<p><span></p>\n<p>whose state transitions in effect just \u201cimmediately look up\u201d these values:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"139\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026sufficientlyimg3.png\" title=\"\" width=\"461\" /> </div>\n<p><span></p>\n<p>(If we try to compute a value that hasn\u2019t been defined, the Turing machine will simply not halt.)</p>\n<p>If we stay with a fixed value of <em>k</em>, then for a \u201cfunction lookup table\u201d of size <em>v</em>, the number of states we need for a \u201cdirect representation\u201d of the lookup table is directly proportional to <em>v</em>. Meanwhile, the runtime is just equal to the absolute lower bound we discussed above, which is linearly proportional to the sizes of input and output. </p>\n<p>Of course, with this setup, as we increase <em>v</em> we increase the size of the Turing machine. And we can\u2019t guarantee to encode a function defined, say, for all integers, with anything less than an infinite Turing machine. </p>\n<p>But by the time we\u2019re dealing with an infinite Turing machine we don\u2019t really need to be computing anything; we can just be looking everything up. And indeed computation theory always in effect assumes that we\u2019re limiting the size of our machines. And as soon as we do this, there starts to be all sorts of richness in questions like which functions are computable, and what runtime is required to compute them. </p>\n<p>In the past, we might just have assumed that there is some arbitrary bound on the size of Turing machines, or, in effect, a bound on their \u201c<a href=\"https://www.wolframscience.com/nks/notes-10-3--algorithmic-information-theory/\">algorithmic information content</a>\u201d or \u201cprogram size\u201d. But the point of what we\u2019re doing here is to explore what happens not with arbitrary bounds, but with bounds that are small enough to allow us to do exhaustive empirical investigations.</p>\n<p>In other words, we\u2019re restricting ourselves to low algorithmic (or program) complexity and<br />\nasking what then happens with time complexity, space complexity, etc. And what we find is that even in that domain, there\u2019s remarkable richness in the behavior we\u2019re able to see. And from the <a href=\"https://www.wolframscience.com/nks/chap-12--the-principle-of-computational-equivalence/\">Principle of Computational Equivalence</a> we can expect that this richness is already characteristic of what we\u2019d see even with much larger Turing machines, and thus larger algorithmic complexity. </p>\n<h2 id=\"beyond-binary-turing-machines\">Beyond Binary Turing Machines</h2>\n<p>In everything we\u2019ve done so far, we\u2019ve been looking at \u201cbinary\u201d (i.e. <em>k </em>= 2) Turing machines that have only values 0 and 1 on their tapes. But what if we consider more possible values\u2014say \u201cternary\u201d (i.e. <em>k </em>= 3) Turing machines, with values 0, 1 and 2 on their tapes?</p>\n<p>The setup we\u2019ve been using translates immediately:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"30\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026beyondimg1.png\" title=\"\" width=\"212\" /> </div>\n<p><span></p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"117\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026beyondimg2.png\" title=\"\" width=\"635\" /> </div>\n<p><span></p>\n<p>The simplest case is <em>s </em>= 1, <em>k </em>= 3\u2014yielding 6<sup>3</sup> = 216 possible machines: </p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"341\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026beyondimg4.png\" title=\"\" width=\"669\" /> </div>\n<p><span></p>\n<p>Of these machines, 88 always halt\u2014and compute 77 distinct functions. The possible runtimes are:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"53\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01302026beyond-cimg1.png\" title=\"\" width=\"564\" /> </div>\n<p><span></p>\n<p>And unlike what we saw even for <em>s </em>= 2, <em>k </em>= 2, there are now \u201cisolate\u201d machines whose worst-case runtime grows quadratically\u2014the largest runtime being achieved by machine 29:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"32\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026beyondimg6.png\" title=\"\" width=\"113\" /> </div>\n<p><span></p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"163\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026beyondimg7.png\" title=\"\" width=\"600\" /> </div>\n<p><span></p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"116\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026beyondimg8.png\" title=\"\" width=\"617\" /> </div>\n<p><span></p>\n<p>For <em>s </em>= 2, <em>k </em>= 3, we have 12<sup>6</sup> = 2,985,984 possible machines\u2014the same number as for <em>s </em>= 3, <em>k </em>= 2. And indeed the behavior we see is similar to what we saw for <em>s </em>= 3, <em>k </em>= 2. With input 1, the number of machines that halt after 1 and 3 steps is actually identical in the two cases (1492992 and 373248, respectively). The fraction of machines that ever halt is similar, though not identical: 68.2% for <em>s </em>= 3, <em>k </em>= 2 and 67.6% for <em>s </em>= 2, <em>k </em>= 3. The longest \u201cfinite lifetime\u201d for input 1 is 53 for <em>s </em>= 3, <em>k </em>= 2 and 83 for <em>s </em>= 2, <em>k </em>= 3:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"439\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026beyondimg10.png\" title=\"\" width=\"308\" /> </div>\n<p><span></p>\n<p>In both cases, of the machines that don\u2019t halt, the vast majority become periodic. For <em>s </em>= 3, <em>k </em>= 2, the largest period (starting from input 1) is 35; for <em>s </em>= 2, <em>k </em>= 3, it is 50:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"324\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026beyondimg11.png\" title=\"\" width=\"526\" /> </div>\n<p><span></p>\n<p>Just as for <em>s </em>= 3, <em>k </em>= 2, there are some <em>s </em>= 2, <em>k </em>= 3 machines that don\u2019t become periodic, though (at least with input 1) all yield nested patterns, with some examples being</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"308\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026beyondimg12.png\" title=\"\" width=\"596\" /> </div>\n<p><span></p>\n<p>or in squashed form:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"220\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026beyondimg13.png\" title=\"\" width=\"595\" /> </div>\n<p><span></p>\n<p>If we look beyond input 1, we find that about 1.12 million <em>s </em>= 2, <em>k </em>= 3 machines always halt (compared to 1.45 million for <em>s </em>= 3, <em>k </em>= 2), But if we ask how many distinct functions these machines compute, the result is around 173,000\u2014nearly ten times as many as for <em>s </em>= 3, <em>k </em>= 2 machines. Why is this? This shows the distribution of the number of <em>s </em>= 2, <em>k </em>= 3 machines computing a given function:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"116\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026beyondimg14.png\" title=\"\" width=\"578\" /> </div>\n<p><span></p>\n<p>A notable feature is that the tail consists of functions computed by only one machine. In the <em>s </em>= 2, <em>k </em>= 3 case, symmetry between transitions to <img alt=\"\" height=\"6\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026beyondimg20.png\" title=\"\" width=\"9\" /> and <img alt=\"\" height=\"6\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026beyondimg21.png\" title=\"\" width=\"9\" /> means that there are always at least two machines computing a given function. But with <em>s </em>= 2, <em>k </em>= 3 this \u201cdegeneracy\u201d is broken, leading to a larger number of distinct functions. </p>\n<p>What about runtimes? The results for <em>s </em>= 2, <em>k </em>= 3 seem to be generally similar to those for <em>s </em>= 3, <em>k </em>= 2, though a bit wilder. The fastest growing runtimes seem to asymptotically grow like 9<sup><em>n</em></sup>, an example being machine 840971, whose worst-case runtimes for successive input sizes are:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"13\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026beyondimg23.png\" title=\"\" width=\"330\" /> </div>\n<p><span></p>\n<p>In a sense it should not be surprising that there is so much similarity between the behavior of <em>s </em>= 3, <em>k </em>= 2 Turing machines and <em>s </em>= 2, <em>k </em>= 3 ones. After all, the total number of possible machines of each kind is the same, as is the number of underlying cases in their rules. </p>\n<p>However, if we look not at the kind of \u201cone-sided\u201d (or \u201chalt if you go to the right\u201d) Turing machines we are considering here, but instead at Turing machines where the head can go freely in either direction, then one difference emerges. Starting with a blank tape, all <em>s </em>= 3, <em>k </em>= 2 machines eventually behave in readily predictable ways. But\u2014as I discovered in <em>A New Kind of Science</em>\u2014<a href=\"https://www.wolframscience.com/nks/p709--universality-in-turing-machines-and-other-systems/\">the <em>s </em>= 2, <em>k </em>= 3 machine 596440 does not</a>:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"32\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026beyondimg24.png\" title=\"\" width=\"228\" /> </div>\n<p><span></p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"232\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026beyondimg25.png\" title=\"\" width=\"641\" /> </div>\n<p><span></p>\n<p>And this fact provides a clue that such a machine (or, actually, the 14 essentially equivalent machines of which this is one example) might be capable of universal computation. And indeed <a href=\"https://www.wolframscience.com/prizes/tm23/\">it can be shown that</a>\u2014at least with appropriate (infinite) initial conditions, the machine can successfully be \u201cprogrammed\u201d to emulate systems that are known to be universal, thereby proving that it itself is universal.</p>\n<p>How does this machine fare with our one-sided setup? Here\u2019s what it does with the first few inputs:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"89\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01302026beyond-dimg1.png\" title=\"\" width=\"620\" /> </div>\n<p><span></p>\n<p>And what one finds is that for any input, the head of the machine eventually goes to the right, so with our one-sided setup we consider the machine to halt:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"121\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026beyondimg27.png\" title=\"\" width=\"617\" /> </div>\n<p><span></p>\n<p>It turns out that the worst-case runtime for input of size <em>n</em> grows according to:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"11\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026beyondimg28.png\" title=\"\" width=\"55\" /> </div>\n<p><span></p>\n<p>But if we look at the function computed by this machine we can ask whether there are ways to compute it faster. And it turns out there are 11 other <em>s </em>= 2, <em>k </em>= 3 machines (though, for example, no <em>s </em>= 3, <em>k </em>= 2 ones) that compute the exact same function. If we look at their behavior from a blank tape</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"76\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026beyondimg29.png\" title=\"\" width=\"648\" /> </div>\n<p><span></p>\n<p>one might think they would be simple enough to have shorter runtimes. But in fact in the one-sided setup their behavior is basically identical to our original machine.</p>\n<p>OK, but what about <em>s </em>= 3, <em>k </em>= 2 machines? Probably their higher symmetry makes them not \u201creveal their computational capabilities\u201d if they are started from a blank tape. But one can expect that with more complicated initial conditions, they may do more complicated things. Still, at least with \u201cinput 1\u201d (i.e. a single 1 on an otherwise blank tape) there are nested behaviors like these, but nothing more: </p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"265\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026beyondimg30.png\" title=\"\" width=\"650\" /> </div>\n<p><span></p>\n<h2 id=\"recognizable-functions\">Recognizable Functions</h2>\n<p>We\u2019ve been talking a lot about how fast Turing machines can compute functions. But what can we say about what functions they compute? With appropriate encoding of inputs and decoding of outputs, we know that (essentially by definition) any computable function can be computed by some Turing machine. But what about the simple Turing machines we\u2019ve been using here? And what about \u201cwithout encodings\u201d? </p>\n<p>The way we\u2019ve set things up, we\u2019re taking both the input and the output to our Turing machines to be the sequences of values on their tapes\u2014and we\u2019re interpreting these values as digits of integers. So that means we can think of our Turing machines as defining functions from integers to integers. But what functions are they? </p>\n<p>Here are two <em>s</em> = 2, <em>k</em> = 2 Turing machines that <a href=\"https://www.wolframscience.com/nks/p760--undecidability-and-intractability/\">compute the function <em>f</em>[<em>i</em>] = <em>i</em> + 1</a>\u2014complete with the appropriate long-range carry, say for input 7:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"155\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026recognizableimg1.png\" title=\"\" width=\"636\" /> </div>\n<p><span></p>\n<p>There are a total of 17 <em>s </em>= 2, <em>k </em>= 2 machines that do this computation. (There are no <em>s </em>= 1, <em>k </em>= 2 machines, and 8934 <em>s </em>= 3, <em>k </em>= 2 machines.) There are no <em>s </em>= 2, <em>k </em>= 2 machines that compute <em>f</em>[<em>i</em>] = <em>i </em>+ <em>a</em> for <em>a</em> > 1\u2014but there are 14 <em>s </em>= 3, <em>k </em>= 2 machines that compute <em>f</em>[<em>i</em>] = <em>i </em>+ 2, examples being:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"182\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026recognizableimg2.png\" title=\"\" width=\"636\" /> </div>\n<p><span></p>\n<p>Still, for <em>a</em> > 2, there are again no <em>s </em>= 3, <em>k </em>= 2 machines that compute <em>f</em>[<em>i</em>] = <em>i </em>+ <em>a</em>.</p>\n<p>If we restrict ourselves to even inputs, then we can compute <em>f</em>[<em>i</em>] = <em>i </em>+ 2 even with an <em>s </em>= 2, <em>k </em>= 2 machine:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"86\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026recognizableimg3.png\" title=\"\" width=\"640\" /> </div>\n<p><span></p>\n<p>Similarly, there are <em>s </em>= 3, <em>k </em>= 2, machines that for even inputs compute <em>f</em>[<em>i</em>] = <em>i </em>+ <em>a</em> up to <em>a </em>= 4:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"208\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026recognizableimg4.png\" title=\"\" width=\"640\" /> </div>\n<p><span></p>\n<p>What about other \u201cmathematically simple\u201d functions, say <em>f</em>[<em>i</em>] = 2<em>i</em> or <em>f</em>[<em>i</em>] = <em>i</em><sup>2</sup>? At least up to <em>s </em>= 4, <em>k </em>= 2 there are no machines that, for example, compute these particular functions. And in general there seems to be something of a disconnect between what\u2019s simple mathematically, and what\u2019s simple in a Turing machine. It\u2019s bit like what happens with mathematical operations and digit sequences of numbers: except in rare cases, <a href=\"https://www.wolframscience.com/nks/chap-4--systems-based-on-numbers#sect-4-5--mathematical-constants\">simple mathematical operations don&#8217;t lead to simple patterns in digit sequences</a>. </p>\n<p>We\u2019ve already seen a variety of examples where our Turing machines can be interpreted as evaluating <a href=\"https://reference.wolfram.com/language/guide/BitwiseOperations.html\">bitwise functions</a> of their inputs. A more minimal case would be something like a single bitflip\u2014and indeed there is an <em>s </em>= 2, <em>k </em>= 2 machine that can compute a flip of the \u201clast digit\u201d on its tape:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"49\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026recognizableimg6.png\" title=\"\" width=\"631\" /> </div>\n<p><span></p>\n<p>To be able to flip a higher-order digit, one needs a Turing machine with more states. There are two <em>s </em>= 3, <em>k </em>= 2 machines that flip the second-to-last digit:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"61\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026recognizableimg7.png\" title=\"\" width=\"615\" /> </div>\n<p><span></p>\n<p>And in general\u2014as these pictures suggest\u2014flipping the <em>m</em><sup>th</sup> bit can be done with a Turing machine with at least <em>m </em>+ 1 possible states for its head. </p>\n<p>What about Turing machines that compute periodic functions? Strict (nontrivial) periodicity seems difficult to achieve. But here, for example, is an <em>s </em>= 2, <em>k </em>= 2 machine (actually, the unique one) that computes <em>f</em>[<em>i</em>] = <em>i</em> + <tt>Mod</tt><tt>[</tt><em>i</em>, 2<tt>]</tt>: </p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"75\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026recognizableimg9.png\" title=\"\" width=\"664\" /> </div>\n<p><span></p>\n<p>With both <em>s </em>= 2, <em>k </em>= 2 and <em>s </em>= 3, <em>k </em>= 2, there are no machines that compute <em>f</em>[<em>i</em>] = <em>i</em> + <tt>Mod[</tt><em>i</em>, 3<tt>]</tt>. But with <em>s </em>= 3, <em>k </em>= 2 there are 4 machines that compute <em>f</em>[<em>i</em>] = <em>i</em> + <tt>Mod[</tt><em>i</em>, 4<tt>]</tt>:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"89\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026recognizableimg10.png\" title=\"\" width=\"664\" /> </div>\n<p><span></p>\n<p>Another thing one might ask is whether one Turing machine can emulate another. And indeed that\u2019s what we see happening\u2014very directly\u2014whenever one Turing machine computes the same function as another. </p>\n<p>(We also know that there exist universal Turing machines\u2014the <a href=\"https://www.wolframscience.com/prizes/tm23/\">simplest having <em>s </em>= 2, <em>k </em>= 3</a>\u2014that can ultimately emulate any other Turing machines. But in general such emulation will not be as direct as what we\u2019re studying here; instead it\u2019ll involve potentially very complex encoding of input and output.)</p>\n<h2 id=\"empirical-computational-irreducibility\">Empirical Computational Irreducibility</h2>\n<p><a href=\"https://www.wolframscience.com/nks/chap-12--the-principle-of-computational-equivalence#sect-12-6--computational-irreducibility\">Computational irreducibility</a> has been central to much of the science I\u2019ve done in the past four decades or so. And indeed it\u2019s guided our intuition in much of what we\u2019ve been exploring here. But the things we\u2019ve discussed now also allow us to take an empirical look at the core phenomenon of computational irreducibility itself. </p>\n<p>Computational irreducibility is ultimately about the idea that there can be computations where in effect there is no shortcut: there is no way to systematically find their results except by running each of their steps. In other words, given an irreducible computation, there\u2019s basically no way to come up with another computation that gives the same result, but in fewer steps. Needless to say, if one wants to tighten up this intuitive idea, there are lots of detailed issues to consider. For example, what about just using a computational system that has \u201cbigger primitives\u201d? Like many other foundational concepts in theoretical science, it\u2019s difficult to pin down exactly how one should set things up\u2014so that one doesn\u2019t either implicitly assume what one\u2019s trying to explain, or so restrict things that everything becomes essentially trivial.</p>\n<p>But using what we\u2019ve done here, we can explore a definite\u2014if restricted\u2014version of computational irreducibility in a very explicit way. Imagine we\u2019re computing a function using a Turing machine. What would it mean to say that that function\u2014and the underlying behavior of the Turing machine that computes it\u2014is computationally irreducible? Essentially it\u2019s that there\u2019s no other faster way to compute that function.</p>\n<p>But if we restrict ourselves to computation by a certain size of Turing machine, that\u2019s exactly what we\u2019ve studied at great length here. And, for example, whenever we have what we\u2019ve called an \u201cisolate\u201d Turing machine, we know that no other Turing machine of the same size can compute the same function. So that means one can say that the function is computationally irreducible with respect to Turing machines of the given size. </p>\n<p>How robust is such a notion? We\u2019ve seen examples above where a given function can be computed, say, only in exponential time by an <em>s </em>= 3, <em>k </em>= 2 Turing machine, but in linear time by an <em>s </em>= 4, <em>k </em>= 2 Turing machine. But the expectation is that as we increase the size of machines\u2014and thus the number of possible machines\u2014there will end up being more and more functions where no significant speedup can be achieved by having a larger machine. And such functions we can then think of as being in effect \u201cabsolutely computationally irreducible\u201d.</p>\n<p>But the important point here is that we can already see a restricted version of computational irreducibility just by looking explicitly at Turing machines of a given size. And this allows us to get concrete results about computational irreducibility, or at least about this restricted version of it. </p>\n<p>One of the remarkable discoveries in looking at lots of kinds of systems over the years has been just how common the phenomenon of computational irreducibility seems to be. But usually we haven\u2019t had a way to rigorously say that we\u2019re seeing computational irreducibility in any particular case. All we typically know is that we can\u2019t \u201cvisually decode\u201d what\u2019s going on, nor can particular methods we try. (And, yes, the fact that a wide variety of different methods <a href=\"https://www.wolframscience.com/nks/chap-10--processes-of-perception-and-analysis#sect-10-5--data-compression\">almost always agree about what&#8217;s \u201ccompressible\u201d</a> and what\u2019s not encourages our conclusions about the presence of computational irreducibility.)</p>\n<p>In looking at Turing machines here, we\u2019re often seeing \u201cvisual complexity\u201d, not so much in the detailed\u2014often ponderous\u2014behavior with a particular initial condition, but more, for example, in what we get by plotting function values against inputs. But now we have a more rigorous\u2014if restricted\u2014test for computational irreducibility: we can ask whether the function that\u2019s being computed is irreducible with respect to this size of Turing machine, or, typically equivalently, whether the Turing machine we\u2019re looking at is an isolate. </p>\n<p>So now we can, for example, explore how common irreducibility defined in this way might be. Here are results for some of the classes of small Turing machines we\u2019ve studied above:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"105\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026irreducibilityimg1.png\" title=\"\" width=\"495\" /> </div>\n<p><span></p>\n<p>And what we see is that\u2014much like our impression from computational systems like cellular automata\u2014computational irreducibility is indeed very common among small Turing machines, where now we\u2019re using our rigorous, if restricted, notion of computational irreducibility. </p>\n<p>(It\u2019s worth commenting that while \u201cglobal\u201d features of Turing machines\u2014like the functions they compute\u2014may be computationally irreducible, there can still be lots of computational reducibility in their more detailed properties. And indeed what we\u2019ve seen here is that there are plenty of features of the behavior of Turing machines\u2014like the back-and-forth motion of their heads\u2014that look visually simple, and that we can expect to compute in dramatically faster ways than just running the Turing machine itself.) </p>\n<h2 id=\"nondeterministic-multiway-turing-machines\">Nondeterministic (Multiway) Turing Machines</h2>\n<p>So far, we\u2019ve made a fairly extensive study of ordinary, deterministic (\u201csingle-way\u201d) Turing machines. But the P vs. NP question is about comparing the capabilities of such deterministic Turing machines with the capabilities of nondeterministic\u2014or multiway\u2014Turing machines. </p>\n<p>An ordinary (deterministic) Turing machine has a rule such as</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"32\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026nondeterministicimg1.png\" title=\"\" width=\"154\" /> </div>\n<p><span></p>\n<p>that specifies a unique sequence of successive configurations for the Turing machine</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"115\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026nondeterministicimg2.png\" title=\"\" width=\"69\" /> </div>\n<p><span></p>\n<p>which we can represent as:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"235\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026nondeterministicimg3.png\" title=\"\" width=\"86\" /> </div>\n<p><span></p>\n<p>A <a href=\"https://bulletins.wolframphysics.org/2021/02/multiway-turing-machines/\" rel=\"noopener\" target=\"_blank\">multiway Turing machine</a>, on the other hand, can have multiple rules, such as</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"32\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026nondeterministicimg4.png\" title=\"\" width=\"336\" /> </div>\n<p><span></p>\n<p>which are applied in all possible ways to generate a whole multiway graph of successive configurations for the Turing machine</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"287\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026nondeterministicimg5.png\" title=\"\" width=\"431\" /> </div>\n<p><span></p>\n<p>where we have indicated edges in the multiway graph associated with the application of each rule respectively by <img alt=\"\" height=\"3\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026nondeterministicimg8.png\" style=\"margin-bottom: 4px;\" title=\"\" width=\"13\" /> and <img alt=\"\" height=\"3\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026nondeterministicimg9.png\" style=\"margin-bottom: 4px;\" title=\"\" width=\"13\" />, and where identical Turing machine configurations are merged. </p>\n<p>Just as we have done for ordinary (deterministic) Turing machines, we take multiway Turing machines to reach a halting configuration whenever the head goes further to the right than it started\u2014though now this may happen on multiple branches\u2014so that the Turing machine in effect can generate multiple outputs.</p>\n<p>With the way we have set things up, we can think of an ordinary (deterministic) Turing machine as taking an input <em>i</em> and giving as output some value <em>f</em>[<em>i</em>] (where that value might be undefined if the Turing machine doesn\u2019t halt for a given <em>i</em>). In direct analogy, we can think of a multiway Turing machine as taking an input <em>i</em> and giving potentially a whole collection of corresponding outputs:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"196\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026nondeterministicimg10.png\" title=\"\" width=\"522\" /> </div>\n<p><span></p>\n<p>Among the immediate complications is the fact that the machine may not halt, at least on some branches\u2014as happens for input 3 here, indicated by a red dot in the plot above: </p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"303\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026nondeterministicimg11.png\" title=\"\" width=\"240\" /> </div>\n<p><span></p>\n<p>(In addition, we see that there can be multiple paths that lead to a given output, in effect defining multiple runtimes for that output. There can also be cycles, but in defining \u201cruntimes\u201d we ignore these.)</p>\n<p>When we construct a multiway graph we are effectively setting up a representation for all possible paths in the evolution of a (multiway) system. But when we talk about nondeterministic evolution we are typically imagining that just a single path is going to be followed, but we don\u2019t know which. </p>\n<p>Let\u2019s say that we have a multiway Turing machine that for every given input generates a certain set of outputs. If we were to pick just one of the outputs from each of these sets, we would effectively in each case be picking one path in the multiway Turing machine. Or, in other words, we would be \u201cdoing a nondeterministic computation\u201d, or in effect getting output from a nondeterministic Turing machine.</p>\n<p>As an example, let\u2019s take our multiway Turing machine <a href=\"https://writings.stephenwolfram.com/2026/01/p-vs-np-and-the-difficulty-of-computation-a-ruliological-approach#:~:text=A%20multiway%20Turing%20machine%2C%20on%20the%20other%20hand%2C%20can%20have%20multiple%20rules%2C%20such%20as\">from above</a>. Here is an example of how this machine\u2014thought of as a nondeterministic Turing machine\u2014can generate a certain sequence of output values:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"204\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026nondeterministicimg12.png\" title=\"\" width=\"548\" /> </div>\n<p><span></p>\n<p>Each of these output values is achieved by following a certain path in the multiway graph obtained with each input: </p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"201\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026nondeterministicimg13.png\" title=\"\" width=\"648\" /> </div>\n<p><span></p>\n<p>Keeping only the path taken (and including the underlying Turing machine configuration) this represents how each output value was \u201cderived\u201d:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"213\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026nondeterministicimg14.png\" title=\"\" width=\"459\" /> </div>\n<p><span></p>\n<p>The length of the path can then be thought of as the runtime required for the nondeterministic Turing machine to reach the output value. (When there are multiple paths to a given output value, we\u2019ll typically consider \u201cthe runtime\u201d to be the length of the shortest of these paths.) So now we can summarize the runtimes from our example as follows:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"143\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026nondeterministicimg15A.png\" title=\"\" width=\"402\" /> </div>\n<p><span></p>\n<p>The core of the P vs. NP problem is to compare the runtime for a particular function obtained by deterministic and nondeterministic Turing machines. </p>\n<p>So, for example, given a deterministic Turing machine that computes a certain function, we can ask whether there is a nondeterministic Turing machine which\u2014if you picked the right branch\u2014can compute that same function, but faster. </p>\n<p>In the case of the example above, there are two possible underlying Turing machine rules indicated by <img alt=\"\" height=\"3\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026nondeterministicimg16.png\" style=\"margin-bottom: 4px;\" title=\"\" width=\"13\" /> and <img alt=\"\" height=\"3\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026nondeterministicimg17.png\" style=\"margin-bottom: 4px;\" title=\"\" width=\"13\" />. For each input we can choose at each step a different rule to apply in order to get to the output: </p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"191\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026nondeterministicimg18.png\" title=\"\" width=\"149\" /> </div>\n<p><span></p>\n<p>The possibility of using different rules at different steps in effect allows much more freedom in how our computation can be done. The P vs. NP question concerns whether this freedom allows one to fundamentally speed up the computation of a given function.</p>\n<p>But before we explore that question further, let\u2019s take a look at what multiway (nondeterministic) Turing machines typically do; in other words, let\u2019s study their ruliology. </p>\n<h2 id=\"multiway-nondeterministic-s1-k2-turing-machines\">Multiway (Nondeterministic) s = 1, k = 2 Turing Machines</h2>\n<p>As our first example of doing <a href=\"https://bulletins.wolframphysics.org/2021/02/multiway-turing-machines/\" rel=\"noopener\" target=\"_blank\">ruliology for multiway Turing machines</a>, let\u2019s consider the case of pairs of <em>s </em>= 1, <em>k </em>= 2 Turing machine rules. There are 16 individual such rules, and therefore 16 \u00d7 (16 \u2013 1) = 120 (orderless) pairs. Here are the functions computed by all these multiway Turing machines:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"450\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026multiwayimg1.png\" title=\"\" width=\"691\" /> </div>\n<p><span></p>\n<p>Sometimes, as in machine {1,9}, there turns out to be a unique output value for every input:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"141\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026multiwayimg2.png\" title=\"\" width=\"357\" /> </div>\n<p><span></p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"265\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01292026multiwayimg1.png\" title=\"\" width=\"556\" /> </div>\n<p><span></p>\n<p>Sometimes, as in machine {5,9}, there is usually a unique value, but sometimes not:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"138\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026multiwayimg4.png\" title=\"\" width=\"350\" /> </div>\n<p><span></p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"216\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026multiwayimg5.png\" title=\"\" width=\"464\" /> </div>\n<p><span></p>\n<p>Something similar happens with {3,7}:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"138\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026multiwayimg6.png\" title=\"\" width=\"350\" /> </div>\n<p><span></p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"261\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026multiwayimg7.png\" title=\"\" width=\"444\" /> </div>\n<p><span></p>\n<p>There are cases\u2014like {1,3}\u2014where for some inputs there\u2019s a \u201cburst\u201d of possible outputs:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"141\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026multiwayimg8.png\" title=\"\" width=\"357\" /> </div>\n<p><span></p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"250\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026multiwayimg9.png\" title=\"\" width=\"672\" /> </div>\n<p><span></p>\n<p>There are also plenty of cases where for some inputs</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"139\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026multiwayimg10.png\" title=\"\" width=\"351\" /> </div>\n<p><span></p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"421\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026multiwayimg11.png\" title=\"\" width=\"620\" /> </div>\n<p><span></p>\n<p>or for all inputs, there are branches that do not halt:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"141\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026multiwayimg12.png\" title=\"\" width=\"357\" /> </div>\n<p><span></p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"203\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026multiwayimg13.png\" title=\"\" width=\"599\" /> </div>\n<p><span></p>\n<p>What about runtimes? Well, for each possible output in a nondeterministic Turing machine, we can see how many steps it takes to reach that output on any branch of the multiway graph, and we can consider that minimum number to be the \u201cnondeterministic runtime\u201d needed to compute that output. </p>\n<p>It\u2019s the quintessential setup for NP computations: if you can successfully guess what branch to follow, you can potentially get to an answer quickly. But if you have to explicitly check each branch in turn, that can be a slow process. </p>\n<p>Here\u2019s an example showing possible outputs and possible runtimes for a sequence of inputs for the {3,7} nondeterministic machine</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"123\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026multiwayimg14.png\" title=\"\" width=\"617\" /> </div>\n<p><span></p>\n<p>or, combined in 3D:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"174\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026multiwayimg15.png\" title=\"\" width=\"307\" /> </div>\n<p><span></p>\n<p>So what functions can a nondeterministic machine like this \u201cnondeterministically\u201d generate? For each input we have to pick one of the possible corresponding (\u201cmultiway\u201d) outputs. And in effect the possible functions correspond to possible \u201cthreadings\u201d through these values</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"129\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026multiwayimg16.png\" title=\"\" width=\"321\" /> </div>\n<p><span></p>\n<p>or:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"108\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026multiwayimg17.png\" title=\"\" width=\"588\" /> </div>\n<p><span></p>\n<p>To each function one can then associate a \u201cnondeterministic runtime\u201d for each output, here:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"108\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026multiwayimg18.png\" title=\"\" width=\"588\" /> </div>\n<p><span></p>\n<h2 id=\"nondeterministic-vs-deterministic-machines\">Nondeterministic vs. Deterministic Machines</h2>\n<p>We\u2019ve seen how a nondeterministic machine can in general generate multiple functions, with each output from the function being associated with a minimum (\u201cnondeterministic\u201d) runtime. But how do the functions that a particular nondeterministic machine can generate compare with the functions that deterministic machines can generate? Or, put another way, given a function that a nondeterministic machine can generate (or \u201ccompute\u201d), what deterministic machine is required to compute the same function?</p>\n<p>Let\u2019s look at the <em>s </em>= 1, <em>k </em>= 2 {3,7} machine we discussed above. Here are three cases of functions it can generate:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"68\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026vsimg1.png\" title=\"\" width=\"555\" /> </div>\n<p><span></p>\n<p>Can we find a deterministic <em>s </em>= 1, <em>k </em>= 2 machine that will reproduce any of these functions? For the first one shown, the answer, rather trivially, is yes. Because this function is what we get by always following the \u201cmachine 3\u201d (<img height=\"3\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026vsimg2.png\" style=\"vertical-align: bottom; margin-top: 2px; margin-bottom: 11px;\" width=\"13\" />) branch in the multiway system</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"261\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026vsimg3.png\" title=\"\" width=\"668\" /> </div>\n<p><span></p>\n<p>so that it inevitably gives the same results as deterministic machine 3. </p>\n<p>But (apart from the other trivial case based on following \u201cmachine 7\u201d branches) none of the other functions we can generate from this nondeterministic machine can be reproduced by any <em>s </em>= 1, <em>k </em>= 2 deterministic machines.</p>\n<p>What about <em>s </em>= 2, <em>k </em>= 2 deterministic machines? Well, there we have a bit more luck. Because there turn out to be a couple of nontrivial choices in our {3,7} nondeterministic machine that lead to functions that can be reproduced by deterministic (<em>s </em>= 2, <em>k </em>= 2) Turing machines. Here\u2019s an example of a function that can be generated by the {3,7} nondeterministic machine:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"155\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026vsimg4.png\" title=\"\" width=\"401\" /> </div>\n<p><span></p>\n<p>And here are the paths through the multiway graphs for that machine that get to these values</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"243\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026vsimg5.png\" title=\"\" width=\"618\" /> </div>\n<p><span></p>\n<p>with the \u201cpaths on their own\u201d being</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"130\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026vsimg6.png\" title=\"\" width=\"616\" /> </div>\n<p><span></p>\n<p>yielding \u201cnondeterministic runtimes\u201d:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"110\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026vsimg7.png\" title=\"\" width=\"249\" /> </div>\n<p><span></p>\n<p>This is how the deterministic <em>s </em>= 2, <em>k </em>= 2 machine 2253 reproduces the sequence of values for this function:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"102\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026vsimg8.png\" title=\"\" width=\"490\" /> </div>\n<p><span></p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"47\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026vsimg9.png\" title=\"\" width=\"586\" /> </div>\n<p><span></p>\n<p>Here are the pair of underlying rules for the nondeterministic machine</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"37\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026vsimg10.png\" title=\"\" width=\"190\" /> </div>\n<p><span></p>\n<p>and here is the deterministic machine that reproduces a particular function it can generate:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"34\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026vsimg11.png\" title=\"\" width=\"162\" /> </div>\n<p><span></p>\n<p>This example is rather simple, and has the feature that even the deterministic machine always has a very small runtime. But now the question we can ask is whether a function that takes a deterministic machine of a certain class a certain time to compute can be computed in a smaller time if its results are \u201cpicked out of\u201d a nondeterministic machine. </p>\n<p>We saw above that <em>s </em>= 2, <em>k </em>= 2 machine 1511 computes its output with a runtime that increases quadratically with input size\u2014and we also saw that no other (deterministic) <em>s </em>= 2, <em>k </em>= 2 machine computes the same output faster. And the same is basically also true for <em>s </em>= 3, <em>k </em>= 2 machines (though 6 machines, of which 1069163 is an example, do manage to compute the output not in 1 + 4<em>n</em> + 2<em>n</em><sup>2</sup> steps, but in the slightly faster 1 + 2<em>n</em>+ 2<em>n</em><sup>2</sup> steps).</p>\n<p>But what about a nondeterministic machine? How fast can this be?</p>\n<p>It turns out that there are 15 nondeterministic machines based on pairs of <em>s </em>= 1, <em>k </em>= 2 rules that can successfully reproduce the function computed by the <em>s </em>= 2, <em>k </em>= 2 machine 1511. Here is an example from the {0,3} nondeterministic machine:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"208\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026vsimg14.png\" title=\"\" width=\"565\" /> </div>\n<p><span></p>\n<p>Here are the paths within the multiway graph for the nondeterministic machine that are sampled to generate the deterministic Turing machine result:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"300\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026vsimg15.png\" title=\"\" width=\"511\" /> </div>\n<p><span></p>\n<p>And here are these \u201cpaths on their own\u201d:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"341\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026vsimg16.png\" title=\"\" width=\"686\" /> </div>\n<p><span></p>\n<p>We can compare these with the computations needed in the deterministic machine:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"179\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026vsimg17.png\" title=\"\" width=\"601\" /> </div>\n<p><span></p>\n<p>With our rendering, the lengths of the nondeterministic paths might look longer. But in fact they are considerably shorter, as we see by plotting them (in orange) along with the deterministic runtimes (in gray):</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"169\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026vsimg18.png\" title=\"\" width=\"617\" /> </div>\n<p><span></p>\n<p>Looking now at the worst-case runtimes for inputs of size <em>n</em>, we get:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"99\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026vsimg19.png\" title=\"\" width=\"302\" /> </div>\n<p><span></p>\n<p>For the deterministic machine we found above for input size <em>n</em>, this worst-case runtime is given by:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"14\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026vsimg20.png\" title=\"\" width=\"77\" /> </div>\n<p><span></p>\n<p>But now the runtime in the nondeterministic machine turns out to be:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"11\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026vsimg21.png\" title=\"\" width=\"39\" /> </div>\n<p><span></p>\n<p>In other words, we\u2019re seeing that nondeterminism makes it substantially faster to compute this particular function\u2014at least by small Turing machines. </p>\n<p>In a deterministic machine, it\u2019s always the same underlying rule that\u2019s applied at each step. But in a nondeterministic machine with the setup we\u2019re using, we\u2019re independently choosing one of two different rules to apply at each step. The result is that for every function value we compute, we\u2019re making a sequence of choices:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"191\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026vsimg22.png\" title=\"\" width=\"603\" /> </div>\n<p><span></p>\n<p>And the core question that underlies things like the P vs. NP problem is how much advantage the freedom to make these choices conveys\u2014and whether, for example, it allows us to \u201cnondeterministically\u201d compute in polynomial time what takes more than polynomial (say, exponential) time to compute deterministically.</p>\n<p>As a first example, let\u2019s look at the function computed by the <em>s </em>= 3, <em>k </em>= 2 deterministic machine 1342057. We found above that this machine is an isolate, that takes worst-case runtime  <span class=\"InlineFormula\"><img align=\"absmiddle\" height=\"32\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026vsimg23.png\" width=\"36\" /></span> \u2013 1 to compute the (admittedly rather simple) function it computes. So what happens with nondeterministic machines? </p>\n<p>Well, it turns out that the <em>s </em>= 1, <em>k </em>= 2 nondeterministic machine {0,7} can (nondeterministically) compute the same function: </p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"174\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026vsimg24.png\" title=\"\" width=\"459\" /> </div>\n<p><span></p>\n<p>And indeed, while the deterministic machine takes exponentially increasing runtime, the nondeterministic machine has a runtime that quickly approaches the fixed constant value of 5:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"130\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026vsimg25.png\" title=\"\" width=\"420\" /> </div>\n<p><span></p>\n<p>But is this somehow trivial? As the plot above suggests, the nondeterministic machine (at least eventually) generates all possible odd output values (and for even input <em>i</em>, also generates <em>f</em>[<em>i</em>] = <em>i</em>). But if we look at the whole multiway graph, we see that it can take a while for the nondeterministic machine to generate any particular output value:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"223\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026vsimg26.png\" title=\"\" width=\"674\" /> </div>\n<p><span></p>\n<p>What makes the runtime end up being constant, however, is that in this particular case, the output <em>f</em>[<em>i</em>] is always close to <em>i</em> (in fact, |<em>f</em>[<em>i</em>] \u2013 <em>i</em>| \u2264 5).</p>\n<p>There are actually no fewer than 9 <em>s </em>= 1, <em>k </em>= 2 nondeterministic machines that can nondeterministically compute the same function. All of them work essentially the same way, generating (at least for odd <em>i</em>) all possible outputs\u2014with runtime at most 9.</p>\n<p>And while all of them are in a sense straightforward in their operation, they illustrate the point that even when a function requires exponential time for a deterministic Turing machine, it can require much less time for a nondeterministic machine\u2014and even a nondeterministic machine that has a much smaller rule. </p>\n<p>What about other cases of functions that require exponential time for deterministic machines? The functions computed by the <em>s </em>= 3, <em>k </em>= 2 deterministic machines with the most rapid runtime growth\u2014600720 and 589111\u2014can\u2019t be computed by any nondeterministic machine based on pairs of <em>s </em>= 1, <em>k </em>= 2 machines. But functions computed by other deterministic machines with runtime ~2<sup><em>n</em></sup> can also be computed in constant time by nondeterministic machines. </p>\n<p>Something slightly different happens with <em>s </em>= 3, <em>k </em>= 2 machine 889249. This machine has asymptotic runtime 2<sup><em>n</em>/2</sup>. The function it computes can also be computed by an <em>s </em>= 1, <em>k </em>= 2 nondeterministic machine, but now that machine computes the function not in constant time, but instead with asymptotic runtime 2<em>n </em>+ 1 (and, yes, for <em>i </em>= 1 the nondeterministic machine is actually slower, taking 5 steps instead of 1):</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"126\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026vsimg29.png\" title=\"\" width=\"414\" /> </div>\n<p><span></p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"156\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026vsimg30.png\" title=\"\" width=\"685\" /> </div>\n<p><span></p>\n<h2 id=\"the-limit-of-nondeterminism-and-the-ruliad\">The Limit of Nondeterminism and the Ruliad</h2>\n<p>A deterministic Turing machine has a single, definite rule that\u2019s applied at each step. In the previous sections we\u2019ve explored what\u2019s in a sense a minimal case of nondeterminism in Turing machines\u2014where we allow not just one, but two different possible rules to be applied at each step. But what if we increase the nondeterminism\u2014say by allowing more possible rules at each step? </p>\n<p>We\u2019ve seen that there\u2019s a big difference between determinism\u2014with one rule\u2014and even our minimal case of nondeterminism, with two rules. But if we add in, say, a third rule, it doesn\u2019t seem to typically make any qualitative difference. So what about the limiting case of <a href=\"https://bulletins.wolframphysics.org/2020/06/exploring-rulial-space-the-case-of-turing-machines/\" rel=\"noopener\" target=\"_blank\">adding in all conceivable rules</a>?</p>\n<p>We can think of what we get as an \u201ceverything machine\u201d\u2014a machine that has every possible rule case for any possible Turing machine, say for <em>s </em>= 1, <em>k </em>= 2:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"32\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026limitimg1.png\" title=\"\" width=\"370\" /> </div>\n<p><span></p>\n<p>Running this \u201ceverything machine\u201d for one step starting with input 1 we get:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"285\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026limitimg2.png\" title=\"\" width=\"315\" /> </div>\n<p><span></p>\n<p>Four of the rule cases just lead back to the initial state. Then of the other four, two lead to halting states, and two do not. Dropping self-loops, going another couple of steps, and using a different graph rendering, we see that outputs 2 and 3 now appear:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"211\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026limitimg3.png\" title=\"\" width=\"548\" /> </div>\n<p><span></p>\n<p>Here are the results for input 2:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"166\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026limitimg4.png\" title=\"\" width=\"560\" /> </div>\n<p><span></p>\n<p>So where can the \u201ceverything machine\u201d reach, and how long does it take? The answer is that from any input <em>i</em> it can eventually reach absolutely any output value <em>j</em>. The minimum number of steps required (i.e. the minimum path length in the multiway graph) is just the absolute lower bound that <a href=\"https://writings.stephenwolfram.com/2026/01/p-vs-np-and-the-difficulty-of-computation-a-ruliological-approach/#absolute-lower-bounds-and-the-efficiency-of-machines\">we found for runtimes in deterministic machines above</a>: </p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"14\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026limitimg5.png\" title=\"\" width=\"315\" /> </div>\n<p><span></p>\n<p>Starting with input 1, the nondeterministic runtime to reach output <em>j</em> is then</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"14\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026limitimg6.png\" title=\"\" width=\"176\" /> </div>\n<p><span></p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"103\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026limitimg7.png\" title=\"\" width=\"305\" /> </div>\n<p><span></p>\n<p>which grows logarithmically with output value, or linearly with output size. </p>\n<p>So what this means is that the \u201ceverything machine\u201d lets one nondeterministically go from a given input to a given output in the absolutely minimum number of steps structurally possible. In other words, with enough nondeterminism every function becomes nondeterministically \u201ceasy to compute\u201d.</p>\n<p>An important feature of the \u201ceverything machine\u201d is that we can think of it as being a <a href=\"https://writings.stephenwolfram.com/2021/11/the-concept-of-the-ruliad/\">fragment of the ruliad</a>. The full ruliad\u2014which appears at the foundations of physics, mathematics and much more\u2014is the entangled limit of all possible computations. There are many possible bases for the ruliad; Turing machines are one. In the full ruliad, we\u2019d have to consider all possible Turing machines, with all possible sizes. The \u201ceverything machine\u201d we\u2019ve been discussing here gives us just part of that, corresponding to all possible Turing machine rules with a specific number of states and colors. </p>\n<p>In representing all possible computations, the ruliad\u2014like the \u201ceverything machine\u201d\u2014is maximally nondeterministic, so that it in effect includes all possible computational paths. But when we apply the ruliad in science (and even mathematics) we are interested not so much in its overall form as in particular slices of it which are sampled by <a href=\"https://writings.stephenwolfram.com/2023/12/observer-theory/\">observers that, like us, are computationally bounded</a>. And indeed in the past few years it\u2019s become clear that there\u2019s a lot to say about the foundations of many fields by thinking in this way.</p>\n<p>And one feature of computationally bounded observers is that they\u2019re not maximally nondeterministic. Instead of following all possible paths in the multiway system, they tend to follow specific paths or bundles of paths\u2014for example reflecting the <a href=\"https://writings.stephenwolfram.com/2025/05/what-if-we-had-bigger-brains-imagining-minds-beyond-ours/\">single thread of experience</a> that characterizes our human perception of things. So\u2014when it comes to observers\u2014the \u201ceverything machine\u201d is somehow too nondeterministic. An actual (computationally bounded) observer will be concerned with one or just a few \u201cthreads of history\u201d. In other words, if we\u2019re interested in slices of the ruliad that observers will sample, what will be relevant is not so much the \u201ceverything machine\u201d but rather deterministic machines, or at most machines with the kind of limited nondeterminism that we\u2019ve studied the past few sections. </p>\n<p>But just how does what the \u201ceverything machine\u201d can do compare with what all possible deterministic machines can do? In some ways, this is a core question in the comparison between determinism and nondeterminism. And it\u2019s straightforward to start studying it empirically.</p>\n<p>For example, here are successive steps in the multiway graph for the (<em>s </em>= 1, <em>k </em>= 2) \u201ceverything machine\u201d, with <a href=\"https://bulletins.wolframphysics.org/2020/06/exploring-rulial-space-the-case-of-turing-machines/#the-space-of-deterministic-turing-machine-computations\" rel=\"noopener\" target=\"_blank\">the path associated with each possible deterministic (<em>s </em>= 1, <em>k </em>= 2) machine highlighted</a>:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"224\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026limitimg8.png\" title=\"\" width=\"553\" /> </div>\n<p><span></p>\n<p>In a sense these pictures illustrate the \u201creach\u201d of deterministic vs. nondeterministic computation. In this particular case, with <em>s </em>= 1, <em>k </em>= 2, the only values that can ever be reached by deterministic machines from input 1 are 0, 1 and 3\u2014even though nondeterministically the \u201ceverything machine\u201d can reach every possible integer. </p>\n<p>For <em>s </em>= 2, <em>k </em>= 2, we get</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"224\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026limitimg9.png\" title=\"\" width=\"553\" /> </div>\n<p><span></p>\n<p>and the values that can be reached by deterministic machines are:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"13\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026limitimg10.png\" title=\"\" width=\"170\" /> </div>\n<p><span></p>\n<p>But how long does it take to reach these values? This shows as dots the possible (deterministic) runtimes; the filling represents the minimum (nondeterministic) runtimes for the \u201ceverything machine\u201d:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"130\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026limitimg11.png\" title=\"\" width=\"319\" /> </div>\n<p><span></p>\n<p>The most dramatic outlier occurs with value 31, which is reached deterministically only by machine 1447, in 15 steps, but which can be reached in 9 (nondeterministic) steps by the \u201ceverything machine\u201d:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"181\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026limitimg12.png\" title=\"\" width=\"90\" /> </div>\n<p><span></p>\n<p>For <em>s </em>= 3, <em>k </em>= 2, the divergence between deterministic and nondeterministic cases increases:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"160\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026limitimg13.png\" title=\"\" width=\"413\" /> </div>\n<p><span></p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"55\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01282026limitimg14.png\" title=\"\" width=\"675\" /> </div>\n<p><span></p>\n<h2 id=\"what-does-it-all-mean-for-p-vs-np\">What Does It All Mean for P vs. NP?</h2>\n<p>The P vs. NP question asks whether every computation that can be done by any nondeterministic Turing machine with a runtime that increases at most polynomially with input size can also be done by some deterministic Turing machine with a runtime that also increases at most polynomially. Or, put more informally, it asks whether introducing nondeterminism can fundamentally speed up computation. </p>\n<p>In its full form, this is an infinite question, that talks about limiting behavior over all possible inputs, in all possible Turing machines. But within this infinite question, there are definite, finite subquestions we can ask. And one of the things we\u2019ve done here is in effect to explore some of these questions in an explicit, ruliological way. Looking at these finite subquestions won\u2019t in any direct way be able to resolve the full P vs. NP question.</p>\n<p>But it can give us important intuition about the P vs. NP question, and what some of the difficulties and subtleties involved in it are. When one analyzes specific, <a href=\"https://www.wolframscience.com/nks/notes-12-8--classes-of-fast-algorithms/\">constructed algorithms</a>, it\u2019s common to see that their runtimes vary quite smoothly with input size. But one of the things we\u2019ve seen here is that for arbitrary Turing machines \u201cin the wild\u201d, it\u2019s very typical for the runtimes to jump around in complicated ways. It\u2019s also not uncommon to see dramatic outliers that occur only for very specific inputs. </p>\n<p>If there was just one outlier, then in the limit of arbitrarily large input size it would eventually become irrelevant. But what if there were an unending sequence of outliers, of unpredictable sizes at unpredictable positions? Ultimately we expect all sorts of computational irreducibility, which in the limit can make it infinitely difficult to determine in any particular case the limiting behavior of the runtime\u2014and, for example, to find out if it\u2019s growing like a polynomial or not. </p>\n<p>One might imagine, though, that if one looked at enough inputs, enough Turing machines, etc. then somehow any wildness would get in some way averaged out. But our ruliological results don\u2019t encourage that idea. And indeed they tend to show that \u201cthere\u2019s always more wildness\u201d, and it\u2019s somehow ubiquitous. One might have imagined that computational irreducibility\u2014or undecidability\u2014would be sufficiently rare that it wouldn\u2019t affect investigations of \u201cglobal\u201d questions like the P vs. NP one. But our results suggest that, to the contrary, there are all sorts of complicated details and \u201cexceptions\u201d that seem to get in the way of general conclusions. </p>\n<p>Indeed, there seem to be issues at every turn. Some are related to unexpected behavior and outliers in runtimes. Some are related to the question of whether a particular machine ever even halts at all for certain inputs. And yet others are related to taking limits of sizes of inputs versus sizes of Turing machines, or amounts of nondeterminism. What our ruliological explorations have shown is that such issues are not obscure corner cases; rather they are generic and ubiquitous.</p>\n<p>One has the impression, though, that they are more pronounced in deterministic than in nondeterministic machines. Nondeterministic machines in some sense \u201caggregate\u201d over paths, and in doing so, wash out the \u201ccomputational coincidences\u201d which seem ubiquitous in determining the behavior of deterministic machines. </p>\n<p>Certainly the specific experiments we\u2019ve done on machines of limited size do seem to support the idea that there are indeed computations that can be done quickly by a nondeterministic machine, but for which in deterministic machines there are for example at least occasional large runtime outliers, which imply longer general runtimes.</p>\n<p>I had always suspected that the P vs. NP question would ultimately get ensnared in issues of computational irreducibility and undecidability. But from our explicit ruliological explorations we get an explicit sense of how this can happen. Will it nevertheless ultimately be possible to resolve the P vs. NP question with a finite mathematical-style proof based, say, on standard mathematical axioms? The results here make me doubt it. </p>\n<p>Yes, it will be possible to get at least certain restricted global results\u2014in effect by \u201cmining\u201d pockets of computational reducibility. And, as we already know from what we have seen repeatedly here, it\u2019s also possible to get definite results for, say, specific (ultimately finite) classes of Turing machines. </p>\n<p>I\u2019ve only scratched the surface here of the ruliological results that can be found. In some cases to find more just requires expending more computer time. In other cases, though, we can expect that new methodologies, particularly around \u201cbulk\u201d automated theorem proving, will be needed. </p>\n<p>But what we\u2019ve seen here already makes it clear that there is much to be learned by ruliological methods about questions of theoretical computer science\u2014P vs. NP among them. In effect, we\u2019re seeing that theoretical computer science can be done not only \u201cpurely theoretically\u201d\u2014say with methods from traditional mathematics\u2014but also \u201cempirically\u201d, finding results and developing intuition by doing explicit computational experiments and enumerations. </p>\n<hr style=\"border: none; border-top: 1px solid #ccc; margin: 1em 0;\" />\n<h2 id=\"some-personal-notes\">Some Personal Notes</h2>\n<p>My efforts on what I now call ruliology <a href=\"https://www.wolframscience.com/nks/chap-1--the-foundations-for-a-new-kind-of-science#sect-1-4--the-personal-story-of-the-science-in-this-book\">started at the beginning of the 1980s</a>, and in the early years I almost exclusively <a href=\"https://www.wolframscience.com/nks/p23--how-do-simple-programs-behave/\">studied cellular automata</a>. A large part of the reason was just that these were the first types of simple programs I\u2019d investigated, and in them I had made a series of discoveries. I was certainly aware of Turing machines, but viewed them as less connected than cellular automata to <a href=\"https://www.wolframscience.com/nks/p1--an-outline-of-basic-ideas/\">my goal of studying actual systems in nature and elsewhere</a>\u2014though ultimately theoretically equivalent. </p>\n<p>It wasn\u2019t until 1991, when I started systematically studying different types of simple programs as I embarked on my book <em><a href=\"https://www.wolframscience.com/nks/\">A New Kind of Science</a></em> that I actually began to do <a href=\"https://www.wolframscience.com/nks/chap-3--the-world-of-simple-programs#sect-3-4--turing-machines\">simulations of Turing machines</a>. (Despite their widespread use in theoretical science for more than half a century, I think <a href=\"https://www.wolframscience.com/nks/notes-3-4--history-of-turing-machines/\">almost nobody</a> else\u2014<a href=\"https://writings.stephenwolfram.com/2012/06/happy-100th-birthday-alan-turing/\">from Alan Turing on</a>\u2014had ever actually simulated them either.) At first I wasn\u2019t particularly enamored of Turing machines. They seemed a little less elegant than <a href=\"https://www.wolframscience.com/nks/chap-3--the-world-of-simple-programs#sect-3-3--mobile-automata\">mobile automata</a>, and had much less propensity to show interesting and complex behavior than cellular automata. </p>\n<p>Towards the end of the 1990s, though, I was working to connect my discoveries in what became <em>A New Kind of Science</em> to existing results in theoretical computer science\u2014and Turing machines emerged as a useful bridge. In particular, as part of the <a href=\"https://www.wolframscience.com/nks/chap-12--the-principle-of-computational-equivalence/\">final chapter of <em>A New Kind of Science</em>\u2014\u201cThe Principle of Computational Equivalence\u201d</a>\u2014I had a <a href=\"https://www.wolframscience.com/nks/chap-12--the-principle-of-computational-equivalence#sect-12-8--undecidability-and-intractability\">section entitled \u201cUndecidability and Intractability\u201d</a>. And in that section I <a href=\"https://www.wolframscience.com/nks/p761--undecidability-and-intractability/\">used Turing machines</a> as a way to explore the relation of my results to existing results on computational complexity theory.</p>\n<p>And it was in the process of that effort that I invented the kind of one-sided Turing machines I\u2019ve used here:</p>\n<p><a class=\"magnific image sourced\" href=\"https://content.wolfram.com/sites/43/2026/01/sw01232026notesimg1.png\"><img alt=\"Click to enlarge\" height=\"349\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01232026notesimg1.png\" title=\"Click to enlarge\" width=\"547\" /></a></p>\n<p>I <a href=\"https://www.wolframscience.com/nks/notes-12-8--one-sided-turing-machines/\">concentrated on the <em>s </em>= 2, <em>k </em>= 2 machines</a> (for some reason I never looked at <em>s </em>= 1, <em>k </em>= 2), and found classes of machines that compute the same function\u2014sometimes at different speeds: </p>\n<p><img alt=\"Page 761 of the book A New Kind of Science showing examples of computations being done by Turing machines with two states and two colors\" height=\"699\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01232026notesimg2.png\" title=\"Page 761 of the book A New Kind of Science showing examples of computations being done by Turing machines with two states and two colors\" width=\"531\" /></p>\n<p>And even though the computers <a href=\"https://www.wolframscience.com/nks/notes-0-1--computer-experiments/\">I was using at the time</a> were much slower than the ones I use today, I <a href=\"https://www.wolframscience.com/nks/p762--undecidability-and-intractability/\">managed to extend what I was doing to <em>s </em>= 3, <em>k </em>= 2</a>. At every turn, though, I came face to face with computational irreducibility and undecidability. I tried quite hard do things like resolve the exact number of distinct functions for <em>s </em>= 3, <em>k </em>= 2 machines, but in the end didn\u2019t succeed and just gave an \u201capproximate\u201d number:</p>\n<p><a alt=\"\" class=\"magnific image\" href=\"https://content.wolfram.com/sites/43/2026/01/sw01232026notesimg3.png\" title=\"\"><img alt=\"Click to enlarge\" height=\"187\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01232026notesimg3.png\" title=\"Click to enlarge\" width=\"547\" /></a></p>\n<p>Nearly three decades later, I think I <a href=\"https://writings.stephenwolfram.com/2026/01/p-vs-np-and-the-difficulty-of-computation-a-ruliological-approach/#s3-k2-turing-machines-and-the-problem-of-undecidability\">finally have the exact number</a>. (Note that some of the details from <em>A New Kind of Science</em> are also different from what I have here, because in <em>A New Kind of Science</em> I included partial functions in my enumeration; here I\u2019m mostly insisting on total functions, that halt and give a definite result for all inputs.) </p>\n<p>After <em>A New Kind of Science</em> was released in 2002, I made another foray into Turing machines in 2007, <a href=\"https://writings.stephenwolfram.com/2007/05/today-we-put-a-prize-on-a-small-turing-machine/\">putting up a prize on the fifth anniversary of the book</a> for a proof (or refutation) of my <a href=\"https://www.wolframscience.com/nks/p709--universality-in-turing-machines-and-other-systems/\">suspicion that <em>s </em>= 2, <em>k </em>= 3 machine 596440 was capable of universal computation</a>. The <a href=\"https://writings.stephenwolfram.com/2007/10/the-prize-is-won-the-simplest-universal-turing-machine-is-proved/\">prize was soon won</a>, establishing this machine as the very simplest universal Turing machine: </p>\n<p><a alt=\"\" class=\"magnific image\" href=\"https://content.wolfram.com/sites/43/2026/01/sw01232026notesimg4.png\" title=\"\"><img alt=\"Click to enlarge\" height=\"477\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01232026notesimg4.png\" title=\"Click to enlarge\" width=\"413\" /></a></p>\n<p>Many years passed. I occasionally suggested projects on Turing machines to students at the <a href=\"https://education.wolfram.com/summer-school\">summer research program</a> we started in 2003 (more on that later&#8230;). And I participated in <a href=\"https://writings.stephenwolfram.com/2012/06/happy-100th-birthday-alan-turing/\">celebrations of Alan Turing&#8217;s centenary in 2012</a>. Then in 2020 we <a href=\"https://writings.stephenwolfram.com/2020/04/finally-we-may-have-a-path-to-the-fundamental-theory-of-physics-and-its-beautiful/\">announced the Wolfram Physics Project</a>\u2014and I looked at Turing machines again, now as an <a href=\"https://www.wolframphysics.org/technical-introduction/equivalence-and-computation-in-our-models/correspondence-with-other-systems/#p-381\" rel=\"noopener\" target=\"_blank\">example of a computational system that could be encoded with hypergraph rewriting</a>, and studied using physics-inspired causal graphs, etc.:</p>\n<p><a class=\"magnific image sourced\" href=\"https://content.wolfram.com/sites/43/2026/01/sw01232026notesimg5.png\"><img alt=\"Click to enlarge\" height=\"435\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01232026notesimg5.png\" title=\"Click to enlarge\" width=\"615\" /></a></p>\n<p>Less than two months after the launch of our Physics Project I was studying what I now call the ruliad\u2014and I decided to <a href=\"https://bulletins.wolframphysics.org/2020/06/exploring-rulial-space-the-case-of-turing-machines/\" rel=\"noopener\" target=\"_blank\">use Turing machines as a model for it</a>: </p>\n<p><a class=\"magnific image sourced\" href=\"https://content.wolfram.com/sites/43/2026/01/sw01232026notesimg6.png\"><img alt=\"Click to enlarge\" height=\"400\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01232026notesimg6.png\" title=\"Click to enlarge\" width=\"427\" /></a></p>\n<p>A crucial part of this was the idea of multiway Turing machines:</p>\n<p><a class=\"magnific image sourced\" href=\"https://content.wolfram.com/sites/43/2026/01/sw01232026notesimg7.png\"><img alt=\"Click to enlarge\" height=\"321\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01232026notesimg7.png\" title=\"Click to enlarge\" width=\"432\" /></a></p>\n<p>I\u2019d <a href=\"https://www.wolframscience.com/nks/chap-5--two-dimensions-and-beyond#sect-5-6--multiway-systems\">introduced multiway systems</a> in <em>A New Kind of Science</em>, and had examples close to multiway Turing machines in the book. But now multiway Turing machines were more central to what I was doing\u2014and in fact I started studying essentially what I\u2019ve here called the \u201ceverything machine\u201d (though the details were different, because I wasn\u2019t considering Turing machines that can halt):</p>\n<p><a alt=\"\" class=\"magnific image\" href=\"https://content.wolfram.com/sites/43/2026/01/sw01232026notesimg8.png\" title=\"\"><img alt=\"Click to enlarge\" height=\"348\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01232026notesimg8.png\" title=\"Click to enlarge\" width=\"432\" /></a></p>\n<p>I also started looking at the comparison between what can be reached deterministically and nondeterministically\u2014and <a href=\"https://bulletins.wolframphysics.org/2020/06/exploring-rulial-space-the-case-of-turing-machines/#deterministic-turing-machine-paths-in-rulial-space\" rel=\"noopener\" target=\"_blank\">discussed the potential relation of this to the P vs. NP question</a>: </p>\n<p><a alt=\"\" class=\"magnific image\" href=\"https://content.wolfram.com/sites/43/2026/01/sw01232026notesimg9.png\" title=\"\"><img alt=\"Click to enlarge\" height=\"492\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01232026notesimg9.png\" title=\"Click to enlarge\" width=\"432\" /></a></p>\n<p>By the next year, I was <a href=\"https://writings.stephenwolfram.com/2021/09/multicomputation-a-fourth-paradigm-for-theoretical-science/\">expanding my study of multiway systems</a>, and exploring many different examples\u2014with one of them being <a href=\"https://bulletins.wolframphysics.org/2021/02/multiway-turing-machines/\" rel=\"noopener\" target=\"_blank\">multiway Turing machines</a>:</p>\n<p><a class=\"magnific image sourced\" href=\"https://content.wolfram.com/sites/43/2026/01/sw01232026notesimg10.png\"><img alt=\"Click to enlarge\" height=\"455\" src=\"https://content.wolfram.com/sites/43/2026/01/sw01232026notesimg10.png\" title=\"Click to enlarge\" width=\"427\" /></a></p>\n<p>Soon I realized that the general approach I was taking could be applied not only to the foundations of physics, but also to <a href=\"https://writings.stephenwolfram.com/2021/09/multicomputation-a-fourth-paradigm-for-theoretical-science/#potential-application-areas\">foundations of other fields</a>. I studied the <a href=\"https://writings.stephenwolfram.com/2022/03/the-physicalization-of-metamathematics-and-its-implications-for-the-foundations-of-mathematics/\">foundations of mathematics</a>, of <a href=\"https://writings.stephenwolfram.com/2023/02/computational-foundations-for-the-second-law-of-thermodynamics/\">thermodynamics</a>, of <a href=\"https://writings.stephenwolfram.com/2024/08/whats-really-going-on-in-machine-learning-some-minimal-models/\">machine learning</a> and of <a href=\"https://writings.stephenwolfram.com/2024/05/why-does-biological-evolution-work-a-minimal-model-for-biological-evolution-and-other-adaptive-processes/\">biology</a>. But what about the foundations of theoretical computer science? </p>\n<p>Over the years, I\u2019d explored the ruliology of many kinds of systems studied in theoretical computer science\u2014doing deep dives into <a href=\"https://writings.stephenwolfram.com/2020/12/combinators-a-centennial-view/\">combinators for their centenary in 2020</a>, as well as <a href=\"https://writings.stephenwolfram.com/2025/09/the-ruliology-of-lambdas/\">(last year) into lambdas</a>. In all these investigations, I was constantly seeing concrete versions of phenomena discussed in theoretical computer science\u2014even though my emphasis tended to be different. But I was always curious what one might be able to say about central questions in theoretical computer science\u2014like P vs. NP. </p>\n<p>I had imagined that the principal problem in doing an empirical investigation of something like P vs. NP would just be to enumerate enough cases. But when I got into it, I realized that the shadow of computational irreducibility loomed even larger than I\u2019d imagined\u2014and that even within particular cases it could be irreducibly difficult to figure out what one needed to know about their behavior.</p>\n<p>Fairly late in the project I was trying to look up some \u201cconventional wisdom\u201d about NP problems. Most of it was couched in rather traditional mathematical terms, and didn\u2019t seem likely to have too much to say about what I was doing. But then I found a paper entitled \u201c<a href=\"http://www.joostjjoosten.nl/papers/SlowDownTMNew.pdf\" rel=\"noopener\" target=\"_blank\">Program-size versus Time Complexity: Slowdown and Speed-up Phenomena in the Micro-cosmos of Small Turing Machines</a>\u201d\u2014and I was excited to see that it was following up on what I\u2019d done in <em>A New Kind of Science</em>, and doing ruliology. But then I realized: the lead author of the paper, Joost Joosten, had been an (already-a-professor) <a href=\"https://education.wolfram.com/summer-school/alumni/2009/joosten/\">student at our summer program in 2009</a>, and I\u2019d in fact suggested the original version of the project (though the paper had taken it further, and in some slightly different directions than I\u2019d anticipated). </p>\n<p>Needless to say, what I\u2019ve now done here raises a host of new questions, which can now be addressed by future projects done at our summer programs, and beyond&#8230;.</p>\n<p><em>Note</em>: For general historical background see my related writings from <a href=\"https://www.wolframscience.com/nks/notes-12-8--p-versus-np-questions/\">2002</a> and <a href=\"https://bulletins.wolframphysics.org/2021/02/multiway-turing-machines/#notes\" rel=\"noopener\" target=\"_blank\">2021</a>.</p>\n<h2 id=\"thanks\" style=\"font-size: 1.2rem;\">Thanks</h2>\n<p style=\"font-size: 90%;\">Thanks to Willem Nielsen, Nik Murzin and Brian Mboya of the <a href=\"https://wolframinstitute.org/\" rel=\"noopener\" target=\"_blank\">Wolfram Institute</a> for extensive help. Thanks also to Wolfram Institute affiliate Anneline Daggelinckx, as well as to Richard Assar and Pavel Hajek of the Wolfram Institute for additional help. Work at the Wolfram Institute on this project was <a href=\"https://www.templeton.org/grant/causality-observers-and-computation-a-new-approach-to-fundamental-physics-and-metamathematics\" rel=\"noopener\" target=\"_blank\">supported in part by the John Templeton Foundation</a>.</p>\n<p style=\"font-size: 90%;\">Additional input on the project was provided by Lenore &#038; Manuel Blum, Christopher Gilbert, Josh Grochow, Don Knuth and Michael Sun. Matthew Szudzik also <a href=\"https://www.wolframscience.com/nks/pxii--preface/\">contributed relevant work</a> in 1999 <a href=\"https://writings.stephenwolfram.com/2022/05/the-making-of-a-new-kind-of-science/\">during the development</a> of <em>A New Kind of Science</em>.</p>"
            ],
            "link": "https://writings.stephenwolfram.com/2026/01/p-vs-np-and-the-difficulty-of-computation-a-ruliological-approach/",
            "publishedAt": "2026-01-30",
            "source": "Stephen Wolfram",
            "summary": "<span class=\"thumbnail\"><img alt=\"\" class=\"attachment-thumbnail size-thumbnail wp-post-image\" height=\"104\" src=\"https://content.wolfram.com/sites/43/2026/01/p-vs-np-icon-turing2.png\" width=\"124\" /></span>Empirical Theoretical Computer Science \u201cCould there be a faster program for that?\u201d It\u2019s a fundamental type of question in theoretical computer science. But except in special cases, such a question has proved fiendishly difficult to answer. And, for example, in half a century, almost no progress has been made even on the rather coarse (though [&#8230;]",
            "title": "P vs. NP and the Difficulty of Computation: A Ruliological Approach"
        },
        {
            "content": [
                "<p>Anthropic CEO Dario Amodei is back with another extended essay, <a href=\"https://www.darioamodei.com/essay/the-adolescence-of-technology\">The Adolescence of Technology</a>.</p>\n<p>This is the follow up to his previous essay <a href=\"https://darioamodei.com/machines-of-loving-grace\">Machines of Loving Grace</a>. In MoLG, Dario talked about some of the upsides of AI. Here he talks about the dangers, and the need to minimize them while maximizing the benefits.</p>\n<p>In many aspects this was a good essay. Overall it is a mild positive update on Anthropic. It was entirely consistent with his previous statements and work.</p>\n<p>I believe the target is someone familiar with the basics, but who hasn\u2019t thought that much about any of this and is willing to listen given the source. <a href=\"https://x.com/ohabryka/status/2015963212869775732\">For that audience</a>, there are a lot of good bits. For the rest of us, it was good to affirm his positions.</p>\n<div>\n\n\n<span id=\"more-25066\"></span>\n\n\n</div>\n<p>That doesn\u2019t mean there aren\u2019t major problems, especially with its treatment of those more worried, and its failure to present stronger calls to action.</p>\n<p>He is at his weakest when he is criticising those more worried than he is. In some cases <a href=\"https://x.com/allTheYud/status/2016377321452929452\">the description of those positions is on the level of a clear strawman</a>. The central message is, \u2018yes this might kill everyone and we should take that seriously and it will be a tough road ahead, but careful not to take it too seriously or speak that too plainly, or call for doing things that would be too costly.\u2019</p>\n<p>One can very much appreciate him stating his views, and his effort to alter people to the risks involved, while also being sad about these major problems.</p>\n<p>While I agree with Dario about export controls, I do not believe an aggressively adversarial framing of the situation is conducive to good outcomes.</p>\n<p>In the end when he essentially affirms his commitment to racing and rules out trying to do all that much, saying flat out that others will go ahead regardless, so I <a href=\"https://x.com/ohabryka/status/2015871329980055809\">broadly agree with Oliver Habryka and Daniel Kokotajlo here</a>, <a href=\"https://x.com/RyanPGreenblatt/status/2016553987861000238\">and also with Ryan Greenblatt</a>. This is true even though Anthropic\u2019s commitment to racing to superintelligence (here \u2018powerful AI\u2019) should already be \u2018priced in\u2019 to your views on them.</p>\n<p><a href=\"https://x.com/aakashgupta/status/2015868978745507956\">Here is a 3 million views strong \u2018tech Twitter slop\u2019 summary of the essay</a>, linked because it is illustrative of how such types read and pull from the essay, including how it centrally attempts to position Dario as the reasonable one between two extremes.</p>\n\n\n<h4 class=\"wp-block-heading\">Table of Contents</h4>\n\n\n<ol>\n<li><a href=\"https://thezvi.substack.com/i/185978950/blame-the-imperfect\">Blame The Imperfect.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/185978950/anthropic-s-term-is-powerful-ai\">Anthropic\u2019s Term Is \u2018Powerful AI\u2019.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/185978950/dario-doubles-down-on-dates-of-dazzling-datacenter-daemons\">Dario Doubles Down on Dates of Dazzling Datacenter Daemons.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/185978950/how-you-gonna-keep-em-down-on-the-server-farm\">How You Gonna Keep Em Down On The Server Farm.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/185978950/if-he-wanted-to-he-would-have\">If He Wanted To, He Would Have.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/185978950/so-will-he-want-to\">So Will He Want To?</a></li>\n<li><a href=\"https://thezvi.substack.com/i/185978950/the-balance-of-power\">The Balance of Power.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/185978950/defenses-of-autonomy\">Defenses of Autonomy.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/185978950/weapon-of-mass-destruction\">Weapon of Mass Destruction.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/185978950/defenses-against-biological-attacks\">Defenses Against Biological Attacks.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/185978950/one-model-to-rule-them-all\">One Model To Rule Them All.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/185978950/defenses-against-autocracy\">Defenses Against Autocracy.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/185978950/they-took-our-jobs\">They Took Our Jobs.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/185978950/don-t-let-them-take-our-jobs\">Don\u2019t Let Them Take Our Jobs.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/185978950/economic-concentrations-of-power\">Economic Concentrations of Power.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/185978950/unknown-unknowns\">Unknown Unknowns.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/185978950/oh-well-back-to-racing\">Oh Well Back To Racing.</a></li>\n</ol>\n\n\n<h4 class=\"wp-block-heading\">Blame The Imperfect</h4>\n\n\n<p>Right up front we get the classic tensions we get from Dario Amodei and Anthropic. He\u2019s trying to be helpful, but also narrowing the window of potential actions and striking down anyone who speaks too plainly or says things that might seem too weird.</p>\n<p>It\u2019s an attempt to look like a sensible middle ground that everyone can agree upon, but it\u2019s an asymmetric bothsidesism in a situation that is very clearly asymmetric the other way, and I\u2019m pretty sick of it.</p>\n<blockquote><p>As with talking about the benefits, I think it is important to discuss risks in a careful and well-considered manner. In particular, I think it is critical to:</p>\n<ul>\n<li><strong>Avoid doomerism. </strong>Here, I mean \u201cdoomerism\u201d not just in the sense of believing doom is inevitable (which is both a false and self-fulfilling belief), but more generally, thinking about AI risks in a quasi-religious way. \u2026 These voices used off-putting language reminiscent of religion or science fiction, and called for extreme actions without having the evidence that would justify them.</li>\n</ul>\n</blockquote>\n<p>His full explanation on \u2018doomerism,\u2019 here clearly used as a slur or at minimum an ad hominem attack, basically blames the \u2018backlash\u2019 against efforts to not die on people being too pessimistic, or being \u2018quasi-religious\u2019 or sounding like \u2018science fiction,\u2019 or sounding \u2018sensationalistic.\u2019</p>\n<p><a href=\"https://x.com/RyanPGreenblatt/status/2015869503385772037\">\u2018Quasi-religious\u2019 is also being used as an ad hominem or associative attack</a> to try and dismiss and lower the status of anyone who is too much more concerned than he is, and to distance himself from similar attacks made by others.</p>\n<p>I can\u2019t let that slide. This is a dumb, no good, unhelpful and false narrative. Also <a href=\"https://x.com/RyanPGreenblatt/status/2016553987861000238\">see Ryan Greenblatt\u2019s extended explanation for why these labels and dismissals are not okay</a>. He is also right that the post does not engage with the actual arguments here, and that the vibes in several other ways downplay the central stakes and dangers while calling them \u2018autonomy risks\u2019 and that the essay is myopic in only dealing with modest capability gains (e.g. to the \u2018geniuses in a datacenter\u2019 level but then he implicitly claims advancements mostly stop, which they very much wouldn\u2019t.)</p>\n<p>The \u2018backlash\u2019 against those trying to not die was primarily due to a coordinated effort by power and economic interests, who engage in far worse sensationalism and \u2018quasi-religious\u2019 talk constantly, and also from the passage of time and people\u2019s acting as if not having died yet meant it was all overblown, as happens with many that warn of potential dangers, including things like nuclear war.</p>\n<p>You know what\u2019s the most \u2018quasi-religious\u2019 such statement I\u2019ve seen recently, except without the quasi? Marc Andreessen, deliberate bad faith architect of much of this backlash, <a href=\"https://www.youtube.com/watch?v=87Pm0SGTtN8\">calling AI the \u2018Philosopher\u2019s Stone</a>.\u2019 I mean, okay, Newton.</p>\n<p>What causes people call logical arguments that talk plainly about likely physical consequences \u2018reminiscent of science fiction\u2019 or of \u2018religion\u2019 as an attack, they\u2019re at best engaging in low-level pattern matching. Of course the future is going to \u2018sound like science fiction\u2019 when we are building powerful AI systems. Best start believing in science fiction stories, because you\u2019re living in one.</p>\n<p>And it\u2019s pretty rich to say that those warning that all humans could die from this \u2018sound like religion\u2019 when you\u2019re the CEO of a company that is literally named Anthropic. Also you opened the post by quoting Carl Sagan\u2019s Contact.</p>\n<p>Does that mean those involved played a perfect or even great game? Absolutely not. Certainly there were key mistakes, and some private actors engaged in overreach. The pause letter in particular was a mistake and I said so at the time. Such overreach is present in absolutely every important cause in history, and every single political movement. Several calls for regulation or model bills included compute thresholds that were too low, and again I said so at the time.</p>\n<p>If anything, most of those involved have been extraordinarily restrained.</p>\n<p>At some point, restraint means no one hears what you are saying. Dario here talks about \u2018autonomy\u2019 instead of \u2018AI takeover\u2019 or \u2018everyone dies,\u2019 and I think this failure to be blunt is a major weakness of the approach. So many wish to not listen, and Dario gives them that as an easy option.</p>\n<blockquote>\n<ul>\n<li><strong>Acknowledge uncertainty. </strong>There are plenty of ways in which the concerns I\u2019m raising in this piece could be moot. Nothing here is intended to communicate certainty or even likelihood. Most obviously, AI may simply not advance anywhere near as fast as I imagine.\n<p>Or, even if it does advance quickly, some or all of the risks discussed here may not materialize (which would be great), or there may be other risks I haven\u2019t considered. No one can predict the future with complete confidence\u2014but we have to do the best we can to plan anyway.</li>\n</ul>\n</blockquote>\n<p>On this point we mostly agree, especially that it might not progress so quickly. Dario should especially be prepared to be wrong about that, given his prediction is things will go much faster than most others predict.</p>\n<p>In terms of the risks, certainly we will have missed important ones, it is very possible we will avoid the ones we worry most about now, but I don\u2019t think it\u2019s reasonable to say the risks we worry about now might not materialize at all as capabilities advance.</p>\n<p>If AI becomes sufficiently advanced, yes the dangers will be there. The hope is that we will deal with them, perhaps in highly unexpected ways and with unexpected tools.</p>\n<blockquote>\n<ul>\n<li><strong>Intervene as surgically as possible. </strong>Addressing the risks of AI will require a mix of voluntary actions taken by companies (and private third-party actors) and actions taken by governments that bind everyone. The voluntary actions\u2014both taking them and encouraging other companies to follow suit\u2014are a no-brainer for me. I firmly believe that government actions will also be required <em>to some extent</em>, but these interventions are different in character because they can potentially destroy economic value or coerce unwilling actors who are skeptical of these risks (and there is some chance they are right!).\n<p>\u2026 It is easy to say, \u201cNo action is too extreme when the fate of humanity is at stake!,\u201d but in practice this attitude simply leads to backlash.</li>\n</ul>\n</blockquote>\n<p>It is almost always wise to intervene as surgically as possible, provided you still do enough to get the job done. And yes, if we want to do very costly interventions we will need better evidence and need better consensus. But context matters here. In the past, Anthropic has used such arguments as a kudgel against remarkably surgical interventions, including SB 1047.</p>\n\n\n<h4 class=\"wp-block-heading\">Anthropic\u2019s Term Is \u2018Powerful AI\u2019</h4>\n\n\n<p>Dario quotes his definition from <a href=\"https://darioamodei.com/essay/machines-of-loving-grace\">Machines of Loving Grace</a>: An AI smarter than a Nobel Prize winner across most relevant fields, with all the digital (but not physical) affordances available to a human, that can work autonomously for indefinite periods, and that can be run in parallel, or his \u2018country of geniuses in a data center.\u2019</p>\n<p>Functionally I think this is a fine AGI alternative. For most purposes I have been liking my use of the term Sufficiently Advanced AI, but PAI works.</p>\n\n\n<h4 class=\"wp-block-heading\">Dario Doubles Down on Dates of Dazzling Datacenter Daemons</h4>\n\n\n<blockquote><p>As I wrote in <a href=\"https://darioamodei.com/essay/machines-of-loving-grace\"><em>Machines of Loving Grace</em></a>, powerful AI could be as little as 1\u20132 years away, although it could also be considerably further out.</p></blockquote>\n<p>That\u2019s \u2018could\u2019 rather than \u2018probably will be,\u2019 so not a full doubling down.</p>\n<p>In this essay Dario chooses his words carefully, and explains what he means. I worry that in other contexts, including within the past two weeks, Dario has been less careful, and that people will classify him as having made a stupid prediction if we don\u2019t get his PAI by the end of 2027.</p>\n<p>I don\u2019t find it likely that we get PAI by the end of 2027, I\u2019d give it less than a 10% chance of happening, but I agree that this is not something we can rule out, that it is more than 1% likely, and that we want to be prepared in case it happens.</p>\n\n\n<h4 class=\"wp-block-heading\">How You Gonna Keep Em Down On The Server Farm</h4>\n\n\n<blockquote><p>\u200bI think the best way to get a handle on the risks of AI is to ask the following question: suppose a literal \u201ccountry of geniuses\u201d were to materialize somewhere in the world in ~2027. Imagine, say, 50 million people, all of whom are much more capable than any Nobel Prize winner, statesman, or technologist.</p>\n<p>\u2026for every cognitive action we can take, this country can take ten.</p>\n<p>What should you be worried about? I would worry about the following things:</p>\n<ol>\n<li><strong>Autonomy risks. </strong>What are the intentions and goals of this country? Is it hostile, or does it share our values? Could it militarily dominate the world through superior weapons, cyber operations, influence operations, or manufacturing?</li>\n<li><strong>Misuse for destruction. </strong>Assume the new country is malleable and \u201cfollows instructions\u201d\u2014and thus is essentially a country of mercenaries. Could existing rogue actors who want to cause destruction (such as terrorists) use or manipulate some of the people in the new country to make themselves much more effective, greatly amplifying the scale of destruction?</li>\n<li><strong>Misuse for seizing power. </strong>What if the country was in fact built and controlled by an existing powerful actor, such as a dictator or rogue corporate actor? Could that actor use it to gain decisive or dominant power over the world as a whole, upsetting the existing balance of power?</li>\n<li><strong>Economic disruption. </strong>If the new country is not a security threat in any of the ways listed in #1\u20133 above but simply participates peacefully in the global economy, could it still create severe risks simply by being so technologically advanced and effective that it disrupts the global economy, causing mass unemployment or radically concentrating wealth?</li>\n<li><strong>Indirect effects. </strong>The world will change very quickly due to all the new technology and productivity that will be created by the new country. Could some of these changes be radically destabilizing?</li>\n</ol>\n<p>I think it should be clear that this is a dangerous situation\u2014a report from a competent national security official to a head of state would probably contain words like \u201cthe single most serious national security threat we\u2019ve faced in a century, possibly ever.\u201d It seems like something the best minds of civilization should be focused on.</p>\n<p>Conversely, I think it would be absurd to shrug and say, \u201cNothing to worry about here!\u201d But, faced with rapid AI progress, that seems to be the view of many US policymakers, some of whom deny the existence of any AI risks, when they are not distracted entirely by the usual tired old hot-button issues. Humanity needs to wake up, and this essay is an attempt\u2014a possibly futile one, but it\u2019s worth trying\u2014to jolt people awake.</p></blockquote>\n<p>Yes, even if those were the only things to worry about, that\u2019s a super big deal.</p>\n<p>My responses:</p>\n<ol>\n<li>Yes, just yes, obviously if it wants to take over it can do that, and it probably effectively takes over even if it doesn\u2019t try. Dario spends time later arguing they would \u2018have a fairly good shot\u2019 to avoid sounding too weird, and if you need convincing you should read that section of the essay, but come on.\n<ol>\n<li>What are its intentions and goals? Great question.</li>\n</ol>\n</li>\n<li>Yeah, that is going to be a real problem.</li>\n<li>Given [X] can take over, if you can control [X] then you can take over, too.</li>\n<li>Participation in economics would mean it effectively takes over, and rapidly has control over an increasing share of resources. Worry less about wealth concentration among the humans and more about wealth and with it power and influence acquisition by the AIs. Whether or not this causes mass unemployment right away is less clear, it might require a bunch of further improvements and technological advancements and deployments first.</li>\n<li>Yes, it would be radically destabilizing in the best case.</li>\n<li>But all of this, even that these AIs could easily take over, buries the lede. If you had this nation of geniuses in a datacenter it would very obviously then make rapid further AI progress and go into full recursive self-improvement mode. It would quickly solve robotics, improve its compute efficiency, develop various other new technologies and so on. Thinking about what happens in this \u2018steady state\u2019 over a period of years is mostly asking a wrong question, as we will have already passed the point of no return.</li>\n</ol>\n\n\n<h4 class=\"wp-block-heading\">If He Wanted To, He Would Have</h4>\n\n\n<p>Dario correctly quickly dismisses the \u2018PAI won\u2019t be able to take over if it tried\u2019 arguments, and then moves on to whether it will try.</p>\n\n\n<h4 class=\"wp-block-heading\">So Will He Want To?</h4>\n\n\n<ol>\n<li>Some people say the PAI definitely won\u2019t want to take over, AIs only do what humans ask them to do. He provides convincing evidence that no, AIs do unexpected other stuff all the time. I\u2019d add that also some people will tell the AIs to take over to varying degrees in various ways.</li>\n<li>Some people say PAI (or at least sufficiently advanced AI) will inevitably seek power or deceive humans. He cites but does not name instrumental convergence, as well as \u2018AI will generalize that seeking power is good for achieving goals\u2019 in a way described as a heuristic rather than being accurate.</li>\n</ol>\n<blockquote><p>This \u201cmisaligned power-seeking\u201d is the intellectual basis of predictions that AI will inevitably destroy humanity.\u200b</p>\n<p>The problem with this pessimistic position is that it mistakes a vague conceptual argument about high-level incentives\u2014one that masks many hidden assumptions\u2014for definitive proof.</p></blockquote>\n<p>Once again, no, this is not in any way necessary for AI to end up destroying humanity, or for AI causing the world to go down a path where humanity ends up destroyed (without attributing intent or direct causation).</p>\n<blockquote><p>One of the most important hidden assumptions, and a place where what we see in practice has diverged from the simple theoretical model, is the implicit assumption that AI models are necessarily monomaniacally focused on a single, coherent, narrow goal, and that they pursue that goal in a clean, consequentialist manner.</p></blockquote>\n<p>This in particular <a href=\"https://x.com/allTheYud/status/2016377321452929452\">is a clear strawmanning</a> of the position of the worried. As Rob Bensinger points out, <a href=\"https://x.com/robbensinger/status/2016416947647422716\">there has been a book-length clarification of the actual position</a>, and LLMs will give you dramatically better summaries than Dario\u2019s here.</p>\n<blockquote><p><a href=\"https://x.com/MIRIBerkeley/status/2017036691920531647\">MIRI</a>: A common misconception\u2014showing up even in @DarioAmodei &#8216;s recent essay\u2014is that the classic case for worrying about AI risk assumes an AI &#8220;monomaniacally focused on a single, coherent, narrow goal.&#8221;</p>\n<p>But, as @ESYudkowsky explains, this is a misunderstanding of where the risk lies:</p>\n<p>Eliezer Yudkowsky: Similarly: A paperclip maximizer is not &#8220;monomoniacally&#8221; &#8220;focused&#8221; on paperclips. We talked about a superintelligence that wanted 1 thing, because you get exactly the same results as from a superintelligence that wants paperclips <em>and</em> staples (2 things), or from a superintelligence that wants 100 things. The number of things It wants bears zero relevance to anything. It&#8217;s just easier to explain the mechanics if you start with a superintelligence that wants 1 thing, because you can talk about how It evaluates &#8220;number of expected paperclips resulting from an action&#8221; instead of &#8220;expected paperclips * 2 + staples * 3 + giant mechanical clocks * 1000&#8221; and onward for a hundred other terms of Its utility function that all asymptote at different rates.</p></blockquote>\n<p>I\u2019d also refer to this response from Harlan Stewart, especially the maintaining of plausible deniability by not specifying who is being responded to:</p>\n<blockquote><p><a href=\"https://x.com/HumanHarlan/status/2016639776590614871\">Harlan Stewart</a>: I have a lot of thoughts about the Dario essay, and I want to write more of them up, but it feels exhausting to react to this kind of thing.</p>\n<p>The parts I object to are mostly just iterations of the same messaging strategy the AI industry has been using over the last two years:</p>\n<ol>\n<li>Discredit critics by strawmanning their arguments and painting them as crazy weirdos, while maintaining plausible deniability by not specifying which of your critics you&#8217;re referring to.</li>\n<li>Instead of engaging with critics&#8217; arguments in depth, dismiss them as being too &#8220;theoretical.&#8221; Emphasize the virtue of using &#8220;empirical evidence,&#8221; and use such a narrow definition of &#8220;empirical evidence&#8221; that it leaves no choice but to keep pushing ahead and see what happens, because the future will always be uncertain.</li>\n<li>Reverse the burden of proof. Instead of it being your responsibility to demonstrate that your R&amp;D project will not destroy the world, say that you will need definitive proof that it will destroy the world before changing course.</li>\n<li>Predict that superhumanly powerful minds will be built within a matter of years, while also suggesting that this timeline somehow gives adequate time for an iterative, trial-and-error approach to alignment.</li>\n</ol>\n</blockquote>\n<p>So again, no, none of that is being assumed. Power is useful for any goal it does not directly contradict, whether it be one narrow goal or a set of complex goals (which, for a sufficiently advanced AI, collapses to the same thing). Power is highly useful. It is especially useful when you are uncertain what your ultimate goal is going to be.</p>\n<p>Consequentialism is also not required for this. A system of virtue ethics would conclude it is good to grow more powerful. A deontologically based system would conclude the same thing to the extent it wasn\u2019t designed to effectively be rather dumb, even if it pursued this under its restrictions. And so on.</p>\n<p>While current AIs are best understood by treating them as what Dario calls \u2018psychologically complex\u2019 (however literally you do or don\u2019t take that), one should expect a sufficiently advanced AI to \u2018get over it\u2019 and effectively act optimally. The psychological complexity is the way of best dealing with various limitations, and in practical terms we should expect that it falls away if and as the limitations fall away. This is indeed what you see when humans get sufficiently advanced in a subdomain.</p>\n<blockquote><p>However, there is a more moderate and more robust version of the pessimistic position which does seem plausible, and therefore does concern me.\u200b</p>\n<p>\u2026 Some fraction of those behaviors will have a coherent, focused, and persistent quality (indeed, as AI systems get more capable, their long-term coherence increases in order to complete lengthier tasks), and some fraction of <em>those </em>behaviors will be destructive or threatening.</p>\n<p>\u2026 We don\u2019t need a specific narrow story for how it happens, and we don\u2019t need to claim it definitely will happen, we just need to note that the combination of intelligence, agency, coherence, and poor controllability is both plausible and a recipe for existential danger.</p></blockquote>\n<p>He goes on to add additional arguments and potential ways it could go down, such as extrapolating from science fiction or drawing ethical conclusions that become xenocidal, or that power seeking could emerge as a persona. Even if misalignment is not inevitable in any given instance, some instances becoming misaligned, and this causing them to be in some ways more fit and thus act in ways that make this dangerous, is completely inevitable as a default.</p>\n<p>Dario is asserting the extremely modest and obvious claim that building these PAIs is not a safe thing to do, that things could (as opposed to would, or probably will) get out of control.</p>\n<p>Yes, obviously they could get out of control. As Dario says Anthropic has already seen it happen during their own testing. If it doesn\u2019t happen, it will be because we acted wisely and stopped it from happening. If it doesn\u2019t become catastrophic, it will similarly be because we acted wisely and stopped that from happening.</p>\n\n\n<h4 class=\"wp-block-heading\">The Balance of Power</h4>\n\n\n<blockquote><p>Second, some may object that we can simply keep AIs in check with a balance of power between many AI systems, as we do with humans. The problem is that while humans vary enormously, AI systems broadly share training and alignment techniques across the industry, and those techniques may fail in a correlated way.</p>\n<p>Furthermore, given the cost of training such systems, it may even be the case that all systems are essentially derived from a very small number of base models.</p>\n<p>Additionally, even if a small fraction of AI instances are misaligned, they may be able to take advantage of <a href=\"https://sk.sagepub.com/ency/edvol/power/chpt/offense-defense-dominance\">offense-dominant</a> technologies, such that having \u201cgood\u201d AIs to defend against the bad AIs is not necessarily always effective.</p></blockquote>\n<p>I think this is far from the only problem.</p>\n<p>Humans are not so good at maintaining a balance of power. Power gets quite unbalanced quite a lot, and what balance we do have comes at very large expense. We\u2019ve managed to keep some amount of balance in large part because individual humans can only be in one place at a time, with highly limited physical and cognitive capacity, and thus have to coordinate with other humans in unreliable ways and with all the associated incentive problems, and also humans age and die, and we have strong natural egalitarian instincts, and so on.</p>\n<p>So, so many of the things that work for human balance of power simply don\u2019t apply in the AI scenarios, even before you consider that the AIs will largely be instances of the same model, and even without that likely will be good enough at decision theory to be essentially perfectly coordinated.</p>\n<p>I\u2019d also say the reverse of what Dario says in one aspect. Humans vary enormously in some senses, but they also all tap out at reasonably similar levels when healthy. Humans don\u2019t scale. AIs vary so much more than humans do, especially when one can have orders of magnitude more hardware and copies of itself available.</p>\n<p>The third objection he raises, that AI companies test their AIs before release, is not a serious reason to not worry about any of this.</p>\n\n\n<h4 class=\"wp-block-heading\">Defenses of Autonomy</h4>\n\n\n<p>He thinks there are four categories (this is condensed):</p>\n<blockquote>\n<ol>\n<li>First, it is important to develop the science of reliably training and steering AI models, of forming their personalities in a predictable, stable, and positive direction. One of our core innovations (aspects of which have since been adopted by other AI companies) is <a href=\"https://arxiv.org/abs/2212.08073\">Constitutional AI</a>.\n<ol>\n<li>Anthropic has just published its <a href=\"https://www.anthropic.com/constitution\">most recent constitution</a>, and one of its notable features is that instead of giving Claude a long list of things to do and not do (e.g., \u201cDon\u2019t help the user hotwire a car\u201d), the constitution attempts to give Claude a set of high-level principles and values.</li>\n<li>We believe that a feasible goal for 2026 is to train Claude in such a way that it almost never goes against the spirit of its constitution.</li>\n</ol>\n</li>\n</ol>\n</blockquote>\n<p>I have a three-part series on the recent Claude constitution. It is an extraordinary document and I think it is the best approach we can currently implement.</p>\n<p>\u200bAs I write in that serious, I don\u2019t think this works on its own as an \u2018endgame\u2019 strategy but it could help us quite a lot along the way.</p>\n<blockquote>\n<ol>\n<li>\u200bThe second thing we can do is develop the science of looking inside AI models to <em>diagnose</em> their behavior so that we can identify problems and fix them. This is the science of interpretability, and I\u2019ve talked about its <a href=\"https://www.darioamodei.com/post/the-urgency-of-interpretability\">importance in previous essays</a>.\n<ol>\n<li>The unique value of interpretability is that by looking inside the model and seeing how it works, you in principle have the ability to deduce what a model might do in a hypothetical situation you can\u2019t directly test\u2014which is the worry with relying solely on constitutional training and empirical testing of behavior.</li>\n<li>Constitutional AI (along with similar alignment methods) and mechanistic interpretability are most powerful when used together, as a back-and-forth process of improving Claude\u2019s training and then testing for problems.</li>\n</ol>\n</li>\n</ol>\n</blockquote>\n<p>I agree that interpretability is a useful part of the toolbox, although we need to be very careful with it lest it stop working or we think we know more than we do.</p>\n<blockquote>\n<ol>\n<li>\u200bThe third thing we can do to help address autonomy risks is to build the infrastructure necessary to monitor our models in live internal and external use, and publicly share any problems we find.</li>\n</ol>\n</blockquote>\n<p>Transparency and sharing problems is also useful, sure, although it is not a solution.</p>\n<blockquote>\n<ol>\n<li>\u200bThe fourth thing we can do is encourage coordination to address autonomy risks at the level of industry and society.\n<ol>\n<li>For example, some AI companies have shown a disturbing negligence towards the sexualization of children in today\u2019s models, which makes me doubt that they\u2019ll show either the inclination or the ability to address autonomy risks in future models.</li>\n<li>In addition, the commercial race between AI companies will only continue to heat up, and while the science of steering models can have some commercial benefits, overall the intensity of the race will make it increasingly hard to focus on addressing autonomy risks.</li>\n<li>I believe the only solution is legislation\u2014laws that directly affect the behavior of AI companies, or otherwise incentivize R&amp;D to solve these issues. Here it is worth keeping in mind the warnings I gave at the beginning of this essay about uncertainty and surgical interventions.</li>\n</ol>\n</li>\n</ol>\n</blockquote>\n<p>You can see here, as he talks about, \u2018autonomy risks,\u2019 that this doesn\u2019t have the punch it would have if you called it something that made the situation clear. \u2018Autonomy risks\u2019 sounds very nice and civilized, not like \u2018AIs take over\u2019 or \u2018everyone dies.\u2019</p>\n<p>You can also see the attempt to use a normie example, sexualization of children, where the parallel doesn\u2019t work so well, except as a pure \u2018certain companies I won\u2019t name have been so obviously deeply irresponsible that they obviously will keep being like that.\u2019 Which is a fair point, but the fact that Anthropic, Google and OpenAI have been good on such issues does not give me much comfort.</p>\n<p>What\u2019s the pitch?</p>\n<blockquote><p>Anthropic\u2019s view has been that the right place to start is with <em>transparency legislation, </em>which essentially tries to require that every frontier AI company engage in the transparency practices I\u2019ve described earlier in this section. <a href=\"https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=202520260SB53\">California\u2019s SB 53</a> and <a href=\"https://www.nysenate.gov/legislation/bills/2025/A6453/amendment/A\">New York\u2019s RAISE Act</a> are examples of this kind of legislation, which Anthropic supported and which have successfully passed. In supporting and helping to craft these laws, we\u2019ve put a particular focus on trying to minimize collateral damage, for example by exempting smaller companies unlikely to produce frontier models from the law.\u200b</p></blockquote>\n<p>Anthropic has had a decidedly mixed relationship with efforts along these lines, although they ultimately did support these recent minimalist efforts. I agree it is a fine place to start, but then were do you go after that? Anthropic was deeply reluctant even with extremely modest proposals and I worry this will continue.</p>\n\n\n<h4 class=\"wp-block-heading\">Weapon of Mass Destruction</h4>\n\n\n<p>If everyone has a genius in their pocket, will some people use it to do great harm? What happens when you no longer need rare technical skills to case catastrophe?</p>\n<p>Dario focuses on biological risks here, noting that LLMs are already substantially reducing barriers, but that skill barriers remain high. In the future, things could become far worse on such fronts.</p>\n<p>This is a tricky situation, especially if you are trying to get people to take it seriously. Every time nothing has happened yet people relax further. You only find out afterwards if things went too far and there\u2019s broad uncertainty about where that is. Meanwhile, there are other things we can do to mitigate risk but right now we are failing in maximally undignified ways:</p>\n<blockquote><p>An <a href=\"https://drive.google.com/file/d/1hNUnU8i2yubt5uesmmV17aTJXhYYDgTY/edit\">MIT study</a> found that 36 out of 38 providers fulfilled an order containing the sequence of the 1918 flu.\u200b</p></blockquote>\n<p>The counterargument is, essentially, People Don\u2019t Do Things, and the bad guys who try for real are rare and also rather bad at actually accomplishing anything. If this wasn\u2019t true the world would already look very different, for reasons unrelated to AI.</p>\n<blockquote><p>The best objection is one that I\u2019ve rarely seen raised: that there is a gap between the models being useful in principle and the actual propensity of bad actors to use them. Most individual bad actors are disturbed individuals, so almost by definition their behavior is unpredictable and irrational\u2014and it\u2019s <em>these</em> bad actors, the unskilled ones, who might have stood to benefit the most from AI making it much easier to kill many people.\u200b</p></blockquote>\n<p>One problem with this situation is that damage from such incidents is on a power law, up to and including global pandemics or worse. So the fact that the \u2018bad guys\u2019 are not taking so many competent shots on goal means that the first shot that hits could be quite catastrophically bad. Once that happens, many mistakes already made cannot be undone, both in terms of the attack and the availability of the LLMs, especially if they are open models.</p>\n<p>It\u2019s great that capability in theory doesn\u2019t usually translate into happening in practice, and we\u2019re basically able to use security through obscurity, but when that fails it can really fail hard.</p>\n\n\n<h4 class=\"wp-block-heading\">Defenses Against Biological Attacks</h4>\n\n\n<p>What can we do?</p>\n<blockquote><p>\u200bHere I see three things we can do.</p>\n<ol>\n<li>First, AI companies can put guardrails on their models to prevent them from helping to produce bioweapons. Anthropic is very actively doing this.\n<ol>\n<li>But all models <a href=\"https://www.microsoft.com/en-us/security/blog/2024/06/04/ai-jailbreaks-what-they-are-and-how-they-can-be-mitigated/\">can be jailbroken</a>, and so as a second line of defense, we\u2019ve implemented (since mid-2025, when our tests showed our models were starting to get close to the threshold where they might begin to pose a risk) a classifier that specifically detects and blocks bioweapon-related outputs.</li>\n<li>To their credit, some other AI companies <a href=\"https://arxiv.org/pdf/2504.01849\">have implemented classifiers as well</a>. But not every company has, and there is also nothing requiring companies to keep their classifiers. I am concerned that over time there may be a <a href=\"https://en.wikipedia.org/wiki/Prisoner%27s_dilemma\">prisoner\u2019s dilemma</a> where companies can defect and lower their costs by removing classifiers.</li>\n</ol>\n</li>\n</ol>\n</blockquote>\n<p>You can jailbreak any model. You can get around any classifier. In practice, the bad guys mostly won\u2019t, for the same reasons discussed earlier, so \u2018make it sufficiently hard and annoying\u2019 works. That\u2019s not the best long term solution.</p>\n<blockquote>\n<ol>\n<li>But ultimately defense may require government action, which is the second thing we can do.\u200b My views here are the same as they are for addressing autonomy risks: we should start with <a href=\"https://www.anthropic.com/news/the-need-for-transparency-in-frontier-ai\">transparency requirements</a>.\n<ol>\n<li>Then, if and when we reach clearer thresholds of risk, we can craft legislation that more precisely targets these risks and has a lower chance of collateral damage.</li>\n</ol>\n</li>\n<li>Finally, the third countermeasure we can take is to try to develop defenses against biological attacks themselves.\n<ol>\n<li>This could include monitoring and tracking for early detection, investments in air purification R&amp;D (such as <a href=\"https://worksinprogress.co/issue/the-death-rays-that-guard-life/\">far-UVC</a> disinfection), rapid vaccine development that can respond and adapt to an attack, better personal protective equipment (PPE), and treatments or vaccinations for some of the most likely biological agents.</li>\n<li><a href=\"https://en.wikipedia.org/wiki/MRNA_vaccine\">mRNA vaccines</a>, which can be designed to respond to a particular virus or variant, are an early example of <a href=\"https://worksinprogress.co/issue/the-golden-age-of-vaccine-development/\">what is possible here</a>.</li>\n</ol>\n</li>\n</ol>\n</blockquote>\n<p>We aren\u2019t even doing basic things like \u2018don\u2019t hand exactly the worst flu virus to whoever asks for it\u2019 so yes there is a lot to do in developing physical defenses. Alas, our response to the Covid pandemic has been worse than useless, with Moderna actively stopping work on mRNA vaccines due to worries about not getting approved, and we definitely aren\u2019t working much on air purification, far-UVC or PPE.</p>\n<p>If people who otherwise want to push forward were supporting at least those kinds of countermeasures more vocally and strongly, as opposed to letting us slide backwards, I\u2019d respect such voices quite a lot more.</p>\n<p>On the direct regulation of AI front, yes I think we need to at least have transparency requirements, and it will likely make sense soon to legally require various defenses be built into frontier AI systems.</p>\n\n\n<h4 class=\"wp-block-heading\">One Model To Rule Them All</h4>\n\n\n<blockquote><p>In <a href=\"https://darioamodei.com/essay/machines-of-loving-grace\"><em>Machines of Loving Grace</em></a>, I discussed the possibility that authoritarian governments might use powerful AI to surveil or repress their citizens in ways that would be extremely difficult to reform or overthrow. Current autocracies are limited in how repressive they can be by the need to have humans carry out their orders, and humans often have limits in how inhumane they are willing to be. But AI-enabled autocracies would not have such limits.</p>\n<p>\u200bWorse yet, countries could also use their advantage in AI to gain power over <em>other countries</em>.</p></blockquote>\n<p>That\u2019s a really bizarre \u2018worse yet\u2019 isn\u2019t it? Most every technology in history has been used to get an advantage in power by some countries over other countries. It\u2019s not obviously good or bad for nation [X] to have power over nation [Y].</p>\n<p>America certainly plans to use AI to gain power. If you asked \u2018what country is most likely to use AI to try to impose its will on other nations\u2019 the answer would presumably be the United States.</p>\n<blockquote><p>There are many ways in which AI could enable, entrench, or expand autocracy, but I\u2019ll list a few that I\u2019m most worried about. Note that some of these applications have legitimate defensive uses, and I am not necessarily arguing against them in absolute terms; I am nevertheless worried that they structurally tend to favor autocracies:</p>\n<ul>\n<li><strong>Fully autonomous weapons.</strong></li>\n<li><strong>\u200bAI surveillance. </strong>Sufficiently powerful AI could likely be used to compromise any computer system in the world, and could also use the access obtained in this way to read <em>and make sense of</em> all the world\u2019s electronic communications.</li>\n<li><strong>AI propaganda.</strong></li>\n<li><strong>Strategic decision-making.</strong></li>\n</ul>\n</blockquote>\n<p>If your AI can compromise any computer system in the world and make sense of all the world\u2019s information, perhaps AI surveillance should be rather far down on your list of worries for that?</p>\n<p>Certainly misuse of AI for various purposes is a real threat, but let us not lack imagination. An AI capable of all this can do so much more. In terms of who is favored in such scenarios, assuming we continue to disregard fully what Dario calls \u2018autonomy risks,\u2019 the obvious answer is whoever has access to the most geniuses in the data centers willing to cooperate with them, combined with who has access to capital.</p>\n<p>Dario\u2019s primary worry is the CCP, especially if it takes the lead in AI, noting that the most likely to suffer here are the Chinese themselves. Democracies competitive in AI are listed second, with the worry that AI would be used to route around democracy.</p>\n<p>AI companies are only listed fourth, behind other autocracies. Curious.</p>\n<p>It\u2019s less that autocracy becomes favored in such scenarios, as that the foundations of democracy by default will stop working. The people won\u2019t be in the loops, won\u2019t play a key part in having new ideas or organizing or expanding the economy, won\u2019t be key to military or state power, you won\u2019t need lots of people willing to carry out the will of the state, and so on. The reasons democracy historically wins may potentially be going away.</p>\n\n\n<h4 class=\"wp-block-heading\">Defenses Against Autocracy</h4>\n\n\n<p>At last we at least one easy policy intervention we can get behind.</p>\n<blockquote>\n<ol>\n<li>\u200bFirst, we should absolutely not be selling chips, chip-making tools, or datacenters to the CCP\u2026. It makes no sense to sell the CCP the tools with which to build an AI totalitarian state and possibly conquer us militarily.\n<ol>\n<li>A number of complicated arguments are made to justify such sales, such as the idea that \u201cspreading our tech stack around the world\u201d allows \u201cAmerica to win\u201d in some general, unspecified economic battle. In my view, this is like selling nuclear weapons to North Korea and then bragging that the missile casings are made by Boeing and so the US is \u201cwinning.\u201d</li>\n</ol>\n</li>\n</ol>\n</blockquote>\n<p>Yes. Well said. It really is this simple.</p>\n<blockquote>\n<ol>\n<li>\u200bSecond, it makes sense to use AI to empower democracies to resist autocracies. This is the reason Anthropic considers it important to provide AI to the intelligence and defense communities in the US and its democratic allies.</li>\n<li>Third, we need to draw a hard line against AI abuses within democracies. There need to be limits to what we allow our governments to do with AI, so that they don\u2019t seize power or repress their own people. The formulation I have come up with is that we should use AI for national defense in all ways <em>except those which would make us more like our autocratic adversaries</em>.\n<ol>\n<li>Where should the line be drawn? In the list at the beginning of this section, two items\u2014using AI for domestic mass surveillance and mass propaganda\u2014seem to me like bright red lines and entirely illegitimate.</li>\n<li>The other two items\u2014fully autonomous weapons and AI for strategic decision-making\u2014are harder lines to draw since they have legitimate uses in defending democracy, while also being prone to abuse.</li>\n</ol>\n</li>\n</ol>\n</blockquote>\n<p>It is difficult to draw clear lines on such questions, but you do have to draw the lines somewhere, and that has to be a painful action if it\u2019s going to work.</p>\n<blockquote>\n<ol>\n<li>\u200bFourth, after drawing a hard line against AI abuses in democracies, we should use that precedent to create an international taboo against the worst abuses of powerful AI. I recognize that the current political winds have turned against international cooperation and international norms, but this is a case where we sorely need them.</li>\n</ol>\n</blockquote>\n<p>It is not, as he says and shall we say, a good time to be asking for norms of this type, for various reasons. If we continue down our current path, it doesn\u2019t look good.</p>\n<blockquote>\n<ol>\n<li>Fifth and finally, AI companies should be carefully watched, as should their connection to the government, which is necessary, but must have limits and boundaries\u200b</li>\n</ol>\n</blockquote>\n<p>Dario is severely limited here in what he can say out loud, and perhaps in what he allows himself to think. I encourage each of us to think seriously about what one would say if such restrictions did not apply.</p>\n\n\n<h4 class=\"wp-block-heading\">They Took Our Jobs</h4>\n\n\n<p>Ah, good, some simple economic disruption problems. Every essay needs a break.</p>\n<blockquote><p>\u200bIn <a href=\"https://darioamodei.com/essay/machines-of-loving-grace\"><em>Machines of Loving Grace</em></a>, I suggest that a 10\u201320% sustained annual GDP growth rate may be possible.</p>\n<p>But it should be clear that this is a double-edged sword: what are the economic prospects for most existing humans in such a world?</p>\n<p>There are two specific problems I am worried about: labor market displacement, and concentration of economic power.</p></blockquote>\n<p>Dario starts off pushing back against those who think AI couldn\u2019t possibly disrupt labor markets and cause mass unemployment, crying \u2018lump of labor fallacy\u2019 or what not, so he goes through the motions to show he understands all that including the historical context.</p>\n<blockquote><p>It\u2019s possible things will go roughly the same way with AI, but I would bet pretty strongly against it. Here are some reasons I think AI is likely to be different:</p>\n<ul>\n<li>\u200bSpeed.</li>\n<li>Cognitive breadth.</li>\n<li>Slicing by cognitive ability.</li>\n<li>Ability to fill in the gaps.</li>\n</ul>\n<p>Slow diffusion of technology is <a href=\"https://www.ft.com/content/3b93e647-2a8b-4fb4-831d-e27adf4db5f8\">definitely real</a>\u2014I talk to people from a wide variety of enterprises, and there are places where the adoption of AI will take years. That\u2019s why my prediction for 50% of entry level white collar jobs being disrupted is 1\u20135 years, even though I suspect we\u2019ll have powerful AI (which would be, technologically speaking, enough to do <em>most or all </em>jobs, not just entry level) in much less than 5 years.</p>\n<p>Second, some people say that human jobs will move to the physical world, which avoids the whole category of \u201ccognitive labor\u201d where AI is progressing so rapidly. I am not sure how safe this is, either.</p>\n<p>Third, perhaps some tasks inherently require or greatly benefit from a human touch. I\u2019m a little more uncertain about this one, but I\u2019m still skeptical that it will be enough to offset the bulk of the impacts I described above.</p>\n<p>Fourth, some may argue that comparative advantage will still protect humans. Under the <a href=\"https://en.wikipedia.org/wiki/Comparative_advantage\">law of comparative advantage</a>, even if AI is better than humans at everything, any <em>relative </em>differences between the human and AI profile of skills creates a basis of trade and specialization between humans and AI. The problem is that if AIs are literally thousands of times more productive than humans, this logic starts to break down. Even tiny <a href=\"https://en.wikipedia.org/wiki/Transaction_cost\">transaction costs</a> could make it not worth it for AI to trade with humans. And human wages may be very low, even if they technically have something to offer.</p></blockquote>\n<p>Dario\u2019s basic explanation here is solid, especially since he\u2019s making a highly tentative and conservative case. He\u2019s portraying a scenario where things in many senses move remarkably slowly, and the real question is not \u2018why would this disrupt employment\u2019 but \u2018why wouldn\u2019t this be entirely transformative even if it is not deadly.\u2019</p>\n\n\n<h4 class=\"wp-block-heading\">Don\u2019t Let Them Take Our Jobs</h4>\n\n\n<p>Okay, candlemakers, lay out your petitions.</p>\n<blockquote><p>\u200bWhat can we do about this problem? I have several suggestions, some of which Anthropic is already doing.</p>\n<ol>\n<li>The first thing is simply to get accurate data about what is happening with job displacement in real time.</li>\n<li>Second, AI companies have a choice in how they work with enterprises. The very inefficiency of traditional enterprises means that their rollout of AI can be very path dependent, and there is some room to choose a better path.</li>\n<li>Third, companies should think about how to take care of their employees.</li>\n<li>Fourth, wealthy individuals have an obligation to help solve this problem. It is sad to me that many wealthy individuals (especially in the tech industry) have recently adopted a cynical and nihilistic attitude that philanthropy is inevitably fraudulent or useless.\n<ol>\n<li>All of Anthropic\u2019s co-founders have pledged to donate 80% of our wealth, and Anthropic\u2019s staff have individually pledged to donate company shares worth billions at current prices\u2014donations that the company has committed to matching.</li>\n</ol>\n</li>\n<li>Fifth, while all the above private actions can be helpful, ultimately a macroeconomic problem this large will require government intervention.</li>\n</ol>\n<p>Ultimately, I think of all of the above interventions as ways to buy time.</p></blockquote>\n<p>The last line is the one that matters most. Mostly all you can do is buy a little time.</p>\n<p>If you want to try and do more than that, and the humans can remain alive and in control (or in Dario\u2019s term \u2018we solve the autonomy problem\u2019) then you can engage in massive macroeconomic redistribution, either by government or by the wealthy or both. There will be enough wealth around, and value produced, that everyone can have material abundance.</p>\n<p>That doesn\u2019t protect jobs. To protect jobs in such a scenario, you would need to explicitly protect jobs via protectionism and restrictions. I don\u2019t love that idea.</p>\n\n\n<h4 class=\"wp-block-heading\">Economic Concentrations of Power</h4>\n\n\n<p>Assuming everyone is doing fine materially, the real problem with economic inequality is the problem of economic concentration of power. Dario worries that too much wealth concentration would break society.</p>\n<blockquote><p>Democracy is ultimately backstopped by the idea that the population as a whole is necessary for the operation of the economy. If that economic leverage goes away, then the implicit social contract of democracy may stop working.</p></blockquote>\n<p>So that\u2019s the thing. That leverage is going to go away. I don\u2019t see any distribution of wealth changing that inevitability. \u200b</p>\n<p>What can be done?</p>\n<blockquote><p>First, and most obviously, companies should simply choose not to be part of it.\u200b</p></blockquote>\n<p>By this he means that companies (and individuals) can choose to advocate in the public interest, rather than in the interests of themselves or the wealthy.</p>\n<blockquote><p>Second, the AI industry needs a healthier relationship with government\u2014one based on substantive policy engagement rather than political alignment.\u200b</p></blockquote>\n<p>That is a two way street. Both sides have to be willing.</p>\n<p>Dario frames Anthropic\u2019s approach as being principled, and willing to take a stand for what they believe in. As I\u2019ve said before, I\u2019m very much for standing up for what you believe in, and in some cases I\u2019m very much for pragmatism, and I think it\u2019s actively good that Anthropic does a mix of both.</p>\n<p>My concern is that Anthropic\u2019s actions have not been on the Production Possibilities Frontier. As in, I feel Anthropic has spoken up in ways that don\u2019t help much but that burn a bunch of political capital with key actors, and also Anthropic has failed to speak up in places where they could have helped a lot at small or no expense. As long as we stick to the frontier, we can talk price.</p>\n\n\n<h4 class=\"wp-block-heading\">Unknown Unknowns</h4>\n\n\n<p>Dario calls this the \u2018black seas of infinity,\u2019 of various indirect effects.</p>\n<blockquote><p>Suppose we address all the risks described so far, and begin to reap the benefits of AI. We will likely get a \u201c<a href=\"https://www.darioamodei.com/essay/machines-of-loving-grace\">century of scientific and economic progress compressed into a decade</a>,\u201d and this will be hugely positive for the world, but we will then have to contend with the problems that arise from this rapid rate of progress, and those problems may come at us fast.\u200b</p></blockquote>\n<p>This would include:</p>\n<blockquote>\n<ul>\n<li>\u200bRapid advances in biology.</li>\n<li>AI changes human life in an unhealthy way.</li>\n<li>Human purpose.</li>\n</ul>\n</blockquote>\n<p>On biology, the idea that extending lifespan might make people power-seeking or unstable strikes me as way more science fiction than anything that those worried about AI have prominently said. I think this distinction is illustrative.</p>\n<p>Science fiction (along with fantasy) usually has a rule that if you seek an \u2018unnatural\u2019 or \u2018unfair\u2019 benefit, that there must be some sort of \u2018catch\u2019 to it. Something will go horribly wrong. The price must be paid.</p>\n<p>Why? Because there is no story without it, and because we want to tell ourselves why it is okay that we are dumb and grow old and die. That\u2019s why. Also, <a href=\"https://www.youtube.com/watch?v=84ebGxPONXU\">because it\u2019s wrong</a>. You \u2018shouldn\u2019t\u2019 want to be <a href=\"https://en.wikipedia.org/wiki/Flowers_for_Algernon\">smarter</a>, or <a href=\"https://en.wikipedia.org/wiki/Altered_Carbon_(TV_series)\">live forever</a>, or <a href=\"https://en.wikipedia.org/wiki/The_Substance\">be or look younger</a>, or <a href=\"https://en.wikipedia.org/wiki/Frankenstein_(2025_film)\">create a man artificially</a>. Such hubris, such blasphemy.</p>\n<p>Not that there aren\u2019t trade-offs with new technologies, especially in terms of societal adjustments, but the alternative remains among other issues the planetary death rate of 100%.</p>\n<p>AI \u2018changing human life in an unhealthy way\u2019 will doubtless happen in dozens of ways if we are so lucky as to be around for it to happen. It will also enhance our life in other ways. Dario does some brainstorming, including reinventing <a href=\"https://croissanthology.com/earring\">the whispering earring</a>, and also loss of purpose which is sufficiently obvious it counts as a Known Known.</p>\n\n\n<h4 class=\"wp-block-heading\">Oh Well Back To Racing</h4>\n\n\n<p>Sounds like we have some big problems, even if we accept Dario\u2019s framing of the geniuses in the data center basically sitting around being ordinary geniuses rather than quickly proceeding to the next phase.</p>\n<p>It\u2019s a real shame we can\u2019t actually do anything about them that would cost us anything, or speak aloud about what we want to be protecting other than \u2018democracy.\u2019</p>\n<blockquote><p>\u200bFurthermore, the last few years should make clear that the idea of stopping or even substantially slowing the technology is fundamentally untenable.</p>\n<p>I do see a path to a <em>slight</em> moderation in AI development that is compatible with a <a href=\"https://en.wikipedia.org/wiki/Realism_(international_relations)\">realist view of geopolitics</a>.</p></blockquote>\n<p>This is where we are. We\u2019re about to go down a path likely to kill literally everyone, and the responsible one is saying maybe we can \u2018see a path to\u2019 a <em>slight </em>moderation.</p>\n<p>He doesn\u2019t even talk about building capacity to potentially slow down or intercede, if the situation should call for it. I think we should read this as, essentially, \u2018I cannot rhetorically be seen talking about that, and thus my failure to mention it should not be much evidence of whether I think this would be a good idea.\u2019</p>\n<p>Harlan Stewart notes a key rhetorical change, and not for the better:</p>\n<blockquote><p><a href=\"https://x.com/HumanHarlan/status/2015886802222252257\">Harlan Stewart</a>: You flipped the burden of proof. In 2023, Anthropic\u2019s position was:</p>\n<p>\u201cIndications that we are in a pessimistic or near-pessimistic scenario may be sudden and hard to spot. We should therefore always act under the assumption that we still may be in such a scenario unless we have sufficient evidence that we are not.\u201d</p>\n<p>But in this essay, you say:</p>\n<p>\u201cTo be clear, I think there\u2019s a decent chance we eventually reach a point where much more significant action is warranted, but that will depend on stronger evidence of imminent, concrete danger than we have today, as well as enough specificity about the danger to formulate rules that have a chance of addressing it.\u201d</p></blockquote>\n<p>Here is how the essay closes:</p>\n<blockquote><p>But we will need to step up our efforts if we want to succeed. The first step is for those closest to the technology to simply tell the truth about the situation humanity is in, which I have always tried to do; I\u2019m doing so more explicitly and with greater urgency with this essay.</p>\n<p>The next step will be convincing the world\u2019s thinkers, policymakers, companies, and citizens of the imminence and overriding importance of this issue\u2014that it is worth expending thought and political capital on this in comparison to the thousands of other issues that dominate the news every day. Then there will be a time for courage, for enough people to buck the prevailing trends and stand on principle, even in the face of threats to their economic interests and personal safety.</p>\n<p>The years in front of us will be impossibly hard, asking more of us than we think we can give. But in my time as a researcher, leader, and citizen, I have seen enough courage and nobility to believe that we can win\u2014that when put in the darkest circumstances, humanity has a way of gathering, seemingly at the last minute, the strength and wisdom needed to prevail. We have no time to lose.\u200b</p></blockquote>\n<p>Yes. <a href=\"https://x.com/scaling01/status/2015882618831568948\">This stands in sharp contrast with the writings of Sam Altman over at OpenAI</a>, where he talks about cool ideas and raising revenue.</p>\n<p>The years in front of us will be impossibly hard (in some ways), asking more of us than we think we can give. That goes for Dario as well. What he thinks can be done is not going to get it done.</p>\n<p>Dario\u2019s strategy is that we have a history of pulling through seemingly at the last minute under dark circumstances. You know, like Inspector Clouseau, The Flash or Buffy the Vampire Slayer.</p>\n<p>He is the CEO of a frontier AI company called Anthropic.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n\n\n<h4 class=\"wp-block-heading\"></h4>\n\n\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>\u200b</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>"
            ],
            "link": "https://thezvi.wordpress.com/2026/01/30/on-the-adolescence-of-technology/",
            "publishedAt": "2026-01-30",
            "source": "TheZvi",
            "summary": "Anthropic CEO Dario Amodei is back with another extended essay, The Adolescence of Technology. This is the follow up to his previous essay Machines of Loving Grace. In MoLG, Dario talked about some of the upsides of AI. Here he &#8230; <a href=\"https://thezvi.wordpress.com/2026/01/30/on-the-adolescence-of-technology/\">Continue reading <span class=\"meta-nav\">&#8594;</span></a>",
            "title": "On The Adolescence of Technology"
        },
        {
            "content": [],
            "link": "https://xkcd.com/3201/",
            "publishedAt": "2026-01-30",
            "source": "XKCD",
            "summary": "<img alt=\"There's also a proof without content of a conjecture without content, but it's left as an exercise for the reader.\" src=\"https://imgs.xkcd.com/comics/proof_without_content.png\" title=\"There's also a proof without content of a conjecture without content, but it's left as an exercise for the reader.\" />",
            "title": "Proof Without Content"
        }
    ],
    "lookbackDays": 1,
    "publishDate": "2026-01-30"
}