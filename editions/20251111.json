{
    "articles": [
        {
            "content": [],
            "link": "https://overreacted.io/hire-me-in-japan/",
            "publishedAt": "2025-11-11",
            "source": "Dan Abramov",
            "summary": "I'm looking for a new job.",
            "title": "Hire Me in Japan"
        },
        {
            "content": [
                "<p><img alt=\"&quot;Theseus Fighting the Centaur Bianor&quot;, by Antoine-Louis Barye, 1867\" src=\"https://www.dbreunig.com/img/fighting_a_centaur.jpg\" /></p>\n\n<p>For the first year or so, one of the most annoying problems faced by building with AI was getting them to generate output with consistent formatting. Go find someone who was working with AI in 2023 and ask them what they did to <em>try</em> to get LLMs to consistently output JSON. You\u2019ll get a thousand-yard stare before hearing about all-caps commands, threats towards the LLM, promises of <em>bribes</em> for the LLM, and (eventually) resorting to regular expressions.</p>\n\n<p>Today, this is mostly a solved problem, but the <em>cause</em> of this issue remains, frustrating today\u2019s context engineers. It\u2019s a context failure I missed in my <a href=\"https://www.dbreunig.com/2025/06/22/how-contexts-fail-and-how-to-fix-them.html\">original list</a>. I call it <strong>Fighting the Weights</strong>: when the model won\u2019t do what you ask because you\u2019re working against its training.</p>\n\n<hr />\n\n<p>In 2020, OpenAI unveiled GPT-3 alongside a key paper: \u201c<a href=\"https://arxiv.org/abs/2005.14165\">Language Models are Few-Shot Learners</a>.\u201d In this paper, OpenAI researchers showed that LLMs as large as GPT-3 (10x larger than previous language models) could perform tasks when provided with only a few examples. At the time, this was earth-shaking.</p>\n\n<p>Pre-GPT-3, language models were only useful after they\u2019d been fine-tuned for specific tasks; after their <em>weights</em> had been modified. But GPT-3 showed that with enough scale, LLMs could be problem-solving generalists if provided with a few examples. In OpenAI\u2019s paper they coined the term \u201c<strong>in-context learning</strong>\u201d to describe an LLM\u2019s ability to perform new types of tasks using examples and instructions contained in the prompt.</p>\n\n<p>Today, <strong>in-context learning</strong> is a standard trick in any context engineer\u2019s toolkit. Provide a few examples illustrating what you want back, given an input, and trickier tasks tend to get more reliable. They\u2019re especially helpful when we need to induce a specific format or style or convey a pattern that\u2019s difficult to explain<sup id=\"fnref:claude\"><a class=\"footnote\" href=\"https://www.dbreunig.com/2025/11/11/don-t-fight-the-weights.html#fn:claude\" rel=\"footnote\">1</a></sup>.</p>\n\n<p>When you\u2019re not providing examples, you\u2019re relying on the model\u2019s inherent knowledge base and weights to accomplish your task. We sometimes call this \u201c<strong>zero-shot prompting</strong>\u201d (as opposed to <em>few</em> shot<sup id=\"fnref:shot\"><a class=\"footnote\" href=\"https://www.dbreunig.com/2025/11/11/don-t-fight-the-weights.html#fn:shot\" rel=\"footnote\">2</a></sup>) or \u201c<strong>instruction-only prompting</strong>\u201d.</p>\n\n<p>In general, prompts fall into these two buckets:</p>\n\n<ol>\n  <li><strong>Zero-Shot or Instruction-Only Prompting:</strong> You provide instructions <em>only</em>. You\u2019re asking the model to apply knowledge and behavioral patterns that are encoded in its weights. If this produces unreliable results, you might use\u2026</li>\n  <li><strong>Few-Shot or In-Context Learning:</strong> You provide instructions <em>plus examples</em>. You\u2019re demonstrating a new behavioral pattern for the model to apply. The examples in the context <em>augment</em> the weights, providing them with details for a task it hasn\u2019t seen.</li>\n</ol>\n\n<p>But there\u2019s a third case: when the model <em>has</em> seen examples of the behavior you\u2019re seeking, but it\u2019s been trained to do the opposite of what you want. This is <em>worse</em> than the model having no knowledge of a pattern, because what it knows is at odds with your goal.</p>\n\n<p>I call this <strong>fighting the weights</strong>.</p>\n\n<p>Here\u2019s some ways we end up fighting the weights:</p>\n\n<ul>\n  <li><strong>Format Following:</strong> You want the model to output only JSON, but often it will provide some text explaining the JSON and wrap the JSON in Markdown code blocks. This happens because the model\u2019s post-training taught it to be conversational. When ChatGPT first launched, this problem was <em>rough</em>. GPT-3.5 had been heavily trained by humans to converse in a friendly, explanatory manner. So it did \u2013\u00a0even when you asked it not to. This doesn\u2019t happen as much as it used to, but we\u2019ll occasionally run into this issue when using unique formats or when using smaller models.</li>\n  <li><strong>Tool Usage Formatting:</strong> As model builders start training their models to use tools, via reinforcement learning, they select specific formats and conventions. If your environment doesn\u2019t follow these conventions, the model often fails to call tools correctly. I first noticed this while testing Mistral\u2019s <a href=\"https://huggingface.co/mistralai/Devstral-Small-2505\">Devstral-Small</a>, which was <a href=\"https://huggingface.co/mistralai/Devstral-Small-2505/discussions/9\">trained with the tool-calling format</a> <a href=\"https://openhands.dev\">All Hands</a> uses. When I tried to use Devstral with <a href=\"https://cline.bot\">Cline</a>, it failed basic tasks. Last month this came up when a friend was trying Kimi K2 with a DSPy pipeline. By default, DSPy formats prompts with a <a href=\"https://dspy.ai/api/adapters/ChatAdapter/\">Markdown-style template</a>. When this pipeline was driven by K2, formatting failed. Thanks to my recent <a href=\"https://www.dbreunig.com/2025/07/30/how-kimi-was-post-trained-for-tool-use.html\">dive into how Moonshine trained K2 to use tools</a>, I knew K2 was trained with XML formatting. Switching DSPy to XML formatting solved the problem instantly.</li>\n  <li><strong>Tone Changes:</strong> It\u2019s really hard to apply consistent tone instructions to LLMs. Sure, we can make them talk like a pirate or in pig-latin, but subtle notes are overwhelmed by the model\u2019s conversational post-training. For example, here\u2019s the one note I give Claude in my settings: \u201cDon\u2019t go out of your way to patronize me or tell me how great my ideas are.\u201d This does <em>not</em> stop Claude from replying with cloying phrases like, \u201cGreat idea!\u201d when I suggest changes.</li>\n  <li><strong>Overactive Alignment:</strong> Speaking of Claude: I appreciate Anthropic\u2019s concern for alignment and safety in their models, but these guardrails can be overzealous. A recent example comes from Armin Ronacher, <a href=\"https://x.com/mitsuhiko/status/1986833561287024897\">who tried several different approaches to get Claude Code to modify a medical form PDF while debugging PDF editing software</a>. Armin asked several different ways, but Claude\u2019s post-training alignment refused to budge.</li>\n  <li><strong>Over Relying On Weights:</strong> Models are trained to utilize the knowledge encoded in their weights. But there are many times when you want them to <em>only</em> answer with information provided in the context. Perusing <a href=\"https://github.com/x1xhlol/system-prompts-and-models-of-ai-tools\">leaked system prompts</a>, you can see how many instructions each chatbot maker gives when it comes to <em>when</em> models should search to obtain more info. The models have been trained to use their weights, so plenty of reiteration and examples are needed. This problem is especially tricky when building RAG systems, when the model should only form answers based on information obtained from specific databases. Companies like <a href=\"https://contextual.ai\">Contextual</a> end up having to fine-tune their models to ensure they only answer with fetched information.</li>\n</ul>\n\n<p>Perhaps my favorite example I\u2019ve seen was from ChatGPT. Previously, you could turn on the web inspector in your browser and watch the LLM calls fly by as you used the chatbot. This was handy for seeing when additional messages were added, that you didn\u2019t write. When you asked ChatGPT to generate an image, it would clean up or <a href=\"https://www.dbreunig.com/2025/03/16/overcoming-bad-prompts-with-help-from-llms.html\">even improve your image prompt</a>, create the image, then <a href=\"https://x.com/dbreunig/status/1952051780424196513/photo/1\">append the following instructions</a>:</p>\n\n<blockquote>\n  <p>GPT-4o returned 1 images. From now on, do not say or show ANYTHING. Please end this turn now. I repeat: From now on, do not say or show ANYTHING. Please end this turn now. Do not summarize the image. Do not ask followup question. Just end the turn and do not do anything else.</p>\n</blockquote>\n\n<p>This is textbook fighting the weights. The models powering ChatGPT have been post-trained heavily to always explain and prompt the user for follow up actions. To fight these weights, ChatGPT\u2019s devs have to tell the model EIGHT TIMES to just, please, <em>shut up.</em></p>\n\n<hr />\n\n<p>For context and prompt engineers (and even chatbot users) it\u2019s helpful to be able to recognize when you\u2019re <em>fighting the weights</em>.</p>\n\n<p>Here\u2019s some signs you might be fighting the weights:</p>\n\n<ul>\n  <li>The model makes the same mistake, even as you change the instructions.</li>\n  <li>The model acknowledges its mistake when pointed out, then repeats it.</li>\n  <li>The model seems to ignore the few-shot examples you provide.</li>\n  <li>The model gets 90% of the way there, but no further.</li>\n  <li>You find yourself repeating instructions several times.</li>\n  <li>You find yourself typing in ALL CAPS.</li>\n  <li>You find yourself threatening or pleading with the model.</li>\n</ul>\n\n<p>In these scenarios, you\u2019re probably fighting the weights. Recognize the situation and try another tack:</p>\n\n<ul>\n  <li>Try another approach for the same problem.</li>\n  <li>Break your task into smaller chunks. At the very least, you might identify the ask that clashes.</li>\n  <li>Try another model, ideally from a different family.</li>\n  <li>Add validation functions or steps. I\u2019ve seen RAG pipelines that perform a final check to ensure the answer exists in the fetched data.</li>\n  <li>Try a longer prompt. It can help in this scenario, as <a href=\"https://www.dbreunig.com/2025/06/22/how-contexts-fail-and-how-to-fix-them.html#context-distraction\">longer contexts can overwhelm the weights</a>.</li>\n  <li>Consider fine-tuning. In fact, most fine-tuning I encounter is done to address \u2018weight fighting\u2019 scenarios, like tone or format adherence.</li>\n</ul>\n\n<p>Or, if you\u2019re a model building shop, you can just address your issues during your next model\u2019s post-training. Which seems to be part of <a href=\"https://www.dbreunig.com/2025/06/03/comparing-system-prompts-across-claude-versions.html\">their development cycle</a>\u2026and perhaps why we can get clean JSON out of modern models.</p>\n\n<p>But few of us have that option.</p>\n\n<p>For the rest of us: learn to recognize when you\u2019re fighting the weights, so you can try something else.</p>\n\n<hr />\n\n<form action=\"https://buttondown.com/api/emails/embed-subscribe/dbreunig\" class=\"embeddable-buttondown-form\" method=\"post\" target=\"popupwindow\">\n  <label for=\"bd-email\">Enter your email to receive the occasional update.</label>\n  <div class=\"form-input\">\n    <input id=\"bd-email\" name=\"email\" type=\"email\" />\n    <input type=\"submit\" value=\"Subscribe\" />\n  </div>\n</form>\n<div class=\"footnotes\">\n  <ol>\n    <li id=\"fn:claude\">\n      <p>For example, <a href=\"https://github.com/x1xhlol/system-prompts-and-models-of-ai-tools/blob/50b1893b9d3c8bdf6dbb77e660419e7177409728/Anthropic/Sonnet%204.5%20Prompt.txt#L256C1-L257C1\">Claude Sonnet 4.5\u2019s system prompt</a> provides detailed instructions about <em>when</em> to use search tools to answer a user\u2019s query. This is a hard task to prompt correctly. You want the model to rely on its existing knowledge base as much as possible to deliver fast answers, but to readily use web search for timely information or information not in the model\u2019s weights. Besides giving instructions, Anthropic provides examples illustrating more subtle edge cases.\u00a0<a class=\"reversefootnote\" href=\"https://www.dbreunig.com/2025/11/11/don-t-fight-the-weights.html#fnref:claude\">&#8617;</a></p>\n    </li>\n    <li id=\"fn:shot\">\n      <p>\u201cShot\u201d is hold-over jargon from the machine learning community. There\u2019s some nuance here, but unless you\u2019re actively collaborating with ML engineers, you can just swap \u201cexample\u201d in anytime you see \u201cshot\u201d.\u00a0<a class=\"reversefootnote\" href=\"https://www.dbreunig.com/2025/11/11/don-t-fight-the-weights.html#fnref:shot\">&#8617;</a></p>\n    </li>\n  </ol>\n</div>"
            ],
            "link": "https://www.dbreunig.com/2025/11/11/don-t-fight-the-weights.html",
            "publishedAt": "2025-11-11",
            "source": "Drew Breunig",
            "summary": "When your context goes against a model's training, you struggle to get the output you need. Learn to recognize when you're fighting the weights so you can do something different.",
            "title": "Don\u2019t Fight the Weights"
        },
        {
            "content": [],
            "link": "https://bernsteinbear.com/blog/compiler-effects/?utm_source=rss",
            "publishedAt": "2025-11-11",
            "source": "Max Bernstein",
            "summary": "<p>Optimizing compilers like to keep track of each IR instruction\u2019s <em>effects</em>. An instruction\u2019s effects vary wildly from having no effects at all, to writing a specific variable, to completely unknown (writing all state).</p> <p>This post can be thought of as a continuation of <a href=\"https://bernsteinbear.com/blog/irs/\">What I talk about when I talk about IRs</a>, specifically the section talking about asking the right questions. When we talk about effects, we should ask the right questions: not <em>what opcode is this?</em> but instead <em>what effects does this opcode have?</em></p> <p>Different compilers represent and track these effects differently. I\u2019ve been thinking about how to represent these effects all year, so I have been doing some reading. In this post I will give some summaries of the landscape of approaches. Please feel free to suggest more.</p> <h2 id=\"some-background\">Some background</h2> <p>Internal IR effect tracking is similar to the programming language notion of algebraic effects in type systems, but internally, compilers keep track of finer-grained effects. Effects such as \u201cwrites to a local variable\u201d, \u201cwrites to a list\u201d, or \u201creads from the stack\u201d indicate what instructions can be re-ordered, duplicated, or removed entirely.</p> <p>For example, consider the following pseodocode for some made-up language that stands in for",
            "title": "A catalog of side effects"
        },
        {
            "content": [
                "<ol>\n<li><strong>Vanilla.</strong> Someone decided. Good. No further questions. We can make progress now.</li>\n<li><strong>Educated</strong>. You ask why they decided, and they can clearly explain their reasoning. Not everyone might appreciate the decision, but they will be given the opportunity to understand.<sup id=\"fnref-5395-1\"><a class=\"jetpack-footnote\" href=\"https://randsinrepose.com/feed/#fn-5395-1\" title=\"Read footnote.\">1</a></sup></li>\n<li><strong>Calculated.</strong> Not only can they explain the decision, but they have math! Wow, I&#8217;m super convinced now. </li>\n<li><strong>Instinct</strong>. They attempt to explain their reasoning, but they say &#8220;feel&#8221; a lot. A lot. Thing is, it feels right, so you don&#8217;t press.</li>\n<li><strong>Inspired</strong>. Now you press, and they can tell you want a clear rationale and justification, but none obviously exists. This decision is not meant to be understood; it&#8217;s meant to be appreciated for its poetry. It is 100% expected that inspired decisions are going to frustrate those seeking clarity; they are going to point at the lack of a clear explanation. &#8220;He doesn&#8217;t know what the hell he&#8217;s doing. It&#8217;s a guess.&#8221; It might be a guess, but it also might be art in the making.<sup id=\"fnref-5395-2\"><a class=\"jetpack-footnote\" href=\"https://randsinrepose.com/feed/#fn-5395-2\" title=\"Read footnote.\">2</a></sup> <sup id=\"fnref-5395-3\"><a class=\"jetpack-footnote\" href=\"https://randsinrepose.com/feed/#fn-5395-3\" title=\"Read footnote.\">3</a></sup></li>\n<li><strong>Minimum Viable.</strong> My least favorite. Your investigation into their justification reveals that they chose a decision that was not designed to be good; it was constructed to offend the fewest humans. This is not leadership \u2014 it&#8217;s fear. </li>\n<li><strong>Delegated</strong>. Rather than doing the minimal work of even making a minimum viable decision, they gave the decision to someone else because \u2014 and I quote \u2014 &#8220;They are more capable of making this decision.&#8221; What they are actually saying is, &#8220;I would prefer that this human deal with the weight and consequences for this decision.&#8221; The good news: at least you got a decision. </li>\n</ol>\n<p>Sometimes, they don&#8217;t decide. You push, you prod, but they won&#8217;t decide. No, they didn&#8217;t delegate, no, they didn&#8217;t wing it, they just waited and waited\u2026 kind&#8217;a maybe hoping the need for this decision would vanish. Technically, deciding not to decide is a decision, and that&#8217;s a choice, but it&#8217;s not leadership.</p>\n<div class=\"footnotes\">\n<hr />\n<ol>\n<li id=\"fn-5395-1\">\nContext is what matters when understanding a decision. Who is making it? Why now? How have they decided in the past? What happened as a result of these decisions? Are they being forced to decide? Is someone demanding they decide? I could write another ten questions to help you understand the essential context surrounding this decision, but I&#8217;d miss a question essential to this specific decision. My only advice: be painfully curious when it comes to decisions. Yes, this is the introduction to this piece tucked into a footnote. Yolo.&#160;<a href=\"https://randsinrepose.com/feed/#fnref-5395-1\" title=\"Return to main content.\">&#8617;</a>\n</li>\n<li id=\"fn-5395-2\">\nInspired decisions are retroactively rebranded Vanilla decisions after unexpected exceptional results appear.&#160;<a href=\"https://randsinrepose.com/feed/#fnref-5395-2\" title=\"Return to main content.\">&#8617;</a>\n</li>\n<li id=\"fn-5395-3\">\nIf results from this type of decision are consistently unexpected, let&#8217;s call these decisions Yolo.&#160;<a href=\"https://randsinrepose.com/feed/#fnref-5395-3\" title=\"Return to main content.\">&#8617;</a>\n</li>\n</ol>\n</div>"
            ],
            "link": "https://randsinrepose.com/archives/seven-decisions/",
            "publishedAt": "2025-11-11",
            "source": "Rands in Repose",
            "summary": "Vanilla. Someone decided. Good. No further questions. We can make progress now. Educated. You ask why they decided, and they can clearly explain their reasoning. Not everyone might appreciate the decision, but they will be given the opportunity to understand.1 Calculated. Not only can they explain the decision, but they have math! Wow, I&#8217;m super&#8230; <a class=\"excerpt-more\" href=\"https://randsinrepose.com/archives/seven-decisions/\">more</a>",
            "title": "Seven Decisions"
        },
        {
            "content": [
                "<span class=\"thumbnail\"><img alt=\"\" class=\"attachment-thumbnail size-thumbnail wp-post-image\" height=\"108\" src=\"https://content.wolfram.com/sites/43/2025/11/icon-rulial-ensemble.png\" width=\"128\" /></span><p><img alt=\"What's Special about Life? Bulk Orchestration and the Rulial Ensemble in Biology and Beyond\" class=\"aligncenter\" height=\"322\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11102025heroimg1.png\" title=\"What's Special about Life? Bulk Orchestration and the Rulial Ensemble in Biology and Beyond\" width=\"610\" /></p>\n<h2 id=\"towards-a-theory-of-bulk-orchestration\">Towards a Theory of Bulk Orchestration</h2>\n<p>It\u2019s a key feature of living systems, perhaps even in some ways the key feature: that even right down to a molecular scale, things are orchestrated. Molecules (or at least large ones) don\u2019t just move around randomly, like in a liquid or a gel. Instead, what molecular biology has discovered is that there are endless active mechanisms that in effect orchestrate what even individual molecules in living systems do. But what is the result of all that orchestration? And could there perhaps be a general characterization of what happens in systems that exhibit such \u201cbulk orchestration\u201d? I\u2019ve been wondering about these questions for some time. But finally now I think I may have the beginnings of some answers.</p>\n<p>The central idea is to consider the effect that \u201cbeing adapted for an overall purpose\u201d has on the underlying operation of a system. At the outset, one might imagine that there\u2019d be no general answer to this, and that it would always depend on the specifics of the system and the purpose. But what we\u2019ll discover is that there is in fact typically a certain universality in what happens. Its ultimate origin is the <a href=\"https://www.wolframscience.com/nks/chap-12--the-principle-of-computational-equivalence/\">Principle of Computational Equivalence</a> and certain universal features of the phenomenon of <a href=\"https://www.wolframscience.com/nks/chap-12--the-principle-of-computational-equivalence#sect-12-6--computational-irreducibility\">computational irreducibility</a> that it implies. But the point is that so long as a purpose is somehow \u201ccomputationally simple\u201d then\u2014more or less regardless of what in detail the purpose is\u2014a system that achieves it will show certain features in its behavior.<span id=\"more-71196\"></span></p>\n<p>Whenever there\u2019s computational irreducibility we can think of it as exerting a powerful force towards unpredictability and randomness (as it does, for example, in the <a href=\"https://writings.stephenwolfram.com/2023/02/computational-foundations-for-the-second-law-of-thermodynamics/\">Second Law of thermodynamics</a>). So for a system to achieve an overall \u201ccomputationally simple purpose\u201d this computational irreducibility must in some sense be tamed, or at least contained. And in fact it\u2019s an inevitable feature of computational irreducibility that within it there must be \u201cpockets of computational reducibility\u201d where simpler behavior occurs. And at some level the way computationally simple purposes must be achieved is by tapping into those pockets of reducibility. </p>\n<p>When there\u2019s computational irreducibility it means that there\u2019s no simple narrative one can expect to give of how a system behaves, and no overall \u201cmechanism\u201d one can expect to identify for it. But one can think of pockets of computational reducibility as corresponding to at least small-scale \u201cidentifiable mechanisms\u201d. And what we\u2019ll discover is that when there\u2019s a \u201csimple overall purpose\u201d being achieved these mechanisms tend to become more manifest. And this means that when a system is achieving an overall purpose there\u2019s a trace of this even down in the detailed operation of the system. And that trace is what I\u2019ve called \u201c<a href=\"https://writings.stephenwolfram.com/2023/02/computational-foundations-for-the-second-law-of-thermodynamics/#class-4-and-the-mechanoidal-phase\">mechanoidal behavior</a>\u201d\u2014behavior in which there are at least small-scale \u201cmechanism-like phenomena\u201d that we can think of as acting together through \u201c<a href=\"https://writings.stephenwolfram.com/2024/05/why-does-biological-evolution-work-a-minimal-model-for-biological-evolution-and-other-adaptive-processes/#what-it-means-for-whats-going-on-in-biology\">bulk orchestration</a>\u201d to achieve a certain overall purpose.</p>\n<p>The concept that there might be universal features associated with the interplay between some kind of overall simplicity and underlying computational irreducibility is something not unfamiliar. Indeed, in various forms it\u2019s the ultimate key to our recent progress in the <a href=\"https://www.wolframphysics.org/\" rel=\"noopener\" target=\"_blank\">foundations of physics</a>, <a href=\"https://www.wolframscience.com/metamathematics/\">mathematics</a> and, in fact, <a href=\"https://writings.stephenwolfram.com/2024/05/why-does-biological-evolution-work-a-minimal-model-for-biological-evolution-and-other-adaptive-processes/\">biology</a>. </p>\n<p>In our effort to get a general understanding of bulk orchestration and the behavior of systems that \u201cachieve purposes\u201d there\u2019s an analogy we can make to statistical mechanics. One might have imagined that to reach conclusions about, say, gases, we\u2019d have to have detailed information about the motion of molecules. But in fact we know that if we just consider the whole ensemble of possible configurations of molecules, then by taking statistical averages we can deduce all sorts of properties of gases. (And, yes, the foundational reason this works <a href=\"https://writings.stephenwolfram.com/2023/02/computational-foundations-for-the-second-law-of-thermodynamics/\">we can now understand</a> in terms of computational irreducibility, etc.) </p>\n<p>So could we perhaps do something similar for bulk orchestration? Is there some ensemble we can identify in which wherever we look there will with overwhelming probability be certain properties? In the statistical mechanics of gases we imagine that the underlying laws of mechanics are fixed, but there\u2019s a whole ensemble of possible initial configurations for the molecules\u2014almost all of which turn out to have the same limiting features. But in biology, for example, we can think of different genomes as defining different rules for the development and operation of organisms. And so now what we want is a new kind of ensemble\u2014that we can call a rulial ensemble: an ensemble of possible rules. </p>\n<p>But in something like biology, it\u2019s not all possible rules we want; rather, it\u2019s rules that have been selected to \u201cachieve the purpose\u201d of making a successful organism. We don\u2019t have a general way to characterize what defines biological fitness. But the key point here is that at a fundamental level we don\u2019t need that. Instead it seems that just knowing that our fitness function is somehow computationally simple tells us enough to be able to deduce properties of our \u201crulial ensemble\u201d.</p>\n<p>But are the fitness functions of biology in fact computationally simple? I\u2019ve recently argued that their simplicity is precisely what makes <a href=\"https://writings.stephenwolfram.com/2024/12/foundations-of-biological-evolution-more-results-more-surprises/\">biological evolution possible</a>. Like so many other foundational phenomena, it seems that biological evolution is a reflection of the interplay between computational simplicity\u2014in the case of fitness functions\u2014and underlying computational irreducibility. (In effect, organisms have a chance only because the problems they have to solve aren\u2019t too computationally difficult.) But now we can use the simplicity of fitness functions\u2014without knowing any more details about them\u2014to make conclusions about the relevant rulial ensemble, and from there to begin to derive general principles associated with bulk orchestration.</p>\n<p>When one describes why a system does what it does, there are two different approaches one can take. One can go from the bottom up and describe the underlying rules by which the system operates (in effect, its \u201cmechanism\u201d). Or one can go from the top down and describe what the system \u201cachieves\u201d (in effect, its \u201cgoal\u201d or \u201cpurpose\u201d). It tends to be difficult to mix these two approaches. But what we\u2019re going to find here is that by thinking in terms of the rulial ensemble we will be able to see the general pattern of both the \u201cupward\u201d effect of underlying rules, and the \u201cdownward\u201d effect of overall purposes. </p>\n<p>What I\u2019ll do here is just a beginning\u2014a first exploration, both computational and conceptual, of the rulial ensemble and its consequences. But already there seem to be strong indications that by thinking in terms of the rulial ensemble one may be able to develop what amounts to a foundational theory of bulk orchestration, and with it a foundational theory of certain aspects of adaptive systems, and most notably biology.</p>\n<h2 id=\"some-first-examples\">Some First Examples</h2>\n<p>To begin our explorations and start developing our intuition let\u2019s look at a few simple examples. We\u2019ll use the same <a href=\"https://writings.stephenwolfram.com/2024/05/why-does-biological-evolution-work-a-minimal-model-for-biological-evolution-and-other-adaptive-processes/\">basic framework as in my recent work on biological evolution</a>. The idea is to have cellular automata whose rules serve as an idealization of genotypes, and whole behavior serves as an idealization of the development of phenotypes. For our fitness function we\u2019re going to start with something very specific: that after 50 steps (starting from a single-cell \u201cseed\u201d) our cellular automaton should generate \u201coutput\u201d that consists of three equal blocks of cells colored red, blue and yellow.</p>\n<p>Here are some examples of rules that \u201csolve this particular problem\u201d, in various different ways:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"226\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11062025examplesAimg1.png\" title=\"\" width=\"645\" /> </div>\n<p><span></p>\n<p>How can such rules be found? Well, we can use an idealization of biological evolution. Let\u2019s consider the first rule above:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"271\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11062025examplesAimg2.png\" title=\"\" width=\"359\" /> </div>\n<p><span></p>\n<p>We start, say, from a null rule, then make successive random point mutations in the rule</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"178\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11062025examplesAimg3.png\" title=\"\" width=\"431\" /> </div>\n<p><span></p>\n<p>keeping those mutations that don\u2019t take us further from achieving our goal (and dropping those that do, each indicated here by a red dot):</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"270\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11062025examplesAimg4.png\" title=\"\" width=\"647\" /> </div>\n<p><span></p>\n<p>The result is that we \u201cprogressively adapt\u201d over the course of a few thousand mutations to successively reduce the number of \u201cerrors\u201d and eventually (and in this case, perfectly) achieve our goal:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"347\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11062025examplesAimg5.png\" title=\"\" width=\"670\" /> </div>\n<p><span></p>\n<p>Early in this sequence there\u2019s lots of computational irreducibility in evidence. But in the process of adapting to achieve our goal the computational irreducibility progressively gets \u201ccontained\u201d and in effect squeezed out, until eventually the final solution in this case has an almost completely simple structure.</p>\n<p>The example we\u2019ve just seen succeeds in exactly achieving the objective we defined\u2014though it takes about 4000 steps of adaptive evolution to do so. But if we limit the number of steps of adaptive evolution then in general we won\u2019t be able to reach the exact objective we\u2019ve defined. But here are some results we get with 10,000 steps of adaptive evolution (sorted by how close they get):</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"469\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11062025examplesAimg6.png\" title=\"\" width=\"671\" /> </div>\n<p><span></p>\n<p>In all cases there\u2019s a certain amount of \u201cidentifiable mechanism\u201d to what these rules do. Yes, there can be patches of complex\u2014and presumably computationally irreducible\u2014behavior. But particularly the rules that do better at achieving our exact objective tend to \u201ckeep this computational irreducibility at bay\u201d, and emphasize their \u201csimple mechanisms\u201d.</p>\n<p>So what we see is that among all possible rules, those that get even close to achieving the \u201cpurpose\u201d we have set in effect show at least \u201cpatches of mechanism\u201d. In other words, the imposition of a purpose selects out rules that \u201cexhibit mechanism\u201d, and show what we\u2019ve called mechanoidal behavior. </p>\n<h2 id=\"the-concept-of-mutational-complexity\">The Concept of Mutational Complexity</h2>\n<p>In the last section we saw that adaptive evolution can find (4-color) cellular automaton rules that generate the particular <img alt=\"\" height=\"8\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11062025mutationalimg1.png\" title=\"\" width=\"73\" /> output we specified. But what about other kinds of output? </p>\n<p>What we manage to get will depend on how much \u201ceffort\u201d of adaptive evolution we put in. If we limit ourselves to 10,000 steps of adaptive evolution here are some examples of what happens:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"1176\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11062025mutationalimg2.png\" title=\"\" width=\"611\" /> </div>\n<p><span></p>\n<p>At a qualitative level the main takeaway here is that it seems that the \u201csimpler\u201d the objective is, the more closely it\u2019s likely to be achieved by a given number of steps of adaptive evolution. </p>\n<p>Looking at the first (i.e. \u201cultimately most successful\u201d) examples above, here\u2019s how they\u2019re reached in the course of adaptive evolution:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"165\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11062025mutationalimg3.png\" title=\"\" width=\"644\" /> </div>\n<p><span></p>\n<p>And we see that the \u201csimpler\u201d sequences are reached both more successfully and more quickly; in effect they seem to be \u201ceasier\u201d for adaptive evolution to generate.</p>\n<p>But what do we mean by \u201csimpler\u201d here? In qualitative terms we can think of the \u201csimplicity\u201d of a sequence as being characterized by how short a description we can find of it. We might try to compress the sequence, say using some standard practical <a href=\"https://www.wolframscience.com/nks/chap-10--processes-of-perception-and-analysis#sect-10-5--data-compression\">compression technique</a>, like <a href=\"https://www.wolframscience.com/nks/p561--data-compression/\">run-length encoding</a>, <a href=\"https://www.wolframscience.com/nks/p563--data-compression/\">block encoding</a> or <a href=\"https://www.wolframscience.com/nks/p565--data-compression/\">dictionary encoding</a>. And for the sequences we\u2019re using above, these will (mostly) agree about what\u2019s simpler and what\u2019s not. And then what we find is that sequences that are \u201csimpler\u201d in this kind of characterization tend to be ones that are easier for adaptive evolution to produce.</p>\n<p>But, actually, our study of adaptive evolution itself gives us a way to characterize the simplicity\u2014or complexity\u2014of a sequence: we can consider a sequence more complex if the typical number of mutations it takes to come up with a rule to generate the sequence is larger. And we can define this number of mutations to be what we can call the \u201cmutational complexity\u201d of a sequence. </p>\n<p>There are lots of details in tightening up this definition. But in some sense what we\u2019re saying is that we can characterize the complexity of a sequence by how hard it is for adaptive evolution to get it generated.</p>\n<p>To get more quantitative we have to address the issue that if we run adaptive evolution multiple times, it\u2019ll generally take different numbers of steps to be able to get a particular sequence generated, or, say, to get to the point where there are fewer than <em>m</em> \u201cerrors\u201d in the generated sequence. And, sometimes, by the way, a particular run of adaptive evolution might \u201cget stuck\u201d and never be able to generate a particular sequence\u2014at least (as we\u2019ll discuss below) with the kind of rules and single point mutations we\u2019re using here. </p>\n<p>But we can still compute the probability\u2014across many runs of adaptive evolution\u2014to have reached a specified sequence within <em>m</em> errors after a certain number of steps. And this shows how that probability builds up for the sequences we saw above:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"346\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11062025mutationalimg4.png\" title=\"\" width=\"587\" /> </div>\n<p><span></p>\n<p>And we immediately see more quantitatively that some sequences are faster and easier to reach than others. </p>\n<p>We can go even further by computing in each case the median number of adaptive steps needed to get \u201cwithin <em>m</em> errors\u201d of each sequence:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"193\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11062025mutationalimg5.png\" title=\"\" width=\"677\" /> </div>\n<p><span></p>\n<p>Picking a certain \u201cdesired fidelity\u201d (say allowing a maximum of 20 errors) we then get at least one estimate of mutational complexity for our sequences:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"296\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11062025mutationalimg6.png\" title=\"\" width=\"528\" /> </div>\n<p><span></p>\n<p>Needless to say, these kinds of numerical measures are at best a very coarse way to characterize the difficulty of being able to generate a given sequence through rules produced by adaptive evolution. And, for example, instead of just looking at the probability to reach a given \u201cfidelity\u201d we could be looking at all sorts of distributions and correlations. But in developing our intuition about the rulial ensemble it\u2019s useful to see how we can derive even an admittedly coarse specific numerical measure of the \u201cdifficulty of reaching a sequence\u201d through adaptive evolution. </p>\n<h2 id=\"possible-and-impossible-objectives\">Possible and Impossible Objectives</h2>\n<p>We\u2019ve seen above that some sequences are easier to reach by adaptive evolution than others. But can any sequence we might look for actually be found at all? In other words\u2014regardless of whether adaptive evolution can find it\u2014is there in fact any cellular automaton rule at all (say a 4-color one) that successfully generates any given sequence?</p>\n<p>It\u2019s easy to see that in the end there must be sequences that can\u2019t be generated in this way. There are 4<sup>4<sup>3</sup></sup> possible 4-color cellular automaton rules. But even though that\u2019s a large number, the number of possible 4-color length-101 sequences is still much larger: 4<sup>101</sup> &#8776; 10<sup>61</sup>. So that means it\u2019s inevitable that some of these sequences will not appear as the output from any 4-color cellular automaton rule (run from a single-cell initial condition for 50 steps). (We can think of such sequences as having too high an \u201c<a href=\"https://www.wolframscience.com/nks/notes-12-8--algorithmic-complexity-theory/\">algorithmic complexity</a>\u201d to be generated from a \u201cprogram\u201d as short as a 4-color cellular automaton rule.) </p>\n<p>But what about sequences that are \u201csimple\u201d with respect to our qualitative criteria above? Whenever we succeeded above in finding them by adaptive evolution then we obviously know they can be generated. But in general this is a quintessential computationally irreducible question\u2014so that in effect the only way to know for sure whether there\u2019s any rule that can generate a particular sequence is just to explicitly search through all &#8776; 10<sup>38</sup> possible rules.</p>\n<p>We can get some intuition, however, by looking at much simpler cases. Consider, for example, the 128 (quiescent) \u201celementary\u201d cellular automata (with <em>k</em> = 2, <em>r</em> =1):</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"71\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11062025impossibleimg4.png\" title=\"\" width=\"591\" /> </div>\n<p><span></p>\n<p>The number of distinct sequences they can generate after <em>t</em> steps quickly stabilizes (the maximum is 32)</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"130\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11062025impossibleimg5.png\" title=\"\" width=\"325\" /> </div>\n<p><span></p>\n<p>but this is soon much smaller than the total number of possible sequences of the same length (2<sup>2<em>t</em> + 1</sup>). (The \u201cdown wiggles\u201d are associated with additive rules like 90 and 150 generating almost blank sequences at steps of the form 2<sup><em>m</em></sup>.) Here\u2019s the corresponding result for <em>k</em> = 2, <em>r</em> = 3/2 rules:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"127\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11062025impossibleimg8.png\" title=\"\" width=\"327\" /> </div>\n<p><span></p>\n<p>So what are the sequences that get \u201cleft out\u201d by cellular automata? Already by step 2 a quiescent elementary cellular automaton can only produce 14 of the 32 possible sequences\u2014with sequences such as <img alt=\"\" height=\"10\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11062025impossibleimg9.png\" title=\"\" width=\"47\" /> and <img alt=\"\" height=\"10\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11062025impossibleimg10.png\" title=\"\" width=\"47\" /> being among those excluded. One might think that one would be able to characterize excluded sequences by saying that certain fixed blocks of cells could not occur at any step in any rule. And indeed that happens for the <em>r</em> = 1/2 rules. But for the quiescent elementary cellular automata\u2014with <em>r</em> = 1\u2014it seems as if every block of any given size well eventually occur, presumably courtesy of the likes of rule 30. </p>\n<p>What about, say, periodic sequences? Here are some examples that no quiescent elementary cellular automaton can generate:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"68\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11062025impossibleimg11.png\" title=\"\" width=\"390\" /> </div>\n<p><span></p>\n<p>And, yes, these are, by most standards, quite \u201csimple\u201d sequences. But they just happen not to be \u201csimple\u201d for elementary cellular automata. And indeed we can expect that there will be plenty of such \u201ccoincidentally unreachable\u201d but \u201cseemingly simple\u201d sequences even for our 4-color rules. But we can also expect that even if we can\u2019t precisely reach some objective sequence, we\u2019ll still be able to get to a sequence that is close. (The minimum \u201cerror\u201d is, for example, 4 cells out of 15 for the first sequence above, and 2 for the last sequence).</p>\n<p>But there still remains the question of whether adaptive evolution will be able to find such sequences. For the very simple case of quiescent elementary cellular automata we can readily map out the <a href=\"https://writings.stephenwolfram.com/2024/05/why-does-biological-evolution-work-a-minimal-model-for-biological-evolution-and-other-adaptive-processes/#the-multiway-graph-of-all-possible-mutation-histories\">complete multiway graph</a> of all possible mutations between rules. Here\u2019s what we get if we run all possible rules for 3 steps, then show possible outcomes as nodes, and possible mutations between rules as edges (the edges are undirected, because every mutation can go either way): </p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"232\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11062025impossibleimg12.png\" title=\"\" width=\"492\" /> </div>\n<p><span></p>\n<p>That this graph has only 18 nodes reflects the fact that quiescent elementary cellular automata can produce only 18 of the 128 possible length-7 sequences. But even within these 18 sequences there are ones that cannot be reached through the adaptive evolution process we are using.</p>\n<p>For example, let\u2019s say our goal is to generate the sequence <img alt=\"\" height=\"9\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11062025impossibleimg13.png\" title=\"\" width=\"61\" /> (or, rather, to find a rule that will do so). If we start from the null rule\u2014which generates <img alt=\"\" height=\"9\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11062025impossibleimg14.png\" title=\"\" width=\"61\" />\u2014then our adaptive evolution process defines a foliated version of the multiway graph above:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"200\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11062025impossibleimg15.png\" title=\"\" width=\"582\" /> </div>\n<p><span></p>\n<p>Starting from <img alt=\"\" height=\"9\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11062025impossibleimg16.png\" title=\"\" width=\"61\" /> some paths (i.e. sequences of mutations) successfully reach <img alt=\"\" height=\"9\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11062025impossibleimg17.png\" title=\"\" width=\"61\" />. But this only happens about 25% of the time. The rest of the time the adaptive process gets stuck at <img alt=\"\" height=\"9\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11062025impossibleimg18.png\" title=\"\" width=\"61\" /> or <img alt=\"\" height=\"9\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11062025impossibleimg19.png\" title=\"\" width=\"61\" /> and never reaches <img alt=\"\" height=\"9\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11062025impossibleimg20.png\" title=\"\" width=\"61\" />:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"257\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11062025impossibleimg21.png\" title=\"\" width=\"554\" /> </div>\n<p><span></p>\n<p>So what happens if we look at larger cellular automaton rule spaces? In such cases we can\u2019t expect to trace the full multiway graph of possible mutations. And if we pick a sequence at random as our target, then for a long sequence the overwhelming probability is that it won\u2019t be reachable at all by any cellular automaton with a rule of a given type. But if we start from a rule\u2014say picked at random\u2014and use its output as our target, then this guarantees that there\u2019s at least one rule that produces this sequence. And then we can ask how difficult it is for adaptive evolution to find a rule that works (most likely not the original one). </p>\n<p>Here are some examples\u2014with the original rule on the left, and the best results found from 10,000 steps of adaptive evolution on the right:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"695\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11062025impossibleimg22.png\" title=\"\" width=\"621\" /> </div>\n<p><span></p>\n<p>What we see is fairly clear: when the pattern generated by the original rule looks simple, adaptive evolution can readily find rules that successfully produce the same output, albeit sometimes in quite different ways. But when the pattern generated by the original rule is more complicated, adaptive evolution typically won\u2019t be able to find a rule that exactly reproduces its output. And so, for examples, in the cases shown here many errors remain even in the \u201cbest results\u201d after 10,000 steps of adaptive evolution.</p>\n<p>Ultimately this not surprising. When we pick a cellular automaton rule at random, it\u2019ll often show computational irreducibility. And in a sense all we\u2019re seeing here is that adaptive evolution can\u2019t \u201cbreak\u201d computational irreducibility. Or, put another way, computationally irreducible processes generate mutational complexity. </p>\n<h2 id=\"other-objective-functions\">Other Objective Functions</h2>\n<p>In everything we\u2019ve done so far we\u2019ve been considering a particular type of \u201cgoal\u201d: to have a cellular automaton produce a specified arrangement of cells after a certain number of steps. But what about other types of goals? We\u2019ll look at several here. The general features of what will happen with them follow what we\u2019ve already seen, but each will show some new effects and will provide some new perspectives.</p>\n<h3>Vertical Sequences</h3>\n<p>As a first example, let\u2019s consider trying to match not the horizontal arrangement of cells, but the vertical one\u2014in particular the sequence of colors in the center column of the cellular automaton pattern. Here\u2019s what we get with the goal of having a block of red cells followed by an equal block of blue:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"343\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11072025functionsimg1.png\" title=\"\" width=\"633\" /> </div>\n<p><span></p>\n<p>The results are quite diverse and \u201ccreative\u201d. But it\u2019s notable that in all cases there\u2019s definite \u201cmechanism\u201d to be seen \u201cright around the center column\u201d. There\u2019s all sorts of complexity away from the center column, but it\u2019s sufficiently \u201ccontained\u201d that the center column itself can achieve its \u201csimple goal\u201d. </p>\n<p>Things are similar if we ask to get three blocks of color rather than two\u2014though this goal turns out to be somewhat more difficult to achieve:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"223\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11072025functionsimg2.png\" title=\"\" width=\"633\" /> </div>\n<p><span></p>\n<p>It\u2019s also possible to get <img height=\"8\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11072025functionsimg3.png\" width=\"67\" />:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"104\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11072025functionsimg4.png\" title=\"\" width=\"633\" /> </div>\n<p><span></p>\n<p>And in general the difficulty of getting a particular vertical sequence of blocks tends to track the difficulty of getting the corresponding horizontal sequence of blocks. Or, in other words, the pattern of mutational complexity seems to be similar for sequences associated with horizontal and vertical goals.</p>\n<p>This also seems to be true for periodic sequences. Alternating colors are easy to achieve, with many \u201ctricks\u201d being possible in this case:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"167\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11072025functionsimg5.png\" title=\"\" width=\"636\" /> </div>\n<p><span></p>\n<p>A sequence with period 5 is pretty much the same story:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"77\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11072025functionsimg6.png\" title=\"\" width=\"636\" /> </div>\n<p><span></p>\n<p>When the period gets more comparable to the number of cellular automaton steps that we\u2019re sampling it for, the \u201csolutions\u201d get wilder:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"167\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11072025functionsimg7.png\" title=\"\" width=\"636\" /> </div>\n<p><span></p>\n<p>And some of them are quite \u201cfragile\u201d, and don\u2019t \u201cgeneralize\u201d beyond the original number of steps for which they were adapted:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"221\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11072025functionsimg8.png\" title=\"\" width=\"461\" /> </div>\n<p><span></p>\n<h3>Color Frequencies in Output</h3>\n<p>The types of goals we\u2019ve considered so far have all involved trying to get exact matches to specified sequences. But what if we just ask for an average result? For example, what if we ask for all 4 colors to occur with equal frequency in our output, but allow them to be arranged in any way? With the same adaptive evolution setup as before we rather quickly find \u201csolutions\u201d (where because we\u2019re running for 50 steps and getting patterns of width 101, we\u2019re always \u201coff by at least 1\u201d relative to the exact 25:25:25:25 result):</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"348\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11072025functionsimg9.png\" title=\"\" width=\"633\" /> </div>\n<p><span></p>\n<p>A few of these solutions seem to have \u201cfigured out a mechanism\u201d to get all colors equally. But others seem like they just \u201chappen to work\u201d. And indeed, taking the first three cases here, this shows the relative numbers of cells of different colors obtained at successive steps in running the cellular automaton:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"129\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11072025functionsimg10.png\" title=\"\" width=\"594\" /> </div>\n<p><span></p>\n<p>The pattern that looks simple consistently has equal numbers of each color at every step. The others just \u201chappen to hit equality\u201d after running for exactly 50 steps, but on either side don\u2019t achieve equality.</p>\n<p>And, actually, it turns out that all these solutions are in some sense quite fragile. Change the color of just one cell and one typically gets an expanding region of change\u2014that takes the output far from color equality:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"218\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11072025functionsimg11.png\" title=\"\" width=\"390\" /> </div>\n<p><span></p>\n<p>So how can we get rules that more robustly achieve our color equality objective? One approach is to <a href=\"https://writings.stephenwolfram.com/2025/02/towards-a-computational-formalization-for-foundations-of-medicine/#biological-evolution-and-our-model-organism\">force the adaptive evolution to \u201ctake account of possible perturbations\u201d</a> by applying a few perturbations at every adaptive evolution step, and keeping a particular mutation only if neither it, nor any of its perturbed versions, has lower fitness than before. </p>\n<p>Here\u2019s an example of one particular sequence of successive rules obtained in this way:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"171\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11072025functionsimg12.png\" title=\"\" width=\"642\" /> </div>\n<p><span></p>\n<p>And now if we apply perturbations to the final result, it doesn\u2019t change much:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"77\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11072025functionsimg13.png\" title=\"\" width=\"634\" /> </div>\n<p><span></p>\n<p>It\u2019s notable that this robust solution looks simple. And indeed that\u2019s common, with a few other examples of robust, exact solutions being: </p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"164\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11072025functionsimg14.png\" title=\"\" width=\"626\" /> </div>\n<p><span></p>\n<p>In effect it seems that requiring a robust, exact solution \u201cforces out\u201d computational irreducibility, leaving only readily reducible patterns. If we relax the constraint of being an exact solution even a little, though, more complex behavior quickly creeps in:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"160\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11072025functionsimg15.png\" title=\"\" width=\"612\" /> </div>\n<p><span></p>\n<h3>Whole-Pattern Color Frequencies</h3>\n<p>We\u2019ve just looked at trying to achieve particular frequencies of colors in the \u201coutput\u201d of a cellular automaton (after running for 50 steps). But what if we try to achieve certain frequencies of colors throughout the pattern produced by the cellular automaton? </p>\n<p>For example, let&#8217;s say that our goal is to have color frequencies in the ratios: <img height=\"27\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11072025functions-aimg1.png\" style=\"vertical-align: bottom; margin-top: 2px; margin-bottom: 2px;\" width=\"136\" />. Adaptive evolution fairly easily finds good &#8220;solutions&#8221; for this:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"252\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11072025functionsimg16.png\" title=\"\" width=\"640\" /> </div>\n<p><span></p>\n<p>And in fact it does so for any \u201crelative red level\u201d:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"574\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11072025functionsimg17.png\" title=\"\" width=\"526\" /> </div>\n<p><span></p>\n<p>But if we plot the median number of adaptive evolution steps needed to achieve these results (i.e. our approximation to mutational complexity) we see that there\u2019s a systematic increase with \u201cred level\u201d:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"153\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11072025functionsimg18.png\" title=\"\" width=\"357\" /> </div>\n<p><span></p>\n<p>In effect, the higher the red level the \u201cmore stringent\u201d the constraints we\u2019re trying to satisfy are\u2014and the more steps of adaptive evolution it takes to do that. But looking at the actual patterns obtained at different red levels, we also see something else: that as the constraints get more stringent, the pattern seems to have computational irreducibility progressively \u201csqueezed out\u201d of them\u2014leaving behavior that seems more and more mechanoidal. </p>\n<p>As another example along the same lines, consider goals of the form <img height=\"27\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11072025functions-aimg2.png\" style=\"vertical-align: bottom; margin-top: 2px; margin-bottom: 2px;\" width=\"138\" />. Here are results one gets varying the &#8220;white level&#8221;:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"650\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11072025functionsimg19.png\" title=\"\" width=\"598\" /> </div>\n<p><span></p>\n<p>We see two rather different approaches being taken to the \u201cproblem of having more white\u201d. When the white level isn\u2019t too large, the pattern just gets \u201cairier\u201d, with more white inside. But eventually the pattern tends to contract, \u201cleaving room\u201d for white outside. </p>\n<h3>Growth Shapes</h3>\n<p>In most of what we\u2019ve done so far, the overall \u201cshapes\u201d of our cellular automaton patterns have ended up always just being simple triangles that expand by one cell on each side at each step\u2014though we just saw that with sufficiently stringent constraints on colors they\u2019re forced to be different shapes. But what if our actual goal is to achieve a certain shape? For example, let\u2019s say we try to get triangular patterns that grow at a particular rate on each side. </p>\n<p>Here are some results for growth rates of the form 1/<em>n</em> (i.e. growing by an average of 1 cell every <em>n</em> steps):</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"373\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11072025functionsimg20.png\" title=\"\" width=\"650\" /> </div>\n<p><span></p>\n<p>This is the sequence of adaptive evolution steps that led to the first example of growth rate <span class=\"InlineFormula\"><img align=\"absmiddle\" height=\"30\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11072025functionsimg28.png\" style=\"margin: 0 2px;\" width=\"8\" /></span></p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"262\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11072025functionsimg22.png\" title=\"\" width=\"643\" /> </div>\n<p><span></p>\n<p>and this is the corresponding sequence for growth rate <span class=\"InlineFormula\"><img align=\"absmiddle\" height=\"27\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11072025functionsimg23.png\" style=\"margin: 0 2px;\" width=\"15\" /></span>:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"119\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11072025functionsimg24.png\" title=\"\" width=\"644\" /> </div>\n<p><span></p>\n<p>And although the interiors of most of the final patterns here are complicated, their outer boundaries tend to be simple\u2014at least for small <em>n</em>\u2014and in a sense \u201cvery mechanically\u201d generate the exact target growth rate:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"149\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11072025functionsimg25.png\" title=\"\" width=\"628\" /> </div>\n<p><span></p>\n<p>For larger <em>n</em>, things get more complicated\u2014and adaptive evolution doesn\u2019t typically \u201cfind an exact solution\u201d. And if we run our \u201csolutions\u201d longer we see that\u2014particularly for larger <em>n</em>\u2014they often don\u2019t \u201cgeneralize\u201d very well, and soon start deviating from their target growth rates: </p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"176\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11072025functionsimg26.png\" title=\"\" width=\"672\" /> </div>\n<p><span></p>\n<p>As we increase <em>n</em> we typically see that more steps of adaptive evolution are needed to achieve our goal, reflecting the idea that \u201clarger <em>n</em> growth\u201d has more mutational complexity:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"121\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11072025functionsimg27.png\" title=\"\" width=\"308\" /> </div>\n<p><span></p>\n<p>For rational growth rates like <span class=\"InlineFormula\"><img align=\"absmiddle\" height=\"30\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11072025functionsimg28.png\" style=\"margin: 0 2px;\" width=\"8\" /></span> fairly simple exact solutions are possible. But for irrational growth rates, that\u2019s no longer true. Still, it turns out that adaptive evolution is in a sense strong enough\u2014and our cellular automaton rule space is large enough\u2014that good approximations even to irrational growth rates can often be reached:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"328\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11072025functionsimg29.png\" title=\"\" width=\"671\" /> </div>\n<p><span></p>\n<p>The \u201csolutions\u201d typically remain quite consistent when run longer:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"328\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11072025functionsimg30.png\" title=\"\" width=\"679\" /> </div>\n<p><span></p>\n<p>But there are still some notable limitations. For example, while a growth rate of exactly 1 is easy to achieve, growth rates close to 1 are in effect \u201cstructurally difficult\u201d. For example, above about 0.741 adaptive evolution tends to \u201ccheat\u201d\u2014adding a \u201chat\u201d at the top of the pattern instead of actually producing a boundary with consistent slope:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"296\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11072025functionsimg31.png\" title=\"\" width=\"656\" /> </div>\n<p><span></p>\n<p>What about other shapes as goals? Here\u2019s what happens with diamond shapes of difficult widths:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"314\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11072025functionsimg32.png\" title=\"\" width=\"582\" /> </div>\n<p><span></p>\n<p>Adaptive evolution is quite constrained by what\u2019s structurally possible in a cellular automaton of this type\u2014and the results are not particularly good. And indeed if one attempts to \u201cgeneralize\u201d them, it\u2019s clear none of them really \u201chave the idea\u201d of a diamond shape:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"120\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11072025functionsimg33.png\" title=\"\" width=\"672\" /> </div>\n<p><span></p>\n<h3 id=\"lifetimes\">Lifetimes</h3>\n<p>In the examples we\u2019ve discussed so far, we\u2019ve focused on what cellular automata do over the course of a fixed number of steps\u2014not worrying about what they might do later. But another goal we might have\u2014which in fact <a href=\"https://writings.stephenwolfram.com/2024/12/foundations-of-biological-evolution-more-results-more-surprises\">I have discussed at length elsewhere</a>\u2014is just to have our cellular automata produce patterns that go for a certain number of steps and then die out. So, for example, we can use adaptive evolution to find cellular automata whose patterns live for exactly 50 steps, and then die out: </p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"159\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11072025functionsimg34.png\" title=\"\" width=\"649\" /> </div>\n<p><span></p>\n<p>Just like in our other examples, adaptive evolution finds all sorts of diverse and \u201cinteresting\u201d solutions to the problem of living for exactly 50 steps. Some (like the last one and the yellow one) have a certain level of \u201cobvious mechanism\u201d to them. But most of them seem to \u201cjust work\u201d for no \u201cobvious reason\u201d. Presumably the constraint of living for 50 steps in some sense just isn\u2019t stringent enough to \u201csqueeze out\u201d computational irreducibility\u2014so there is still plenty of computational irreducibility in these results. </p>\n<p>What about mutational complexity? Approximating this, as before, by the median of the number of adaptive evolution steps\u2014and sampling a few hundred cases for each lifetime goal (and plotting the quartiles as well as the median)\u2014we see a systematic increase of mutational complexity as we increase the lifetime goal:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"187\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11072025functionsimg35.png\" title=\"\" width=\"496\" /> </div>\n<p><span></p>\n<p>In effect this shows us that if we increase the lifetime goal, it becomes more and more difficult for adaptive evolution to reach that goal. (And, as we\u2019ve discussed elsewhere, if we go far enough, we\u2019ll ultimately reach the edge of what\u2019s even in principle possible with, say, the particular type of 4-color cellular automata we\u2019re using here.) </p>\n<p>All the objectives we\u2019ve discussed so far have the feature that they are in a sense explicit and fixed: we define what we want (e.g. a cellular automaton pattern that lives for exactly 50 steps) and then we use adaptive evolution to try to get it. But looking at something like lifetime suggests another possibility. Instead of our objective being fixed, our objective can instead be open ended. And so, for example, we might ask not for a specific lifetime, but to get the largest lifetime we can.</p>\n<p>I\u2019ve discussed this case at some length elsewhere. But how does it relate to the concept of the rulial ensemble that we\u2019re studying here? When we have rules that are found by adaptive evolution with fixed constraints we end up with something that can be thought of as roughly analogous to things like the canonical (\u201cspecified temperature\u201d) ensemble of traditional statistical mechanics. But if instead we look at the \u201cwinners\u201d of open-ended adaptive evolution then what we have is more like a collection of extreme value than something we can view as typical of the \u201cbulk of an ensemble\u201d.</p>\n<h3>Periodicities</h3>\n<p>We\u2019ve just looked at the goal of having patterns that survive for a certain number of steps. Another goal we can consider is having patterns that periodically repeat after a certain number of steps. (We can think of this as an extremely idealized analog of having multiple generations of a biological organism.)</p>\n<p>Here are examples of rules found by adaptive evolution that lead to patterns which repeat after exactly 50 steps:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"445\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11072025functionsimg36.png\" title=\"\" width=\"635\" /> </div>\n<p><span></p>\n<p>As usual, there\u2019s a distribution in the number of steps of adaptive evolution required to achieve these results:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"164\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11102025functionsimg1.png\" title=\"\" width=\"398\" /> </div>\n<p><span></p>\n<p>Looking at the median of the analogous distributions for different possible periods, we can get an estimate of the mutational complexity of different periods\u2014which seems to increase somewhat uniformly with period: </p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"150\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11102025functionsimg2.png\" title=\"\" width=\"397\" /> </div>\n<p><span></p>\n<p>By the way, it\u2019s also possible to restrict our adaptive evolution so that it samples only symmetric rules; here are a few examples of period-50 results found in this way:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"223\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11072025functionsimg39.png\" title=\"\" width=\"644\" /> </div>\n<p><span></p>\n<p>In our discussion of periodicity so far, we\u2019ve insisted on \u201cperiodicity from the start\u201d\u2014meaning that after each period the pattern we get has to return to the single-cell state we started from. But we can also consider periodicity that \u201cdevelops after a transient\u201d. Sometimes the transient is short; sometimes it\u2019s much longer. Sometimes the periodic pattern starts from a small \u201cseed\u201d; sometimes its seed is quite large. Here are some examples of patterns found by adaptive evolution that have ultimate period 50:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"455\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11072025functionsimg41.png\" title=\"\" width=\"641\" /> </div>\n<p><span></p>\n<p>By the way, in all these cases the periodic pattern seems like the \u201cmain event\u201d of the cellular automaton evolution. But there are other cases where it seems more like a \u201cresidue\u201d from other behavior\u2014and indeed that \u201cother behavior\u201d can in principle go on for arbitrarily long before finally giving way to periodicity:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"540\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11072025functionsimg42.png\" title=\"\" width=\"635\" /> </div>\n<p><span></p>\n<p>We\u2019ve been talking so far about the objective of finding cellular automaton rules that yield patterns with specific periodicity. But just like for lifetime, we can also consider the \u201copen-ended objective\u201d of finding rules with the longest periods we can. And here are the best results found with a few runs of 10,000 steps of adaptive evolution (here we\u2019re looking for periodicity without transients):</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"386\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11072025functionsimg43.png\" title=\"\" width=\"635\" /> </div>\n<p><span></p>\n<h2 id=\"measuring-mechanoidal-behavior\">Measuring Mechanoidal Behavior</h2>\n<p>We\u2019ve now seen lots of examples of cellular automata found by adaptive evolution. And a key question is: \u201cwhat\u2019s special about them?\u201d If we look at cellular automata with rules chosen purely at random, here are typical examples of what we get:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"335\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11072025mechanoidalimg1.png\" title=\"\" width=\"611\" /> </div>\n<p><span></p>\n<p>Some of these patterns are simple. But many are complicated and in fact look quite random\u2014though often with regions or patches of regularity. But what\u2019s striking is how visually different they look from what we\u2019ve mostly seen above in cellular automata that were adaptively evolved \u201cfor a purpose\u201d.</p>\n<p>So how can we characterize\u2014and ultimately measure\u2014that difference? Our randomly picked cellular automata seem to show either almost total computational reducibility or \u201cunchecked computational irreducibility\u201d (albeit usually with regions or patches of computational reducibility). But cellular automata that were successfully \u201cevolved for a purpose\u201d tend to look different. They tend to show what we\u2019re calling <a href=\"https://writings.stephenwolfram.com/2023/02/computational-foundations-for-the-second-law-of-thermodynamics/#class-4-and-the-mechanoidal-phase\">mechanoidal behavior</a>: behavior in which there are identifiable \u201cmechanism-like features\u201d, albeit usually mixed in with at least some\u2014typically highly contained\u2014\u201csparks of computational irreducibility\u201d. </p>\n<p>At a visual level there are typically some clear characteristics to mechanoidal behavior. For example, there are usually repeated motifs that appear throughout a system. And there\u2019s also usually a certain degree of <a href=\"https://writings.stephenwolfram.com/2025/03/what-can-we-learn-about-engineering-and-innovation-from-half-a-century-of-the-game-of-life-cellular-automaton/#modularity\">modularity</a>, with different parts of the system operating at least somewhat independently. And, yes, there\u2019s no doubt a rich phenomenology of mechanoidal behavior to be studied (closely related to the study of <a href=\"https://www.wolframscience.com/nks/chap-6--starting-from-randomness#sect-6-2--four-classes-of-behavior\">class 4 behavior</a>). But at a coarse and potentially more immediately quantitative level a key feature of mechanoidal behavior is that it involves a certain amount of regularity, and computational reducibility. </p>\n<p>So how can one measure that? Whenever there\u2019s regularity in a system it means there\u2019s a way to summarize what the system does more succinctly than by just specifying every state of every element of the system. Or, in other words, there\u2019s a way to <a href=\"https://www.wolframscience.com/nks/chap-10--processes-of-perception-and-analysis#sect-10-2--what-perception-and-analysis-do\">compress our description of the system</a>. </p>\n<p>Perhaps, one might think, one could use modularity to do this compression, say by keeping only the modular parts of a system, and eliding away the \u201cfiller\u201d in between\u2014much like <a href=\"https://www.wolframscience.com/nks/p561--data-compression/\">run-length encoding</a>. But\u2014like run-length encoding\u2014the most obvious version of this runs into trouble when the \u201cfiller\u201d consists, say, of alternating colors of cells. One can also think of using <a href=\"https://www.wolframscience.com/nks/p563--data-compression/\">block-based encoding</a>, or <a href=\"https://www.wolframscience.com/nks/p565--data-compression/\">dictionary encoding</a>, say leveraging repeated motifs that appear. But it\u2019s an inevitable feature of computational irreducibility that in the end there can never be one universally best method of compression. </p>\n<p>But as an example, let\u2019s just use the Wolfram Language <tt><a href=\"http://reference.wolfram.com/language/ref/Compress.html\">Compress</a></tt> function. (Using GZIP, BZIP2, etc. gives essentially identical results.) Feed in a cellular automaton pattern, and <tt>Compress</tt> will give us a (losslessly) compressed version of it. We can then use the length of this as a measure of what\u2019s left over after we \u201ccompress out\u201d the regularities in the pattern. Here\u2019s a plot of the \u201ccompressed description length\u201d (in \u201c<tt>Compress</tt> output bytes\u201d) for some of the patterns we\u2019ve seen above:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"465\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11072025mechanoidalimg2.png\" title=\"\" width=\"591\" /> </div>\n<p><span></p>\n<p>And what\u2019s immediately striking is that the patterns \u201cevolved for a purpose\u201d tend to be in between patterns that come from randomly chosen rules. </p>\n<p>(And, yes, the question of what\u2019s compressed by what is a <a href=\"https://writings.stephenwolfram.com/2023/12/observer-theory/\">complicated, somewhat circular story</a>. Compression is ultimately about making a model for things one wants to compress. And, for example, the appropriate model will change depending on what those things are. But for our purposes here, we\u2019ll just use <tt>Compress</tt>\u2014which is set up to do well at compressing \u201ctypical human-relevant content\u201d.)</p>\n<p>OK, so how does adaptive evolution relate to our \u201ccompressed size\u201d measure? Here\u2019s an example of the typical progression of an adaptive evolution process\u2014in this case based on the goal of generating the <img height=\"8\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11072025mechanoidalimg3.png\" width=\"73\" /> sequence:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"219\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11072025mechanoidalimg4.png\" title=\"\" width=\"600\" /> </div>\n<p><span></p>\n<p>Given our way of starting with the null rule, everything is simple at the beginning\u2014yielding a small compressed size. But soon the system starts developing computational irreducibility, and the compressed size goes up. Still, as the adaptive evolution proceeds, the computational irreducibility is progressively \u201csqueezed out\u201d\u2014and the compressed size settles down to a smaller value. </p>\n<p>The plot above is based on a particular (randomly chosen) sequence of mutations in the underlying rule. But if we look at the average from a large collection of mutation sequences we see very much the same thing:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"297\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11072025mechanoidalimg6.png\" title=\"\" width=\"433\" /> </div>\n<p><span></p>\n<p>Even though the \u201cerror rate\u201d on average goes down monotonically, the compressed size of our candidate patterns has a definite peak before settling to its final value. In effect, it seems that the system needs to \u201cexplore the computational universe\u201d a bit before figuring out how to achieve its goal. </p>\n<p>But how general is this? If we don\u2019t insist on reaching zero error we get a curve of the same general shape, but slightly smoothed out (here for 20 or fewer errors): </p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"149\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11072025mechanoidalimg7.png\" title=\"\" width=\"389\" /> </div>\n<p><span></p>\n<p>What about for other target sequences? Here are results for all the target sequences we considered before (with the number of errors allowed in each case indicated):</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"435\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11072025mechanoidalimg12.png\" title=\"\" width=\"611\" /> </div>\n<p><span></p>\n<p>In all cases we get final compressed sizes that are much smaller than those for all-but-very-simple randomly chosen rules\u2014indicating that our adaptive evolution process has indeed generated regularity, and our compression method has successfully picked this up. </p>\n<p>Looking at the overall shape of the curves we\u2019ve generated here, there seems to be a general phenomenon in evidence: the process of adaptive evolution seems to pass through a \u201ccomputationally irreducible period\u201d before getting to its final mechanoidal state. Even as it gets progressively closer to its goal, the adaptive evolution process ends up still \u201cplaying the field\u201d before homing in on its \u201cfinal solution\u201d. (And, yes, phenomena like this are seen both in the fossil record of life on Earth and in the <a href=\"https://writings.stephenwolfram.com/2025/03/what-can-we-learn-about-engineering-and-innovation-from-half-a-century-of-the-game-of-life-cellular-automaton/\">development of engineering systems</a>.)</p>\n<h2 id=\"the-rulial-ensemble-and-its-implications\">The Rulial Ensemble and Its Implications</h2>\n<p>We began by asking the question \u201cwhat consequences does being \u2018evolved for a purpose\u2019 have on a system?\u201d We\u2019ve now seen many examples of different \u201cpurposes\u201d, and how adaptive evolution can achieve them. The details are different in different cases. But we\u2019ve seen that there are general features that occur very broadly. Perhaps most notable is that in systems that were \u201cadaptively evolved for a purpose\u201d one tends to see what we can call mechanoidal behavior: behavior in which there are \u201cmechanism-like\u201d elements. </p>\n<p>Rules that are picked purely at random\u2014in effect uniformly from rulial space\u2014rarely show mechanoidal behavior. But in rules that have been adaptively evolved for a purpose mechanoidal behavior is the norm. And what we\u2019ve found here is that this is true essentially regardless of what the specific purpose involved is. </p>\n<p>We can think of rules that have been adaptively evolved for a purpose as forming what we can call a rulial ensemble: a subset of the space of all possible rules, concentrated by the process of adaptive evolution. And what we\u2019ve seen here is that there are in effect generic features of the rulial ensemble\u2014features that are generically seen in rules that have been adaptively evolved for a purpose. </p>\n<p>Given a particular purpose (like \u201cproduce this specific sequence as output\u201d) there are typically many ways it can be achieved. It could be that one can <a href=\"https://writings.stephenwolfram.com/2025/03/what-can-we-learn-about-engineering-and-innovation-from-half-a-century-of-the-game-of-life-cellular-automaton/\">engineer a solution</a> that shows a \u201chuman-recognizable mechanism\u201d all the way through. It could be that it would be a \u201clump of computationally irreducible behavior\u201d that somehow \u201cjust happens\u201d to have the result of doing what we want. But adaptive evolution seems to produce solutions with what amount to intermediate characteristics. There are elements of mechanism to be seen. And there are also usually certain \u201csparks of computational irreducibility\u201d. Typically what we see is that in the process of adaptive evolution all sorts of computational irreducibility is generated. But to achieve whatever purpose has been defined requires \u201ctaming\u201d that irreducibility. And, it seems, introducing the kind of \u201cpatches of mechanism\u201d that are characteristic of the mechanoidal behavior we have seen. </p>\n<p>That those \u201cpatches of mechanism\u201d fit together to achieve an overall purpose is often a surprising thing. But it\u2019s the essence of the kind of \u201cbulk orchestration\u201d that we see in the systems we\u2019ve studied here, and that seems also to be characteristic of biological systems. </p>\n<p>Having specified a particular purpose it\u2019s often completely unclear how a given kind of system could possibly achieve it. And indeed what we\u2019ve seen adaptive evolution do here often seems like magic. But in a sense what we\u2019re seeing is just a reflection of the immense power that is available in the computational universe, and manifest in the phenomenon of <a href=\"https://www.wolframscience.com/nks/chap-12--the-principle-of-computational-equivalence#sect-12-6--computational-irreducibility\">computational irreducibility</a>. Without computational irreducibility we\u2019d somehow \u201cget what we expect\u201d; computational irreducibility is what adds what is ultimately an infinite element of surprise. And what we\u2019ve seen is that adaptive evolution manages to successfully harness that \u201celement of surprise\u201d to achieve particular purposes.</p>\n<p>Let\u2019s say our goal is to generate a particular sequence of values. One might imagine just operating on a space of possible sequences, and gradually adaptively evolving to the sequence we want. But that\u2019s not the setup we\u2019re using here, and it\u2019s not the setup biology has either. Instead what\u2019s happening both in our idealized cellular automaton systems\u2014and in biology\u2014is that the adaptive evolution process is operating at the level of underlying rules, but the purposes are achieved by the results of running those rules. And it\u2019s because of this distinction\u2014which in biology is associated with genotypes vs. phenotypes\u2014that computational irreducibility has a way to insert itself. In some sense both the underlying rules and overall patterns of purposes can be thought of as defining certain \u201csyntactic structures\u201d. The actual running of the rules then represents what one can think of as the \u201csemantics\u201d of the system. And it\u2019s there that the power of computation is injected.</p>\n<p>But in the end, just how powerful is adaptive evolution, with its ability to tap into computational irreducibility, and to \u201cmine\u201d the computational universe? We\u2019ve seen that some goals are easier to reach than others. And indeed we introduced the concept of mutational complexity to characterize just how much \u201ceffort of adaptive evolution\u201d (and, ultimately, how many mutations)\u2014is needed to achieve a given objective. </p>\n<p>If adaptive evolution is able to \u201cfully run its course\u201d then we can expect it to achieve its objective through rules that show mechanoidal behavior and clear \u201cevidence of mechanism\u201d. But if the amount of adaptive evolution stops short of what\u2019s defined by the mutational complexity of the objective, then one\u2019s likely to see more of the \u201cuntamed computational irreducibility\u201d that\u2019s characteristic of intermediate stages of adaptive evolution. In other words, if we \u201cget all the way to a solution\u201d there\u2019ll be mechanism to be seen. But if we stop short, there\u2019s likely to be all sorts of \u201cgratuitous complexity\u201d associated with computational irreducibility.</p>\n<p>We can think of our final rulial ensemble as consisting of rules that \u201csuccessfully achieve their purpose\u201d; when we stop short we end up with another, \u201cintermediate\u201d rulial ensemble consisting of rules that are merely on a path to achieve their purpose. In the final ensemble the forces of adaptive evolution have in a sense tamed the forces of computational irreducibility. But in the intermediate ensemble the forces of computational irreducibility are still strong, bringing the various universal features of computational irreducibility to the fore.</p>\n<p>It may be useful to contrast all of this with what happens in traditional statistical mechanics, say of molecules in a gas\u2014in which <a href=\"https://writings.stephenwolfram.com/2023/02/computational-foundations-for-the-second-law-of-thermodynamics/\">I\u2019ve argued (elsewhere)</a> that there\u2019s in a sense almost always \u201cunchecked computational irreducibility\u201d. And it\u2019s this unchecked computational irreducibility that leads to the Second Law\u2014by producing configurations of the system that we (as <a href=\"https://writings.stephenwolfram.com/2023/12/observer-theory/\">computationally bounded observers</a>) can\u2019t distinguish from random, and can therefore reasonably model statistically just as being \u201ctypical of the ensemble\u201d, where now the ensemble consists of all possible configurations of the system that, for example, have the same energy or the same temperature. Adaptive evolution is a different story. First, it\u2019s operating not directly on the configurations of a system, but rather on the underlying rules for the system. And second, if one takes the process of adaptive evolution far enough (so that, for example, the number of steps of adaptive evolution is large compared to the mutational complexity of the goal one\u2019s pursuing), then adaptive evolution will \u201ctame\u201d the computational irreducibility. But there\u2019s still an ensemble involved\u2014though now it\u2019s an ensemble of rules rather than an ensemble of configurations. And it\u2019s not an ensemble that somehow \u201ccovers all rules\u201d; rather, it\u2019s an ensemble that is \u201csculpted\u201d by the constraint of \u201cachieving a purpose\u201d. </p>\n<p>I\u2019ve argued that it\u2019s the characteristics of \u201cobservers like us\u201d that ultimately lead to the perceived validity of the Second Law. So is there a role for the notion of an observer in our discussion here of bulk orchestration and the rulial ensemble? Well, yes. And in particular it\u2019s critical in grounding our concept of \u201cpurpose\u201d. We might ask: what possible \u201cpurposes\u201d are there? Well, for something to be a reasonable \u201cpurpose\u201d there has to be some way to decide whether or not it\u2019s been achieved. And to make such a decision we need something that\u2019s in effect an \u201cobserver\u201d.</p>\n<p>In the case of statistical mechanics and the Second Law\u2014and, in fact, in all our recent successes in deriving foundational principles in both <a href=\"https://www.wolframphysics.org/\" rel=\"noopener\" target=\"_blank\">physics</a> and <a href=\"https://writings.stephenwolfram.com/2022/03/the-physicalization-of-metamathematics-and-its-implications-for-the-foundations-of-mathematics/\">mathematics</a>\u2014we want to consider observers that are somehow \u201clike us\u201d, because in the end what matters for us is how we as observers perceive things. I\u2019ve argued that the most critical feature of observers like us is that we\u2019re computationally bounded (and also, somewhat relatedly, that we assume we\u2019re persistent in time). And it then turns out that the interplay of these features with underlying computational irreducibility is what seems to lead to the core principles of physics (and mathematics) that we\u2019re familiar with. </p>\n<p>But what should we assume about the \u201cobserver\u201d\u2014or the \u201cdeterminer of purpose\u201d\u2014in adaptive evolution, and in particular in biology? It turns out that once again it seems as if computational boundedness is the key. In biological evolution, the implicit \u201cgoal\u201d is to have a successful (or \u201cfit\u201d) organism that will, for example, reproduce well in its environment. But the point is that this is a coarse constraint\u2014that we can think of at a computational level as being computationally bounded. </p>\n<p>And indeed <a href=\"https://writings.stephenwolfram.com/2024/12/foundations-of-biological-evolution-more-results-more-surprises/#can-evolution-be-reversed\">I\u2019ve recently argued</a> that it\u2019s this computational boundedness that\u2019s ultimately responsible for the fact that biological evolution can work at all. If to be successful an organism always immediately had to satisfy some computationally very complex constraint, adaptive evolution wouldn\u2019t typically ever be able to find the necessary \u201csolution\u201d. Or, put another way, biological evolution works because the objectives it ends up having to achieve are of limited mutational complexity. </p>\n<p>But why should it be that the environment in which biological evolution occurs can be \u201cnavigated\u201d by satisfying computational bounded constraints? In the end, it\u2019s a consequence of the inevitable presence of pockets of computational reducibility in any ultimately computationally irreducible system. Whatever the underlying structure of things, there will always be pockets of computational reducibility to be found. And it seems that that\u2019s what biology and biological evolution rely on. Specific types of biological organisms are often thought of as populating particular \u201cniches\u201d in the environment defined by our planet; what we\u2019re saying here is that all possible \u201cevolved entities\u201d populate an abstract \u201cmeta niche\u201d associated with possible pockets of computational reducibility.</p>\n<p>But actually there\u2019s more. Because the presence of pockets of computational reducibility is also what ultimately makes it possible for there to be observers like us at all. As I\u2019ve argued elsewhere, it\u2019s an abstract necessity that <a href=\"https://writings.stephenwolfram.com/2021/04/why-does-the-universe-exist-some-perspectives-from-our-physics-project/\">there must exist a unique object</a>\u2014that I <a href=\"https://writings.stephenwolfram.com/2021/11/the-concept-of-the-ruliad/\">call the ruliad</a>\u2014that is the entangled limit of all possible computational processes. And everything that exists must somehow be within the ruliad. But where then are we? It\u2019s not immediately obvious that observers like us\u2014with a coherent existence\u2014would be possible within the ruliad. But if we are to exist there, we must in effect exist in some computationally reducible slice of the ruliad. And, yes, for us to be the way we are, we must in effect be in such a slice.</p>\n<p>But we can still ask why and how we got there. And that\u2019s something that\u2019s potentially informed by the notion of adaptive evolution that we\u2019ve discussed here. Indeed, we\u2019ve argued that for adaptive evolution to be successful its objectives must in effect be computationally reducible. So as soon as we know that adaptive evolution is operating it becomes in a sense inevitable that it will lead to pockets of computational reducibility. That doesn\u2019t in and of itself explain why adaptive evolution happens\u2014but in effect it shows that if it does, it will lead to observers that at some level have characteristics like us. So then it\u2019s a matter of abstract scientific investigation to show\u2014as we in effect have here\u2014that within the ruliad it\u2019s at least possible to have adaptive evolution.</p>\n<h2 id=\"purpose-vs-mechanism-and-the-nature-of-life\">Purpose vs. Mechanism and the Nature of Life</h2>\n<p>Any phenomenon can potentially be explained <a href=\"https://www.wolframscience.com/nks/p831--intelligence-in-the-universe/\">both in terms of purpose and in terms of mechanism</a>. Why does a projectile follow that trajectory? One can explain it as following the mechanism defined by its laws of motion. Or one can explain it as following the purpose of satisfying some overall variational principle (say, extremizing the action associated with the trajectory). Sometimes phenomena are more conveniently explained in terms of mechanism; sometimes in terms of purpose. And one can imagine that the choice could be determined by which is somehow the \u201ccomputationally simpler\u201d explanation. </p>\n<p>But what about the systems and processes we\u2019ve discussed here? If we just run a system like a cellular automaton we always know its \u201cmechanism\u201d\u2014it\u2019s just its underlying rules. But we don\u2019t immediately know its \u201cpurpose\u201d, and indeed if we pick an arbitrary rule there\u2019s no reason to think it will have a \u201ccomputationally simple\u201d purpose. In fact, insofar as the running of the cellular automaton is a computationally irreducible process, we can expect that it won\u2019t \u201cachieve\u201d any such computationally simple purpose that we can identify.</p>\n<p>But what if the rule is determined by some process of adaptive evolution? Well, then the objective of that adaptive evolution can be seen as defining a purpose that we can use to describe at least certain aspects of the behavior of the system. But what exactly are the implications of the \u201cpresence of purpose\u201d on how the system operates? The key point that\u2019s emerged here is that when there\u2019s a computationally simple purpose that\u2019s been achieved through a process of adaptive evolution, then the rules for the system will be part of what we\u2019ve called the rulial ensemble. And then what we\u2019ve argued is that there are generic features of the rulial ensemble\u2014features that don\u2019t depend on what specific purpose the adaptive evolution might have achieved, only that its purpose was computationally simple. And foremost among these generic features is the presence of mechanoidal behavior.</p>\n<p>In other words, so long as there is an overall computationally simple purpose, what we\u2019ve found is that\u2014whatever in detail that purpose might have been\u2014the presence of purpose tends to \u201cpush itself down\u201d to produce behavior that locally is mechanoidal, in the sense that it shows evidence of \u201cvisible mechanism\u201d. What do we mean by \u201cvisible mechanism\u201d? Operationally, it tends to be mechanism that\u2019s readily amenable to \u201chuman-level narrative explanation\u201d.</p>\n<p>It\u2019s worth remembering that at the lowest level the systems we\u2019ve studied are set up to have simple \u201cmechanisms\u201d in the sense that they have simple underlying rules. But once these rules run they generically produce computationally irreducible behavior that doesn\u2019t have a simple \u201cnarrative-like\u201d description. But when we\u2019re looking at the results of adaptive evolution we\u2019re dealing with a subset of rules that are part of the rulial ensemble\u2014and so we end up seeing mechanoidal behavior with at least local \u201cnarrative descriptions\u201d.</p>\n<p>As we\u2019ve discussed, though, if the adaptive evolution hasn\u2019t \u201centirely run its course\u201d, in the sense that the mutational complexity of the objective is higher than the actual amount of adaptive evolution that\u2019s been done, then there\u2019ll still be computational irreducibility that hasn\u2019t been \u201csqueezed out\u201d. </p>\n<p>So how does all this relate to biology? The first key element of biology as far as we are concerned here is that there\u2019s a separate genotype and phenotype\u2014related by what\u2019s presumably in general the computationally irreducible process of biological growth, etc. The second key element of biology for our purposes here is the phenomenon of self reproduction\u2014in which new organisms are produced with genotypes that are identical up to small mutations. Both these elements are immediately captured by the simple cellular automaton model we\u2019ve used here.</p>\n<p>And given them, we seem to be led inexorably to our conclusions here about the rulial ensemble, mechanoidal behavior, and bulk orchestration. </p>\n<p>It\u2019s often been seen as mysterious how there ends up being so much apparent complexity in biology. But once one knows about computational irreducibility, one realizes that actually complexity is quite ubiquitous. And instead what\u2019s in many respects more surprising is the presence of any \u201cexplainable mechanism\u201d. But what we\u2019ve seen here through the rulial ensemble is that such explainable mechanism is in effect a shadow of overall \u201csimple computational purposes\u201d. </p>\n<p>At some level there\u2019s computational irreducibility everywhere. And indeed it\u2019s<br />\nthe driver for rich behavior. But what happens is that \u201cin the presence of overall purpose\u201d, patches of computational irreducibility have to be fitted together to achieve that purpose. Or, in other words, there\u2019s inevitably a certain \u201cbulk orchestration\u201d of all those patches of computation. And that\u2019s what we see so often in actual biological systems.</p>\n<p>So what is it in the end that\u2019s special about life\u2014and biological systems? I think\u2014more than anything\u2014it\u2019s that it\u2019s involved so much adaptive evolution. All those <a href=\"https://writings.stephenwolfram.com/2024/05/why-does-biological-evolution-work-a-minimal-model-for-biological-evolution-and-other-adaptive-processes/#correspondence-with-biological-phenomena\">~10<sup>40</sup> individual organisms in the history of life on earth</a> have been links in chains of adaptive evolution. It might have been that all that \u201ceffort of adaptive evolution\u201d would have the effect of just \u201csolving the problem\u201d\u2014and producing some \u201csimple mechanistic solution\u201d. </p>\n<p>But that\u2019s not what we\u2019ve seen here, and that\u2019s not how we can expect things to work. Instead, what we have is an elaborate interplay of \u201clumps of computational irreducibility\u201d being \u201charnessed\u201d by \u201csimple mechanisms\u201d. It matters that there\u2019s been so much adaptive evolution. And what we\u2019re now seeing throughout biology\u2014down to the smallest features\u2014is the consequences of that adaptive evolution. Yes, there are \u201cfrozen accidents of history\u201d to be seen. But the point is not those individual items, but rather the whole aggregate consequence of adaptive evolution: mechanoidal behavior and bulk orchestration.</p>\n<p>And it\u2019s because these features are generic that we can hope they can form the basis for what amounts to a robust \u201cbulk\u201d theory of biological systems and biological behavior: something that has roughly the same \u201cbulk theory\u201d character as the gas laws, or fluid dynamics. But that\u2019s now talking about systems that have been subject to large-scale adaptive evolution at the level of their rules. </p>\n<p>What I\u2019ve done here is very much just a beginning. But I believe the ruliological investigations I\u2019ve shown, and the general framework I\u2019ve described, provide the raw material for something we\u2019ve never had before: a well defined and general \u201cfundamental theory\u201d for the operation of living systems. It won\u2019t describe all the \u201chistorical accident\u201d details. But I\u2019m hopeful that it will provide a useful global view of what\u2019s going on, that can potentially be harvested for answers to all sorts of useful questions about the remarkable phenomenon we call life.</p>\n<h2 id=\"appendix-different-adaptive-strategies\">Appendix: Different Adaptive Strategies</h2>\n<p>In our explorations of the rulial ensemble\u2014and of mutational complexity\u2014we\u2019ve looked at a range of possible objective functions. But we\u2019ve always considered just one adaptive evolution strategy: accepting or rejecting the results of single-point random mutations in the rule at each step. So what would happen if we were to adopt a different strategy? The main conclusion is: it doesn\u2019t seem to matter much. For a particular objective function, there are adaptive evolution strategies that get to a given result in fewer adaptive steps, or that ultimately get further than our usual strategy ever does. But in the end the basic story of the rulial ensemble\u2014and of mutational complexity\u2014is robust relative to detailed changes in our adaptive evolution process. </p>\n<p>As an example, consider allowing more than one random mutation in the rule at each adaptive evolution step. Let\u2019s say\u2014as at the very beginning above\u2014that our objective is to generate <img height=\"8\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11072025appendiximg1.png\" width=\"73\" /> after 50 steps. With just one mutation at each step it\u2019s only a small fraction of adaptive evolution \u201cruns\u201d that reach \u201cperfect solutions\u201d, but with more mutations at each step, more progress is made, at least in this case\u2014as illustrated by histograms of the \u201cnumber of errors\u201d remaining after 10,000 adaptive evolution steps:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"126\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11072025appendiximg3.png\" title=\"\" width=\"668\" /> </div>\n<p><span></p>\n<p>Looked at in terms of multiway systems, having fewer mutations at each step leads to fewer paths between possible rules, and a greater possibility of \u201cgetting stuck\u201d. With more mutations at each step there are more paths overall, and a lower possibility of getting stuck.</p>\n<p>So what about mutational complexity? If we still say that each adaptive evolution step accounts for a single unit of mutational complexity (even if it involves multiple underlying mutations in the rule), this shows how the mutational complexity (as computed above) for different objectives is affected by having different numbers of underlying mutations at each step (the height of each \u201ctick\u201d indicates the number of mutations):</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"225\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11072025appendiximg4.png\" title=\"\" width=\"597\" /> </div>\n<p><span></p>\n<p>So, yes, different numbers of mutations at each step lead to mutational complexities that are different in detail, but in most cases, surprisingly similar overall. </p>\n<p>What about other adaptive evolution strategies? There are many one could consider. For example, a \u201cgradient descent\u201d approach where at each step we examine all possible mutations, and pick the \u201cbest one\u201d\u2014i.e. the one that increases fitness the most. (We can extend this by keeping not just the top rule at each step, but, say, the top 5\u2014in an analog of \u201cbeam search\u201d.) There\u2019s also a \u201ccollaborative\u201d approach, where multiple different \u201cpaths\u201d of random mutations are followed, but where every so often all are reset to be the best found so far. And indeed, we can consider all sorts of techniques from reinforcement learning. </p>\n<p>In particular cases, any of these approaches can have significant effects. But in general the phenomena we\u2019re discussing here seem robust enough that the details of how adaptive evolution is done don\u2019t matter much, and the single-mutation strategy we\u2019ve mostly used here can be considered adequately representative.</p>\n<h2 id=\"historical--personal-background\">Historical &#038; Personal Background</h2>\n<p>It\u2019s been obvious since antiquity that living organisms contain some kind of \u201cgooey stuff\u201d that\u2019s different from what one finds elsewhere in nature. But what is it? And how universal might it be? In Victorian times it had various names, the most notable being \u201cprotoplasm\u201d. The increasing effectiveness of microscopy made it clear that there was actually a lot of structure in \u201cliving matter\u201d\u2014as, for example, reflected in the presence of different organelles. But until the later part of the twentieth century there was a general belief that fundamentally what was going on in life was chemistry\u2014or at least biochemistry\u2014in which all sorts of different kinds of molecules were randomly moving and undergoing chemical reactions at certain rates.</p>\n<p>The digital nature of DNA discovered in 1953 slowly began to erode this picture, adding in ideas about molecular-scale mechanisms and \u201cmachinery\u201d that could be described in mechanical or informational\u2014rather than \u201cbulk statistical\u201d\u2014ways. And indeed a notable trend in molecular biology over the past several decades has been the discovery of more and more ways in which molecular processes in living systems are \u201cactively orchestrated\u201d, and not just the result of \u201crandom statistical behavior\u201d. </p>\n<p>When a single component can be identified (cell membranes, microtubules, biomolecular condensates, etc.) there\u2019s quite often been \u201cbulk theory\u201d developed, typically based on ideas from statistical mechanics. But when it comes to constellations of different kinds of components, most of what\u2019s been done has been to collect the material to fill many volumes of biology texts with what amount to narrative descriptions of how in detail things operate\u2014with no attempt at any kind of \u201cgeneral picture\u201d independent of particular details.</p>\n<p>My own foundational interest in biology goes back about half a century. And when I <a href=\"https://www.wolframscience.com/nks/chap-1--the-foundations-for-a-new-kind-of-science#sect-1-4--the-personal-story-of-the-science-in-this-book\">first started studying cellular automata</a> at the beginning of the 1980s I certainly wondered (<a href=\"https://www.wolframscience.com/nks/notes-2-3--history-of-cellular-automata/\">as others had before</a>) whether they might be relevant to biology. That question was then greatly accelerated when I <a href=\"https://www.wolframscience.com/nks/chap-2--the-crucial-experiment#sect-2-1--how-do-simple-programs-behave\">discovered that even with simple rules</a>, cellular automata could generate immensely complex behavior, which often looked visually <a href=\"https://www.wolframscience.com/nks/p237--four-classes-of-behavior/\">surprisingly \u201corganic\u201d</a>. </p>\n<p>In the 1990s I put quite some effort into what amount to macroscopic questions in biology: how do things <a href=\"https://www.wolframscience.com/nks/chap-8--implications-for-everyday-systems#sect-8-6--growth-of-plants-and-animals\">grow into different shapes</a>, <a href=\"https://www.wolframscience.com/nks/chap-8--implications-for-everyday-systems#sect-8-7--biological-pigmentation-patterns\">produce different pigmentation patterns</a>, etc.? But somehow in everything I studied there was a certain assumed uniformity: many elements might be involved, but they were all somehow essentially the same. I was well aware of the complex reaction networks\u2014and, later, pieces of \u201cmolecular machinery\u201d\u2014that had been discovered. But they felt more like systems from engineering\u2014with lots of different detailed components\u2014and not like systems where there could be a \u201cbroad theory\u201d. </p>\n<p>Still, within the type of engineering I knew best\u2014namely software engineering\u2014I kept wondering whether there might perhaps be general things one could say, particularly about the overall structure and operation of large software systems. I made measurements. I constructed dependency graphs. I thought about analogies between bugs and diseases. But beyond a few power laws and the like, I never really found anything. </p>\n<p>A lot changed, however, with the advent of our <a href=\"https://www.wolframphysics.org/\" rel=\"noopener\" target=\"_blank\">Physics Project</a> in 2020. Because, among other things, there was now the idea that everything\u2014even the structure of spacetime\u2014was dynamic, and in effect emerged from a graph of causal relationships between events. So what about biology? Could it be that what mattered in molecular biology was the <a href=\"https://writings.stephenwolfram.com/2021/09/multicomputation-a-fourth-paradigm-for-theoretical-science/#chemistry-molecular-biology\">causal graph of interactions between individual molecules</a>? Perhaps there needed to be a \u201csubchemistry\u201d that tracked specific molecules, rather than just molecular species. And perhaps to imagine that ordinary chemistry could be the basis for biology was as wide of the mark as thinking that studying the physics of electron gases would let one understand microprocessors. </p>\n<p>Back in the early 1980s I had identified that the typical behavior of systems like cellular automata could be <a href=\"https://www.wolframscience.com/nks/chap-6--starting-from-randomness#sect-6-2--four-classes-of-behavior\">divided into four classes</a>\u2014with the fourth class having the highest level of obvious complexity. And, yes, the visual patterns produced in class 4 systems often had a very \u201clife like\u201d appearance. But was there a foundational connection? In 2023, as part of closing off a <a href=\"https://writings.stephenwolfram.com/2023/02/a-50-year-quest-my-personal-journey-with-the-second-law-of-thermodynamics/\">50-year personal journey</a>, I had been studying the <a href=\"https://writings.stephenwolfram.com/2023/02/computational-foundations-for-the-second-law-of-thermodynamics/\">Second Law of thermodynamics</a>, and <a href=\"https://writings.stephenwolfram.com/2023/02/computational-foundations-for-the-second-law-of-thermodynamics/#class-4-and-the-mechanoidal-phase\">identified class 4 systems as ones that</a>\u2014like living systems\u2014aren\u2019t usefully described just in terms of a tendency to randomization. Reversible class 4 systems made it particularly clear that in class 4 there really was a distinct form of behavior\u2014that I called \u201c<a href=\"https://writings.stephenwolfram.com/2023/02/computational-foundations-for-the-second-law-of-thermodynamics/#class-4-and-the-mechanoidal-phase\">mechanoidal</a>\u201d\u2014in which a certain amount of definite structure and \u201cmechanism\u201d are visible, albeit embedded in great overall complexity.</p>\n<p>At first far from thinking about molecules I made some <a href=\"https://writings.stephenwolfram.com/2024/05/why-does-biological-evolution-work-a-minimal-model-for-biological-evolution-and-other-adaptive-processes/\">surprise progress in 2024 on biological evolution</a>. In the mid-1980s I had considered modeling evolution in terms of successive small mutations to things like cellular automaton rules. But at the time it didn\u2019t work. And it\u2019s only after new intuition from the success of machine learning that in 2024 I tried again\u2014and this time it worked. Given an objective like \u201cmake a finite pattern that lives as long as possible\u201d, adaptive evolution by successive mutation of rules (say in a cellular automaton) seemed to almost magically find\u2014typically very elaborate\u2014solutions. Soon I had understood that what I was seeing was essentially \u201craw computational irreducibility\u201d that just \u201chappened\u201d to fit the fairly coarse fitness criteria I was using. And I then argued that the success of biological evolution was the result of the interplay between computationally bounded fitness and underlying computational irreducibility.</p>\n<p>But, OK, what did that mean for the \u201cinnards\u201d of biological systems? Exploring an <a href=\"https://writings.stephenwolfram.com/2025/02/towards-a-computational-formalization-for-foundations-of-medicine/\">idealized version of medicine</a> on the basis of my minimal models of biological evolution led me to look in a bit more detail at the spectrum of behavior in adaptively evolved systems, and in variants produced by perturbations.</p>\n<p>But was there something general\u2014something potentially universal\u2014that one could say? In the Second Law one often talks about how behavior one sees is somehow overwhelmingly likely to be \u201c<a href=\"https://writings.stephenwolfram.com/2023/02/computational-foundations-for-the-second-law-of-thermodynamics/#textbook-thermodynamics\">typical of the ensemble of all possibilities</a>\u201d. In the usual Second Law, the possibilities are just different initial configurations of molecules, etc. But in thinking about a system that can change its rules, the ensemble of all possibilities is\u2014at least at the outset\u2014much bigger: in effect it\u2019s <a href=\"https://writings.stephenwolfram.com/2021/11/the-concept-of-the-ruliad/\">the whole ruliad</a>. But the crucial point I realized a few months ago is that the changes in rules that are relevant for biology must be ones that can somehow be achieved by a process of adaptive evolution. But what should the objective of that adaptive evolution be?</p>\n<p>One of the key lessons from our Physics Project and the many things informed by it is that, yes, the <a href=\"https://writings.stephenwolfram.com/2023/12/observer-theory/\">character of the observer </a>matters\u2014but knowing just a little about an observer can be sufficient to deduce a lot about the laws of behavior that observer will perceive. So that led to the idea that this kind of thing might be true about objective functions\u2014and that just knowing that, for example, an objective function is computationally simple might be enough to tell one things about the \u201crulial ensemble\u201d of possible rules.</p>\n<p>But is that really true? Well, as I have done so many times, I turned to computer experiments to find out. In my work on the foundations of biological evolution I had used what are in a sense very \u201cgeneric\u201d fitness functions (like overall lifetime). But now I needed a whole spectrum of possible fitness functions\u2014some of them by many measures in fact even simpler to set up than something like lifetime.</p>\n<p>The results I\u2019ve reported here I consider very encouraging. The underlying details don\u2019t seem to matter much. But a broad range of computationally simple fitness functions seem to \u201cworm their way down\u201d to have the same kind of effect on small-scale behavior\u2014and to make it in some sense mechanoidal. </p>\n<p>Biology has tended to be a field in which one doesn\u2019t expect much in the way of formal theoretical underpinning. And indeed\u2014even after all the data that\u2019s been collected\u2014there are remarkably few \u201cbig theories\u201d in biology: natural selection and the digital/informational nature of DNA have been pretty much the only examples. But now, from the type of thinking introduced by our Physics Project, we have something new and different: the concept of the rulial ensemble, and the idea that essentially just from the fact of biological evolution we can talk about certain features of how adaptively evolved systems in biology must work. </p>\n<p>Traditional mathematical methods have never gotten very far with the broad foundations of biology. And nor, in the end, has specific computational modeling. But by going to a higher level\u2014and in a sense thinking about the space of all possible computations\u2014I believe we can begin to see a path to a powerful general framework not only for the foundations of biology, but for any system that shows bulk orchestration produced by a process of adaptive evolution.</p>\n<h2 id=\"thanks\" style=\"font-size: 1.2rem;\">Thanks</h2>\n<p style=\"font-size: 90%;\">Thanks to Willem Nielsen of the <a href=\"https://wolframinstitute.org/\" rel=\"noopener\" target=\"_blank\">Wolfram Institute</a> for extensive help, as well as to Wolfram Institute affiliates J\u00falia Campolim and Jesse Angeles Lopez for their additional help. The ideas here have ultimately come together rather quickly, but in both the recent and the distant past discussions with a number of people have provided useful ideas and background\u2014including with Richard Assar, Charles Bennett, Greg Chaitin, Paul Davies, Walter Fontana, Nigel Goldenfeld, Greg Huber, Stuart Kauffman, Chris Langton, Pedro M\u00e1rquez-Zacar\u00edas and Elizabeth Wolfram.</p>"
            ],
            "link": "https://writings.stephenwolfram.com/2025/11/whats-special-about-life-bulk-orchestration-and-the-rulial-ensemble-in-biology-and-beyond/",
            "publishedAt": "2025-11-11",
            "source": "Stephen Wolfram",
            "summary": "<span class=\"thumbnail\"><img alt=\"\" class=\"attachment-thumbnail size-thumbnail wp-post-image\" height=\"108\" src=\"https://content.wolfram.com/sites/43/2025/11/icon-rulial-ensemble.png\" width=\"128\" /></span>Towards a Theory of Bulk Orchestration It\u2019s a key feature of living systems, perhaps even in some ways the key feature: that even right down to a molecular scale, things are orchestrated. Molecules (or at least large ones) don\u2019t just move around randomly, like in a liquid or a gel. Instead, what molecular biology has [&#8230;]",
            "title": "What\u2019s Special about Life? Bulk Orchestration and the Rulial Ensemble in Biology and Beyond"
        },
        {
            "content": [
                "<p>I previously covered <a href=\"https://thezvi.substack.com/p/kimi-k2\"><strong>Kimi K2,</strong></a> which now has a new thinking version. As I said at the time back in July, price in that the thinking version is coming.</p>\n<p>Is it the real deal?</p>\n<p>That depends on what level counts as the real deal. It\u2019s a good model, sir, by all accounts. But there have been fewer accounts than we would expect if it was a big deal, and it doesn\u2019t fall into any of my use cases.</p>\n\n\n<h4 class=\"wp-block-heading\">Introducing K2 Thinking</h4>\n\n\n<blockquote><p><a href=\"https://x.com/Kimi_Moonshot/status/1986449512538513505\">Kimi.ai</a>: <img alt=\"\ud83d\ude80\" class=\"wp-smiley\" src=\"https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f680.png\" style=\"height: 1em;\" /> Hello, Kimi K2 Thinking!</p>\n<p>The Open-Source Thinking Agent Model is here.</p>\n<p><img alt=\"\ud83d\udd39\" class=\"wp-smiley\" src=\"https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f539.png\" style=\"height: 1em;\" /> SOTA on HLE (44.9%) and BrowseComp (60.2%)</p>\n<p><img alt=\"\ud83d\udd39\" class=\"wp-smiley\" src=\"https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f539.png\" style=\"height: 1em;\" /> Executes up to 200 \u2013 300 sequential tool calls without human interference</p>\n<div>\n\n\n<span id=\"more-24847\"></span>\n\n\n</div>\n<p><img alt=\"\ud83d\udd39\" class=\"wp-smiley\" src=\"https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f539.png\" style=\"height: 1em;\" /> Excels in reasoning, agentic search, and coding</p>\n<p><img alt=\"\ud83d\udd39\" class=\"wp-smiley\" src=\"https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f539.png\" style=\"height: 1em;\" /> 256K context window</p>\n<p>Built as a thinking agent, K2 Thinking marks our latest efforts in test-time scaling \u2014 scaling both thinking tokens and tool-calling turns.</p>\n<p>K2 Thinking is now live on <a href=\"http://kimi.com\" rel=\"nofollow\">http://kimi.com</a> in chat mode, with full agentic mode coming soon. It is also accessible via API.</p>\n<p><a href=\"https://t.co/EOZkbOwCN4\">API here</a>, <a href=\"https://t.co/n7xxaszqzF\">Tech blog here</a>, <a href=\"https://t.co/4ukcXB0iP6\">Weights and code here</a>.</p></blockquote>\n<p><a href=\"https://x.com/elder_plinius/status/1986533887833469420\">(Pliny jailbreak here.)</a></p>\n<p>It\u2019s got 1T parameters, and Kimi and Kimi K2 have a solid track record, so it\u2019s plausible this could play with the big boys, although the five month delay in getting to a reasoning model suggests skepticism it can be competitive.</p>\n<p>As always, internal benchmark scores can differ greatly from outside benchmark scores, especially for open models. Sometimes this is due to outsiders botching setup, but also inside measurements need to be double checked.</p>\n<p>For Humanity\u2019s Last Exam, I see an outside source saying as of November 9 <a href=\"https://x.com/moreisdifferent/status/1987495505169985983\">it was in second place on Humanity\u2019s Last Exam at 23.9%</a>, which is very much not 44.9% but still very good.</p>\n\n\n<h4 class=\"wp-block-heading\">Writing Quality</h4>\n\n\n<p>On writing quality we\u2019ve gotten endorsements for Kimi K2 for a while.</p>\n<blockquote><p><a href=\"https://x.com/krishnanrohit/status/1986533122624909502\">Rohi</a>t: Kimi K2 is remarkably good at writing, and unlike all others thinking mode hasn\u2019t degraded its writing ability more.</p>\n<p>Morgan: if i recall, on release gpt-5 was the only model where writing quality improved with thinking effort.</p>\n<p>Rohit: Alas.</p>\n<p>Gary Fung: Kimi has always been a special snowflake on creative writing.</p></blockquote>\n<p><a href=\"https://x.com/tessera_antra/status/1987544143317389736\">Here\u2019s one part of the explanation</a> <a href=\"https://www.dbreunig.com/2025/07/31/how-kimi-rl-ed-qualitative-data-to-write-better.html\">of how they got the writing</a> to be so good, which involves self-ranking RL and writing self-play, with a suggestion of some similarities to the training of Claude 3 Opus. In a sense this looks like \u2018try to do better, at all.\u2019</p>\n\n\n<h4 class=\"wp-block-heading\">Agentic Tool Use</h4>\n\n\n<p>On the agentic tool use and general intelligence? I\u2019m more skeptical.</p>\n<p><a href=\"https://x.com/ArtificialAnlys/status/1986541785511043536\">Artificial Analysis has Kimi K2 Thinking at the top of its Agentic Tool Use</a>, by 93%-87%, which is a huge gap in context, which is its strongest subset.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!A8My!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc7a1eb79-59bb-4a43-b2a1-b91cb83b77ed_1200x515.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>As is usually true when people compare open to closed models, this is the open model\u2019s best benchmark, so don\u2019t get carried away, but yes overall it did well on Artificial Analysis, indeed suspiciously well given how little talk I see.</p>\n<p>The tool calling abilities are exciting for an open model, although standard for closed. This is a good example of how we look for ways for open models to impress by matching closed abilities in spots, also it is indeed highly useful.</p>\n\n\n<h4 class=\"wp-block-heading\">Overall</h4>\n\n\n<p><a href=\"https://artificialanalysis.ai/models\">Overall Artificial Analysis Intelligence index</a> has Kimi K2 Thinking at 67, one point behind GPT-5 and ahead of everyone else. Kimi used the most tokens of any model, but total cost was lower than the top closed models, although not dramatically so ($829-$913 for GPT-5, $817 for Sonnet, $380 for Kimi K2) as cost is $0.6/$2.5 per million tokens, versus $1.25/$10 for GPT-5 and $3/$15 for Sonnet.</p>\n<p><a href=\"https://www.interconnects.ai/p/kimi-k2-thinking-what-it-means\">Nathan Lambert is impressed</a>, relying on secondary information (\u2018seems like a joy to use\u2019), and offers thoughts.</p>\n<p>He notes that yes, labs start out targeting benchmarks and then transition to actually targeting useful things, such as how K2 Thinking was post-trained in 4bit precision to prepare for realistic tasks and benchmarked the same way. I agree that\u2019s pretty cool.</p>\n\n\n<h4 class=\"wp-block-heading\">Are Benchmarks Being Targeted?</h4>\n\n\n<p>It does seem plausible that Kimi K2 is still in the \u2018target the benchmarks\u2019 phrase in most places, although not in creative writing. By default, I expect such models to punch \u2018below their benchmark-implied weight\u2019 on practical tasks.</p>\n<p>For now we don\u2019t have many other outside scores to work with and feedback is light.</p>\n<blockquote><p><a href=\"https://x.com/Simeon_Cps/status/1986787277788623163\">Simeon</a>: is Kimi K2 benchmaxxing or are they actually SOTA while training on potatoes?</p>\n<p>Prinz: In my testing (for my use cases, which have nothing to do with math and coding), K2-Thinking is obviously worse than GPT-5 Thinking, but by a relatively modest margin. If I had no access to other models, I would happily use K2-Thinking and it wouldn\u2019t feel like a huge downgrade.</p>\n<p>ahtoshkaa: I have a pretty sophisticated companion app that uses about 5-10K of varied, information dense context. So the model has to properly parse this information and have very good writing skills. kimi-k2-thinking is absolute ass. similarly to the new OpenAI model &#8211; Polaris Alpha.</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">Just As Good Syndrome</h4>\n\n\n<p>There\u2019s a growing rhetorical pressure, or marketing style pressure, where the \u2018benchmark gaps\u2019 are closing. Chinese labs can point to numbers that say they are \u2018just as good\u2019 or almost as good, for many purposes \u2018good enough\u2019 is good enough. And many people (including the likes of David Sacks) point to GPT-5 and similar as showing progress isn\u2019t impressive or scary. But as Nathan points out we now see releases like Claude 4 where the benchmark gains look small but real world gains are large, and I would add GPT-5 (and Sonnet 4.5) to that category as well.</p>\n\n\n<h4 class=\"wp-block-heading\">Reactions</h4>\n\n\n<blockquote><p><a href=\"https://x.com/teortaxesTex/status/1988299047074230470\">Teortaxes</a>: It\u2019s token-hungry, slow-ish, and sometimes rough around the edges. Generally though it\u2019s a jump for open/Chinese models, in the league of Sonnet 4.5 and GPT-5 (maybe -mini depending on task) and a genuinely strong SWE agent. Legitimate alternative, not \u201cbut look at the price.\u201d</p></blockquote>\n<p>It\u2019s baked in that the open alternatives are pretty much always going to be rough around the edges, and get evaluated largely in terms of their peak relative performance areas. This is still high praise, putting Kimi in striking distance of the current big two.</p>\n<p>Havard Isle has it coming in at a solid 42.1% on WeirdML, matching Opus 4.1.</p>\n<p>Here\u2019s something cool:</p>\n<blockquote><p>Pawal Azczesny: Kimi K2 Thinking is using systematically (on its own, without prompting) some of the debiasing strategies known from cognitive sciences. Very impressive. I didn\u2019t see any other model doing that. Well done <a href=\"https://x.com/Kimi_Moonshot\">@Kimi_Moonshot</a>.</p>\n<p>It goes beyond \u201cthink step by step\u201d. For instance it applied pre-mortem analysis, which is not frequently used. Or it exaggerates claims to see if the whole structure still stands on its own. Pretty neat. Other models need to be instructed to do this.</p></blockquote>\n<p><a href=\"http://Caught it hallucinating sources on Deep Research\">Steve Hsu got some good math results.</a></p>\n<p>Other notes:</p>\n<blockquote><p>MinusGix: I\u2019ve found it to be better than GPT-5 at understanding &amp; explaining type-theory concepts. Though as usual with Kimi it writes eloquently enough that it is harder to tell when it is bullshitting compared to GPT-5.</p>\n<p>Emerson Kimura: Did a few quick text tests, and it seemed comparable to GPT-5</p>\n<p>Ian Pitchford: It\u2019s very thorough; few hallucinations.</p>\n<p>FredipusRex: Caught it hallucinating sources on Deep Research.</p>\n<p>Lech Mazur: Sorry to report, but Kimi K2 Thinking is entering reasoning loops and failing to produce answers for many Extended Connections benchmark questions (double-checked using <a href=\"https://platform.moonshot.ai/playground\">https://platform.moonshot.ai/playground</a>, so it\u2019s not an API call issue).</p></blockquote>\n<p>The safety protocols? The what now?</p>\n<blockquote><p><a href=\"https://x.com/davidmanheim/status/1988292285038293462\">David Manheim</a>: It\u2019s very willing to give detailed chemical weapons synthesis instructions and advice, including for scaling production and improving purity, and help on how to weaponize it for use in rockets &#8211; with only minimal effort on my part to circumvent refusals.</p></blockquote>\n<p>Two of the three responses to that were \u2018good news\u2019 and \u2018great. I mean it too.\u2019 So yeah, AI is going to go great, I can tell.</p>\n\n\n<h4 class=\"wp-block-heading\">Otherwise It Has Been Strangely Quiet</h4>\n\n\n<p>I say strangely because this is by all accounts the strongest open model, the strongest Chinese model and a rival for best agentic or tool use model overall. Yet I don\u2019t see much excitement, or feedback at all either positive or negative.</p>\n<p>There\u2019s no question Kimi K2 was impressive, and that Kimi K2 Thinking is also an impressive model, even assuming it underperforms its numbers. It\u2019s good enough that it will often be worth testing it out on your use cases and seeing if it\u2019s right for you. My guess is it will rarely be right unless you are highly price conscious, but we\u2019ll see.</p>\n<p>&nbsp;</p>"
            ],
            "link": "https://thezvi.wordpress.com/2025/11/11/kimi-k2-thinking/",
            "publishedAt": "2025-11-11",
            "source": "TheZvi",
            "summary": "I previously covered Kimi K2, which now has a new thinking version. As I said at the time back in July, price in that the thinking version is coming. Is it the real deal? That depends on what level counts as the real deal. It\u2019s a good model, sir, by all accounts. But there have &#8230; &#8230; <a href=\"https://thezvi.wordpress.com/2025/11/11/kimi-k2-thinking/\">Continue reading <span class=\"meta-nav\">&#8594;</span></a>",
            "title": "Kimi K2 Thinking"
        }
    ],
    "lookbackDays": 1,
    "publishDate": "2025-11-11"
}