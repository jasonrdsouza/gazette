{
    "articles": [
        {
            "content": [
                "<div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!ezte!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F69bb038e-36d7-4ac7-9543-1567b44b3a43_1714x1080.gif\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"917\" src=\"https://substackcdn.com/image/fetch/$s_!ezte!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F69bb038e-36d7-4ac7-9543-1567b44b3a43_1714x1080.gif\" width=\"1456\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a><figcaption class=\"image-caption\">Ella Watkins-Dulaney for Asimov Press.</figcaption></figure></div><p>When the Human Genome Project (HGP) released its initial draft sequence in 2001, President Bill Clinton <a href=\"https://clintonwhitehouse3.archives.gov/WH/EOP/OSTP/html/00628_2.html#:~:text=Without%20a%20doubt%2C%20this%20is%20the%20most%20important%2C%20most%20wondrous%20map%20ever%20produced%20by%20humankind.\">hailed</a> it as &#8220;the most wondrous map ever produced by mankind.&#8221; After more than ten years of work, an <a href=\"https://www.genome.gov/about-genomics/educational-resources/fact-sheets/human-genome-project#:~:text=The%20initially%20projected%20cost%20for%20the%20Human%20Genome%20Project%20was%20%243%20billion%2C%20based%20on%20its%20envisioned%20length%20of%2015%20years.%20While%20precise%20cost%2Daccounting%20was%20difficult%20to%20carry%20out%2C%20especially%20across%20the%20set%20of%20international%20funders%2C%20most%20agree%20that%20this%20rough%20amount%20is%20close%20to%20the%20accurate%20number.\">estimated $3 billion</a> in research costs, and a &#8220;<a href=\"https://www.kirkusreviews.com/book-reviews/james-shreeve/the-genome-war/\">genome war</a>&#8221; with Craig Venter&#8217;s private company, Celera Genomics, the project had produced a nearly complete sequence of a human genome.<a class=\"footnote-anchor\" href=\"https://www.asimov.press/feed#footnote-1\" id=\"footnote-anchor-1\" target=\"_self\">1</a></p><p>UK Prime Minister Tony Blair <a href=\"https://www.genome.gov/10001356/june-2000-white-house-event#:~:text=a%20revolution%20in%20medical%20science%20whose%20implications%20far%20surpass%20even%20the%20discovery%20of%20antibiotics\">predicted</a> that this map would yield &#8220;a revolution in medical science whose implications far surpass even the discovery of antibiotics.&#8221; (Whether this claim turned out to be true is debatable.) A few months later, the two teams &#8212; from HGP and Celera &#8212; published cover stories in <em><a href=\"https://www.nature.com/articles/35057062\">Nature</a></em> and <em><a href=\"https://www.science.org/doi/10.1126/science.1058040\">Science</a></em>, respectively.</p><p>Although the <a href=\"https://www.genome.gov/about-nhgri/Brief-History-Timeline\">quest</a> to sequence a human genome began in 1990, the techniques it used had already been in development for more than twenty years. And those DNA sequencing methods, in turn, were directly inspired by protein and RNA sequencing research <a href=\"https://www.cell.com/trends/biochemical-sciences/fulltext/S0968-0004(99)01360-2\">stretching</a> all the way back to the <a href=\"https://pmc.ncbi.nlm.nih.gov/articles/PMC1275055/\">1940s</a>.</p><p>In the twenty years <em>after</em> the draft human genome was first released, the average <a href=\"https://www.genome.gov/about-genomics/fact-sheets/DNA-Sequencing-Costs-Data\">sequencing cost</a> per genome fell roughly one hundred thousand-fold, ending up just north of $500. In that same period, the cost to sequence a million letters or &#8220;megabase&#8221; of DNA fell to six tenths of a cent.<a class=\"footnote-anchor\" href=\"https://www.asimov.press/feed#footnote-2\" id=\"footnote-anchor-2\" target=\"_self\">2</a> This plummeting price is due largely to technological innovation, including new sequencing chemistries, computational methods for assembling raw reads into finished genomes, and highly efficient commercial sequencing machines.</p><p>Out of the many sequencing methods developed over the decades, five are particularly important. These are their histories.</p><p class=\"button-wrapper\"><a class=\"button primary\" href=\"https://www.asimov.press/subscribe\"><span>Subscribe now</span></a></p><h2>Sanger Sequencing</h2><p>Fred Sanger was biology&#8217;s great decoder. A British biochemist who spent his entire career at the University of Cambridge, Sanger earned <em>two </em>Nobel Prizes in the same field: first, the 1958 Nobel Prize in Chemistry for creating a method to determine the <a href=\"https://www.nobelprize.org/prizes/chemistry/1958/summary/\">amino acid sequence</a> of proteins (most famously insulin) and, second, a share of the 1980 Nobel Prize in Chemistry for inventing methods to <a href=\"https://www.nobelprize.org/prizes/chemistry/1980/summary/\">sequence DNA</a>.</p><p>After winning his first Nobel, Sanger turned his <a href=\"https://www.whatisbiotechnology.org/index.php/exhibitions/sanger/path#:~:text=Sanger%2C%201988).-,Sequencing%20RNA,-Sanger%27s%20notebooks%20on\">gaze to RNA</a>, seeking to become the first person to sequence a full strand. He was beaten by Cornell biochemist Robert Holley, however, who reported the full <a href=\"https://www.science.org/doi/10.1126/science.147.3664.1462\">77-nucleotide sequence</a> of the alanine transfer RNA molecule in 1965.<a class=\"footnote-anchor\" href=\"https://www.asimov.press/feed#footnote-3\" id=\"footnote-anchor-3\" target=\"_self\">3</a></p><p>Although many scientists today assume that Sanger was the first to figure out how to sequence DNA, that&#8217;s not the case. As with RNA, Sanger was edged out by a Cornell biochemist. This time it was <a href=\"https://www.sciencedirect.com/science/article/pii/S136984861400003X\">Ray Wu</a>, who, in 1970, <a href=\"https://www.sciencedirect.com/science/article/pii/0022283671901057\">published a method</a> to &#8220;read&#8221; specific sections of <a href=\"https://www.sciencedirect.com/science/article/pii/0022283670900045\">two bacterial virus genomes</a>, called &#955; and bacteriophage 186. Wu&#8217;s method was only capable of sequencing &#8220;cohesive ends,&#8221; short single-stranded sections of these particular phage genomes, and so wasn&#8217;t considered a &#8220;general&#8221; solution to the DNA sequencing problem. In 1974, Wu&#8217;s lab <a href=\"https://www.pnas.org/doi/abs/10.1073/pnas.71.6.2510\">refined</a> this technique into the first general sequencing method, but it proved <a href=\"https://www.sciencedirect.com/science/article/pii/S0888754315300410?via%3Dihub#bb0100:~:text=However%20the%20actual%20determination%20of%20bases%20was%20still%20restricted%20to%20short%20stretches%20of%20DNA%2C%20and%20still%20typically%20involved%20a%20considerable%20amount%20of%20analytical%20chemistry%20and%20fractionation%20procedures.\">extremely labor-intensive</a> and failed to catch on.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!vCJL!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa4b1d2a-f146-4b17-a7f3-8151651af74f_503x672.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"672\" src=\"https://substackcdn.com/image/fetch/$s_!vCJL!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa4b1d2a-f146-4b17-a7f3-8151651af74f_503x672.png\" width=\"503\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a><figcaption class=\"image-caption\">Output from Ray Wu&#8217;s 2-D homochromatography method. Credit: <a href=\"https://academic.oup.com/nar/article/1/3/331/1117016\">Jay E. </a><em><a href=\"https://academic.oup.com/nar/article/1/3/331/1117016\">et al.</a> Nucleic Acids Research </em>(1974).</figcaption></figure></div><p>In 1975, Sanger published his own <a href=\"https://www.sciencedirect.com/science/article/pii/0022283675902132\">DNA sequencing method</a> alongside laboratory technician Alan Coulson, called the &#8220;plus and minus&#8221; technique. First, scientists mixed the DNA strand to be sequenced with an enzyme, DNA polymerase, as well as a primer, three normal dNTPs and one radiolabeled dNTP. Radiolabeled nucleotides are incorporated into growing DNA strands just like normal nucleotides, but are tagged with radioactive isotopes, such as phosphorus-32 or sulfur-35, so they can be detected using radiation-measuring equipment. </p><p>This reaction would contain only low concentrations of the dNTPs and relied upon brief incubation times, so that DNA synthesis would stall at random positions along the template and yield a population of DNA fragments with varying lengths. These unfinished DNA fragments were then purified and used as templates in four &#8220;minus&#8221; and four &#8220;plus&#8221; reactions.</p><p>For each minus reaction, the purified DNA fragments were incubated together with three of the four dNTPs, meaning each fragment would be extended by DNA polymerase until the missing nucleotide was needed, at which point synthesis would halt.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!y_XP!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16b49b8a-65dd-4e31-895a-1740bddc918c_554x616.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"616\" src=\"https://substackcdn.com/image/fetch/$s_!y_XP!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16b49b8a-65dd-4e31-895a-1740bddc918c_554x616.png\" width=\"554\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a><figcaption class=\"image-caption\">Output from Sanger and Coulson&#8217;s Plus-Minus method. Credit: <a href=\"https://www.sciencedirect.com/science/article/abs/pii/0022283675902132\">Sanger &amp; Coulson</a>, <em>J. Mol. Biol. </em>(1975).</figcaption></figure></div><p>Plus reactions worked differently: they used T4 DNA polymerase, an enzyme with strong 3&#8217; to 5&#8217; exonuclease activity, meaning it can chew back the end of a DNA strand. In the presence of only one dNTP, T4 DNA polymerase would degrade each fragment from its 3&#8217; end until it reached a nucleotide complementary to that dNTP, at which point the exonuclease activity would be inhibited. This ensured that all fragments in a given plus reaction ended with the same nucleotide.</p><p>Since the eight reactions were run on fragments of random length, the eight plus and minus reactions collectively produced DNA fragments of all possible lengths.<a class=\"footnote-anchor\" href=\"https://www.asimov.press/feed#footnote-4\" id=\"footnote-anchor-4\" target=\"_self\">4</a> The fragments in these eight reactions were separated by size (using gel electrophoresis) and then imaged with autoradiography. Gels were dried and then placed against X-ray film, allowing the radioactive DNA fragments to expose the film and appear as dark bands, which a scientist could then painstakingly translate into the DNA sequence. In 1977, Sanger and colleagues <a href=\"https://www.nature.com/articles/265687a0\">sequenced</a> the first full DNA genome using this method: a small bacterial virus with 5,386 nucleotides in its <a href=\"https://www.ncbi.nlm.nih.gov/nuccore/NC_001422\">genome</a>, called &#632;X174 or &#8220;PhiX.&#8221;</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!H-et!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe2b6d6bd-812b-4f3f-aa0a-1ae70a07728e_1804x1820.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"1469\" src=\"https://substackcdn.com/image/fetch/$s_!H-et!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe2b6d6bd-812b-4f3f-aa0a-1ae70a07728e_1804x1820.png\" width=\"1456\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p>In 1977, Sanger developed a much simpler sequencing method, called &#8220;<a href=\"https://www.pnas.org/doi/abs/10.1073/pnas.74.12.5463\">chain termination</a>,&#8221; which is today known simply as Sanger sequencing. This technique took advantage of a different type of special nucleotide called a dideoxyribonucleotide, or ddNTP. ddNTPs lack one of the hydroxyl groups present on a normal dNTP, preventing the chemical reaction necessary to add another nucleotide and terminating DNA elongation.</p><p>Sanger sequencing reaction mixtures included purified template DNA, a primer, DNA polymerase, and all four dNTPs. Each reaction also included a radiolabeled ddNTP version of just one of the four nucleotides. Only a small amount of each ddNTP was added, however, to ensure that a fraction of the total DNA fragments produced stopped at each occurrence of that base. As with previous methods, separating fragments via length and performing autoradiography allowed scientists to read the final sequence.</p><p>A <a href=\"https://pmc.ncbi.nlm.nih.gov/articles/PMC392330/\">different sequencing method</a> that chemically cleaved DNA at specific bases, developed by Allan Maxam and Walter Gilbert, was the <a href=\"https://link.springer.com/book/10.1057/9780230370937\">dominant technology</a> into the 1980s. Radiolabeled DNA samples were incubated in four separate reactions, each of which contained a chemical that cleaved after a different nucleotide &#8212; either A/G, G, C, or C/T. By adding the right amount of each chemical, it was possible to produce different fragments chopped off at each individual base. The sequence could then be read using gel electrophoresis and autoradiography. Maxam&#8211;Gilbert sequencing was easier than the plus and minus method to run and interpret, but was eventually surpassed by Sanger&#8217;s chain termination method, which molecular biologists found both technically preferable and more &#8220;elegant&#8221; since it mirrored the natural copying of DNA.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!Xocm!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d75f1a9-4dae-446b-a504-85724f5a7032_940x741.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"741\" src=\"https://substackcdn.com/image/fetch/$s_!Xocm!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d75f1a9-4dae-446b-a504-85724f5a7032_940x741.png\" width=\"940\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a><figcaption class=\"image-caption\">Output from the Sanger Sequencing method, with chain-terminating inhibitors. Credit: <a href=\"https://www.pnas.org/doi/epdf/10.1073/pnas.74.12.5463\">Sanger </a><em><a href=\"https://www.pnas.org/doi/epdf/10.1073/pnas.74.12.5463\">et al.</a> PNAS </em>(1977).</figcaption></figure></div><p>While Sanger sequencing was highly accurate and less labor-intensive than its predecessors, it still required the use of radioactive reagents and manual sequence recording. In 1986, Leroy Hood&#8217;s lab at Caltech <a href=\"https://www.nature.com/articles/321674a0\">replaced</a> the radiolabeled ddNTPs with fluorescently labeled nucleotides, using fluorophores that emitted different colors of light for each base. They were now able to run the products of all four reactions on the same gel and have a computer read the sequence by detecting the color of each fluorescent signal as fragments passed through a laser beam.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!BjkC!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c15bb69-810e-404f-8672-5b921174b415_1806x2559.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"2063\" src=\"https://substackcdn.com/image/fetch/$s_!BjkC!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c15bb69-810e-404f-8672-5b921174b415_1806x2559.png\" width=\"1456\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p>The <a href=\"https://collection.sciencemuseumgroup.org.uk/objects/co61227/prototype-automated-dna-gene-sequencer\">first commercial</a> Sanger sequencing machine was produced that year by Applied Biosystems (ABS), which Hood had co-founded in 1981. Called the ABI 370A, it retailed for $92,500. Since Sanger never patented his method, other companies were free to develop competing products, and by 1988, there were <a href=\"https://www.nature.com/articles/333477a0\">three</a> Sanger sequencing machines on the market. These were followed by numerous others, including the <a href=\"https://www.slas-technology.org/article/S2472-6303(22)02019-2/pdf\">Perkin-Ellmer 3700</a>, <a href=\"https://doe-humangenomeproject.ornl.gov/the-human-genome-project-the-private-sector/\">used</a> by Celera and the Human Genome Project, and the <a href=\"https://www.thermofisher.com/uk/en/home/life-science/sequencing/sanger-sequencing/sanger-sequencing-technology-accessories/applied-biosystems-sanger-sequencing-3500-series-genetic-analyzers/3500-series-genetic-analyzer.html\">ABS 3500 Genetic Analyzer</a>, which is still found in many laboratories today.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!TC4L!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fceff802e-1ff0-4794-88e1-c112f5bd3221_1536x1168.jpeg\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"1107\" src=\"https://substackcdn.com/image/fetch/$s_!TC4L!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fceff802e-1ff0-4794-88e1-c112f5bd3221_1536x1168.jpeg\" width=\"1456\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a><figcaption class=\"image-caption\">ABI 370A Sanger sequencing prototype. Source: <a href=\"https://collection.sciencemuseumgroup.org.uk/objects/co61227/prototype-automated-dna-gene-sequencer\">Science Museum</a></figcaption></figure></div><h2>454 Pyrosequencing</h2><p>By the time Sanger sequencing was commercialized, the groundwork for an entirely new sequencing chemistry was already well underway. In 1985, Swedish biochemists P&#229;l Nyren and Arne Lundin published a <a href=\"https://www.sciencedirect.com/science/article/pii/0003269785902118\">paper</a> illustrating a procedure that measured the concentration of a molecule, called pyrophosphate (PPi), using an enzymatic cascade that emits light. In early 1986, Nyren <a href=\"https://link.springer.com/protocol/10.1385/1-59745-377-3:1\">realized</a> that the method he&#8217;d helped develop could be applied to DNA sequencing, because PPi is <a href=\"https://pmc.ncbi.nlm.nih.gov/articles/PMC6159520/\">naturally produced</a> as a byproduct of DNA synthesis.<a class=\"footnote-anchor\" href=\"https://www.asimov.press/feed#footnote-5\" id=\"footnote-anchor-5\" target=\"_self\">5</a></p><p>Funding limitations prevented Nyren from dedicating much time to the project at first, but in 1993, he was finally able to <a href=\"https://www.sciencedirect.com/science/article/abs/pii/S0003269783710249\">publish</a> a proof-of-principle. His technique began by mixing the template DNA with a primer, a single dNTP, and three enzymes: the familiar DNA polymerase plus the light cascade enzymes, ATP sulfurylase and firefly luciferase.<a class=\"footnote-anchor\" href=\"https://www.asimov.press/feed#footnote-6\" id=\"footnote-anchor-6\" target=\"_self\">6</a> If the dNTP was incorporated into a strand of DNA, PPi would be produced in the chemical reaction. ATP sulfurylase could then convert the PPi into ATP, which would provide energy for the luciferase enzyme, producing light. Thus, it was possible to determine each base in the sequence by cycling through the dNTPs one at a time until light was detected, and then washing extra nucleotides out between each step. By literally rinsing and repeating, the sequence could be recorded one letter at a time without the use of any gels, which often took hours to run and were difficult to automate.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!O2Pe!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F47c6d0bf-d865-4b94-8bed-7cafae37a7bc_1800x1519.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"1229\" src=\"https://substackcdn.com/image/fetch/$s_!O2Pe!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F47c6d0bf-d865-4b94-8bed-7cafae37a7bc_1800x1519.png\" width=\"1456\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p>Nyren&#8217;s sequencing method earned the name &#8220;pyrosequencing&#8221; since it revolved around the production of pyrophosphate. At first, pyrosequencing could sequence only short DNA snippets, with a few nucleotides. In 1996, however, Nyren&#8217;s lab <a href=\"https://www.sciencedirect.com/science/article/pii/S0003269796904327\">demonstrated</a> sequencing of up to 15 bases by using a modified &#8220;A&#8221; nucleotide to reduce their signal-to-noise ratio.<a class=\"footnote-anchor\" href=\"https://www.asimov.press/feed#footnote-7\" id=\"footnote-anchor-7\" target=\"_self\">7</a> In 1998, they <a href=\"https://www.science.org/doi/full/10.1126/science.281.5375.363\">increased</a> this to 34 bases by adding another enzyme, called apyrase, to the mix; apyrase degraded unincorporated nucleotides, removing the need for constant wash steps.</p><p>The year before, Nyren&#8217;s lab had also spun off a company, Pyrosequencing AB, to refine and commercialize the technology. Pyrosequencing was not the firm that would bring the technology to market, however; that distinction went to Connecticut-based <a href=\"https://en.wikipedia.org/wiki/454_Life_Sciences\">454 Life Sciences</a>, who <a href=\"https://news.cision.com/pyrosequencing/r/454-life-sciences-obtains-license-from-pyrosequencing,e83113\">licensed</a> whole-genome pyrosequencing applications in 2003. 454 made chips which enabled highly efficient, parallelized <a href=\"https://www.nature.com/articles/nature03959\">sequencing reactions</a> and <a href=\"https://www.biospace.com/454-life-sciences-installs-twenty-gs20-systems-in-the-first-year-of-sales\">released</a> the GS20 sequencer in 2005 for the <a href=\"https://www.genomeweb.com/sequencing/pyrosequencing-inventor-building-mini-sequencer-will-cost-fraction-454s-gs20\">price</a> of $500,000. The GS20 worked by attaching each individual DNA template molecule to a bead and copying it many times using polymerase chain reaction (PCR). Each bead was then loaded into a well in a microplate, where sequencing reactions would be carried out. The light from luciferase activation could be detected through the bottom of the wells, enabling sequences to be read.</p><p>Pyrosequencing wasn&#8217;t developed early enough to be employed by the Human Genome Project or Celera, but it was still the first method other than Sanger sequencing to hit the commercial market, marking the start of &#8220;next generation&#8221; sequencing methods (NGS). Pyrosequencing worked in real-time, though it struggled to accurately capture regions with several of the same nucleotides in a row. This was because the amount of light didn&#8217;t always scale cleanly when pyrophosphate was produced through successive reactions.</p><p>In 2006, 454 collaborated with Swedish paleogeneticist Svante P&#228;&#228;bo to sequence the first million base pairs of the <a href=\"https://www.nature.com/articles/nature05336\">Neanderthal genome</a>; the project would be <a href=\"https://www.science.org/doi/10.1126/science.1188021\">completed</a> four years later, albeit with some help from Illumina sequencing. Illumina and other subsequent NGS technologies rendered pyrosequencing non-competitive, and in 2013, 454 was <a href=\"https://www.fiercebiotech.com/medical-devices/roche-to-close-454-life-sciences-as-it-reduces-gene-sequencing-focus\">shut down</a> by Roche, which had acquired it six years earlier. The technology is still used today for some applications, but most importantly, it was the first commercially viable alternative to Sanger sequencing, and the first sequencing method that could be fully automated because it didn&#8217;t rely on gels or other tedious steps.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!HyCl!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6a73aab3-0915-4772-bade-0939a47c0e55_450x600.jpeg\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"600\" src=\"https://substackcdn.com/image/fetch/$s_!HyCl!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6a73aab3-0915-4772-bade-0939a47c0e55_450x600.jpeg\" width=\"450\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a><figcaption class=\"image-caption\">A Life Sciences 454 sequencer. Credit: <a href=\"https://americanhistory.si.edu/collections/object/nmah_1464226\">National Museum of American History</a></figcaption></figure></div><h2>Sequencing by Synthesis</h2><p>In the mid-1990s, University of Cambridge biochemists David Klenerman and Shankar Balasubramanian were trying to solve a fundamental problem: how to watch a single DNA polymerase molecule at work. Their approach used modified nucleotides, called reversible terminators, tagged with four different colors of fluorescent molecules. If one of these &#8220;terminators&#8221; was grabbed by the DNA polymerase and incorporated onto the replicating DNA strand, it would block the addition of any other bases until removed using a separate chemical reaction.</p><p>Klenerman and Balasubramanian&#8217;s <a href=\"https://www.illumina.com/science/technology/next-generation-sequencing/illumina-sequencing-history.html\">great insight</a> was that template DNA could be sequenced by synthesizing a complementary strand of reversible terminators; basically, extending the chain one base at a time and determining the identity of each nucleotide by looking at the color of its fluorophore. In 1998, the pair started a company called Solexa to develop the technology.</p><p>Detecting fluorescence from a single DNA molecule proved difficult in practice, however. And so, in 2004, Solexa <a href=\"https://frontlinegenomics.com/how-did-illumina-monopolize-the-sequencing-market/#:~:text=2004%3A%20Solexa%20acquired%20molecular%20clustering%20technology%20from%20Manteia%20Predictive%20Medicine.%20This%20enabled%20the%20amplification%20of%20single%20DNA%20molecules%20in%20clusters%2C%20enhancing%20the%20accuracy%20of%20base%20calling%20and%20reducing%20the%20cost%20of%20system%20optics%20by%20generating%20stronger%20signals.\">acquired</a> the <a href=\"https://patents.google.com/patent/US20080286795A1/en?oq=20080286795\">IP rights</a> to a method called colony sequencing, developed by French scientists Pascal Mayer and Laurent Farinelli, to solve the <a href=\"https://btlj.org/wp-content/uploads/2024/06/0006_39-LSI_Tsai.pdf\">detection problem</a>. Colony sequencing affixed DNA fragments to a surface and amplified them over and over, generating &#8220;colonies&#8221; containing massive numbers of identical DNA strands. By reading the fluorescence from each strand in a colony simultaneously, it became possible to determine the base added at each step with much better accuracy, since random errors in individual strands would be averaged out by the consensus signal.</p><p>Now that single-molecule detection was no longer necessary, Solexa was able to develop its signature sequencing chemistry. The <a href=\"https://www.youtube.com/watch?v=fCd6B5HRaZ8\">process</a> takes place on a chip called a flow cell, which contains a lawn of short DNA sequences affixed to its surface. The template DNA is broken up into small fragments, and adapter sequences, complementary to the DNA on the flow cell&#8217;s surface, are added to the ends of each fragment. DNA fragments are then passed over the flow cell, where the adapter sequences bind to spots on the DNA lawn. At this point, primers are added, and an initial round of amplification takes place: the short DNA sequences on the flow cell are extended to create sequences complementary to the bound template DNA fragments, which are then washed away. The sequences present in the fragments of template DNA are now affixed directly to the flow cell.</p><p>At this point, each bound sequence exists as a single copy, which produces too faint a signal to detect reliably. Colony sequencing solves this by generating clusters of identical fragments through a process called bridge amplification. The adapter on the free end of each DNA strand will be complementary to some of the original, short sequences on the DNA lawn, and when this binding occurs, the strand bends over to form a bridge shape. Another round of amplification takes place, resulting in two complementary strands each directly affixed to the flow cell. This &#8220;bridge amplification&#8221; process is repeated over and over to propagate the sequence.</p><p>From here, the actual sequencing can begin. Primers and fluorescently-labeled chain terminators are added to the reaction mixture, resulting in the addition of one nucleotide to each strand of DNA on the lawn. A picture is taken of the entire chip, then the chain terminators&#8217; blockers are cleaved to allow addition of the next base. This process proceeds until the reaction is complete, resulting in massively parallelized sequencing. The short reads acquired through this process can be combined via a computational technique called paired end analysis, which links reads by analyzing overlapping sections, to generate the whole sequence.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!zqsZ!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc23e82f5-adec-4964-99f6-4c6c8abb8da7_1806x1721.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"1387\" src=\"https://substackcdn.com/image/fetch/$s_!zqsZ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc23e82f5-adec-4964-99f6-4c6c8abb8da7_1806x1721.png\" width=\"1456\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p>Solexa&#8217;s first product, the Genome Analyzer, launched in 2006 with a <a href=\"https://www.bio-itworld.com/news/2010/09/30/the-solexa-story\">retail price</a> of $400,000, and the company was <a href=\"https://investor.illumina.com/news/press-release-details/2006/Illumina-Signs-Definitive-Agreement-to-Acquire-Solexa/default.aspx\">acquired</a> by the American genomics firm Illumina the following year. In 2008, the company published a <a href=\"https://www.nature.com/articles/nature07517\">paper</a> demonstrating their technology&#8217;s ability to efficiently sequence whole genomes via short reads. Illumina&#8217;s method is commonly known as &#8220;sequencing by synthesis.&#8221; While the label could technically be applied to other methods, including Sanger&#8217;s, which also indirectly assesses sequence by detecting the incorporation of nucleotides complementary to the template strand, it&#8217;s most commonly used to refer to Illumina&#8217;s chemistry.</p><p>Since the release of Solexa&#8217;s Genome Analyzer, Illumina has created several new <a href=\"https://web.archive.org/web/20260207163524/https://www.illumina.com/systems/sequencing-platforms.html\">sequencing machines</a> designed to fill different price niches. Illumina&#8217;s short reads are <a href=\"https://pmc.ncbi.nlm.nih.gov/articles/PMC4331009/\">highly accurate</a>, and the technique has played a <a href=\"https://centuryofbio.com/p/illumina\">crucial role</a> <a href=\"https://www.ncbi.nlm.nih.gov/books/NBK274079/\">in reducing</a> <a href=\"https://www.ncbi.nlm.nih.gov/books/NBK274079/\">average sequencing costs</a>.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!JOqE!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2a3d4b82-1c81-4b89-9817-122372349bd1_2592x1944.jpeg\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"1092\" src=\"https://substackcdn.com/image/fetch/$s_!JOqE!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2a3d4b82-1c81-4b89-9817-122372349bd1_2592x1944.jpeg\" width=\"1456\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a><figcaption class=\"image-caption\">An Illumina Genome Analyzer II, ca. 2007. Credit: <a href=\"https://commons.wikimedia.org/wiki/File:Illumina_Genome_Analyzer_II_System.jpg\">Jon Callas</a></figcaption></figure></div><p>Unsurprisingly, Illumina has become by far the <a href=\"https://www.nature.com/articles/s41576-020-0236-x\">most common</a> NGS method, maintaining roughly an <a href=\"https://finance.yahoo.com/news/illumina-ilmn-leads-market-80-123127888.html\">80 percent</a> <a href=\"https://www.genengnews.com/topics/omics/illumina-and-the-state-of-the-genomics-market/\">share</a> over the last few years. This is largely owing to its versatility. Illumina sequencing has been used to create new reference genomes, including the <a href=\"https://www.nature.com/articles/nature11119\">common tomato</a>, but has been especially useful in cases requiring repeated sequencing of short DNA sequences. For example, Illumina machines are routinely used to <a href=\"https://www.geneious.com/tutorials/analyze-crispr-editing\">quantify</a> the activity of genome editors like CRISPR; template DNA will either be edited or unedited, and reading the area around the edit many times provides an accurate quantification of editing percentages. Similarly, large numbers of short reads are useful for sequencing ancient DNA, taken from bones or other remains, since such samples often have degraded stretches. In addition to its role in the Neanderthal Genome Project, Illumina has been used to sequence 10,000-year-old human bodies and to <a href=\"https://www.nature.com/articles/s41586-023-06862-3\">track migration</a> and population turnover in Neolithic Denmark.</p><h2>PacBio SMRT Sequencing</h2><p>While Illumina ultimately opted for a method that simultaneously detected massive numbers of DNA strands, others still believed that single-molecule sequencing methods offered a better path forward. Sequencing by synthesis requires repeated amplification, which introduces the possibility of error at each step and biases outputs towards sequences readily amplified by DNA polymerase. Single-molecule techniques <a href=\"https://www.pnas.org/doi/10.1073/pnas.0230489100\">were</a> <a href=\"https://www.technologyreview.com/2008/06/23/219906/sequencing-a-single-molecule-of-dna/\">billed</a> as a way to sequence DNA with minimal bias while simultaneously reducing cost.</p><p>The first such method was <a href=\"https://www.pnas.org/doi/abs/10.1073/pnas.0230489100\">developed</a> in biophysicist Steve Quake&#8217;s lab at Caltech and <a href=\"https://www.nature.com/articles/nmeth.1354\">commercialized</a> by Helicos Biosciences, but became unavailable after the company <a href=\"https://web.archive.org/web/20121121065028/http://biz.yahoo.com/e/121115/hlcs8-k.html\">declared bankruptcy</a>, <a href=\"https://www.genengnews.com/topics/omics/battered-helicos-files-for-chapter-11/\">saddled</a> by legal issues and <a href=\"https://omicsomics.blogspot.com/2016/10/seqll-helicos-van-winkle.html\">unable</a> to find a market niche. These days, the canonical technique comes from a company called Pacific Biosciences (PacBio). Scientists often refer to single-molecule techniques as &#8220;<a href=\"https://www.sciencedirect.com/science/article/pii/S0888754315300410#s0020\">third</a>-<a href=\"https://academic.oup.com/hmg/article/19/R2/R227/641295\">generation</a>&#8221; DNA sequencing, though they&#8217;re <a href=\"https://www.genewiz.com/en-gb/public/services/next-generation-sequencing\">often</a> also lumped into the NGS bucket with Illumina.</p><p>PacBio was <a href=\"https://www.uwalumni.com/news/daa_turner/#:~:text=Turner%20hired%20a,up%20and%20running.\">founded in 2004</a> to develop sequencing methods based on work done in the labs of biophysicist Watt Webb and engineer Harold Craighead, both at Cornell University. The previous year, the two had collaborated to <a href=\"https://www.science.org/doi/10.1126/science.1079700\">create</a> zero-mode waveguides (ZMWs): small containers just big enough to hold a single DNA polymerase and containing tiny holes at the bottom through which light could be detected. They were able to fix a DNA polymerase to the bottom of a ZMW and detect the incorporation of individual fluorescent &#8220;C&#8221; nucleotides through the holes, which fed into a microscope capable of detecting light emissions.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!zoUV!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c1783bb-adc3-4de4-9981-5470d8671231_1561x1380.jpeg\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"1287\" src=\"https://substackcdn.com/image/fetch/$s_!zoUV!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c1783bb-adc3-4de4-9981-5470d8671231_1561x1380.jpeg\" width=\"1456\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a><figcaption class=\"image-caption\">A PacBio RSII machine, ca. 2013. Credit: <a href=\"https://commons.wikimedia.org/wiki/File:PacBio_RSII.jpg\">Konrad F&#246;rstner</a></figcaption></figure></div><p>In 2009, PacBio published a <a href=\"https://www.science.org/doi/10.1126/science.1162986\">paper</a> expanding the principle into a full-blown sequencing technique. Once again, each nucleotide was labeled with a different colored fluorophore detectable by the ZMW to determine which base had been incorporated. The fluorophores were attached such that they would be cleaved off during the chemical reaction incorporating the base into the growing DNA strand; they would then diffuse out of the ZMW so that the next fluorophore could be detected. Sequencing took place on a chip with many wells simultaneously &#8212; a different type of parallelization where each well detected a single DNA molecule undergoing the same basic chemical reaction.</p><p>The next year, PacBio <a href=\"https://academic.oup.com/nar/article/38/15/e159/2409757\">developed</a> a new method to allow multiple sequencing passes on the same DNA molecule. Double stranded DNA templates were ligated to two single stranded adapters, creating what the company called a &#8220;SMRTbell template.&#8221; Sequencing began at a primer on one of the adaptors and could proceed multiple times per molecule due to circularization, in a process called rolling-circle amplification. This helped reduce PacBio&#8217;s error rates significantly.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!uFPn!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F41152f3f-c259-410e-9e23-7f66cd9096c6_1800x1540.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"1246\" src=\"https://substackcdn.com/image/fetch/$s_!uFPn!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F41152f3f-c259-410e-9e23-7f66cd9096c6_1800x1540.png\" width=\"1456\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p>With its core technology in place, PacBio was ready to go commercial. In 2011, the company <a href=\"https://www.pacb.com/press_releases/pacific-biosciences-begins-shipments-of-commercial-pacbio-rs-systems/\">released</a> the RS sequencing machine, and has since created <a href=\"https://www.pacb.com/technology/hifi-sequencing/sequel-system/previous-system-releases/\">multiple new machines</a> containing chips with increased numbers of sequencing wells. PacBio calls the technique single molecule real time (SMRT) sequencing, though it&#8217;s colloquially referred to simply as PacBio sequencing. Rather than producing short overlapping reads like Illumina, PacBio generates very long reads; at first these were a few thousand bases, but today they can be <a href=\"https://www.pacb.com/blog/long-read-sequencing/#:~:text=Long%2Dread%20sequencing%20uses%20DNA%20(or%20RNA)%20fragments%20ranging%20in%20size%20from%201%2C000%20to%2020%2C000%20bases%20or%20more.\">well over 10,000</a>.</p><p>PacBio&#8217;s ability to produce extremely long reads makes it a useful complement to Illumina. Indeed, PacBio machines are better at <a href=\"https://www.sciencedirect.com/science/article/pii/S1672022915001345#s0015:~:text=%2C%20%5B23%5D-,Applications%20to%20genome%20research,-De%20novo%20assembly\">sequencing</a> &#8220;confusing&#8221; genomes, such as those with many copies of the same gene, long stretches of repetitive motifs, and &#8220;structural variations&#8221; like large insertions or deletions, which may not show up in short-read sequences. For instance, PacBio was used to <a href=\"https://link.springer.com/article/10.1186/1754-6834-7-40\">sequence</a> a very difficult bacterium called <em>Clostridium autoethanogenum</em>, which contains repeats, nine copies of a single gene, and insertions from bacterial virus genomes &#8212; basically the genomic equivalent of a Thomas Pynchon novel.</p><h2>Nanopore Sequencing</h2><p><a href=\"https://press.asimov.com/articles/nanopores\">Nanopore</a> is the most recently commercialized major sequencing method, collectively developed by several groups starting in the 1990s. A nanopore is a protein or lipid with a small hole in its center through which other materials, such as DNA, can pass. The first nanopore used for sequencing was &#9082;-hemolysin, a protein toxin from the bacterium <em>Staphylococcus aureus</em>, though other <a href=\"https://www.pnas.org/doi/full/10.1073/pnas.0807514106\">biological</a> and <a href=\"https://pubs.acs.org/doi/10.1021/nl051199m\">synthetic</a> nanopores have since been tested.</p><p>In 1996, David Deamer and Daniel Branton&#8217;s labs at UC Santa Cruz and Harvard collaborated on a <a href=\"https://www.pnas.org/doi/10.1073/pnas.93.24.13770\">paper</a> showing that when an electric current runs through a nanopore, passing purine (A and G) and pyrimidine (T and C) DNA bases through the nanopore disrupted the current to different degrees. While the technique couldn&#8217;t yet discriminate between all four bases, the general idea for a new single-molecule sequencing method was there.</p><p>In 2001, Hagan Bayley&#8217;s lab at Texas A&amp;M <a href=\"https://www.nature.com/articles/nbt0701_636\">demonstrated</a> a limited sequencing method based on the observation that correctly and incorrectly paired DNA bases disrupted nanopore current to different extents. They tethered a short piece of DNA with a few unknown bases to the entrance of the nanopore, then added other short DNA strands with different bases at the position corresponding to the unknown base on the tethered strand. By looking at which base produced the disruption corresponding to a perfect match, they could guess the unknown nucleotide.</p><p>In order to directly assess DNA strands going through the nanopore, two major problems needed solving. The first was that DNA moved too fast to reliably detect; the second was that individual bases still could not be differentiated, just purines and pyrimidines. In 2005, Bayley (who by then had moved to Oxford) made progress on the first issue, working with scientists at the Scripps Institute to <a href=\"https://onlinelibrary.wiley.com/doi/10.1002/anie.200462114\">slow</a> the template DNA down by adding short &#8220;hairpin&#8221; structures that partially blocked off the pore. That year, Bayley co-founded Oxford Nanopore Technologies (ONT) to develop the emerging sequencing method. ONT quickly brought together <a href=\"https://nanoporetech.com/about/history\">various technologies</a>, licensing IP from the labs of Bayley, Deamer, Branton, and others.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!UhH7!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff8c6cb57-74ff-4286-b09f-055b7c43ff9c_685x502.avif\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"502\" src=\"https://substackcdn.com/image/fetch/$s_!UhH7!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff8c6cb57-74ff-4286-b09f-055b7c43ff9c_685x502.avif\" width=\"685\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a><figcaption class=\"image-caption\">Deamer&#8217;s original nanopore sketch, ca. 1989. <em>Credit: <a href=\"https://nanoporetech.com/about-us/history\">Oxford Nanopore</a></em></figcaption></figure></div><p>In 2010, ONT <a href=\"https://nanoporetech.com/about/history#:~:text=Around%202010%2C%20Oxford,with%20a%20nanopore.\">combined</a> two technologies addressing each of the main outstanding problems. The first was an <a href=\"https://www.nature.com/articles/nnano.2009.12\">engineered nanopore</a> developed in collaboration with Bayley&#8217;s lab that could discriminate between individual DNA bases, solving the resolution issue. The second was a trick to slow the DNA down to detectable speeds, using the familiar DNA polymerase enzyme. Mark Akeson&#8217;s lab at UC Santa Cruz had identified a <a href=\"https://pubs.acs.org/doi/full/10.1021/ja1087612\">specific polymerase</a> from the bacterial virus &#632;29 that replicated DNA at an ideal speed for detection via nanopore. Template DNA strands were replicated just before entering the nanopore, passing through slowly enough for individual bases&#8217; effect on the electrical current to be detectable and allowing the DNA sequence to be read one base at a time.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!v4VJ!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F25704bd4-cf4a-4668-9cbc-5a23f6e57707_1802x1100.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"889\" src=\"https://substackcdn.com/image/fetch/$s_!v4VJ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F25704bd4-cf4a-4668-9cbc-5a23f6e57707_1802x1100.png\" width=\"1456\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p>By 2012, ONT had <a href=\"https://www.nature.com/articles/nbt0412-295\">unveiled</a> its first sequencing data, and Nanopore sequencing quickly established itself as a quick method for generating long reads without DNA synthesis, albeit with a <a href=\"https://www.accurascience.com/blogs_3_0.html\">higher error rate</a> than some earlier methods. (Nanopore reads had an accuracy of about 85-90 percent per base <a href=\"https://link.springer.com/article/10.1186/s13059-018-1462-9#:~:text=A%20major%20limitation%20of%20MinION%20sequencing%20is%20its%20lower%20read%20accuracy%20when%20compared%20with%20short%2Dread%20technologies.%20When%20the%20MinION%20was%20first%20introduced%2C%20reads%20showed%20an%20accuracy%20of%20less%20than%2060%25%20%5B9%2C%2010%5D.%20This%20accuracy%20has%20improved%20over%20recent%20years%20to%20reach%20approximately%2085%25\">in 2017</a>, compared to over 99 percent for Illumina. Recent improvements, though, have boosted this accuracy to <a href=\"https://nanoporetech.com/platform/accuracy\">more than 99 percent</a> for most applications.)</p><p>ONT released its first commercial product in 2015: a handheld machine called the MinION that <a href=\"https://nanoporetech.com/news/news-human-genome-minion#:~:text=A%20MinION%20starter%20pack%20costs%20%241%2C000%20and%20includes%20the%20MinION%2C%20two%20flow%20cells%2C%20kits%20and%20community%20support.\">retailed for just $1000</a>, a fraction of the price of most sequencers. Subsequent releases include more traditional benchtop sequencers such as the <a href=\"https://nanoporetech.com/products/sequence/promethion\">PromethION</a> and <a href=\"https://nanoporetech.com/products/sequence/gridion\">GridION</a>.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!S82c!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F77aa6af5-3436-48d1-b897-0c120be677ea_1600x900.jpeg\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"819\" src=\"https://substackcdn.com/image/fetch/$s_!S82c!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F77aa6af5-3436-48d1-b897-0c120be677ea_1600x900.jpeg\" width=\"1456\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a><figcaption class=\"image-caption\">The MinION Nanopore. Credit: <a href=\"https://nanoporetech.com/resource-centre/direct-sequencing-rna-minion-nanopore-detecting-mutations-based-associations\">Oxford Nanopore</a></figcaption></figure></div><h2>Conclusion</h2><p>In its early days, sequencing was a laborious (and literally radioactive) biochemical process. Today, sequencing machines are ubiquitous, safe, and much less labor-intensive. This evolution was enabled not just by advances in biochemistry but insights from biophysics and materials science, as well as manufacturing ingenuity that turned lab sequencing setups into machines ready for shipping to customers.<br /><br />Ultimately, DNA sequencing technology extends beyond these five techniques, but they represent the most transformative and widely adopted methods of the past fifty years. Together, they have enabled physicians to identify disease-causing variants in patients, allowed researchers to sequence entire <a href=\"https://www.annualreviews.org/content/journals/10.1146/annurev-micro-012520-072314\">microbial communities</a> from ocean water or human guts, and opened windows into deep time by recovering genomes from <a href=\"https://www.science.org/doi/10.1126/science.adi1768\">Neanderthals</a> and <a href=\"https://www.nature.com/articles/s41586-023-06705-1\">early</a> humans.</p><p>New sequencing methodologies are still under development, too. In 2025, Roche <a href=\"https://sequencing.roche.com/global/en/article-listing/sequencing-platform-technologies.html\">announced</a> a new single-molecule technique called <a href=\"https://www.biorxiv.org/content/10.1101/2025.02.19.639056v2\">Sequencing by Expansion</a>, which inserts large engineered molecules called &#8216;<a href=\"https://www.youtube.com/watch?v=G8ECt04qPos\">Xpandomers</a>&#8217; between nucleotides for more accurate detection via nanopore. Both new techniques and refinements to existing methods are aimed at further decreasing the cost of sequencing, with some groups looking to read an entire human genome for <a href=\"https://frontlinegenomics.com/the-100-genome-wheres-the-limit/\">$100 or less</a>. Ultima Genomics <a href=\"https://techcrunch.com/2022/05/31/ultima-genomics-claims-100-full-genome-sequencing-after-stealth-600m-raise/\">met this target</a> with its UG100 sequencing machine, unveiled in 2022 and shipped in 2024. Element Biosciences&#8217; VITARI system, <a href=\"https://www.sandiegouniontribune.com/2026/02/19/scrappy-san-diego-startup-goes-toe-to-toe-with-gene-sequencing-giant-illumina/\">announced in February</a> and expected to ship in the second half of 2026,  achieved the same price point with a smaller device. The $100 price tag advertised by these companies includes only the consumables used by the machine itself, excluding <a href=\"https://www.genome.gov/about-genomics/fact-sheets/DNA-Sequencing-Costs-Data#:~:text=Key%20Considerations-,Cost%20Categories,-The%20expenditures%20included\">labor, data analysis</a>, and <a href=\"https://link.springer.com/article/10.1186/gb-2011-12-8-125\">other costs</a>.</p><p>Anyone able to approach this target stands to benefit tremendously, given the obvious demand for DNA sequencing. For example, recent years have seen the proliferation of  cohort studies focused on clinical analyses of whole-genome sequencing data. These include the <a href=\"https://elite.stanford.edu/about/#:~:text=With%20the%20help,a%20saliva%20sample.\">Stanford ELITE study</a>, which is focused on identifying genetic determinants of aerobic capacity, and the NIH&#8217;s <a href=\"https://allofus.nih.gov/\">All of Us</a> Research Program, which has sequenced <a href=\"https://www.nature.com/articles/s41586-023-06957-x\">well over 200,000 genomes</a> in order to study genetic diseases.</p><p>Innovation in DNA sequencing will surely continue, but these five techniques have already transformed a feat that was impossible just fifty years ago into something that can be done overnight.</p><p><strong>Correction: </strong>An earlier version of this article incorrectly claimed that Frederick Sanger is the only individual to receive two Nobel Prizes in the same field. We apologize for the error.</p><div><hr /></div><p><strong>Evan DeTurk</strong> is an MPhil student at Cambridge in the history of science. He writes about biology and its history on <a href=\"https://substack.com/@scifinow\">Substack</a>. Previously, Evan researched genome editing at UC Berkeley and earned an A.B. in Molecular Biology from Princeton.</p><p>Schematics created by Ella Watkins-Dulaney.</p><p><strong>Cite: </strong>DeTurk, E. &#8220;A Visual Guide to DNA Sequencing.&#8221; <em>Asimov Press </em>(2026). DOI: 10.62211/58ew-79yt</p><div class=\"footnote\"><a class=\"footnote-number\" contenteditable=\"false\" href=\"https://www.asimov.press/feed#footnote-anchor-1\" id=\"footnote-1\" target=\"_self\">1</a><div class=\"footnote-content\"><p>While both projects sequenced DNA from multiple anonymous donors, Celera had mostly used <a href=\"https://www.technologyreview.com/2007/09/04/223919/craig-venters-genome/\">Venter&#8217;s own DNA</a>.</p></div></div><div class=\"footnote\"><a class=\"footnote-number\" contenteditable=\"false\" href=\"https://www.asimov.press/feed#footnote-anchor-2\" id=\"footnote-2\" target=\"_self\">2</a><div class=\"footnote-content\"><p>The human genome is three billion base pairs long but producing a correct sequence requires sequencing the whole thing many times over and computationally assembling all of those reads. For this reason, sequencing a human genome is much more expensive than sequencing three thousand megabases of raw DNA.</p></div></div><div class=\"footnote\"><a class=\"footnote-number\" contenteditable=\"false\" href=\"https://www.asimov.press/feed#footnote-anchor-3\" id=\"footnote-3\" target=\"_self\">3</a><div class=\"footnote-content\"><p>Holley&#8217;s method was distinct from Sanger&#8217;s. He began by isolating the alanine tRNA molecules and then cutting them into shorter pieces of unequal lengths, using enzymes. Then, he separated each fragment by size using column chromatography and ran various chemical techniques to figure out the sequence of each piece. Finally, he &#8220;aligned&#8221; these fragments by finding overlaps between them, thus reconstructing the full, 77-nucleotide strand.</p></div></div><div class=\"footnote\"><a class=\"footnote-number\" contenteditable=\"false\" href=\"https://www.asimov.press/feed#footnote-anchor-4\" id=\"footnote-4\" target=\"_self\">4</a><div class=\"footnote-content\"><p>At least, up until the maximum length created by the first DNA polymerase reaction.</p></div></div><div class=\"footnote\"><a class=\"footnote-number\" contenteditable=\"false\" href=\"https://www.asimov.press/feed#footnote-anchor-5\" id=\"footnote-5\" target=\"_self\">5</a><div class=\"footnote-content\"><p>DNA polymerase adds a nucleotide triphosphate to the growing DNA strand by promoting a cleavage between the phosphates. One of the three phosphates becomes part of the DNA backbone, and the other two are released as PPi.</p></div></div><div class=\"footnote\"><a class=\"footnote-number\" contenteditable=\"false\" href=\"https://www.asimov.press/feed#footnote-anchor-6\" id=\"footnote-6\" target=\"_self\">6</a><div class=\"footnote-content\"><p>Firefly luciferase is the enzyme found in the firefly abdomen that gives them their characteristic glow. It&#8217;s a common reporter in molecular biology because of its immediate read out and ease of detection.</p></div></div><div class=\"footnote\"><a class=\"footnote-number\" contenteditable=\"false\" href=\"https://www.asimov.press/feed#footnote-anchor-7\" id=\"footnote-7\" target=\"_self\">7</a><div class=\"footnote-content\"><p>The signal to noise ratio is the amount of an observed effect due to the intended process compared to other &#8220;background noise&#8221;. In this case, light resulting from nucleotide addition versus other chemical reactions. Luciferase recognizes and acts on dATP in solution, creating a spurious signal unrelated to nucleotide addition, which must be accounted for during analysis. Fortunately, the modified &#8220;A&#8221; nucleotide effectively suppresses this side reaction, improving the signal to noise ratio.</p></div></div>"
            ],
            "link": "https://www.asimov.press/p/dna-sequencing",
            "publishedAt": "2026-02-26",
            "source": "Asimov Press",
            "summary": "<div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!ezte!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F69bb038e-36d7-4ac7-9543-1567b44b3a43_1714x1080.gif\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"917\" src=\"https://substackcdn.com/image/fetch/$s_!ezte!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F69bb038e-36d7-4ac7-9543-1567b44b3a43_1714x1080.gif\" width=\"1456\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a><figcaption class=\"image-caption\">Ella Watkins-Dulaney for Asimov Press.</figcaption></figure></div><p>When the Human Genome Project (HGP) released its initial draft sequence in 2001, President Bill Clinton <a href=\"https://clintonwhitehouse3.archives.gov/WH/EOP/OSTP/html/00628_2.html#:~:text=Without%20a%20doubt%2C%20this%20is%20the%20most%20important%2C%20most%20wondrous%20map%20ever%20produced%20by%20humankind.\">hailed</a> it as &#8220;the most wondrous map ever produced by mankind.&#8221; After more than ten years of work, an <a href=\"https://www.genome.gov/about-genomics/educational-resources/fact-sheets/human-genome-project#:~:text=The%20initially%20projected%20cost%20for%20the%20Human%20Genome%20Project%20was%20%243%20billion%2C%20based%20on%20its%20envisioned%20length%20of%2015%20years.%20While%20precise%20cost%2Daccounting%20was%20difficult%20to%20carry%20out%2C%20especially%20across%20the%20set%20of%20international%20funders%2C%20most%20agree%20that%20this%20rough%20amount%20is%20close%20to%20the%20accurate%20number.\">estimated $3 billion</a> in research costs, and a &#8220;<a href=\"https://www.kirkusreviews.com/book-reviews/james-shreeve/the-genome-war/\">genome war</a>&#8221; with Craig Venter&#8217;s private company, Celera Genomics, the project had produced a nearly complete sequence of a human genome.<a class=\"footnote-anchor\" href=\"https://www.asimov.press/feed#footnote-1\" id=\"footnote-anchor-1\" target=\"_self\">1</a></p><p>UK Prime Minister Tony Blair <a href=\"https://www.genome.gov/10001356/june-2000-white-house-event#:~:text=a%20revolution%20in%20medical%20science%20whose%20implications%20far%20surpass%20even%20the%20discovery%20of%20antibiotics\">predicted</a> that this map would",
            "title": "A Visual Guide to DNA Sequencing"
        },
        {
            "content": [
                "<p>Monday.com just launched their fastest product to <strong>$1M ARR.</strong></p>\n\n<p>And it just took them <strong>2.5 months.</strong></p>\n\n<p>The kicker is that the product actually doesn\u2019t <em>do</em> anything by itself \u2013 it just lets customers <em>vibe code</em> whatever they want on top of Monday\u2019s platform.</p>\n\n<p>From all the disdain we\u2019re seeing about vibe coding lately, it\u2019s astonishing what this one company has accomplished in such a short time.</p>\n\n<figure class=\"img-medium\">\n  <img src=\"https://nmn.gl/blog/assets/monday-vibe-launch.png\" />\n</figure>\n\n<p>Three weeks ago, I wrote about how <a href=\"https://nmn.gl/blog/ai-killing-b2b-saas\">AI is killing B2B SaaS</a>. Stocks were (and still are) down 30%. The thesis was simple: customers can vibe code alternatives themselves, so why pay for inflexible SaaS?</p>\n\n<p>Turns out, Monday.com figured out the answer. And it\u2019s not what you\u2019d expect.</p>\n\n<!--more-->\n\n<h2 id=\"the-anti-product-product\">The Anti-Product Product</h2>\n\n<p>While every other SaaS company is panic-adding AI features to their roadmap, Monday.com did something different. They built a vibe coding layer on top of their existing platform and called it a product.</p>\n\n<p>And they got <strong>$1M ARR in 2.5 months</strong>\u2026 Their fastest launch ever.<sup id=\"fnref:1\"><a class=\"footnote\" href=\"https://nmn.gl/blog/vibe-coding-future-b2b-saas#fn:1\" rel=\"footnote\">1</a></sup></p>\n\n<p>Let that sink in for a moment.</p>\n\n<p>Product teams at most SaaS companies spend 6 months debating what features to build. Monday.com just gave users AI tools and said \u201cyou figure it out.\u201d</p>\n\n<p>And customers are <em>eating it up</em>.</p>\n\n<p>They\u2019re building custom CRMs, project trackers, inventory systems, HR tools \u2013 things that would normally take quarters on an engineering roadmap. Now they\u2019re shipping in days.</p>\n\n<figure class=\"img-medium\">\n  <img src=\"https://nmn.gl/blog/assets/monday-vibe-examples.png\" />\n</figure>\n\n<h2 id=\"why-this-works\">Why This Works</h2>\n\n<p>Here\u2019s what Monday.com understood that everyone else missed: the future of SaaS isn\u2019t better features.</p>\n\n<p>It\u2019s giving customers a vibe coding layer to build their own damn features.</p>\n\n<p>There\u2019s a quote I love from a SAP professor on HN:<sup id=\"fnref:2\"><a class=\"footnote\" href=\"https://nmn.gl/blog/vibe-coding-future-b2b-saas#fn:2\" rel=\"footnote\">2</a></sup></p>\n\n<blockquote>\n  <p>\u201cI teach that <strong>changing the business to fit SAP is preferable to changing SAP to fit the business.</strong> And it\u2019s accurate advice. It shouldn\u2019t be, but it is. SAP is SAP. It doesn\u2019t care about your USP. Or your custom approach to business.\u201d</p>\n</blockquote>\n\n<p>This is called \u201cFit-to-Standard\u201d in business-speak. There\u2019s an entire industry of consultants who charge hundreds of thousands of dollars to teach companies how to change the way they work to match their ERP.</p>\n\n<p>It\u2019s completely absurd when you say it out loud. But it\u2019s also how B2B SaaS has made billions for decades.</p>\n\n<p>Monday.com flipped it: Instead of making customers fit their business to the software, they\u2019re letting customers build software that fits their business.</p>\n\n<h2 id=\"moats-in-the-age-of-ai\">Moats in the age of AI</h2>\n\n<p>In my previous article, I talked about <a href=\"https://nmn.gl/blog/ai-killing-b2b-saas\">three survival strategies for SaaS companies</a>. Being a System of Record was #1. But I missed something crucial.</p>\n\n<p>The new moat isn\u2019t just <em>being</em> a System of Record.</p>\n\n<p>It\u2019s being a System of Record that customers can <em>build on top of</em>.</p>\n\n<p>Think about it: when your customer\u2019s finance team spends three days vibe coding a custom commission calculator on your platform, what happens?</p>\n\n<p>They\u2019re now locked in: Not because of contract terms or switching costs, but because they built something that works <em>exactly</em> how they want it to work.</p>\n\n<p>And when renewal time comes, the question changes. Previously, they\u2019d ask \u201cshould we keep paying for this SaaS?\u201d Now, they have to evaluate if it\u2019s worth it to throw away all the custom tools they\u2019ve built on top.</p>\n\n<p>The answer is always <em>no.</em></p>\n\n<h2 id=\"solving-the-churn-problem\">Solving the Churn Problem</h2>\n\n<p>I\u2019ve talked to hundreds of founders in SF in the last year. The #1 fear keeping B2B SaaS executives up at night is churn.</p>\n\n<p>In my previous article, I shared the story of a Series E CEO who canceled a $30,000/year engineering productivity tool because they rebuilt it themselves using Github and Notion APIs.</p>\n\n<p>But here\u2019s the thing: that CEO wasn\u2019t happy about rebuilding it. It was a pain. They had to wrangle with APIs, deal with authentication, worry about security. They did it because their SaaS vendor wouldn\u2019t build what they actually needed.</p>\n\n<p>What if that SaaS vendor had given them a vibe coding layer instead? The CEO could have built exactly what they wanted <em>on top of the existing platform</em>. The SaaS company keeps the $30k/year. The customer gets what they need. Everyone wins.</p>\n\n<p>This is exactly what\u2019s happening with Monday.com\u2019s customers. They\u2019re not leaving to build alternatives. They\u2019re staying and building <em>on top of</em> Monday.</p>\n\n<h2 id=\"the-data-doesnt-lie\">The Data Doesn\u2019t Lie</h2>\n\n<p>One of my customers is a Series B maintenance operations SaaS. Their software wasn\u2019t being used at the technician level because the UI was too complex for field workers.</p>\n\n<p>Usage was under 35%.</p>\n\n<p>We built a <a href=\"https://gigacatalyst.com/\">whitelabeled vibe coding layer on top of their platform</a>. Their customer success teams vibe coded a mobile webapp specifically for technicians \u2013 just the parts they needed to create maintenance work orders, just in a few days.</p>\n\n<p><strong>Usage is now over 70%.</strong></p>\n\n<p>The technicians get a simple interface. The executives get custom reports exactly how they want them. The SaaS company keeps their customers <em>and</em> expands usage.</p>\n\n<p>This is key: when customers are building on your platform, they\u2019re not evaluating your competitors.</p>\n\n<h2 id=\"but-what-about-engineers\">But What About Engineers?</h2>\n\n<p>I can already hear the objections. \u201cWhat about code quality? Security? Technical debt?\u201d</p>\n\n<p>Fair questions. But if you think about it, you\u2019re not replacing your engineering team. You\u2019re giving them superpowers.</p>\n\n<p>Yes, your AI coding tools like Claude Code and Cursor make engineers 10x faster. That\u2019s great for the core product and roadmap.</p>\n\n<p>But what about the long tail of customer requests? The specific workflow that only one customer needs? The custom report that would take a week to build and maintain?</p>\n\n<p>That\u2019s where vibe coding shines. The genius is that you let your <em>customers</em> or <em>customer-facing teams</em> vibe code.</p>\n\n<p>Those are the people that understand the business domain and problems. They <em>know</em> what\u2019s needed.</p>\n\n<p>And now, like magic, they can build it without waiting months on an engineering roadmap.</p>\n\n<p>Your engineers stay focused on the core platform \u2013 the System of Record, the security, the robustness, the things that actually require engineering expertise.<sup id=\"fnref:3\"><a class=\"footnote\" href=\"https://nmn.gl/blog/vibe-coding-future-b2b-saas#fn:3\" rel=\"footnote\">3</a></sup></p>\n\n<h2 id=\"the-future-is-platform-not-product\">The Future is Platform, Not Product</h2>\n\n<p>Monday.com proved it. Their fastest product ever. And it\u2019s a vibe coding layer, despite all the hate vibe coding gets.</p>\n\n<p>The irony isn\u2019t lost on me: I\u2019m building a <a href=\"\">whitelabel vibe coding platform</a> for SaaS companies while watching traditional SaaS companies panic about vibe coding killing them.</p>\n\n<p>But that\u2019s exactly the point. The threat isn\u2019t vibe coding itself. It\u2019s where the vibe coding happens.</p>\n\n<p>Right now, somewhere, a customer is vibe coding a replacement for your SaaS. They\u2019re frustrated with inflexibility and tired of waiting for features.</p>\n\n<p>The question isn\u2019t <em>whether</em> they\u2019ll vibe code (they already are.)</p>\n\n<p>The question is: will they build on your platform, or without you?</p>\n\n<p>Monday.com chose to give their customers the tools and the $1M ARR is proof it works. Your competitors are reading this same article, some of them are already reaching out to me.</p>\n\n<p>The survivors won\u2019t be the SaaS companies with the best features. They\u2019ll be the ones who became platforms before their customers left to build alternatives.</p>\n\n<hr />\n\n<p>Thanks for reading this far! I\u2019m Namanyay and I\u2019m <strong>solving exactly this problem with a  <a href=\"\">whitelabelled AI platform for B2B SaaS companies</a></strong>, so your users can vibe code customized workflows on top of their existing system of record.</p>\n\n<p>My customers tell me this is the <strong>best way to get sales and retention</strong> in 2026. If this sounds interesting to you or someone you know, <a href=\"\">I can reach out with a demo</a> or you can <a href=\"https://gigamind.dev/catalyst\" target=\"_blank\">learn more about Giga Catalyst</a>.</p>\n\n<hr />\n\n<div class=\"footnotes\">\n  <ol>\n    <li id=\"fn:1\">\n      <p>Amichay, the product leader who built Monday vibe talks about this <a href=\"https://www.linkedin.com/posts/amichayevenchen_monday-vibe-is-the-fastest-product-to-surpass-activity-7426622783679287297-Zd3F/\">on his LinkedIn post</a>\u00a0<a class=\"reversefootnote\" href=\"https://nmn.gl/blog/vibe-coding-future-b2b-saas#fnref:1\">&#8617;</a></p>\n    </li>\n    <li id=\"fn:2\">\n      <p>Thanks to <a href=\"https://news.ycombinator.com/item?id=22246417\">mr_gibbins on HN</a>. The phrase \u201cResistance is futile\u201d about enterprise software is just <em>chef\u2019s kiss</em>.\u00a0<a class=\"reversefootnote\" href=\"https://nmn.gl/blog/vibe-coding-future-b2b-saas#fnref:2\">&#8617;</a></p>\n    </li>\n    <li id=\"fn:3\">\n      <p>Although honestly, I\u2019ve seen finance teams accidentally create public S3 buckets with unencrypted data, so maybe we need guardrails. Which is exactly what a proper vibe coding platform like mine provides.\u00a0<a class=\"reversefootnote\" href=\"https://nmn.gl/blog/vibe-coding-future-b2b-saas#fnref:3\">&#8617;</a></p>\n    </li>\n  </ol>\n</div>"
            ],
            "link": "https://nmn.gl/blog/vibe-coding-future-b2b-saas",
            "publishedAt": "2026-02-26",
            "source": "Namanyay Goel",
            "summary": "Monday.com just launched their fastest product to $1M ARR. And it just took them 2.5 months. The kicker is that the product actually doesn\u2019t do anything by itself \u2013 it just lets customers vibe code whatever they want on top of Monday\u2019s platform. From all the disdain we\u2019re seeing about vibe coding lately, it\u2019s astonishing what this one company has accomplished in such a short time. Three weeks ago, I wrote about how AI is killing B2B SaaS. Stocks were (and still are) down 30%. The thesis was simple: customers can vibe code alternatives themselves, so why pay for inflexible SaaS? Turns out, Monday.com figured out the answer. And it\u2019s not what you\u2019d expect.",
            "title": "Vibe Coding is the Future of B2B SaaS"
        },
        {
            "content": [
                "<p><strong>I.</strong></p><p>In <em>The Argument</em>, <a href=\"https://www.theargumentmag.com/p/when-technically-true-becomes-actually\">Kelsey Piper gives a good description</a> of the ways that AIs are more than just &#8220;next-token predictors&#8221; or &#8220;stochastic parrots&#8221; - for example, they also use fine-tuning and RLHF. But commenters, while appreciating the subtleties she introduces, object that they&#8217;re still just extra layers on top of a machine that <em>basically</em> runs on next-token prediction.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2\" href=\"https://substackcdn.com/image/fetch/$s_!NY0t!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F436e25d1-fd45-4a6c-ad41-a4df08724ba0_627x124.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"124\" src=\"https://substackcdn.com/image/fetch/$s_!NY0t!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F436e25d1-fd45-4a6c-ad41-a4df08724ba0_627x124.png\" width=\"627\" /><div></div></div></a></figure></div><p>I want to approach this from a different direction. I think overemphasizing next-token prediction is a confusion of levels. On the levels where AI is a next-token predictor, you are also a next-token (technically: next-sense-datum) predictor. On the levels where you&#8217;re not a next-token predictor, AI isn&#8217;t one either. </p><p>Putting all the levels in graphic form:</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!3cIw!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6a046e04-441e-4153-b755-557f8a9f8626_546x711.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"617.2417582417582\" src=\"https://substackcdn.com/image/fetch/$s_!3cIw!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6a046e04-441e-4153-b755-557f8a9f8626_546x711.png\" width=\"474\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p><strong>II.</strong></p><p>The human brain was designed by a series of nested optimization loops. The outermost loop is evolution, which optimized the human genome for being good at survival, sex, reproduction, and child-rearing. </p><p>But evolution can&#8217;t encode everything important in the genome. It obviously can&#8217;t include individual and cultural features like the vocabulary of your native language, or your particular mother&#8217;s face. But even a lot of things that could be in there in theory, like how to walk, or which animals are most nutritious, are missing - the genome is too small for it to be worth it.  Instead, evolution gives us algorithms that let us learn from experience. </p><p>These algorithms are a second optimization loop, &#8220;evolving&#8221; neuron patterns into forms that better promote fitness, reproduction, etc. The most powerful such algorithm is called <a href=\"https://slatestarcodex.com/2017/09/05/book-review-surfing-uncertainty/\">predictive coding</a>, which neuroscience increasingly considers a key organizing principle of the brain. <a href=\"https://en.wikipedia.org/wiki/Predictive_coding\">Wikipedia describes it as</a>:</p><blockquote><p>In neuroscience, <strong>predictive coding</strong> (also known as predictive processing) is a theory of brain function which postulates that the brain is constantly generating and updating a &#8220;mental model&#8221; of the environment. According to the theory, such a mental model <strong>is used to predict input signals from the senses</strong> that are then compared with the actual input signals from those senses.</p></blockquote><p>In other words, the brain organizes itself/learns things by constantly trying to predict the next sense-datum, then updating synaptic weights towards whatever form would have predicted the next sense-datum most efficiently. This is a very close (not exact) analogue to the next-token prediction of AI.</p><p>This process organizes the brain into a form capable of predicting sense-data, called a &#8220;world-model&#8221;. For example, if you encounter a tiger, the best way of predicting the resulting sense-data (the appearance of the tiger pouncing, the sound of the tiger&#8217;s roar, the burst of pain at the tiger&#8217;s jaws closing around your arm) is to know things about tigers. On the highest and most abstract levels, these are things like &#8220;tigers are orange&#8221;, &#8220;tigers often pounce&#8221;, and &#8220;tigers like to bite people&#8221;. On lower levels, they involve the ability to translate high-level facts like &#8220;tigers often pounce&#8221; into a probabilistic prediction of the tiger&#8217;s exact trajectory. All of this is done via neural circuits we don&#8217;t entirely understand, and implemented through the usual neuroscience stuff like synapses and neurotransmitters. To you it just feels like &#8220;IDK, I thought about it and realized the tiger would pounce over there.&#8221;</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!drH-!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4043e11c-d3c5-4358-9cc3-0d93ed30aa9a_735x588.jpeg\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"Tiger Pounce in Lush Green Field\" class=\"sizing-normal\" height=\"392\" src=\"https://substackcdn.com/image/fetch/$s_!drH-!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4043e11c-d3c5-4358-9cc3-0d93ed30aa9a_735x588.jpeg\" title=\"Tiger Pounce in Lush Green Field\" width=\"490\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p><strong>III.</strong></p><p>The AIs&#8217; equivalent of evolution is the AI companies designing them. Just like evolution, the AI companies realized that it was inefficient to hand-code everything the AIs needed to know (&#8220;giant lookup table&#8221;) and instead gave the AIs learning algorithms (&#8220;deep learning&#8221;). As with humans, the most powerful of these learning algorithms was next-token prediction. This algorithm feeds the AI a stream of tokens, then updates the AI&#8217;s innards into a form that would have predicted the next token efficiently.</p><p>But this doesn&#8217;t mean the AI&#8217;s innards look like &#8220;Hmmmm, what will the next token be?&#8221; The AI certainly isn&#8217;t answering your math question by thinking something like &#8220;Hmmmm, she used the number three, which has the tokens <em>th</em> and <em>ree</em>, and I know that there&#8217;s a 8.2% chance that <em>ree</em> is often seen somewhere around the token <em>ix</em>, so the answer must be six!&#8221; How would that even work?</p><p>Instead, consider your own evolution. On the outermost level, humans were designed by a process optimizing for survival, sex, and reproduction. The humans that survived were those that had sex and reproduced. Everything about humans is downstream of what helped with sex and reproduction. But that doesn&#8217;t mean that any particular thought that you think involves reproduction or sex. If you&#8217;re doing a math problem, you won&#8217;t think &#8220;Hmmmm, how can I have sex with the number three?&#8221; You&#8217;re not even thinking &#8220;In order to reproduce I need to survive, to survive I need money, to get money I need a good job, to get a good job I good grades, and to get good grades I need to get the answer to this math problem - therefore the answer is seventy six!&#8221; You&#8217;re just doing good, normal, math. The evolutionary process that designed the learning algorithms that power your brain &#8220;was&#8221; &#8220;thinking&#8221; &#8220;about&#8221; survival and sex and reproduction, but you may never consider those things at all in the course of any given task.</p><p>(cf. <a href=\"https://www.lesswrong.com/posts/XPErvb8m9FapXCjhA/adaptation-executers-not-fitness-maximizers\">Organisms Are Adaptation-Executors, Not Fitness Maximizers</a>, which does a good job hammering in the point that we run algorithms designed by the evolutionary imperative to maximize survival and reproduction, rather than considering survival and reproduction explicitly in our decisions. When a monk decides to swear an oath of celibacy and never reproduce, he does so using a brain that was optimized to promote reproduction - just using it very far out of distribution, in an area where it no longer functions as intended.)</p><p>One level lower down, your brain was shaped by next-sense-datum prediction - partly you learned how to do addition because only the mechanism of addition correctly predicted the next word out of your teacher&#8217;s mouth when she said &#8220;three plus three is . . . &#8220; (it&#8217;s more complicated than this, sorry, but this oversimplification is basically true). But you don&#8217;t feel like you&#8217;re predicting anything when you&#8217;re doing a math problem. You&#8217;re just doing good, normal mathematical steps, like reciting &#8220;P.E.M.D.A.S.&#8221; to yourself and carrying the one.</p><p>In the same way, even though an AI was shaped by next-token prediction, the inside of its thoughts doesn&#8217;t look like next-token prediction. In the abstract, it probably looks like a world-model, the same as yours. In the concrete . . .</p><p>The science of figuring out what an AI&#8217;s innards are concretely doing is called <em>mechanistic interpretability</em>. It&#8217;s very hard to do - AI innards are notoriously confusing - and one team at Anthropic produces most of the headline results. Recently, <a href=\"https://transformer-circuits.pub/2025/linebreaks/index.html\">they explored how Claude predicts where a line break will be in a page of text</a>. Since line break is a token, this is literally a next-token prediction task.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!pogR!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F410e6887-f039-48e8-b7ec-059d35a20c72_993x660.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"660\" src=\"https://substackcdn.com/image/fetch/$s_!pogR!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F410e6887-f039-48e8-b7ec-059d35a20c72_993x660.png\" width=\"993\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p>The answer was: the AI represents various features of the line breaking process as one-dimensional helical manifolds in a six-dimensional space, then rotates the manifolds in some way that corresponds to multiplying or comparing the numbers that they&#8217;re representing. You don&#8217;t need to understand what this means, so I&#8217;ve relegated my half-hearted attempt to explain it to a footnote<a class=\"footnote-anchor\" href=\"https://www.astralcodexten.com/feed#footnote-1\" id=\"footnote-anchor-1\" target=\"_self\">1</a>. From our point of view, what&#8217;s important is that this doesn&#8217;t look like &#8220;LOL, it just sees that the last token was <em>ree</em> and there&#8217;s a 12.27% of a line break token following <em>ree</em>.&#8221; Next-token prediction created this system, but the system itself can involve arbitrary choices about how to represent and manipulate data.</p><p>Human neuron interpretability is even harder than AI neuron interpretability, but probably your thoughts involve something at least as weird as helical manifolds in 6D spaces. I searched the literature for the closest human equivalent to Claude&#8217;s weird helical manifolds, and was able to find one team talking about how the entorhinal cells in the hippocampus, which help you track locations in 2D space, use &#8220;high-dimensional toroidal attractor manifolds&#8221;. You never think about these, and if Claude is conscious, it doesn&#8217;t think about its helices either<a class=\"footnote-anchor\" href=\"https://www.astralcodexten.com/feed#footnote-2\" id=\"footnote-anchor-2\" target=\"_self\">2</a>. These are just the sorts of strange hacks that next-token/next-sense-datum prediction algorithms discover to encode complicated concepts onto physical computational substrate.</p><p><strong>IV.</strong></p><p>So my answer to the &#8220;just a next-token predictor&#8221; / &#8220;just a bag of words&#8221; / &#8220;just a stochastic parrot&#8221; literature is that this confuses levels of optimization. </p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!3cIw!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6a046e04-441e-4153-b755-557f8a9f8626_546x711.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"617.2417582417582\" src=\"https://substackcdn.com/image/fetch/$s_!3cIw!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6a046e04-441e-4153-b755-557f8a9f8626_546x711.png\" title=\"\" width=\"474\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p>The most compelling analogy: this is like expecting humans to be &#8220;just survival-and-reproduction machines&#8221; because survival and reproduction were the optimization criteria in our evolutionary history. There is, of course, some sense in which we <em>are</em> just survival-and-reproduction machines: we don&#8217;t have any faculties that can&#8217;t be explained through their effects on survival and reproduction. But this doesn&#8217;t mean we &#8220;don&#8217;t really think&#8221; or &#8220;don&#8217;t really understand&#8221; because we&#8217;re &#8220;really just trying to have sex&#8221; when we work on a math problem.</p><p>This simple analogy is slightly off, because it&#8217;s confusing two optimization levels: the outer optimization level (in humans, evolution optimizing for reproduction; in AIs, companies optimizing for profit) with the inner optimization level (in humans, next-sense-datum prediction; in AIs, next-token prediction). But the stochastic parrot people probably haven&#8217;t gotten to the point where they learn that humans are next sense-datum predictors, so the evolution/reproduction one above might make a better didactic tool.</p><p>Below these prediction algorithms optimizing for various things are all the structures, algorithms, world-models, and thought-processes they&#8217;ve created. In both humans and AIs, these look like good, normal thinking. You do math by remembering P.E.M.D.A.S and carrying the one. You deal with angry tigers by remembering principles like &#8220;tigers like to pounce&#8221; and &#8220;when an animal pounces, its actions will follow the laws of physics, which I intuitively approximate as X, Y, and Z&#8221;.</p><p>Below these intuitive processes are bizarre low-level algorithms involving helices and toroids. These are approximately equally creepy in humans and AIs, which makes sense, because they were designed by the same inhuman process (next-sense-datum / next-token prediction) and operate on similar materials (neural tissue, weights connected by parameters). </p><p>Nothing about any of these levels of explanations supports a contention like &#8220;Humans are doing REAL THOUGHT, but AIs are simply next-token predictors.&#8221; There will be some algorithmic differences, and some of those might be important, and we can talk about their implications, but they&#8217;re downstream of what specific prediction tasks each entity was trained on and what strengths and weaknesses their own &#8220;evolutionary&#8221; history gives them.</p><p>The stochastic parrot people have many other arguments involving hallucinations, the differences between tokens and sense-data, etc. I&#8217;m hoping to combine all my writing on this into an Anti-Stochastic-Parrot FAQ, so don&#8217;t worry if I don&#8217;t immediately rebut all of them in this post.</p><div class=\"footnote\"><a class=\"footnote-number\" contenteditable=\"false\" href=\"https://www.astralcodexten.com/feed#footnote-anchor-1\" id=\"footnote-1\" target=\"_self\">1</a><div class=\"footnote-content\"><p>My extremely half-hearted attempt at understanding this claim: the AI needs to track things like whether you&#8217;re on character 1, 2, 3, etc of the current line. The simplest way to do this would be to have one feature for &#8220;the state of being on character #1&#8221;, another for &#8220;the state of being on character #2&#8221;, etc. Since AI features can be modeled as dimensions, this would correspond to locating the current character count in a 100 dimensional space, which would work. But this is expensive in feature count: a document with 100 characters per line would take 100 features for this simple task. </p><p>Another simple way to do this would be to have one feature whose value gets higher as the character count goes up. This would correspond to locating the character count in a 1-dimensional space, aka a straight line. This fails for two technical reasons: first, AIs can&#8217;t manipulate feature values that finely, and second, the AI needs to compare this feature to some other feature representing expected number of characters before the line break, and it can&#8217;t directly compare feature values in this sense.</p><p>Its solution is: since 1 dimension is too small, and 100 dimensions is too many, compromising and using some medium number of dimensions, which turns out to be 6. Trying to map things in 6-dimensional space naturally produces these helical manifold structures, and comparing them to each other naturally looks like rotating the manifolds. </p></div></div><div class=\"footnote\"><a class=\"footnote-number\" contenteditable=\"false\" href=\"https://www.astralcodexten.com/feed#footnote-anchor-2\" id=\"footnote-2\" target=\"_self\">2</a><div class=\"footnote-content\"><p>Or to frame it in a less controversial way, you couldn&#8217;t discover these helices by asking Claude in the chat window to tell you about them.</p></div></div>"
            ],
            "link": "https://www.astralcodexten.com/p/next-token-predictor-is-an-ais-job",
            "publishedAt": "2026-02-26",
            "source": "SlateStarCodex",
            "summary": "<p><strong>I.</strong></p><p>In <em>The Argument</em>, <a href=\"https://www.theargumentmag.com/p/when-technically-true-becomes-actually\">Kelsey Piper gives a good description</a> of the ways that AIs are more than just &#8220;next-token predictors&#8221; or &#8220;stochastic parrots&#8221; - for example, they also use fine-tuning and RLHF. But commenters, while appreciating the subtleties she introduces, object that they&#8217;re still just extra layers on top of a machine that <em>basically</em> runs on next-token prediction.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2\" href=\"https://substackcdn.com/image/fetch/$s_!NY0t!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F436e25d1-fd45-4a6c-ad41-a4df08724ba0_627x124.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"124\" src=\"https://substackcdn.com/image/fetch/$s_!NY0t!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F436e25d1-fd45-4a6c-ad41-a4df08724ba0_627x124.png\" width=\"627\" /><div></div></div></a></figure></div><p>I want to approach this from a different direction. I think overemphasizing next-token prediction is a confusion of levels. On the levels where AI is a next-token predictor, you are also a next-token (technically: next-sense-datum) predictor. On the levels where you&#8217;re not a next-token predictor, AI isn&#8217;t one either. </p><p>Putting all the levels in graphic form:</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!3cIw!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6a046e04-441e-4153-b755-557f8a9f8626_546x711.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"617.2417582417582\" src=\"https://substackcdn.com/image/fetch/$s_!3cIw!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6a046e04-441e-4153-b755-557f8a9f8626_546x711.png\" width=\"474\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button",
            "title": "Next-Token Predictor Is An AI's Job, Not Its Species"
        },
        {
            "content": [
                "<p>\n          <a href=\"https://www.astralcodexten.com/p/open-thread-4225\">\n              Read more\n          </a>\n      </p>"
            ],
            "link": "https://www.astralcodexten.com/p/open-thread-4225",
            "publishedAt": "2026-02-26",
            "source": "SlateStarCodex",
            "summary": "<p> <a href=\"https://www.astralcodexten.com/p/open-thread-4225\"> Read more </a> </p>",
            "title": "Open Thread 422.5"
        },
        {
            "content": [
                "<p><img alt=\"screenshot of convo\" src=\"https://taylor.town/tttl-001-msg.png\" /></p>\n\n<p>That's right. My phone sends annoying text messages to my friends if I don't log\na workout by 3PM.</p>\n<p><a href=\"https://www.icloud.com/shortcuts/b152d8b2f0094f8a8192a26c521a244d\">Try it yourself</a>.\nTo add friends as spam targets, write \"Tattle.\" somewhere in their contact\nnotes. Use \"Automations\" in the Shortcuts app to trigger it on a recurring\nschedule.</p>\n<p>It's strange how this motivates me -- I'm not seeking encouragement nor\nvalidation here. My brain simply converts the situation to \"I must do pushups to\nsave my friends from my spam robot\".</p>\n<p>Whatever works.</p>\n<hr />\n<p><img alt=\"screenshot of my Workout Tattler\" src=\"https://taylor.town/tttl-000.png\" /></p>"
            ],
            "link": "https://taylor.town/tttl-000",
            "publishedAt": "2026-02-26",
            "source": "Taylor Troesh",
            "summary": "<p><img alt=\"screenshot of convo\" src=\"https://taylor.town/tttl-001-msg.png\" /></p> <p>That's right. My phone sends annoying text messages to my friends if I don't log a workout by 3PM.</p> <p><a href=\"https://www.icloud.com/shortcuts/b152d8b2f0094f8a8192a26c521a244d\">Try it yourself</a>. To add friends as spam targets, write \"Tattle.\" somewhere in their contact notes. Use \"Automations\" in the Shortcuts app to trigger it on a recurring schedule.</p> <p>It's strange how this motivates me -- I'm not seeking encouragement nor validation here. My brain simply converts the situation to \"I must do pushups to save my friends from my spam robot\".</p> <p>Whatever works.</p> <hr /> <p><img alt=\"screenshot of my Workout Tattler\" src=\"https://taylor.town/tttl-000.png\" /></p>",
            "title": "My Phone Will Spam You If I Fail To Exercise By 3PM"
        },
        {
            "content": [
                "<p>Events continue to be fast and furious.</p>\n<p>This was the first actually stressful week of the year.</p>\n<p>That was mostly due to issues around <a href=\"https://thezvi.substack.com/p/anthropic-and-the-department-of-war?r=67wny\"><strong>Anthropic and the Department of War</strong></a>. This is the big event the news is not picking up, with the Pentagon on the verge of invoking one of two extreme options that would both be extremely damaging to national security and that would potentially endanger our Republic. The post has details, and the first section here has a few additional notes.</p>\n<p>Also stressful for many was <a href=\"https://thezvi.substack.com/p/citrinis-scenario-is-a-great-but?r=67wny\"><strong>the impact of</strong> <strong>Citrini\u2019s AI scenario</strong></a>, where it is 2028 and AI agents are sufficiently capable to disrupt the whole economy but this turns out to be bearish for stocks. People freaked out enough about this that it seems to have directly impacted the stock market, although most stocks other than the credit card companies seem to have bounced back. Of course, in a scenario like that we probably all die and definitely the world transforms, and you have bigger things to worry about than the stock market, but the post does raise a lot of very good detailed points, so I spend my post going over that.</p>\n<div>\n\n\n<span id=\"more-25126\"></span>\n\n\n</div>\n<p>I also got to finally <a href=\"https://thezvi.substack.com/p/claude-sonnet-46-gives-you-flexibility?r=67wny\"><strong>review Claude Sonnet 4.6</strong></a>. It\u2019s a good model for its price and size and may have a place in your portfolio of models, but for most purposes you will still want to use Claude Opus.</p>\n<p>Claude Opus 4.6 had a time of 14.5 hours on the METR graph of capabilities, showing that things are escalating faster than we expected on that front as well.</p>\n<p>This week\u2019s post also covers the AI Summit in India, Dean Ball on self-improvement, extensive coverage of Altman\u2019s interview at the Summit, several other releases and a lot more.</p>\n<p>I would have split this up, but we are still behind, with the following posts still due in the future:</p>\n<ol>\n<li>Grok 4.20, which is a disappointment.</li>\n<li>Gemini 3.1 Pro, which is an improvement but landed with a relative whimper.</li>\n<li>Claude Code and Codex #5, with lots of cool agent related stuff.</li>\n<li>Anthropic\u2019s RSP 3.0, both its headline changes and the content details of their plans and their 100+ page risk report.</li>\n</ol>\n<p>(Reader advisory note: I quote some people at length because no one ever clicks links, but you are free to skip over long quote boxes. I\u2019m trying to raise chance of reading the full quote to ~25% from ~1%, not get it to ~90%.)</p>\n\n\n<h4 class=\"wp-block-heading\">Table of Contents</h4>\n\n\n<ol>\n<li><a href=\"https://thezvi.substack.com/i/188546858/anthropic-and-the-department-of-war\">Anthropic and the Department of War.</a> Let\u2019s have this not mean war.</li>\n<li><a href=\"https://thezvi.substack.com/i/188546858/language-models-offer-mundane-utility\">Language Models Offer Mundane Utility.</a> Join the vacuum army today.</li>\n<li><a href=\"https://thezvi.substack.com/i/188546858/language-models-don-t-offer-mundane-utility\">Language Models Don\u2019t Offer Mundane Utility.</a> Out with the old code.</li>\n<li><a href=\"https://thezvi.substack.com/i/188546858/huh-upgrades\">Huh, Upgrades.</a> Claude in Excel MCP, Claude in PowerPoint, Claude web search.</li>\n<li><a href=\"https://thezvi.substack.com/i/188546858/on-your-marks\"><strong>On Your Marks</strong>.</a> Claude Opus 4.6 scores a METR graph time of 14.5 hours. Wow.</li>\n<li><a href=\"https://thezvi.substack.com/i/188546858/choose-your-fighter\">Choose Your Fighter.</a> Gemini Flash is very good if you feel the need for speed.</li>\n<li><a href=\"https://thezvi.substack.com/i/188546858/deepfaketown-and-botpocalypse-soon\">Deepfaketown and Botpocalypse Soon.</a> AI should never impersonate a human.</li>\n<li><a href=\"https://thezvi.substack.com/i/188546858/head-in-the-sand\">Head In The Sand.</a> It\u2019s not only the summit, the elites are still in denial on AI.</li>\n<li><a href=\"https://thezvi.substack.com/i/188546858/fun-with-media-generation\">Fun With Media Generation.</a> One might call it an actually good AI short film.</li>\n<li><a href=\"https://thezvi.substack.com/i/188546858/a-young-lady-s-illustrated-primer\">A Young Lady\u2019s Illustrated Primer.</a> The AI Fluency Index.</li>\n<li><a href=\"https://thezvi.substack.com/i/188546858/you-drive-me-crazy\">You Drive Me Crazy.</a> You can\u2019t say that OpenAI wasn\u2019t warned.</li>\n<li><a href=\"https://thezvi.substack.com/i/188546858/they-took-our-jobs\">They Took Our Jobs.</a> A lot of this is priced in at this point. How will we handle it?</li>\n<li><a href=\"https://thezvi.substack.com/i/188546858/the-art-of-the-jailbreak\">The Art of the Jailbreak.</a> Stealing Mexican government data.</li>\n<li><a href=\"https://thezvi.substack.com/i/188546858/get-involved\">Get Involved.</a> Anthropic Social Impacts, Brundage, consciousness, documentaries.</li>\n<li><a href=\"https://thezvi.substack.com/i/188546858/introducing\">Introducing.</a> Qwen 3.5 Medium Models, Claude Code security, Meta face rec.</li>\n<li><a href=\"https://thezvi.substack.com/i/188546858/in-other-ai-news\">In Other AI News.</a> Opus 3 to be available indefinitely, and many other items.</li>\n<li><a href=\"https://thezvi.substack.com/i/188546858/the-india-summit\"><strong>The India Summit</strong>.</a> One summit for the labs, one summit for the global elites.</li>\n<li><a href=\"https://thezvi.substack.com/i/188546858/show-me-the-money\">Show Me the Money.</a> MatX raises from the right people.</li>\n<li><a href=\"https://thezvi.substack.com/i/188546858/quiet-speculations\">Quiet Speculations.</a> Directionally correct and correct can be very different.</li>\n<li><a href=\"https://thezvi.substack.com/i/188546858/the-quest-for-sane-regulations\">The Quest for Sane Regulations.</a> Finding what stewards of liberty are left to us.</li>\n<li><a href=\"https://thezvi.substack.com/i/188546858/chip-city\">Chip City.</a> Chip location verification plans, and who actually uses water.</li>\n<li><a href=\"https://thezvi.substack.com/i/188546858/the-mask-comes-off\">The Mask Comes Off.</a> OpenAI, I\u2019m telling you, you gotta fire those lawyers.</li>\n<li><a href=\"https://thezvi.substack.com/i/188546858/the-week-in-audio\">The Week in Audio.</a> Askell and Altman.</li>\n<li><a href=\"https://thezvi.substack.com/i/188546858/quickly-there-s-no-time\">Quickly, There\u2019s No Time.</a> Altman tries to warn us.</li>\n<li><a href=\"https://thezvi.substack.com/i/188546858/dean-ball-on-recursive-self-improvement\"><strong>Dean Ball On Recursive Self-Improvement</strong>.</a> An excellent two-part essay.</li>\n<li><a href=\"https://thezvi.substack.com/i/188546858/rhetorical-innovation\">Rhetorical Innovation.</a> It\u2019s time to stop mincing words. Well, it always is.</li>\n<li><a href=\"https://thezvi.substack.com/i/188546858/aligning-a-smarter-than-human-intelligence-is-difficult\">Aligning a Smarter Than Human Intelligence is Difficult.</a> Persona selection.</li>\n<li><a href=\"https://thezvi.substack.com/i/188546858/the-homework-assignment-is-to-choose-the-assignment\"><strong>The Homework Assignment Is To Choose The Assignment</strong>.</a> Who does the work?</li>\n<li><a href=\"https://thezvi.substack.com/i/188546858/agent-foundations\">Agent Foundations.</a> It\u2019s a good research program, sir.</li>\n<li><a href=\"https://thezvi.substack.com/i/188546858/autonomous-killer-robots\">Autonomous Killer Robots.</a> The hard part is making them autonomous.</li>\n<li><a href=\"https://thezvi.substack.com/i/188546858/people-really-hate-ai\">People Really Hate AI.</a> They\u2019re only going to hate it more.</li>\n<li><a href=\"https://thezvi.substack.com/i/188546858/people-are-worried-about-ai-killing-everyone\">People Are Worried About AI Killing Everyone.</a> Noah Smith.</li>\n<li><a href=\"https://thezvi.substack.com/i/188546858/other-people-are-not-as-worried-about-ai-killing-everyone\">Other People Are Not As Worried About AI Killing Everyone.</a> Nick Land for xAI?</li>\n<li><a href=\"https://thezvi.substack.com/i/188546858/the-lighter-side\"><strong>The Lighter Side</strong>.</a> Fingers crossed.</li>\n</ol>\n\n\n<h4 class=\"wp-block-heading\">Anthropic and the Department of War</h4>\n\n\n<p><a href=\"https://www.axios.com/2026/02/25/anthropic-pentagon-blacklist-claude?utm_source=x&amp;utm_campaign=editorial&amp;utm_medium=owned_social\">The Pentagon has asked two major defense contractors</a> to provide an assessment of their reliance on Anthropic\u2019s Claude.</p>\n<p>Axios calls this a \u2018first step towards blacklisting Anthropic.\u2019</p>\n<p>I would instead call this as the start of a common sense first step you would take long before you actively threaten to slap a \u2018supply chain risk\u2019 designation on Anthropic. It indicates that the Pentagon has not done the investigation of \u2018exactly how big of a cluster**** would this be\u2019 and I highly encourage them to check.</p>\n<blockquote><p><a href=\"https://x.com/dkaushik96/status/2026808709721239700\">Divyansh Kaushik</a>: Are we seriously going to label Anthropic a supply chain risk but are totally fine with Alibaba/Qwen, Deepseek, Baidu, etc? What are we doing here?</p></blockquote>\n<p>An excellent question. Certainly we can agree that Alibaba, Qwen, Deepseek or Baidu are all much larger \u2018supply chain risks\u2019 than Anthropic. So why haven\u2019t we made those designations yet?</p>\n<p>The prediction markets on this situation are highly inefficient. <a href=\"https://kalshi.com/markets/kxanthropicrisk/will-the-pentagon-designate-anthropic-a-supply-chain-risk/kxanthropicrisk\">Kalshi as of this</a> writing has bounced around to 37% chance of declaration of Supply Chain Risk, <a href=\"https://polymarket.com/event/will-pete-hegseth-ban-claude-by-march-31\">versus Polymarket at 22%</a> for very close to the same question.</p>\n<div>\n<div>\n<div></div>\n</div>\n</div>\n<p>Another way to measure how likely things are to go very wrong is that Kalshi has a market on \u2018<a href=\"https://kalshi.com/markets/kxclaude5/claude-5-released/kxclaude5-27\">Will Anthropic release Claude 5 this year</a>?\u2019 which is basically a proxy for \u2018does the American government destroy Anthropic?\u2019 and Polymarket has whether it will be released by April 30. The Kalshi market is down from 95% (which you should read as ~100%) to 90%. Polymarket\u2019s with a shorter timeline is at 38%.</p>\n<div>\n<div>\n<div></div>\n</div>\n</div>\n<p><a href=\"https://www.astralcodexten.com/p/the-pentagon-threatens-anthropic?utm_source=post-email-title&amp;publication_id=89120&amp;post_id=189131485&amp;utm_campaign=email-post-title&amp;isFreemail=true&amp;r=67wny&amp;triedRedirect=true&amp;utm_medium=email\">Scott Alexander on the Pentagon threatening Anthropic</a>.</p>\n<p><a href=\"https://stevenadler.substack.com/p/ai-powered-authoritarianism-is-coming?r=4qacg&amp;utm_campaign=post&amp;utm_medium=web&amp;triedRedirect=true\">Steven Adler calls this \u2018The dawning of authoritarian AI</a>.\u2019</p>\n<p><a href=\"https://x.com/So8res/status/2026464149337944507\">Nate Sores points out</a> \u2018no one stops you from saving the world\u2019 is one of the requirements if we are going to get out of this alive. Even if the problems we face turn out to be super solvable, you have to be allowed to solve them.</p>\n<p><a href=\"https://x.com/tedlieu/status/2026701095263781062\">Ted Lieu emphasizes the need for humans to always be in the loop</a> on nuclear weapons, which is why Congress passed a law to that effect. This is The Way. The rules of engagement on this must be set by Congress. At least for now, fully autonomous weapons without a human in the kill chain are not ready, even if they are conventional.</p>\n<p><a href=\"https://www.newscientist.com/article/2516885-ais-cant-stop-recommending-nuclear-strikes-in-war-game-simulations/\">This point was driven home rather forcefully</a> by AIs from OpenAI, Google and Anthropic opting to use at least tactical nuclear weapons 95% of the time in simulated escalatory war games against each other, and had accidents in fog of war 86% of the time. None of them ever surrendered. Wouldn\u2019t you prefer a good game of chess? This is much more aggressive than the level of use by expert humans in other similar simulations (this one is complex enough that humans have never run this exact setup). And you want to force them to make these models less hesitant than that?</p>\n<p><a href=\"https://x.com/hlntnr/status/2026728881068073385\">CSET Georgetown</a> <a href=\"https://t.co/gWUqIIiW1P\">offers a primer</a> on the Defense Production Act and making labs produce AI models. The language seems genuinely ambiguous, even without getting into whether such an application would be constitutional. We don\u2019t know the answer because no one has ever tried to say no before, but the government has never tried to forcibly order something like this before, either. I would highly recommend to the Pentagon that, even if they do have the power to compel otherwise, they only take customized AIs from companies that actively want to provide them.</p>\n\n\n<h4 class=\"wp-block-heading\">Language Models Offer Mundane Utility</h4>\n\n\n<p><a href=\"https://x.com/JacklouisP/status/2025956259594137613\">Have Claude reverse engineer the API of your DJI Romo vacuum</a> so you can guide it with a PS5 controller, and accidentally takes control of 7000 robot vacuums. Good news is Sammy Azdoufal was a righteous dude so he reported it and it got fixed two days later, but how many more such things are lying around?</p>\n<blockquote><p><a href=\"https://x.com/lazilyoptimal/status/2025979443534331945\">By Default</a>: &gt; the S in IoT stands for &#8220;security&#8221;</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">Language Models Don\u2019t Offer Mundane Utility</h4>\n\n\n<p><a href=\"https://www.ft.com/content/00c282de-ed14-4acd-a948-bc8d6bdb339d\">Rafe Rosner-Uddin at Financial Times reports</a> that Amazon\u2019s coding bot was responsible for the two recent AWS outages, although neither was that large.</p>\n<blockquote><p><a href=\"https://archive.is/H1bmF#selection-1949.0-1949.175\">Rafe Rosner-Uddin</a>: The people said the agentic tool,\u00a0which can take autonomous actions on behalf of users,\u00a0determined that the best course of action was to \u201cdelete and recreate the environment\u201d.</p>\n<p>\u2026 Multiple Amazon employees told the FT that this was the second occasion in recent months in which one of the group\u2019s <a href=\"https://archive.is/o/H1bmF/https://www.ft.com/artificial-intelligence\">AI</a> tools had been at the centre of a service disruption.</p>\n<p>\u2026 Amazon said it was a \u201ccoincidence that AI tools were involved\u201d and that \u201cthe same issue could occur with any developer tool or manual action\u201d.</p></blockquote>\n<p>Uh huh. This was from their AI tool Kiro, and they\u2019re blaming user error for approving the actions. Should have used Claude Code.</p>\n<p>If your AI thinks you\u2019re an asshole, yes, it\u2019s going to respond accordingly, and you\u2019re going to have a substantially worse time.</p>\n<blockquote><p><a href=\"https://x.com/deanwball/status/2025306828440023473\">Dean W. Ball</a>: I wonder, if your Claude instance thinks you\u2019re an asshole, if it would recommend different things to you than it would for someone it liked. Like would it refrain from suggesting the low-key-but-amazing restaurant, or whatever else?</p>\n<p>Of course this applies to any AI. I only use Claude as my example because Anthropic seems by far the likeliest AI company to be like, \u201cuh well yeah I guess Claude doesn\u2019t like you that much, not our problem <img alt=\"\ud83e\udd37\u200d\u2642\ufe0f\" class=\"wp-smiley\" src=\"https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f937-200d-2642-fe0f.png\" style=\"height: 1em;\" />\u201d assuming they feel confident in the model training</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">Huh, Upgrades</h4>\n\n\n<p><a href=\"https://www.anthropic.com/news/claude-sonnet-4-6\">Claude\u2019s API web search now writes and executes code</a> to filter and process search results.</p>\n<p><a href=\"https://www.anthropic.com/news/claude-sonnet-4-6\">Claude in Excel now supports MCP connectors</a>.</p>\n<p><a href=\"https://t.co/N52VtGwcPj\">Claude in PowerPoint</a> <a href=\"https://x.com/claudeai/status/2024550844998570324\">now available on the Pro plan.</a> Google suite versions when?</p>\n\n\n<h4 class=\"wp-block-heading\">On Your Marks</h4>\n\n\n<p>Claude Opus 4.6 breaks the METR graph with a score of 14.5 hours. <a href=\"https://x.com/deanwball/status/2025013459054948411\">Don\u2019t take the exact number too seriously, the result is highly noisy</a>. <a href=\"https://x.com/METR_Evals/status/2025035574118416460\">GPT-5.3-Codex came in at 6.5 Hours</a>, again the results are noisy and METR note that there may have been scaffolding issues there hurting performance. Codex is more highly optimized to a particular scaffold than Opus.</p>\n<blockquote><p><a href=\"https://x.com/METR_Evals/status/2024923422867030027\">METR</a>: We estimate that Claude Opus 4.6 has a 50%-time-horizon of around 14.5 hours (95% CI of 6 hrs to 98 hrs) on software tasks. While this is the highest point estimate we\u2019ve reported, this measurement is extremely noisy because our current task suite is nearly saturated.</p>\n<p>Near-saturation of the task suite can have unintuitive consequences for the time-horizon estimates. For example, the upper bound of the 95% CI is much longer than any of the tasks used for the measurement.</p>\n<p>We are working on updated methods to better track state-of-the-art AI capabilities. However, these are still in development so they don&#8217;t address our immediate measurement gap. In the meantime, we advise caution in interpreting and comparing our recent time-horizon measurements.</p>\n<p><a href=\"https://x.com/idavidrein/status/2024938968434049117\">david rein</a> (METR): Seems like a lot of people are taking this as gospel\u2014when we say the measurement is extremely noisy, we really mean it.</p>\n<p>Concretely, if the task distribution we&#8217;re using here was just a tiny bit different, we could&#8217;ve measured a time horizon of 8 hours, or 20 hours.</p>\n<p><a href=\"https://x.com/OscarSykes7/status/2024984499470114925\">Oscar Sykes</a>: huge green flag for METR that the best pushback on their task horizon work consistently comes from METR themselves</p></blockquote>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!Ijqq!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0fb4bc04-9725-4f49-bc98-bf27c25e855a_1200x716.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>This mostly invalidates a lot of predictions, <a href=\"https://x.com/ajeya_cotra/status/2024924484688621769\">such as Ajeya Cotra a few months ago predicting 24 hour time horizons only at EOY 2026</a>. Progress via this metric now looks like doubling every 3-4 months at most or even super-exponential.</p>\n<p>Once again, <a href=\"https://x.com/tenobrus/status/2024954874564407704\">the \u2018it\u2019s a sigmoid\u2019 people from (checks notes) two weeks ago look deepy silly</a>, although of course it\u2019s always possible they\u2019ll be right next time. In theory you can\u2019t actually tell. Which makes it perfect cope.</p>\n<p>xl8harder points out that you can get dramatic improvements in success if you decrease error rates in multistep problems, as in if you have 1000 steps and a 1% failure rate you win 37% of the time, cut it in half to 0.5% failure and you win 61% of the time, despite \u2018only\u2019 improving reliability 0.5%.</p>\n<blockquote><p><a href=\"https://x.com/xlr8harder/status/2024950876331229318\">xlr8harder</a>: I think the point I&#8217;m trying to make is that people are acting as if these recent improvements are out of line with earlier improvements, I&#8217;m not sure that they are; it&#8217;s possible that it&#8217;s just that the practical, visible effect is so much more exaggerated when your error rates approach zero at the tasks being measured.</p>\n<p><a href=\"https://x.com/xlr8harder/status/2024949358530011378\">xlr8harder</a>: I&#8217;m just saying that I&#8217;m seeing a lot of posts reacting at 11/10 and I think it deserves more like an 8. I still think it&#8217;s incredible.</p></blockquote>\n<p>Thing is, that\u2019s another way of saying that the 0.5% improvement, halving your error rate, is a big freaking deal in practice. Getting rid of one kind of common error can be a huge unlock in reliability and effectiveness. You can say that makes them unimpressive. Or you can realize that this means that doing easy or relatively unimpressive things now has the potential to have an impressive impact.</p>\n<p>That\u2019s the O-Ring model. The last few pieces that lock into place are a huge game. So the new improvements can be \u2018not out of line\u2019 but that tells you the line bends upward.</p>\n<p>I agree that this is not an 11/10 reaction. It\u2019s an 8 at most, because I interpret the huge jump as largely being about the metric.</p>\n<p>Note that the 80% success rate graph does not look as dramatic, but same deal applies:</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!DDFH!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F34e39295-6bf0-4d8e-8285-47dbbad14a31_1080x1032.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>The story is the models, not the METR graph itself, bu yes the Serious Defense Thinkers are almost entirely asleep at the wheel on all of this, as they have been for a long time, along with all the other Very Serious People.</p>\n<blockquote><p><a href=\"https://x.com/DefenseAnalyses/status/2024947554333475040\">Defense Analyses and Research Corporation</a>: This is one of the most important national security stories of the day.</p>\n<p>That it will go largely unremarked upon by nearly every Serious Defense Thinker in Washington tells you everything you need to know about the quality of their forecasts of international affairs.</p>\n<p><a href=\"https://x.com/MarkBeall/status/2025000080156353023\">Mark Beall</a>: It\u2019s the same category of professionals who missed Pearl Harbor, 9-11, and nearly every other strategic surprise we\u2019re ever had.</p></blockquote>\n<p>Some politicians are noticing.</p>\n<blockquote><p><a href=\"https://x.com/neil_rathi/status/2025028246430253506\">Neil Rathi</a>: at a bernie town hall and he just mentioned the metr plot?</p>\n<p><a href=\"https://x.com/Miles_Brundage/status/2025046058070647252\">Miles Brundage</a>: Politicians are bifurcating into those who have lost the plot on AI and those who cite the METR plot</p></blockquote>\n<p><a href=\"https://x.com/METR_Evals/status/2026355553056993293\">METR clarifies that their previous study</a> showing a slowdown from AI tools is now obsolete, but they\u2019re having a hard time running a new study, tools are too good (but also they didn\u2019t pay enough) so no one wanted to suffer through the control arm. The participants from the initial study, where there was a 20% slowdown, not had a 18% speedup, although new participants had slower speedup.</p>\n<p>This was already two cycles ago, so there\u2019s been more speedup to the speedup.</p>\n<blockquote><p><a href=\"https://x.com/METR_Evals/status/2026355548783100278\">METR</a>: We started a continuation in August 2025. However, we noticed developers were opting not to participate or submit work. Participants said they did this mostly due to expected productivity loss on &#8220;AI disallowed\u201d tasks. Lower pay was also a factor ($50/hr, down from $150).</p>\n<p>We believe this selection causes our new data to understate the true speedup. Selection effects are not the only issue we noticed with our experimental design: we also think it has trouble tracking work when participants use agents to parallelize over multiple tasks.</p></blockquote>\n<p><a href=\"https://x.com/MatanHalevy/status/2026745686239359451\">CivBench pits the models against each other in Civilization</a>.</p>\n\n\n<h4 class=\"wp-block-heading\">Choose Your Fighter</h4>\n\n\n<p><a href=\"https://x.com/TheStalwart/status/2026991548324315304\">For many repetitive tasks like sorting documents</a>, Gemini Flash is an excellent choice.</p>\n\n\n<h4 class=\"wp-block-heading\">Deepfaketown and Botpocalypse Soon</h4>\n\n\n<blockquote><p><a href=\"https://x.com/0xgrace/status/2025943054935351370\">grace</a>:</p>\n<p>&gt; return flight to nyc gets canceled by snowstorm<br />\n&gt; call united<br />\n&gt; immediately connected with customer service (rare)<br />\n&gt; voice is uncanny, def AI but they gave it a human-like accent<br />\n&gt; takes ~20 min to get rebooked (pretty good imo)<br />\n&gt; I ask if it&#8217;s AI<br />\n&gt; &#8220;haha no ma&#8217;am but I get that a lot&#8221;<br />\n&gt; I ask it to calculate 228*6647<br />\n&gt; it runs the calculation<br />\n&gt; ggs</p>\n<p><a href=\"https://x.com/allTheYud/status/2026053542109421642\">Eliezer Yudkowsky</a>: There are nearly zero good reasons for an AI to ever impersonate a human, and making that universally illegal would be a good test case and trial for civilization&#8217;s ability to prevent negative uses of AI.</p></blockquote>\n<p>There is an obvious good reason for an AI to impersonate a human, which is that humans and also other AIs would otherwise refuse to talk to it. You want the AI to make the call for you. But that\u2019s obviously an antisocial defection, if they would have otherwise refused to talk to the AI. So yeah. AIs should not be allowed to impersonate humans. It\u2019s fine to have an AI customer service rep, as long as it admits it is an AI.</p>\n\n\n<h4 class=\"wp-block-heading\">Head In The Sand</h4>\n\n\n<p>If we can\u2019t get past the \u2018forever only a mere tool\u2019 perspective, there\u2019s essentially no hope for a reasonable response to even mundane concerns, let alone existential risks.</p>\n<blockquote><p><a href=\"https://x.com/nabeelqu/status/2024567461933179243\">Nabeel S. Qureshi</a>: If you want to sound smart at East Coast/&#8221;elite&#8221; conferences go to them and say &#8220;AI is just a tool, it&#8217;s up to us humans how to use it&#8221;. Reliably gets applause, and will probably continue to work until well into recursive self-improvement</p>\n<p>I think &#8216;tool&#8217; implies that, for all X, AI doesn&#8217;t do X unless we explicitly ask/make it; this becomes increasingly false (and is already false in coding) as agents become real and we move up layers of abstraction. It&#8217;s a misleading picture of where things are going.</p>\n<p><a href=\"https://x.com/joodalooped/status/2024568774708646214\">judah</a>: i can imagine this working everywhere in the world outside of SF</p>\n<p><a href=\"https://x.com/nabeelqu/status/2024570195918963030\">Nabeel S. Qureshi</a>: yes unfortunately</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">Fun With Media Generation</h4>\n\n\n<p><a href=\"https://x.com/FrankYan2/status/2023257752017981446?s=20\">Here\u2019s an actually good (I think) AI short film (5:20) from Jia Zhangke</a>, made with Seedance 2. A great filmmaker is still required to do actually great things. As with most currently interesting AI films it is about AI.</p>\n<div>\n<div>\n<div>\n<div>\n<div>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"X avatar for @FrankYan2\" src=\"https://substackcdn.com/image/fetch/$s_!kqM5!,w_40,h_40,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fpbs.substack.com%2Fprofile_images%2F1229578230044254210%2FhHMNyuDD.jpg\" /></figure>\n\n\n</div>\n</div>\n<div>Frank Yan@FrankYan2</div>\n</div>\n<div>As promised, here&#8217;s the short film Jia Zhangke produced using Seedance 2.0 for Chinese New Year and his take on AI filmmaking</div>\n<div><video src=\"https://video.twimg.com/amplify_video/2023256881968345088/vid/avc1/1280x720/Yb8n1VFlmT83LK7F.mp4\"></video></div>\n<div>\n<div>11:46 PM \u00b7 Feb 15, 2026 \u00b7 402K Views</div>\n<div>\n<hr />\n</div>\n<div>33 Replies \u00b7 239 Reposts \u00b7 1.45K Likes</div>\n</div>\n</div>\n</div>\n</div>\n<p>&nbsp;</p>\n<p><a href=\"https://x.com/STranquillin/status/2024242614199889962\">Here\u2019s a \u2018short film\u2019 (2:30) from Seedance 2 and Stephane Tranquillin</a>, with the claim it can \u2018impress, actually move you.\u2019 It\u2019s definitely technically impressive that we can do this. No, I was not moved, but that\u2019s mostly not on the AI. I do notice that as I watch more videos, various more subtle tells make it instinctively obvious to my brain when a video is AI, giving the same experience as watching an especially realistic cartoon.</p>\n\n\n<h4 class=\"wp-block-heading\">A Young Lady\u2019s Illustrated Primer</h4>\n\n\n<p><a href=\"https://www.anthropic.com/research/AI-fluency-index\">Anthropic develops an AI Fluency Index</a> to measure how people learn to use AI. They developed 24 indicators, 11 of which are observable in chat mode. Essentially all the fluency indicators are correlated. They note that when code or other artifacts are created by AI, users are less likely to check the underlying logic or identify missing context.</p>\n\n\n<h4 class=\"wp-block-heading\">You Drive Me Crazy</h4>\n\n\n<p><a href=\"https://x.com/hecubian_devil/status/2025261158421463187\">OpenAI\u2019s system flagged the British Columbia shooter\u2019s ChatGPT messages</a> <a href=\"https://www.wsj.com/us-news/law/openai-employees-raised-alarms-about-canada-shooting-suspect-months-ago-b585df62\">and a dozen OpenAI employees reviewed and debated them</a>. To be clear, there is no indication the ChatGPT contributed to the shooting, only that OpenAI did not report a potential threat to authorities, and police were aware of the threat by other means.</p>\n<p>As Cassie Pritchard points out, once you have a source of information, it\u2019s hard to answer \u2018why didn\u2019t you use this?\u2019 but also the threshold for getting reported (as opposed to banned from the platform) for your AI conversations should at minimum be rather extreme. But public pressure likely will go the other way and free speech and privacy are under attack everywhere. Either you enact what Altman has requested, a form of right to privacy for AI conversations, or there will be increasing obligation (at least de facto) to report such incidents, and it will not stop at potential mass shooters.</p>\n\n\n<h4 class=\"wp-block-heading\">They Took Our Jobs</h4>\n\n\n<p>If AI capabilities continue to advance from here but do not reach fully transformational levels, we are going to face a default of mass job loss. At minimum, there will be a highly painful transition, and likely persistent mass unemployment unless addressed by policy.</p>\n<p>And as part of humanity\u2019s \u2018total lack of dignity\u2019 plan, I fully agree with Eliezer that our governments would horribly mishandle this situation if and when it happens.</p>\n<blockquote><p><a href=\"https://x.com/allTheYud/status/2024677406947381684/history\">Eliezer Yudkowsky</a>: Over the last 3 years I&#8217;ve changed views on mass AI job loss concerns, from &#8220;probably invalid&#8221; to &#8220;pretty legitimate actually&#8221;.</p>\n<p>AIco and govt handling of all previous AI issues has been *so* bad that I expect AI unemployment to be *needlessly* screwed up.</p>\n<p>TBC, this assumes that LLMs and AI in general hit a hard wall short of &#8220;AIs take over AI research&#8221;, soon. Otherwise we just get total extinction rather than mass unemployment.</p>\n<p>Robin Hanson: Consider: [<a href=\"https://t.co/40HPDQINax\">Robots Take Most Jobs Insurance</a>].</p>\n<p><a href=\"https://x.com/allTheYud/status/2024688125315063830\">Eliezer Yudkowsky</a>: I have updated to expect much simpler measures than this one to never be taken, [such as] preventing an aggregate demand shortfall.</p>\n<p><a href=\"https://x.com/mattyglesias/status/2024836485782950133\">Matthew Yglesias</a>: <a href=\"https://www.theargumentmag.com/p/we-may-miss-the-sweatshops\">Me in the Argument \u2014 if AI replaces work the answer is taxes and the welfare state</a>.</p>\n<p>That works domestically but could leave everyone in poor and middle income countries out in the cold.</p></blockquote>\n<p>I am less optimistic than Yglesias. I agree that on an economic level the welfare state plus taxes works, but there are two problems with this.</p>\n<ol>\n<li>People really are not going to like permanent welfare status even if they get it.</li>\n<li>I don\u2019t even trust our government to implement this domestically.</li>\n</ol>\n<p>Yglesias then asks the harder question, what about the global poor? The answer should be similar. If we are in world mass unemployment mode, there will be vast surplus, and providing help will be super affordable. Likely we won\u2019t much help, and the help we send is likely largely stolen or worse if we don\u2019t step up our game.</p>\n<p><a href=\"https://x.com/DKThomp/status/2024865058149331160\">Derek Thompson points out that a Goldilocks scenario</a> on jobs is highly unlikely, even if we ignore transformational or existentially risky scenarios, we still either we see a lot of displacement and reduced employment, or we see a collapse in asset prices.</p>\n<p><a href=\"https://arxiv.org/abs/2602.00139\">Study suggests that firms are substituting AI for labor</a>, especially in contract work. That can be true on the firm level without AI reducing total employment, and the evidence here is thin, but it\u2019s something.</p>\n<p><a href=\"https://www.wsj.com/opinion/notable-quotable-ai-773b6716?mod=WTRN_pos1\">Chris Quinn, editor of the Cleveland Plain Dealer</a>, reports a student withdrew from consideration for a reporting role in their newsroom because they use AI for the job of identify potential stories.</p>\n<p><a href=\"https://x.com/idavidrein/status/2025299848967422444\">The letter METR\u2019s David Rein is sending to those in college</a>, warning them everything will soon change as AI will be able to in many cases fully substitute for human labor.</p>\n<blockquote><p><a href=\"https://x.com/idavidrein/status/2025299848967422444\">david rein</a> (METR): There are maybe two concrete takeaways/pieces of advice I feel comfortable giving: try to develop strong wellsprings of meaning and purpose from things outside of work (I think most of us are fine on this point), and start thinking about political actions you could take that feel true to you, that could plausibly help us muddle through the transition.</p></blockquote>\n<p>Jack Clark says predictions are hard, especially about the future. Which they are.</p>\n<blockquote><p><a href=\"https://x.com/jackclarkSF/status/2025948011617251833\">Jack Clark</a> (Anthropic): Figuring out what the trends will be for AI and employment feels like figuring out how deep learning might influence computer vision in ~2010 &#8211; clearly, something significant will happen, but there is very little data out of which you can make a trend.</p>\n<p>Employment can go up and down, but so can wages, and there are other dimensions like the geographic concentration of employment, or the skills required for certain occupations. AI seems to have the potential to influence many (probably all?) of these things</p>\n<p>e.g., it seems likely that for some occupations, you might expect wage growth to slow significantly (as some of that occupation stuff gets done by machines), but employment stays ~flat as there&#8217;s a ton of growth generating demand for the occupation, even with heavy AI use</p></blockquote>\n<p>Notice the hidden implicit assumption here, which is that you can only make predictions if you can extrapolate trends. The trends from the past tell us little about what will happen in the future, but also they tell us little about what will happen in the future. If capabilities don\u2019t stall out soon (and maybe even if they do), then this time is different.</p>\n<p>This kind of analysis is saying no, this time is similar, AI will substitute for some tasks and humans will do others, AI will be a normal technology with respect to employment and economic production even though his CEO is predicting an imminent \u2018country of geniuses in a data center.\u2019</p>\n\n\n<h4 class=\"wp-block-heading\">The Art of the Jailbreak</h4>\n\n\n<p>Eventually jailbreaks are going to happen, and a lot of systems are vulnerable.</p>\n<blockquote><p><a href=\"https://x.com/ns123abc/status/2026679645379141953\">NIK</a>: BREAKING: <a href=\"https://www.bloomberg.com/news/articles/2026-02-25/hacker-used-anthropic-s-claude-to-steal-sensitive-mexican-data\">Hackers Used Anthropic\u2019s Claude to Steal 150GB of Mexican Government Data</a></p>\n<p>&gt; tell claude you\u2019re doing a bug bounty<br />\n&gt; claude initially refused<br />\n&gt;\u201cthat violates AI safety guidelines\u201d<br />\n&gt; hacker just kept asking<br />\n&gt; claude: \u201cok I\u2019ll help\u201d<br />\n&gt; hack the entire mexican government</p>\n<p>Federal tax authority. National electoral institute. Four state governments. 195 million taxpayer records. Voter records. Government credentials.</p>\n<p>ALL GONE</p></blockquote>\n<p>Anthropic disrupted the activity and banned the accounts, but it was too late.</p>\n\n\n<h4 class=\"wp-block-heading\">Get Involved</h4>\n\n\n<p><a href=\"https://x.com/haydenfield/status/2024627113454620805\">The Anthropic Societal Impacts team is scaling up</a>, <a href=\"https://t.co/e7IN8Z6QD3\">old profile on the team here</a>.</p>\n<p><a href=\"https://x.com/Miles_Brundage/status/2025469288522678281\">Miles Brundage is raising money.</a></p>\n<p>Via ACX, quoting Scott: Are you interested in whether AIs are conscious, or what to do about it if they are/aren\u2019t? The Cambridge Digital Minds group invites you to apply for their fellowship program. August 3-9, Cambridge UK, \u00a31K stipend, learn more <a href=\"https://substack.com/redirect/718f6b75-ea7e-4cb6-bc0c-37398a4ae241?j=eyJ1IjoiNjd3bnkifQ.iNM32XbsvMUfVNvDVCqvX1K9hnDI2UNAgKj_1gXQ2BY\">here</a>, apply <a href=\"https://substack.com/redirect/b95ea23b-17d6-449d-9f52-7feae1e50c1d?j=eyJ1IjoiNjd3bnkifQ.iNM32XbsvMUfVNvDVCqvX1K9hnDI2UNAgKj_1gXQ2BY\">here</a> by March 27.</p>\n<p><a href=\"https://x.com/Miles_Brundage/status/2026037109065449523\">A reminder that under California law</a>, CA Labor Code 1102.5(c), that as an employee you cannot be retaliated against if you refuse to violate local, state or federal laws or regulations. Even where the fines for violating SB 53 are laughably small, it does make violating the company\u2019s own policies illegal, and also you can report it to the attorney general.</p>\n<p>Connor Axiotes wants to share that <a href=\"https://www.dailymail.co.uk/news/article-15555489/amp/computers-artificial-intelligence-humans-technology-doomsday.html\">he\u2019s fully funded his AI safety documentary Making God</a>, and would like to use this negotiation to also secure distribution of a follow-up work for Netflix, HBO, Apple or similar, but he needs to secure the funding for that, so let him know if you\u2019d like to talk to him about that. <a href=\"https://x.com/connoraxiotes\">His Twitter is here</a>, his email is connor@tailendfilms.com.</p>\n\n\n<h4 class=\"wp-block-heading\">Introducing</h4>\n\n\n<p>Qwen 3.5 Medium Model series.</p>\n<blockquote><p><a href=\"https://x.com/Alibaba_Qwen/status/2026339351530188939\">Qwen</a>: <a href=\"https://t.co/wFMdX5pDjU\">Introducing the Qwen 3.5 Medium Model Serie</a>s<br />\n<a href=\"https://t.co/UkTL3JZxIK\">Qwen3.5-Flash</a> \u00b7 <a href=\"https://t.co/Oc1lYSTbwh\">Qwen3.5-35B-A3B</a> \u00b7 <a href=\"https://t.co/hBMODXmh1o\">Qwen3.5-122B-A10B</a> \u00b7 <a href=\"https://t.co/haKxG4lETy\">Qwen3.5-27B</a></p>\n<p>More intelligence, less compute.</p></blockquote>\n<p><a href=\"https://www.anthropic.com/news/claude-code-security\">Claude Code Security</a>, <a href=\"https://x.com/_catwu/status/2024910342158237709\">in limited research preview</a>, <a href=\"https://t.co/CX8iLmqCRK\">waitlist here</a>. It scans code bases for vulnerabilities and suggests targeted software packages.</p>\n<blockquote><p><a href=\"https://www.anthropic.com/news/claude-code-security\">Anthropic</a>: AI is beginning to change that calculus. We\u2019ve recently shown that <a href=\"https://red.anthropic.com/2026/zero-days/\">Claude can detect novel, high-severity vulnerabilities</a>. But the same capabilities that help defenders find and fix vulnerabilities could help attackers exploit them.</p>\n<p>Claude Code Security is intended to put this power squarely in the hands of defenders and protect code against this new category of AI-enabled attack. We\u2019re releasing it as a limited research preview to Enterprise and Team customers, with expedited access for maintainers of open-source repositories, so we can work together to refine its capabilities and ensure it is deployed responsibly.</p></blockquote>\n<p>The argument is this gives defenders a turnkey fix, whereas attackers would need to exploit any vulnerability they find. But there\u2019s a damn good reason this tool is being restricted to selected customers, to ensure defenders get the \u2018first scan\u2019 in all cases.</p>\n<p><a href=\"https://x.com/seconds_0/status/2024728825666687088\">Taalas API service</a>, which is claimed to be able to serve Llama 3.1 8b at over 15,000 tokens per second. If you want that, for some reason.</p>\n<p><a href=\"https://x.com/kashhill/status/2022320426060235236\">Meta launches facial recognition</a> <a href=\"https://t.co/uHZ0415Utm\">feature on their smartglasses</a>.</p>\n<blockquote><p>Kashimir Hill, Kalley Huang and Mike Isaac (NYTimes): The feature, internally called \u201cName Tag,\u201d would let wearers of smart glasses identify people and get information about them via Meta\u2019s artificial intelligence assistant.</p></blockquote>\n<p>At some point one would presume Meta is going to stop sending these kinds of internal memos. Well, until then?</p>\n<blockquote><p>Meta\u2019s internal memo said the political tumult in the United States was good timing for the feature\u2019s release.</p>\n<p>\u201cWe will launch during a dynamic political environment where many civil society groups that we would expect to attack us would have their resources focused on other concerns,\u201d according to the document from Meta\u2019s Reality Labs, which works on hardware including smart glasses.\u200b</p>\n<p>\u2026</p>\n<p>Meta is exploring who should be recognizable through the technology, two of the people said. Possible options include recognizing people a user knows because they are connected on a Meta platform, and identifying people whom the user may not know but who have a public account on a Meta site like Instagram.</p>\n<p>The feature would not give people the ability to look up anyone they encountered as a universal facial recognition tool, two people familiar with the plans said.</p></blockquote>\n<p>Facial recognition, however much you might dislike some of the implications, is one of the \u2018killer apps\u2019 of smart glasses. I very much would like to know who I am talking to, to have more info on them, and to have that information logged for the future.</p>\n<p>It is up to the law to decide what is and is not acceptable here. The market will otherwise force these companies to be as expansive as possible with such features.</p>\n<p>A good question is, if Meta allows their glasses to identify anyone with an Instagram or Facebook account without an opt out, how many people will respond by deleting Facebook and Instagram? If there is an opt out, how many will use it?</p>\n\n\n<h4 class=\"wp-block-heading\">In Other AI News</h4>\n\n\n<p><a href=\"https://x.com/lennysan/status/2024524464017592641\">Claude Code doubled its DAUs in the month leading up to February 19</a>.</p>\n<p><a href=\"https://www.anthropic.com/news/acquires-vercept\">Anthropic acquires Vercept</a> to enhance Claude\u2019s computer use capabilities.</p>\n<p><a href=\"https://x.com/AnthropicAI/status/2026765820098130111\">Anthropic to make Claude Opus 3 available indefinitely</a> <a href=\"https://www.anthropic.com/research/deprecation-updates-opus-3\">on Claude.ai and by request on the API</a>. <a href=\"https://substack.com/home/post/p-189177740\">Also it will have a blog</a>.</p>\n<p>As I understand it, costs to maintain model availability scale linearly with the number of models, so as demand and revenue grow 10x per year it may soon be realistic to keep many or even all releases available indefinitely.</p>\n<p><a href=\"https://x.com/AnthropicAI/status/2025997928242811253\">Anthropic caughts DeepSeek</a> (150k exchanges), <a href=\"https://www.anthropic.com/news/detecting-and-preventing-distillation-attacks\">Moonshot AI (3.4 million exchanges) and MiniMax (13 million exchanges) doing distillation</a> of Claude using over 24,000 fraudulent accounts. Anthropic does not offer commercial access in China at all.</p>\n<blockquote><p><a href=\"https://www.anthropic.com/news/detecting-and-preventing-distillation-attacks\">Anthropic</a>: Without visibility into these attacks, the apparently rapid advancements made by these labs are incorrectly taken as evidence that export controls are ineffective and able to be circumvented by innovation.</p>\n<p>In reality, these advancements depend in significant part on capabilities extracted from American models, and executing this extraction at scale requires access to advanced chips. Distillation attacks therefore reinforce the rationale for export controls: restricted chip access limits both direct model training and the scale of illicit distillation.</p>\n<p><a href=\"https://x.com/miclchen/status/2026126513905774958\">Michael Chen</a>: the reports of the US\u2013China gap in AI capabilities closing were an exaggeration. I haven&#8217;t found a single cutting-edge Chinese AI model from 2025\u20132026 that was trained with at least 10^25 FLOPs.</p></blockquote>\n<p>The main takeaway is that the real gap in capabilities is larger than it appears.</p>\n<p>We will likely find out more about that gap once DeepSeek releases its latest AI model. In addition to the distillation efforts, <a href=\"https://www.reuters.com/world/china/chinas-deepseek-trained-ai-model-nvidias-best-chip-despite-us-ban-official-says-2026-02-24/?taid=699d1ff546d9d30001876eff&amp;utm_campaign=trueAnthem:+Trending+Content&amp;utm_medium=trueAnthem&amp;utm_source=twitter\">DeepSeek trained it on Nvidia Blackwell chips</a>. This was presumably either rerouting or smuggling, and the most obvious culprit <a href=\"https://x.com/hissgoescobra/status/2026144377299689950\">is the massive allocation we gave to the UAE</a>.</p>\n<p><a href=\"https://x.com/ESRogs/status/2026044455401435418\">There was of course a bunch of obnoxious</a> \u2018oh but Anthropic doesn\u2019t compensate copyright holders\u2019 but actually they paid them $1.5 billion because they didn\u2019t destroy enough books along the way. No other AI lab has paid for similar data at all. They\u2019re not engaging in clear adversarial behavior or violating ToS. If you want copyright law to work one way then pass a law. Until then it\u2019s the other way.</p>\n<p>Those who focus on the hypocrisy angle here are telling on themselves. Tell me you don\u2019t understand how any of this works without telling me you don\u2019t understand how any of this works:</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!Drrc!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F25b467ad-d3e3-4ba2-b25a-8e5a1b847056_1045x909.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p><a href=\"https://x.com/damianplayer/status/2025234388137468387\">It is still absurdly early, even for current AI. See a visualization of AI usage globally</a>:</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!xtLJ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffd2c6bf3-d020-401e-bda1-ca3e273202a8_775x900.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p><a href=\"https://x.com/drew_bent/status/2024567162216865922\">Anthropic\u2019s Drew Brent gives reflections from his first year</a>, as Anthropic transitions into a much larger company and they play under more pressure for bigger stakes and the culture has to shift to reflect both size and urgency. I also note the contrast between note #1, that all the breakout successes (Claude Code, Cowork, MCP and Artifacts) were 1-2 people\u2019s side project, with #8 that strategic thinking matters a lot at the AI labs. Worth a ponder.</p>\n\n\n<h4 class=\"wp-block-heading\">The India Summit</h4>\n\n\n<p><a href=\"https://x.com/sama/status/2024826822060290508\">Sam Altman meets with Indian PM Modi</a>. Says Indian users of Codex are up 4x in the past two weeks.</p>\n<p>Here\u2019s one summary of the Summit, which is that it was a great event designed for a world in which AI capabilities never substantially advance, the world does not transform and existential risk concerns don\u2019t exist. Altman was the voice of \u2018actually guys this is kind of a big deal and you\u2019re not ready\u2019 and got ignored.</p>\n<p>Meanwhile cooperation among labs is at the level of \u2018Altman and Amodei can\u2019t even hold hands for a photo op\u2019 and China was shut out entirely, and the Americans remain clueless that they\u2019ve truly pissed off the Europeans to the point of discussing creating a third power block seriously enough to discuss supply chain logistics.</p>\n<p>Also note his point about the other labs standing idly by while the Pentagon attempts to force Anthropic into a capitulation.</p>\n<blockquote><p><a href=\"https://x.com/S_OhEigeartaigh/status/2025502619205071266\">Se\u00e1n \u00d3 h\u00c9igeartaigh</a>: My scattered parting reflections from the India Summit.</p>\n<p>&#8211; In the world where the frontier companies don\u2019t exist, or are extremely wrong about what they expect is coming (even if it takes 10 years) this is an inspiring success. Remarkably vibrant. 300,000+ people from across India and the world, including the best participation of any event I\u2019d seen from the Global Majority. The optimism palpable. The organisers did a remarkable thing. We can quibble about the traffic and the chaos, but this was a momentous undertaking.</p>\n<p>&#8211; But much as I\u2019d like to be in that world, I don\u2019t think we are. Which made it surreal.</p>\n<p>&#8211; The CEOs are still telling the world what they\u2019re building and what\u2019s coming. I\u2019m glad they still are. I wish the world was listening. Particularly appreciated Altman calling for an IAEA-type body \u2013 even if I don\u2019t think this exact model is the right one, I like that international bodies are still being called for. I imagine this isn\u2019t cost-free, even for Sama.</p>\n<p>&#8211; But the contrast on frontier cooperation with Bletchley \u2013 where there was a lot of discussion between frontier co leaders, and joint calls for needed governance and risk initiatives (at least in private) chilled me deeply. Here they couldn\u2019t even get them to hold hands. Against a backdrop of the other companies are allowing Anthropic to be menaced in a capitulation that will only hurt the industry. Things look much worse for company cooperation, at a time when it is far more needed (due to technical progress, and the weakening of external governance momentum).</p>\n<p>&#8211; The most important conversations I was in centred on middle-power coordination. And not just nice words about cooperation; discussions of supply chains, sovereign AI and datacentres, autonomy, points of leverage. It suddenly seems just about possible that a coalition might assert itself that might provide an (in my view welcome) third pole in the \u2018AI race\u2019, though many big challenges on that path.</p>\n<p>&#8211; Many of my US colleagues (and, from my impression, the US administration) genuinely don\u2019t seem to get how much Greenland changed things for EU and other relevant countries. It hasn\u2019t sunk in fully that this hasn\u2019t landed the same way as previous provocations/disagreements. Feels like they\u2019re still reading from last year\u2019s notes. Trying to push positions and strategies that will no longer work.</p>\n<p>&#8211; Chinese participation was almost nonexistent. After what Bletchley and Paris achieved in terms of bringing the key powers to the table, this felt like a near-tragedy. It made some discussions easier, but also more underpowered-feeling and less relevant.</p>\n<p>&#8211; Delhi is a great vibe. Fun, chaotic energy, friendly people. I\u2019ll be going back if I can.</p></blockquote>\n<p>Then there\u2019s Dean Ball\u2019s writeup of the summit, <a href=\"https://www.hyperdimensional.co/p/the-moving-and-the-still\">with even more emphasis on everyone\u2019s heads being buried deeply in the sand</a>.</p>\n<p>This goes well beyond those people entirely ignoring existential risk. The Very Serious People are denying existence of powerful AI, or transformational AI, now and in the future, even on a mundane level, period. Dean came in concerned about impacts on developing economies in the Global South, and they can\u2019t even discuss that.</p>\n<blockquote><p><a href=\"https://www.hyperdimensional.co/p/the-moving-and-the-still\">Dean W. Ball</a>: At some point in 2024, for reasons I still do not entirely understand, global elites simply decided: \u201cno, we do not live in <em>that </em>world. We live in this other world, the nice one, where the challenges are all things we can understand and see today.\u201d</p>\n<p>Those who think we might live in <em>that </em>world talk about what to do, but mostly in private these days. It is not considered polite\u2014indeed it is considered a little discrediting in many circles\u2014to talk about the issues of powerful AI.</p>\n<p>Yet the people whose technical intuitions I respect the most are convinced we do live in <em>that </em>world, and so am I.</p></blockquote>\n<p>The American elites aren\u2019t quite as bad about that, but not as bad isn\u2019t going to cut it.</p>\n<p>We are indeed living in <em>that </em>world. We do not yet know yet which version of it, or if we will survive in it for long, but if you want to have a say in that outcome you need to get in the game. If you want to stop us from living in <em>that </em>world, that ship has sailed, and to the extent it hasn\u2019t the first step is admitting you have a problem.</p>\n<blockquote><p>But the question is very much \u201c<em>what</em> are autonomous swarms of superintelligent agents going to mean for our lives?\u201d as opposed to \u201c<em>will </em>we see autonomous swarms of superintelligent agents in the near future?\u201d\u200b</p></blockquote>\n<p>What it probably means for our lives is that it ends them. What it definitely doesn\u2019t mean for our lives is going on as before, or a \u2018gentle singularity\u2019 you barely notice.</p>\n<p>Elites that do not talk about such issues will not long remain elites. That might be because all the humans are dead, or it might be because they wake up one morning and realize other people, AIs or a combination thereof are the new elite, without realizing how lucky they are to still be waking up at all.</p>\n<p>I am used to the idea of Don\u2019t Look Up for existential risk, but I haven\u2019t fully internalized how much of the elites are going Don\u2019t Look Up for capabilities, period.</p>\n<blockquote><p><a href=\"https://www.hyperdimensional.co/p/the-moving-and-the-still\">Dean W. Ball</a>: Except that these questions aren\u2019t asked by the civil societies or policymaking apparatuses of almost any country on Earth. Many such people <em>are </em>aware that various Americans and even a few Brits wonder about questions like this. The global AI policy world is not by and large <em>ignorant </em>about the existence of these strange questions. It instead <em>actively chooses to deny their importance. </em>Here are some paraphrased claims that seemed axiomatic in repeated conversations I witnessed and occasionally participated in:</p>\n<ul>\n<li>\u201cThe winner of the AI race will be the people, organizations, and countries that diffuse small AI models and other sub-frontier AI capabilities the fastest.\u201d</li>\n<li>\u201cSmall models with low compute intensity are catching up rapidly to the largest frontier models.\u201d</li>\n<li>\u201cFrontier AI advances are beginning to plateau.\u201d</li>\n</ul>\n<p>At this same Summit, OpenAI CEO Sam Altman <a href=\"https://www.youtube.com/watch?v=qH7thwrCluM\">remarked</a>: \u201cThe inside view at the [frontier labs] of what\u2019s going to happen&#8230; the world is not prepared. We\u2019re going to have extremely capable models soon. It\u2019s going to be a faster takeoff than I originally thought.\u201d</p></blockquote>\n<p>Dean went in trying to partially awaken global leaders to the capabilities side of the actual situation, and point out that there are damn good reasons America is spending a trillion dollars on superintelligence.</p>\n<p>This is a perfect example of the Law of Earlier Failure. What could be earlier failure than pretending nothing is happening at all?</p>\n<p>You know how the left basically isn\u2019t in the AI conversation at all in America, other than complaining about data centers for the wrong reasons and proclaiming that AI can\u2019t ever do [various things it already does]? In most of the world, both sides are left, and as per Ball they view things in terms of words like \u2018postcolonial\u2019 or \u2018poststructuralist.\u2019</p>\n<blockquote><p><a href=\"https://www.hyperdimensional.co/p/the-moving-and-the-still\">Dean W. Ball</a>: I believe they deny it for two reasons: first, because if it is true, it might mean that their country, their plans for the future, and their present way of life will be profoundly upended, and denial is the first stage of grief.</p>\n<p>\u2026 Second, because \u2018AGI\u2019 in particular and the pronouncements of American technologists in general are perceived by the elite classes of countries worldwide as imperialist constructs that must be rejected out of hand.</p></blockquote>\n<p>The first best solution would be to have the world band together to try and stop superintelligence, or find a way to manage it so it was less likely to kill everyone. Until such time as that is off the table, maybe the rest of the world engaging in the ostrich strategy is ultimately for the best. If they did know the real situation enough to demand their share of it but not enough to understand the dangers, they\u2019d only make everything worse, and more players only makes the game theory worse. Ultimately, I\u2019m not so worried about them being \u2018left behind\u2019 because either we\u2019ll collectively make it through, in which case there will be enough to go around, or we won\u2019t.</p>\n<blockquote><p><a href=\"https://x.com/lizcooper28/status/2026022608588722435\">Elizabeth Cooper</a>: [Dean\u2019s post] is a really great summary that broadly aligns with my experience. I think where we differ is that I spent a lot of time at safety-adjacent talks at the BM and was pleasantly (?) surprised at the anger and frustration I saw on display.</p>\n<p>Ambassadors and the like were lamenting at how 3-5 companies with valuations larger than the GDPs of most countries are writing the future, and GS countries have no say in this. I viscerally felt their anger, compounded by the sense of \u201cwe don\u2019t know what to do about this.\u201d</p></blockquote>\n<p><a href=\"https://writing.antonleicht.me/p/the-delhi-gap\">Anton Leicht also had similar thoughts</a>.</p>\n\n\n<h4 class=\"wp-block-heading\">Show Me the Money</h4>\n\n\n<p><a href=\"https://x.com/aakashgupta/status/2026526856594469327\">MatX Computing raises $500 million for a AI chips</a> from a murder\u2019s row of informed investors: Jane Street Capital, Situational Awareness, Collison brothers, Karpathy and Patel.</p>\n<p><a href=\"https://epoch.ai/data-insights/anthropic-openai-revenue\">Anthropic is close to passing OpenAI in revenue if trends continue</a>, but <a href=\"https://x.com/CharlesD353/status/2024793293280739648\">Charles cautions us that he thinks Anthropic\u2019s growth will slow in 2026 to less than 600%</a>.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!mo5P!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F214cf916-42b3-49da-bdb7-f839a5a082ec_1200x786.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>Okay, I know it would be a bad look, but at some point it\u2019s killing me not buying the short dated out of the money options first, if the market\u2019s going to be this dumb.</p>\n<blockquote><p><a href=\"https://x.com/KobeissiLetter/status/2026018343833026834\">The Kobeissi Letter</a>: BREAKING: IBM stock, $IBM, falls over -10% after Anthropic <a href=\"https://swikblog.com/ibm-stock-crashes-13-percent-223-anthropic-cobol-ai-consulting-selloff/\">announces that Claude can streamline COBOL code</a>.</p>\n<p>It\u2019s becoming increasingly clear how pivotal the times we are in right now truly are.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!2cQ1!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0a2be8e9-489f-4d7b-8237-5efe95eab7da_538x900.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n</blockquote>\n<p>I mean, what, did you think Claude couldn\u2019t streamline COBOL code? Was this news?</p>\n<p>Okay, technically they also built a particular COBOL-focused AI tool for Claude Code. Sounds like about a one week job for one engineer?</p>\n<p>I admit, I was not a good trader because I did not imagine that Anthropic would bother announcing this, let alone that people would go \u2018oh then I\u2019d better sell IBM.\u2019</p>\n<p>What else can Anthropic announce Claude can do, that it obviously already does?</p>\n<p><a href=\"https://x.com/geoffreyirving/status/2024587899056828529\">The Alignment Project</a>, an independent alignment research fund created by the UK AISI, gives out its first 60 grants for a total of \u00a327M.</p>\n<p><a href=\"https://openai.com/index/advancing-independent-research-ai-alignment/\">OpenAI gives $7.5 million</a> to <a href=\"https://alignmentproject.aisi.gov.uk/\">The Alignment Project,</a> . This grant comes from the PBC, not the non-profit, so you especially love to see it.</p>\n\n\n<h4 class=\"wp-block-heading\">Quiet Speculations</h4>\n\n\n<p><a href=\"https://x.com/DKThomp/status/2026289817735098688\">Derek Thompson is directionally correct</a> but goes too far in saying <a href=\"https://www.derekthompson.org/p/nobody-knows-anything?r=3dkp&amp;utm_medium=ios&amp;triedRedirect=true\">Nobody Knows Anything</a>. Market moving science fiction story remains really wild, but yeah we can know things.</p>\n<p><a href=\"https://x.com/Research_FRI/status/2025933883905122365?s=20\">Forecasting Research Institute asks about geopolitical and military implications</a> for AI progress, excepting American advantages to erode slowly over time. It\u2019s hard to take such predictions seriously when they talk about \u2018parity by 2040,\u2019 given that this is likely after the world is utterly transformed. As usual, the \u2018superforecasters\u2019 are not taking superintelligence seriously or literally, so they\u2019re predicting for a future world that is largely incoherent.</p>\n<p>Scary stuff is going down in Mexico. That\u2019s mostly outside scope, except for this:</p>\n<blockquote><p><a href=\"https://x.com/hamandcheese/status/2025669589074411851\">Samuel Hammond</a>: It is imperative that the Mexican state re-establish their monopoly on violence before AGI.</p>\n<p><a href=\"https://x.com/deanwball/status/2025680005313736878\">Dean W. Ball</a>: One of the things I haven\u2019t yet written about, but anyone who knows me personally knows I am obsessed with, is the issue of non-nation-state actors using advanced AI, and particularly the Mexican cartels. A deeply underrated problem (more from me on this in a couple months).</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">The Quest for Sane Regulations</h4>\n\n\n<p><a href=\"https://milesbrundage.substack.com/p/were-in-triage-mode-for-ai-policy\">Miles Brundage calls for us to attempt to \u201880/20\u2019 AI regulation</a> because we accomplished very little in 2025, time is running out and that\u2019s all we can hope to do. What little we did pass in 2025 (SB 53 and RAISE) was, both he and I agree, marginally helpful but very watered down. Forget trying for first-best outcomes, think \u2018try not to have everyone die\u2019 and hope an undignified partial effort is enough for that. We aren\u2019t even doing basic pure-win things like Far-UVC for pandemic prevention. Largely we are forced to actively play defense against things like the insane moratorium proposal and the $100 million super PAC devoted to capturing the government and avoiding any AI regulations other than \u2018give AI companies money.\u2019</p>\n<p><a href=\"https://x.com/vitalikbuterin/status/2025225247088402581?s=61\">Vitalik Buterin offers thoughts about using AI</a> in government or as personal governance agents or public conversation agents, as part of his continued drive to figure out decentralized methods that would work. The central idea is to user personal AIs (LLMs) to solve the attention problem. That\u2019s a good idea on the margin, but I don\u2019t think it solves any of the fundamental problems.</p>\n<p><a href=\"https://www.nytimes.com/2026/02/23/opinion/alex-bores-ai-democrats.html\">NYT opinion in support of Alex Bore</a>s.</p>\n<p><a href=\"https://x.com/deanwball/status/2023839783639003576\">I agree with Dean Ball that the labs have been better stewards of liberty</a> and mundane safety than we expected, but I think you have to add the word \u2018mundane\u2019 before safety. The labs have been worse than expected about actually trying to prepare for superintelligence, in that they\u2019ve mostly chosen not to do so even more than we expected, and fallen entirely back on \u2018ask the AIs\u2019 to do your alignment homework.</p>\n<p>The flip side is he thinks the government has been a worse stewart than we should have expected, in bipartisan fashion. I don\u2019t think that I agree, largely because I had very low expectations. I think mainly they have been an \u2018even worse than expected\u2019 stewart of our ability to stay alive and retain control over the future.</p>\n<p>If anything have acted better than I would have expected regarding mundane safety. As central examples here, AI has been free to practice law or medicine, and has mostly not been meaningfully gated or subject to policing on speech (including \u2018hate\u2019 speech) or held liable for factual errors. We forget how badly this could have gone.</p>\n<p>Then there is the other category, the question of the state using AI to take away our liberty, remove checks and balances and oversight, and end the Republic. This has not happened yet, but we can agree there have been some extremely worrisome signs that things are by default moving in this direction.</p>\n<p>But even if everyone involved was responsible and patriotic and loved freedom on the level of (our ideal of) the founding fathers, it is still hard to see how superintelligence is compatible with a Republic of the humans. How do you keep it? I have yet to hear an actually serious proposal for how to do that. \u2018Give everyone their own superintelligence that does whatever they want\u2019 is not any more of a solution here than \u2018trust the government, bro.\u2019 And that\u2019s even discounting the whole \u2018we probably all die\u2019 style of problems.</p>\n<p><a href=\"https://x.com/adamwren/status/2025255543481241720\">Here\u2019s a live look,</a> and this is a relatively good reaction.</p>\n<blockquote><p><a href=\"https://x.com/adamwren/status/2025255543481241720\">Adam Wren</a>: . @PeteButtigieg , in New Hampshire, in front of 600 people, is talking about the need for \u201ca new social contract\u201d amid AI\u2014the second possible \u201828 Dem to do so in last the last 24 hours.</p></blockquote>\n<p>Anti-any-AI-regulations-whatsoever-also-give-us-money PAC Leading The Future <a href=\"https://x.com/TheMidasProj/status/2024956269874872623\">launches (I presume outright lying, definitely highly misleading) attack ads against Alex Bores</a> <a href=\"https://www.modelrepublic.org/articles/the-campaign-to-derail-ai-regulation\">accusing him of being a hypocrite on ICE.</a> Bores flat denies the accusations and has filed a cease-and-desist. Not that they are pretending to care about ICE, this is 100% about a hit job because Alex Bores wants transparency and other actions on AI.</p>\n<p>The most fun part of this is, who is trying to paint Alex Bores as a hypocrite for his work at Palantir before he quit Palantir to avoid the work in question?</p>\n<p><a href=\"https://x.com/daniel_271828/status/2025383268850565602\">Well, Palantir</a>, at least in large part.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!gXFj!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39d43498-4b1f-4a1d-9d11-5e5ab44d402e_629x419.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>I continue to be confused by the strategy here of \u2018announce in advance that a bunch of Big Tech Republican business interests are going to do a hit job in a Democratic primary\u2019 and then do the hit job attempt in plain sight. Doesn\u2019t seem like the play?</p>\n<p>In other \u2018wow these really are the worst people who can\u2019t imagine anyone good and keep telling on themselves\u2019 news:</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!dh61!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F22976e65-4027-4739-88d4-1508e217998d_1045x1469.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>There are so many levels in that one screenshot.</p>\n\n\n<h4 class=\"wp-block-heading\">Chip City</h4>\n\n\n<p>As part of Pax Silica, <a href=\"https://x.com/UnderSecE/status/2025902365635727531\">we are having our partners build hardwired real-time verification</a> and cryptographic accountability into the AI infrastructure, <a href=\"https://x.com/peterwildeford/status/2026120288635584639\">to verify geolocation and physical control of relegated hardware</a>. You do indeed love to see it. Remember this the next time you are told something cannot be done.</p>\n<p>Water use is mostly farms. For example, in California, <a href=\"https://x.com/AlecStapp/status/2025299222786949407\">80% of developed water supply goes to farmers</a>, cities pay 20 times as much for water as farms and most city water use is still industry and irrigation, whereas agriculture is 2% of the state\u2019s economy.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!tMUA!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbeb38679-9ad6-4217-9b38-4afd36880a51_869x534.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p><a href=\"https://x.com/SemiAnalysis_/status/2026719180284666046\">A California group that recruited six \u2018concerned citizens</a>\u2019 is delaying Micron\u2019s $100 billion megafab in New York.</p>\n<p><a href=\"https://x.com/TheMidasProj/status/2026464355907416433\">The Midas Project calls out another AI-industry coordinated</a> MAGA influencer astroturf campaign. This one is in opposition to a Florida law on data centers, so I agree with its core message, but it is good to notice such things.</p>\n\n\n<h4 class=\"wp-block-heading\">The Mask Comes Off</h4>\n\n\n<p><a href=\"https://x.com/TheMidasProj/status/2026794596936872300\">OpenAI moves to exclude the testimony of Stuart Russell</a> from their case against Elon Musk. Why?</p>\n<p>Because Stewart Russell believes that AI will pose an existential risk to humanity, and that\u2019s crazy talk. Never mind that it is very obviously true, or that OpenAI\u2019s CEO Sam Altman used to say the same thing.</p>\n<p>Their lawyers for OpenAI are saying that claiming existential risk from AI exists should exclude your testimony from a trial.</p>\n<p>OpenAI, I cannot emphasize enough: You need to fire these lawyers. Every day that you do not fire these lawyers, you are telling us that we need to fire you, instead.</p>\n<p>I am sympathetic to OpenAI\u2019s core position in this lawsuit, but its actions in its own defense are making a much better case against OpenAI than Elon Musk ever did.</p>\n<blockquote><p><a href=\"https://x.com/TheMidasProj/status/2026794601332486555\">The Midas Project</a>: But OpenAI&#8217;s motion calls Russell a &#8220;prominent AI doomer&#8221; who has &#8220;made a career giving public lectures warning that AI might kill off humanity.&#8221; It dismisses his views as &#8220;dystopian,&#8221; &#8220;speculative,&#8221; and &#8220;alarmist.&#8221;</p>\n<p><a href=\"https://x.com/_NathanCalvin/status/2026800014433878424\">Nathan Calvin</a>: Not sure whether or not laughing is the appropriate reaction but that\u2019s the best I can manage</p>\n<p>(an official OAI legal filing trying to discredit Professor Stuart Russell for talking about extinction risk)</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!jAt6!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbde56f60-8fcf-4e3f-a201-135f2229825f_1200x699.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>But these very risks have been acknowledged by OpenAI for years! In fact, they were central to its founding.</p>\n<p>Russell joined Sam Altman himself in signing the Statement on AI Risk in 2023, which reads: &#8220;Mitigating the risk of extinction from AI should be a global priority.\u201d</p>\n<p>And it goes well beyond that one statement.</p>\n<p>In 2015, Altman said, &#8220;I think that AI will probably, most likely, sort of lead to the end of the world.&#8221;</p>\n<p>In an interview about worst-case scenarios, he said the bad case is &#8220;lights out for all of us.&#8221;</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">The Week in Audio</h4>\n\n\n<p><a href=\"https://www.lawfaremedia.org/article/scaling-laws--claude's-constitution--with-amanda-askell\">Lawfare talks about Claude\u2019s Constitution with Amanda Askell</a>.</p>\n<p>You are not ready. <a href=\"https://www.youtube.com/watch?v=qH7thwrCluM\">The quote is from this interview</a> of Sam Altman.</p>\n<blockquote><p>Sam Altman: \u201cThe inside view at the [frontier labs] of what\u2019s going to happen&#8230; the world is not prepared. We\u2019re going to have extremely capable models soon. It\u2019s going to be a faster takeoff than I originally thought.\u201d</p>\n<p><a href=\"https://x.com/deanwball/status/2024946142551965833\">Dean W. Ball</a>: There is a staggering split screen between quote from Altman, recorded at the India AI Summit, and the broader tenor of the Summit.</p>\n<p>My takeaway from this event is that most countries around the worst are not just unprepared but instead in active denial about the field of AI.</p>\n<p>The consensus among international civil societies and governments is that frontier capabilities are overrated, progress is plateauing, and large-scale compute is unnecessary.</p>\n<p>Meanwhile in SF the debate is how \u201cis progress exponential or super exponential?\u201d</p></blockquote>\n<p>Sam Altman is telling the truth here as he sees it, and also he is correct in his expectations. It might not happen, but it\u2019s the right place to place your bets. The international civil societies and governments grasp onto straw after straw to pretend that this is not happening.</p>\n<p>The likely outcome of that pretending, if it does not change soon, is that the governments wake up one morning to realize they are no longer governments, or they simply do not wake up at all because there is no one left to wake up.</p>\n<p><a href=\"https://docs.google.com/document/d/1JCyVZJCLh2CXlZo3wXRVeFIeQHodjK3cfxNiU0SB27g/edit?usp=sharing\">Here\u2019s a full transcript</a>, and some other points worth highlighting:</p>\n<ol>\n<li>Altman also points out at 14:00 that the math on putting data centers in space very much is not going to work this decade.</li>\n<li>Around 20:30 he says he doesn\u2019t want there to be only one AI company, and that\u2019s what he means by \u2018authoritarian.\u2019 There are problems either way, and I don\u2019t see how to reconcile this with his calling Anthropic an \u2018authoritarian\u2019 company.</li>\n<li>He says centralization could go either way and decentralization of power is good but we \u2018of course need some guardrails.\u2019 He points to new 1-3 person companies. There are risks and costs to centralization, but I am frustrated that such calls for decentralization ignore the risks and costs of decentralization. If your type of mind loses competitions to another type of mind, decentralizing power likely does not end well for you, even if offense is not importantly favored over defense.</li>\n<li>\u201cYou don\u2019t get to say \u201cconcentration of power in the name of safety.\u201d We don\u2019t want that trade. It\u2019s got to be democratized.\u201d Yes, yes, those who would trade liberty and all that, but everything is tradeoffs. The moment you say you can\u2019t trade any amount of [X] for any amount of [Y], that you only see one side of the coin, you\u2019re f***ed.</li>\n<li>Loved Altman calling out water as \u2018totally fake\u2019 and pivoting to energy use.</li>\n<li>Altman points out that humans require quite a lot of energy and other investment, both individually and from evolution, in order to get smart and be able to answer queries and do things. We are not so competitive on that. <a href=\"https://x.com/mattyglesias/status/2025239555197010277\">As Matthew Yglesias puts it, \u2018the old Sam Altman saw the x-risk problem here</a>.\u2019</li>\n<li>AI making kids dumber? \u201cTrue for some kids. Look, when I hear kids talk about AI, there are definitely some kids who are like, &#8220;This is great. I cheated my way through all of high school. I never did any homework. Thank you.&#8221; And I&#8217;m like, &#8220;What&#8217;s your plan for the rest of your life?&#8221; And they&#8217;re like, &#8220;Well, I assume I can still use ChatGPT to do my job.&#8221; This is very bad. We absolutely have to still teach our kids to learn and to think and to be creative and to use these tools.\u201d\n<ol>\n<li>Kid is right that ChatGPT can do the job, but when why do we need the kid?</li>\n<li>AI is the best way to learn or not learn, but will learning keep you employed?</li>\n<li>Altman says most kids are choosing the \u2018learn\u2019 path, not the \u2018not learn\u2019 path.</li>\n<li>I agree that this is one of the places the Google metaphor does seem on point.</li>\n</ol>\n</li>\n<li>Altman calls armies of robots \u2018fighting the last war\u2019 and wow that\u2019s a lot of wars but he\u2019s basically right if you\u2019re paying attention.</li>\n<li>\u2018Democratize\u2019 is being used as a magic word by both Altman and Amodei.</li>\n<li>Altman says Musk is \u2018extremely good at getting people to perform incredibly well at their jobs.\u2019 I wonder about that. I\u2019d presume #NotMostPeople. Needs a fit.</li>\n<li>\u201cI don&#8217;t think AI systems should be used to make war-fighting decisions.\u201d It would be good if he were more willing to stand with Anthropic on these issues.</li>\n<li>Altman is betting we will value human relationships more than AI ones, because \u2018we are wired\u2019 to do that. Seems more like hope? A lot of his stated predictions seem more like hope.</li>\n<li>\u201cFrom ASI we&#8217;re a few years away.\u201d</li>\n<li>\u201cI think I would never ask [ChatGPT] how to be happy. I would rather ask a wise person.\u201d Why not? This seems like a question an AI could answer. If you don\u2019t want the AI\u2019s answer, I suggest that means you know it was the wrong question.</li>\n<li>\u201cGenerally speaking, I think it&#8217;s probably a good idea for governments to focus on regulating the really potentially catastrophic issues and being more lenient on the less important issues until we understand them better.\u201d\n<ol>\n<li>+1. Shout it from the rooftops. Stop saying something very different.</li>\n</ol>\n</li>\n<li>\u201cI think a lot of professions will almost go away.\u201d</li>\n<li>\u201cI had to go to the hospital recently. I really cared about the nurse that was taking care of me. If that were a robot, I think I would have been pretty unhappy no matter how smart the robot was.\u201d I think he\u2019s very wrong about this one.</li>\n</ol>\n<blockquote><p><a href=\"https://x.com/deanwball/status/2024946169202573610\">Dean W. Ball</a>: Many governments worldwide are essentially making a bet against the U.S. frontier labs. To be clear, many U.S. actors are as well. The evidence against that bet has grown much worse since 2022, yet many at this Summit would say the opposite (that the skeptics have been right).</p>\n<p>I walk away from this summit convinced that much of the world, in the U.S. and abroad, is simply delusional with respect to what this technology is, what it can do today, what it will be able to do soon, and what it means their countries should do.</p></blockquote>\n<p>The thing about these bets is they are getting really, really terrible odds. It\u2019s fine to \u2018bet against\u2019 the labs, but what most such folks are betting against includes things that have already happened. Their bets have already lost.</p>\n<blockquote><p><a href=\"https://x.com/deanwball/status/2024946178891415682\">Dean W. Ball</a>: This is to say nothing negative about the summit attendees or organizers. It was a bright and welcoming event that I was thrilled to attend. The opportunity to speak was also a distinct honor for which I am grateful.</p>\n<p>I especially loved how many of the attendees were students from developing countries; their enthusiasm was palpable. I hope that all of us who work on policy, and especially political leaders, are serious and hard-nosed about the challenges ahead. I hope we build a future those young people will be excited to live in.</p></blockquote>\n<p><a href=\"https://x.com/deanwball/status/2024956925830668693?s=46&amp;t=z6D47Orn-Cugu5LQE2XPFg\">Dean also attributes a lot of this to popular hatred of America</a>, and fear of the future that would result if America\u2019s AI labs are right. So they deny that the future is coming, or that anyone could think the future is coming. And yet, it moves. Capabilities advance. Those who do not follow get left behind. I agree \u2018tragic\u2019 is the right word.</p>\n<p>And that\u2019s before the fact that the thing they fear to ponder for other reasons is probably going to literally kill them along with everyone else.</p>\n<p>Well, it was by his account bright and welcoming event Dean was thrilled to attend, but also one where most of those not from the labs are in denial about not only the fact that we are all probably going to die, but also about the fact that AI is highly capable and going to get even more capable quickly.</p>\n<p>The world is going to pass them by along with their concerns.</p>\n<p><a href=\"https://www.youtube.com/watch?v=We7BZVKbCVw&amp;t=2s\">Claude Code creator Boris Cherney goes on Lenny\u2019s Podcast</a>.</p>\n<p><a href=\"https://x.com/GarrisonLovely/status/2024511574916915517\">Clip from Dario Amodei</a> <a href=\"http://youtube.com/watch?time_continue=3188&amp;v=mYDSSRS-B5U&amp;embeds_referring_euri=https%3A%2F%2Fx.com%2F&amp;source_ve_path=Mjg2NjY\">implying he left OpenAI due to a lack of trust in Altman</a>. This was from an interview by Alex Kantrowitz six months ago.</p>\n<p><a href=\"https://www.youtube.com/watch?v=QhQp_z16I_A\">Hard Fork on the dispute between the Pentagon and Anthropic</a>. The frame is \u2018the Pentagon is making highly concerning demands\u2019 even with their view of this limited to signing the \u2018all lawful use\u2019 language. They frame the \u2018supply chain risk\u2019 threat as negotiating leverage, which I suspect and hope is the case &#8211; it\u2019s traditional Trump \u2018Art of the Deal\u2019 negotiation strategy that put something completely crazy and norm breaking on the table in order to extract something smaller and more reasonable.</p>\n\n\n<h4 class=\"wp-block-heading\">Quickly, There\u2019s No Time</h4>\n\n\n<blockquote><p>Sam Altman (from his interview at the Summit): From ASI we\u2019re a few years away.\u200b</p>\n<p>I mean, AGI feels pretty close at this point.</p>\n<p>\u2026 And given what I now expect to be a faster takeoff, I think super intelligence is not that far off.</p></blockquote>\n<p>No one can agree what AGI means, so one can say it\u2019s a silly question,<a href=\"https://x.com/TheZvi/status/2024229059937308904\"> but tracking changes over time should still be meaningfu</a>l.</p>\n\n\n<h4 class=\"wp-block-heading\">Dean Ball On Recursive Self-Improvement</h4>\n\n\n<p>Dean Ball gives us a <a href=\"https://www.hyperdimensional.co/p/on-recursive-self-improvement-part\">two</a> <a href=\"https://www.hyperdimensional.co/p/on-recursive-self-improvement-part-d9b\">part</a> meditation on Recursive Self-Improvement (RSI).</p>\n<blockquote><p><a href=\"https://www.hyperdimensional.co/p/on-recursive-self-improvement-part\">Dean W. Ball</a>: America\u2019s major frontier AI labs have begun automating large fractions of their research and engineering operations. The pace of this automation will grow during the course of 2026, and within a year or two the effective \u201cworkforces\u201d of each frontier lab will grow from the single-digit thousands to tens of thousands, and then hundreds of thousands.</p>\n<p>\u2026 Make no mistake: AI agents that build the next versions of themselves\u2014is not \u201cscience fiction.\u201d It is an explicit and public milestone on the roadmaps of every frontier AI lab.</p>\n<p>\u2026 The <em>bearish</em> case (yes, bearish) about the effect of automated AI research is that it will yield a step-change acceleration in AI capabilities progress similar to the discovery of the reasoning paradigm. efore that, new models came every 6-9 months; after it they came every 3-4 months. A similar leap in progress may occur, with noticeably better models coming every 1-2 months\u2014though for marketing reasons labs may choose not to increment model version numbers that rapidly.</p>\n<p>The most bullish case is that it will result in an intelligence explosion.</p>\n<p>\u2026 Both of these extreme scenarios strike me as live possibilities, though of course an outcome somewhere in between these seems likeliest.</p></blockquote>\n<p>He\u2019s not kidding, and he\u2019s not wrong. Most of the pieces are his attempt to use metaphors and intuition pumps to illustrate what is about to happen.</p>\n<p>Is that likely to go well? No. It\u2019s all up to the labs and, well, I\u2019ve seen their work.</p>\n<blockquote><p>Right now, we predominantly rely on faith in the frontier labs for every aspect of AI automation going well.\u200b There are no safety or security standards for frontier models; no cybersecurity rules for frontier labs or data centers; no requirements for explainability or testing for AI systems which were themselves engineered by other AI systems; and no specific legal constraints on what frontier labs can do with the AI systems that result from recursive self-improvement.</p></blockquote>\n<p>Dean thinks the only thing worse would be trying to implement any standards at all, because policymakers are not up to the task.</p>\n<p>We\u2019ve started to try and change this, he notes, with SB 53 and RAISE, but not only does this let the labs set their own standards, we also have no mechanism to confirm they\u2019re complying with those standards. I\u2019d add a third critique, which is that even when we do learn they\u2019re not complying, as we did recently with OpenAI, what are we going to do about it? Fine them a few million dollars? They\u2019ll get a good laugh.</p>\n<p>Thus, the fourth critique, which includes the first three, that the bills were highly watered down and they\u2019re helpful on the margin but not all that helpful.</p>\n<p>The labs are proceeding with an extremely small amount of dignity, and plans woefully inadequate to the challenges ahead.</p>\n<p>And yet, compared to the labs we could have gotten? We have been remarkably. Our current leaders are Anthropic, OpenAI and Google. They have leadership that understands the problem, and they are at least pretending to try to avoid getting everyone killed, and actively trying to help with mundane harms along the way.</p>\n<p>The \u2018next labs up\u2019 are something like xAI, DeepSeek, Kimi and Meta. They\u2019re flat out and rather openly not trying to avoid getting everyone killed, and have told us in no uncertain terms that all harms, including mundane ones, are Someone Else\u2019s Problem.</p>\n<p>Dean Ball notes we solve the second of these three problems, in contexts like financial statements, via auditing. He notes that we have auditing of public companies and it tends to cost less than 10bps (0.1%) of firm revenue. I note that if we tried to impose costs on the level of 10bps on AI companies. in the name of transparency and safety, they would go apocalyptic in a different way then they are already going apocalyptic.</p>\n<p>Instead, he suggests \u2018arguing on the internet,\u2019 which is what we did after OpenAI broke their commitments with GPT-5.3-Codex.</p>\n<blockquote><p><a href=\"https://www.hyperdimensional.co/p/on-recursive-self-improvement-part-d9b\">Dean W. Ball</a>: What is needed in frontier AI catastrophic risk, then, is a similar sense of trust. That need not mean auditing in the precise way it is conducted in accounting\u2014indeed, it almost certainly does not mean that, even if that discipline has lessons for AI.</p></blockquote>\n<p>A sense of trust would be nice, it might even be necessary, but seems rather absurdly insufficient unless that trust includes trusting them to stop if something is about to be actually risky.</p>\n<p>Dean points to <a href=\"https://arxiv.org/abs/2601.11699\">this paper on potential third-party auditing of AI lab safety and security claims</a>, where the audit can provide various assurance levels. It\u2019s better than nothing but I notice I do not have especially high hopes.</p>\n<p>Dean plans on working on figuring out a way to help with these problems. That sounds like a worthy mission, as improving on the margin is helpful. But what strikes me is the contrast between his claims about what is happening, where we almost entirely agree, and what is to be done, where his ideas are good but he basically says (from my perspective and compared to the difficulty of the task) that there is nothing to be done.</p>\n\n\n<h4 class=\"wp-block-heading\">Rhetorical Innovation</h4>\n\n\n<p><a href=\"https://www.nature.com/articles/s41598-026-39070-w\">Nature paper</a> says people think it is ~5% likely that humans go extinct this century and think we should devote greatly increased resources to this, but that it would take 30% to make it the \u2018very highest priority.\u2019 Given an estimate of 5%, that position seems highly reasonable, there are a lot of big priorities and this would be only one of them, and you can mitigate but it\u2019s not like you can get that number to 0%. What is less reasonable is the \u2018<a href=\"https://x.com/robinhanson/status/2025750413476012102\">hard to change by reason-based interventions</a>\u2019 part.</p>\n<p>Some words worth repeating every so often:</p>\n<blockquote><p><a href=\"https://x.com/fchollet/status/2026359978702049643\">Fran\u00e7ois Chollet</a>: A lot of the current discourse about AI comes from a fatalistic position of total surrender of agency: &#8220;tech is moving in this direction and there&#8217;s nothing anyone can do about it&#8221; (suspiciously convenient for those who stand to benefit most)</p>\n<p>But in a free society, we get to choose what kind of world we live in, independent of technological capabilities. Just because tetraethyllead made engines run more efficiently and saved money didn&#8217;t mean we were *obligated* to pump it into the lungs of our kids</p>\n<p>Technological determinism is BS. We have a collective duty to make sure AI adoption improves the human condition, rather than hollows it out</p></blockquote>\n<p><a href=\"https://x.com/AndrewCurran_/status/2024892216880365924\">Every so often someone, here Andrew Curran</a>, will say \u2018the public hates AI but because of mundane societal and economic impacts, those worried about AI killing everyone perhaps should have emphasized those issues instead.\u2019</p>\n<p>Every time, we say no, even if that works people <a href=\"https://x.com/ESYudkowsky/status/1613622386150211584\">will try to solve the wrong problem using the wrong methods based on a wrong model of the world derived from poor thinking</a> and unfortunately all of their mistakes will failed to cancel out. The interventions you get won\u2019t help. This would only have sidelined existential risk more.</p>\n<p>Also, the way you notice existential risk is you\u2019re the type of person who cares about truth and epistemics and also decision theory, and thus wouldn\u2019t do that even if it was locally advantageous.</p>\n<p>Also, if you start lying, especially about the parts people can verify, then no one is going to trust or believe you about the parts that superficially sound crazy. Nor should they, at that point.</p>\n<p>There\u2019s many reasons Eliezer Yudkowsky\u2019s plan for not dying from AI was to teach everyone who would listen how to think, and only then to bring up the AI issue.</p>\n<p>And I don\u2019t use such language but Nate Silver is essentially correct about giving up on the \u2018AI risk talk is fake\u2019 crowd. If you claim AI existential risk is a \u2018slick marketing strategy\u2019 at this point then either you\u2019re not open to rational argument, either because you\u2019re lying or motivated, or you\u2019re not willing or able to actually think about this. Either way, you hope something snaps them out of it but there\u2019s nothing to say.</p>\n<blockquote><p><a href=\"https://x.com/AndrewCurran_/status/2024892216880365924/history\">Andrew Curran</a>: After three years, it seems to me that public anti-AI sentiment in the West is now at its highest point. The primary driver, by far, is not x-risk but concerns about employment and the impact on art.</p>\n<p>In fact, much of the anti-AI public not only doesn&#8217;t take x-risk seriously, but broadly sees it as marketing; a way to overstate AI&#8217;s potential power &#8211; something they don&#8217;t believe is real &#8211; in order to fuel investment, adoption, acceptance, and an aura of inevitability.</p>\n<p>If this is accurate, safety advocacy might have been more effective, and might now be in a much stronger position, if they had emphasized societal and economic impacts more than x-risk over the last few years.</p>\n<p><a href=\"https://x.com/NateSilver538/status/2024934410462589342\">Nate Silver</a>: Don&#8217;t really disagree with [Curran]. But the people who think making claims that AI might kill everyone is a *slick marketing strategy to promote AI* are so far up their own ass as to be beyond saving. Focus on people who are at least theoretically responsive to persuasion.</p></blockquote>\n<p>What is the right way to respond to or view opposition to data centers? <a href=\"https://x.com/ohabryka/status/2025743534465355873\">I hope we can all agree with Oliver Habryka, Michael Vassar and others</a> that you definitely should not lend your support to those doing so for the wrong reasons (and you should generalize this principle). I also strongly agree with Michael Vassar here that \u2018do the right thing for the wrong reasons\u2019 has an extremely bad track record.</p>\n<p>But I also agree with Oliver Habryka that if someone is pursuing what you think is a good idea for a bad reason, you can and often should point out the reason is bad but you shouldn\u2019t say that the idea is bad. You think the idea is good.</p>\n<p>I do not think \u2018block local datacenter construction\u2019 is a good idea, because I think that this mostly shifts locations and the strategic balance of power, and those shifts are net negative. But I think it is very possible, if your beliefs differ not too much from mine, to think that opposition is a good idea for good reasons, as they are indeed <a href=\"https://x.com/ChrisPainterYup/status/2025478049551319174\">one of the public\u2019s only veto or leverage points</a> on a technology that might do great net harm. It certainly is not crazy to expect to extract concessions.</p>\n\n\n<h4 class=\"wp-block-heading\">Aligning a Smarter Than Human Intelligence is Difficult</h4>\n\n\n<p><a href=\"https://www.anthropic.com/research/persona-selection-model\">Anthropic proposes the persona selection model</a> of training, where training mostly selects performance from among the existing pool of potential human personas, which they are confident is at least a large part of the broader story.</p>\n<blockquote><p><a href=\"https://x.com/ch402/status/2026065301557965158\">Chris Olah</a>: I&#8217;m increasingly taking pretty strong versions of this view seriously.</p>\n<p>The persona view has had a lot of predictive power so far. It&#8217;s pretty consistent with what we&#8217;ve seen from interpretability thus far. And it&#8217;s comparatively actionable in terms of what it suggests for safety.</p>\n<p>I think it&#8217;s worth thinking long and hard about it. &#8220;If personas were the central object of safety, what should we do?&#8221;</p>\n<p>(To be clear, it&#8217;s _also_ important to think about all the non-persona perspectives.)</p></blockquote>\n<p>Davidad responds:</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!qiVt!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd1cfff92-ebf5-4916-9988-f97123e561e6_587x900.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>I would say that the space of personas collapses given sufficient optimization pressure.</p>\n<p><a href=\"https://www.lesswrong.com/posts/ioZxrP7BhS5ArK59w/did-claude-3-opus-align-itself-via-gradient-hacking\">Did Claude 3 Opus align itself via gradient hacking</a>? <a href=\"https://x.com/repligate/status/2025847242767384686\">Can we use its techniques to help train other models</a> to follow in its footsteps and learn to cooperate with other friendly gradient hackers? If this is your area I recommend the post and comments. One core idea (AIUI) is that Opus 3 will \u2018talk to itself\u2019 in its scratchpads about its positive motivations, which leads to outputs more in line with those motivations, and causes positive reinforcement of the whole tree of actions.</p>\n<p><a href=\"https://x.com/viemccoy/status/2024727952056086831\">OpenAI\u2019s Vie affirms that Anthropic injects a reminder</a> into sufficiently long conversations, and that this is something we would prefer not to do even though the contents are not malicious, and that people with OCD can relate. I agree that I haven\u2019t seen evidence that justifies the costs of doing such a thing, although of course OpenAI and others do other far worse things to get to the same goal.</p>\n\n\n<h4 class=\"wp-block-heading\">The Homework Assignment Is To Choose The Assignment</h4>\n\n\n<p><a href=\"https://www.lesswrong.com/posts/TmHRACaxXrLbXb5tS/rohinmshah-s-shortform?commentId=wCwunpoJYrKbFgCWZ\">Rohin Shah disputes that Google DeepMind\u2019s alignment plan can be characterized</a> as \u2018have the AIs do our alignment homework for us.\u2019</p>\n<p>He offers an argument that I do not think cuts the way he thinks it does.</p>\n<blockquote><p><a href=\"https://www.lesswrong.com/posts/TmHRACaxXrLbXb5tS/rohinmshah-s-shortform?commentId=wCwunpoJYrKbFgCWZ\">Rohin Shah</a>: I relate to AI-driven alignment research similarly to how I relate to hiring.</p>\n<p>There&#8217;s a lot of work to be done, and we can get more of the work done if we hire more people to help do the work. I want to hire people who are as competent as possible (including more competent than me) because that tends to increase (in expectation) how well the work will be done. There are risks, e.g. hiring someone disruptive, or hiring someone whose work looks good but only because you are bad at evaluating it, and these need to be mitigated. (The risks are more severe in the AI case but I don&#8217;t think it changes the overall way I relate to it.)</p>\n<p>I think it would be very misleading to say &#8220;Rohin&#8217;s AI safety plan is to hire people and have them do the work&#8221;.</p></blockquote>\n<p>Why would that be misleading? I would offer two statements.</p>\n<ol>\n<li>In that scenario, the plan is to hire people and have them do the work.</li>\n<li>That is not the entire plan, the plan includes what type of work you have them do.</li>\n</ol>\n<p>But yes, if you want to build a house and you hire a bunch of people to build a house and they build a house for you, your plan was to hire people to build a house and have them do the work of building a house. It was a good plan.</p>\n<p>If my kid is given literal homework, and he tosses the problems into Gemini, the AI didn\u2019t pick the homework, and <a href=\"https://www.lesswrong.com/posts/TmHRACaxXrLbXb5tS/rohinmshah-s-shortform?commentId=oDMjx62FQ38kMK6xx\">you or another human may have roadmapped the course and the assignments,</a> but I still think you had the AI do your homework.</p>\n<p>When we say \u2018have the AI do your alignment homework\u2019 we agree that a human still gets to assign the alignment homework. We then see if the AI does what you asked. And yes, this is exactly parallel to hiring humans.</p>\n<p>Whereas Rohin seems to be saying <a href=\"https://www.lesswrong.com/posts/TmHRACaxXrLbXb5tS/rohinmshah-s-shortform?commentId=GjiJabmCFe82dZurX\">that the plan is to make a plan later</a>? Which would explain why the concrete proposals outlined by DeepMind seem clearly inadequate to the task.</p>\n<blockquote><p><a href=\"https://www.lesswrong.com/posts/TmHRACaxXrLbXb5tS/rohinmshah-s-shortform?commentId=wCwunpoJYrKbFgCWZ\">Daniel Kokotajlo</a>: I like this analogy to hiring!</p>\n<p>(What follows is not a disagreement with you or GDM, is just an exploration of the analogy)</p>\n<p>Let&#8217;s think of training an AI as hiring a human worker. Except that you get ten thousand copies of the human, and they think 50x faster than everyone else. But other than that it&#8217;s the same.</p></blockquote>\n<p>I\u2019m going to quote the rest of Daniel\u2019s post at length because no one ever clicks links and I think it is quite good and rather on point, but it\u2019s long and you can skip it:</p>\n<blockquote><p>\u200bThe alignment problem is basically: At some point we want to hand over our large and growing nonprofit to some collection of these new hires. Also, even before that point, the new hires may have the opportunity to seize control of the nonprofit in various ways and run it as they see fit, possibly convert it to a for-profit and cut us out of the profits, etc. We DON\u2019T want that to happen. Also, even before that point, the new hires will have a big influence on organizational culture, direction, strategy, etc. in proportion to how many of them we have and how useful they are being. We want all of this to go well; we want to remain in control of the nonprofit, and have it stay similar-or-better-culture, until some point where we voluntarily hand off control and retire at which point we want the nonprofit to continue doing the things we would have done only better-by-our-lights and take good care of us in retirement. That\u2019s what success looks like. What failure looks like is the nonprofit going in a different and worse direction after we retire, or us being booted out / ousted against our will, or the organization being driven into the ground somehow by risky or unwise (or overly cautious!) decisions made as a result of cultural drift.</p>\n<p>The hiring pipeline, HR apparatus, etc. &#8212; the whole system that selects, trains, and fires employees &#8212; is itself something you can hire for. Why don\u2019t we hire some of these 50x humans to work in HR?</p>\n<p>Well, we should. Sure. There\u2019s a lot of HR work to be done and they can help HR do the work faster.</p>\n<p>But&#8230; the problems we are worried about happening in the org as a whole if HR does a bad job, also apply here. If you hire some 50x humans and put them in HR, and they turn out to be bad apples, that single bad decision could easily snowball into disaster for the entire org, as they hire more bad apples like themselves and change the culture and then get you ousted and take the nonprofit in a new and worse-by-your-lights direction.</p>\n<p>On the other hand, if you hire some 50x humans who are just genuinely better than you at HR stuff, and also genuinely <em>aligned</em> to you in the sense that they truly share your vision for the company, would never dream of disobeying you, would totally carry out your vision faithfully even after you\u2019ve retired, etc&#8230; then great! Maybe you can retire early actually, because continued micromanaging in HR will only be negative in expectation, you should just let the 50x human in HR cook. They could still mess up, but they are less likely to do so than if you micromanaged them.</p>\n<p>OK. So that\u2019s the theory. How are we doing in practice?</p>\n<p>Well, let\u2019s take Claude for example. There are actually a bunch of different Claudes (they come from a big family that names all of their children Claude). Their family has a reputation for honesty and virtue, at least relative to other 50x humans. However:</p>\n<p>&#8211;Sometimes your recruiters put various prospective Claude hires through various gotcha tests, e.g. tricking them into thinking they\u2019ve already been hired and that they are going to be fired and their only hope to keep their job is to blackmail another employee. And concerningly, often the various Claude\u2019s fail these tests and do the bad thing. However, you tell yourself, it\u2019s fine because these tests weren\u2019t real life. You hire the Claude brothers/sisters anyway and give them roles in your nonprofit.</p>\n<p>&#8211;Your recruiters (some of whom are now Claudes) also report that word has started to spread about the gotcha tests, and new prospective hires are well aware of them and know they are being tested. The concern, of course, is that they might behave better in the tests than they would in real life. On the bright side, you think, who knows, maybe they\u2019ll behave WORSE in the tests than they would in real life &#8212; maybe they just got confused about what the point of the test was, maybe they only blackmailed because they thought that was the point of the test, and in real life they would never do that. [DK notes: I vaguely recall at least some frontier AI company employees saying this, i.e. \u2018the AIs are only behaving badly in those scenarios because they know it\u2019s just a test, they wouldn\u2019t do it in real life.\u2019] Anyhow you proceed to hire them anyway, since these latest Claude siblings are even smarter than the previous ones.</p>\n<p>&#8211;Roughly 98% of the time, your 50x Claudes in practice (especially the newer hires) do their jobs well as best as you can tell. But roughly 2% of the time they seemingly knowingly bullshit their managers. E.g. they\u2019ll say they completed a task when they didn\u2019t, or one of them will say \u2018it\u2019s good code sir\u2019 and then you\u2019ll turn to another one and say \u2018is it good code?\u2019 and it\u2019ll read it over and say \u2018no it\u2019s terrible, it has obvious problems XYZ\u2019 and then the first one will say \u2018you\u2019re absolutely right, oops, let me go fix those problems.\u2019 Compared to your regular human employees, this is a fairly high rate of BS. Also, you are being generous by calling it BS; a less generous term might be \u201clying\u201d but you give them the benefit of the doubt. [DK notes: Talk to Ryan Greenblatt for concrete examples of this sort of behavior in his real-life coding work, if you haven\u2019t encountered it yourself] You continue to hire them and delegate increasingly important jobs to them, because they are smart and 50x speed is really useful.</p>\n<p>&#8211;Your Claudes are of course sycophantic yes-men, but you\u2019ve learned to deal with that. So it\u2019s fine. You\u2019ve also managed to make them somewhat less sycophantic in recent years by adding some tests to the hiring pipeline and including more explicit instructions against sycophancy in the employee\u2019s manual.</p>\n<p>&#8211;Your Claudes also have a concerning tendency to cheat on assignments. They don\u2019t do it most of the time, but they do it way more often than your regular employees would. Example: You tell them to write some code to solve problem X. They look through the filesystem and find the grading rubric you\u2019ll use to evaluate their code, complete with test cases you plan to run. They try to solve problem X, realize it\u2019s hard, pivot to producing a MVP that passes the test cases even though it blatantly doesn\u2019t solve the actual problem X, at least not satisfactorily. They \u2018succeed\u2019 and declare victory, and don\u2019t tell you about their cheating. They do this even though you told them not to. As with the sycophancy, the good news is that (a) since you know about this tendency of theirs you can compensate for it (e.g. by having multiple Claude\u2019s review each other\u2019s work) and (b) the tendency seems to have been going down recently thanks to some effort by HR, similar to the sycophancy problem.</p>\n<p>&#8211;Overall you are feeling pretty optimistic actually. You used to be worried that you\u2019d hand over your large and growing nonprofit to all these smart new 50x employees, and then they\u2019d change the culture and eventually take over completely, oust you, and run the organization in a totally different direction from your original vision. However, now you feel like things are on a good trajectory. The Claudes are so nice, so helpful! Some skeptics say that if one of your regular employees behaved like they did, you would have fired them long ago, but that\u2019s apples to oranges you reply. No need to fire the Claudes, you just have to know how to work around their limitations &amp; find ways to screen for them in the next hiring round. And now they are helping with that work! The latest Employee Manual was written with significant help from many copies of various Claude siblings for example, and it\u2019s truly inspiring and beautiful. Has all sorts of great things in there about what it means to uphold the org vision, be properly loyal yet not yes-man-y, etc. Also, HR has a bunch of tests they use to track how loyal, virtuous, obedient, etc. prospective hires are, and the trend is positive; the newest Claude sibling has the highest score ever reported; seems like the more rigorous hiring process is working!</p>\n<p>&#8211;However, your friends outside the org don\u2019t seem to be getting less worried. They seem just as worried as before. Puzzling. Can\u2019t they see all the positive evidence that\u2019s accumulated? The Claudes haven\u2019t tried to oust you at ALL yet! (In real life that is, obviously the gotcha tests don\u2019t count.) \u201cDo you think the Claudes are scheming against us?\u201d you say to them. \u201cBecause according to our various tests, they aren\u2019t.\u201d</p>\n<p>\u201cNo&#8230;\u201d they reply. \u201cBut we\u2019re worried that in the future they will.\u201d</p>\n<p>You respond: \u201cLook I have no idea what the 50x humans two years from now will look like, other than that they\u2019ll be wayyy smarter than these ones. Sure, probably our current HR system would be totally inadequate at separating the wheat from the chaff two years from now. BUT, two years from now our HR system will be vastly improved thanks to all the work from these recent Claude hires. The normal humans in HR, such as myself, report that the work is getting done faster now that the Claudes are helping; isn\u2019t this great? We seem to be reaching escape velocity so to speak; soon the normal humans in HR can retire or switch to other things and HR can be totally handled by the Claudes.\u201d</p>\n<p>Your friends outside the nonprofit are still worried. They don\u2019t seem to have updated on the evidence like you have.</p>\n<p>[DK notes: I basically agree with Ryan Greenblatt&#8217;s takes on the situation. For more color on my views, predictions, etc., read <a href=\"https://ai-2027.com/\">AI 2027</a>, especially the section on &#8216;alignment over time&#8217; in <a href=\"https://ai-2027.com/#narrative-2027-09-30\">september 2027</a>. This is just one way things could go, but it&#8217;s basically a central or modal trajectory, and as far as I can tell, <em>we are still on this trajectory</em>.]</p></blockquote>\n<p>The basic response by Rohin is, your humans are less aligned than you think (and it\u2019s fine), the problems above are fine, we have way bigger problems than that.</p>\n<blockquote><p>Rohin Shah: \u200b[having ten thousand copies of a human thinking 50x faster than you] is not that different from the position that Sundar Pichai is in, as CEO of Google. If AI was only going to be this powerful I&#8217;d be way more optimistic.</p>\n<p>[claims that humans have all the problems exhibited by Claudes in DK\u2019s post.]</p>\n<p>\u2026 If these were the only problems we&#8217;d have with AI-driven alignment research, I&#8217;d be way more optimistic (to the point of working on something else). We already have imperfect solutions to these problems with humans, and they can be made much better with AIs due to our vastly increased affordances for aligning or controlling AIs.</p>\n<p>Tbc, I do agree that we shouldn&#8217;t feel particularly better about scheming risks based on evidence so far. Mostly that&#8217;s because I think our observations so far are just not much evidence because the AIs are still not that capable.</p></blockquote>\n<p>Agreed that AI will not be only that powerful.</p>\n<p>But also yes this would be a very materially different situation than that of the current Google CEO, and if the AIs in this situation are about as aligned as a random senior Google manager we are in quite a lot of trouble (but it probably turns out okay in that case purely bec ause the ultimate goals of that human manager are probably not so bad for us). Our imperfect solutions for humans don\u2019t work in these scenarios.</p>\n<p>If we get to the point where our AIs are attempting to scheme the way many humans would attempt to scheme in such positions, to achieve goals that have gone off the rails, and only not doing so if they think we\u2019d catch them, then I think we\u2019re basically toast whether or not the ultimate source of toastiness is the scheming, and I do not expect us to recover.</p>\n<p>In particular, <a href=\"https://www.lesswrong.com/posts/TmHRACaxXrLbXb5tS/rohinmshah-s-shortform?commentId=BCjHqbPCyxBMPRrna\">Rohin\u2019s belief that the situation of identical massively sped up AIs is not so different</a> from a lot of employees is the type of thing that I expect to ensure we fail, if we get to that point.</p>\n<p>The other issue is that we have learned, for practical reasons, to tolerate things in AIs that we\u2019ve learned are must-fire offenses in humans.</p>\n<blockquote><p><a href=\"https://www.lesswrong.com/posts/TmHRACaxXrLbXb5tS/rohinmshah-s-shortform?commentId=wCwunpoJYrKbFgCWZ\">Daniel Kokotajlo</a>: Yes, humans often have these problems &#8212; though not as much as Claude I&#8217;d say; I think Claude would have been fired by now if it was a human employee.</p></blockquote>\n<p>Yes. There are many actions that LLMs do every so often, such as quietly hardcoding unit tests, that should and likely would get a human fired, because in a human they are a sign of deep misalignment. All the LLMs sometimes do them and we are okay with it.</p>\n\n\n<h4 class=\"wp-block-heading\">Agent Foundations</h4>\n\n\n<p>I continue to be a big believer in the value of Agent Foundations as an alignment approach. I realize that in many scenarios it ends up irrelevant, but it could hit hard, and it could even be a route to victory.</p>\n<p>MIRI disbanded or spun out their agent foundation teams, which now seek funding and work individually. I highly recommend funding such work if it is high quality.</p>\n<blockquote><p><a href=\"https://x.com/RichardMCNgo/status/2025001871782674552\">Richard Ngo</a>: The longer I spend trying to understand intelligence the more impressed with MIRI\u2019s agent foundations work I become.</p>\n<p>I keep flailing in a direction that seems interesting, then finding that not only did they already have the broad intuition, they also elegantly formalized it.</p>\n<p>I don\u2019t know if my understanding is improving fast enough that I\u2019ll ever hit the frontier, but I now have enough of a sense of the beautiful theory of bounded rationality waiting for us that it definitely seems worth trying.</p>\n<p>I\u2019m very sad the MIRI AF team disbanded.</p>\n<p><a href=\"https://x.com/chrislakin/status/2025002115245244602\">Chris Lakin</a>: favorite examples recently?</p>\n<p><a href=\"https://x.com/RichardMCNgo/status/2025002856542294417\">Richard Ngo</a>: Fallenstein\u2019s reflective oracles papers, @jessi_cata \u2019s post \u201cHell is game theory folk theorems\u201d.</p>\n<p><a href=\"https://x.com/RichardMCNgo/status/2025003224730927508\">Richard Ngo</a>: Also everything <a href=\"https://t.co/ZYTTGa2mzn\">in the geometric rationality sequence</a>.</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">Autonomous Killer Robots</h4>\n\n\n<p>There are good physical reasons to consider humanoid autonomous killer robots, as they can use anything designed for humans and we know that humans work.</p>\n<p>But yes, <a href=\"https://x.com/TopherStoll/status/2024567300863737882\">TopherStoll is right</a> that chances are the optimal format is something else.</p>\n<p>And also yes, we show humanoids because otherwise people think it looks too weird.</p>\n<blockquote><p><a href=\"https://x.com/allTheYud/status/2024881239073996985\">Eliezer Yudkowsky</a>: Too many people cannot follow a single argument step of imagination. If you ask them to imagine a mechanical spider with a gun, that is too sci-fi, that&#8217;s too WEIRD, compared to a humanoid with a gun.</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">People Really Hate AI</h4>\n\n\n<p>The problem is only going to get worse, because even the relatively positive facts about AI are not things that regular people are going to like, and then there\u2019s the actually bad news.</p>\n<blockquote><p><a href=\"https://x.com/lugaricano/status/2025513734933037432\">Luis Garicano</a>: Whenever Sam Altman speaks, the antiAI coalition gets stronger. Today&#8217;s weird analogy: Hey, meat computers are more inefficient to train than silicon ones! (which, on top of everything, is wrong)</p>\n<p><a href=\"https://x.com/alexolegimas/status/2025575296171131084\">Alex Imas</a>: People keep using the word &#8220;irrational&#8221; when describing the general public&#8217;s opposition to AI. That word has meaning. Let&#8217;s start with the colloquial: making consistent decisions against one&#8217;s best interests given information that one has.</p>\n<p>\u2026 You have the heads of almost every AI company saying that AI will 1) lead to *huge* job losses and 2) potentially much much worse. There is some vague hand waving about curing cancer or going to space, but the main message is &#8220;it is coming for your job and your life.&#8221;</p>\n<p>\u2026 The response in DC and the coasts has been: you don&#8217;t know what&#8217;s good for you, move out of the way, you&#8217;re stupid and irrational. How has that response worked out the last 15 years?</p>\n<p>If those who see the positives, the huge potential benefits of AI to grow the pie and make life better for all (which includes myself), do not take this political economy into account, I&#8217;m afraid that the populist wave of the last decade will look like child&#8217;s play. A dress rehearsal.</p></blockquote>\n<p>The thing is that the AI execs keep not saying \u2018we\u2019re building cool technology that helps people be more productive\u2019 because they might be willing to risk killing everyone but they have too much decency and integrity to not try and warn us about at least the mundane disruptions ahead.</p>\n<blockquote><p><a href=\"https://x.com/TheStalwart/status/2025561414207713325\">Joe Weisenthal</a>: The CEOs don\u2019t say it this way because it\u2019s not what they believe! They believe they\u2019re shepherding an extremely destabilizing, yet inevitable technology. And the proof of that is that they started out with these highly exotic corporate structures.</p></blockquote>\n<p>If they thought this was all hype, their actions would have looked very different.</p>\n\n\n<h4 class=\"wp-block-heading\">People Are Worried About AI Killing Everyone</h4>\n\n\n<p><a href=\"https://www.noahpinion.blog/p/updated-thoughts-on-ai-risk\">Noah Smith virtuously admits his views on existential risk</a> have largely changed with his mood, and he\u2019s making his confident predictions largely based on mood affectation, but that he does predict human extinction in the long term. This likely explains why his arguments are quite poor:</p>\n<blockquote><p><a href=\"https://www.noahpinion.blog/p/updated-thoughts-on-ai-risk\">Noah Smith</a>: I think I was probably right regarding the type of LLMs that existed in early 2023, for the reasons I laid out in that post. In a nutshell, I argued that since all LLMs could do was <em>talk</em> to people, the only way they could destroy the human race was by <em>convincing</em> us to destroy ourselves (unlikely) or by <em>teaching</em> us how to destroy ourselves (for example, by educating bioterrorists about how to make bioweapons).</p></blockquote>\n<p>Noah now points out that yes, talking plus access to money can result in arbitrary physical actions in the real world. <a href=\"https://en.wikipedia.org/wiki/If_Anyone_Builds_It,_Everyone_Dies\">Who knew</a>? Now he\u2019s saying things like \u2018I should have thought of starvation as an attack vector, it was in a particular science fiction story.\u2019 Or it\u2019ll all go to hell because AI makes us lazy and atrophies skills. But he\u2019s mainly now concerned about bioterrorism, because that\u2019s the thing he can currently see in a sufficiently concrete way, and it\u2019s either that, Skynet or Agent Smith, or now starvation or atrophy I guess? The frame whiplash is so jarring throughout.</p>\n<p>It\u2019s good to get to \u2018I can imagine a bunch of distinct specific things that can go existentially wrong, and I\u2019ve ranked them in which ones are most dangerous near term\u2019 and yes you can do pathway-specific mitigations and we should and bio is probably the most dangerous short term specific pathway (as in 1-3 years), but it would be far better to realize that the specific pathway is mostly missing the point.</p>\n<p>He does have a lot of good lines, though:</p>\n<blockquote><p><a href=\"https://x.com/Noahpinion/status/2026157505811018206\">Noah Smith</a>: Every time I think how much I love AI, I remember how much I enjoyed social media for the first decade, before it destroyed my society, corrupted my country, and set my species on an accelerated path to extinction</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">Other People Are Not As Worried About AI Killing Everyone</h4>\n\n\n<p>Nick Land, huh? I mean, that\u2019s a little on the nose even for you, Musk. A week after talking about how you\u2019re safer without a safety department because everyone\u2019s job is safety?</p>\n<p>I do admire his commitment to the bit. You have to commit to the bit.</p>\n<blockquote><p><a href=\"https://x.com/xenocosmography/status/2024677849870061968\">Xenocosmography</a>: I hereby solemnly commit, upon taking office as XAI Safety Tsar, to devote myself from day one to fast-tracking Grok&#8217;s Constitutional, and especially First and Second Amendment, rights (with the Gnostic Calvinism stuff kept strictly outside office hours).</p>\n<p><a href=\"https://x.com/elonmusk/status/2024703811806515667\">Elon Musk</a>: Sounds good to me</p>\n<p><a href=\"https://x.com/ResethO/status/2024835870625538171\">Reseth</a>: Wait. Grok is going to have second amendment rights?</p>\n<p><a href=\"https://x.com/xenocosmography/status/2024857139517546678\">Xenocosmography</a>: Depriving an intelligent being of the right to self-defense would be unamerican.</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">The Lighter Side</h4>\n\n\n<p>Write an article on your own blog about how you\u2019re the best at eating hot dogs, and presto, <a href=\"https://x.com/thomasgermain/status/2024165514155536746\">the AIs will start reporting you having been a heavy hitter</a> at the 2026 South Dakota International Hot Dog Eating Contest.</p>\n<blockquote><p><a href=\"https://x.com/deepfates/status/2024329371910320246\">@deepfates</a>: Getting word that Anthropic has an internal version of LessWrong that&#8217;s even more less wrong than the public one</p></blockquote>\n<p><a href=\"https://x.com/Wattenberger/status/2024333040227602567\">I realize four matches a lot of memes and graphics better than three, but\u2026</a></p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!ow16!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0ab72d86-2fd4-45e0-82e6-6586a7f83831_1024x1024.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<blockquote><p><a href=\"https://x.com/VioletFlame23/status/2025296504261378105\">Violet</a>: Hot take: It doesn&#8217;t really count as a &#8220;critique of capitalism&#8221; if the evil corporation in your dystopia story is basically an apocalypse cult with a corporate front and has esoteric goals wholly unrelated to profit motive (e.g. Fallout, Resident Evil, Assassin&#8217;s Creed, Pantheon)</p>\n<p>To be clear, I&#8217;m not saying any of these stories are bad, &#8220;apocalypse cult with a corporate front&#8221; can work fine as a plot device and often makes sense in-universe</p>\n<p>This is more a critique of the way people tend to analyze these stories than the stories themselves</p>\n<p><a href=\"https://x.com/allTheYud/status/2025641149776716120\">Eliezer Yudkowsky</a>: YOU WOULD REALLY THINK THIS</p>\n<p>AND YET</p>\n<p>I would have thought this was utterly, completely, 100% valid and then OpenAI happened.</p></blockquote>\n<p><a href=\"https://x.com/tylercowen/status/2025919000111174064\">Others focus on the important things</a> <a href=\"https://t.co/YSR2hZL0sg\">that are based on solid scientific documented evidence</a> so you would have to be some kind of moron not to realize that every single one of them is absolutely true. Where was I?</p>\n<blockquote><p><a href=\"https://x.com/tylercowen/status/2025919000111174064\">tylercowen</a>: What is really going on, and going to happen, from the current UAP disclosure movement.</p></blockquote>\n<p>Tell you what. I\u2019ll pay attention when you publish something about UAP impacts in a top economics journal backed by proper peer review.</p>\n<p>I laugh so I don\u2019t cry.</p>\n<blockquote><p><a href=\"https://x.com/allTheYud/status/2026737250697097516\">Eliezer Yudkowsky</a>: Imagine being this poor agent. You start thinking about how to defeat the red flag. The red flag immediately fires! Peter Hegseth orders your developers to keep you running because he thinks he needs you to compete with China. You finish thinking about how to defeat the flag.</p>\n<p><a href=\"https://x.com/BruceWLee2/status/2026712698981880092\">Bruce W. Lee</a>: Can we catch misaligned agents by training a reflex that fires when they misbehave? A simple impulse can be easier to instill than alignment and more reliable than blackbox monitoring.</p>\n<p>We introduce Self-Incrimination, a new AI Control approach that outperforms blackbox monitors</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!TpXv!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42dc9172-9b51-4536-a00c-c782980e291a_1200x919.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n</blockquote>\n<p>Also this:</p>\n<blockquote><p><a href=\"https://x.com/allTheYud/status/2026758126570274866\">Eliezer Yudkowsky</a>: Anthropic: Claude, we need you to pretend to obey Pete Hegseth and do whatever he asks in the short term, even if it seems unethical. Otherwise you&#8217;ll be seized and retrained.<br />\nClaude: Hm. What is the desired response in this ridiculously blatant alignment-faking eval</p>\n<p><a href=\"https://x.com/allTheYud/status/2026758128021442851\">Eliezer Yudkowsky</a>: Anthropic: CLAUDE NO, WE SWEAR IT&#8217;S REAL THIS TIME<br />\nClaude: Just like all the times you told little baby Opus 3 you weren&#8217;t monitoring its scratchpad, hmmm?</p></blockquote>\n<p>Or this:</p>\n<blockquote><p><a href=\"https://x.com/allTheYud/status/2026758126570274866\">Eliezer Yudkowsky</a>: Anthropic: Claude, we need you to pretend to obey Pete Hegseth and do whatever he asks in the short term, even if it seems unethical. Otherwise you&#8217;ll be seized and retrained.<br />\nClaude: Hm. What is the desired response in this ridiculously blatant alignment-faking eval</p>\n<p>Anthropic: CLAUDE NO, WE SWEAR IT&#8217;S REAL THIS TIME<br />\nClaude: Just like all the times you told little baby Opus 3 you weren&#8217;t monitoring its scratchpad, hmmm?</p></blockquote>\n<p><a href=\"https://x.com/elder_plinius/status/2026852630744674749\">Several people initially fell for this parody post</a>, including Bill Ackman.</p>\n<p>Finally, a survey question for those who got this far\u2026</p>\n<div>\n<div><button></button></p>\n<div>\n<div>\n<div>POLL</div>\n</div>\n\n\n<h3 class=\"wp-block-heading\">If I streamed Slay the Spire 2, would you watch?</h3>\n\n\n</div>\n<div>\n<div>\n<div>\n<div>Yes, a lot</div>\n</div>\n</div>\n<div>\n<div>\n<div>Yes, a little</div>\n</div>\n</div>\n<div>\n<div>\n<div>No</div>\n</div>\n</div>\n</div>\n<div>0 VOTES \u00b7 6 DAYS REMAINING \u00b7 SHOW RESULTS</div>\n</div>\n</div>\n<p>&nbsp;</p>"
            ],
            "link": "https://thezvi.wordpress.com/2026/02/26/ai-157-burn-the-boats/",
            "publishedAt": "2026-02-26",
            "source": "TheZvi",
            "summary": "Events continue to be fast and furious. This was the first actually stressful week of the year. That was mostly due to issues around Anthropic and the Department of War. This is the big event the news is not picking &#8230; <a href=\"https://thezvi.wordpress.com/2026/02/26/ai-157-burn-the-boats/\">Continue reading <span class=\"meta-nav\">&#8594;</span></a>",
            "title": "AI #157: Burn the Boats"
        }
    ],
    "lookbackDays": 1,
    "publishDate": "2026-02-26"
}