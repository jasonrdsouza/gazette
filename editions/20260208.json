{
    "articles": [
        {
            "content": [
                "<h1>Eight more months of agents</h1>\n\n<p><em>2026-02-08</em></p>\n\n<p>I wrote up my experiences programming with LLMs <a href=\"https://crawshaw.io/blog/programming-with-llms\">a bit over a year ago</a>, and updated it for the world of agents <a href=\"https://crawshaw.io/blog/programming-with-agents\">eight months ago</a>. A lot has changed since then, so here is an update.</p>\n\n<h2>Agents have improved dramatically in a year</h2>\n\n<p>We were prototyping our first agent, Sketch, when Claude Code was released 12 months ago. So I, by good fortune, got to be there and be excited right at the beginning. They could be helpful for some things some of the time!</p>\n\n<p>Agent harnesses have not improved much since then. There are things Sketch could do well six months ago that the most popular agents cannot do today. The agent harness is critical, there is plenty of innovation to be done there, but it is as interesting a space right now as compiler optimizations were during the megahertz explosion of the 1990s.</p>\n\n<p>Right now, it is all about the model.</p>\n\n<p>And on the models: there are plenty of public benchmarks but they have all been gamed to death. Ignore them. Clearly the frontier model companies have good internal evals, because the models have qualitatively changed dramatically. In February last year, Claude Code could write a quarter of my code. In February this year, the latest Opus model can write nine tenths of my code. It all needs to be carefully read, and regularly adjusted, but now I can and do rely on the model to do the adjustments for me.</p>\n\n<p>There has been no obvious change in models. Nothing like when GPT2 started talking back. There has however, clearly been a huge incremental improvement in the ability of coding models to get to useful results. (All of this, admittedly qualitative, progress is the most positive economic signal I see today.)</p>\n\n<p>At a big company, my time was 80-20 reading code to writing code. At a startup, it used to be closer to 50-50. Now it is 95-5.</p>\n\n<h2>IDEs are clearly waning</h2>\n\n<p>The history of IDEs is so strange.</p>\n\n<p>On the one hand, the IDE is obviously correct. Of course I should have a development environment that provides as much information and assistance as I can effectively use. By far the greatest IDE I have ever used was Visual Studio C++ 6.0 on Windows 2000. I have never felt like a toolchain was so complete and consistent with its environment as there.</p>\n\n<p>Since those glorious moments in 1999, I have spent more of my programming life outside of IDEs than in them. The truth of programming environments is they are a hot mess. Unix was great, the Howl's Moving Castle we have bolted onto an over-taxed set of Unix concepts, not so much. The same thing happened to that win32 API I used to use in VS6.0, still there, with a giant mess atop and around it and entirely unignorable.</p>\n\n<p>Then co-pilot came out and it seemed the IDE was inevitable. It did not matter how miserable it was trying to fit your IDE into your environment, you had to do the work because LLM-assisted auto-complete and edit were too powerful to ignore. They made my typing go 50% further and a large amount of the programming I do is typing limited, so the effect was enormous.</p>\n\n<p>In 2021, the IDE had won.</p>\n\n<p>In 2026, I don't use an IDE any more.</p>\n\n<p>The degree of certainty I felt about a copilot future, and the astonishing whiplash as agents gave me a better tool not four years later still surprises me.</p>\n\n<p>The only IDE-like feature I use today is go-to-def, which neovim is capable of with little configuration. So here I am, 2026, and I am back on Vi.</p>\n\n<p>Vi is turning 50 this year.</p>\n\n<h2>Using anything other than the frontier models is actively harmful</h2>\n\n<p>A huge part of working with agents is discovering their limits. The limits keep moving right now, which means constant re-learning. But if you try some penny-saving cheap model like Sonnet, or a second rate local model, you do worse than waste your time, <em>you learn the wrong lessons</em>.</p>\n\n<p>I want local models to succeed more than anyone. I found LLMs entirely uninteresting until the day mixtral came out and I was able to get it kinda-sorta working locally on a very expensive machine. The moment I held one of these I finally appreciated it. And I know local models will win. At some point frontier models will face diminishing returns, local models will catch up, and we will be done being beholden to frontier models. That will be a wonderful day, but until then, you will not know what models will be capable of unless you use the best. Pay through the nose for Opus or GPT-7.9-xhigh-with-cheese. Don't worry, it's only for a few years.</p>\n\n<h2>Built-in agent sandboxes do not work</h2>\n\n<p>The constant stream of \"may I run <code>cat foo.txt</code>?\" from Claude Code and \"I tried but cannot <code>go build</code> in my very-sophisticated sandbox\" from Codex is a nightmare. You have to turn off the sandbox, which means you have to provide your own sandbox. I have tried just about everything and I highly recommend: use a fresh VM.</p>\n\n<h2>I have far more programs and services than I used to</h2>\n\n<p>This is why I am building <a href=\"https://exe.dev\">exe.dev</a>. I need a VM, with an unconstrained agent, that I can trivially start up and type the one liner I would have otherwise put into an Apple Note named TODO and forgotten about. A good portion of the time Shelley turns a one-liner into a useful program.</p>\n\n<p>I am having more fun programming than I ever have, because so many more of the programs I wish I could find the time to write actually exist. I wish I could share this joy with the people who are fearful about the changes agents are bringing. The fear itself I understand, I have fear more broadly about what the end-game is for intelligence on tap in our society. But in the limited domain of writing computer programs these tools have brought so much exploration and joy to my work.</p>\n\n<h2>I am extremely out of touch with anti-LLM arguments</h2>\n\n<p>New technology brings a lot of challenges and reasonable concerns. I spend my days trying to push the limits of agents, so I see them fail catastrophically several times a week. Significant change also changes labor markets which has many effects, good and bad. In 1900, 33% of Americans lived on a farm, and 40% worked in agriculture. In 2000, less than one percent lived on farms and 1% of workers are in agriculture. That was a net benefit to the world, that we all don't have to work to eat. (The numbers are even more dramatic if you go back another century.) But a lot of pain and heartbreak can and did happen along the way. It is right to be concerned.</p>\n\n<p>But far more than measured analyses of the reality of the changes that are happening, I see hard anti-LLM takes that a year ago I disagreed with, and now I just cannot understand. It sounds like someone saying power tools should be outlawed in carpentry. I deeply appreciate hand-tool carpentry and mastery of the art, but people need houses and framing teams should obviously have skillsaws. To me that statement is as obvious as \"water is wet\".</p>\n\n<h2>A lot has to change</h2>\n\n<p>Most software is the wrong shape now. Most of the ways we try to solve problems are the wrong shape.</p>\n\n<p>To give you an example, consider Stripe Sigma. This product is a nice new SQL query system for your Stripe DB. It has a little LLM built into it to help you write queries. The LLM is not very good. I want Claude Code or Codex writing my queries. But Stripe launched a fancy Sigma UI with an integrated helper <em>before</em> their API. There is a private alpha for the SQL REST endpoint that I do not have access to yet. So instead I had my agent do ETL-from-scratch: it used the standard Stripe APIs to query everything about my account, build a local SQLite DB, and now my agent queries against that far better than Sigma can.</p>\n\n<p>I implemented that entire Stripe product (as it relates to me) by typing three sentences. It solves my problem better than their product.</p>\n\n<p>That's the world we are in today. By far the worst product I had to use every day in this new world were clouds, so that's what I'm building over at <a href=\"https://exe.dev\">exe.dev</a>. It's a lot harder than it looks, but the entire point of the product is you should never feel that your agent should rewrite part of it for you.</p>\n\n<p>Along the way I have developed a programming philosophy I now apply to everything: <strong>the best software for an agent is whatever is best for a programmer</strong>. The practical nature of writing software for customers has traditionally pushed us away from that philosophy. Product Managers have long had to find gentle ways to tell engineers: you are not the customer. Well, that has all been turned on its head. Every customer has an agent that will write code against your product for them. Build what programmers love and everyone will follow.</p>\n\n<p>Hopefully that philosophy will survive the next year of changes wrought by LLMs.</p>"
            ],
            "link": "https://crawshaw.io/blog/eight-more-months-of-agents",
            "publishedAt": "2026-02-08",
            "source": "David Crawshaw",
            "summary": "<h1>Eight more months of agents</h1> <p><em>2026-02-08</em></p> <p>I wrote up my experiences programming with LLMs <a href=\"https://crawshaw.io/blog/programming-with-llms\">a bit over a year ago</a>, and updated it for the world of agents <a href=\"https://crawshaw.io/blog/programming-with-agents\">eight months ago</a>. A lot has changed since then, so here is an update.</p> <h2>Agents have improved dramatically in a year</h2> <p>We were prototyping our first agent, Sketch, when Claude Code was released 12 months ago. So I, by good fortune, got to be there and be excited right at the beginning. They could be helpful for some things some of the time!</p> <p>Agent harnesses have not improved much since then. There are things Sketch could do well six months ago that the most popular agents cannot do today. The agent harness is critical, there is plenty of innovation to be done there, but it is as interesting a space right now as compiler optimizations were during the megahertz explosion of the 1990s.</p> <p>Right now, it is all about the model.</p> <p>And on the models: there are plenty of public benchmarks but they have all been gamed to death. Ignore them. Clearly the frontier model companies have good internal evals, because the models have qualitatively changed dramatically. In February last",
            "title": "Eight more months of agents"
        },
        {
            "content": [
                "<h1>Every Man a Microservice</h1>\n<blockquote>\n<p>Organizations which design systems are constrained to produce designs which are copies of the communication structures of these organizations.</p>\n<p>\u2014\u200aMelvin E. Conway, How Do Committees Invent?</p>\n</blockquote>\n<p>Conway's law appears true if you observe organizations and systems as they are, <strong>but the causality is reversed</strong>.</p>\n<p>Systems are not <em>conceived</em> by organizations, but by a single individual or a tight-knit cabal.</p>\n<p>As such, there is no communication structure to emulate. The initial idea is conjured as a gestalt and an organization <em>is built around</em> the system as it comes into existence and operates.</p>\n<p><strong>And thus we invert Conway's law</strong>: A system's design informs the communication structure of the organization that is built around it.</p>\n<p>With this in mind, we can ask: what design facilitates the most effective organization?</p>\n<p>There's a whole landscape of solutions here, but I just want to focus on one that I saw work <em>extremely</em> well in the earlier years of AWS.</p>\n<h3>The right way</h3>\n<p>The idea is your system is made up of person-sized services. A person-sized service is one whose codebase is in the realm of a few tens of thousands of lines of code.</p>\n<p>This scale is such that a single developer, working on that codebase full-time, can keep the whole codebase in their head.</p>\n<p><em>N.B. By \"codebase in head\" I don't mean they literally know every line of code. I mean they have a complete picture of all the modules, interfaces, data structures, scaling dimensions, tradeoffs, design decisions, etc.</em></p>\n<p>You want there to be a 1-to-1 mapping between each service and an individual who has that service's code completely loaded into their brain.</p>\n<p>The advantages of having the whole service loaded into an individual brain is hard to overstate.</p>\n<p><strong>It enables a ton of offline mulling</strong>. Your devs know their domain so well, they'll have regular shower-thoughts about how to optimize their service.</p>\n<p><strong>You reach consensus on improvements faster</strong>. Alice has an idea in a shower. She wants Bob's system to start batching requests to hers to improve her cache hit ratio. She tells Bob the idea in the morning. Bob calls over Charlie, whose service would also be affected. In 20 minutes they agree on a path forward. The code is shipped after lunch.</p>\n<p><strong>You actually have fewer outages and issues</strong>. You might think an organization that designs features in 20 minutes and ships them after lunch is going to break things by moving so fast. But in practice, a single engineer with 100% context will anticipate and design around issues better than a design review by a whole team of devs who each have 50% context.</p>\n<p><strong>Quality goes up</strong>. Each owner has a narrative for the health of their codebase: aspirations for future improvements, haunted by lingering jank. They take this holistic view into account when considering all ideas. They have the familiarity needed to do deep, refactoring integrations, but also to safely add hacks when the business needs it.</p>\n<p><strong>Architectural changes are politically manageable</strong>. It's much easier for technical management (i.e. principal engineers) to rearchitect the system, because individual devs have essentially no political power or desire for such. They won't defend their service if it becomes vestigial as long as you give them something else to own.</p>\n<p><strong>Engineers develop faster</strong>. Take a college-hire and give them one of the smaller services. Tell them \"this service is yours, and you are this service, you are one\". This is a sink-or-swim tactic, but a good one. Engineers that can't take individual ownership are toxic to the long-term health of the org. Those that can have a much higher likelihood of evolving into high-value <a href=\"https://blog.sbensu.com/posts/lieutenants/\">lieutenants</a>.</p>\n<h3>The wrong way</h3>\n<p>If you've worked at a traditional company, you've probably seen the inverse of all this. Services aren't owned by individuals, but by whole teams. A team of 8 people might own 3 services. Everyone is kind of vaguely familiar with all of them, but nobody is a master of any one.</p>\n<p>Because nobody is a master, people will tend to implement changes in a purely accretive way. They're afraid to do deeper refactors to integrate changes more holistically.</p>\n<p>And for good reason! When they attempt such deeper refactors without a complete understanding of the service they're operating on, they're stumbling in the dark and cause outages. They do design reviews with the team to try to mitigate this, but nobody knows enough to contribute more than surface-level concerns.</p>\n<p>Managers in charge of teams will resist deprecation of the services their team owns. Not only will they do this, but they will actually invent new services that don't need to exist to justify increasing their headcount (which increases their status).</p>\n<h3>Risks</h3>\n<p><strong>What happens when the owner of a system gets hit by a bus?</strong> Or, less dramatically, leaves the company.</p>\n<p>In practice, engineers in such an org don't <em>only</em> have context on their single service. They'll typically have a decent amount of context on the services theirs touches, and vice versa. After all, who is doing code reviews for whom?</p>\n<p>Most of the devs who've been around for a while will have owned a few different services at different points in their career. When they joined as a college-hire, they were given a tiny metadata caching service. Then someone left and they were given that guy's medium-sized service. Then they had an idea for a brand new system, built it, and now own it as a senior engineer.</p>\n<p>The effect is a senior engineer in the org will have somewhat-stale but easily-refreshable context on a handful of services. It's like riding a bike. This is useful both for bus-factor situations, and also mentoring the juniors who own those services.</p>\n<p>So in a bus-factor situation, there are usually enough seniors around who can keep the lights on until a new owner is found. And in this kind of org, you'll always have a cohort of bright up-and-coming juniors who passed the sink-or-swim test and are ready to take ownership of a bigger service.</p>\n<p><strong>How to manage such an org?</strong> That is, what is the place for managers in this brave world?</p>\n<p>Such a system only needs a few managers, because it won't have <em>that</em> many engineers. It won't have that many engineers because there simply don't exist very many systems that <em>need</em> that many services.</p>\n<p>For context, <a href=\"https://en.wikipedia.org/wiki/Amazon_S3\">AWS S3</a> was built and operated by fewer than 20 engineers in the early years. And if you were to design a storage service on a whiteboard, you might find yourself with 20 or so boxes. There's the storage node, the webserver, the caching layer, the index, the corruption scanner, etc etc etc. It all adds up. Almost no system needs more than a few dozen boxes on the whiteboard.</p>\n<p>In such a world, you only need a handful of managers, and you definitely don't need many layers of management. You want the person in charge of the whole org, a small handful of managers, and then all the engineers.</p>\n<p>The person in charge of the whole org should rely on senior technical <a href=\"https://blog.sbensu.com/posts/lieutenants/\">lieutenants</a> as much as (and perhaps more than) management to maintain visibility.</p>"
            ],
            "link": "https://grantslatton.com/every-man-a-microservice",
            "publishedAt": "2026-02-08",
            "source": "Grant Slatton",
            "summary": "<h1>Every Man a Microservice</h1> <blockquote> <p>Organizations which design systems are constrained to produce designs which are copies of the communication structures of these organizations.</p> <p>\u2014 Melvin E. Conway, How Do Committees Invent?</p> </blockquote> <p>Conway's law appears true if you observe organizations and systems as they are, <strong>but the causality is reversed</strong>.</p> <p>Systems are not <em>conceived</em> by organizations, but by a single individual or a tight-knit cabal.</p> <p>As such, there is no communication structure to emulate. The initial idea is conjured as a gestalt and an organization <em>is built around</em> the system as it comes into existence and operates.</p> <p><strong>And thus we invert Conway's law</strong>: A system's design informs the communication structure of the organization that is built around it.</p> <p>With this in mind, we can ask: what design facilitates the most effective organization?</p> <p>There's a whole landscape of solutions here, but I just want to focus on one that I saw work <em>extremely</em> well in the earlier years of AWS.</p> <h3>The right way</h3> <p>The idea is your system is made up of person-sized services. A person-sized service is one whose codebase is in the realm of a few tens of thousands of lines of code.</p> <p>This scale is such that",
            "title": "Every Man a Microservice"
        },
        {
            "content": [
                "<p>Large tech companies operate via <em>systems</em>. What that means is that the main outcomes - up to and including the overall success or failure of the company - are driven by a complex network of processes and incentives. These systems are outside the control of any particular person. Like the parts of a large codebase, they have accumulated and co-evolved over time, instead of being designed from scratch.</p>\n<p>Some of these processes and incentives are \u201clegible\u201d, like OKRs or promotion criteria. Others are \u201cillegible\u201d, like the backchannel conversations that usually precede a formal consensus on decisions<sup id=\"fnref-1\"><a class=\"footnote-ref\" href=\"https://www.seangoedecke.com/rss.xml#fn-1\">1</a></sup>. But either way, <strong>it is these processes and incentives that determine what happens, not any individual heroics</strong>.</p>\n<h3>How heroes are forged in large tech companies</h3>\n<p>This state of affairs is not efficient at producing good software. In large tech companies, good software often seems like it is produced <em>by accident</em>, as a by-product of individual people responding to their incentives. However, that\u2019s just the way it has to be. A shared belief in the mission can cause a small group of people to prioritize good software over their individual benefit, for a little while. But thousands of engineers can\u2019t do that for decades. Past a certain point of scale<sup id=\"fnref-2\"><a class=\"footnote-ref\" href=\"https://www.seangoedecke.com/rss.xml#fn-2\">2</a></sup>, companies must depend on the strength of their systems.</p>\n<p>Individual engineers often react to this fact with horror. After all, <em>they</em> want to produce high-quality software. Why is everyone around them just cynically<sup id=\"fnref-3\"><a class=\"footnote-ref\" href=\"https://www.seangoedecke.com/rss.xml#fn-3\">3</a></sup> focused on their own careers? On top of that, many software engineers got into the industry because they are internally compelled<sup id=\"fnref-4\"><a class=\"footnote-ref\" href=\"https://www.seangoedecke.com/rss.xml#fn-4\">4</a></sup> to make systems more efficient. For these people, it is viscerally uncomfortable being employed in an inefficient company. They are thus prepared to do <em>whatever it takes</em> to patch up their system\u2019s local inefficiencies.</p>\n<p>Of course, making your team more effective does not always require heroics. Some amount of fixing inefficiencies - improving process, writing tests, cleaning up old code - is just part of the job, and will get engineers rewarded and promoted just like any other kind of engineering work. But there\u2019s a line. Past a certain point, working on efficiency-related stuff instead of your actual projects will get you punished, not rewarded. To go over that line requires someone willing to sacrifice their own career progression in the name of good engineering. In other words, it requires a <em>hero</em>.</p>\n<h3>Large tech companies do not benefit from heroes</h3>\n<p>You can sacrifice your promotions and bonuses to make one tiny corner of the company hum along nicely for a while. However, like I said above, the overall trajectory of the company is almost never determined by one person. It doesn\u2019t really matter how efficient you made some corner of the <a href=\"https://en.wikipedia.org/wiki/Google_Wave\">Google Wave</a> team if the whole product was doomed. And even poorly-run software teams can often win, so long as they\u2019re targeting some niche that the company is set up to support (think about the quality of most profitable enterprise software).</p>\n<p>On top of that, <strong>heroism makes it difficult for real change to happen</strong>. If a company is set up to reward bad work and punish good work, having some hero step up to do good work anyway and be punished <em>will only insulate the company from the consequences of its own systems</em>. Far better to let the company be punished for its failings, so it can (slowly, slowly) adjust, or be replaced by companies that operate better.</p>\n<h3>\u2026but will exploit them</h3>\n<p>Large tech companies don\u2019t benefit long-term from heroes, but there\u2019s still a role for heroes. That role is <em>to be exploited</em>. There are no shortage of <a href=\"https://www.seangoedecke.com/predators\">predators</a> who will happily recruit a hero for some short-term advantage.</p>\n<p>Some product managers keep a mental list of engineers in other teams who are \u201ceasy targets\u201d: who can be convinced to do extra work on projects that benefit the product manager (but not that engineer). During high-intensity periods, such as the lead-up to a major launch, there is sometimes a kind of cold war between different product organizations, as they try to extract behind-the-scenes help from the engineers in each other\u2019s camps while jealously guarding their own engineering resources.</p>\n<p>Likewise, some managers have no problem letting one of their engineers spend all their time on <a href=\"https://www.seangoedecke.com/glue-work-considered-harmful\">glue work</a>. Much of that work would otherwise be the manager\u2019s responsibility, so it makes the manager\u2019s job easier. Of course, when it comes time for promotions, the engineer will be punished for not doing their real work.</p>\n<p>This is why it\u2019s important for engineers to pay attention to their <em>actual</em> rewards. Promotions, bonuses and raises are the hard currency of software companies. Giving those out shows what the company really values. Predators don\u2019t control those things (if they did, they wouldn\u2019t be predators). As a substitute, they attempt to appeal to a hero\u2019s internal compulsion to be useful or to clean up inefficiencies.</p>\n<h3>Summary</h3>\n<ul>\n<li>\n<p>Large tech companies are structurally set up to encourage software engineers to engage in heroics</p>\n<ul>\n<li>This is largely accidental, and doesn\u2019t really benefit those tech companies in the long term, since large tech companies are just too large to be meaningfully moved by individual heroics</li>\n<li>However, individual managers and product managers inside these tech companies have learned to exploit this surplus heroism for their individual ends</li>\n</ul>\n</li>\n<li>As a software engineer, you should resist the urge to heroically patch some obvious inefficiency you see in the organization</li>\n<li>Unless that work is explicitly rewarded by the company, all your efforts will do is delay the point at which the company has to change its processes</li>\n<li>\n<p>A background level of inefficiency is just part of the landscape of large tech companies</p>\n<ul>\n<li>It\u2019s the price they pay to be so large (and in return reap the benefits of scale and <a href=\"https://www.seangoedecke.com/seeing-like-a-software-company\">legibility</a>)</li>\n<li>The more you can learn to live with it, the more you\u2019ll be able to use your energy tactically for your own benefit</li>\n</ul>\n</li>\n</ul>\n<div class=\"footnotes\">\n<hr />\n<ol>\n<li id=\"fn-1\">\n<p>I write about this point at length in <a href=\"https://www.seangoedecke.com/seeing-like-a-software-company\"><em>Seeing like a software company</em></a>.</p>\n<a class=\"footnote-backref\" href=\"https://www.seangoedecke.com/rss.xml#fnref-1\">\u21a9</a>\n</li>\n<li id=\"fn-2\">\n<p>Why do companies need to scale, if it means they become less efficient? The best piece on this is Dan Luu\u2019s <a href=\"https://danluu.com/sounds-easy/\"><em>I could build that in a weekend!</em></a>: in short, because the value of marginal features in a successful software product is surprisingly high, and you need a lot of developers to capture all the marginal features.</p>\n<a class=\"footnote-backref\" href=\"https://www.seangoedecke.com/rss.xml#fnref-2\">\u21a9</a>\n</li>\n<li id=\"fn-3\">\n<p>For a post on why this is not actually that cynical, see my <a href=\"https://www.seangoedecke.com/a-little-bit-cynical/\"><em>Software engineers should be a little bit cynical</em></a>.</p>\n<a class=\"footnote-backref\" href=\"https://www.seangoedecke.com/rss.xml#fnref-3\">\u21a9</a>\n</li>\n<li id=\"fn-4\">\n<p>I write about these internal compulsions in <a href=\"https://www.seangoedecke.com/addicted-to-being-useful\"><em>I\u2019m addicted to being useful</em></a>.</p>\n<a class=\"footnote-backref\" href=\"https://www.seangoedecke.com/rss.xml#fnref-4\">\u21a9</a>\n</li>\n</ol>\n</div>"
            ],
            "link": "https://seangoedecke.com/heroism/",
            "publishedAt": "2026-02-08",
            "source": "Sean Goedecke",
            "summary": "<p>Large tech companies operate via <em>systems</em>. What that means is that the main outcomes - up to and including the overall success or failure of the company - are driven by a complex network of processes and incentives. These systems are outside the control of any particular person. Like the parts of a large codebase, they have accumulated and co-evolved over time, instead of being designed from scratch.</p> <p>Some of these processes and incentives are \u201clegible\u201d, like OKRs or promotion criteria. Others are \u201cillegible\u201d, like the backchannel conversations that usually precede a formal consensus on decisions<sup id=\"fnref-1\"><a class=\"footnote-ref\" href=\"https://www.seangoedecke.com/rss.xml#fn-1\">1</a></sup>. But either way, <strong>it is these processes and incentives that determine what happens, not any individual heroics</strong>.</p> <h3>How heroes are forged in large tech companies</h3> <p>This state of affairs is not efficient at producing good software. In large tech companies, good software often seems like it is produced <em>by accident</em>, as a by-product of individual people responding to their incentives. However, that\u2019s just the way it has to be. A shared belief in the mission can cause a small group of people to prioritize good software over their individual benefit, for a little while. But thousands of engineers can\u2019t do that",
            "title": "Large tech companies don't need heroes"
        }
    ],
    "lookbackDays": 1,
    "publishDate": "2026-02-08"
}