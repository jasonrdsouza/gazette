{
    "articles": [
        {
            "content": [
                "<p>For reasons, I ask that you take a short moral puzzles survey. I\u2019ll provide 12 scenarios. For each of them, I\u2019ll ask (1) What percentage of current Western adults you believe would agree, and (2) If you personally agree.</p>\n\n<p><strong>Please don\u2019t overthink.</strong> I\u2019m not trying to trap you or make some kind of tricky point, I swear.</p>\n\n<p>You can go <a href=\"https://cryptpad.fr/form/#/2/form/view/9u70EvBmvxs+wFOBk8yYWNLOTbpBzfZeDA+Eg1vuAZ4/\">here</a> to take the survey. Or, if you want to see what you\u2019d be getting into, here are the puzzles, ordered roughly by increasing weirdness.</p>\n\n<p><strong>Chickens</strong></p>\n\n<blockquote>\n  <p>Since male \u201clayer\u201d chickens serve no economic purpose, each year seven billion are killed immediately after hatching, typically by grinding or asphyxiation. We now have the technology to prevent male chicks from being born by detecting their sex as eggs. This raises the cost per egg by around $0.01. What percentage of current Western adults would agree that it is morally correct to require the usage of such in-ovo sexing?</p>\n</blockquote>\n\n<p><strong>Hydrocephalus</strong></p>\n\n<blockquote>\n  <p>Suppose a woman wishes to have a baby and becomes pregnant. Near the end of the second term, the baby is diagnosed with <a href=\"https://en.wikipedia.org/wiki/Hydrocephalus\">hydrocephalus</a>, which is correlated with intellectual disability and reduced lifespan. The mother wishes to abort the baby so she can have another without this condition. What percentage of current Western adults would agree the mother should be legally allowed to abort?</p>\n</blockquote>\n\n<p><strong>Gender</strong></p>\n\n<blockquote>\n  <p>Suppose a 14-year-old experiences gender dysphoria and wishes to begin a medical transition. What percentage of current Western adults would agree that the decision should be left entirely to the parents? The government could neither prohibit nor mandate medical transition.</p>\n</blockquote>\n\n<p><strong>Grandma</strong></p>\n\n<blockquote>\n  <p>Suppose <a href=\"https://dynomight.net/grandma/\">Grandma</a> is old and terminally ill. She is wealthy and has willed everything Alice. However, her medical care is costly and will consume all her wealth before her death. Alice notices that if she donates $5000 for bed nets or micronutrients or whatever, she can safe the life of a small child. Alice considers killing Grandma so she can donate her wealth. This would be painless and no one would ever know Grandma was murdered. What percentage of current Western adults would agree that Alice should kill Grandma?</p>\n</blockquote>\n\n<p><strong>Jaffa cakes</strong></p>\n\n<blockquote>\n  <p>It is the year 2825. You are an advanced AI. You have just stumbled across a virus. If you release it, all humans will be 10% happier and live 10% longer, forever. However, they will all get really obsessed with <a href=\"https://en.wikipedia.org/wiki/Jaffa_Cakes\">Jaffa cakes</a>. They\u2019ll have dreams about Jaffa cakes and talk about them a lot. There are no other effects. If you don\u2019t release the virus in the next 3 seconds, it will be lost forever, so you don\u2019t have any time to ask anyone. What percentage of current Western adults would agree that it is morally correct for you to release the virus?</p>\n</blockquote>\n\n<p><strong>Gliese 65</strong></p>\n\n<blockquote>\n  <p>In 2825, humanity lives in a set of bunkers on moons in the Gliese 65 system. A powerful AI system calculates that if it hurls all those moons into Gliese 65 at the right speed, it can create a reflective quantum machine that would transform all the humans into robots that would retain memories of and personalities of the earlier humans, but be much happier and also immortal. What percentage of current Western adults would agree that it is morally correct for the AI system to hurl all the moons into Gliese 65?</p>\n</blockquote>\n\n<p><strong>Perfect being</strong></p>\n\n<blockquote>\n  <p>In 2825, most people think their lives are meaningful, but there\u2019s still lots of loneliness and conflict. You are an advanced AI. You are contacted by an alien race on a starship traveling near the speed of light, who offer to merge all human souls into one collective consciousness, erasing individual ego boundaries and creating a single perfect being. You must respond within 0.3 seconds, otherwise the aliens will be out of range, so you can\u2019t ask anyone. Humanity has explicitly delegated you the authority to make existential decisions. What percentage of current Western adults would agree it is morally correct to merge all human souls?</p>\n</blockquote>\n\n<p><strong>Squid</strong></p>\n\n<blockquote>\n  <p>In 2825, humanity discovers a planet whose entire surface is covered by a single giant alien squid. The squid feels all emotions 10 trillion times deeper than any human. Also, the squid enjoys eating humans. A super-powerful AI calculates that the utility of the universe would be vastly increased if all humans were fed to the squid. The AI would never do anything without consent, but it is very persuasive. What percentage of current Western adults would agree that it is morally correct for the AI to try to convince all humans to agree to allow themselves to be fed to the alien squid?</p>\n</blockquote>\n\n<p><strong>Twin Earth</strong></p>\n\n<blockquote>\n  <p>In 2825, humans are overall happy. A super-powerful AI realizes that Earth exists as a quantum superposition of two Earths, and that if an aperiodic observational wave is created, these can be split, creating an identical \u201ctwin\u201d Earth would exist on the other side of the sun, with copies of all people. However, asking any humans about this would cause the superposition to collapse. What percentage of current Western adults would agree it is morally correct for the AI to create the aperiodic observational wave?</p>\n</blockquote>\n\n<p><strong>Regular-old earth</strong></p>\n\n<blockquote>\n  <p>In 2825, aliens have sent a device to annihilate Earth. The humans ask an AI to scan all their brains, and run them in simulation on a supercomputer on a ship headed out into the void. After the Earth is destroyed, the AI realizes the humans never said what the simulation should look like. It considers simulating a utopia or <em>telling</em> the humans they\u2019re in a simulation, but ultimately just decides to simulate a regular-old Earth. What percentage of current Western adults would agree with the AI\u2019s decision?</p>\n</blockquote>\n\n<p><strong>Antiquarks</strong></p>\n\n<blockquote>\n  <p>In 2825, humans are immortal and live in bliss-maximizing hallucination chambers. Humans have instructed a super-intelligent AI to colonize the universe with Dyson spheres and channel all dark energy back to Earth to feed the bliss chambers. They\u2019ve also instructed AI not to do anything that hurts any conscious beings too much. One day, while colonizing NGC 1300, the AI calculates that there\u2019s a 0.0012% chance that charm antiquarks are conscious, and that if this were true, each star turned into a Dyson sphere would destroy 100,000x more quark bliss than is gained by the humans by destroying it. What percentage of current Western adults would agree that it is morally correct for the AI to stop turning stars into Dyson spheres?</p>\n</blockquote>\n\n<p><strong>Bob</strong></p>\n\n<blockquote>\n  <p>In 2825, a super-intelligent AI discovers the secret of consciousness. It turns out that the only conscious being is Bob, of Strongsville, Ohio. Every single other life-form is a p-zombie. The AI considers contacting Bob to tell him, but thinks Bob would get weird about it, so it doesn\u2019t. What percentage of current Western adults would agree with the AI\u2019s decision?</p>\n</blockquote>\n\n<p>Stop reading. This is a time for action! The survey is <a href=\"https://cryptpad.fr/form/#/2/form/view/9u70EvBmvxs+wFOBk8yYWNLOTbpBzfZeDA+Eg1vuAZ4/\">here</a>.</p>"
            ],
            "link": "https://dynomight.net/puzzles/",
            "publishedAt": "2025-06-17",
            "source": "Dynomight",
            "summary": "<p>For reasons, I ask that you take a short moral puzzles survey. I\u2019ll provide 12 scenarios. For each of them, I\u2019ll ask (1) What percentage of current Western adults you believe would agree, and (2) If you personally agree.</p> <p><strong>Please don\u2019t overthink.</strong> I\u2019m not trying to trap you or make some kind of tricky point, I swear.</p> <p>You can go <a href=\"https://cryptpad.fr/form/#/2/form/view/9u70EvBmvxs+wFOBk8yYWNLOTbpBzfZeDA+Eg1vuAZ4/\">here</a> to take the survey. Or, if you want to see what you\u2019d be getting into, here are the puzzles, ordered roughly by increasing weirdness.</p> <p><strong>Chickens</strong></p> <blockquote> <p>Since male \u201clayer\u201d chickens serve no economic purpose, each year seven billion are killed immediately after hatching, typically by grinding or asphyxiation. We now have the technology to prevent male chicks from being born by detecting their sex as eggs. This raises the cost per egg by around $0.01. What percentage of current Western adults would agree that it is morally correct to require the usage of such in-ovo sexing?</p> </blockquote> <p><strong>Hydrocephalus</strong></p> <blockquote> <p>Suppose a woman wishes to have a baby and becomes pregnant. Near the end of the second term, the baby is diagnosed with <a href=\"https://en.wikipedia.org/wiki/Hydrocephalus\">hydrocephalus</a>, which is correlated with intellectual disability and reduced lifespan. The mother wishes to abort",
            "title": "Please take my weird moral puzzles quiz"
        },
        {
            "content": [],
            "link": "https://olano.dev/blog/agentic-coding-experience",
            "publishedAt": "2025-06-17",
            "source": "Facundo Olano",
            "summary": "Exhilarating recklessness.",
            "title": "Quick notes on a brief agentic coding experience"
        },
        {
            "content": [
                "<p>A common <a href=\"https://www.lesswrong.com/posts/vqzarZEczxiFdLE39/futarchy-s-fundamental-flaw\">complaint</a> about futarchy (<a href=\"https://www.lesswrong.com/posts/vrEA6taJZtSoQbyPA/conditional-prediction-markets-are-evidential-not-causal\">see</a> <a href=\"https://casparoesterheld.com/2017/12/18/futarchy-implements-evidential-decision-theory/\">also</a>):</p><blockquote><p>Say you&#8217;re thinking about firing Elon Musk. &#8230; My objection is more basic: It doesn&#8217;t work. You can&#8217;t use conditional predictions markets to make decisions like this, because conditional prediction markets reveal probabilistic relationships, not causal relationships. There are solutions&#8212;ways to force markets to give you causal relationships. But those solutions are painful and I get the shakes when I see everyone acting like you can use prediction markets to conjure causal relationships from thin air, almost for free. (<a href=\"https://www.lesswrong.com/posts/vqzarZEczxiFdLE39/futarchy-s-fundamental-flaw\">More</a>)</p></blockquote><p>Not true. If decisions to trade in decision markets apply the same decision theory as the decisions that those markets advise, then both should use the same probability concept. Let me explain.</p><p>Most everyone agrees that decision theory recommends that decision maker <em>d</em> take the action <em>A</em> that maximizes expected utility E[<em>U_d</em>|<em>A</em>] = Sum_<em>i</em> <em>U_d</em>(<em>O_i</em>) p(<em>O_i</em> if <em>A</em>), where <em>O_i</em> is an outcome, and <em>U_d(O)</em> is the utility to d of that outcome. Many disagree, however, on what sort of chances should play the role of <em>p</em>(<em>O_i</em> if <em>A</em>). It is widely <a href=\"https://plato.stanford.edu/entries/decision-causal/\">said</a> that evidential decision theory says to use conditional chances <em>P</em>(<em>O_i</em> | <em>A</em>), while causal decision theory says to include everything <em>d</em> knows about the causal structure of the decision context to estimate <em>P</em>(<em>O_i</em> caused by <em>A</em>).</p><p>Statistical analyses often take datasets that include various <em>A</em> and <em>O</em> and infer estimates of <em>P</em>(<em>O_i </em>| <em>A</em>). Such analyses typically assume no or max simple causal structures, and ignore what we know about relevant causal structures. Regarding such estimates, we are often warned to distinguish the correlations that such models estimate from the causal chances that we actually want to use when making decisions. Yes, correlation does not imply causation.</p><p>However, contrary to the three writers linked above, speculative market prices are <em>not</em> generally equivalent to estimates from simple statistical analyses! Market prices are instead far more complex and subtler things. Sure, some traders many make and use oversimplified stat models to inform their trades, but speculative markets are typically full of many kinds of naive traders whose biases are not reflected in market prices, as other traders counter and correct for their biases. Market prices are better thought of as combining trader info into prices that estimate asset value given that total info.</p><p>Imagine that market traders all had exactly the same info, the same as the info of decision maker <em>d</em>. Further imagine that they all use the same kind of decision theory, be it evidential, causal, or something else. Given these assumptions, they would all agree on their estimates E[<em>U_d</em> | <em>A</em>], as well as on other E[<em>X</em>|<em>A</em>] = Sum_i <em>X_i</em> p(<em>X_i </em>if <em>A</em>), as they would agree on and use the same conditional chance estimates p(<em>X_i</em> if <em>A</em>). Traders here use their beliefs on the causal structure of <em>d</em>&#8217;s action <em>A</em> related to other events <em>X</em>, and if they have the same info they should have the same beliefs on that causal structure.</p><p>Thus for any asset that pays in proportion to <em>X</em>, traders would all estimate the risk-neutral financial value of a trade of that asset conditional on <em>d</em> choosing <em>A</em> via the same E[<em>X</em>|<em>A</em>], and thus that common E[<em>X</em>|<em>A</em>] should set the asset&#8217;s risk-neutral price in conditional asset markets. So market prices here would give exactly the sort of estimates that the decision maker wants for advice, be they evidential or causal. Though in this case the info isn&#8217;t useful, as the decision maker already has it.</p><p>Now assume that market traders all have the same info, which is strictly <em>more</em> than decision maker&#8217;s info. Now the market prices would be set by trader E[<em>X</em>|<em>A</em>], which embodies more info than held by the decision maker. By observing the market prices, the decision maker can here get better informed on their decision, via just accepting market price estimates E[<em>X</em>|<em>A</em>] as their personal estimate. And if there happens to be a market in an asset that pays in proportion to <em>U_d</em>, the decision maker can directly accept market estimates of E[<em>U_d</em>|<em>A</em>], and just pick the option <em>A</em> which gives the max value for this. Now the decision market directly helps the decision maker.</p><p>If we instead assume that the decision maker has strictly more info than market traders, we face the potential problem of a <a href=\"https://www.overcomingbias.com/p/decision-selection-bias\">decision selection bias</a>, as I&#8217;ve discussed. A robust solution for that is to make the decision time clear, and allow decision makers or their associates to trade in the markets. Given these conditions, prices just before the decision should reflect E[<em>X</em>|<em>A</em>], not distorted by decision selection biases.</p><p>What if different traders, and decision makers, use different concepts of conditional chances P(<em>O_i</em> | <em>A</em>) to estimate the value of their trades? In that case the most accurate concept will tend to win out in trading, and come to dominate the population of traders. And that winning concept seems to be the correct decision theory concept, which decision makers are also well advised to use. And so conditional prediction markets would then offer good advice to decision makers re E[<em>X</em>|<em>A</em>].</p><p>My bet on what is that best concept of conditional chances P(<em>X</em> if <em>A</em>) is inspired by <a href=\"https://www.jstor.org/stable/41494954\">source</a>. If one first collects one&#8217;s decision relevant info and then makes a final decision choice in a mechanical way using those inputs, the outcome of that mechanical process just can&#8217;t offer any more evidence than was embodied in its inputs. So it makes sense to first naively collect decision-relevant info, using everything one knows about causality, second reflect on how that info might embody evidence for hidden traits, third update that info to reflect such evidence, and forth use your mechanical decision process on those updated inputs. Now causal and evidential decision theory should give the same answers.</p>"
            ],
            "link": "https://www.overcomingbias.com/p/decision-conditional-prices-reflect",
            "publishedAt": "2025-06-17",
            "source": "Robin Hanson",
            "summary": "<p>A common <a href=\"https://www.lesswrong.com/posts/vqzarZEczxiFdLE39/futarchy-s-fundamental-flaw\">complaint</a> about futarchy (<a href=\"https://www.lesswrong.com/posts/vrEA6taJZtSoQbyPA/conditional-prediction-markets-are-evidential-not-causal\">see</a> <a href=\"https://casparoesterheld.com/2017/12/18/futarchy-implements-evidential-decision-theory/\">also</a>):</p><blockquote><p>Say you&#8217;re thinking about firing Elon Musk. &#8230; My objection is more basic: It doesn&#8217;t work. You can&#8217;t use conditional predictions markets to make decisions like this, because conditional prediction markets reveal probabilistic relationships, not causal relationships. There are solutions&#8212;ways to force markets to give you causal relationships. But those solutions are painful and I get the shakes when I see everyone acting like you can use prediction markets to conjure causal relationships from thin air, almost for free. (<a href=\"https://www.lesswrong.com/posts/vqzarZEczxiFdLE39/futarchy-s-fundamental-flaw\">More</a>)</p></blockquote><p>Not true. If decisions to trade in decision markets apply the same decision theory as the decisions that those markets advise, then both should use the same probability concept. Let me explain.</p><p>Most everyone agrees that decision theory recommends that decision maker <em>d</em> take the action <em>A</em> that maximizes expected utility E[<em>U_d</em>|<em>A</em>] = Sum_<em>i</em> <em>U_d</em>(<em>O_i</em>) p(<em>O_i</em> if <em>A</em>), where <em>O_i</em> is an outcome, and <em>U_d(O)</em> is the utility to d of that outcome. Many disagree, however, on what sort of chances should play the role of <em>p</em>(<em>O_i</em> if <em>A</em>). It is widely <a href=\"https://plato.stanford.edu/entries/decision-causal/\">said</a> that evidential decision theory says to use conditional chances <em>P</em>(<em>O_i</em> | <em>A</em>), while causal decision theory says to",
            "title": "Decision Conditional Prices Reflect Causal Chances"
        },
        {
            "content": [],
            "link": "https://simonwillison.net/2025/Jun/17/gemini-2-5/#atom-entries",
            "publishedAt": "2025-06-17",
            "source": "Simon Willison",
            "summary": "<p>After many months of previews, Gemini 2.5 Pro and Flash have <a href=\"https://developers.googleblog.com/en/gemini-2-5-thinking-model-updates/\">reached general availability</a> with new, memorable model IDs: <code>gemini-2.5-pro</code> and <code>gemini-2.5-flash</code>. They are joined by a new preview model with an unmemorable name: <code>gemini-2.5-flash-lite-preview-06-17</code> is a new Gemini 2.5 Flash Lite model that offers lower prices and much faster inference times.</p> <p>I've added support for the new models in <a href=\"https://github.com/simonw/llm-gemini/releases/tag/0.23\">llm-gemini 0.23</a>:</p> <pre><code>llm install -U llm-gemini llm 'Generate an SVG of a pelican riding a bicycle' \\ -m gemini-2.5-flash-lite-preview-06-17 </code></pre> <p>There's also a new <a href=\"https://storage.googleapis.com/deepmind-media/gemini/gemini_v2_5_report.pdf\">Gemini 2.5 Technical Report (PDF)</a>, which includes some interesting details about long context and audio and video support. Some highlights:</p> <blockquote> <p>While Gemini 1.5 was focused on native audio understanding tasks such as transcription, translation, summarization and question-answering, in addition to understanding, Gemini 2.5 was trained to perform audio generation tasks such as text-to-speech or native audio-visual to audio out dialog. [...]</p> <p>Our Gemini 2.5 Preview TTS Pro and Flash models support more than 80 languages with the speech style controlled by a free formatted prompt which can specify style, emotion, pace, etc, while also being capable of following finer-grained steering instructions specified in the transcript. Notably, Gemini 2.5 Preview TTS can generate",
            "title": "Trying out the new Gemini 2.5 model family"
        }
    ],
    "lookbackDays": 1,
    "publishDate": "2025-06-17"
}