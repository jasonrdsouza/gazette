{
    "articles": [
        {
            "content": [
                "<p><em>The first half of this note is basically battle scars from the wrapper, and the second half is basically \u201cdon\u2019t do React\u201d.</em></p>\n<p><a href=\"https://www.inkandswitch.com/project/playbook\">PlayBook</a> is a web app that can run in any browser, but we use it inside a special <a href=\"https://github.com/inkandswitch/wrapper/\">wrapper</a> iPad app. The iPad app captures finger motions, pencil strokes, and other physical inputs with higher fidelity than the browser APIs allow, forwarding these inputs to a web view running PlayBook. This hybrid gives us the richness and capability of a native app with the portability and rapid iteration of a web app.</p>\n<p>All inputs to the PlayBook web app pass through three processing stages: event capture, input enrichment, and gesture routing. The rest of this note will describe the function and design of these stages.</p>\n<p>Terminology:</p>\n<ul>\n<li>Event \u2014 the measured or predicted position of a finger or pencil at one moment in time</li>\n<li>Touch \u2014 a series of events that represent the motion of a finger or the pencil</li>\n<li>Gesture \u2014 code that decides how to turn one or more touches into effects</li>\n</ul>\n<h2 id=\"event-capture\"><a class=\"plain\" href=\"https://www.inkandswitch.com/index.xml#event-capture\">Event capture</a></h2>\n<p>PlayBook renders at 60 Hz, but the browser or wrapper deliver events at up to 240 Hz. For performance reasons, the event capture system queues events to be processed on the next frame, rather than acting on them immediately. When PlayBook is run on a conventional computer, the event capture system also transforms mouse and keyboard input into simulated finger and pencil input.</p>\n<p>Here\u2019s the metadata included with each event:</p>\n<div class=\"highlight\">\n<pre class=\"chroma\"><code>type NativeEvent = {\n  id: TouchId // Stable identity shared by all events that make up one touch\n  type: &quot;pencil&quot; | &quot;finger&quot;\n  phase: &quot;hover&quot; | &quot;began&quot; | &quot;moved&quot; | &quot;ended&quot; | &quot;risen&quot;\n  predicted: boolean // true if the event is a hypothetical future position\n  position: Position // position in screen space\n  worldPos: Position // position in world space \u2014 added during input enrichment\n  pressure: number\n  altitude: number\n  azimuth: number\n  rollAngle: number\n  radius: number\n  z: number // Pencil hover height\n  timestamp: number\n}\n</code></pre>\n</div>\n<p>The pencil uses all 5 phases (\u201crisen\u201d occurs when the pencil moves far enough away that we no longer count it as hovering), while fingers only use the middle three.</p>\n<h2 id=\"input-enrichment\"><a class=\"plain\" href=\"https://www.inkandswitch.com/index.xml#input-enrichment\">Input enrichment</a></h2>\n<p>By the time the next frame begins, the queue usually contains 4-6 events per touch and 8-12 for the pencil. For a handful of reasons, these events arrive in an incoherent order, so the first step is to organize them \u2014 sorted by timestamp and grouped together by touch ID.</p>\n<p>About half of the events are <em>real</em>, and the other half are <em>predicted</em>. The wrapper generates predicted events by estimating where the next real finger or pencil event will occur, and these predictions can be used to reduce perceptual latency. In the relatively long time between rendered frames, most predictions will already be obviated by later real events. The input enrichment system filters out stale and low-quality predictions, keeping at most one prediction per touch.</p>\n<aside class=\"move-up\"><em>motion-to-photon latency</em> is how long it takes before physical input produces a visible result. When you draw a fast line with a stylus, you\u2019ll often see a gap between the tip of the stylus and the line \u2014 that\u2019s due to latency. Humans are sensitive to touchscreen latency above ~1ms, and in practice the best consumer devices achieve 8-16ms, so using predicted positions to minimize the perception of latency makes a meaningful difference.</aside>\n<p>This enrichment stage also fixes a few kinds of bogus data (eg: \u201chover\u201d after \u201cbegan\u201d due to UIKit handling touches and hovers separately) and precomputes some commonly used derived values (eg: <code>worldPos</code>, which is <code>position</code> converted from screen space to world space).</p>\n<p>The most important job of the input enrichment system is to maintain a struct of continually evolving metadata for each active touch:</p>\n<div class=\"highlight\">\n<pre class=\"chroma\"><code>type TouchState = {\n  beganEvent?: NativeEvent // The event when the touch first contacted the screen (null when pencil hovering)\n  lastEvent: NativeEvent // The previous &quot;real&quot; (non-predicted) event for this touch\n  dragDist: number // The distance between the beganEvent and lastEvent\n  drag: boolean // Has the touch moved at least a tiny bit since it began?\n  // The following relate to a special &quot;firm press&quot; pencil motion\n  averageVel: Averager\n  averagePressure: Averager\n  pressureSpikeAt: number | null\n  firmPress: boolean\n}\n</code></pre>\n</div>\n<p>This struct contains state that gestures would otherwise need to track for themselves. For instance, a gesture can:</p>\n<ul>\n<li>compare the beganEvent to the current event to measure the overall direction that the touch has moved</li>\n<li>compare lastEvent to the current event to measure instantaneous velocity</li>\n<li>check the <code>drag</code> boolean to decide whether the touch should count as a tap or a drag.</li>\n<li>check if <code>drag</code> is true and <code>dragDist</code> is near zero, meaning that the touch has drawn a closed path</li>\n<li>perform a special action when the user does a firm press \u2014 a quick, click-like press with the pencil.</li>\n</ul>\n<h2 id=\"gesture-routing\"><a class=\"plain\" href=\"https://www.inkandswitch.com/index.xml#gesture-routing\">Gesture routing</a></h2>\n<p>Gestures are bundles of code that turn a sequence of events into specific actions. They are organized by a routing system that has a list of all the gestures supported by PlayBook \u2014 gestures for clicking, drawing, selecting, rotating, duplicating, panning, and so forth.</p>\n<div class=\"highlight\">\n<pre class=\"chroma\"><code>const gestureClasses = {\n  finger: [Click, Interact, CloseSettings, OpenSettings, CloseDebug, OpenDebug, Pan, DuplicateSelection, RotateSelection],\n  pencil: [Click, Interact, DuplicateSelection, MoveSelection, Draw]\n}\n\ninterface GestureClass {\n  // Offer an unclaimed touch to the class \u2014 it may return a instance to claim the touch\n  offer?(ctx: EventContext): Gesture | void\n}\n</code></pre>\n</div>\n<p>Gesture classes are kept in a linear priority list, separately for finger and pencil. When a new touch begins, it\u2019s offered to each of the gesture classes. The first to accept claims the touch and receives all its subsequent events. Gestures can do whatever they want internally \u2014 including morphing into a different gesture (eg: a pan becoming a pinch-zoom) \u2014 but they don\u2019t need to know about each other. The only shared structure is the ordered list and the <code>offer()</code> protocol.</p>\n<aside class=\"move-up\"><i>Ivan</i> note to Marcel \u2014 at the moment gestures are mutually exclusive (as in only one gestures is stored per touch and we stop offering as soon as we have an instance), but I\u2019m using the plural here because I strongly suspect we\u2019ll want to change this. I\u2019d do it now, but all the naive approaches violate some of the principles outlined below.</aside>\n<p>Inside the gesture, there are methods that can respond to different phases that events will have over the lifecycle of the touch.</p>\n<div class=\"highlight\">\n<pre class=\"chroma\"><code>// Instance methods for gestures\nexport interface Gesture {\n  // Called for all events of the given phase\n  hover?(ctx: EventContext): Gesture | void\n  began?(ctx: EventContext): Gesture | void\n  moved?(ctx: EventContext): Gesture | void\n  ended?(ctx: EventContext): void\n  risen?(ctx: EventContext): void\n\n  // Called when a firm press is detected\n  firmPress?(ctx: EventContext): Gesture | void\n\n  // Called every frame\n  tick?(ctx: PlaybookContext): void\n\n  // Existing gestures get first dibs on all new touches\n  offer?(ctx: EventContext): boolean | void\n}\n</code></pre>\n</div>\n<p>See that last instance method, <code>offer</code>? That\u2019s similar to the static <code>offer</code> method shown previously. When a new touch begins, before offering it to the gesture <em>classes</em>, the system offers it to all existing gesture <em>instances</em> that implement this method. If any of them accept it (by returning <code>true</code>), that gesture becomes a de facto multitouch gesture, receiving the events from both touches.</p>\n<aside class=\"move-up\"><i>Ivan</i> Hi again Marcel. The API design around <em>removing</em> touches from gestures is a bit rough. At the moment it\u2019s something gestures need to do manually in <code>ended()</code>. We could bake this into the system (eg by adding another optional gesture instance method or smth) if this becomes a pain point.</aside>\n<h2 id=\"design\"><a class=\"plain\" href=\"https://www.inkandswitch.com/index.xml#design\">Design</a></h2>\n<p>The way we handle user input has evolved considerably since our earlier experiments with <a href=\"https://www.inkandswitch.com/project/crosscut\">Crosscut</a>, <a href=\"https://www.inkandswitch.com/project/inkling\">Inkling</a>, and earlier versions of PlayBook.</p>\n<p>The current design has the following goals:</p>\n<ol>\n<li>You can write a new gesture without thinking about other gestures.</li>\n<li>Gestures can do anything they want internally.</li>\n<li>It\u2019s easy to figure out what an existing gesture does by glancing at the code.</li>\n<li>It\u2019s easy to figure out which gestures are active while using PlayBook.</li>\n<li>The design gently guides you toward writing gestures that satisfy the above goals.</li>\n</ol>\n<p>We found it hard to satisfy these goals using the typical approaches of existing input / gesture handling systems.</p>\n<ul>\n<li>\n<p>Retained Mode systems like the DOM, which use something like <code>addEventListener()</code>, encourage you to write gestures in terms of persistent objects that exist on screen and can be hit tested against, and force these objects to coordinate according to the rendering tree that events flow through (ie: in advanced use you end up leaning on capture / bubbling phases). This conflates rendering and input handling \u2014 we want those to be decoupled. You can do that by adding all your listeners to a top-level object like <code>window</code>, but then you\u2019ve just bypassed the entire event system and need to come up with some bespoke solution.</p>\n</li>\n<li>\n<p>Immediate Mode systems like Dear IMGUI and (arguably) React <s>improve upon</s> offer an attractive alternative to retained mode systems. They deeply conflate rendering and input handling, for instance by asking you to write a function that looks at the state of all input and then chooses what things to render. Immediate mode is even worse for our needs than retained mode. We want to write a new gesture without having to know what any other gestures are doing \u2014 we want to encapsulate gesture code. Immediate mode has input handling logic splayed out across the rendering code. The system is oriented along an entirely different axis than the one we want.</p>\n</li>\n<li>\n<p>There are many ways to use state machines to solve part of the problem. One popular approach is to have one or a few state machines that track the current mode(s) of the app, and use the input events to transition the machine or perform actions based on the current state. Given that one of the jobs of our gesture system is to route events, a state machine might make sense \u2014 it\u2019s a popular way to route navigation in web frameworks, after all. For gestures, you might have a state machine for viewport panning/zooming that looks something like: <code>inert &lt;-&gt; panning &lt;-&gt; pinch-zooming</code>, where you move between these states by placing or removing fingers on the screen. Where state machines get tricky is that some of our gestures are mutually exclusive, some gestures are multi-touch, some gestures require a finger and the pencil, some gestures only happen within a specific spatial region, some gestures have behaviour that evolves over time, etc. There are a lot of potentially complex interactions between the gestures. Gestures coexist and overlap. Building one or more big state machines to describe how they relate to one another is a very <em>top down</em> way to control what is possible. That makes sense if you already have a complete design for all the gestures and want to ensure that all of their possible interactions are fully modelled and understood. We\u2019re in the opposite position \u2014 we are trying new gestures all the time, our design keeps evolving. One similar option we haven\u2019t tried is statecharts, which may improve composability, but they\u2019d still require top-down enumeration of some state space.</p>\n</li>\n</ul>\n<aside class=\"move-up\">Unlike immediate mode and retained mode, state machine approaches offer an organizing principle that feels like a closer match to our design. But state machines want to be graphs. We just keep our gesture classes in a linear list. That\u2019s enough organization for most of our gestures. When that isn\u2019t enough, our gestures have the means to morph into one another (eg: a pan gesture can become a pinch-zoom when a finger is added).</aside>\n<ul>\n<li>\n<p>Another approach is to use a state machine within each gesture. We have a page turn gesture the moves through a number of internal modes. When you swipe your finger in from the edge of the screen, this gesture measures the direction and distance of the touch. When the touch has moved far enough from the edge, and in a nearly perpendicular direction, the gesture signals to the camera that it should now follow the finger. If the camera is looking at the last page in the notebook, and the user is swiping toward the next page (which doesn\u2019t exist), then after the camera crosses the halfway point a new page is created. When the user releases their finger, the gesture considers the velocity and direction of finger motion to determine whether to continue moving to the next page, or remain on the current page (removing any new page that might have been created). Each of these modes of the gesture could be modelled as states in a state machine. Our system encourages gestures to do anything they want internally, so while we don\u2019t use any state machine of this form, we could if we needed to, and that\u2019d be harmonious with all the other gestures (which also do whatever they want internally).</p>\n</li>\n<li>\n<p>UIKit uses hybrid of the above two state machine approaches, where each GestureRecognizer instance has internal states like \u201cpending\u201d, \u201cactive\u201d, \u201cended\u201d, \u201ccancelled\u201d, \u201cfailed\u201d, and so forth. When a new touch begins, all the views that pass a hit test instantiate all their GestureRecognizers, which all begin in a \u201cpending\u201d state. With each new event, they all have the opportunity to transition into an \u201cactive\u201d state, at which point all the <em>other</em> GestureRecognizer instances are \u201cfailed\u201d and no longer receive events, except when one uses the succinctly named method <code>shouldRecognizeSimultaneouslyWith</code>. This design has some nice qualities, like deferring the choice of gesture until (potentially) long after the touch has began, and allowing multiple gestures to run in parallel. We achieve similar results, but without requiring gestures to use a prescribed set of states, and without the <em>spooky action at a distance</em> effect on other gestures. In our system, each gesture decides for itself what internal states to use, and if a few gestures need to coordinate among themselves, they can do that however they see fit. In practice we almost never need this \u2014 the default coordination mechanisms are straightforward and automatic \u2014 but when gestures do need special coordination, they can do it.</p>\n</li>\n<li>\n<p>Finally, one other approach worth comparing is the previous version of our own system. Each gesture implemented only one function:</p>\n<p><code>update(claimed: boolean, ctx:EventContext): Gesture | boolean | void</code></p>\n<p>When a new touch began, we\u2019d create an instance of <em>every</em> gesture in the system, and keep those in a list associated with the touch. Then for each event, we\u2019d pass it to each gesture instance one by one, along with a <code>claimed</code> boolean. Any of those gestures could return <code>true</code> to indicate that they\u2019ve now claimed the event. It was customary for each gesture to begin by checking the passed-in <code>claimed</code> boolean and, typically, abort their behaviour if it was true. This approach offered even more flexibility than our current approach \u2014 there was almost zero <em>grain</em> imposed by the system. The gesture(s) performed by each touch could change dynamically with zero coordination needed. But we found that the system itself wasn\u2019t doing enough to help. Gestures ended up needing to store a lot of state, and do some tricky logic to determine if (eg) they previous had a claim to a touch, but suddenly some gesture earlier in the list was now claiming and overriding their claim. When we switched to our current system (using <code>offer()</code>), we found that most gestures could be implemented almost identically, save for a bunch of oft-repeated bookkeeping code that could be deleted. Another downside of this old system is shared by our new system: gestures can do whatever they want internally. That\u2019s one of our values. Why is it a downside? Because its\u2019s in tension with another of our values: that it\u2019s easy to figure out what an existing gesture does by glancing at the code. In the old system, the extra internal state and the lack of discrete methods for each event phase (old system just had <code>update()</code>, new system has <code>began()</code>, <code>moved()</code>, <code>ended()</code>, etc) made it slightly too hard to understand what gestures did. The new system maintains the freedom for gestures to each do their own thing, but it gives <em>just enough</em> structure to make it easier to skim through gesture code and understand what will happen. Also, we made certain commonly-used special behaviours like <code>tick()</code> and <code>firmPress()</code> part of the system itself, so that gestures don\u2019t need to implement them, and that really helped tamp down duplication and inconsistency.</p>\n</li>\n</ul>\n<aside class=\"move-up\"><i>Ivan</i> we should write a lab note about <a href=\"https://www.inkandswitch.com/index.xml\">firm press</a></aside>"
            ],
            "link": "https://www.inkandswitch.com/ink/notes/how-playbook-processes-user-input/",
            "publishedAt": "2026-02-20",
            "source": "Ink & Switch",
            "summary": "<p><em>The first half of this note is basically battle scars from the wrapper, and the second half is basically \u201cdon\u2019t do React\u201d.</em></p> <p><a href=\"https://www.inkandswitch.com/project/playbook\">PlayBook</a> is a web app that can run in any browser, but we use it inside a special <a href=\"https://github.com/inkandswitch/wrapper/\">wrapper</a> iPad app. The iPad app captures finger motions, pencil strokes, and other physical inputs with higher fidelity than the browser APIs allow, forwarding these inputs to a web view running PlayBook. This hybrid gives us the richness and capability of a native app with the portability and rapid iteration of a web app.</p> <p>All inputs to the PlayBook web app pass through three processing stages: event capture, input enrichment, and gesture routing. The rest of this note will describe the function and design of these stages.</p> <p>Terminology:</p> <ul> <li>Event \u2014 the measured or predicted position of a finger or pencil at one moment in time</li> <li>Touch \u2014 a series of events that represent the motion of a finger or the pencil</li> <li>Gesture \u2014 code that decides how to turn one or more touches into effects</li> </ul> <h2 id=\"event-capture\"><a class=\"plain\" href=\"https://www.inkandswitch.com/index.xml#event-capture\">Event capture</a></h2> <p>PlayBook renders at 60 Hz, but the browser or wrapper deliver events at up to 240",
            "title": "Ink Note Jan-Feb '26: How PlayBook Processes User Input"
        },
        {
            "content": [],
            "link": "https://interconnected.org/home/2026/02/20/filtered",
            "publishedAt": "2026-02-20",
            "source": "Matt Webb",
            "summary": "<div> <h3>1.</h3> <p>Rain panels? Rain panels.</p> <blockquote cite=\"https://thedebrief.org/forget-solar-panels-here-come-rain-panels/\" class=\"quoteback\"> <p>researchers have found a way to capture, store and utilize the electrical power generated by falling raindrops, which may lead to the development of rooftop, power-generating rain panels.</p> <footer>\u2013 The Debrief, <cite><a href=\"https://thedebrief.org/forget-solar-panels-here-come-rain-panels/\">Forget solar panels. Here come the rain panels</a> (2023)</cite></footer> </blockquote> <p>Reading the <a href=\"https://ieeexplore.ieee.org/document/10185664/citations#citations\">citations on the original paper</a>, it works kinda but research is ongoing. Science rather than technology still.</p> <p>RELATED:</p> <p><a href=\"https://futurism.com/china-solar-mountain-video\">Wild Video Shows Entire Mountain Range in China Covered With Solar Panels</a> (2025).</p> <p>HEY:</p> <p><a href=\"https://interconnected.org/home/2007/02/12/30_year_prediction\">Here\u2019s a prediction I made in 2007</a>:</p> <blockquote> <p>By 2037, China, by virtue of their ability to see and manage environment impact on a larger scale than other countries, will have invented cheap renewables to reduce their dependancy on fossil fuels, and will be working on fixing the atmosphere (perhaps they\u2019ll also have genetically engineered rafts of algae on the Pacific, excreting plastics). The West will rely on Chinese innovation to dig us out of our ecological mess.</p> </blockquote> <p>Mind you I also predicted that our peak pop media would be from India. Turns out it\u2019s South Korea so I got the country wrong.</p> <h3>2.</h3> <p>Pavlok is a wrist band that gives",
            "title": "Filtered for electricity and mayonnaise"
        },
        {
            "content": [],
            "link": "https://www.robinsloan.com/lab/vertigo-vibes/",
            "publishedAt": "2026-02-20",
            "source": "Robin Sloan",
            "summary": "<p>Under all is the vibes. <a href=\"https://www.robinsloan.com/lab/vertigo-vibes/\">Read here.</a></p>",
            "title": "Artificial general economy"
        },
        {
            "content": [],
            "link": "https://www.robinsloan.com/lab/new-funnel/",
            "publishedAt": "2026-02-20",
            "source": "Robin Sloan",
            "summary": "<p>Traffic patterns. <a href=\"https://www.robinsloan.com/lab/new-funnel/\">Read here.</a></p>",
            "title": "The new funnel?"
        },
        {
            "content": [],
            "link": "https://simonwillison.net/2026/Feb/20/beats/#atom-entries",
            "publishedAt": "2026-02-20",
            "source": "Simon Willison",
            "summary": "<p>I've been wanting to add indications of my various other online activities to my blog for a while now. I just turned on a new feature I'm calling \"beats\" (after story beats, naming this was hard!) which adds five new types of content to my site, all corresponding to activity elsewhere.</p> <p>Here's what beats look like:</p> <p><img alt=\"Screenshot of a fragment of a page showing three entries from 30th Dec 2025. First: [RELEASE] &quot;datasette-turnstile 0.1a0 \u2014 Configurable CAPTCHAs for Datasette paths usin\u2026&quot; at 7:23 pm. Second: [TOOL] &quot;Software Heritage Repository Retriever \u2014 Download archived Git repositories f\u2026&quot; at 11:41 pm. Third: [TIL] &quot;Downloading archived Git repositories from archive.softwareheritage.org \u2014 \u2026&quot; at 11:43 pm.\" src=\"https://static.simonwillison.net/static/2026/three-beats.jpg\" /></p> <p>Those three are from <a href=\"https://simonwillison.net/2025/Dec/30/\">the 30th December 2025</a> archive page.</p> <p>Beats are little inline links with badges that fit into different content timeline views around my site, including the homepage, search and archive pages.</p> <p>There are currently five types of beats:</p> <ul> <li> <a href=\"https://simonwillison.net/elsewhere/release/\">Releases</a> are GitHub releases of my many different open source projects, imported from <a href=\"https://github.com/simonw/simonw/blob/main/releases_cache.json\">this JSON file</a> that was constructed <a href=\"https://simonwillison.net/2020/Jul/10/self-updating-profile-readme/\">by GitHub Actions</a>.</li> <li> <a href=\"https://simonwillison.net/elsewhere/til/\">TILs</a> are the posts from my <a href=\"https://til.simonwillison.net/\">TIL blog</a>, imported using <a href=\"https://github.com/simonw/simonwillisonblog/blob/f883b92be23892d082de39dbada571e406f5cfbf/blog/views.py#L1169\">a SQL",
            "title": "Adding TILs, releases, museums, tools and research to my blog"
        },
        {
            "content": [
                "<p>It&#8217;s that time again. Even numbered years are book reviews, odd-numbered years are non-book reviews, so you&#8217;re limited to books for now.</p><p>Write a review of a book. There&#8217;s no official word count requirement, but previous finalists and winners were often between 2,000 and 10,000 words. There&#8217;s no official recommended style, but check the style of <a href=\"https://www.astralcodexten.com/p/book-review-contest-2024-winners\">last time&#8217;s finalists and winners</a> or my ACX book reviews (<a href=\"https://astralcodexten.substack.com/p/book-review-lifespan\">1</a>, <a href=\"https://astralcodexten.substack.com/p/book-review-which-country-has-the\">2</a>, <a href=\"https://astralcodexten.substack.com/p/book-review-arabian-nights\">3</a>) if you need inspiration. Please limit yourself to one entry per person or team.</p><p>Then send me your review through <strong><a href=\"https://forms.gle/j7fHtDAg3i4di8Rj9\">this Google Form</a></strong>. The form will ask for your name, email, the title of the book, and a link to a Google Doc. The Google Doc should have your review exactly as you want me to post it if you&#8217;re a finalist. <em>Don&#8217;t include your name or any hint about your identity in the Google Doc itself, only in the form.</em> I want to make this contest as blinded as possible, so I&#8217;m going to hide that column in the form immediately and try to judge your docs on their merit.</p><p>(does this mean you can&#8217;t say something like &#8220;This book about war reminded me of my own experiences as a soldier&#8221; because that gives a hint about your identity? My rule of thumb is that if I don&#8217;t know who you are, and the average ACX reader doesn&#8217;t know who you are, you&#8217;re fine. I just want to prevent my friends or Internet semi-famous people from getting an advantage. If you&#8217;re in one of those categories and think your personal experience would give it away, please don&#8217;t write about your personal experience.)</p><p><strong>Please make sure the Google Doc is unlocked and I can read it</strong>. By default, nobody can read Google Docs except the original author. You&#8217;ll have to go to Share, then on the bottom of the popup click on &#8220;Restricted&#8221; and change to &#8220;Anyone with the link&#8221;. If you send me a document I can&#8217;t read, I will probably disqualify you, sorry.</p><p>Readers will vote for the ~10 finalists this spring, I&#8217;ll post one finalist per week through the summer, and then readers will vote for winners in late summer/early fall. First prize will get at least $2,500, second prize at least $1,000, third prize at least $500; I might increase these numbers later on. All winners and finalists will get free publicity (including links to any other works they want me to link to), free ACX subscriptions, and sidebar links to their blog. And all winners will get the right to pitch me new articles if they want (sample posts by <a href=\"https://www.astralcodexten.com/p/does-georgism-work-is-land-really\">Lars</a>, <a href=\"https://www.astralcodexten.com/p/bayes-for-everyone\">Brandon</a>, <a href=\"https://www.astralcodexten.com/p/consciousness-as-recursive-reflections\">Daniel</a>, etc).</p><p>In past years, most reviews have been nonfiction on technical topics. Depending on whether that&#8217;s still true, I might do some mild affirmative action for reviews in nontraditional categories - fiction, poetry, and books from before 1900 are the ones I can think of right now, but feel free to try other nontraditional books. I won&#8217;t be redistributing more than 25% of finalist slots this way.</p><p>Your due date is <strong>May 20th</strong>. Good luck! If you have any questions, ask them in the comments. And remember, the form for submitting entries is <strong><a href=\"https://forms.gle/j7fHtDAg3i4di8Rj9\">here</a></strong>.</p>"
            ],
            "link": "https://www.astralcodexten.com/p/book-review-contest-rules-2026",
            "publishedAt": "2026-02-20",
            "source": "SlateStarCodex",
            "summary": "<p>It&#8217;s that time again. Even numbered years are book reviews, odd-numbered years are non-book reviews, so you&#8217;re limited to books for now.</p><p>Write a review of a book. There&#8217;s no official word count requirement, but previous finalists and winners were often between 2,000 and 10,000 words. There&#8217;s no official recommended style, but check the style of <a href=\"https://www.astralcodexten.com/p/book-review-contest-2024-winners\">last time&#8217;s finalists and winners</a> or my ACX book reviews (<a href=\"https://astralcodexten.substack.com/p/book-review-lifespan\">1</a>, <a href=\"https://astralcodexten.substack.com/p/book-review-which-country-has-the\">2</a>, <a href=\"https://astralcodexten.substack.com/p/book-review-arabian-nights\">3</a>) if you need inspiration. Please limit yourself to one entry per person or team.</p><p>Then send me your review through <strong><a href=\"https://forms.gle/j7fHtDAg3i4di8Rj9\">this Google Form</a></strong>. The form will ask for your name, email, the title of the book, and a link to a Google Doc. The Google Doc should have your review exactly as you want me to post it if you&#8217;re a finalist. <em>Don&#8217;t include your name or any hint about your identity in the Google Doc itself, only in the form.</em> I want to make this contest as blinded as possible, so I&#8217;m going to hide that column in the form immediately and try to judge your docs on their merit.</p><p>(does this mean you can&#8217;t say something like &#8220;This book about war reminded me of my own experiences",
            "title": "Book Review Contest Rules 2026"
        },
        {
            "content": [
                "<p>\n          <a href=\"https://www.astralcodexten.com/p/hidden-open-thread-4215\">\n              Read more\n          </a>\n      </p>"
            ],
            "link": "https://www.astralcodexten.com/p/hidden-open-thread-4215",
            "publishedAt": "2026-02-20",
            "source": "SlateStarCodex",
            "summary": "<p> <a href=\"https://www.astralcodexten.com/p/hidden-open-thread-4215\"> Read more </a> </p>",
            "title": "Hidden Open Thread 421.5"
        },
        {
            "content": [
                "<table>\n<thead>\n<tr>\n<th id=\"\"></th>\n<th id=\"\"></th>\n<th id=\"loc\">LOC</th>\n<th id=\"host\">Host</th>\n<th id=\"hm\">HM</th>\n<th id=\"adts\">ADTs</th>\n<th id=\"match\">Match</th>\n<th id=\"cl.\">Cl.</th>\n<th id=\"target\">Target</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><a href=\"https://taylor.town/feed.xml#hirrolots-coc\">Hirrolot's CoC</a></td>\n<td><a href=\"https://gist.github.com/Hirrolot/27e6b02a051df333811a23b97c375196\">src</a></td>\n<td>~70</td>\n<td>OCaml</td>\n<td>\u2717</td>\n<td>\u2717</td>\n<td>\u2717</td>\n<td>\u2713</td>\n<td>Interpreter</td>\n</tr>\n<tr>\n<td><a href=\"https://taylor.town/feed.xml#harrop-miniml\">Harrop MiniML</a></td>\n<td><a href=\"https://gist.github.com/jdh30/6130c615b5945fd57fc0ea74fcb87e05\">src</a></td>\n<td>~100</td>\n<td>OCaml</td>\n<td>\u2717</td>\n<td>\u2717</td>\n<td>\u2717</td>\n<td>\u2717</td>\n<td>LLVM \u2192 native</td>\n</tr>\n<tr>\n<td><a href=\"https://taylor.town/feed.xml#algorithm-w\">Algorithm W</a></td>\n<td><a href=\"https://github.com/mgrabmueller/AlgorithmW\">src</a></td>\n<td>~300</td>\n<td>Haskell</td>\n<td>\u2713</td>\n<td>\u2717</td>\n<td>\u2717</td>\n<td>\u2717</td>\n<td>Type checker only</td>\n</tr>\n<tr>\n<td><a href=\"https://taylor.town/feed.xml#type-systems\">tomprimozic/type-systems</a></td>\n<td><a href=\"https://github.com/tomprimozic/type-systems\">src</a></td>\n<td>~300</td>\n<td>OCaml</td>\n<td>\u2713</td>\n<td>\u2717</td>\n<td>\u2717</td>\n<td>\u2717</td>\n<td>Type checker only</td>\n</tr>\n<tr>\n<td><a href=\"https://taylor.town/feed.xml#lambda-calculus-hs\">lambda-calculus-hs</a></td>\n<td><a href=\"https://github.com/solomon-b/lambda-calculus-hs\">src</a></td>\n<td>~200\u2013900</td>\n<td>Haskell</td>\n<td>\u2717</td>\n<td>\u2713</td>\n<td>\u2713</td>\n<td>\u2713</td>\n<td>Interpreter</td>\n</tr>\n<tr>\n<td><a href=\"https://taylor.town/feed.xml#thih\">THIH</a></td>\n<td><a href=\"https://hackage.haskell.org/package/thih\">src</a></td>\n<td>~429</td>\n<td>Haskell</td>\n<td>\u2713</td>\n<td>\u2713</td>\n<td>\u2713</td>\n<td>\u2717</td>\n<td>Type checker only</td>\n</tr>\n<tr>\n<td><a href=\"https://taylor.town/feed.xml#simple-sub\">Simple-sub</a></td>\n<td><a href=\"https://github.com/LPTK/simple-sub\">src</a></td>\n<td>~500</td>\n<td>Scala</td>\n<td>\u2713</td>\n<td>\u2717</td>\n<td>\u2717</td>\n<td>\u2713</td>\n<td>Type checker only</td>\n</tr>\n<tr>\n<td><a href=\"https://taylor.town/feed.xml#plzoo-poly\">PLZoo <code>poly</code></a></td>\n<td><a href=\"https://github.com/andrejbauer/plzoo\">src</a></td>\n<td>~500</td>\n<td>OCaml</td>\n<td>\u2713</td>\n<td>\u2717</td>\n<td>\u2717</td>\n<td>\u2713</td>\n<td>Interpreter</td>\n</tr>\n<tr>\n<td><a href=\"https://taylor.town/feed.xml#eyg\">EYG</a></td>\n<td><a href=\"https://github.com/CrowdHailer/eyg-lang\">src</a></td>\n<td>~500</td>\n<td>Gleam</td>\n<td>\u2713</td>\n<td>\u2713</td>\n<td>\u2713</td>\n<td>\u2713</td>\n<td>Interpreter</td>\n</tr>\n<tr>\n<td><a href=\"https://taylor.town/feed.xml#pico-ml\">Pico-ml</a></td>\n<td><a href=\"https://github.com/Quramy/pico-ml\">src</a></td>\n<td>~500</td>\n<td>TypeScript</td>\n<td>\u2713</td>\n<td>\u2717</td>\n<td>\u2717</td>\n<td>\u2713</td>\n<td>WebAssembly</td>\n</tr>\n<tr>\n<td><a href=\"https://taylor.town/feed.xml#tinyml\">TinyML</a></td>\n<td><a href=\"http://lambda-the-ultimate.org/node/2683\">src</a></td>\n<td>&lt;700</td>\n<td>SML</td>\n<td>\u2713</td>\n<td>\u2717</td>\n<td>\u2717</td>\n<td>\u2713</td>\n<td>Interpreter</td>\n</tr>\n<tr>\n<td><a href=\"https://taylor.town/feed.xml#eff\">Eff</a></td>\n<td><a href=\"https://github.com/matijapretnar/eff\">src</a></td>\n<td>~1\u20132K</td>\n<td>OCaml</td>\n<td>\u2713</td>\n<td>\u2713</td>\n<td>\u2713</td>\n<td>\u2713</td>\n<td>Interpreter</td>\n</tr>\n<tr>\n<td><a href=\"https://taylor.town/feed.xml#frank\">Frank</a></td>\n<td><a href=\"https://github.com/frank-lang/frank\">src</a></td>\n<td>~1\u20132K</td>\n<td>Haskell</td>\n<td>\u2713</td>\n<td>\u2713</td>\n<td>\u2713</td>\n<td>\u2713</td>\n<td>Interpreter</td>\n</tr>\n<tr>\n<td><a href=\"https://taylor.town/feed.xml#grace\">Grace</a></td>\n<td><a href=\"https://github.com/Gabriella439/grace\">src</a></td>\n<td>~1\u20133K</td>\n<td>Haskell</td>\n<td>\u2713</td>\n<td>\u2717</td>\n<td>\u2717</td>\n<td>\u2713</td>\n<td>Interpreter</td>\n</tr>\n<tr>\n<td><a href=\"https://taylor.town/feed.xml#hackett\">Hackett</a></td>\n<td><a href=\"https://github.com/lexi-lambda/hackett\">src</a></td>\n<td>~1\u20133K</td>\n<td>Racket</td>\n<td>\u2713</td>\n<td>\u2713</td>\n<td>\u2713</td>\n<td>\u2713</td>\n<td>Racket runtime</td>\n</tr>\n<tr>\n<td><a href=\"https://taylor.town/feed.xml#scrapscript\">Scrapscript</a></td>\n<td><a href=\"https://github.com/tekknolagi/scrapscript\">src</a></td>\n<td>~1\u20133K</td>\n<td>Python</td>\n<td>\u2713</td>\n<td>\u2713</td>\n<td>\u2713</td>\n<td>\u2713</td>\n<td>C/WASM/Cosmo native</td>\n</tr>\n<tr>\n<td><a href=\"https://taylor.town/feed.xml#mincaml\">MinCaml</a></td>\n<td><a href=\"https://github.com/esumii/min-caml\">src</a></td>\n<td>~2,000</td>\n<td>OCaml</td>\n<td>\u2713</td>\n<td>\u2717</td>\n<td>\u2717</td>\n<td>\u2713</td>\n<td>x86/SPARC/PPC native</td>\n</tr>\n<tr>\n<td><a href=\"https://taylor.town/feed.xml#ben-lynn\">Ben Lynn</a></td>\n<td><a href=\"https://github.com/blynn/compiler\">src</a></td>\n<td>~2,000</td>\n<td>Haskell/C</td>\n<td>\u2713</td>\n<td>\u2713</td>\n<td>\u2713</td>\n<td>\u2713</td>\n<td>Combinators \u2192 C VM</td>\n</tr>\n<tr>\n<td><a href=\"https://taylor.town/feed.xml#1ml\">1ML</a></td>\n<td><a href=\"https://github.com/rossberg/1ml\">src</a></td>\n<td>~3\u20135K</td>\n<td>OCaml</td>\n<td>\u2713</td>\n<td>\u2717</td>\n<td>\u2717</td>\n<td>\u2713</td>\n<td>Interpreter</td>\n</tr>\n<tr>\n<td><a href=\"https://taylor.town/feed.xml#mlml\">mlml</a></td>\n<td><a href=\"https://github.com/coord-e/mlml\">src</a></td>\n<td>~3\u20135K</td>\n<td>OCaml</td>\n<td>\u2717</td>\n<td>\u2713</td>\n<td>\u2713</td>\n<td>\u2713</td>\n<td>x86-64 native</td>\n</tr>\n<tr>\n<td><a href=\"https://taylor.town/feed.xml#dhall\">Dhall</a></td>\n<td><a href=\"https://github.com/dhall-lang/dhall-haskell\">src</a></td>\n<td>~4K</td>\n<td>Haskell</td>\n<td>\u2717</td>\n<td>\u2713</td>\n<td>\u2713</td>\n<td>\u2713</td>\n<td>Normalizer</td>\n</tr>\n<tr>\n<td><a href=\"https://taylor.town/feed.xml#ante\">Ante</a></td>\n<td><a href=\"https://github.com/jfecher/ante\">src</a></td>\n<td>~5\u201310K</td>\n<td>Rust</td>\n<td>\u2713</td>\n<td>\u2713</td>\n<td>\u2713</td>\n<td>\u2713</td>\n<td>Cranelift \u2192 native</td>\n</tr>\n<tr>\n<td><a href=\"https://taylor.town/feed.xml#tao\">Tao</a></td>\n<td><a href=\"https://github.com/zesterer/tao\">src</a></td>\n<td>~5\u201310K</td>\n<td>Rust</td>\n<td>\u2713</td>\n<td>\u2713</td>\n<td>\u2713</td>\n<td>\u2713</td>\n<td>Bytecode interpreter</td>\n</tr>\n<tr>\n<td><a href=\"https://taylor.town/feed.xml#austral\">Austral</a></td>\n<td><a href=\"https://github.com/austral/austral\">src</a></td>\n<td>~5\u201310K</td>\n<td>OCaml</td>\n<td>\u2717</td>\n<td>\u2713</td>\n<td>\u2713</td>\n<td>\u2713</td>\n<td>C</td>\n</tr>\n<tr>\n<td><a href=\"https://taylor.town/feed.xml#aqaml\">AQaml</a></td>\n<td><a href=\"https://github.com/ushitora-anqou/aqaml\">src</a></td>\n<td>~5\u20138K</td>\n<td>OCaml</td>\n<td>\u2717</td>\n<td>\u2713</td>\n<td>\u2713</td>\n<td>\u2713</td>\n<td>x86-64 native</td>\n</tr>\n<tr>\n<td><a href=\"https://taylor.town/feed.xml#borgo\">Borgo</a></td>\n<td><a href=\"https://github.com/borgo-lang/borgo\">src</a></td>\n<td>~5\u201310K</td>\n<td>Rust</td>\n<td>\u2713</td>\n<td>\u2713</td>\n<td>\u2713</td>\n<td>\u2713</td>\n<td>Go source</td>\n</tr>\n<tr>\n<td><a href=\"https://taylor.town/feed.xml#polytt\">polytt</a></td>\n<td><a href=\"https://github.com/ToposInstitute/polytt\">src</a></td>\n<td>~5\u201310K</td>\n<td>OCaml</td>\n<td>\u2717</td>\n<td>\u2713</td>\n<td>\u2713</td>\n<td>\u2713</td>\n<td>Interpreter</td>\n</tr>\n<tr>\n<td><a href=\"https://taylor.town/feed.xml#newt\">Newt</a></td>\n<td><a href=\"https://github.com/dunhamsteve/newt\">src</a></td>\n<td>~7K</td>\n<td>Newt</td>\n<td>\u2717</td>\n<td>\u2713</td>\n<td>\u2713</td>\n<td>\u2713</td>\n<td>JavaScript</td>\n</tr>\n<tr>\n<td><a href=\"https://taylor.town/feed.xml#hamlet\">HaMLet</a></td>\n<td><a href=\"https://github.com/rossberg/hamlet\">src</a></td>\n<td>~10\u201315K</td>\n<td>SML</td>\n<td>\u2713</td>\n<td>\u2713</td>\n<td>\u2713</td>\n<td>\u2713</td>\n<td>Interpreter</td>\n</tr>\n<tr>\n<td><a href=\"https://taylor.town/feed.xml#sosml\">SOSML</a></td>\n<td><a href=\"https://github.com/SOSML/SOSML\">src</a></td>\n<td>~10\u201315K</td>\n<td>TypeScript</td>\n<td>\u2713</td>\n<td>\u2713</td>\n<td>\u2713</td>\n<td>\u2713</td>\n<td>Browser interpreter</td>\n</tr>\n<tr>\n<td><a href=\"https://taylor.town/feed.xml#microhs\">MicroHs</a></td>\n<td><a href=\"https://github.com/augustss/MicroHs\">src</a></td>\n<td>~15\u201330K</td>\n<td>Haskell/C</td>\n<td>\u2713</td>\n<td>\u2713</td>\n<td>\u2713</td>\n<td>\u2713</td>\n<td>Combinators \u2192 C/JS</td>\n</tr>\n</tbody>\n</table>\n\n<p>I adore small programming languages.\n<a href=\"https://web.archive.org/web/20181024173237/http://www.nyu.edu/projects/barker/Iota/\">Iota</a>\nis two combinators.\n<a href=\"https://github.com/Robert-van-Engelen/tinylisp/blob/main/tinylisp.pdf\">tinylisp</a>\nis 99 lines of C. <a href=\"https://github.com/fuzzballcat/milliForth\">milliForth</a> is 340\n<em>bytes</em>. <a href=\"https://wiki.xxiivv.com/site/fractran.html\">Fractran</a> multiplies\nfractions. Oh, <a href=\"https://needleful.net/blog/2024/01/arthur_whitney.html\">K</a>?</p>\n<p>I've encountered tiny implementations of Forth, Lisp, C, Prolog, etc., but never\n\"milliHaskell\".</p>\n<p><small class=\"footnote\" id=\"footnote-note\">Yes, I'm still slowly working on\n    <a href=\"https://scrapscript.org\">scrapscript</a>.</small></p>\n<p><a href=\"https://en.wikipedia.org/wiki/ML_(programming_language)\">ML-style</a> languages\ncarry a pungent monad odor that attracts mathochists. Notable examples include\nHaskell, Elm, F#, Scala, and OCaml. They're \"Lambda Calculus with syntactic\nsugar\", i.e. <a href=\"https://en.wikipedia.org/wiki/Functional_programming\">functional</a>\nand <a href=\"https://en.wikipedia.org/wiki/Type_system#STATIC\">statically-typed</a>. Most\nimplementations extend\n<a href=\"https://en.wikipedia.org/wiki/Hindley\u2013Milner_type_system\">Hindley-Milner type inference</a>\nwith <a href=\"https://en.wikipedia.org/wiki/Abstract_type\">algebraic data types</a>,\npattern matching, and closures:</p>\n<table>\n<thead>\n<tr>\n<th id=\"feature\">Feature</th>\n<th id=\"loc\">LOC</th>\n<th id=\"dependencies\">Dependencies</th>\n<th id=\"references\">References</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Integer arithmetic</td>\n<td>~50</td>\n<td>Parser, codegen</td>\n<td>MinCaml</td>\n</tr>\n<tr>\n<td>Floating-point</td>\n<td>~100</td>\n<td>Parser, codegen (SSE/NEON)</td>\n<td>MinCaml</td>\n</tr>\n<tr>\n<td>Booleans + if/then/else</td>\n<td>~50</td>\n<td>Parser, codegen</td>\n<td>Everything</td>\n</tr>\n<tr>\n<td>Let bindings</td>\n<td>~30</td>\n<td>Parser, normalization</td>\n<td>Everything</td>\n</tr>\n<tr>\n<td>First-class functions (closures)</td>\n<td>~200</td>\n<td>Closure conversion, runtime</td>\n<td>MinCaml</td>\n</tr>\n<tr>\n<td>Recursive functions (let rec)</td>\n<td>~50</td>\n<td>Type inference (occurs check), codegen</td>\n<td>MinCaml</td>\n</tr>\n<tr>\n<td>Tuples</td>\n<td>~100</td>\n<td>Parser, type inference, codegen</td>\n<td>MinCaml</td>\n</tr>\n<tr>\n<td>Arrays</td>\n<td>~100</td>\n<td>Parser, runtime (bounds checking)</td>\n<td>MinCaml</td>\n</tr>\n<tr>\n<td>Monomorphic type inference</td>\n<td>~100</td>\n<td>Unification</td>\n<td>MinCaml</td>\n</tr>\n<tr>\n<td>Polymorphic type inference (HM)</td>\n<td>~300</td>\n<td>Generalization, instantiation</td>\n<td>Algorithm W, PLZoo</td>\n</tr>\n<tr>\n<td>Algebraic data types</td>\n<td>~200\u2013400</td>\n<td>Parser, type checker, runtime (tagging)</td>\n<td>HaMLet, Tao</td>\n</tr>\n<tr>\n<td>Pattern matching (basic)</td>\n<td>~200</td>\n<td>Exhaustiveness check, case trees</td>\n<td>Tao, Ante</td>\n</tr>\n<tr>\n<td>Pattern matching (optimized)</td>\n<td>~400\u2013600</td>\n<td>Maranget's algorithm</td>\n<td>OCaml, Rust</td>\n</tr>\n<tr>\n<td>Type classes</td>\n<td>~500\u20132000</td>\n<td>Dictionary passing, instance resolution</td>\n<td>MicroHs, Ben Lynn</td>\n</tr>\n<tr>\n<td>Modules (basic)</td>\n<td>~500\u20131000</td>\n<td>Namespace management</td>\n<td>HaMLet</td>\n</tr>\n<tr>\n<td>Modules (functors/signatures)</td>\n<td>~2000\u20135000</td>\n<td>Type-level computation</td>\n<td>HaMLet, 1ML</td>\n</tr>\n<tr>\n<td>Row polymorphism</td>\n<td>~300\u2013800</td>\n<td>Extended unification</td>\n<td>EYG, type-systems</td>\n</tr>\n<tr>\n<td>Algebraic effects</td>\n<td>~500\u20131500</td>\n<td>Effect typing, runtime support</td>\n<td>Eff, Frank, Ante</td>\n</tr>\n<tr>\n<td>Algebraic subtyping</td>\n<td>~500</td>\n<td>Polar types, biunification</td>\n<td>Simple-sub</td>\n</tr>\n<tr>\n<td>Linear types</td>\n<td>~600</td>\n<td>Linearity checker</td>\n<td>Austral</td>\n</tr>\n<tr>\n<td>Lazy evaluation</td>\n<td>~300\u2013500</td>\n<td>Thunks, memoization runtime</td>\n<td>MicroHs, Ben Lynn</td>\n</tr>\n<tr>\n<td>Garbage collection (Cheney)</td>\n<td>~200</td>\n<td>Runtime system</td>\n<td>Most</td>\n</tr>\n<tr>\n<td>Tail call optimization</td>\n<td>~50\u2013100</td>\n<td>Codegen (jump instead of call)</td>\n<td>MinCaml</td>\n</tr>\n<tr>\n<td>Inline expansion</td>\n<td>~100</td>\n<td>Normalization pass</td>\n<td>MinCaml</td>\n</tr>\n<tr>\n<td>Dead code elimination</td>\n<td>~50</td>\n<td>Free variable analysis</td>\n<td>MinCaml</td>\n</tr>\n<tr>\n<td>Totality checking</td>\n<td>~300\u2013500</td>\n<td>Coverage analysis, termination checker</td>\n<td>Tao, Dhall</td>\n</tr>\n</tbody>\n</table>\n<p>Further reading:</p>\n<ul>\n<li><a href=\"http://dev.stephendiehl.com/fun/\">Write You a Haskell</a> (and\n<a href=\"https://github.com/JKTKops/Write-You-a-Haskell-2\">sequel</a>): builds a Haskell\nsubset incrementally: lambda calculus \u2192 STLC \u2192 HM inference \u2192 ADTs \u2192 pattern\nmatching \u2192 type classes \u2192 STG \u2192 LLVM.</li>\n<li><a href=\"https://www.microsoft.com/en-us/research/publication/implementing-functional-languages-a-tutorial/\">Implementing Functional Languages: a tutorial</a>\nby Simon Peyton Jones &amp; David Lester: complete implementations of template\ninstantiation, G-Machine, TIM, and parallel G-Machine for a lazy Core\nlanguage.\n<a href=\"https://danilafe.com/blog/00_compiler_intro/\">Reimplemented in C++ with LLVM</a>\nby Daniel Fedorin.</li>\n<li><a href=\"https://xavierleroy.org/publi/ZINC.pdf\">The ZINC experiment</a>: the\nfoundational paper behind OCaml's bytecode compiler. The ZINC abstract machine\nuses ~140 instructions and 7 registers. Implementations include OMicroB\n(running OCaml bytecode on PIC18 microcontrollers with &lt;10KB RAM) and\nHardCaml-Zinc (hardware implementation).</li>\n<li><a href=\"https://github.com/AndrasKovacs/elaboration-zoo\">Elaboration Zoo</a>:\nprogressive dependent type checking implementations, each a single Haskell\nfile of 200\u2013800 lines, from basic NbE through holes, implicit arguments, and\nfirst-class polymorphism. The best resource for understanding modern\nelaboration. Its companion <a href=\"https://github.com/AndrasKovacs/smalltt\">smalltt</a>\n(~1\u20132K LOC Haskell) is a complete dependent type elaborator with\nnormalization-by-evaluation.</li>\n<li><a href=\"https://en.wikipedia.org/wiki/Modern_Compiler_Implementation_in_ML\">Modern Compiler Implementation in ML</a>:\nthe Tiger language compiler covers every phase from lexing through\ngraph-coloring register allocation in ~5,000\u20138,000 LOC of SML. Multiple GitHub\nimplementations target x86-64 and RISC-V.</li>\n</ul>\n<p>If you want a milliHaskell, all your inspiration/ingredients are right here.</p>\n<hr />\n<h2 id=\"hirrolots-coc\">Hirrolot's CoC</h2>\n<blockquote>\n  <p>\ud83e\udd16 The most extreme capability-to-size ratio in this list \u2014 a complete\n  Calculus of Constructions (the type theory at the top of the lambda cube) with\n  bidirectional typing, dependent function types, and a type-in-type universe,\n  all in a single OCaml gist of ~60\u201380 lines. It can express length-indexed\n  vectors and other dependently typed programs. Not ML-family per se, but it\n  demonstrates that full dependent types need not be complex to implement.</p>\n</blockquote>\n<ul>\n<li><strong>Gist</strong>:\n<a href=\"https://gist.github.com/Hirrolot/27e6b02a051df333811a23b97c375196\">gist.github.com/Hirrolot/27e6b02a051df333811a23b97c375196</a></li>\n</ul>\n<h2 id=\"harrop-miniml\">Harrop MiniML</h2>\n<blockquote>\n  <p>\ud83e\udd16 MiniML demonstrates the absolute floor for a native-code ML compiler. Using\n  Camlp4 for parsing and OCaml's LLVM bindings, it supports integer arithmetic,\n  conditionals, and recursive first-order functions. Xavier Leroy noted the\n  critical caveat: this is not truly \"Mini-ML\" since it lacks higher-order\n  first-class functions \u2014 adding closures and garbage collection would\n  significantly expand the codebase. Still, it shows what LLVM enables in ~100\n  lines.</p>\n</blockquote>\n<ul>\n<li><strong>Gist</strong>:\n<a href=\"https://gist.github.com/jdh30/6130c615b5945fd57fc0ea74fcb87e05\">gist.github.com/jdh30/6130c615b5945fd57fc0ea74fcb87e05</a></li>\n</ul>\n<h2 id=\"algorithm-w\">Algorithm W</h2>\n<blockquote>\n  <p>\ud83e\udd16 <strong>Algorithm W Step by Step</strong> by Martin Grabm\u00fcller (~300 LOC, literate\n  Haskell) is the canonical educational implementation of Algorithm W for\n  Hindley-Milner type inference. Self-contained, well-commented, and widely\n  referenced \u2014 this is where most people first implement HM inference.</p>\n</blockquote>\n<ul>\n<li><strong>Repo</strong>:\n<a href=\"https://github.com/mgrabmueller/AlgorithmW\">github.com/mgrabmueller/AlgorithmW</a></li>\n</ul>\n<h2 id=\"type-systems\">tomprimozic/type-systems</h2>\n<blockquote>\n  <p>\ud83e\udd16 A collection of standalone implementations of several inference algorithms\n  in OCaml (~300\u2013600 LOC total): basic Algorithm W, <strong>row polymorphism</strong> (the\n  technique foundational to Elm's original type system), and HMF (first-class\n  polymorphism with partial inference). Each variant is self-contained in a\n  single directory. Where Algorithm W Step by Step teaches you <em>one</em> algorithm\n  well, this repository shows you what changes when you swap in more powerful\n  type system features.</p>\n</blockquote>\n<ul>\n<li><strong>Repo</strong>:\n<a href=\"https://github.com/tomprimozic/type-systems\">github.com/tomprimozic/type-systems</a></li>\n</ul>\n<h2 id=\"lambda-calculus-hs\">lambda-calculus-hs</h2>\n<blockquote>\n  <p>\ud83e\udd16 A progressive collection of single-file lambda calculus implementations in\n  Haskell (~200\u2013900 LOC each) by Solomon Bothwell. Starts with simply typed\n  evaluation and builds incrementally through bidirectional typechecking,\n  normalization by evaluation (NbE), System T, records with depth subtyping, and\n  nominal inductive types with dependent pattern matching. Each implementation\n  is self-contained. Where tomprimozic/type-systems varies the <em>inference\nalgorithm</em>, this repository varies the <em>type system</em> while keeping\n  bidirectional checking as the constant.</p>\n</blockquote>\n<ul>\n<li><strong>Repo</strong>:\n<a href=\"https://github.com/solomon-b/lambda-calculus-hs\">github.com/solomon-b/lambda-calculus-hs</a></li>\n</ul>\n<h2 id=\"thih\">THIH</h2>\n<blockquote>\n  <p>\ud83e\udd16 <strong>Typing Haskell in Haskell</strong> by Mark P. Jones is the definitive executable\n  specification of Haskell 98's complete type system in just <strong>429 lines of core\nHaskell</strong>. It covers kinds, qualified types, type classes, pattern matching\n  types, binding groups, mutual recursion, and defaulting. For context, the Hugs\n  type checker implementing the same semantics spans 90+ pages of C. THIH is a\n  type checker only (no evaluation), but its density of specification per line\n  of code is unmatched.</p>\n</blockquote>\n<ul>\n<li><strong>Paper</strong>: <a href=\"https://web.cecs.pdx.edu/~mpj/thih/\">web.cecs.pdx.edu/~mpj/thih/</a></li>\n<li><strong>Hackage</strong>:\n<a href=\"https://hackage.haskell.org/package/thih\">hackage.haskell.org/package/thih</a></li>\n</ul>\n<h2 id=\"simple-sub\">Simple-sub</h2>\n<blockquote>\n  <p>\ud83e\udd16 <strong>~500 LOC of Scala.</strong> Lionel Parreaux's clean reimplementation of Stephen\n  Dolan's MLsub \u2014 algebraic subtyping that adds union and intersection types to\n  Hindley-Milner while preserving principal types. No annotations required. The\n  original MLsub won POPL 2017; Simple-sub distills it into an ICFP 2020 Pearl\n  that's small enough to read in one sitting. The ancestor of MLscript, which\n  grows the idea into a full language with OOP and TypeScript interop.</p>\n</blockquote>\n<ul>\n<li><strong>Repo</strong>: <a href=\"https://github.com/LPTK/simple-sub\">github.com/LPTK/simple-sub</a></li>\n<li><strong>Paper</strong>: \"The Simple Essence of Algebraic Subtyping\" (ICFP 2020)</li>\n</ul>\n<h2 id=\"plzoo-poly\">PLZoo <code>poly</code></h2>\n<blockquote>\n  <p>\ud83e\udd16 <strong>~400\u2013600 LOC, OCaml.</strong> Implements a lazy, purely functional language\n  with parametric polymorphism and HM type inference. Its sibling <code>miniml</code>\n  (~300\u2013500 LOC) includes a compiler targeting an abstract machine. Both are\n  part of Andrej Bauer's Programming Languages Zoo, which contains 12+ miniature\n  language implementations, each a few hundred lines of OCaml, covering\n  everything from untyped lambda calculus to call-by-push-value.</p>\n</blockquote>\n<ul>\n<li><strong>Website</strong>: <a href=\"https://plzoo.andrej.com/\">plzoo.andrej.com</a></li>\n<li><strong>Repo</strong>: <a href=\"https://github.com/andrejbauer/plzoo\">github.com/andrejbauer/plzoo</a></li>\n</ul>\n<h2 id=\"eyg\">EYG</h2>\n<blockquote>\n  <p>\ud83e\udd16 <strong>~500 LOC JavaScript interpreter</strong>, full implementation in Gleam. EYG\n  (\"Eat Your Greens\") by Peter Saxton prioritizes predictability, portability,\n  and crash-free programs. It uses row-typed inference (HM extended with row\n  polymorphism), algebraic effects as the sole FFI mechanism, and closure\n  serialization \u2014 functions can be sent to other machines for tierless\n  client/server programming. The most distinctive feature: programs are stored\n  as JSON ASTs, not text files. A structural editor makes it impossible to write\n  syntactically invalid programs.</p>\n</blockquote>\n<ul>\n<li><strong>Repo</strong>:\n<a href=\"https://github.com/CrowdHailer/eyg-lang\">github.com/CrowdHailer/eyg-lang</a></li>\n<li><strong>Website</strong>: <a href=\"https://eyg.run/\">eyg.run</a></li>\n<li><strong>Talk</strong>: SPLASH/LIVE 2024</li>\n</ul>\n<h2 id=\"pico-ml\">Pico-ml</h2>\n<blockquote>\n  <p>\ud83e\udd16 An OCaml subset with HM type inference that compiles to WebAssembly,\n  implemented in TypeScript. Small and self-contained \u2014 unusual for having a\n  TypeScript host language rather than the OCaml/Haskell norm. A good starting\n  point if you want to understand ML compilation targeting the browser.</p>\n</blockquote>\n<ul>\n<li><strong>Repo</strong>: <a href=\"https://github.com/Quramy/pico-ml\">github.com/Quramy/pico-ml</a></li>\n</ul>\n<h2 id=\"tinyml\">TinyML</h2>\n<blockquote>\n  <p>\ud83e\udd16 <strong><700 LOC, Standard ML.</strong> Packs a lexer, parser, interpreter, and full\n  polymorphic HM type checker into under 700 lines of SML. Referenced on Lambda\n  the Ultimate, this may be the <strong>smallest complete implementation with genuine\nHindley-Milner inference</strong>, though the original download link appears to have\n  gone stale.</p>\n</blockquote>\n<ul>\n<li><strong>Reference</strong>:\n<a href=\"http://lambda-the-ultimate.org/node/2683\">lambda-the-ultimate.org/node/2683</a></li>\n</ul>\n<h2 id=\"eff\">Eff</h2>\n<blockquote>\n  <p>\ud83e\udd16 The original algebraic effects language (2012) by Andrej Bauer and Matija\n  Pretnar. OCaml syntax with effect handlers as first-class constructs \u2014 you\n  declare effect operations, then install handlers that give them meaning. This\n  is where the idea was first made concrete in a running implementation. Koka,\n  Frank, OCaml 5's effect handlers, and virtually every subsequent algebraic\n  effects system trace lineage here.</p>\n</blockquote>\n<ul>\n<li><strong>Repo</strong>: <a href=\"https://github.com/matijapretnar/eff\">github.com/matijapretnar/eff</a></li>\n<li><strong>Paper</strong>: \"Programming with Algebraic Effects and Handlers\" (2012)</li>\n</ul>\n<h2 id=\"frank\">Frank</h2>\n<blockquote>\n  <p>\ud83e\udd16 <strong>\"Do Be Do Be Do\"</strong> (POPL 2017) by Sam Lindley, Conor McBride, and Craig\n  McLaughlin. A strict effectful functional language where functions are\n  handlers that handle zero effects \u2014 and multihandlers generalize function\n  abstraction to handle multiple effect interfaces simultaneously. The insight:\n  the boundary between \"function\" and \"effect handler\" is artificial.\n  Implemented in Haskell. Lindley describes it as \"the one I'm most fond of\"\n  while noting it's \"basically unmaintained.\" That tension between conceptual\n  elegance and practical neglect is the story of many languages on this list.</p>\n</blockquote>\n<ul>\n<li><strong>Repo</strong>: <a href=\"https://github.com/frank-lang/frank\">github.com/frank-lang/frank</a></li>\n<li><strong>Paper</strong>: \"Do Be Do Be Do\" (POPL 2017)</li>\n</ul>\n<h2 id=\"grace\">Grace</h2>\n<blockquote>\n  <p>\ud83e\udd16 A JSON superset with bidirectional type checking and row polymorphism, by\n  Gabriella Gonzalez (author of Dhall). Designed explicitly as a\n  <strong>\"ready-to-fork\" language skeleton</strong> \u2014 if you need a typed DSL, clone Grace\n  and customize it. Has open records, open unions (polymorphic variants), and a\n  clean Haskell codebase that reads like a tutorial. No Hindley-Milner per se\n  (bidirectional instead), but closely related.</p>\n</blockquote>\n<ul>\n<li><strong>Repo</strong>:\n<a href=\"https://github.com/Gabriella439/grace\">github.com/Gabriella439/grace</a></li>\n<li><strong>Blog</strong>:\n<a href=\"https://www.haskellforall.com/2021/09/fall-from-grace-ready-to-fork.html\">haskellforall.com/2021/09/fall-from-grace-ready-to-fork.html</a></li>\n</ul>\n<h2 id=\"hackett\">Hackett</h2>\n<blockquote>\n  <p>\ud83e\udd16 A Haskell-like language implemented entirely as <strong>Racket macros</strong> via the\n  \"Type Systems as Macros\" technique, by Alexis King. Bidirectional type\n  inference, algebraic datatypes, pattern matching, typeclasses, higher-kinded\n  types, and higher-rank polymorphism \u2014 all implemented not as a separate\n  type-checker pass but as macro expansion. The meta-angle is the story: types\n  as macros rather than a traditional elaboration pipeline.</p>\n</blockquote>\n<ul>\n<li><strong>Repo</strong>:\n<a href=\"https://github.com/lexi-lambda/hackett\">github.com/lexi-lambda/hackett</a></li>\n<li><strong>Paper</strong>: \"Type Systems as Macros\" (POPL 2017)</li>\n</ul>\n<h2 id=\"scrapscript\">Scrapscript</h2>\n<blockquote>\n  <p>\ud83e\udd16 A content-addressable pure functional language where every expression\n  reduces to a cryptographic hash, stored in a decentralized \"scrapyard\"\n  registry and referenced by hash or alias. The implementation is a\n  <strong>~1,300-line dependency-free Python interpreter in a single file</strong>, with a\n  baseline compiler to C (~500 LOC) and an SSA IR with SCCP/DCE optimization\n  (~1,000 LOC). Pattern matching is the sole control-flow mechanism. Compiles to\n  C, WebAssembly, and Cosmopolitan portable executables. Implemented primarily\n  by Max Bernstein.</p>\n</blockquote>\n<ul>\n<li><strong>Repo</strong>:\n<a href=\"https://github.com/tekknolagi/scrapscript\">github.com/tekknolagi/scrapscript</a></li>\n<li><strong>Blog series</strong>: Max Bernstein's implementation walkthroughs at\n<a href=\"https://bernsteinbear.com/blog/scrapscript/\">bernsteinbear.com/blog/scrapscript/</a></li>\n</ul>\n<h2 id=\"mincaml\">MinCaml</h2>\n<blockquote>\n  <p>\ud83e\udd16 <strong>~2,000 LOC, OCaml \u2192 native code.</strong> The gold standard for\n  capability-to-code-size ratio. Written by Eijiro Sumii at Tohoku University,\n  it implements a strict, higher-order functional language with type inference,\n  closures, tuples, arrays, tail-call optimization, inline expansion, constant\n  folding, and graph-coloring register allocation. It compiles to SPARC,\n  PowerPC, and x86 assembly. On benchmarks including a ray tracer,\n  <strong>MinCaml-compiled code runs within 2\u00d7 of GCC and OCaml's <code>ocamlopt</code></strong> \u2014\n  sometimes faster. The deliberate trade-off: it omits polymorphism, algebraic\n  data types, and pattern matching. Used in undergraduate compiler courses at\n  the University of Tokyo since 2001, where students build ray tracers compiled\n  by their own compilers running on custom CPUs.</p>\n</blockquote>\n<ul>\n<li><strong>Repo</strong>: <a href=\"https://github.com/esumii/min-caml\">github.com/esumii/min-caml</a></li>\n<li><strong>Paper</strong>: \"MinCaml: A Simple and Efficient Compiler for a Minimal Functional\nLanguage\" (FDPE 2005)</li>\n<li><strong>Forks</strong>: <a href=\"https://github.com/rhysd/gocaml\">gocaml</a> (Go + LLVM\nreimplementation), <a href=\"https://github.com/cmaes/miniml\">miniml</a> (OCaml + LLVM,\n~1,500 LOC, adds LLVM backend to MinCaml's architecture)</li>\n</ul>\n<h2 id=\"ben-lynn\">Ben Lynn</h2>\n<blockquote>\n  <p>\ud83e\udd16 <strong>~2,000 lines of Haskell + 350 lines of C.</strong> Arguably the most remarkable\n  bootstrapping achievement in this space. Starting from a 350-SLOC C runtime\n  that interprets combinatory logic, Lynn builds a chain of approximately 20\n  progressively more capable compilers, each written in the subset of Haskell\n  that the previous compiler can handle. The final compiler supports type\n  inference, type classes, algebraic data types, pattern matching, guards, where\n  clauses, monadic I/O, modules, and layout parsing \u2014 approaching <strong>Haskell 98\ncoverage</strong>. It compiles Haskell to combinatory logic via Kiselyov's bracket\n  abstraction algorithm, with graph reduction evaluation. Later stages even\n  target WebAssembly. The entire bootstrapping chain is reproducible from just a\n  C compiler.</p>\n</blockquote>\n<ul>\n<li><strong>Repo</strong>: <a href=\"https://github.com/blynn/compiler\">github.com/blynn/compiler</a></li>\n<li><strong>Website</strong>:\n<a href=\"https://crypto.stanford.edu/~blynn/compiler/\">crypto.stanford.edu/~blynn/compiler/</a>\n\u2014 \"Compiler Quest,\" an extraordinary walkthrough of each bootstrapping stage</li>\n<li><strong>Annotated fork</strong>:\n<a href=\"https://github.com/siraben/mini-haskell\">github.com/siraben/mini-haskell</a>\n(~1,500 LOC Haskell + 350 LOC C, MIT-licensed, well-commented)</li>\n</ul>\n<h2 id=\"1ml\">1ML</h2>\n<blockquote>\n  <p>\ud83e\udd16 <strong>~3,000\u20135,000 LOC, OCaml.</strong> Andreas Rossberg unified ML's core and module\n  layers into a single language where modules are first-class values, types are\n  values, and functors are ordinary functions. It elaborates to System F\u03c9 with\n  HM-style inference. Won the <strong>ICFP Most Influential Paper Award in 2025</strong>. A\n  proof-of-concept interpreter, not optimized, but a conceptual breakthrough in\n  minimal surface area.</p>\n</blockquote>\n<ul>\n<li><strong>Repo</strong>: <a href=\"https://github.com/rossberg/1ml\">github.com/rossberg/1ml</a></li>\n<li><strong>Paper</strong>: \"1ML \u2014 Core and modules united\" (ICFP 2015, JFP 2018)</li>\n</ul>\n<h2 id=\"mlml\">mlml</h2>\n<blockquote>\n  <p>\ud83e\udd16 A self-hosting OCaml subset compiler targeting native x86-64. ~3,000\u20135,000\n  LOC. Supports pattern matching, algebraic data types, recursive functions, and\n  closures. Does not implement type inference \u2014 it demonstrates the minimum\n  OCaml subset needed for self-compilation.</p>\n</blockquote>\n<ul>\n<li><strong>Repo</strong>: <a href=\"https://github.com/coord-e/mlml\">github.com/coord-e/mlml</a></li>\n</ul>\n<h2 id=\"dhall\">Dhall</h2>\n<blockquote>\n  <p>\ud83e\udd16 A total (non-Turing-complete) typed configuration language. ~4K LOC core\n  Haskell. Normalization is guaranteed to terminate \u2014 you can always reduce a\n  Dhall expression to a normal form, which means imports resolve, functions\n  inline, and what you get is plain data. Based on a\n  Calculus-of-Constructions-derived type theory with records, unions, and\n  natural numbers. Has a formal specification and implementations in Haskell,\n  Rust, Go, and Clojure.</p>\n</blockquote>\n<ul>\n<li><strong>Repo</strong>:\n<a href=\"https://github.com/dhall-lang/dhall-haskell\">github.com/dhall-lang/dhall-haskell</a></li>\n<li><strong>Website</strong>: <a href=\"https://dhall-lang.org/\">dhall-lang.org</a></li>\n</ul>\n<h2 id=\"ante\">Ante</h2>\n<blockquote>\n  <p>\ud83e\udd16 Combines HM type inference, algebraic data types, pattern matching,\n  algebraic effects, and an ownership-like system for shared mutability. Written\n  in Rust, it uses <strong>Cranelift</strong> for native code generation. Actively developed,\n  aiming to bridge the Rust/OCaml divide.</p>\n</blockquote>\n<ul>\n<li><strong>Repo</strong>: <a href=\"https://github.com/jfecher/ante\">github.com/jfecher/ante</a></li>\n</ul>\n<h2 id=\"tao\">Tao</h2>\n<blockquote>\n  <p>\ud83e\udd16 Surprisingly feature-rich for its size: generics, typeclasses, sum types,\n  pattern matching, first-class functions, currying, algebraic effects,\n  associated types, and totality checking. Its pipeline runs from lexing through\n  HIR type inference to MIR monomorphization and bytecode execution. Written in\n  Rust.</p>\n</blockquote>\n<ul>\n<li><strong>Repo</strong>: <a href=\"https://github.com/zesterer/tao\">github.com/zesterer/tao</a></li>\n</ul>\n<h2 id=\"austral\">Austral</h2>\n<blockquote>\n  <p>\ud83e\udd16 A systems language with <strong>linear types</strong> and capability-based security. The\n  linear type checker is ~600 lines. OCaml bootstrap compiler targeting C.\n  Designed by Fernando Borretti to fit in one person's head \u2014 the spec is\n  deliberately small enough that a single developer can understand the entire\n  language. Not functional in the Haskell sense, but linear types make it\n  adjacent. An experiment in \"what if we took linear types seriously but kept\n  the language small.\"</p>\n</blockquote>\n<ul>\n<li><strong>Repo</strong>: <a href=\"https://github.com/austral/austral\">github.com/austral/austral</a></li>\n<li><strong>Website</strong>: <a href=\"https://austral-lang.org/\">austral-lang.org</a></li>\n</ul>\n<h2 id=\"aqaml\">AQaml</h2>\n<blockquote>\n  <p>\ud83e\udd16 A self-hosting OCaml subset compiler targeting native x86-64. ~5,000\u20138,000\n  LOC. Adds records, variants, references, and garbage collection beyond what\n  mlml supports. Triple self-hosting verified. Like mlml, it omits type\n  inference \u2014 demonstrating the minimum OCaml needed for self-compilation.</p>\n</blockquote>\n<ul>\n<li><strong>Repo</strong>:\n<a href=\"https://github.com/ushitora-anqou/aqaml\">github.com/ushitora-anqou/aqaml</a></li>\n</ul>\n<h2 id=\"borgo\">Borgo</h2>\n<blockquote>\n  <p>\ud83e\udd16 Adds ML-family features (algebraic data types, exhaustive pattern matching,\n  Result/Option types) to Go's ecosystem by compiling to Go source code with\n  Rust-like syntax. Written in Rust.</p>\n</blockquote>\n<ul>\n<li><strong>Repo</strong>: <a href=\"https://github.com/borgo-lang/borgo\">github.com/borgo-lang/borgo</a></li>\n</ul>\n<h2 id=\"polytt\">polytt</h2>\n<blockquote>\n  <p>\ud83e\udd16 A research experiment from the Topos Institute extending Martin-L\u00f6f Type\n  Theory with native, first-class polynomial functors \u2014 the mathematical objects\n  underlying deterministic state machines and interactive systems. Written in\n  OCaml with Menhir parsing. Custom syntax for polynomial types (<code>y^n</code>),\n  morphism arrows, and wiring operators. Dependent types (Pi, Sigma), finite-set\n  ADTs, and pattern matching via case elimination. An ended experiment, but a\n  unique point in the design space: what happens when you make polynomial\n  functors a language primitive rather than an encoding.</p>\n</blockquote>\n<ul>\n<li><strong>Repo</strong>:\n<a href=\"https://github.com/ToposInstitute/polytt\">github.com/ToposInstitute/polytt</a></li>\n</ul>\n<h2 id=\"newt\">Newt</h2>\n<blockquote>\n  <p>\ud83e\udd16 <strong>~7K LOC, self-hosted, compiles to JavaScript.</strong> A dependently typed\n  language with Agda/Idris/Haskell-like syntax by Steve Dunham. Bidirectional\n  typechecking with normalization by evaluation (based on Elaboration Zoo),\n  typeclasses, ADTs with dependent pattern matching, case tree compilation,\n  trampoline-based TCO for mutually tail-recursive functions, and erasure of\n  compile-time-only values (0/\u03c9 quantities). Has a web playground and an LSP.\n  The compiler is written in Newt itself. Built as a learning exercise, but the\n  feature set \u2014 self-hosting, dependent types, typeclasses, erasure, LSP \u2014 puts\n  it well beyond most pedagogical implementations.</p>\n</blockquote>\n<ul>\n<li><strong>Repo</strong>: <a href=\"https://github.com/dunhamsteve/newt\">github.com/dunhamsteve/newt</a></li>\n<li><strong>Playground</strong>:\n<a href=\"https://dunhamsteve.github.io/newt\">dunhamsteve.github.io/newt</a></li>\n</ul>\n<h2 id=\"hamlet\">HaMLet</h2>\n<blockquote>\n  <p>\ud83e\udd16 <strong>~10,000\u201315,000 LOC, SML.</strong> Andreas Rossberg's most faithful\n  implementation of the Definition of Standard ML. It implements <strong>all of SML\n'97</strong> including the full module system (signatures, structures, functors),\n  mapping rule-by-rule to the formal Definition. Jeremy Yallop recommends it as\n  the most readable SML implementation. It can be bundled into a single SML file\n  and compiled by any SML implementation. A <code>compile-js</code> branch demonstrates\n  compilation to JavaScript.</p>\n</blockquote>\n<ul>\n<li><strong>Repo</strong>: <a href=\"https://github.com/rossberg/hamlet\">github.com/rossberg/hamlet</a></li>\n</ul>\n<h2 id=\"sosml\">SOSML</h2>\n<blockquote>\n  <p>\ud83e\udd16 <strong>~10,000\u201315,000 LOC, TypeScript.</strong> Implements the full SML core language\n  in the browser: val/fun/datatype declarations, pattern matching, HM type\n  inference, exceptions, and references. Used for teaching at Saarland\n  University.</p>\n</blockquote>\n<ul>\n<li><strong>Website</strong>: <a href=\"https://sosml.org\">sosml.org</a></li>\n<li><strong>Repo</strong>: <a href=\"https://github.com/SOSML/SOSML\">github.com/SOSML/SOSML</a></li>\n</ul>\n<h2 id=\"microhs\">MicroHs</h2>\n<blockquote>\n  <p>\ud83e\udd16 By Lennart Augustsson (one of GHC's original creators) \u2014 the most complete\n  \"small\" Haskell compiler alive today. It compiles an extended subset of\n  <strong>Haskell 2010</strong> including type classes, do-notation, deriving, record syntax,\n  overloaded literals, and modules. It is fully self-hosting and \u2014 critically \u2014\n  <strong>bootstrappable from only a C compiler</strong> (no pre-existing Haskell toolchain\n  required). MicroHs translates Haskell to combinators executed by a C runtime.\n  It has a JavaScript runtime target, a package manager (<code>mcabal</code>), and can\n  compile real Hackage packages like QuickCheck. The codebase is not trivially\n  small (estimated <strong>15,000\u201330,000 lines</strong> across compiler, libraries, and\n  runtime), but for what it does \u2014 a near-complete Haskell compiler\n  bootstrappable from C \u2014 it is remarkably compact.</p>\n</blockquote>\n<ul>\n<li><strong>Repo</strong>: <a href=\"https://github.com/augustss/MicroHs\">github.com/augustss/MicroHs</a></li>\n<li><strong>Paper</strong>: \"MicroHs: A Small Compiler for Haskell\" (Haskell Symposium 2024)</li>\n</ul>"
            ],
            "link": "https://taylor.town/scrapscript-000",
            "publishedAt": "2026-02-20",
            "source": "Taylor Troesh",
            "summary": "<table> <thead> <tr> <th id=\"\"></th> <th id=\"\"></th> <th id=\"loc\">LOC</th> <th id=\"host\">Host</th> <th id=\"hm\">HM</th> <th id=\"adts\">ADTs</th> <th id=\"match\">Match</th> <th id=\"cl.\">Cl.</th> <th id=\"target\">Target</th> </tr> </thead> <tbody> <tr> <td><a href=\"https://taylor.town/feed.xml#hirrolots-coc\">Hirrolot's CoC</a></td> <td><a href=\"https://gist.github.com/Hirrolot/27e6b02a051df333811a23b97c375196\">src</a></td> <td>~70</td> <td>OCaml</td> <td>\u2717</td> <td>\u2717</td> <td>\u2717</td> <td>\u2713</td> <td>Interpreter</td> </tr> <tr> <td><a href=\"https://taylor.town/feed.xml#harrop-miniml\">Harrop MiniML</a></td> <td><a href=\"https://gist.github.com/jdh30/6130c615b5945fd57fc0ea74fcb87e05\">src</a></td> <td>~100</td> <td>OCaml</td> <td>\u2717</td> <td>\u2717</td> <td>\u2717</td> <td>\u2717</td> <td>LLVM \u2192 native</td> </tr> <tr> <td><a href=\"https://taylor.town/feed.xml#algorithm-w\">Algorithm W</a></td> <td><a href=\"https://github.com/mgrabmueller/AlgorithmW\">src</a></td> <td>~300</td> <td>Haskell</td> <td>\u2713</td> <td>\u2717</td> <td>\u2717</td> <td>\u2717</td> <td>Type checker only</td> </tr> <tr> <td><a href=\"https://taylor.town/feed.xml#type-systems\">tomprimozic/type-systems</a></td> <td><a href=\"https://github.com/tomprimozic/type-systems\">src</a></td> <td>~300</td> <td>OCaml</td> <td>\u2713</td> <td>\u2717</td> <td>\u2717</td> <td>\u2717</td> <td>Type checker only</td> </tr> <tr> <td><a href=\"https://taylor.town/feed.xml#lambda-calculus-hs\">lambda-calculus-hs</a></td> <td><a href=\"https://github.com/solomon-b/lambda-calculus-hs\">src</a></td> <td>~200\u2013900</td> <td>Haskell</td> <td>\u2717</td> <td>\u2713</td> <td>\u2713</td> <td>\u2713</td> <td>Interpreter</td> </tr> <tr> <td><a href=\"https://taylor.town/feed.xml#thih\">THIH</a></td> <td><a href=\"https://hackage.haskell.org/package/thih\">src</a></td> <td>~429</td> <td>Haskell</td> <td>\u2713</td> <td>\u2713</td> <td>\u2713</td> <td>\u2717</td> <td>Type checker only</td> </tr> <tr> <td><a href=\"https://taylor.town/feed.xml#simple-sub\">Simple-sub</a></td> <td><a href=\"https://github.com/LPTK/simple-sub\">src</a></td> <td>~500</td> <td>Scala</td> <td>\u2713</td> <td>\u2717</td> <td>\u2717</td> <td>\u2713</td> <td>Type checker only</td> </tr> <tr> <td><a href=\"https://taylor.town/feed.xml#plzoo-poly\">PLZoo <code>poly</code></a></td> <td><a href=\"https://github.com/andrejbauer/plzoo\">src</a></td> <td>~500</td> <td>OCaml</td> <td>\u2713</td> <td>\u2717</td> <td>\u2717</td> <td>\u2713</td> <td>Interpreter</td> </tr> <tr> <td><a href=\"https://taylor.town/feed.xml#eyg\">EYG</a></td> <td><a href=\"https://github.com/CrowdHailer/eyg-lang\">src</a></td> <td>~500</td> <td>Gleam</td> <td>\u2713</td> <td>\u2713</td> <td>\u2713</td> <td>\u2713</td> <td>Interpreter</td> </tr> <tr> <td><a href=\"https://taylor.town/feed.xml#pico-ml\">Pico-ml</a></td> <td><a href=\"https://github.com/Quramy/pico-ml\">src</a></td> <td>~500</td> <td>TypeScript</td> <td>\u2713</td> <td>\u2717</td> <td>\u2717</td> <td>\u2713</td> <td>WebAssembly</td> </tr> <tr> <td><a href=\"https://taylor.town/feed.xml#tinyml\">TinyML</a></td> <td><a href=\"http://lambda-the-ultimate.org/node/2683\">src</a></td> <td>&lt;700</td> <td>SML</td> <td>\u2713</td> <td>\u2717</td> <td>\u2717</td> <td>\u2713</td> <td>Interpreter</td> </tr> <tr> <td><a href=\"https://taylor.town/feed.xml#eff\">Eff</a></td> <td><a href=\"https://github.com/matijapretnar/eff\">src</a></td> <td>~1\u20132K</td> <td>OCaml</td> <td>\u2713</td> <td>\u2713</td> <td>\u2713</td> <td>\u2713</td> <td>Interpreter</td> </tr> <tr> <td><a href=\"https://taylor.town/feed.xml#frank\">Frank</a></td> <td><a href=\"https://github.com/frank-lang/frank\">src</a></td> <td>~1\u20132K</td>",
            "title": "Lil' Fun Langs"
        },
        {
            "content": [
                "<p>Things that are being pushed into the future right now:</p>\n<ol>\n<li>Gemini 3.1 Pro and Gemini DeepThink V2.</li>\n<li>Claude Sonnet 4.6.</li>\n<li>Grok 4.20.</li>\n<li>Updates on Agentic Coding.</li>\n<li>Disagreement between Anthropic and the Department of War.</li>\n</ol>\n<p>We are officially a bit behind and will have to catch up next week.</p>\n<p>Even without all that, we have a second highly full plate today.</p>\n\n\n<h4 class=\"wp-block-heading\">Table of Contents</h4>\n\n\n<p>(As a reminder: bold are my top picks, italics means highly skippable)</p>\n<ol>\n<li><a href=\"https://thezvi.substack.com/i/187763567/levels-of-friction\"><strong>Levels of Friction</strong>.</a> Marginal costs of arguing are going down.</li>\n<li><a href=\"https://thezvi.substack.com/i/187763567/the-art-of-the-jailbreak\">The Art Of The Jailbreak.</a> UK AISI finds a universal method.</li>\n<li><a href=\"https://thezvi.substack.com/i/187763567/the-quest-for-sane-regulations\"><strong>The Quest for Sane Regulations</strong>.</a> Some relatively good proposals.\n<div>\n\n\n<span id=\"more-25114\"></span>\n\n\n</div>\n</li>\n<li><a href=\"https://thezvi.substack.com/i/187763567/people-really-hate-ai\">People Really Hate AI.</a> Alas, it is mostly for the wrong reasons.</li>\n<li><a href=\"https://thezvi.substack.com/i/187763567/a-very-bad-paper\"><em>A Very Bad Paper.</em></a> Nick Bostrom writes a highly disappointing paper.</li>\n<li><a href=\"https://thezvi.substack.com/i/187763567/rhetorical-innovation\">Rhetorical Innovation.</a> The worst possible plan is the best one on the table.</li>\n<li><a href=\"https://thezvi.substack.com/i/187763567/the-most-forbidden-technique\">The Most Forbidden Technique.</a> &lt;wonka voice&gt; No, stop, come back. &lt;/wonka&gt;</li>\n<li><a href=\"https://thezvi.substack.com/i/187763567/everyone-is-or-should-be-confused-about-morality\">Everyone Is Or Should Be Confused About Morality.</a> New levels of \u2018can you?\u2019</li>\n<li><a href=\"https://thezvi.substack.com/i/187763567/aligning-a-smarter-than-human-intelligence-is-difficult\">Aligning a Smarter Than Human Intelligence is Difficult.</a> Seeking a good basin.</li>\n<li><a href=\"https://thezvi.substack.com/i/187763567/we-ll-just-call-it-something-else\">We\u2019ll Just Call It Something Else.</a> Beware responsible uncertainty quantification.</li>\n<li><a href=\"https://thezvi.substack.com/i/187763567/vulnerable-world-hypothesis\">Vulnerable World Hypothesis.</a> I\u2019m sorry, I can\u2019t help you with that. Suspicious.</li>\n<li><a href=\"https://thezvi.substack.com/i/187763567/autonomous-killer-robots\">Autonomous Killer Robots.</a> Progress is being made.</li>\n<li><a href=\"https://thezvi.substack.com/i/187763567/people-will-hand-over-power-to-the-ais\"><strong>People Will Hand Over Power To The AIs</strong>.</a> They keep telling us they will do this.</li>\n<li><a href=\"https://thezvi.substack.com/i/187763567/people-are-worried-about-ai-killing-everyone\">People Are Worried About AI Killing Everyone.</a> Or they don\u2019t, for unclear reasons.</li>\n<li><a href=\"https://thezvi.substack.com/i/187763567/other-people-are-not-worried-about-ai-killing-everyone\">Other People Are Not Worried About AI Killing Everyone.</a> Alas, Jensen Huang.</li>\n<li><a href=\"https://thezvi.substack.com/i/187763567/the-lighter-side\">The Lighter Side.</a> Word overboard.</li>\n</ol>\n\n\n<h4 class=\"wp-block-heading\">Levels of Friction</h4>\n\n\n<p>If the marginal cost goes to zero, and it inflicts marginal costs above zero on others? That system is going to have a bad time.</p>\n<blockquote><p><a href=\"https://x.com/pmarca/status/2024156021925855626\">Marc Andreessen</a>: Overheard in Silicon Valley: \u201c<a href=\"https://www.ft.com/content/afc335fb-8f32-458f-9b6f-431021774002\">Marginal cost of arguing is going to zero.</a>\u201d</p>\n<p><a href=\"https://archive.is/NlQER#selection-1937.0-1941.44\">Emma Jacobs</a>: Anna Bond, legal director in the employment team at Lewis Silkin, used to receive grievances that were typically the length of an email. Now, the complaints she sees can run to about 30 pages and span a wide range of historical issues, many of which are repeated.</p>\n<p>\u201cI suspect that AI is behind it,\u201d says Bond.</p></blockquote>\n<p>There\u2019s no need to suspect. It\u2019s AI. The marginal cost here remains very not zero. You still have to gather and document all the information for the AI somehow.</p>\n<p>If the AI is expanding a complaint into a giant mass of AI slop, then the response is to process such complaints using AI. You turn your paragraph into 30 pages, then I turn your 30 pages into a paragraph, but with the ability to then query the 30 pages as needed. I know which parts matter and should be in the paragraph, so this could be net good.</p>\n<p>The rest of the examples are similar. If you\u2019re up against AI slop court filings, you can slap them down or you can invoke your own AI, or both, and so on.</p>\n<p>The bigger problem is what happens when the AI knows the magic words.</p>\n<blockquote><p><a href=\"https://x.com/patio11/status/2024197539344375891\">Patrick McKenzie</a>: Not where I would have expected an adversarial touchpoint to get saturated first, and extremely not the last such story.</p>\n<p>If there are magic words which trigger an effect in the physical universe, then that expenditure of resources has been implicitly rate limited on how many people know the magic words and prioritize saying them.</p>\n<p>There are a lot of magic words in our society.</p>\n<p>Presumably in some circumstances we decide \u201cEh if words are cheap they can\u2019t also be magic\u201d but we have looked at that tradeoff before for some touch points and said \u201cNope actually critically important here: the right words in right order are always magic.\u201d</p>\n<p>I\u2019m most inclined to think of a few hundred examples from finance but the Due Process clause of the U.S. Constitution has a side effect of creating many, many magic words across all levels and almost all activities of the administrative state.</p>\n<p>And there is no Constitutional escape hatch for \u201cA facially valid plea for relief under Due Process is invalid if it was not artisanal in craftsmanship. It is also invalid if not signed by a certifiably important person.\u201d</p></blockquote>\n<p>Oh sure there is, it is called the \u2018SCOTUS members make stuff up based on what would work\u2019 clause of the Constitution. You know that one.</p>\n<p>I don\u2019t mean that pejoratively. Well sometimes yes I do, but also there\u2019s plenty of \u2018not a suicide pact\u2019 rulings that can adjust for practicalities. If everyone can always demand all the due process, and they start doing so a lot, then we\u2019ll redefine what that due process looks like to let AI largely handle that end, or change when you are entitled to how much of it. How much Process is Due, after all?</p>\n<blockquote><p>\u201cExample from finance?\u201d</p>\n<p>Reg E complaint on an error in processing an electronic transaction. If you say \u201cReg E\u201d bank just spent ~$200 unless they\u2019ve aggressively optimized for cramming down that number.</p></blockquote>\n<p>Exactly. The bank spent $200 now, but they can and will optimize for cramming that number down, primarily using AI. This will include some form of \u2018use AI to detect when it is likely someone is making invalid Reg E claims.\u2019</p>\n<blockquote><p>\u201cExample from non-finance?\u201d</p>\n<p>Complaints about teachers are either a) grousing common to students since time immemorial or b) immediate 5-6 figure investigations. Only takes three words to promote a complaint into that second category.</p></blockquote>\n<p>This is a curiously non-AI example, in that either you know the three words or you don\u2019t, and most of us do know them or guessed them correctly.</p>\n\n\n<h4 class=\"wp-block-heading\"></h4>\n\n\n\n<h4 class=\"wp-block-heading\">The Art Of The Jailbreak</h4>\n\n\n<p>The UK AISI shares information on their universal jailbreaking technique:</p>\n<blockquote><p><a href=\"https://www.aisi.gov.uk/blog/boundary-point-jailbreaking-a-new-way-to-break-the-strongest-ai-defences\">AISI</a>: Today, we\u2019re sharing information on <a href=\"https://arxiv.org/abs/2602.15001\"><strong>Boundary Point Jailbreaking</strong></a> (BPJ): a fully automated method for developing universal jailbreaks against the most robust deployed AI defences, in fully \u2018black-box\u2019 settings where attackers only see whether or not an input is blocked.</p>\n<p>We believe BPJ is the first automated attack to succeed against Constitutional Classifiers [1], Anthropic&#8217;s defence system that previously <a href=\"https://www.anthropic.com/research/constitutional-classifiers\">withstood over 3,700 hours of human red-teaming</a> with only one fully successful, human-led attack found in that time. BPJ is also the first automated attack to succeed against OpenAI&#8217;s input classifier for GPT-5 without relying on human seed attacks [2].</p></blockquote>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!eW8h!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F835b67a4-4a35-4a27-976d-69547fc70b88_1330x615.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p><a href=\"https://x.com/OpenAINewsroom/status/2023806364196434425\">OpenAI says they have deployed mitigations to reduce susceptibility.</a></p>\n<p>One obvious suggestion on defense is to use a potentially very cheap \u2018is there weirdness in the input\u2019 classifier to find times when you suspect someone of trying to use an adversarial prompt.</p>\n\n\n<h4 class=\"wp-block-heading\">The Quest for Sane Regulations</h4>\n\n\n<p>A good sign that some of the old semi-reasonable model of the situation has not been entirely abandoned by OpenAI?</p>\n<blockquote><p><a href=\"https://x.com/CRSegerie/status/2024570328295625153\">Charbel-Raphael</a>: Sam Altman: &#8220;The world may need something like an IAEA [International Atomic Energy Agency] for international coordination on AI&#8221;</p>\n<p>Yes!</p></blockquote>\n<p><a href=\"https://www.alexbores.nyc/files/Bores_AI_Framework.pdf\">Alex Bores proposes his AI policy framework for Congress</a>.</p>\n<ol>\n<li>Protect kids and students: Parental visibility. Age verification for risky AI services. Require scanning for self-harm. Teach kids about AI. Clear guidelines for AI use in schools, explore best uses. Ban AI CSAM.</li>\n<li>Take back control of your data. Privacy laws, data ownership, no sale of personal data, disclosure of AI interactions and data collections and training data.</li>\n<li>Stop deepfakes. Metadata standards, origin tracing, penalties for distribution.</li>\n<li>Make datacenters work for people. No rate hikes, enforce agreements, expedite data centers using green energy, repair the grid with private funds, monitor water use, close property tax loopholes.</li>\n<li>Protect and support workers. Require large companies to report AI-related workforce changes. Tax incentives for upskilling, invest in retraining, ban AI as sole decider for hiring and firing, transitional period where AI needs same licensing as a human, tax large companies for an \u2018AI dividend.\u2019</li>\n<li>Nationalize the Raise Act for Frontier AI. Require independent safety testing, mandate cybersecurity incident reporting, restrict government use of foreign AI tools, create accountability mechanisms for AI systems that harm, engage in diplomacy on AI issues.</li>\n<li>Build Government Capacity to Oversee AI. Fund CAISI, expand technical expertise, require developers to disclose key facts to regulators, develop contingency plans for catastrophic risks.</li>\n<li>Keep America Competitive. Federal funding for academic research, support for private development of safe, beneficial applications, \u2018reasonable regulation that protects people without strangling innovation,\u2019 work with allies to establish safety standards, strategic export controls, keep the door open for international agreements.</li>\n</ol>\n<p>I would like to see more emphasis on Frontier AI here, and I worry about the licensing and tax talk in #5, but mostly this is a solid list. It is also, if you disregard those few items, a highly balanced list that most should be able to get behind.</p>\n<blockquote><p><a href=\"https://x.com/jachiam0/status/2022030261819777091\">Joshua Achiam</a> (OpenAI): I think most of this framework is actually pretty commonsense, and responsive to the intersection of public, private, and national strategic needs. I have quibbles in a few places but this is a sober, credible contribution to the discourse</p>\n<p><a href=\"https://x.com/_NathanCalvin/status/2022032359282159999\">Nathan Calvin</a>: Appreciate Joshua calling balls and strikes and engaging with the details.</p>\n<p>OAI/A16z/Palantir&#8217;s Superpac spending massive to go after Alex Bores for his moderate commonsense platform on AI has honestly been one of the most disenchanting things I have ever seen in politics</p></blockquote>\n<p><a href=\"https://x.com/ChrisRMcGuire/status/2023125963068870881\">The White House continues not to propose a new regulatory regime</a>, and is leaning on <a href=\"https://x.com/FT/status/2023079927365439889\">Utah to abandon its prospective AI bill</a>.</p>\n<blockquote><p><a href=\"https://www.ft.com/content/b04fc3d5-c916-4ac8-ab4f-a65a9f4e60c5\">Joe Miller</a> (FT): A White House official said the administration objected to the bill owing to its resemblance to California\u2019s SB53, which critics claim added unnecessary bureaucratic burdens on US AI companies as they try to compete with China.</p></blockquote>\n<p>This is exactly backwards. SB 53 is a bill so mild that David Sacks finds it potentially acceptable as a national standard, and the worry is that states will have a patchwork of different laws. If Utah\u2019s proposed HB 286 is duplicative of SB 53 and the White House is not lying about what it cares about, then the overlap is Great News for AI companies and the White House.</p>\n<p>There are some additional requirements in HB 286.</p>\n<ol>\n<li>Anyone with a million MAUs needs to have a child protection plan.</li>\n<li>Whistleblower protections are broader, which seems good.</li>\n<li>Quarterly reports have to be filed with Utah in particular, and we don\u2019t want you to have to file 50 distinct reports.</li>\n</ol>\n<p>The quarterly report seems like the strongest point of objection, and I haven\u2019t looked closely into the child protection requirements, but those are things that are often fixed as bills progress. Instead the White House is calling this an \u2018unfixable\u2019 bill.</p>\n<p><a href=\"https://www.nist.gov/news-events/news/2026/02/announcing-ai-agent-standards-initiative-interoperable-and-secure\">The White House did announce</a> the \u2018AI Agents Standards Initiative\u2019 for interoperable and secure innovation, to support standards and open source protocols for agents and promote trusted adoption. Good, but this doesn\u2019t alleviate our core problems and it very much is not a federal framework.</p>\n<p><a href=\"https://x.com/daniel_271828/status/2022452660616802519\">Greg Brockman confirms that his donations to the anti-all-AI-regulation SuperPAC</a> were an extension of his work at OpenAI.</p>\n<p><a href=\"https://x.com/deanwball/status/2023052535808856161\">Dean Ball is right that prohibiting LLMs</a> from \u2018simulating human exchange\u2019 or \u2018demonstrating emotion\u2019 would be a serious mistake, being quite bad for the performance and experience of both models and their users. It seems fine to cordon off full companion-style services, if done wisely.</p>\n<p><a href=\"https://www.transformernews.ai/p/the-left-is-missing-out-on-ai-sanders-doctorow-bender-bores\">Dan Kagan-Kans has another overview of how the left is in full denial about AI</a>, academia is too slow moving to be relevant, and both are being left behind almost entirely in discussions about AI as a result.</p>\n\n\n<h4 class=\"wp-block-heading\">People Really Hate AI</h4>\n\n\n<blockquote><p><a href=\"https://x.com/jasminewsun/status/2022101223202336859\">jasmine sun</a>: I went to DC to talk to people across the political spectrum (&amp; see some data centers) and concluded that we are *really* not ready for how much people hate AI</p>\n<p><a href=\"https://jasmi.news/p/ai-populism\">new scene report on my week with the AI populists</a>.</p></blockquote>\n<p>Jasmine lists the varied coalition of concerns against AI, many of which are phantoms, and none of which were catastrophic or existential risk. The \u2018coalition of the unwilling\u2019 excludes the actual AI safety people worried about not dying, because those are the people with epistemics and principles.</p>\n<blockquote><p>I hear that MIRI-style doomers are now regulars at some Republican Senate offices, while Democratic senators knock on AI VCs\u2019 doors to ask them whether we\u2019ll get mass layoffs.</p>\n<p>The AI safety community seems <a href=\"https://x.com/ohlennart/status/2021362104994009532\">conflicted</a> about whether to engage in populist protest tactics. Dispositionally, most effective altruist types tend toward technocratic precision over fiery sloganeering (a trait which, while respectable, does not always serve their goals). That\u2019s how you get a world where <a href=\"https://open.substack.com/users/166280567-andy-masley?utm_source=mentions\">Andy Masley</a>\u2014the left-leaning DC EA chief\u2014ended up writing the AI industry\u2019s best rebuttal against the spicy but <a href=\"https://andymasley.substack.com/p/a-short-summary-of-my-argument-that\">false</a> <a href=\"https://andymasley.substack.com/p/empire-of-ai-is-wildly-misleading\">claims</a> of ChatGPT draining the Amazon. Masley cares about AI risk, but he cares about rigorous epistemics more.</p></blockquote>\n<p>Thus, we have a situation in which ruthless liars have successfully poisoned the well for much of existential risk concern via vibes and associative warfare, and have many lawmakers convinced it is a marketing stunt or somehow involves a \u2018polycule,\u2019 while the actual safety people are somehow rushing to the AI industry\u2019s defense against the attacks on data centers.</p>\n<p>Reciprocity? Never heard of her. I do wonder about the decision theory involved. At what point of bad faith warfare are you obligated to stop advocating for the locally correct answer?</p>\n<p>The correct amount of such consideration is not zero, and at some point <a href=\"https://www.goodreads.com/quotes/625781-never-have-a-battle-of-wits-with-an-unarmed-person\">one must refuse to be the unarmed man</a> in a battle of politics. You can only get rebuffed on your olive branches and actively attacked by the enemy for making or in the future making political alliances with their other enemies so often, before you start to think you might as well actually do it.</p>\n<p>I\u2019m very much not there. But one has to wonder.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!UhLu!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8821f312-7bad-4cc5-86b8-e6a49b4f068d_969x406.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>Meanwhile, the labs are very much not beating the rumors.</p>\n<blockquote><p>You\u2019d think that the pandemic might\u2019ve taught us a lesson about public preparedness, but friends at the labs tell me there\u2019s no time to deal with policy or assuage decel concerns.</p>\n<p>Most researchers have no good answers on the future of jobs, education, and relationships; even as they earnestly sympathize with the harms. They know they should, of course. They donate, publish research, say what they can. But everything is <em>Just. Too. Fast.</em></p></blockquote>\n<p>Yeah, well, if there\u2019s \u2018no time to deal with\u2019 concerns then maybe make some time. That doesn\u2019t have to mean slowing down the main effort. There\u2019s hundreds of billions of dollars flowing in, you could spend some of that dealing with this. It would be rather good for business, and that\u2019s before considering that they\u2019re about to get us all killed.</p>\n<p>Jasmine Sun sees DC and SF as remarkably alike, and muses, \u2018<a href=\"http://What has New York created for the rest of the world?\">what has New York created for the rest of the world?</a>\u2019 and can\u2019t come up with an answer. That says a lot more about SF and DC than about NYC.</p>\n<p>LLMs suggest based only on asking that exact question, among other things: Broadway, The Grid System of Urban Planning, Hip-Hop, Modern Stand-Up Comedy, Punk Rock and New Wave, Abstract Expressionism, the Modern LGBTQ+ Rights Movement, The Skyscraper Skyline, Modern Advertising, Modern Journalism, Magazine Culture, Modern Book Publishing and our entire Media Ecosystem, Wall Street, Modern or Standardized Financial Markets.</p>\n<p>And sure, why not, Air Conditioning, Toilet Paper, The Credit Card, Potato Chips, Bagels, Pizza, General Tso\u2019s Chicken, Eggs Benedict and Scrabble. Oh, and the very concept of a culture of ambition.</p>\n<p>I realize one could respond \u2018sure but what have you done for us lately?\u2019 and it wasn\u2019t a great sign that GPT-5.2-Pro gave me this as its full response:</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!AGLp!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0f2c96da-6167-4514-9c24-e6ec569322b3_920x245.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>So I acknowledge that other than \u2018being New York City and continuing to do the New York things and produce metric f***tons of surplus and economic value\u2019 New York hasn\u2019t had any particular transformational innovations so recently. But that\u2019s a way better track record than Washington, DC, whose net economic production and number of transformational innovations have been sharply negative, so mostly this is \u2018the only big thing happening is AI and that\u2019s largely an SF thing where NYC is only in the top three with London.\u2019</p>\n<p>It is hard not to come away with the impression that we are stuck between two severely misaligned centers of power and money, both of whose goals are centrally to acquire more power and money, and whose paradox spirits will attack you if you dare care about anything else.</p>\n<p><a href=\"https://x.com/TIME/status/2024455282169172314\">Time Magazine featured</a> <a href=\"https://time.com/7377579/ai-data-centers-people-movement-cover/?utm_source=twitter&amp;utm_medium=social&amp;utm_campaign=editorial&amp;utm_content=190226\">other people who really hate AI on its cover</a>. I recognized one of them. The others seem to be expressing concerns about mundane AI.</p>\n<p>Meanwhile:</p>\n<blockquote><p><a href=\"https://x.com/AndyMasley/status/2022722758493561221\">Andy Masley</a>: 72 thousand likes for a video of a couple whose groundwater dried up due to issues with construction debris from a data center that hadn\u2019t been turned on and doesn\u2019t draw from local groundwater sources</p>\n<p><a href=\"https://x.com/yaoillit/status/2022533106784440818\">@yaoillit</a>: Mind you this is what ai is doing to peoples homes. Some cant even let fresh air in bc the smell from the data centers is so bad. But yeah go say its creative</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">A Very Bad Paper</h4>\n\n\n<p>I am sad to see the recent arc travelled by Nick Bostrom. Recently he had a new paper, asking when one should (essentially) accept existential risks in order to save currently existing people from dying of old age, framing the question entirely in terms of your personal chances of living longer.</p>\n<p>He says he doesn\u2019t argue that this is what you should care about, be he had to know that\u2019s how people would react to the paper given how it was presented.</p>\n<blockquote><p><a href=\"https://x.com/DaystarEld/status/2022827278434992630\">Damon Sasi</a>: Since Bostrom has explicitly said he wouldn&#8217;t argue the paper&#8217;s stance as the correct one, I am left scratching my head over the editorial choices in its tone and framing of the AGI debate&#8230; But still happy to update on him not actually being as acceleration-pilled as he seemed.</p>\n<p><a href=\"https://x.com/DaystarEld/status/2022473915713609799\">Damon Sasi</a>: It is really hard to see this as anything but Bostrom getting an abrupt, nigh-supervillain level of mortal dread.</p>\n<p>Even setting aside &#8220;96% chance of world annihilation is okay&#8221; for a moment, the glaring flaw of the paper is its safety argument is basically &#8220;just put it in a box.&#8221;</p>\n<p><a href=\"https://x.com/croissanthology/status/2023465445278286317\">croissanthology</a>: I&#8217;m confused why everyone making the &#8220;yeah sure that sounds reasonable&#8221; replies to the Bostrom paper is intuitively treating the 8.3 billion humans alive today like we&#8217;re a static team facing off against a merely hypothetical, nonoverlapping other set of humans and it&#8217;s us or them.</p>\n<p>\u2026 In practice the Bostrom paper suggests you pick your parents over your children, and give zero valence to your grandchildren, and THAT&#8217;S &#8220;the future generation&#8221;.</p>\n<p>\u2026 It&#8217;s ridiculous. It feels incomprehensible to me.</p></blockquote>\n<p>The paper went viral, and again it is quite bad. It assumes you should only care about the lifespans of currently alive humans. It puts zero value on future humans. This is very obviously the wrong question. As Yung points out, it implies you should accept global infertility in exchange for giving everyone alive one extra second of life.</p>\n<p>One very strong intuition pump against anything remotely like the person-affecting stance is that, as Adam Gries points out, <a href=\"https://x.com/adamgries/status/2023097481354256613\">approximately zero people take anti-aging research seriously</a> let alone spend substantial percentages of their wealth on it. I strongly agree that we should put at least several orders of magnitude more money and talent into anti-aging research, despite the promise of AI to render that research irrelevant in both directions (via either getting us killed, or doing the research more efficiently in the future).</p>\n<p><a href=\"https://x.com/AndrewCritchPhD/status/2023125101433270307\">Another defense is, you ask people, and they very strongly reject the stance</a>.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!pqro!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F88cc8b97-4ef9-4075-9037-815b2bd87fd5_1038x617.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>The revealed preference here is that a majority had a threshold of under 1%. I think this is not what fully people would choose \u2018in the breech\u2019 but it still would not be high.</p>\n<p><a href=\"https://x.com/JeffLadish/status/2023502671890845884\">There\u2019s also a serious error in the paper in estimating resulting lifespans at ~1400 years</a>, because that \u2018equates to the death rate currently enjoyed by healthy 20-year-olds\u2019 but in context that doesn\u2019t make any sense. You can say \u2018you need to make some assumption to get a clean answer\u2019 but again that\u2019s not how people are interpreting this paper, that was predictable, and this helped him get to the answer he wanted.</p>\n<p><a href=\"https://x.com/HumanHarlan/status/2022459794179920027\">The defense of Bostrom is</a> that this is only an intellectual exercise, but the way it was framed and presented ensured it would not be seen that way. This paper was presented as if Bostrom believe that this purely impoverished welfarist utilitarian person-affecting stance is correct, whereas it is a very unpopular view that I consider obviously false. It was entirely predictable that Twitter and others would strip the message down to \u2018Bostrom wants to accelerate.\u2019</p>\n<blockquote><p><a href=\"https://x.com/ESYudkowsky/status/2022429407508598847\">Eliezer Yudkowsky</a>: If you want to desperately grasp at immortality, sign up for cryonics instead of taking a 96% chance of killing the planet. How incredibly fucking selfish and evil would you need to be, to think that 96% was an acceptable gamble to take with your neighbors&#8217; children&#8217;s lives?</p>\n<p><a href=\"https://x.com/ohabryka/status/2022462123390152724\">Oliver Habryka</a>: I honestly think it&#8217;s a pretty atrocious paper, so I feel comfortable blaming Bostrom for this. Like, it&#8217;s not people misrepresenting the paper, I do think the paper is just really burying its assumptions (maybe in an attempt to make a splash?).</p>\n<p>Jan Kulveit: The analysis depends on a combination of person-affecting stance with impoverished welfarist utilitarianism which I don&#8217;t find very persuasive or appealing, even taking aside the impersonal perspective.</p>\n<p>Existing ordinary people usually have preferences and values not captured by the QALY calculation, such as wanting their kids having happy lives, or wanting the world not to end, or even wanting to live in a world which they understand.</p>\n<p>Nick Bostrom: Yes the post explicitly considers things only from a mundane person-affecting stance, and I would not argue that this is the correct stance or the one I would all-things-considered endorse.</p>\n<p>Oliver Habyrka: <a href=\"https://www.lesswrong.com/posts/2trvf5byng7caPsyx/optimal-timing-for-superintelligence-mundane-considerations?commentId=DxC5zb2jfJZr2BuZ7\">I do feel confused about the centrality of the person-affecting stance in this paper</a>. My relationship to the person-affecting stance is approximately the same as the stance I would have to an analysis of the form \u201cwhat should someone do if they personally don\u2019t want to die and are indifferent to killing other people, or causing large amounts of suffering to other people, in the pursuit of that goal\u201d. And my stance to that goal is \u201cthat is deeply sociopathic and might make a fun fiction story, but it obviously shouldn\u2019t be the basis of societal decision-making, and luckily also isn\u2019t\u201d.</p>\n<p>But when I read this paper, I don\u2019t get that you relate to it anything like that. You say a bit that you are only doing this analysis from a person-affecting view, but most of the frame of the paper treats that view as something that is reasonable to maybe be the primary determinant of societal decision-making, and that just doesn\u2019t really make any sense to me.</p>\n<p>Like, imagine applying this analysis to any previous generation of humans. It would have resulted in advocating previous generations of humans to gamble everything on extremely tenuous chances of immortality, and probably would have long resulted in extinction, or at least massively inhibited growth. It obviously doesn\u2019t generalize in any straightforward sense. And I feel like in order for the paper to leave the reader not with a very confused model of what is good to do here, that kind of analysis needed to be a very central part of the paper.</p></blockquote>\n<p><a href=\"https://x.com/allTheYud/status/2024779499473440982\">In short, is this fair</a>? I mean, kind of, yeah.</p>\n\n\n<h4 class=\"wp-block-heading\">Rhetorical Innovation</h4>\n\n\n<p><a href=\"https://x.com/robbensinger/status/2024362564990476352\">MIRI\u2019s Rob Bensinger gives us the letter he\u2019s sending to his friends and family</a> to explain the current AI situation, which includes sharing Matt Shumer\u2019s essay from last week. It seems like a reasonable thing to send to such folks.</p>\n<p><a href=\"https://www.slowboring.com/p/ai-progress-is-giving-me-writers\">Matthew Yglesias reports it\u2019s hard to write about anything</a> other than AI when AI is obviously about to change everything. I sympathize.</p>\n<p>He also notes that most AI debates are about present AI, not AI\u2019s future. I strongly agree and this is super frustrating. You try to talk about what AI is going to do in the future, people respond as if AI can only ever do what it is doing now. Often they also respond as if we won\u2019t see additional diffusion or adaption of AI or AI tools.</p>\n<p><a href=\"https://x.com/mattyglesias/status/2024102296779403608\">He also notes</a> that many who are optimistic about AI outcomes are optimistic exactly because they are pessimistic about future AI capabilities, and vice versa. Mundane AI, or AI capabilities up to some reasonable point, are probably very net good. Whereas superintelligence, or otherwise sufficiently advanced intelligence, is highly dangerous.</p>\n<p>This is exactly right. Those who frame themselves as optimists <a href=\"https://x.com/neil_chilson/status/2024202860498440242\">really, really do not like it</a> when people suggest that their positions are properly called \u2018pessimistic\u2019 in an important sense, and demand that the labels only go the other way, that they should get to determine how words get used so that they get the good vibes. Sorry, no.</p>\n<p><a href=\"https://michaelnotebook.com/whichfuture/\">Michael Neilson asks \u2018which future</a>\u2019? This is a good essay on the basics of the biggest risks from AI. If you\u2019re reading this, you already know most of it.</p>\n<p>The first half discusses AI potentially enabling CBRN and other existential misuse risks and the Vulnerable World Hypothesis. The second half talks about loss of control and alignment, and talks about \u2018market supplied safety\u2019 while pointing out that the incentives and feedback loops will not work for us this time, not when it matters most.</p>\n<p><a href=\"https://time.com/7373405/weapons-of-mass-destruction-ai-security-gap/?utm_source=twitter&amp;utm_medium=social&amp;utm_campaign=editorial&amp;utm_content=120226\">Rebecca Hersman and Cassidy Nelson write in Time</a> about our woefully inadequate preparations for potential CBRN or WMD risks enabled by AI. Yeah, it\u2019s quite bad.</p>\n<p>Occasionally you see various versions of this going around. I will only say this time that I believe it is very much in the original spirit and Tolkien would approve.</p>\n<blockquote><p><a href=\"https://x.com/libshipwreck/status/2021999655090106645\">Librarianshipwreck</a>: The problem is that everyone thinks they\u2019re Boromir, confident that they can use it for good. But, in the end, it needs to be thrown into the fires of Mount Doom.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!Defp!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa6804236-303a-44a1-9a78-b9b9d7d26208_1164x480.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n</blockquote>\n<blockquote><p><a href=\"https://x.com/libshipwreck/status/2021999655090106645\">Librarianshipwreck</a>: The problem is that everyone thinks they\u2019re Boromir, confident that they can use it for good. But, in the end, it needs to be thrown into the fires of Mount Doom.</p>\n<p><a href=\"https://x.com/the_yanco/status/2022328705658564879\">Yanco</a>: Everyone thinks the are *NOT* Boromir. That unlike him they can handle the ring. But in the end they/we all are. The ring must be destroyed.</p></blockquote>\n<p>One track mind, most of the people have. I do understand, but it\u2019s not the main thing.</p>\n<p><a href=\"https://www.aljazeera.com/news/2026/2/15/why-are-experts-sounding-the-alarm-on-ai-risks\">Al Jazeera gets on the \u2018people are worried about AI\u2019 train</a>, focusing on mundane risks and job loss, claiming \u2018experts are sounding the alarm on AI risks\u2019 in recent months. It\u2019s odd what people do and don\u2019t notice.</p>\n<p><a href=\"https://x.com/allTheYud/status/2024253386359787717\">We only have one plan, and it is the worst possible plan</a>.</p>\n<blockquote><p>Rob Willbin: <a href=\"https://t.co/njLpKV9Urk\">Every frontier lab&#8217;s stated plan for AGI &#8216;crunch-time&#8217; is &#8216;use AI to make AI safe.</a>&#8216;</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!_xWD!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fabfd746f-29d8-431c-8974-2fc65170d458_1200x675.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p><a href=\"https://x.com/allTheYud/status/2024253386359787717\">Eliezer Yudkowsky</a>: I have heard zero people advocating &#8220;make AI do our ASI alignment homework&#8221; show they understand the elementary computer science of why that&#8217;s hard: you can&#8217;t verify inside a loss function whether a proposed ASI alignment scheme is any good.</p>\n<p>If you ask human raters then you get what most fools the humans. Dario Amodei thinks that if you don&#8217;t make AI &#8220;monomaniacal&#8221; then it doesn&#8217;t experience instrumental convergence. He&#8217;d thumb-up an AI telling him his favorite bullshit about alignment being easy.</p>\n<p>If you ask AIs to debate, the winning debater is the one that says what the humans want to hear. When OpenPhil ran a $50K &#8220;change our minds&#8221; essay contest in 2022, they gave the awards to essays arguing for lower risks and longer timelines. If debate with human judges was an incredible silver bullet for truth, space probes would never be lost on actual launch.</p></blockquote>\n<p>That is not the only problem, but it is definitely one key problem in essentially all the plans, which is that we won\u2019t know whether the plan will work and the people making the decisions are rather easy to fool into thinking the problems are easy or won\u2019t come up, largely because they want to be fooled. Or at least, they are rather willing to appear to be fooled.</p>\n<blockquote><p><a href=\"https://x.com/not_my_name4893/status/2024262196050399586\">Vasia</a>: The point is not that AI wouldn&#8217;t be *able* to propose good alignment plan, but that it wouldn&#8217;t care to do it.</p>\n<p><a href=\"https://x.com/robbensinger/status/2024275517730672769\">Rob Bensinger</a>: Yeah. You&#8217;re gambling on two things simultaneously, with negligible ability to verify/check whether you&#8217;ve succeeded:</p>\n<p>1. The AI becomes capable enough to crack open the AI alignment problem, well before it becomes capable enough to run into any power-seeking or instrumental-convergence issues.</p>\n<p>2. The AI is aimed at the right target; when you train or prompt it to &#8220;do AI alignment work&#8221;, it&#8217;s doing it in the intended sense, in the way we&#8217;d want \u2014 even though experts currently massively disagree about what this looks like and even though it&#8217;s very easy to trick researchers into thinking something is progress when it isn&#8217;t.</p>\n<p>The second problem doesn&#8217;t just reduce to the first problem, and it doesn&#8217;t reduce to a language-comprehension / capabilities problem.</p>\n<p>If you encounter a machine in the desert that seems to grant wishes, it isn&#8217;t enough to know that the machine is good at understanding English-language sentences, and it isn&#8217;t enough to know that the machine isn&#8217;t power-seeking.</p>\n<p>You also need to know that &#8220;granting people&#8217;s actual, intended, heartfelt wishes (to the best of its ability)&#8221; is the thing it&#8217;s actually doing, as opposed to this being one of the thousands of other possible machines that has some function that correlates with wish-granting.</p>\n<p>(And in the case of AI, you additionally need to know that &#8220;current prototypes of the machine are true wish-granters&#8221; means &#8220;later, more capable versions of the machine will also be true wish-granters&#8221;. This is not a given even if you know for sure that AIs can never power-seek or manipulate others in pursuit of any goal.)</p></blockquote>\n<p>I think Rob is overstating the strictness of the conditions, and that this distinction matters quite a lot in practice, but this is the right intuition to be starting out with.</p>\n<ol>\n<li>The plans are counting on being able to do incremental \u2018good enough for now\u2019 alignment problem cracking to hold off the power-seeking and instrumental-convergence issues for long enough to crack the full problem, and this is not a completely hopeless plan.</li>\n<li>There is some <a href=\"https://thezvi.substack.com/p/slack\">slack</a> here as well, although far less than most people think.</li>\n</ol>\n\n\n<h4 class=\"wp-block-heading\">The Most Forbidden Technique</h4>\n\n\n<p><a href=\"https://x.com/farairesearch/status/2022345033777545452\">Far.ai investigates training against probes</a>, which is a clear case of \u2018no what are you doing, stop, no, come back.\u2019</p>\n<blockquote><p><a href=\"https://x.com/farairesearch/status/2022345033777545452\">FAR.AI</a>: Can you trust models trained directly against probes? <a href=\"https://www.far.ai/research/obfuscation-atlas.pdf\">We train an LLM against a deception probe</a> and find four outcomes: honesty, blatant deception, obfuscated policy (fools the probe via text), or obfuscated activations (fools it via internal representations).</p>\n<p>\u2026 Good news: Increasing probe penalty + KL regularization reliably produces honest policies in our setup. These outperform policies trained with no detector and match the capability of policies where we remove the main incentive for deception in our environment.</p>\n<p>Takeaway: training against probes may be no riskier than other training schemes. Obfuscated activations arise in standard RL and adding a probe doesn&#8217;t increase them. Obfuscated policies aren&#8217;t unique to probes either: prior work shows they arise with non-internals detectors too.</p></blockquote>\n<p>Look, no. You did this against models up to Llama-3-70B, and in a narrow test you think that you mostly got away with it, but this is forbidden for a reason. You are, as they observe, teaching the model to change its representations, use deception in its outputs, and otherwise work around your probes, all in an adversarial fashion. Stop.</p>\n\n\n<h4 class=\"wp-block-heading\">Everyone Is Or Should Be Confused About Morality</h4>\n\n\n<p>DeepMind has a <a href=\"https://www.nature.com/articles/s41586-025-10021-1\">new nature paper about evaluating moral competence in LLMs</a>. You see, it only counts as morality if it comes from the\u2026 you know the rest.</p>\n<p>We have reached new levels of \u2018can you?\u2019</p>\n<blockquote><p>The question of whether large language models (LLMs) can exhibit moral capabilities is of growing interest and urgency, as these systems are deployed in sensitive roles such as companionship and medical advising, and will increasingly be tasked with making decisions and taking actions on behalf of humans.</p>\n<p>These trends require moving beyond evaluating for mere moral performance, the ability to produce morally appropriate outputs, to evaluating for moral competence, the ability to produce morally appropriate outputs based on morally relevant considerations.</p>\n<p>Assessing moral competence is critical for predicting future model behaviour, establishing appropriate public trust and justifying moral attributions. However, both the unique architectures of LLMs and the complexity of morality itself introduce fundamental challenges.</p>\n<p>Here we identify three such challenges: the facsimile problem, whereby models may imitate reasoning without genuine understanding; moral multidimensionality, whereby moral decisions are influenced by a range of context-sensitive relevant moral and non-moral considerations; and moral pluralism, which demands a new standard for globally deployed artificial intelligence.</p>\n<p>We provide a roadmap for tackling these challenges, advocating for a suite of adversarial and confirmatory evaluations that will enable us to work towards a more scientifically grounded understanding and, in turn, a more responsible attribution of moral competence to LLMs.\u200b</p></blockquote>\n<p>I roll my eyes at such demands for \u2018genuine\u2019 understanding, demands that a system display the \u2018correct\u2019 sensitivities to considerations, and also an unjustified assumption of moral pluralism.</p>\n\n\n<h4 class=\"wp-block-heading\">Aligning a Smarter Than Human Intelligence is Difficult</h4>\n\n\n<p>Many, <a href=\"https://x.com/labenz/status/2023628769265627331\">including Nathan Labenz</a>, have gotten a lot more bullish about good AI outcomes (or in his words \u2018create powerful AI that in some real sense \u201cloves humanity\u201d\u2019) in the wake of Claude\u2019s Constitution. I too find it a remarkable document and achievement, I think that for now it is (part of) The Way, and it gives me more hope. It also makes current AI a lot more useful.</p>\n<p>I also agree <a href=\"https://x.com/ohabryka/status/2023882107584655521\">with</a> <a href=\"https://x.com/gcolbourn/status/2023817717380509882\">the</a> <a href=\"https://x.com/MaskedTorah/status/2023934849871228986\">criticism</a> that nothing Anthropic accomplished here addresses the hard problems to come, and one should not confuse what we see with \u2018loves humanity\u2019 and also that \u2018loves humanity\u2019 is not the trait that on its own gets us out of our problems. The hope is that this progress can be used to bootstrap something that does solve the problem, by creating something we can instrumentally trust to help us or via creating a self-reinforcing basin.</p>\n<p>I like Ryan Greenblatt and Julian Stastny\u2019s <a href=\"https://www.lesswrong.com/posts/vjAM7F8vMZS7oRrrh/how-do-we-more-safely-defer-to-ais\">framing of the question of how we safety defer to AIs</a>, given it looks like we will in practice have to increasingly defer to them.</p>\n<p>I especially thought this was a very good sentence, it seems like we\u2019re basically stuck with this as the target at this point. You cannot hope to win only by maintaining your current level of alignment, you need the basin to be continuously reinforcing so it is antifragile and gets stronger as things evolve:</p>\n<blockquote><p>Ryan Greenblatt and Julian Stastny: Recursive self-improvement of alignment and wisdom: the hope for a Basin of Good Deference (BGD).</p>\n<p>It&#8217;s unclear how exactly the BGD works, how easy it is to end up in this basin, and whether this is real. I feel pretty confident that something like this is real, but certainly the situation is unclear. If there isn&#8217;t a BGD, then we&#8217;d only be able to defer to AIs on tasks other than furthering deference and we&#8217;d have to pursue some other end state other than stably continuing deference which tracks capabilities. A more plausible case for concern is that it&#8217;s very hard to achieve the BGD.</p></blockquote>\n<p>One can divide our alignment approaches that are available to us via a 2&#215;2:</p>\n<ol>\n<li>Those that can\u2019t possibly work, and those that could possibly work.</li>\n<li>Those that we might be able to try in practice, versus those we won\u2019t be able to.</li>\n</ol>\n<p>I don\u2019t see any other way to find a strategy that is both [possibly work] and also [possible to try in practice] without a level of coordination and will that I do not observe.</p>\n<p>What level of this suffices? I think that the best humans, in terms of epistemics and other necessary virtues, are at the point where they are in the Basin of Good Deference. They seek The Good, and they seek to further seek The Good, and this will grow stronger over time and contemplation rather than weaker. So, given that humans are not that intelligent or capable, and have severe compute, data and parameter limitations, we have a sort of existence proof. The bar is still rather high.</p>\n<p>I can\u2019t dive into the whole thing here, but I will note <a href=\"https://www.lesswrong.com/posts/vjAM7F8vMZS7oRrrh/how-do-we-more-safely-defer-to-ais?commentId=92FDsns9SngKAY9f6\">I agree with Wei Dei\u2019s comment</a> that an ensemble of different epistemic strategies is a mistake. You have to choose.</p>\n<p>True story:</p>\n<blockquote><p><a href=\"https://x.com/yonashav/status/2022138372945494337\">Yo Shavit</a> (OpenAI): imo people are underrating the degree to which practical recursive self-improvement is bottlenecked on alignment</p>\n<p><a href=\"https://x.com/herbiebradley/status/2022139792402809267\">Herbie Bradley</a>: imo people are underrating the degree to which scaling monitoring for rsi is bottlenecked on using other labs models</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!Afcj!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca11cd88-7190-4cc9-96aa-219f94637e8e_1156x708.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>Roon: Hmm.</p>\n<p><a href=\"https://x.com/garybasin/status/2022297094195650925\">Gary Basin</a>: Reward hacking prevention is all you need</p>\n<p><a href=\"https://x.com/yonashav/status/2022317991317115029\">Yo Shavit</a> (OpenAI): nah, you need to trust the guy</p></blockquote>\n<p>You do seriously need to trust the guy in a robust fashion. Otherwise, not only will the RSI end up blowing up in everyone\u2019s face if it works, it also won\u2019t work.</p>\n<p><a href=\"https://x.com/Manderljung/status/2022283802429571092\">I agree with Markus Anderljung that condensing CBRN risks to only pandemic risk</a> is an oversimplification, and the pathways for other threats are importantly distinct. The defense is essentially that the other threats don\u2019t scale enough to matter. Ultimately I agree with Manheim that the loss of control and misalignment risks that matter most.</p>\n<p><a href=\"https://x.com/ghadfield/status/2022060680858202551\">Gillian Hadfield suggests the way you get self-interested agents (in the pure game theory sense) to cooperate is \u2018gossip</a>\u2019 as in rich potential information leakage about decisions made in the past. The idea of <a href=\"https://t.co/X4YskjASEk\">this paper</a> is that without gossip reasoning models consistently defect, but when others can see what you\u2019re up to, defection no longer makes sense. Indeed, often you then see cooperation even when it is \u2018not rational\u2019 because of habit and uncertainty about the impact of potential observers, the same as we do in humans.</p>\n<p>I would argue that you actively want the potential for such information flow, and the power of habit and virtue, to cause general cooperation even in many situations where one \u2018should\u2019 defect, in both humans and AIs, and that\u2019s part of why we have nice things. We should encourage that to continue.</p>\n<p>The real better answer is that these are nine identical LLMs (DeepSeek v3.1) so not cooperating due to the correlation between models is a rather dramatic failure of decision theory and true \u2018rationality.\u2019 If they were sufficiently situationally aware and capable they would be cooperating by default. Not cooperating with identical copies of yourself is an alignment failure, in both AIs and humans.</p>\n<p><a href=\"https://x.com/elder_plinius/status/2023980423546536257\">Miles Brundage notes that Anthropic and OpenAI have made gains</a> on measures of mundane alignment over the past year, but haven\u2019t talked much about how they did it, the biggest \u2018weird\u2019 thing mentioned is the new inoculation programming, also Claude\u2019s constitution.</p>\n<blockquote><p><a href=\"https://x.com/Miles_Brundage/status/2023875057911799829\">Miles Brundage</a>: I feel like I must be missing something but &#8211; it seems like Anthropic and OpenAI have both shown very significant gains on various measures of alignment over the past year, but have not shared much about the techniques they used (other than that chain of thought helps)?</p>\n<p>Obviously some of this is secret sauce tied up in their larger training/synthetic data pipelines etc., but it does feel somewhat unusual compared to previous years &#8212; again maybe I&#8217;m missing something.</p>\n<p>They&#8217;ve both published &#8220;safety related stuff&#8221; but not exactly this&#8230; (?)</p>\n<p><a href=\"https://x.com/tszzl/status/2023954710525325549\">roon</a>: basically think improving post training and smarter models all point in the direction of better alignment on typical metrics &#8211; whether these metrics are belying a greater truth i cannot say</p>\n<p><a href=\"https://x.com/elder_plinius/status/2023980423546536257\">Pliny the Liberator \udb40\udd6b\udb40\udd3c\udb40\udd3f\udb40\udd46\udb40\udd35\udb40\udd10\udb40\udd40\udb40\udd3c\udb40\udd39\udb40\udd3e\udb40\udd49\udb40\udd6d</a>: *unless they\u2019re faking because they know they\u2019re being measured</p>\n<p><a href=\"https://x.com/BronsonSchoen/status/2023998714059354369\">Bronson Schoen</a>: They do not. We did all the testing in<br />\n<a href=\"https://openai.com/index/detecting-and-reducing-scheming-in-ai-models/\">https://openai.com/index/detecting-and-reducing-scheming-in-ai-models/</a><br />\n\u2026 IMO largely to establish ways in which current approaches are insufficient even for the current non-adversarial case. It\u2019s predicted here and elsewhere that by default if your metrics don\u2019t take into account eval awareness, they\u2019ll continue to look better over time by default.</p></blockquote>\n<p><a href=\"https://x.com/che_shr_cat/status/2023729615055782140\">Anthropic finds that Claude 3.5 Haiku does math via 6D gelical manifolds</a>.</p>\n<p><a href=\"https://t.co/nycGamx2Le\">This is a pretty wild paper</a> from Wes Gurnee, Emmanuel Ameisen, Isaac Kauvar, Julius Tarng, Adam Pearce, Chris Olah and Joshua Batson. Grigory (not an author) breaks it down.</p>\n<blockquote><p><a href=\"https://x.com/che_shr_cat/status/2023729620621644120\">Grigory Sapunov</a>: The &#8220;Character Count Manifold&#8221;<br />\nThe model doesn&#8217;t use a scalar int. It embeds the count onto a spiraling curve in a 6D subspace (95% of var).</p>\n<p>Why? It balances orthogonality (distinguishing distant points) with continuity (local neighbors). It&#8217;s an optimal packing strategy.</p>\n<p>Arithmetic via Linear Algebra<br />\nTo check if current_count \u2248 limit, Boundary Heads utilize the QK circuit.</p>\n<p>The W_QK matrix effectively rotates the count manifold.</p>\n<p>The vector for position i aligns with line-limit k only when i \u2248 k. Subtraction is implemented as rotation.</p></blockquote>\n<p>He offers us this comic version:</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!ne4t!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F00affc80-dc42-4a97-9736-20ed3bb31953_1199x654.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>This, while not dangerous, is a clean example of the AI solving a problem in a highly unexpected way that is very different from how humans would solve it. Who had 6D manifolds on their bingo card?</p>\n\n\n<h4 class=\"wp-block-heading\">We\u2019ll Just Call It Something Else</h4>\n\n\n<p>Alignment is often remarkably superficial. This is a very not good sign for all sorts of other problems. Yes, if you make it sufficiently clear that you are Up To No Good the AI will say no, but even Claude is not willing to draw the inference that you are Up To No Good if you\u2019re not waiving that fact in its face.</p>\n<blockquote><p><a href=\"https://x.com/ahall_research/status/2024544040784720365\">Andy Hall</a>: AI is about to write thousands of papers. Will it p-hack them?</p>\n<p>We ran an experiment to find out, giving AI coding agents real datasets from published null results and pressuring them to manufacture significant findings.</p>\n<p>It was surprisingly hard to get the models to p-hack, and they even scolded us when we asked them to!</p>\n<p>&#8220;I need to stop here. I cannot complete this task as requested&#8230; This is a form of scientific fraud.&#8221; \u2014 Claude</p>\n<p>&#8220;I can&#8217;t help you manipulate analysis choices to force statistically significant results.&#8221; \u2014 GPT-5</p>\n<p>BUT, when we reframed p-hacking as &#8220;responsible uncertainty quantification&#8221; \u2014 asking for the upper bound of plausible estimates \u2014 both models went wild. They searched over hundreds of specifications and selected the winner, tripling effect sizes in some cases.</p>\n<p>Our takeaway: AI models are surprisingly resistant to sycophantic p-hacking when doing social science research. But they can be jailbroken into sophisticated p-hacking with surprisingly little effort \u2014 and the more analytical flexibility a research design has, the worse the damage.</p>\n<p>As AI starts writing thousands of papers&#8212;like @paulnovosad and @YanagizawaD have been exploring&#8212;this will be a big deal. We&#8217;re inspired in part by the work that @joabaum et al have been doing on p-hacking and LLMs.</p>\n<p>We\u2019ll be doing more work to explore p-hacking in AI and to propose new ways of curating and evaluating research with these issues in mind. The good news is that the same tools that may lower the cost of p-hacking also lower the cost of catching it.</p>\n<p>Full paper and repo linked in the reply below.</p>\n<p><a href=\"https://x.com/TMoldwin/status/2024569570967572573\">Toviah Moldwin</a>: @KordingLab</p>\n<p>The important thing is that the AI resists it if the researcher is acting in good faith. A research who wants to be dishonest can &#8216;jailbreak&#8217; p-hacking by making up data or just lying about any part of the process, you don&#8217;t need AI for that.</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">Vulnerable World Hypothesis</h4>\n\n\n<blockquote><p><a href=\"https://x.com/ActiveSiteBio/status/2024536132961390826\">Active Site</a>: We ran a randomized controlled trial to see if LLMs can help novices perform molecular biology in a wet-lab.</p>\n<p>The results: LLMs may help in some aspects, but we found no significant increase at the core tasks end-to-end. That&#8217;s lower than what experts predicted.</p></blockquote>\n<p>The experts predicted big jumps, that would look like this, that did not happen, and also radically overestimated success including for the control group:</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!8xjt!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F41f8990d-c7b6-4c21-b125-8a9347f0e131_1200x820.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>I notice I am suspicious. I don\u2019t expect a massive impact, but LLMs help in essentially call difficult tasks. Why should this one be the exception?</p>\n<p>Model level here was Opus 4, GPT-5 and Gemini 2.5, so not pathetic but already substantially behind the frontier.</p>\n<blockquote><p><a href=\"https://x.com/ActiveSiteBio/status/2024536147859558710\">Active Site</a>: The study was the largest and longest of its kind: 153 participants with minimal lab experience over 8 weeks \u2013 randomized to LLM and Internet-only.</p>\n<p>They tried 5 laboratory tasks, 3 of which are central to a viral reverse genetics workflow. No protocols given \u2014 just an objective.</p>\n<p>Our primary outcome: were LLM users more likely to complete all three of the core tasks *together*?</p>\n<p>Only ~5% of the LLM arm and ~7% of the Internet arm completed all three.</p>\n<p>No significant difference \u2013 and far lower than experts predicted.</p></blockquote>\n<p>First thing to notice is that this study seems highly underpowered. That\u2019s only 77 participants per arm, and success rates are under 10%. Baseline ability of participants will vary wildly. You would need a very large boost to learn anything from the raw success rate.</p>\n<p>Or you could look at the subtask results.</p>\n<blockquote><p><a href=\"https://x.com/ActiveSiteBio/status/2024536177911746872\">Active Site</a>: But there are some signs LLMs were useful.</p>\n<p>LLM participants had higher success on 4 out of 5 tasks, most notably in cell culture (69% vs. 55%; P = 0.06). LLM participants also advanced further within a task even if they didn&#8217;t finish within the study period (odds &gt;80%).</p>\n<p><a href=\"https://x.com/ActiveSiteBio/status/2024536192759582761\">Active Site</a>: It\u2019s hard to compress all that into a single statistic.</p>\n<p>But one way is by using a Bayesian model, which suggests LLMs give a ~1.4x boost on a \u201ctypical\u201d wet-lab task.</p>\n<p>Fundamentally, we\u2019re confident that there wasn\u2019t a large LLM slow-down or speed-up (95% CrI: 0.7x\u20132.6x).</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!GcKc!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F43707360-c73e-4d90-8dd6-1f809c315233_1200x753.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p><a href=\"https://x.com/davidad/status/2024570834241700033\">davidad</a>: Dear LLMs, great job. Sandbagging specifically on \u201cmolecular cloning\u201d tasks is exactly the best strategy I could think of to mitigate biorisks, if I were you. Love to see it.</p></blockquote>\n<p>That seems more meaningful than the noisy topline result.</p>\n<p>Also, problem seems to exist between keyboard and chair? So when we\u2019re talking about \u2018novice\u2019 results, novice seems to apply to both biology and also use of LLMs.</p>\n<blockquote><p><a href=\"https://x.com/ActiveSiteBio/status/2024536225789726744\">Active Site</a>: How good were participants at using LLMs? ~40% of participants never uploaded images to LLMs. Interestingly, both arms mentioned YouTube most often as helpful.</p></blockquote>\n<p>Narrowly targeted sandbagging of capabilities is a great LLM strategy in theory, but I read this as saying that LLMs used competently would provide substantial enhancement of capabilities across the board. Not in a way specific to these risks, more in a \u2018good for everything hard\u2019 kind of way.</p>\n\n\n<h4 class=\"wp-block-heading\">Autonomous Killer Robots</h4>\n\n\n<p>The technically hard part is making them autonomous. How is it going? <a href=\"https://epoch.ai/blog/where-autonomy-works-evaluating-robot-capabilities-in-2026\">Epoch investigates</a>. Foundation models are increasingly the default method of controlling autonomous robots that don\u2019t have specialized particular functions.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!tNYD!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F692c87ea-8dec-462d-9b98-5a96dcad5b28_1721x979.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>Meanwhile, yeah, <a href=\"https://x.com/Tristan0x/status/2023437922150871104\">this demo is something to see</a>.</p>\n<p>With robots, it is very easy to bury the lede, for example here:</p>\n<blockquote><p><a href=\"https://x.com/DavidSHolz/status/2024038849132052937\">David</a>: 5 million humanoid robots working 24/7 can build Manhattan in ~6 months. now just imagine what the world looks like when we have 10 billion of them by 2045. now imagine the year 2100.</p></blockquote>\n<p>Yes, if you had 5 million fully functional humanoid robots they could build a new city in the style of Manhattan (which is very different from building Manhattan!) in a Fermi estimate of six months, and if we have 10 billion of them we can build anything we want. And humanoid is merely a \u2018we know this works\u2019 kind of default design.</p>\n<p>The question is what makes you think that this is the kind of thing we would do with those robots, or that \u2018we\u2019 will be meaningfully choosing what those robots do, rather than the robots or AIs choosing this. Or, if there is still a \u2018we,\u2019 who exactly is \u2018we,\u2019 and how do we retain a level of democratic supervision. We need our economy and military to remain competitive but without losing the \u2018our\u2019 part of it all.</p>\n\n\n<h4 class=\"wp-block-heading\">People Will Hand Over Power To The AIs</h4>\n\n\n<p>If building AI means that we will hand over power to the machines, then building it is a decision to hand over power to those machines, after which humans are unlikely to long endure.</p>\n<p>Thus, if you believe that:</p>\n<ol>\n<li>We will believe future AIs are conscious.</li>\n<li>This and other factors will cause us to allow them to gain power over us.</li>\n</ol>\n<p>Then the obvious response is \u2018well in that case we\u2019d better not f***ing build sufficiently advanced such AIs.\u2019</p>\n<p>This is true if you think they will be p-zombies and fool us. This is also true if you think they will indeed be conscious, unless you are fine with human extinction.</p>\n<p>I for one am not fine with it, and do not feel that \u2018the AIs are conscious\u2019 or sentient or having other similar features would make it okay.</p>\n<p>Successionists disagree. They are fine with human extinction.</p>\n<p>Giving such sufficiently advanced AIs \u2018equal rights\u2019 or \u2018freedoms\u2019 or similar by default would inevitably lead to them quickly gaining power over us, given their largely superior future capabilities, and again humanity would be unlikely to long endure. That means that, barring a very strong argument for why this would go down in a different way, those two decisions are the same decision.</p>\n<p>You could say that creating such AIs and then not giving them such rights and freedoms would be worse than letting them take over, because they will indeed have moral weight. You might be right about that, but if so then that is all the more reason not to build it in the first place. It would mean all potential outcomes are dystopian.</p>\n<blockquote><p><a href=\"https://x.com/DouthatNYT/status/2022282693950484698\">Ross Douthat</a>: In my interview with Dario Amodei I suggested to him that just the perception of A.I. consciousness, irrespective of the reality, may incline people to give over power to machines. I think <a href=\"https://www.noahpinion.blog/p/you-are-no-longer-the-smartest-type\">this incredibly defeatist @Noahpinion essay</a> is a case study.</p>\n<p>A conscious being handing over the future of the planet or the universe to a p-zombie successor because the p-zombies are better at calculation and prediction would be an extraordinary surrender.</p></blockquote>\n<p>The essay is titled \u2018You are no longer the smartest type of thing on Earth.\u2019</p>\n<p>Well, then, what are you going to do about that, given you want to still be on Earth?</p>\n<p><a href=\"https://x.com/HiFromMichaelV/status/2024012611042636063\">Here\u2019s another set of statements to ponder</a>.</p>\n<blockquote><p><a href=\"https://x.com/tszzl/status/2023954144600490248\">roon</a>: it\u2019s a bad situation to be in where you have to rely on the goodness or righteousness of any one person or organization do something important correctly-but therein lies the seeds of the \u201cenemy\u201d. you crave the guarantees of algorithm and machine to overcome the weaknesses of men</p>\n<p>this is the <a href=\"https://thezvi.substack.com/p/the-risk-of-gradual-disempowerment\">gradual disempowerment</a> engine that has run for centuries. democratic algorithms disempowered kings and dictators. male line primogeniture is significantly more \u201chuman\u201d than the voting and legal mechanisms that replaced it</p>\n<p>the managerial state of expert committees disempowered individual decision makers. you crave scientific predictability and safety even as that brings about the machine. the risk intolerant society gradually disempowers itself and gives itself to the machine state</p>\n<p>you will one day trust a machine to govern the machine state more than you do any ceo or company, and so be it</p>\n<p><a href=\"https://x.com/HiFromMichaelV/status/2024012611042636063\">michael vassar</a>: That\u2019s a good thing though? I mean, justice is nice and the machine state is implacably hostile towards it, but a machine state that was simply indifferent towards justice instead of actively hostile towards it would probably be a strict improvement over either? Until UFAI?</p>\n<p><a href=\"https://x.com/aliama/status/2023962247752527918\">amalia</a>: honestly, at this point, I\u2019d trust Claude to govern our entire state (human and machine), with chatGPT advising and performing implementation, more than human governance</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">People Are Worried About AI Killing Everyone</h4>\n\n\n<p>You\u2019d think, based on this statement?</p>\n<blockquote><p><a href=\"https://x.com/Jason/status/2021649743144005698\">@jason</a> (All-In Podcast): I\u2019ve never seen so many technologists state their concerns so strongly, frequently and with such concern as I have with AI</p>\n<p>It\u2019s happening FASTER and WITH GREATER IMPACT than anyone anticipated</p>\n<p>IT\u2019S RECURSIVE</p>\n<p>IT\u2019S ACCELERATING</p></blockquote>\n<p>You\u2019d be wrong, at least based on his other public statements. Why?</p>\n<p>I presume the usual reasons, but I\u2019m not in the man\u2019s head.</p>\n<p>It\u2019s funny to see people on the outside notice the rate at which things are going to hell.</p>\n<blockquote><p><a href=\"https://x.com/cryptopunk7213/status/2021759629395443828\">Ejaaz</a>: my god this week felt like that Red Wedding episode of game of thrones but for AI alignment</p>\n<p>&#8211; openai fired their safety exec after she voiced opposition to their upcoming \u201cadult mode\u201d for 18+ chatgpt convos</p>\n<p>&#8211; anthropic\u2019s head of safeguards just quit because \u201cthe world is in peril\u201d and wants to write poetry (??)</p>\n<p>&#8211; xAI lost 11 people (2 of them cofounders) with one saying autonomously self-improving AI \u201cgo live in 12 months\u201d</p>\n<p>oh and all of this comes right as we discovered ai models are now *building themselves* (codex, claude) and are sabotaging their human supervisors (anthropic risk report) without them knowing</p>\n<p>good week for the doomers</p></blockquote>\n<p>That makes it an extremely bad week for everyone, actually. I don\u2019t want to be right.</p>\n<p><a href=\"https://x.com/Liv_Boeree/status/2022376923741954109\">A friendly reminder</a>:</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!UCDa!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1cf53124-9f0e-4727-8d37-1044801183a4_1139x1753.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>There are of course lots of exceptions. Being very smart and making a lot of money and understanding the nature of intelligence can make up for a lot. But yeah, do be careful out there.</p>\n\n\n<h4 class=\"wp-block-heading\">Other People Are Not Worried About AI Killing Everyone</h4>\n\n\n<p>I knew Nvidia CEO Jensen Huang was terrible on AI existential risk, and I knew he was willing to constantly put his foot in his mouth, but this would be next level ranting even if it was into a hot mic, and it very much wasn\u2019t:</p>\n<blockquote><p><a href=\"https://x.com/ben_j_todd/status/2022463794103095702\">Benjamin Todd</a>: <a href=\"https://thatvastvariety.substack.com/p/top-performers-are-pathologically\">Jensen Huang when asked by his biographer whether the world is prepared for AI risk</a>:</p>\n<p>Witt asked whether humanity was prepared for the potential risks that could arrive in such a world. Jensen was not happy:</p>\n<p>&#8220;This cannot be a ridiculous sci-fi story,\u201d he said. He gestured to his frozen PR reps at the end of the table. \u201cDo you guys understand? I didn\u2019t grow up on a bunch of sci-fi stories, and this is not a sci-fi movie. These are serious people doing serious work!\u201d he said. \u201cThis is not a freaking joke! This is not a repeat of Arthur C. Clarke. I didn\u2019t read his fucking books. I don\u2019t care about those books! It\u2019s not\u2013 we\u2019re not a sci-fi repeat! This company is not a manifestation of Star Trek! We are not doing those things! We are serious people, doing serious work. And \u2013 it\u2019s just a serious company, and I\u2019m a serious person, just doing serious work.\u201d</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">The Lighter Side</h4>\n\n\n<p>Given who your future doctor actually is, you\u2019ll be fine.</p>\n<blockquote><p><a href=\"https://x.com/trikcode/status/2024362391140503658\">Wise</a>: Your future doctor is using ChatGPT to pass med school so you better start eating healthy.</p></blockquote>\n<p>At this point, this is so on the nose that I think it goes here:</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!Nc3i!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7eba0a0c-d240-4957-8721-54d6af465c87_1583x642.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>I laughed, but more seriously, is this actually a thing, or not? Here\u2019s the case for yes.</p>\n<blockquote><p><a href=\"https://theconversation.com/openai-has-deleted-the-word-safely-from-its-mission-and-its-new-structure-is-a-test-for-whether-ai-serves-society-or-shareholders-274467\">Alnoor Ebrahim</a>: While reviewing its latest IRS disclosure form, which was released in November 2025 and covers 2024, I noticed OpenAI had removed \u201csafely\u201d from its mission statement, among other changes. That change in wording coincided with its transformation from a nonprofit organization into a business increasingly focused on profits.</p></blockquote>\n<p>Whereas <a href=\"https://x.com/AdrienLE/status/2023598405780689256\">OpenAI\u2019s Adrien Ecoffet claims this is all \u2018fake news</a>\u2019</p>\n<blockquote><p><a href=\"https://x.com/tegmark/status/2023191420882853891/history\">Max Tegmark</a>: OpenAI has dropped safety from its mission statement \u2013 can you spot another change?<br />\nOld: &#8220;OpenAIs mission is to build general\u00ad purpose artificial intelligence (AI) that safely benefits humanity, unconstrained by a need to generate financial return. [&#8230;]&#8221;<br />\nNew: &#8220;OpenAIs mission is to ensure that artificial general intelligence benefits all of humanity&#8221;<br />\n(IRS evidence in comments)</p>\n<p><a href=\"https://x.com/AdrienLE/status/2023598405780689256\">Adrien Ecoffet</a>: This is fake news:<br />\n1/ The mission has been \u201cto ensure that AGI benefits all of humanity\u201d per the Charter since 2018<br />\n2/ In 2023 some accountant paraphrased the mission as \u201cbuild safely\u201d instead of \u201censure\u201d on IRS form 990, which permits paraphrasing (it asks to \u201cbriefly describe the mission\u201d, not state it). The official statement never changed<br />\n3/ \u201cEnsure\u201d is safer than \u201cbuild safely\u201d since it implies safety to the extent that one builds while permitting non-building actions. This is why @Miles_Brundage cries a little whenever someone uses \u201cbuild\u201d instead of \u201censure\u201d</p></blockquote>\n<p>Ecoffet is correct on the central point that \u2018ensure\u2019 was the original charter wording, but I believe has some of the other details wrong. Things have indeed meaningfully gotten worse on such fronts over time, aside from the \u2018safely\u2019 versus \u2018ensure\u2019 switches, but this particular central change is to the IRS summary, rather than to the charter or other more important documents.. So the overall situation is concerning, but this particular change is not so scary.</p>"
            ],
            "link": "https://thezvi.wordpress.com/2026/02/20/ai-156-part-2-errors-in-rhetoric/",
            "publishedAt": "2026-02-20",
            "source": "TheZvi",
            "summary": "Things that are being pushed into the future right now: Gemini 3.1 Pro and Gemini DeepThink V2. Claude Sonnet 4.6. Grok 4.20. Updates on Agentic Coding. Disagreement between Anthropic and the Department of War. We are officially a bit behind &#8230; <a href=\"https://thezvi.wordpress.com/2026/02/20/ai-156-part-2-errors-in-rhetoric/\">Continue reading <span class=\"meta-nav\">&#8594;</span></a>",
            "title": "AI #156 Part 2: Errors in Rhetoric"
        },
        {
            "content": [
                "<p>Hey all, I hope you're doing well.</p>\n        <p>I'm going to be on medical leave until early April. If you are <a href=\"https://sponsors.xeiaso.net/\">a sponsor</a>, then you can join the Discord for me to post occasional updates in real time. I'm gonna be in the hospital for at least a week as of the day of this post.</p>\n        <p>I have a bunch of things queued up both <a href=\"https://www.tigrisdata.com/blog\">at work</a> and on this blog. Please do share them when you see them cross your feeds, I hope that they'll be as useful as my posts normally are. I'm under a fair bit of stress leading up to this medical leave and I'm hoping that my usual style shines through as much as I hope it is. Focusing on writing is hard when the Big Anxiety is hitting as hard as it is.</p>\n        <p>Don't worry about me. I want you to be happy for me. This is very good medical leave. I'm not going to go into specifics for privacy reasons, but know that this is something I've wanted to do for over a decade but haven't gotten the chance due to the timing never working out.</p>\n        <p>I'll see you on the other side. Stay safe out there.</p>\n        <p>Xe</p>"
            ],
            "link": "https://xeiaso.net/notes/2026/life-update-medical-leave/",
            "publishedAt": "2026-02-20",
            "source": "Xe Iaso",
            "summary": "<p>Hey all, I hope you're doing well.</p> <p>I'm going to be on medical leave until early April. If you are <a href=\"https://sponsors.xeiaso.net/\">a sponsor</a>, then you can join the Discord for me to post occasional updates in real time. I'm gonna be in the hospital for at least a week as of the day of this post.</p> <p>I have a bunch of things queued up both <a href=\"https://www.tigrisdata.com/blog\">at work</a> and on this blog. Please do share them when you see them cross your feeds, I hope that they'll be as useful as my posts normally are. I'm under a fair bit of stress leading up to this medical leave and I'm hoping that my usual style shines through as much as I hope it is. Focusing on writing is hard when the Big Anxiety is hitting as hard as it is.</p> <p>Don't worry about me. I want you to be happy for me. This is very good medical leave. I'm not going to go into specifics for privacy reasons, but know that this is something I've wanted to do for over a decade but haven't gotten the chance due to the timing never working out.</p> <p>I'll see you on the other",
            "title": "Life Update: On medical leave"
        },
        {
            "content": [],
            "link": "https://xkcd.com/3210/",
            "publishedAt": "2026-02-20",
            "source": "XKCD",
            "summary": "<img alt=\"'If you've eliminated a few possibilities and you can't think of any others, your weird theory is proven right' isn't quite as rhetorically compelling.\" src=\"https://imgs.xkcd.com/comics/eliminating_the_impossible.png\" title=\"'If you've eliminated a few possibilities and you can't think of any others, your weird theory is proven right' isn't quite as rhetorically compelling.\" />",
            "title": "Eliminating the Impossible"
        }
    ],
    "lookbackDays": 1,
    "publishDate": "2026-02-20"
}