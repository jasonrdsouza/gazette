{
    "articles": [
        {
            "content": [
                "<div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!7yxn!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5cd1bda2-ee25-4a30-8536-686abd07475e_4756x2929.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"897\" src=\"https://substackcdn.com/image/fetch/$s_!7yxn!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5cd1bda2-ee25-4a30-8536-686abd07475e_4756x2929.png\" width=\"1456\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a></figure></div><p></p><p>This week, explore why one startup&#8217;s bare metal migration saved $1.2M yearly with better latency and 99.993% uptime, how Postgres handles pub/sub and queueing efficiently enough to replace Kafka in many scenarios and SQLite concurrency.</p><blockquote><p><strong>Sponsor Spotlight:</strong> QCon San Francisco &#8212; Enterprise AI Architecture Architecting AI systems? Evaluating LLM infra or planning migrations? <a href=\"https://qconsf.com/?utm_source=architecturenotes&amp;utm_medium=newsletter&amp;utm_campaign=architecturenotesnewsletterad_oct26_qsf25\">QCon San Francisco</a> (Nov 17&#8211;21) dives deep into real-world AI architecture, platforms, and patterns&#8212;before they go mainstream. Learn from early adopters. Make smarter decisions. <a href=\"https://qconsf.com/?utm_source=architecturenotes&amp;utm_medium=newsletter&amp;utm_campaign=architecturenotesnewsletterad_oct26_qsf25\">Learn more at qconsf.com</a> &#8594;</p></blockquote><p>Enjoy this week's round-up!</p><p>&#8212; Mahdi Yusuf (<a href=\"https://twitter.com/myusuf3\">@myusuf3</a>) or <a href=\"https://www.linkedin.com/in/myusuf3/\">LinkedIn</a></p><div class=\"pullquote\"><p>&#128075;&#127998; You are reading <a href=\"https://architecturenotes.co/\">Architecture Notes</a> - Your Sunday newsletter, which curates best system design and architecture news from around the web. We would appreciate you sharing it with like-minded people.</p></div><h2>Articles</h2><h3><a href=\"https://blog.jacobstechtavern.com/p/my-terrible-startup-architecture\">Lessons from a Startup&#8217;s Tech Architecture Disaster</a></h3><pre><code>Dive into the chaotic journey of building a startup&#8217;s tech architecture from scratch, where a young Deloitte graduate with an AWS certification took on the challenge of creating a mobile app and backend systems with little experience. Discover the pitfalls and lessons learned from relying on AWS Amplify, the struggles with GraphQL, and the costly serverless infrastructure that followed.</code></pre><h3><a href=\"https://thehustlingengineer.substack.com/p/the-silent-career-killer-most-engineers\">How Silent Disagreements Can Stall Your Engineering Team</a></h3><pre><code><code>Silent disagreements in the workplace can quietly erode trust, hurt credibility, and stall promotions. Discover how to spot these hidden career killers and learn strategies to ensure alignment and trust within your team.</code></code></pre><h3><a href=\"https://seated.ro/blog/tinkering-a-lost-art\">Why Tinkering Is Essential for Developing Taste</a></h3><pre><code><code>Discover how tinkering can transform your learning process and help you develop a unique sense of taste. The author shares personal insights on how experimenting with different skills and technologies has enriched their life and programming career.</code></code></pre><h3><a href=\"https://topicpartition.io/blog/postgres-pubsub-queue-benchmarks\">Why Postgres Might Be Your Best Bet Over Kafka</a></h3><pre><code>In a world where tech buzzwords often overshadow practicality, this article makes a compelling case for choosing Postgres over Kafka for many use cases. With benchmarks showing Postgres handling pub/sub messaging and queueing efficiently, it challenges the notion that complex distributed systems are always necessary.</code></pre><div><hr /></div><h3><strong>Enterprise AI Architecture at QCon San Francisco (Nov 17-21)</strong></h3><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!jAKN!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2faba52d-0acd-4192-9631-37fdf1beac02_2400x1200.heic\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"728\" src=\"https://substackcdn.com/image/fetch/$s_!jAKN!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2faba52d-0acd-4192-9631-37fdf1beac02_2400x1200.heic\" width=\"1456\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a></figure></div><p></p><p>Whether you&#8217;re designing AI platforms, scaling LLM serving, or building GenAI infrastructure, <a href=\"https://qconsf.com/?utm_source=architecturenotes&amp;utm_medium=newsletter&amp;utm_campaign=architecturenotesnewsletterad_oct26_qsf25\">QCon San Francisco 2025</a> connects you with senior architects, engineers, and technical leaders who&#8217;ve done it at scale.</p><p>Sessions explore balancing deterministic systems with probabilistic agents, autoscaling multi-model serving, vector stores and RAG pipelines at scale, and evolving data access patterns for AI workloads.</p><p>Hear what worked, what failed, and what to avoid from 60+ seasoned practitioners&#8212;so you can adopt emerging trends with confidence.</p><p><a href=\"https://qconsf.com/?utm_source=architecturenotes&amp;utm_medium=newsletter&amp;utm_campaign=architecturenotesnewsletterad_oct26_qsf25\">Learn more at qconsf.com</a> &#8594;</p><div><hr /></div><h3><a href=\"https://michael.stapelberg.ch/posts/2025-10-31-macbook-pro-m4-impressions/\">MacBook Pro M4: A User&#8217;s Honest Impressions</a></h3><pre><code><code>After six months with the MacBook Pro M4, Michael Stapelberg shares his thoughts on its nano-textured display, impressive battery life, and the subtle benefits of a 120 Hz screen. Discover why he chose the Pro over the Air and how the M4 chip keeps things cool and quiet!</code></code></pre><div class=\"subscription-widget-wrap-editor\"><div class=\"subscription-widget show-subscribe\"><div class=\"preamble\"><p class=\"cta-caption\">Architecture Notes &#8212; System Design &amp;  Software Development is a reader-supported publication. To receive new posts and support my work, consider becoming a free or paid subscriber.</p></div><form class=\"subscription-widget-subscribe\"><input class=\"email-input\" name=\"email\" tabindex=\"-1\" type=\"email\" /><input class=\"button primary\" type=\"submit\" value=\"Subscribe\" /><div class=\"fake-input-wrapper\"><div class=\"fake-input\"></div><div class=\"fake-button\"></div></div></form></div></div><h3><a href=\"https://boz.com/articles/you-are-how-you-act\">You Are How You Act</a></h3><pre><code><code>I personally a don't agree with the adage of fake it till you make it, but this was an interesting take on it. </code></code></pre><h3><a href=\"https://jellyfin.org/posts/SQLite-locking/\">Why SQLite Concurrency Matters and How Jellyfin Tackles It</a></h3><pre><code><code>Discover how Jellyfin navigates the tricky waters of SQLite concurrency issues with innovative locking strategies, ensuring smoother database operations and offering a potential solution for developers facing similar challenges.</code></code></pre><h3><a href=\"https://words.filippo.io/claude-debugging/\">Claude Code Debugs Complex Cryptography Bugs</a></h3><pre><code><code>Discover how Claude Code, an AI tool, impressively debugged a complex low-level cryptography bug in a new Go implementation of ML-DSA, a post-quantum signature algorithm. The AI rapidly identified a bug that had stumped the developer, showcasing its potential in tackling intricate coding challenges.</code></code></pre><h2>Projects</h2><h3><a href=\"https://github.com/seaweedfs/seaweedfs\">seaweedfs</a></h3><pre><code><code>SeaweedFS is a fast distributed storage system for blobs, objects, files, and data lake, for billions of files! </code></code></pre><h3><a href=\"https://github.com/janhq/jan\">jan</a></h3><pre><code><code>Discover Jan, the open-source AI that lets you run ChatGPT-like capabilities entirely offline on your computer! With 39k stars on GitHub, it&#8217;s a popular choice for those seeking privacy and control.</code></code></pre><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!wYPn!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd0f8bd98-bdb5-4338-85ce-86f11e5114e3_1000x483.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-large\" height=\"579.6\" src=\"https://substackcdn.com/image/fetch/$s_!wYPn!,w_2400,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd0f8bd98-bdb5-4338-85ce-86f11e5114e3_1000x483.png\" title=\"\" width=\"1200\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a></figure></div><p></p><h3><a href=\"https://oneuptime.com/blog/post/2025-10-29-aws-to-bare-metal-two-years-later/view\">Two Years After AWS: The Bare Metal Journey</a></h3><pre><code><code>Two years after ditching AWS for bare metal, OneUptime shares how they saved over $1.2M annually, improved latency, and maintained 99.993% availability. Dive into their detailed analysis and see why they still use cloud services for specific needs!</code></code></pre>"
            ],
            "link": "https://architecturenotes.co/p/arc-notes-weekly-102-primetime",
            "publishedAt": "2025-11-02",
            "source": "Architecture Notes",
            "summary": "This week, saving $1.2M by leaving AWS for bare metal, why Postgres replaces Kafka more often than you think, and a cautionary startup infrastructure tale. Plus, AI debugging and SQLite concurrency.",
            "title": "Arc Notes Weekly #102: Primetime"
        },
        {
            "content": [],
            "link": "https://olano.dev/blog/whats-different-about-my-rss-reader",
            "publishedAt": "2025-11-02",
            "source": "Facundo Olano",
            "summary": "It's been almost two years since I published and first wrote about feedi, my personal feed reader. During that time I continued to use it as my primary source of information, I slowly dropped Mastodon, and never felt the need to go back to Twitter. I experimented with a few new features but, most importantly, became confident to just remove anything that didn't feel necessary.",
            "title": "What's different about my RSS reader"
        },
        {
            "content": [
                "<p>I use Claude Code. A lot.</p><p>As a hobbyist, I run it in a VM several times a week on side projects, often with <code>--dangerously-skip-permissions</code> to vibe code whatever idea is on my mind. Professionally, part of my team builds the AI-IDE rules and tooling for our engineering team that consumes <em>several billion tokens per month</em> just for codegen.</p><p>The CLI agent space is getting crowded and between Claude Code, Gemini CLI, Cursor, and Codex CLI, it feels like the real race is between Anthropic and OpenAI. But TBH when I talk to other developers, their choice often comes down to what feels like superficials&#8212;a &#8220;lucky&#8221; feature implementation or a system prompt &#8220;vibe&#8221; they just prefer. At this point these tools are all pretty good. I also feel like folks often also over index on the output style or UI. Like to me the &#8220;you&#8217;re absolutely right!&#8221; sycophancy isn&#8217;t a notable bug; it&#8217;s a signal that you&#8217;re too in-the-loop. Generally my goal is to &#8220;shoot and forget&#8221;&#8212;to delegate, set the context, and let it work. Judging the tool by the final PR and not how it gets there.</p><p>Having stuck to Claude Code for the last few months, this post is my set of reflections on Claude Code&#8217;s entire ecosystem. We&#8217;ll cover nearly every feature I use (and, just as importantly, the ones I don&#8217;t), from the foundational <code>CLAUDE.md</code> file and custom slash commands to the powerful world of Subagents, Hooks, and GitHub Actions. <strong>This post ended up a bit long and I&#8217;d recommend it as more of a reference than something to read in entirety. </strong></p><h2><a href=\"https://www.anthropic.com/engineering/claude-code-best-practices\">CLAUDE.md</a></h2><p>The single most important file in your codebase for using Claude Code effectively is the root <code>CLAUDE.md</code>. This file is the agent&#8217;s &#8220;constitution,&#8221; its primary source of truth for how your specific repository works.</p><p>How you treat this file depends on the context. For my hobby projects, I let Claude dump whatever it wants in there.</p><p>For my professional work, our monorepo&#8217;s <code>CLAUDE.md</code> is strictly maintained and currently sits at 13KB (I could easily see it growing to 25KB). </p><ul><li><p>It only documents tools and APIs used by 30% (arbitrary) or more of our engineers (else tools are documented in product or library specific markdown files)</p></li><li><p>We&#8217;ve even started allocating effectively a max token count for each internal tool&#8217;s documentation, almost like selling &#8220;ad space&#8221; to teams. If you can&#8217;t explain your tool concisely, it&#8217;s not ready for the <code>CLAUDE.md</code>.</p></li></ul><h4>Tips and Common Anti-Patterns</h4><p>Over time, we&#8217;ve developed a strong, opinionated philosophy for writing an effective <code>CLAUDE.md</code>.</p><ol><li><p><strong>Start with Guardrails, Not a Manual.</strong> Your <code>CLAUDE.md</code> should start small, documenting based on what Claude is getting wrong.</p></li><li><p><strong>Don&#8217;t </strong><code>@</code><strong>-File Docs.</strong> If you have extensive documentation elsewhere, it&#8217;s tempting to <code>@</code>-mention those files in your <code>CLAUDE.md</code>. This bloats the context window by embedding the entire file on every run. But if you just <em>mention</em> the path, Claude will often ignore it. You have to <em>pitch</em> the agent on <em>why</em> and <em>when</em> to read the file. &#8220;For complex &#8230; usage or if you encounter a <code>FooBarError</code>, see <code>path/to/docs.md</code> for advanced troubleshooting steps.&#8221;</p></li><li><p><strong>Don&#8217;t Just Say &#8220;Never.&#8221;</strong> Avoid negative-only constraints like &#8220;Never use the <code>--foo-bar</code> flag.&#8221; The agent will get stuck when it thinks it <em>must</em> use that flag. Always provide an alternative.</p></li><li><p><strong>Use </strong><code>CLAUDE.md</code><strong> as a Forcing Function.</strong> If your CLI commands are complex and verbose, don&#8217;t write paragraphs of documentation to explain them. That&#8217;s patching a human problem. Instead, write a simple bash wrapper with a clear, intuitive API and document <em>that</em>. Keeping your <code>CLAUDE.md</code> as short as possible is a fantastic forcing function for simplifying your codebase and internal tooling.</p></li></ol><p>Here&#8217;s a simplified snapshot:</p><pre><code><code># Monorepo\n\n## Python\n- Always ...\n- Test with &lt;command&gt;\n... 10 more ...\n\n## &lt;Internal CLI Tool&gt;\n... 10 bullets, focused on the 80% of use cases ...\n- &lt;usage example&gt;\n- Always ...\n- Never &lt;x&gt;, prefer &lt;Y&gt;\n\nFor &lt;complex usage&gt; or &lt;error&gt; see path/to/&lt;tool&gt;_docs.md\n\n...</code></code></pre><p>Finally, we keep this file synced with an <code>AGENTS.md</code> file to maintain compatibility with other AI IDEs that our engineers might be using.</p><p><em>If you are looking for more tips for writing markdown for coding agents see <a href=\"https://blog.sshh.io/p/ai-cant-read-your-docs\">&#8220;AI Can&#8217;t Read Your Docs&#8221;,</a> <a href=\"https://blog.sshh.io/p/ai-powered-software-engineering\">&#8220;AI-powered Software Engineering&#8221;,</a> and <a href=\"https://blog.sshh.io/p/how-cursor-ai-ide-works\">&#8220;How Cursor (AI IDE) Works&#8221;.</a></em></p><p><strong>The Takeaway:</strong> Treat your <code>CLAUDE.md</code> as a high-level, curated set of guardrails and pointers. Use it to guide where you need to invest in more AI (and human) friendly tools, rather than trying to make it a comprehensive manual.</p><div class=\"subscription-widget-wrap-editor\"><div class=\"subscription-widget show-subscribe\"><div class=\"preamble\"><p class=\"cta-caption\">Thanks for reading Shrivu&#8217;s Substack! Subscribe for free to receive new posts and support my work.</p></div><form class=\"subscription-widget-subscribe\"><input class=\"email-input\" name=\"email\" tabindex=\"-1\" type=\"email\" /><input class=\"button primary\" type=\"submit\" value=\"Subscribe\" /><div class=\"fake-input-wrapper\"><div class=\"fake-input\"></div><div class=\"fake-button\"></div></div></form></div></div><h2><a href=\"https://www.reddit.com/r/ClaudeAI/comments/1lk2oay/compact_and_continue_or_clear_and_start_again/\">Compact, Context, &amp; Clear</a></h2><p>I recommend running <code>/context</code> mid coding session at least once to understand how you are using your 200k token context window (even with Sonnet-1M, I don&#8217;t trust that the full context window is actually used effectively). For us a fresh session in our monorepo costs a baseline ~20k tokens (10%) with the remaining 180k for making your change &#8212; which can fill up quite fast.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!o_oM!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7ee93292-646a-407a-95da-d469be81002e_1158x720.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"396.6839378238342\" src=\"https://substackcdn.com/image/fetch/$s_!o_oM!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7ee93292-646a-407a-95da-d469be81002e_1158x720.png\" width=\"638\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a><figcaption class=\"image-caption\">A screenshot of <strong>/context</strong> in one of my recent side projects. You can almost think of this like disk space that fills up as you work on a feature. After a few minutes or hours you&#8217;ll need to clear the messages (purple) to make space to continue.</figcaption></figure></div><p>I have three main workflows:</p><ul><li><p><code>/compact</code><strong> (Avoid):</strong> I avoid this as much as possible. The automatic compaction is opaque, error-prone, and not well-optimized.</p></li><li><p><code>/clear</code><strong> + </strong><code>/catchup</code><strong> (Simple Restart):</strong> My default reboot. I <code>/clear</code> the state, then run a custom <code>/catchup</code> command to make Claude read all changed files in my git branch.</p></li><li><p>&#8220;Document &amp; Clear&#8221;<strong> (Complex Restart):</strong> For large tasks. I have Claude dump its plan and progress into a <code>.md</code>, <code>/clear</code> the state, then start a new session by telling it to read the <code>.md</code> and continue.</p></li></ul><p><strong>The Takeaway:</strong> Don&#8217;t trust auto-compaction. Use <code>/clear</code> for simple reboots and the &#8220;Document &amp; Clear&#8221; method to create durable, external &#8220;memory&#8221; for complex tasks.</p><h2><a href=\"https://docs.claude.com/en/docs/claude-code/slash-commands\">Custom Slash Commands</a></h2><p>I think of slash commands as simple shortcuts for frequently used prompts, nothing more. My setup is minimal:</p><ul><li><p><code>/catchup</code>: The command I mentioned earlier. It just prompts Claude to read all changed files in my current git branch.</p></li><li><p><code>/pr</code>: A simple helper to clean up my code, stage it, and prepare a pull request.</p></li></ul><p>IMHO if you have a long list of complex, custom slash commands, you&#8217;ve created an anti-pattern. To me the entire point of an agent like Claude is that you can type <em>almost</em> whatever you want and get a useful, mergable result. The moment you force an engineer (or non-engineer) to learn a new, documented-somewhere list of essential magic commands just to get work done, you&#8217;ve failed.</p><p><strong>The Takeaway:</strong> Use slash commands as simple, personal shortcuts, not as a replacement for building a more intuitive <code>CLAUDE.md</code> and better-tooled agent.</p><h2><a href=\"https://docs.claude.com/en/docs/claude-code/sub-agents\">Custom Subagents</a></h2><p>On paper, custom subagents are Claude Code&#8217;s most powerful feature for context management. The pitch is simple: a complex task requires <code>X</code> tokens of input context (e.g., how to run tests), accumulates <code>Y</code> tokens of working context, and produces a <code>Z</code> token answer. Running <code>N</code> tasks means <code>(X + Y + Z) * N</code> tokens in your main window.</p><p>The subagent solution is to farm out the <code>(X + Y) * N</code> work to specialized agents, which only return the final <code>Z</code> token answers, keeping your main context clean.</p><p>I find they are a powerful idea that, in practice, <em>custom</em> subagents create two new problems:</p><ol><li><p><strong>They Gatekeep Context:</strong> If I make a <code>PythonTests</code> subagent, I&#8217;ve now hidden all testing context from my <em>main</em> agent. It can no longer reason holistically about a change. It&#8217;s now forced to invoke the subagent just to know how to validate its own code.</p></li><li><p><strong>They Force Human Workflows:</strong> Worse, they force Claude into a rigid, human-defined workflow. I&#8217;m now dictating <em>how</em> it must delegate, which is the very problem I&#8217;m trying to get the agent to solve for me.</p></li></ol><p>My preferred alternative is to use Claude&#8217;s built-in <code>Task(...)</code> feature to spawn clones of the <em>general</em> agent.</p><p>I put all my key context in the <code>CLAUDE.md</code>. Then, I let the <em>main agent</em> decide when and how to delegate work to copies of itself. This gives me all the context-saving benefits of subagents without the drawbacks. The agent manages its own orchestration dynamically.</p><p>In my <a href=\"https://blog.sshh.io/p/building-multi-agent-systems-part\">&#8220;Building Multi-Agent Systems (Part 2)&#8221;</a> post, I called this the &#8220;Master-Clone&#8221; architecture, and I strongly prefer it over the &#8220;Lead-Specialist&#8221; model that custom subagents encourage.</p><p><strong>The Takeaway:</strong> Custom subagents are a brittle solution. Give your main agent the context (in <code>CLAUDE.md</code>) and let it use its own <code>Task/Explore(...)</code> feature to manage delegation.</p><h2><a href=\"https://docs.claude.com/en/docs/claude-code/common-workflows#resume-previous-conversations\">Resume, Continue, &amp; History</a></h2><p>On a simple level, I use <code>claude --resume</code> and <code>claude --continue</code> frequently. They&#8217;re great for restarting a bugged terminal or quickly rebooting an older session. I&#8217;ll often <code>claude --resume</code> a session from days ago just to ask the agent to summarize how it overcame a specific error, which I then use to improve our <code>CLAUDE.md</code> and internal tooling.</p><p>More in the weeds, Claude Code stores all session history in <code>~/.claude/projects/</code> to tap into the raw historical session data. I have scripts that run meta-analysis on these logs, looking for common exceptions, permission requests, and error patterns to help improve agent-facing context.</p><p><strong>The Takeaway:</strong> Use <code>claude --resume</code> and <code>claude --continue </code>to restart sessions and uncover buried historical context.</p><h2><a href=\"https://docs.claude.com/en/docs/claude-code/hooks\">Hooks</a></h2><p>Hooks are huge. I don&#8217;t use them for hobby projects, but they are critical for steering Claude in a complex enterprise repo. They are the deterministic &#8220;must-do&#8221; rules that complement the &#8220;should-do&#8221; suggestions in <code>CLAUDE.md</code>.</p><p>We use two types:</p><ol><li><p><strong>Block-at-Submit Hooks:</strong> This is our primary strategy. We have a <code>PreToolUse</code> hook that wraps any <code>Bash(git commit)</code> command. It checks for a <code>/tmp/agent-pre-commit-pass</code> file, which our test script <em>only</em> creates if all tests pass. If the file is missing, the hook blocks the commit, forcing Claude into a &#8220;test-and-fix&#8221; loop until the build is green.</p></li><li><p><strong>Hint Hooks:</strong> These are simple, non-blocking hooks that provide &#8220;fire-and-forget&#8221; feedback if the agent is doing something suboptimal.</p></li></ol><p>We intentionally do not use &#8220;block-at-write&#8221; hooks (e.g., on <code>Edit</code> or <code>Write</code>). Blocking an agent mid-plan confuses or even &#8220;frustrates&#8221; it. It&#8217;s far more effective to let it finish its work and then check the final, completed result at the commit stage.</p><p><strong>The Takeaway:</strong> Use hooks to enforce state validation at commit time (<code>block-at-submit</code>). Avoid blocking at write time&#8212;let the agent finish its plan, then check the final result.</p><h2><a href=\"https://youtu.be/QlWyrYuEC84?si=mQxc_iyVKmo3iJOd&amp;t=915\">Planning Mode</a></h2><p>Planning is essential for any &#8220;large&#8221; feature change with an AI IDE.</p><p>For my hobby projects, I exclusively use the built-in planning mode. It&#8217;s a way to align with Claude before it starts, defining both <em>how</em> to build something and the &#8220;inspection checkpoints&#8221; where it needs to stop and show me its work. Using this regularly builds a strong intuition for what minimal context is needed to get a good plan without Claude botching the implementation.</p><p>In our work monorepo, we&#8217;ve started rolling out a custom planning tool built on the Claude Code SDK. Its similar to native plan mode but heavily prompted to align its outputs with our existing technical design format. It also enforces our internal best practices&#8212;from code structure to data privacy and security&#8212;out of the box. This lets our engineers &#8220;vibe plan&#8221; a new feature as if they were a senior architect (or at least that&#8217;s the pitch).</p><p><strong>The Takeaway:</strong> Always use the built-in planning mode for complex changes to align on a plan before the agent starts working.</p><h2><a href=\"https://docs.claude.com/en/docs/claude-code/skills\">Skills</a></h2><p>I agree with <a href=\"https://simonwillison.net/2025/Oct/16/claude-skills/\">Simon Willison&#8217;s</a>: <strong>Skills are (maybe) a bigger deal than MCP.</strong></p><p>If you&#8217;ve been following my posts, you&#8217;ll know I&#8217;ve drifted away from MCP for most dev workflows, preferring to build simple CLIs instead (as I argued in <a href=\"https://blog.sshh.io/p/ai-cant-read-your-docs\">&#8220;AI Can&#8217;t Read Your Docs&#8221;</a>). My mental model for agent autonomy has evolved into three stages:</p><ol><li><p><strong>Single Prompt:</strong> Giving the agent all context in one massive prompt. (Brittle, doesn&#8217;t scale).</p></li><li><p><strong>Tool Calling:</strong> The &#8220;classic&#8221; agent model. We hand-craft tools and abstract away reality for the agent. (Better, but creates new abstractions and context bottlenecks).</p></li><li><p><strong><a href=\"https://blog.sshh.io/i/167598476/scripting-agents\">Scripting</a>:</strong> We give the agent access to the raw environment&#8212;binaries, scripts, and docs&#8212;and it writes code <em>on the fly</em> to interact with them.</p></li></ol><p>With this model in mind, <strong>Agent Skills</strong> are the obvious next feature. They are the formal productization of the &#8220;Scripting&#8221; layer.</p><p>If, like me, you&#8217;ve already been <a href=\"https://blog.sshh.io/i/171208815/pattern-choose-the-right-interface-cli-vs-mcp\">favoring CLIs over MCP,</a> you&#8217;ve been implicitly getting the benefit of Skills all along. The <code>SKILL.md</code> file is just a more organized, shareable, and discoverable way to document these CLIs and scripts and expose them to the agent.</p><p><strong>The Takeaway:</strong> Skills are the right abstraction. They formalize the &#8220;scripting&#8221;-based agent model, which is more robust and flexible than the rigid, API-like model that MCP represents.</p><h2><a href=\"https://modelcontextprotocol.io/docs/getting-started/intro\">MCP (Model Context Protocol)</a></h2><p>Skills don&#8217;t mean MCP is dead (see also <a href=\"https://blog.sshh.io/p/everything-wrong-with-mcp\">&#8220;Everything Wrong with MCP&#8221;</a>). Previously, many built awful, context-heavy MCPs with dozens of tools that just mirrored a REST API (<code>read_thing_a()</code>, <code>read_thing_b()</code>, <code>update_thing_c()</code>). </p><p>The &#8220;Scripting&#8221; model (now formalized by Skills) is better, but it needs a secure way to access the environment. This to me is the new, more focused role for MCP.</p><p>Instead of a bloated API, an MCP should be a simple, secure gateway that provides a few powerful, high-level tools:</p><ul><li><p><code>download_raw_data(filters&#8230;)</code></p></li><li><p><code>take_sensitive_gated_action(args&#8230;)</code></p></li><li><p><code>execute_code_in_environment_with_state(code&#8230;)</code></p></li></ul><p>In this model, MCP&#8217;s job isn&#8217;t to abstract reality for the agent; its job is to manage the auth, networking, and security boundaries and then get out of the way. It provides the <em>entry point</em> for the agent, which then uses its scripting and <code>markdown</code> context to do the actual work.</p><p>The only MCP I still use is for <a href=\"https://github.com/microsoft/playwright-mcp\">Playwright</a>, which makes sense&#8212;it&#8217;s a complex, stateful environment. All my stateless tools (like Jira, AWS, GitHub) have been migrated to simple CLIs.</p><p><strong>The Takeaway:</strong> Use MCPs that act as data gateways. Give the agent one or two high-level tools (like a raw data dump API) that it can then script against.</p><h2><a href=\"https://docs.claude.com/en/api/agent-sdk/overview\">Claude Code SDK</a></h2><p>Claude Code isn&#8217;t just an interactive CLI; it&#8217;s also a powerful SDK for building entirely new agents&#8212;for both coding and non-coding tasks. I&#8217;ve started using it as my default agent framework over tools like LangChain/CrewAI for most new hobby projects.</p><p>I use it in three main ways:</p><ol><li><p><strong>Massive Parallel Scripting:</strong> For large-scale refactors, bug fixes, or migrations, I don&#8217;t use the interactive chat. I write simple bash scripts that call <code>claude -p &#8220;in /pathA change all refs from foo to bar&#8221;</code> in parallel. This is far more scalable and controllable than trying to get the main agent to manage dozens of subagent tasks.</p></li><li><p><strong>Building Internal Chat Tools:</strong> The SDK is perfect for wrapping complex processes in a simple chat interface for non-technical users. Like an installer that, on error, falls back to the Claude Code SDK to just <em>fix</em> the problem for the user. Or an in-house &#8220;<a href=\"http://v0.dev/\">v0-at-home</a>&#8221; tool that lets our design team vibe-code mock frontends in our in-house UI framework, ensuring their ideas are high-fidelity and the code is more directly usable in frontend production code.</p></li><li><p><strong>Rapid Agent Prototyping:</strong> This is my most common use. It&#8217;s not just for coding. If I have an idea for any agentic task (e.g., a &#8220;threat investigation agent&#8221; that uses custom CLIs or MCPs), I use the Claude Code SDK to quickly build and test the prototype before committing to a full, deployed scaffolding.</p></li></ol><p><strong>The Takeaway:</strong> The Claude Code SDK is a powerful, general-purpose agent framework. Use it for batch-processing code, building internal tools, and rapidly prototyping new agents <em>before</em> you reach for more complex frameworks.</p><h2><a href=\"https://github.com/anthropics/claude-code-action\">Claude Code GHA</a></h2><p>The Claude Code GitHub Action (GHA) is probably one of my favorite and most slept on features. It&#8217;s a simple concept: just run Claude Code in a GHA. But this simplicity is what makes it so powerful.</p><p>It&#8217;s similar to <a href=\"https://cursor.com/docs/cloud-agent\">Cursor&#8217;s background agents</a> or the Codex managed web UI but is far more customizable. You control the entire container and environment, giving you more access to data and, crucially, much stronger sandboxing and audit controls than any other product provides. Plus, it supports all the advanced features like Hooks and MCP.</p><p>We&#8217;ve used it to build custom &#8220;PR-from-anywhere&#8221; tooling. Users can trigger a PR from Slack, Jira, or even a CloudWatch alert, and the GHA will fix the bug or add the feature and return a fully tested PR<a class=\"footnote-anchor\" href=\"https://blog.sshh.io/feed#footnote-1\" id=\"footnote-anchor-1\" target=\"_self\">1</a>.</p><p>Since the GHA logs are the full agent logs, we have an ops process to regularly review these logs at a company level for common mistakes, bash errors, or unaligned engineering practices. This creates a data-driven flywheel: Bugs -&gt; Improved CLAUDE.md / CLIs -&gt; Better Agent.</p><pre><code>$ query-claude-gha-logs --since 5d | claude -p &#8220;see what the other claudes were getting stuck on and fix it, then put up a PR&#8220;</code></pre><p><strong>The Takeaway:</strong> The GHA is the ultimate way to operationalize Claude Code. It turns it from a personal tool into a core, auditable, and self-improving part of your engineering system.</p><h2><a href=\"https://docs.claude.com/en/docs/claude-code/settings\">settings.json</a></h2><p>Finally, I have a few specific <code>settings.json</code> configurations that I&#8217;ve found essential for both hobby and professional work.</p><ul><li><p><code>HTTPS_PROXY</code>/<code>HTTP_PROXY</code>: This is great for debugging. I&#8217;ll use it to inspect the raw traffic to see exactly what prompts Claude is sending. For background agents, it&#8217;s also a powerful tool for fine-grained network sandboxing.</p></li><li><p><code>MCP_TOOL_TIMEOUT</code>/<code>BASH_MAX_TIMEOUT_MS</code>: I bump these. I like running long, complex commands, and the default timeouts are often too conservative. I&#8217;m honestly not sure if this is still needed now that bash background tasks are a thing, but I keep it just in case.</p></li><li><p><code>ANTHROPIC_API_KEY</code>: At work, we use our enterprise API keys (<a href=\"https://www.reddit.com/r/ClaudeAI/comments/1jwvssa/comment/mtt0urz/?utm_source=share&amp;utm_medium=web3x&amp;utm_name=web3xcss&amp;utm_term=1&amp;utm_content=share_button\">via apiKeyHelper</a>). It shifts us from a &#8220;per-seat&#8221; license to &#8220;usage-based&#8221; pricing, which is a much better model for how we work.</p><ul><li><p>It accounts for the <em>massive</em> variance in developer usage (We&#8217;ve seen 1:100x differences between engineers).</p></li><li><p>It lets engineers to tinker with non-Claude-Code LLM scripts, all under our single enterprise account.</p></li></ul></li><li><p><code>&#8220;permissions&#8221;</code>: I&#8217;ll occasionally self-audit the list of commands I&#8217;ve allowed Claude to auto-run.</p></li></ul><p><strong>The Takeaway:</strong> Your <code>settings.json</code> is a powerful place for advanced customization.</p><h2>Conclusion</h2><p>That was a lot, but hopefully, you find it useful. If you&#8217;re not already using a CLI-based agent like Claude Code or Codex CLI, you probably should be. There are rarely good guides for these advanced features, so the only way to learn is to dive in.</p><div class=\"subscription-widget-wrap-editor\"><div class=\"subscription-widget show-subscribe\"><div class=\"preamble\"><p class=\"cta-caption\">Thanks for reading Shrivu&#8217;s Substack! Subscribe for free to receive new posts and support my work.</p></div><form class=\"subscription-widget-subscribe\"><input class=\"email-input\" name=\"email\" tabindex=\"-1\" type=\"email\" /><input class=\"button primary\" type=\"submit\" value=\"Subscribe\" /><div class=\"fake-input-wrapper\"><div class=\"fake-input\"></div><div class=\"fake-button\"></div></div></form></div></div><div class=\"footnote\"><a class=\"footnote-number\" contenteditable=\"false\" href=\"https://blog.sshh.io/feed#footnote-anchor-1\" id=\"footnote-1\" target=\"_self\">1</a><div class=\"footnote-content\"><p>To me, a fairly interesting philosophical question is how many reviewers should a PR get that was generated directly from a customer request (no internal human prompter)? We&#8217;ve settled on 2 human approvals for any AI-initiated PR for now, but it is kind of a weird paradigm shift (for me at least) when it&#8217;s no longer a human making something for another human to review.</p></div></div>"
            ],
            "link": "https://blog.sshh.io/p/how-i-use-every-claude-code-feature",
            "publishedAt": "2025-11-02",
            "source": "Shrivu Shankar",
            "summary": "<p>I use Claude Code. A lot.</p><p>As a hobbyist, I run it in a VM several times a week on side projects, often with <code>--dangerously-skip-permissions</code> to vibe code whatever idea is on my mind. Professionally, part of my team builds the AI-IDE rules and tooling for our engineering team that consumes <em>several billion tokens per month</em> just for codegen.</p><p>The CLI agent space is getting crowded and between Claude Code, Gemini CLI, Cursor, and Codex CLI, it feels like the real race is between Anthropic and OpenAI. But TBH when I talk to other developers, their choice often comes down to what feels like superficials&#8212;a &#8220;lucky&#8221; feature implementation or a system prompt &#8220;vibe&#8221; they just prefer. At this point these tools are all pretty good. I also feel like folks often also over index on the output style or UI. Like to me the &#8220;you&#8217;re absolutely right!&#8221; sycophancy isn&#8217;t a notable bug; it&#8217;s a signal that you&#8217;re too in-the-loop. Generally my goal is to &#8220;shoot and forget&#8221;&#8212;to delegate, set the context, and let it work. Judging the tool by the final PR and not how it gets there.</p><p>Having stuck to Claude Code for the last few months, this post is my set",
            "title": "How I Use Every Claude Code Feature"
        },
        {
            "content": [],
            "link": "https://simonwillison.net/2025/Nov/2/new-prompt-injection-papers/#atom-entries",
            "publishedAt": "2025-11-02",
            "source": "Simon Willison",
            "summary": "<p>Two interesting new papers regarding LLM security and prompt injection came to my attention this weekend.</p> <h4 id=\"agents-rule-of-two-a-practical-approach-to-ai-agent-security\">Agents Rule of Two: A Practical Approach to AI Agent Security</h4> <p>The first is <a href=\"https://ai.meta.com/blog/practical-ai-agent-security/\">Agents Rule of Two: A Practical Approach to AI Agent Security</a>, published on October 31st on the Meta AI blog. It doesn't list authors but it was <a href=\"https://x.com/MickAyzenberg/status/1984355145917088235\">shared on Twitter</a> by Meta AI security researcher Mick Ayzenberg.</p> <p>It proposes a \"Rule of Two\" that's inspired by both my own <a href=\"https://simonwillison.net/2025/Jun/16/the-lethal-trifecta/\">lethal trifecta</a> concept and the Google Chrome team's <a href=\"https://chromium.googlesource.com/chromium/src/+/main/docs/security/rule-of-2.md\">Rule Of 2</a> for writing code that works with untrustworthy inputs:</p> <blockquote> <p>At a high level, the Agents Rule of Two states that until robustness research allows us to reliably detect and refuse prompt injection, agents <strong>must satisfy no more than two</strong> of the following three properties within a session to avoid the highest impact consequences of prompt injection.</p> <p><strong>[A]</strong> An agent can process untrustworthy inputs</p> <p><strong>[B]</strong> An agent can have access to sensitive systems or private data</p> <p><strong>[C]</strong> An agent can change state or communicate externally</p> <p>It's still possible that all three properties are necessary to carry out a request. If an agent requires all three without",
            "title": "New prompt injection papers: Agents Rule of Two and The Attacker Moves Second"
        },
        {
            "content": [
                "<p>Something I've seen around the internet is that many projects want <a href=\"https://wiki.gentoo.org/wiki/Project:Council/AI_policy\">a blanket policy of no AI tools being allowed</a> for contributors. As much as I agree with the sentiment of policies like this, I don't think it's entirely realistic because it's trivial to lie about not using them when you actually do.</p>\n        <p>I think a better middle ground is something like <a href=\"https://docs.fedoraproject.org/en-US/council/policy/ai-contribution-policy/\">Fedora's AI-Assisted Contributions Policy</a>. This demands that you include a commit footer that discloses what AI tools you've used in your process, such as this:</p>\n        <pre class=\"language-text\"><code class=\"language-text code-highlight\"><span class=\"code-line\">Assisted-by: GPT-OSS 120b via OpenAI Codex (locally hosted)\n        </span></code></pre>\n        <p>Amusingly, you can actually tell AI agents to write this commit footer and they'll happily do it. Consider this part of <a href=\"https://github.com/Xe/site/blob/main/AGENTS.md\">this repo's AGENTS.md file</a> (AGENTS.md is a set of instructions for AI agents to know how to best contribute to the policy):</p>\n        <blockquote>\n        <p><strong>Attribution Requirements</strong></p>\n        <p>AI agents must disclose what tool and model they are using in\n        the &quot;Assisted-by&quot; commit footer:</p>\n        <pre class=\"language-text\"><code class=\"language-text code-highlight\"><span class=\"code-line\">Assisted-by: [Model Name] via [Tool Name]\n        </span></code></pre>\n        <p>Example:</p>\n        <pre class=\"language-text\"><code class=\"language-text code-highlight\"><span class=\"code-line\">Assisted-by: GLM 4.6 via Claude Code\n        </span></code></pre>\n        </blockquote>\n        <p>Not only does this make it trivial for automation to detect when AI tools are being used (and add appropriate tagging so reviewers can be more particular), it lets you know which AI tools cause more issues in the longer run. This can help guide policy and assist contributors that want to use AI tooling into picking the best tools for the job.</p>\n        <p>Anyways, at a high level if you ask people to disclose what AI tools they are using and make it so that the default configuration of most AI tooling will just add that disclosure for you, people are much more likely to comply with that policy. I think that this is a better middle ground than having witch hunts trying to figure out who used what tool and letting it become a free ground for noisy, low\u2011quality contributions.</p>\n        <p>I want to see a future where people are allowed to experiment with fancy new tools. However, given the risks involved with low\u2011effort contributions causing issues, I think it's better for everyone to simply require an easy machine\u2011readable footer.</p>\n        <p>Also, if you want to put <code>Assisted-by: GNU Emacs</code>, I won't stop you.</p>\n        <p>This post was edited with help from GPT-OSS 120b on a DGX Spark, a device which only consumes 150 watts at maximum load. While I was writing this, I had Final Fantasy 14 open in the background to listen to bards perform in Limsa Lominsa. This made my workstation's RTX 4080 pull 150 watts of power constantly.</p>"
            ],
            "link": "https://xeiaso.net/notes/2025/assisted-by-footer/",
            "publishedAt": "2025-11-02",
            "source": "Xe Iaso",
            "summary": "It sounds like ceding ground to the pro-AI crowd, however if you get people to be honest about it then everyone benefits.",
            "title": "Using Assisted-by commit footers instead of banning AI tools"
        }
    ],
    "lookbackDays": 1,
    "publishDate": "2025-11-02"
}