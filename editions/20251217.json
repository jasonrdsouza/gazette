{
    "articles": [
        {
            "content": [
                "<p>A while ago I was looking for a palm tree emoji, and the macOS Character Viewer suggested a variety of other characters I didn\u2019t recognise:</p>\n\n<source media=\"(prefers-color-scheme: dark)\" type=\"image/png\" /><source type=\"image/png\" /><img alt=\"A character picker with some palm-related emojis (like facepalm, palm tree, and open palms), and then some characters drawn with thick lines and gentle curves.\" class=\"screenshot dark_aware\" src=\"https://alexwlchan.net/images/2025/palm_emojis_1x.png\" width=\"500\" />\n\n\n<p>Some of the curves look a bit like Hebrew, but it\u2019s definitely not that alphabet.\nI\u00a0clicked on the first character (\ud802\udc71) and learnt that it\u2019s <em>Palmyrene Letter Pe</em>, which is from the <a href=\"https://en.wikipedia.org/wiki/Palmyrene_alphabet\">Palmyrene alphabet</a>.\nI\u2019d never heard of Palmyrene, so I knew I was about to learn something.</p>\n\n<h2 id=\"the-palmyrene-unicode-block\">The Palmyrene Unicode block</h2>\n\n<p>These letters are part of the <a href=\"https://en.wikipedia.org/wiki/Palmyrene_(Unicode_block)\">Palmyrene Unicode block</a>, a set of 32 code points for the Palmyrene alphabet and digits.\nOne of the cool things about Unicode is that the proposals for new characters are publicly available on the Unicode Consortium website, and they\u2019re usually pretty readable.</p>\n\n<p>Proposals have to provide some background on the characters they\u2019re proposing.\nHere\u2019s the introduction from the <a href=\"https://www.unicode.org/L2/L2010/10003-n3749-palmyrene.pdf\">original proposal in 2010</a>:</p>\n\n<blockquote>\n  <p>The Palmyrene alphabet was used from the first century BCE, in a small independent state established near the Red Sea, north of the Syrian desert between Damascus and the Euphrates.\nThe alphabet was derived as a national script by modification of the customary forms that cursive Aramaic which themselves developed during the first Persian Empire.</p>\n\n  <p>Palmyrene is known from documents distributed over a period from the year 9 BCE until 273 CE, the date of the sack of Palmyra by Aurelian. [\u2026]\nNo documents on perishable materials have survived; there are a few painted inscriptions, but many inscriptions on stone.</p>\n</blockquote>\n\n<p>Here\u2019s an example of a funerary stone inscribed with Palmyrene script, whose shapes match the Unicode characters I didn\u2019t recognise:</p>\n\n<figure>\n  \n\n\n<a href=\"https://commons.wikimedia.org/wiki/File:Inscription_Palmyra_Louvre_AO2205.jpg\"><source type=\"image/avif\" /><source type=\"image/webp\" /><source type=\"image/jpeg\" /><img alt=\"A large brown stone with curving letters written in horizontal lines, making six lines of text in total.\" src=\"https://alexwlchan.net/images/2025/Inscription_Palmyra_Louvre_AO2205_1x.jpg\" width=\"500\" />\n</a>\n\n\n  <figcaption>\n   Funerary slabstone held in the Louvre, catalogue reference <a href=\"https://collections.louvre.fr/en/ark:/53355/cl010127815\">AO\u00a02205</a>.\n   Photo:\u00a0Marie-Lan Nguyen, <a href=\"https://commons.wikimedia.org/wiki/File:Inscription_Palmyra_Louvre_AO2205.jpg\">Wikimedia Commons</a>.\n  </figcaption>\n</figure>\n\n<p>The proposal was written by <a href=\"https://en.wikipedia.org/wiki/Michael_Everson\">Michael Everson</a>, a prolific contributor who\u2019s submitted hundreds of proposals to add characters to Unicode.\nHis Wikipedia article lists <a href=\"https://en.wikipedia.org/wiki/Michael_Everson#Encoding_of_scripts\">over seventy scripts</a>.\nHe was profiled <a href=\"http://www.nytimes.com/2003/09/25/technology/for-the-world-s-abc-s-he-makes-1-s-and-0-s.html\">by the <em>New York Times</em></a> in 2003 \u2013 seven years before proposing Palmyrene \u2013 which described his work and his \u201ccrucial role in developing Unicode\u201d.</p>\n\n<p>He takes a very long view of his work.\nNormally I\u2019m sceptical of claims about the longevity of digital work, but Unicode is a rare area where I think it might just last:</p>\n\n<blockquote>\n  <p>\u201cThere\u2019s satisfaction in knowing that the work of analyzing and encoding these languages, once done, will never need to be done again,\u201d [Everson] said. \u201cThis will be used for the next thousand years.\u201d</p>\n</blockquote>\n\n<p>And I liked this part at the end:</p>\n\n<blockquote>\n  <p>He likes to tell about how he met the president of the Tibetan Calligraphy Society at a Unicode meeting in Copenhagen.\nMr. Everson had helped the organization ensure that Tibetan was included in the standard.\nThe president showed Mr. Everson how to write his name in Tibetan with a highlighter pen.</p>\n\n  <p>\u201cHe thanked me,\u201d Mr. Everson said with reverence. \u201cI couldn\u2019t believe that, because his organization has been in existence for over a thousand years.\u201d</p>\n</blockquote>\n\n<p>I spent eight years working in cultural heritage and thinking about the longevity of digital collections, but I never gave much thought to the history or encoding of writing.\nThis is cool and important work, and I should learn more about it.</p>\n\n<h2 id=\"what-are-the-characters-in-palmyrene\">What are the characters in Palmyrene?</h2>\n\n<p>Palmyrene has 22 letters in its alphabet, which expands to 32 Unicode codepoints when you include alternative letters, numbers, and a pair of symbols.</p>\n\n<p>The only letter I recognise is <em>aleph</em> (\ud802\udc60), which looks similar to the <a href=\"https://en.wikipedia.org/wiki/Aleph\">Hebrew letter aleph \u2135</a>.\nI\u00a0know the latter because it\u2019s used by mathematicians to describe <a href=\"https://en.wikipedia.org/wiki/Aleph_number#Aleph-zero\">the size of infinite sets</a>.\nIt turns out <em>aleph</em> or (<em>alef</em>) is the name of letters in a variety of languages, not all of which look the same \u2013 including Phoenician\u00a0(\ud802\udd00), Syriac\u00a0(\u0710), and Nabatean\u00a0(\ud802\udc81/\ud802\udc80).</p>\n\n<p>The other letters have names which are new to me, like <em>heth</em> (\ud802\udc67), <em>samekh</em> (\ud802\udc6f), and <em>gimel</em> (\ud802\udc62).</p>\n\n<p>One especially interesting letter is <em>nun</em>, which appears differently depending on whether it\u2019s in the middle of the word (\ud802\udc6e) or the end (\ud802\udc6d).\nThis reminds me of the <a href=\"https://en.wikipedia.org/wiki/Sigma\">ancient Greek letter <em>sigma</em></a>, which is either \u03c3 or \u03c2.\nI\u00a0can\u2019t help but see a passing resemblance between final <em>nun</em> and final <em>sigma</em>, but surely it\u2019s a coincidence \u2013 the rest of the alphabets are so different.</p>\n\n<p>The Palmyrene numbers look similar to the Arabic numerals we use today, but not necessarily the same meaning.\nOne, two, three and four are regular tally marks (\ud802\udc79, \ud802\udc7a, \ud802\udc7b, \ud802\udc7c).\nThe more unusual characters are five (\ud802\udc7d), ten (\ud802\udc7e), and twenty (\ud802\udc7f) \u2013 but again, it\u2019s surely a coincidence that the latter resembles the modern digit 3.</p>\n\n<p>Alongside the letters and numbers, there are two decorative symbols for left/right <a href=\"https://en.wikipedia.org/wiki/Fleuron_(typography)\">fleurons</a> (\ud802\udc77/\ud802\udc78).</p>\n\n<h2 id=\"writing-about-a-right-to-left-language\">Writing about a right-to-left language</h2>\n\n<p>Palmyrene is written horizontally from right-to-left, which introduced some new challenges while writing this blog post.</p>\n\n<p>The first issue was in my text editor, which is fairly old and doesn\u2019t have good right-to-left support.\nI\u00a0can include Palmyrene characters directly in my text, but it messes up the ordering and text selection.\nI\u00a0can navigate the text with the arrow keys, but it behaves in weird ways.\nTo get round this, I used HTML entities in all my source code (for example, <code>&amp;#67680;</code>).</p>\n\n<p>The second issue was in the rendered HTML page, where the Unicode characters affect the ordering on the page.\nIn particular, I wanted to show the characters for 1, 2, 3, 4, in that order, so I wrote the four entities \u2013 but the browser uses a <a href=\"https://www.w3.org/International/articles/inline-bidi-markup/uba-basics\">bidirectional algorithm</a> and renders the sequence of characters as right-to-left.\nThat\u2019s the opposite of what I wanted:</p>\n\n\n\n<table class=\"block\">\n  <tr>\n    <th>HTML:</th>\n    <td>\n      <code>&amp;#67705;, &amp;#67706;, &amp;#67707;, &amp;#67708;</code>\n    </td>\n  </tr>\n  <tr>\n    <th>Output:</th>\n    <td>\n      \ud802\udc79, \ud802\udc7a, \ud802\udc7b, \ud802\udc7c\n    </td>\n  </tr>\n</table>\n\n<p>The fix was to wrap each character in the <a href=\"https://developer.mozilla.org/en-US/docs/Web/HTML/Reference/Elements/bdi\">bidirectional isolate <code>&lt;bdi&gt;</code> element</a>.\nThis tells the browser to isolate the direction of the text within that element, so the direction of each character doesn\u2019t affect the overall sequence.\nThis gave me what I wanted:</p>\n\n<table class=\"block\">\n  <tr>\n    <th>HTML:</th>\n    <td>\n      <code>&lt;bdi&gt;&amp;#67705;&lt;/bdi&gt;, &lt;bdi&gt;&amp;#67706;&lt;/bdi&gt;, &lt;bdi&gt;&amp;#67707;&lt;/bdi&gt;, &lt;bdi&gt;&amp;#67708;&lt;/bdi&gt;</code>\n    </td>\n  </tr>\n  <tr>\n    <th>Output:</th>\n    <td>\n      \ud802\udc79, \ud802\udc7a, \ud802\udc7b, \ud802\udc7c\n    </td>\n  </tr>\n</table>\n\n<p>This is the first time the <code>&lt;bdi&gt;</code> element has appeared on this blog, and I think it\u2019s the first time I\u2019ve used it anywhere.</p>\n\n<hr />\n\n<p>I took the original screenshot in September.\nIt took me three months to dig into the detail, and I\u2019m glad I did.\nThis is a corner of history and writing that I\u2019d never heard of, and even now I\u2019ve only scratched the surface.</p>\n\n<p>The Palmyrene alphabet is an example of what I call a \u201cfractally interesting\u201d topic.\nHowever deep you dig, however much you learn, there\u2019s always more to uncover.</p>\n\n\n    <p>[If the formatting of this post looks odd in your feed reader, <a href=\"https://alexwlchan.net/2025/palmyrene-alphabet/?ref=rss\">visit the original article</a>]</p>"
            ],
            "link": "https://alexwlchan.net/2025/palmyrene-alphabet/?ref=rss",
            "publishedAt": "2025-12-17",
            "source": "Alex Chan",
            "summary": "Palmyrene is an alphabet that was used to write Aramaic in 300\u2013100 BCE, and I learnt about it while looking for a palm tree emoji.",
            "title": "The palm tree that led to Palmyra"
        },
        {
            "content": [
                "<p>I recently added domain exclusion lists and paywalled content filtering to <a href=\"https://scour.ing\">Scour</a>. This blog post describes a small but useful SQL(ite) query optimization I came across between the first and final drafts of these features: using an uncorrelated scalar subquery to skip a correlated subquery (if you don't know what that means, I'll explain it below).</p>\n<p>Scour searches noisy sources for content related to users' interests. At the time of writing, it ingests between 1 and 3 million pieces of content from over 15,000 sources each month. For better and for worse, Scour does ranking on the fly, so the performance of the ranking database query directly translates to page load time.</p>\n<h2 id=\"the-ranking-sql-query\">The Ranking SQL Query</h2><p>The main SQL query Scour uses for ranking applies a number of filters and streams the item embeddings through the application code for scoring.</p>\n<p>Scour uses brute force search rather than a vector database, which works well enough for now because of three factors:</p>\n<ol>\n<li>Scour uses SQLite, so the data is colocated with the application code.</li>\n<li>It uses <a href=\"https://emschwartz.me/binary-vector-embeddings-are-so-cool/\">binary-quantized vector embeddings</a> with <a href=\"https://emschwartz.me/unnecessary-optimization-in-rust-hamming-distances-simd-and-auto-vectorization/\">Hamming Distance comparisons, which only take ~5 nanoseconds each</a>.</li>\n<li>We care most about recent posts so we can significantly narrow the search set by publish date.</li>\n</ol>\n<p>A simplified version of the query looks something like:</p>\n<div class=\"highlight\"><pre><span></span><span class=\"k\">SELECT</span><span class=\"w\"> </span><span class=\"o\">*</span>\n<span class=\"k\">FROM</span><span class=\"w\"> </span><span class=\"n\">items</span><span class=\"w\"> </span><span class=\"n\">i</span>\n<span class=\"k\">WHERE</span><span class=\"w\"> </span><span class=\"n\">i</span><span class=\"p\">.</span><span class=\"n\">lang</span><span class=\"w\"> </span><span class=\"k\">IN</span><span class=\"w\"> </span><span class=\"p\">(</span><span class=\"k\">SELECT</span><span class=\"w\"> </span><span class=\"n\">lang</span><span class=\"w\"> </span><span class=\"k\">FROM</span><span class=\"w\"> </span><span class=\"n\">user_languages</span><span class=\"w\"> </span><span class=\"k\">WHERE</span><span class=\"w\"> </span><span class=\"n\">user_id</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"o\">?</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n<span class=\"k\">AND</span><span class=\"w\"> </span><span class=\"n\">i</span><span class=\"p\">.</span><span class=\"n\">published</span><span class=\"w\"> </span><span class=\"k\">BETWEEN</span><span class=\"w\"> </span><span class=\"o\">?</span><span class=\"mi\">2</span><span class=\"w\"> </span><span class=\"k\">AND</span><span class=\"w\"> </span><span class=\"o\">?</span><span class=\"mi\">3</span>\n<span class=\"k\">AND</span><span class=\"w\"> </span><span class=\"p\">...(</span><span class=\"k\">more</span><span class=\"w\"> </span><span class=\"n\">filters</span><span class=\"p\">)...</span>\n</pre></div>\n<p>The query plan shows that this makes good use of indexes:</p>\n<div class=\"highlight\"><pre><span></span>QUERY PLAN\n   |--SEARCH i USING INDEX idx_items_lang_published (lang=? AND published&gt;? AND published&lt;?)\n   `--LIST SUBQUERY 1\n      `--SEARCH user_languages USING COVERING INDEX sqlite_autoindex_user_languages_1 (user_id=?)\n</pre></div>\n<h2 id=\"domain-filters-using-correlated-subqueries\">Domain Filters Using Correlated Subqueries</h2><p>To add user-specified domain blocklists, I created the <code>user_excluded_domains</code> table and added this filter clause to the main ranking query:</p>\n<div class=\"highlight\"><pre><span></span><span class=\"k\">AND</span><span class=\"w\"> </span><span class=\"k\">NOT</span><span class=\"w\"> </span><span class=\"k\">EXISTS</span><span class=\"w\"> </span><span class=\"p\">(</span>\n<span class=\"w\">    </span><span class=\"k\">SELECT</span><span class=\"w\"> </span><span class=\"mi\">1</span>\n<span class=\"w\">    </span><span class=\"k\">FROM</span><span class=\"w\"> </span><span class=\"n\">user_excluded_domains</span><span class=\"w\"> </span><span class=\"n\">ued</span>\n<span class=\"w\">    </span><span class=\"k\">WHERE</span><span class=\"w\"> </span><span class=\"n\">user_id</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"o\">?</span><span class=\"mi\">1</span>\n<span class=\"w\">    </span><span class=\"k\">AND</span><span class=\"w\"> </span><span class=\"n\">ued</span><span class=\"p\">.</span><span class=\"k\">domain</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">i</span><span class=\"p\">.</span><span class=\"k\">domain</span>\n<span class=\"p\">)</span>\n</pre></div>\n<p>The domain exclusion table uses <code>(user_id, domain)</code> as a primary key, so the lookup is efficient. However, this lookup is done for <em>every row</em> returned from the first part of the query. This is a <em>correlated subquery</em>:</p>\n<div class=\"highlight\"><pre><span></span>QUERY PLAN\n   |--SEARCH i USING INDEX idx_items_lang_published (lang=? AND published&gt;? AND published&lt;?)\n   |--LIST SUBQUERY 1\n   |  `--SEARCH user_languages USING COVERING INDEX sqlite_autoindex_user_languages_1 (user_id=?)\n   `--CORRELATED SCALAR SUBQUERY 2\n      `--SEARCH ued USING COVERING INDEX sqlite_autoindex_user_excluded_domains_1 (user_id=? AND domain=?)\n</pre></div>\n<h2 id=\"short-circuiting-correlated-subqueries\">Short-Circuiting Correlated Subqueries</h2><p>A problem with the way we just added this feature is that most users don't exclude any domains, but we've added a check that is run for every row anyway.</p>\n<p>To speed up the queries for users who aren't using the feature, we could first check the user's settings and then dynamically build the query. But we don't have to, because we can accomplish the same effect within one static query.</p>\n<p>We can change our domain exclusion filter to first check whether the user has <em>any</em> excluded domains:</p>\n<div class=\"highlight\"><pre><span></span><span class=\"k\">AND</span><span class=\"w\"> </span><span class=\"p\">(</span>\n<span class=\"w\">    </span><span class=\"k\">NOT</span><span class=\"w\"> </span><span class=\"k\">EXISTS</span><span class=\"w\"> </span><span class=\"p\">(</span>\n<span class=\"w\">        </span><span class=\"k\">SELECT</span><span class=\"w\"> </span><span class=\"mi\">1</span>\n<span class=\"w\">        </span><span class=\"k\">FROM</span><span class=\"w\"> </span><span class=\"n\">user_excluded_domains</span>\n<span class=\"w\">        </span><span class=\"k\">WHERE</span><span class=\"w\"> </span><span class=\"n\">user_id</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"o\">?</span><span class=\"mi\">1</span>\n<span class=\"w\">    </span><span class=\"p\">)</span>\n<span class=\"w\">    </span><span class=\"k\">OR</span><span class=\"w\"> </span><span class=\"k\">NOT</span><span class=\"w\"> </span><span class=\"k\">EXISTS</span><span class=\"w\"> </span><span class=\"p\">(</span>\n<span class=\"w\">           </span><span class=\"k\">SELECT</span><span class=\"w\"> </span><span class=\"mi\">1</span>\n<span class=\"w\">           </span><span class=\"k\">FROM</span><span class=\"w\"> </span><span class=\"n\">user_excluded_domains</span><span class=\"w\"> </span><span class=\"n\">ued</span>\n<span class=\"w\">           </span><span class=\"k\">WHERE</span><span class=\"w\"> </span><span class=\"n\">user_id</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"o\">?</span><span class=\"mi\">1</span>\n<span class=\"w\">           </span><span class=\"k\">AND</span><span class=\"w\"> </span><span class=\"n\">ued</span><span class=\"p\">.</span><span class=\"k\">domain</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">i</span><span class=\"p\">.</span><span class=\"k\">domain</span>\n<span class=\"w\">    </span><span class=\"p\">)</span>\n<span class=\"p\">)</span>\n</pre></div>\n<p>Since the <code>OR</code> short-circuits, if the first <code>NOT EXISTS</code> returns <code>true</code> (when the user has no excluded domains), SQLite never evaluates the correlated subquery at all.</p>\n<p>The first <code>NOT EXISTS</code> clause does not reference any column in <code>items</code>, so SQLite can evaluate it once and reuse the boolean result for all of the rows. This \"uncorrelated scalar subquery\" is extremely cheap to evaluate and, when it returns <code>true</code>, lets us short-circuit and skip the more expensive correlated subquery that checks each item's domain against the exclusion list.</p>\n<p>Here is the query plan for this updated query. Note how the second subquery says <code>SCALAR SUBQUERY</code>, whereas the third one is a <code>CORRELATED SCALAR SUBQUERY</code>. The latter is the per-row check, but it can be skipped by the second subquery.</p>\n<div class=\"highlight\"><pre><span></span>QUERY PLAN\n   |--SEARCH i USING INDEX idx_items_lang_published (lang=? AND published&gt;? AND published&lt;?)\n   |--LIST SUBQUERY 1\n   |  `--SEARCH user_languages USING COVERING INDEX sqlite_autoindex_user_languages_1 (user_id=?)\n   |--SCALAR SUBQUERY 2\n   |  `--SEARCH user_excluded_domains USING COVERING INDEX sqlite_autoindex_user_excluded_domains_1 (user_id=?)\n   `--CORRELATED SCALAR SUBQUERY 3\n      `--SEARCH ued USING COVERING INDEX sqlite_autoindex_user_excluded_domains_1 (user_id=? AND domain=?)\n</pre></div>\n<h2 id=\"benchmarking\">Benchmarking</h2><p>To test the performance of each of these queries, I replaced the <code>SELECT *</code> with <code>SELECT COUNT(*)</code> and used a simple bash script to invoke the <code>sqlite3</code> binary 100 times for each query on my laptop. Starting up the <code>sqlite3</code> process each time adds overhead, but we're comparing relative differences.</p>\n<p>At the time of this benchmark, the last week had 235,975 items, 144,229 of which were in English. The two example users I tested this for below only look for English content.</p>\n<h3 id=\"user-without-excluded-domains\">User Without Excluded Domains</h3><p>This test represents most users, who have not configured any excluded domains:</p>\n<table>\n<thead>\n<tr>\n  <th>Approach</th>\n  <th>Min (ms)</th>\n  <th>Max (ms)</th>\n  <th>Avg (ms)</th>\n  <th>Stddev (ms)</th>\n  <th>Diff (ms)</th>\n  <th>Diff (%)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n  <td>Baseline (no filter)</td>\n  <td>67</td>\n  <td>91</td>\n  <td><strong>72.7</strong></td>\n  <td>4.7</td>\n  <td>\u2014</td>\n  <td>\u2014</td>\n</tr>\n<tr>\n  <td>Correlated Subquery</td>\n  <td>80</td>\n  <td>108</td>\n  <td>85.2</td>\n  <td>5.5</td>\n  <td>+12.5</td>\n  <td>+17.1%</td>\n</tr>\n<tr>\n  <td>With Short-Circuit</td>\n  <td>69</td>\n  <td>91</td>\n  <td><strong>72.7</strong></td>\n  <td>3.8</td>\n  <td>+0</td>\n  <td><strong>+0%</strong></td>\n</tr>\n</tbody>\n</table>\n<p>This shows that the short-circuit query adds practically no overhead for users without excluded domains, whereas the correlated subquery alone makes queries 17% slower for these users.</p>\n<h3 id=\"user-with-excluded-domains\">User with Excluded Domains</h3><p>This test uses an example user that has excluded content from 2 domains:</p>\n<table>\n<thead>\n<tr>\n  <th>Approach</th>\n  <th>Min (ms)</th>\n  <th>Max (ms)</th>\n  <th>Avg (ms)</th>\n  <th>Stddev (ms)</th>\n  <th>Diff (ms)</th>\n  <th>Diff (%)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n  <td>Baseline (no filter)</td>\n  <td>68</td>\n  <td>99</td>\n  <td>76.2</td>\n  <td>7.6</td>\n  <td>\u2014</td>\n  <td>\u2014</td>\n</tr>\n<tr>\n  <td>Correlated Subquery</td>\n  <td>84</td>\n  <td>112</td>\n  <td><strong>90.5</strong></td>\n  <td>6.8</td>\n  <td>+14.3</td>\n  <td>+18.7%</td>\n</tr>\n<tr>\n  <td>With Short-Circuit</td>\n  <td>82</td>\n  <td>109</td>\n  <td><strong>88.5</strong></td>\n  <td>8.1</td>\n  <td>+12.3</td>\n  <td>+16.1%</td>\n</tr>\n</tbody>\n</table>\n<p>In this case, we do need to check each row against the domain filter. But this shows that the short-circuit still adds no overhead on top of the query.</p>\n<h2 id=\"conclusion\">Conclusion</h2><p>When using SQL subqueries to filter down result sets, it's worth thinking about whether each subquery is really needed for most users or most queries. If the check is needed most of the time, this approach won't help. However if the per-row check isn't always needed, using an uncorrelated scalar subquery to short-circuit a condition can dramatically speed up the average case with practically zero overhead.</p>\n<p>This is extra important because the slow-down from each additional subquery compounds. In this blog post, I described and benchmarked a single additional filter. But this is only one of multiple subquery filters.</p>\n<p>Earlier, I also mentioned that users had asked for a way to filter out paywalled content. This works similarly to filtering out content from excluded domains. Some users opt-in to hiding paywalled content. For those users, we check if each item is paywalled. If so, we check if it comes from a site the user has specifically allowed paywalled content from (because they have a subscription). I used the same uncorrelated subquery approach to first check if the feature is enabled for the user and, only then, does SQLite need to check each row.</p>\n<p>Concretely, the paywalled content filter subquery looks like:</p>\n<div class=\"highlight\"><pre><span></span><span class=\"k\">AND</span><span class=\"w\"> </span><span class=\"p\">(</span>\n<span class=\"w\">    </span><span class=\"p\">(</span>\n<span class=\"w\">        </span><span class=\"k\">SELECT</span><span class=\"w\"> </span><span class=\"k\">COALESCE</span><span class=\"p\">(</span><span class=\"n\">hide_paywalled_content</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"mi\">0</span><span class=\"p\">)</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"mi\">0</span>\n<span class=\"w\">        </span><span class=\"k\">FROM</span><span class=\"w\"> </span><span class=\"n\">users</span>\n<span class=\"w\">        </span><span class=\"k\">WHERE</span><span class=\"w\"> </span><span class=\"n\">user_id</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"o\">?</span><span class=\"mi\">1</span>\n<span class=\"w\">    </span><span class=\"p\">)</span><span class=\"w\"> </span><span class=\"c1\">-- note these parentheses are needed so SQLite doesn't mistakenly think this query is correlated with `items`</span>\n<span class=\"w\">    </span><span class=\"k\">OR</span><span class=\"w\"> </span><span class=\"k\">COALESCE</span><span class=\"p\">(</span><span class=\"n\">i</span><span class=\"p\">.</span><span class=\"n\">is_paywalled</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"mi\">0</span><span class=\"p\">)</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"mi\">0</span>\n<span class=\"w\">    </span><span class=\"k\">OR</span><span class=\"w\"> </span><span class=\"n\">i</span><span class=\"p\">.</span><span class=\"k\">domain</span><span class=\"w\"> </span><span class=\"k\">IN</span><span class=\"w\"> </span><span class=\"p\">(</span>\n<span class=\"w\">        </span><span class=\"k\">SELECT</span><span class=\"w\"> </span><span class=\"k\">domain</span>\n<span class=\"w\">        </span><span class=\"k\">FROM</span><span class=\"w\"> </span><span class=\"n\">user_paywall_allowed_domains</span>\n<span class=\"w\">        </span><span class=\"k\">WHERE</span><span class=\"w\"> </span><span class=\"n\">user_id</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"o\">?</span><span class=\"mi\">1</span>\n<span class=\"w\">    </span><span class=\"p\">)</span>\n<span class=\"p\">)</span>\n</pre></div>\n<p>In short, a trivial uncorrelated scalar subquery can help us short-circuit and avoid a more expensive per-row check when we don't need it.</p>\n<h2 id=\"appendix-codenot-existscode-vs-codenot-incode-vs-codeleft-joincode\">Appendix: <code>NOT EXISTS</code> vs <code>NOT IN</code> vs <code>LEFT JOIN</code></h2><p>There are multiple ways to exclude rows from an SQL query.</p>\n<p>Here are the results from the same benchmark I ran above, but with two other ways of checking for whether an item comes from an excluded domain.</p>\n<p>The <code>NULL-safe NOT IN</code> version of the query uses the subquery:</p>\n<div class=\"highlight\"><pre><span></span><span class=\"p\">...</span>\n<span class=\"k\">AND</span><span class=\"w\"> </span><span class=\"p\">(</span>\n<span class=\"w\">    </span><span class=\"n\">i</span><span class=\"p\">.</span><span class=\"k\">domain</span><span class=\"w\"> </span><span class=\"k\">IS</span><span class=\"w\"> </span><span class=\"k\">NULL</span>\n<span class=\"w\">    </span><span class=\"k\">OR</span><span class=\"w\"> </span><span class=\"n\">i</span><span class=\"p\">.</span><span class=\"k\">domain</span><span class=\"w\"> </span><span class=\"k\">NOT</span><span class=\"w\"> </span><span class=\"k\">IN</span><span class=\"w\"> </span><span class=\"p\">(</span>\n<span class=\"w\">        </span><span class=\"k\">SELECT</span><span class=\"w\"> </span><span class=\"k\">domain</span>\n<span class=\"w\">        </span><span class=\"k\">FROM</span><span class=\"w\"> </span><span class=\"n\">user_excluded_domains</span>\n<span class=\"w\">        </span><span class=\"k\">WHERE</span><span class=\"w\"> </span><span class=\"n\">user_id</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"o\">?</span><span class=\"mi\">1</span>\n<span class=\"w\">    </span><span class=\"p\">)</span>\n<span class=\"p\">)</span>\n</pre></div>\n<p>The <code>LEFT JOIN</code> variation joins <code>items</code> with <code>user_excluded_domains</code> and then checks for <code>NULL</code>:</p>\n<div class=\"highlight\"><pre><span></span><span class=\"k\">SELECT</span><span class=\"w\"> </span><span class=\"o\">*</span>\n<span class=\"k\">FROM</span><span class=\"w\"> </span><span class=\"n\">items</span><span class=\"w\"> </span><span class=\"n\">i</span>\n<span class=\"k\">LEFT</span><span class=\"w\"> </span><span class=\"k\">JOIN</span><span class=\"w\"> </span><span class=\"n\">user_excluded_domains</span><span class=\"w\"> </span><span class=\"n\">ued</span><span class=\"w\"> </span><span class=\"k\">on</span><span class=\"w\"> </span><span class=\"n\">ued</span><span class=\"p\">.</span><span class=\"n\">user_id</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"o\">?</span><span class=\"mi\">1</span><span class=\"w\"> </span><span class=\"k\">AND</span><span class=\"w\"> </span><span class=\"n\">ued</span><span class=\"p\">.</span><span class=\"k\">domain</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">i</span><span class=\"p\">.</span><span class=\"k\">domain</span>\n<span class=\"k\">WHERE</span><span class=\"w\"> </span><span class=\"n\">i</span><span class=\"p\">.</span><span class=\"n\">lang</span><span class=\"w\"> </span><span class=\"k\">IN</span><span class=\"w\"> </span><span class=\"p\">(</span><span class=\"k\">SELECT</span><span class=\"w\"> </span><span class=\"n\">lang</span><span class=\"w\"> </span><span class=\"k\">FROM</span><span class=\"w\"> </span><span class=\"n\">user_languages</span><span class=\"w\"> </span><span class=\"k\">WHERE</span><span class=\"w\"> </span><span class=\"n\">user_id</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"o\">?</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n<span class=\"k\">AND</span><span class=\"w\"> </span><span class=\"n\">i</span><span class=\"p\">.</span><span class=\"n\">published</span><span class=\"w\"> </span><span class=\"k\">BETWEEN</span><span class=\"w\"> </span><span class=\"o\">?</span><span class=\"mi\">2</span><span class=\"w\"> </span><span class=\"k\">AND</span><span class=\"w\"> </span><span class=\"o\">?</span><span class=\"mi\">3</span>\n<span class=\"k\">AND</span><span class=\"w\"> </span><span class=\"n\">ued</span><span class=\"p\">.</span><span class=\"k\">domain</span><span class=\"w\"> </span><span class=\"k\">IS</span><span class=\"w\"> </span><span class=\"k\">NULL</span>\n</pre></div>\n<p>And here are the full benchmarks:</p>\n<h3 id=\"user-without-excluded-domains\">User Without Excluded Domains</h3><table>\n<thead>\n<tr>\n  <th>Approach</th>\n  <th>Min (ms)</th>\n  <th>Max (ms)</th>\n  <th>Avg (ms)</th>\n  <th>Stddev (ms)</th>\n  <th>Diff (ms)</th>\n  <th>Diff (%)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n  <td>Baseline (no filter)</td>\n  <td>67</td>\n  <td>91</td>\n  <td>72.7</td>\n  <td>4.7</td>\n  <td>\u2014</td>\n  <td>\u2014</td>\n</tr>\n<tr>\n  <td>NOT EXISTS (no short-circuit)</td>\n  <td>80</td>\n  <td>108</td>\n  <td>85.2</td>\n  <td>5.5</td>\n  <td>+12.5</td>\n  <td>+17.1%</td>\n</tr>\n<tr>\n  <td><strong>NOT EXISTS + short-circuit</strong></td>\n  <td><strong>69</strong></td>\n  <td><strong>91</strong></td>\n  <td><strong>72.7</strong></td>\n  <td><strong>3.8</strong></td>\n  <td><strong>+0</strong></td>\n  <td><strong>+0%</strong></td>\n</tr>\n<tr>\n  <td>NULL-safe NOT IN (no short-circuit)</td>\n  <td>75</td>\n  <td>111</td>\n  <td>79.5</td>\n  <td>7.1</td>\n  <td>+6.8</td>\n  <td>+9.3%</td>\n</tr>\n<tr>\n  <td>NULL-safe NOT IN + short-circuit</td>\n  <td>69</td>\n  <td>103</td>\n  <td>74.8</td>\n  <td>6.6</td>\n  <td>+2.1</td>\n  <td>+2.8%</td>\n</tr>\n<tr>\n  <td>LEFT JOIN (no short-circuit)</td>\n  <td>74</td>\n  <td>100</td>\n  <td>79.1</td>\n  <td>5.1</td>\n  <td>+6.4</td>\n  <td>+8.8%</td>\n</tr>\n<tr>\n  <td>LEFT JOIN + short-circuit</td>\n  <td>76</td>\n  <td>103</td>\n  <td>84.4</td>\n  <td>7.4</td>\n  <td>+11.7</td>\n  <td>+16.0%</td>\n</tr>\n</tbody>\n</table>\n<p>For users without excluded domains, we can see that the <code>NOT EXISTS</code> query using the short-circuit wins and adds no overhead.</p>\n<h3 id=\"user-with-excluded-domains\">User With Excluded Domains</h3><table>\n<thead>\n<tr>\n  <th>Approach</th>\n  <th>Min (ms)</th>\n  <th>Max (ms)</th>\n  <th>Avg (ms)</th>\n  <th>Stddev (ms)</th>\n  <th>Diff (ms)</th>\n  <th>Diff (%)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n  <td>Baseline (no filter)</td>\n  <td>68</td>\n  <td>99</td>\n  <td>76.2</td>\n  <td>7.6</td>\n  <td>\u2014</td>\n  <td>\u2014</td>\n</tr>\n<tr>\n  <td>NOT EXISTS (no short-circuit)</td>\n  <td>84</td>\n  <td>112</td>\n  <td>90.5</td>\n  <td>6.8</td>\n  <td>+14.3</td>\n  <td>+18.7%</td>\n</tr>\n<tr>\n  <td><strong>NOT EXISTS + short-circuit</strong></td>\n  <td><strong>82</strong></td>\n  <td><strong>109</strong></td>\n  <td><strong>88.5</strong></td>\n  <td><strong>8.1</strong></td>\n  <td><strong>+12.3</strong></td>\n  <td><strong>+16.1%</strong></td>\n</tr>\n<tr>\n  <td>NULL-safe NOT IN (no short-circuit)</td>\n  <td>83</td>\n  <td>112</td>\n  <td>89.7</td>\n  <td>8.4</td>\n  <td>+13.5</td>\n  <td>+17.7%</td>\n</tr>\n<tr>\n  <td>NULL-safe NOT IN + short-circuit</td>\n  <td>84</td>\n  <td>112</td>\n  <td>91.3</td>\n  <td>8.2</td>\n  <td>+15.1</td>\n  <td>+19.8%</td>\n</tr>\n<tr>\n  <td><strong>LEFT JOIN (no short-circuit)</strong></td>\n  <td><strong>81</strong></td>\n  <td><strong>107</strong></td>\n  <td><strong>86.3</strong></td>\n  <td><strong>6.7</strong></td>\n  <td><strong>+10.1</strong></td>\n  <td><strong>+13.2%</strong></td>\n</tr>\n<tr>\n  <td>LEFT JOIN + short-circuit</td>\n  <td>82</td>\n  <td>126</td>\n  <td>89.8</td>\n  <td>7.7</td>\n  <td>+13.6</td>\n  <td>+17.8%</td>\n</tr>\n</tbody>\n</table>\n<p>For users who do have excluded domains, the <code>LEFT JOIN</code> is faster than the <code>NOT EXISTS</code> version. However, this version raises the exact problem this whole blog post is designed to address. Since joins happen no matter what, we cannot use the short-circuit to avoid the overhead for users without excluded domains. At least for now, this is why I've gone with the <code>NOT EXISTS</code> subquery using the short-circuit.</p>\n<hr />\n<p>Discuss on <a href=\"https://news.ycombinator.com/item?id=46300776\">Hacker News</a>, <a href=\"https://lobste.rs/s/lfd78r/short_circuiting_correlated_subqueries\">Lobsters</a>, <a href=\"https://www.reddit.com/r/programming/comments/1pou7p8/shortcircuiting_correlated_subqueries_in_sqlite/\">r/programming</a>, <a href=\"https://www.reddit.com/r/sqlite/comments/1pou80l/shortcircuiting_correlated_subqueries_in_sqlite/\">r/sqlite</a>.</p>\n<hr />"
            ],
            "link": "https://emschwartz.me/short-circuiting-correlated-subqueries-in-sqlite/",
            "publishedAt": "2025-12-17",
            "source": "Evan Schwartz",
            "summary": "<p>I recently added domain exclusion lists and paywalled content filtering to <a href=\"https://scour.ing\">Scour</a>. This blog post describes a small but useful SQL(ite) query optimization I came across between the first and final drafts of these features: using an uncorrelated scalar subquery to skip a correlated subquery (if you don't know what that means, I'll explain it below).</p> <p>Scour searches noisy sources for content related to users' interests. At the time of writing, it ingests between 1 and 3 million pieces of content from over 15,000 sources each month. For better and for worse, Scour does ranking on the fly, so the performance of the ranking database query directly translates to page load time.</p> <h2 id=\"the-ranking-sql-query\">The Ranking SQL Query</h2><p>The main SQL query Scour uses for ranking applies a number of filters and streams the item embeddings through the application code for scoring.</p> <p>Scour uses brute force search rather than a vector database, which works well enough for now because of three factors:</p> <ol> <li>Scour uses SQLite, so the data is colocated with the application code.</li> <li>It uses <a href=\"https://emschwartz.me/binary-vector-embeddings-are-so-cool/\">binary-quantized vector embeddings</a> with <a href=\"https://emschwartz.me/unnecessary-optimization-in-rust-hamming-distances-simd-and-auto-vectorization/\">Hamming Distance comparisons, which only take ~5 nanoseconds each</a>.</li> <li>We care most about recent posts so we can",
            "title": "Short-Circuiting Correlated Subqueries in SQLite"
        },
        {
            "content": [],
            "link": "https://harper.blog/notes/2025-12-16_c664c7d43dda_going-through-a-lil-cyberdeck-/",
            "publishedAt": "2025-12-17",
            "source": "Harper Reed",
            "summary": "<p>Going through a lil cyberdeck era</p> <figure> <img alt=\"image_1.jpg\" height=\"1350\" src=\"https://harper.blog/notes/2025-12-16_c664c7d43dda_going-through-a-lil-cyberdeck-/image_1.jpg\" width=\"1800\" /> </figure> <hr /> <p>Thank you for using RSS. I appreciate you. <a href=\"mailto:harper&#64;modest.com\">Email me</a></p>",
            "title": "Note #306"
        },
        {
            "content": [
                "<p>I've heard from a number of folks that they're seeing Claude Code just...not use skills they have installed.</p>\n<p>The way Claude knows about skills is that it builds a big list of skill names and descriptions and injects it into in the system prompt.</p>\n<p><a class=\"glightbox\" href=\"https://blog.fsck.com/assets/2025/12/pasted-image-20251217-144948.png\"><img alt=\"pasted image 20251217 144948\" src=\"https://blog.fsck.com/assets/2025/12/pasted-image-20251217-144948.png\" /></a></p>\n<p>The problems start when you've got too many skills or their <code>description</code> fields are too long.  Then, the system prompt doesn't tell Claude about them. And if it doesn't know about them...it can't use them.</p>\n<p>To add insult to injury, the system prompt tells Claude never to use skills that aren't listed.</p>\n<p><a class=\"glightbox\" href=\"https://blog.fsck.com/assets/2025/12/pasted-image-20251217-145126.png\"><img alt=\"pasted image 20251217 145126\" src=\"https://blog.fsck.com/assets/2025/12/pasted-image-20251217-145126.png\" /></a></p>\n<p>As of Claude Code 2.0.70, the limit for skill and command descriptions defaults to 15,000 characters (or around 4000 tokens).  If you're not making heavy use of skills, that ought to be fine. But, since there's no warning when you go over, you might find yourself with unusable skills.</p>\n<p>For now, the best workaround is to set an environment variable:</p>\n<p><code>SLASH_COMMAND_TOOL_CHAR_BUDGET=30000 claude</code> will give you double the headroom for skill descriptions.</p>\n<p>I've been working on making Superpowers a little bit more system-prompt token efficient. Superpowers 4.0, which should ship &quot;soon&quot;, combines a number of infrequently used skills and rewrites a number of skill descriptions to be a bit shorter. But more on that soon.</p>"
            ],
            "link": "https://blog.fsck.com/2025/12/17/claude-code-skills-not-triggering/",
            "publishedAt": "2025-12-17",
            "source": "Jesse Vincent",
            "summary": "<p>I've heard from a number of folks that they're seeing Claude Code just...not use skills they have installed.</p> <p>The way Claude knows about skills is that it builds a big list of skill names and descriptions and injects it into in the system prompt.</p> <p><a class=\"glightbox\" href=\"https://blog.fsck.com/assets/2025/12/pasted-image-20251217-144948.png\"><img alt=\"pasted image 20251217 144948\" src=\"https://blog.fsck.com/assets/2025/12/pasted-image-20251217-144948.png\" /></a></p> <p>The problems start when you've got too many skills or their <code>description</code> fields are too long. Then, the system prompt doesn't tell Claude about them. And if it doesn't know about them...it can't use them.</p> <p>To add insult to injury, the system prompt tells Claude never to use skills that aren't listed.</p> <p><a class=\"glightbox\" href=\"https://blog.fsck.com/assets/2025/12/pasted-image-20251217-145126.png\"><img alt=\"pasted image 20251217 145126\" src=\"https://blog.fsck.com/assets/2025/12/pasted-image-20251217-145126.png\" /></a></p> <p>As of Claude Code 2.0.70, the limit for skill and command descriptions defaults to 15,000 characters (or around 4000 tokens). If you're not making heavy use of skills, that ought to be fine. But, since there's no warning when you go over, you might find yourself with unusable skills.</p> <p>For now, the best workaround is to set an environment variable:</p> <p><code>SLASH_COMMAND_TOOL_CHAR_BUDGET=30000 claude</code> will give you double the headroom for skill descriptions.</p> <p>I've been working on making Superpowers a little bit more system-prompt token efficient. Superpowers 4.0,",
            "title": "Claude Code skills not triggering? It might not see them."
        },
        {
            "content": [],
            "link": "https://www.nytimes.com/2025/12/17/style/tiny-modern-love-stories-good-riddance-christmas.html",
            "publishedAt": "2025-12-17",
            "source": "Modern Love - NYT",
            "summary": "Modern Love in miniature, featuring reader-submitted stories of no more than 100 words.",
            "title": "Tiny Love Stories: \u2018Good Riddance, Christmas\u2019"
        },
        {
            "content": [],
            "link": "https://simonwillison.net/2025/Dec/17/gemini-3-flash/#atom-entries",
            "publishedAt": "2025-12-17",
            "source": "Simon Willison",
            "summary": "<p>It continues to be a busy December, if not quite as busy <a href=\"https://simonwillison.net/2024/Dec/20/december-in-llms-has-been-a-lot/\">as last year</a>. Today's big news is <a href=\"https://blog.google/technology/developers/build-with-gemini-3-flash/\">Gemini 3 Flash</a>, the latest in Google's \"Flash\" line of faster and less expensive models.</p> <p>Google are emphasizing the comparison between the new Flash and their previous generation's top model Gemini 2.5 Pro:</p> <blockquote> <p>Building on 3 Pro\u2019s strong multimodal, coding and agentic features, 3 Flash offers powerful performance at less than a quarter the cost of 3 Pro, along with higher rate limits. The new 3 Flash model surpasses 2.5 Pro across many benchmarks while delivering faster speeds.</p> </blockquote> <p>Gemini 3 Flash's characteristics are almost identical to Gemini 3 Pro: it accepts text, image, video, audio, and PDF, outputs only text, handles 1,048,576 maximum input tokens and up to 65,536 output tokens, and has the same knowledge cut-off date of January 2025 (also shared with the Gemini 2.5 series).</p> <p>The benchmarks look good. The cost is appealing: 1/4 the price of Gemini 3 Pro \u2264200k and 1/8 the price of Gemini 3 Pro &gt;200k, and it's nice not to have a price increase for the new Flash at larger token lengths.</p> <p>It's a little <em>more</em> expensive than previous",
            "title": "Gemini 3 Flash"
        },
        {
            "content": [
                "<p>This holiday season, you&#8217;ll see many charity fundraisers. I&#8217;ve already mentioned three, and I have another lined up for next week&#8217;s open thread. Many great organizations ask me to signal-boost them, I&#8217;m happy to comply, and I&#8217;m delighted when any of you donate.</p><p>Still, I used to hate this sort of thing. I&#8217;d be reading a blog I liked, then - wham, &#8220;please donate to save the starving children&#8221;. Now I either have to donate to starving children, or feel bad that I didn&#8217;t. And if I do donate, how much? Obviously no amount would fully reflect the seriousness of the problem. When I was a poor college student, I usually gave $10, because it was a nice round number; when I had more money, I usually gave $50, for the same reason. But then the next week, a different blog would advertise &#8220;please donate to save the starving children with cancer&#8221;, and I&#8217;d feel like a shmuck for wasting my donation on non-cancerous starving children. Do I donate another $10, bringing my total up to the non-round number of $20? If I had a spare $20 for altruistic purposes, why hadn&#8217;t I donated that the first time? It was all so unpleasant, and no matter what I did, I would feel all three of stingy <em>and</em> gullible <em>and</em> irrational.</p><p>This is why I was so excited ten-odd years ago when I discovered the <strong><a href=\"https://www.givingwhatwecan.org/pledge\">Giving What We Can Pledge</a></strong>. It&#8217;s a commitment to give a certain percent of your income (originally 10%, but now there&#8217;s also <a href=\"https://www.givingwhatwecan.org/get-involved/trial-pledge\">a 1-10% &#8220;trial&#8221; pledge</a>) to the most effective charity you know. If you can&#8217;t figure out which charity is most effective, you can just donate to <a href=\"https://www.againstmalaria.com/\">Against Malaria Foundation</a>, like all the other indecisive people.</p><p>It&#8217;s not that 10% is obviously the correct number in some deep sense. The people who picked it, picked it because it was big enough to matter, but not so big that nobody would do it. But having been picked, it&#8217;s become a Schelling point. Take it, and you&#8217;re one of the 10,000 people who&#8217;s made this impressive commitment. If someone asks why you&#8217;re not giving more, you can say &#8220;That would dilute the value of the Schelling point we&#8217;ve all agreed on and make it harder for other people to cooperate with us&#8221;. </p><p>The specific numbers and charities matter less than the way the pledge makes you think about your values and then yoke your behavior to them. In theory we&#8217;re supposed to do this all the time. Another holiday institution, New Year&#8217;s Resolutions, also centers around considering your values and yoking your behavior. But they famously don&#8217;t work: most people don&#8217;t have the willpower to go to the gym three times a week, or to volunteer at their local animal shelter on Sundays, or whatever else they decide on. That&#8217;s why GWWC Pledge is so powerful. No willpower involved. Just go to your online banking portal, click click click, and you&#8217;re done. Over my life, I don&#8217;t know if I would say I&#8217;ve ever really changed my character or willpower or overall goodness/badness balance by more than a few percent. But I changed the amount I donated by a factor of ~ten, forever, with one very good decision. </p><p>Unless you&#8217;re a genius or a saint, your money is the strongest tool you have to change the world. 10% of an ordinary First World income donated to AMF saves dozens of lives over a career; even if you&#8217;re a policeman or firefighter, you&#8217;ll have trouble matching that through non-financial means. Unless you&#8217;re Charlie Kirk or Heather Cox Richardson, no amount of your political activism or voting - let alone arguing on the Internet - will match the effect of donating to a politician or a cause you care about. And no amount of carpooling and eating vegan <a href=\"https://www.astralcodexten.com/p/carbon-costs-quantified\">will help the climate</a> as much as donating to carbon capture charities.</p><p>Not an effective altruist? Think it&#8217;s better to contribute to your local community, school, theater, or church? I&#8217;ll argue with you later - but for now, my advice is the same.  Have you thought really hard about how you should be contributing to your local community, school, theater, or church? (The fundraising letters my family used to get from our synagogue left little doubt about what form of contribution they preferred). Have you pledged some specific amount? You won&#8217;t give beyond the $10-when-you-see-a-blog-fundraiser level unless you take a real pledge, registered by someone besides yourself - trust me, I&#8217;ve tested this. The GWWC website is mostly pitched at EAs. But if you like churches so much, you can probably get the same effect by pledging to God - <a href=\"https://www.poetryfoundation.org/poems/44433/abou-ben-adhem\">and He keeps His own list, and offers His own member perks</a>.</p><p>To the degree that you care about changing the world beyond yourself and your family, in any direction, then the odds are good that this one decision - whether or not to take a binding charitable Pledge - matters more than every other decision you&#8217;ll ever make combined. Maybe an order of magnitude more. It&#8217;s something you can do right now, in five minutes. You shouldn&#8217;t do it in five minutes; you should sit down and think about it hard and talk it over with your loved ones and make sure you&#8217;re really planning to keep whatever pledge you make. But you could. And then every time you saw a charity fundraiser on a blog, you could think &#8220;Oh, sorry, I&#8217;m already living my life in accordance with my altruistic values, no thanks!&#8221; You wouldn&#8217;t even have to worry about how much to donate. I don&#8217;t even donate to half the fundraisers that I signal-boost!</p><p>So if you have time this holiday season, and you&#8217;re financially secure enough that it won&#8217;t be a burden, think about whether there&#8217;s some way you want the world to be different and better, whether there are charities that work on it, and whether you want to donate. Then, take <a href=\"https://www.givingwhatwecan.org/\">the pledge</a>. </p><p>If you decide you want to do something but it&#8217;s too stressful to figure out what, take <a href=\"https://www.givingwhatwecan.org/get-involved/trial-pledge\">a 3% trial pledge here</a>, give it to Against Malaria Foundation, and come back next year to see if you&#8217;re ready for the 10% version.</p><p><em><strong>UPDATE:</strong> Bentham&#8217;s Bulldog also thinks you should take the pledge - <a href=\"https://benthams.substack.com/p/a-life-that-cannot-be-a-failure\">here&#8217;s his post</a>. And I&#8217;ll match his offer - take the full 10% pledge this month, and comment below so that I know about it, and I&#8217;ll give you a free lifetime subscription to ACX.</em></p>"
            ],
            "link": "https://www.astralcodexten.com/p/the-pledge",
            "publishedAt": "2025-12-17",
            "source": "SlateStarCodex",
            "summary": "<p>This holiday season, you&#8217;ll see many charity fundraisers. I&#8217;ve already mentioned three, and I have another lined up for next week&#8217;s open thread. Many great organizations ask me to signal-boost them, I&#8217;m happy to comply, and I&#8217;m delighted when any of you donate.</p><p>Still, I used to hate this sort of thing. I&#8217;d be reading a blog I liked, then - wham, &#8220;please donate to save the starving children&#8221;. Now I either have to donate to starving children, or feel bad that I didn&#8217;t. And if I do donate, how much? Obviously no amount would fully reflect the seriousness of the problem. When I was a poor college student, I usually gave $10, because it was a nice round number; when I had more money, I usually gave $50, for the same reason. But then the next week, a different blog would advertise &#8220;please donate to save the starving children with cancer&#8221;, and I&#8217;d feel like a shmuck for wasting my donation on non-cancerous starving children. Do I donate another $10, bringing my total up to the non-round number of $20? If I had a spare $20 for altruistic purposes, why hadn&#8217;t I donated that the first time? It was all",
            "title": "The Pledge"
        },
        {
            "content": [
                "<p>In <a href=\"https://thezvi.substack.com/p/the-140000-question\"><strong>The $140,000 Question</strong></a>, I went over recent viral claims about poverty in America.</p>\n<p>The calculations behind the claims were invalid, the central claim (that the \u2018true poverty line\u2019 was $140k) was absurd, but the terrible vibes are real. People increasingly feel that financial life is getting harder and that success is out of reach.</p>\n<p>\u2018Real income\u2019 is rising, but costs are rising even more.</p>\n<p>Before we get to my central explanations for that &#8211; the Revolution of Rising Expectations and the Revolution of Rising Requirements &#8211; there are calculations and histories to explore, which is what this second post is about.</p>\n<div>\n\n\n<span id=\"more-24959\"></span>\n\n\n</div>\n<p>How are costs changing in America, both in absolute terms and compared to real incomes, for key items: Consumer goods, education, health care and housing?</p>\n<p>That\u2019s a huge percentage of where we spend our post-tax money.</p>\n<p>And how is household wealth actually changing?</p>\n<p>The economists are right that the basket of goods and services we typically purchase in these areas has greatly increased in both quantity and quality, in spite of various severe supply side problems mostly caused by regulations.</p>\n<p>That is not what determines whether a person or family can pay their bills.</p>\n\n\n<h4 class=\"wp-block-heading\">The Debate Continues</h4>\n\n\n<p>People keep saying and feeling that the cost of living is going up and things are getting harder. Economists keep saying no, look at the data, you are buying better goods, so you are wrong.</p>\n<p>Both things can be true at once. It also means people talk past each other a lot.</p>\n<p>There was an iteration on this back in May, when<a href=\"https://x.com/curtis_yarvin/status/1921526333739319458\"> Curtis Yarvin declared a disingenuous \u2018beef\u2019 with Scott Alexander</a> on such questions. A good example of the resulting rhetoric was<a href=\"https://x.com/micsolana/status/1922006671540228521\"> this exchange</a> between Scott Alexander and Mike Solana.</p>\n<blockquote><p><a href=\"https://x.com/micsolana/status/1922006671540228521\">Mike Solana</a>: guy will say \u201cthings are harder now than they were, harder than they have ever been, I don\u2019t know how to make my life work in this new american economy\u201d and an intellectual will show him a graph that indicates \u201cmedian wages have increased 30% since the turn of the century.\u201d</p>\n<p>Guy will say the cost of a house has more than doubled. He\u2019ll say he can\u2019t afford his home town anymore. The intellectual will make a macro argument with another chart. it will seem smart.</p>\n<p>Guy will still be miserable, his life will still be hard. And he will vote.</p></blockquote>\n<p>As with the $140,000 question, many of the specific cost claims of the various Guys here will be wrong, but their life will be hard, and they will be unhappy. And vote.</p>\n<p>Evaluating and often refuting specific claims is a necessary background step. So that\u2019s what this post is here to do. On its own, it\u2019s a distraction, but you need to do it first.</p>\n\n\n<h4 class=\"wp-block-heading\">The Cost of Thriving Index Redux</h4>\n\n\n<p>Two years ago I covered the debate around Cass\u2019s<a href=\"https://thezvi.substack.com/p/on-the-cost-of-thriving-index?utm_source=publication-search\"> <strong>Cost of Thriving Index</strong></a>, and the debate over whether the true \u2018cost of thriving\u2019 was going up or down.</p>\n<p>The Cost of Thriving Index is an attempt to assemble the basket of goods required for \u2018thriving\u2019 in each era and then compare combined costs as a function of what a single man can hope to earn, without regard to the rising quality of the basket over time.</p>\n<p>The post covered the technical arguments in each area between Winship and Cass. Cass argued that thriving had gotten a lot harder. Winship argued against this.</p>\n<p>My conclusion was:</p>\n<ol>\n<li>Cass\u2019s calculations were importantly flawed. My \u2018improved COTI\u2019 shows a basic basket was ~13% harder for a typical person to afford in 2023 than it was in 1985.</li>\n<li>Critics of the index, especially Winship, misunderstood the point of the exercise and in many places<a href=\"https://x.com/ESYudkowsky/status/1613622386150211584?lang=en\"> trying to solve the wrong problem using the wrong methods based on a wrong model of the world</a> derived from poor thinking. Unfortunately all their mistakes failed to cancel out.</li>\n<li>You had to consume goods that cost ~75% more \u2018real income\u2019 in order to thrive in 2023 than you did in 1985. \u2018Real income\u2019 went up 53%. Are you better off in 2023 or in 1985? It is not obvious. One effect does not negate the other.</li>\n</ol>\n<p>This calculation left out at least one very important similar consideration in particular that neither side considered: The time and money costs of not<a href=\"https://thezvi.substack.com/p/letting-kids-be-kids\"> letting kids be kids</a>, and the resulting need to watch them like a hawk at all times, requiring vastly more childcare. You can buy that, or you can pay with your time. Either way, you pay up.</p>\n<p>The two sides continue to talk past each other. Before we can do a synthesis, we need to cover the actual cost details.</p>\n\n\n<h4 class=\"wp-block-heading\">The Housing Theory Of Everything Remains Undefeated</h4>\n\n\n<p>I don\u2019t quite fully buy the Housing Theory of Everything.</p>\n<p>But is close.</p>\n<p>House prices have risen quite a lot, as have interest rates. So did incomes.</p>\n<p>If you\u2019re okay living where people don\u2019t typically want to live, then things aren\u2019t bad.</p>\n<p>However, people are less accepting of that, which is part of the Revolution of Rising Expectations, and opportunity has concentrated in the expensive locations.</p>\n<blockquote><p><a href=\"https://x.com/Noahpinion/status/1990835988193751233\">Noah Smith</a>: In terms of wages, income, and wealth, Gen Z and Millennials are doing much better than previous generations. Corporate America is not failing the youth.</p>\n<p>It\u2019s only housing that\u2019s really broken.</p>\n<p><a href=\"https://x.com/CharlesFLehman/status/1991139243352109495\">Charles Fain Lehman</a>: Americans are unhappy because housing is illegal.</p>\n<p>Zac Hill: &lt;Drake meme&gt; illegal aliens -&gt; illegal housing.</p></blockquote>\n<p>I would instead say, if housing was legal, there would be a lot less unhappiness.</p>\n<p>More precisely: If building housing was generally legal, including things like SROs and also massively more capacity in general in the places people want to live, then housing costs would be a lot lower, people would have vastly more <a href=\"https://thezvi.substack.com/p/slack\">Slack</a>, and the whole thing would seem far more solvable.</p>\n<p>If you look at median home prices, things actually look like they\u2019ve always been pretty terrible, as in this is a share of 200% of median income:</p>\n<blockquote><p><a href=\"https://x.com/RyanRadia/status/1988467411058561025\">Ryan Radia</a>:</p></blockquote>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!sYm3!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5e47538a-7a44-4d58-9e61-f12c92a118db_680x639.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>The median household, with a median income and no outside help, does not by default buy the median house at today\u2019s interest rate. Houses are largely bought with wealth, or owned or acquired in other ways, so by default if you\u2019re relying purely on a median income you\u2019re getting a lot less than the median house. Which is totally fine, the median house is historically huge, you can notch down a bit. Also, when rates go down we refinance and when they go up we delay moving, which lowers costs.</p>\n<p>But if we suppose you\u2019re a median income earner trying to buy the median house today. If you believe the above graph, it\u2019s going to cost you 70% of your income to make a mortgage payment, plus you\u2019ll need a down payment, so yeah, that\u2019s not going to happen. But that number hasn\u2019t been under 50% in fifty years, so people have long had to find another way and make compromises.</p>\n<p>The graph does seem like it has to be understating the jump in recent years, with the jump in mortgage rates, and here\u2019s the Burns Affordability Index, which divides the median monthly housing cost (all-in including insurance) for a 10% down, 30-year-fixed mortgage at current rates versus 125% of the median income (seriously, guys, 100%, use 100% and we can adjust for dual incomes):</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!GayK!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7bcef44a-6a0c-4fb8-8d89-53e530006eb1_900x675.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>I\u2019m willing to believe that this jump happened, and that some of it is permanent, because interest rates were at historic lows for a long time and we\u2019re probably not going to see that again for a while even if AI fizzles.</p>\n<p>That 42% buys a lot more house than the 33% did in 1986. Compared to the early 1970s (so when interest rates hadn\u2019t shot up yet)<a href=\"https://galepooley.substack.com/p/housing-abundance\"> Gale Pooley says a given percentage</a> of household income (counting the shift to two incomes, mind) gets you 73% more house, average size went from 1,634 square feet to 2,614, per person it went from 534 to 1,041, many amenities are much more common (AC, Garage, 4+ bedrooms, etc) and actual housing costs haven\u2019t risen much as a percentage of income.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!0fKu!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5b2fe7dd-5e6e-420e-852b-bdd87df705ad_1109x1034.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>That doesn\u2019t make the new house you need any easier to pay for. More people are working and paying a higher percentage of income in order to pay for that house, again especially in the places with futures (which also are the sources of media).</p>\n<p>Things will look worse if you look at the major cities, where there is the most opportunity, and where people actually want to live. This is NIMBY, it is quite bad, and we need to fix it.</p>\n<p>That includes increasing unwillingness to live far away from work, and endure what is frankly a rather terrible commute, Tristan\u2019s here is relatively light.</p>\n<blockquote><p><a href=\"https://x.com/cunha_tristan/status/1988596187742548023\">Tristan Cunha:</a> When I got out of college 20 years ago I applied to jobs online, found an apartment online, got a car loan online, etc. So I remember searching and comparing the price of everything.</p>\n<p>When people complain about how tough things are now I search and can find the rent for an apartment in the building I lived in, or every level jobs at the first company I worked at, etc. and it doesn\u2019t seem that expensive to me. Sure the nominal prices have gone up, but the rent as a percentage of every level salary is about the same.</p>\n<p>I think the big difference is when I tell young adults now that I had a 30-60 minute commute in to the city on the train, and had a roommate in a tiny apartment in the suburbs, they think that\u2019s a huge sacrifice.</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">Did We Halt the Rise in Healthcare and Education Costs?</h4>\n\n\n<p>For a while a lot of the story of things getting harder was that healthcare and education costs were rising rapidly, far faster than incomes.</p>\n<p>Did we turn this around?<a href=\"https://www.noahpinion.blog/p/service-costs-arent-exploding-anymore\"> Noah Smith strongly asserted during the last iteration of the argument that this is solved</a>, the same way the data says that real wages are now accelerating.</p>\n<p>He starts off with the famous Mark Perry price changes chart.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!01YO!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F72d06331-889c-4844-ae89-92fbe0d14e3a_900x785.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<blockquote><p>Noah Smith: And the story was compelling because it came with a simple theory to explain it. This was the notion that <em>manufacturing productivity naturally increases faster than service productivity</em>. Conceptually, it seems easier to figure out how to rearrange production processes in a factory, and apply new machine tools, than to figure out new ways to educate kids or take care of Grandma.</p></blockquote>\n<p>The story of healthcare and education goes beyond not getting the discounts on manufactured goods. It extends to a large rise in the amount of goods and services we had to purchase, much of it wasted &#8211;<a href=\"https://www.cato-unbound.org/2007/09/10/robin-hanson/cut-medicine-half/\"> Hansonian medicine</a>, academic administrative offices and luxury facilities, credential inflation and years spent mostly on signaling, and so on. Don\u2019t try to pass this all off as Baumol\u2019s Cost Disease.</p>\n<blockquote><p>Noah Smith: If service costs rise relentlessly while manufacturing costs fall, it portends a grim future \u2014 one where we have cheap gadgets, but where the big necessities of modern middle-class life are increasingly out of reach. And in fact, that was the story a lot of people were telling in the mid-2010s.</p>\n<p>That story led to a certain techno-pessimism. If technology could give us cheap gadgets, but couldn\u2019t make the basics of modern life any cheaper, what good was it?</p></blockquote>\n<p>Step back to first principles. This can\u2019t happen purely \u2018because cost disease\u2019 unless the total labor demanded is rising.</p>\n<ol>\n<li>You provide one person-unit of labor.</li>\n<li>You buy [X]-units of labor to get [S] services and also buy [Y]-units of goods.</li>\n<li>That only gets harder for you if either:\n<ol>\n<li>The required quality or quantity of [X] or [Y] is rising.</li>\n<li>The cost of a unit of goods is rising relative to incomes.</li>\n<li>The labor you need is rising in cost faster than your own labor.</li>\n</ol>\n</li>\n</ol>\n<p>Which is it?</p>\n<p>I assert that the primary problem is that [X] is rising, without much benefit to you.</p>\n<p>The secondary issue is a fixed supply of healthcare-relevant [X]s via occupational licensing. Relative to required services, labor productivity and supply are falling.</p>\n<blockquote><p>The failure of educational technologies like online education only seemed to drive the point home \u2014 it seemed like we\u2019d always just be stuck with a teacher giving lectures on a board to 20 or 30 kids.</p></blockquote>\n<p>The \u2018failure of online education\u2019 so far has been due to trying to duplicate that 20-30 kid classroom over zoom. That was always going to be a dystopian nightmare and wouldn\u2019t save on labor anyway.</p>\n<p>Why is a class of the same size so much more expensive in units of middle class labor? Noah focuses on higher education later in the post, but as an obvious lower education example: The New York City DOE school system costs $39k per student. You think that mostly pays for the teachers?</p>\n<p>If all we do is hold the basket of required services [S] constant, we should require less labor units [X] to meet our needs as productivity improves, at least due to technology. Instead, we need more labor.</p>\n<p>Noah then covers attempts to solve the cost issues via policy, or at least to stop making the problem worse via policies that restrict supply and subsidize (and I would add mandate) demand, and instead move around taxes and subsidies in smarter ways. The solutions he seems to favor here still mainly continue to look a lot like subsidizing demand and using transfers.</p>\n\n\n<h4 class=\"wp-block-heading\">Healthcare Costs</h4>\n\n\n<p>But, behold, says Noah. Health care costs have stopped increasing as a percentage of GDP. So Everything Is Fine now, or at least not getting worse. The ways in which he argues things are doing fine helped me realize why things are indeed not so fine here.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!IunS!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F824e51bf-a39f-454f-bea9-dddd49f078d3_1320x450.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>This chart represents us spending more on health care, since it\u2019s a constant percentage of a rising GDP. That\u2019s way better than the previous growing percentage. It is still a high percentage and we are unwise to spend so much.</p>\n<blockquote><p>OK but anyway, what we really care about at the end of the day is <em>affordability</em> \u2014 i.e., how much health care an average America can buy. A good way of measuring affordability is to look at median income divided by an index of health care prices \u2014 in other words, how much health care the typical American can buy with their annual income.</p>\n<p>OK, so, this is total <em>spending</em>, not the price of health care. Is America spending less because we\u2019re getting less care? No. In cost-adjusted terms, Americans have been getting more and more health care services over the years.</p></blockquote>\n<p>Importantly, no. We do not primarily care about how much health care an average American can buy and what it costs them.</p>\n<p>We primarily care, for this purpose, about how much it costs in practice to get a basket of health care you are in practice allowed or required to buy.</p>\n<p>That means buying, or getting as part of your job, acceptable health insurance.</p>\n<p>The systems we have in place de facto require you to purchase a lot more health care services, as measured by these charts. It does not seem to be getting us better health.</p>\n<p>Noah even says, look, healthcare is getting more affordable overall, even accounting for all the extra healthcare we are forced to buy:</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!nA1z!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fedd2cef2-6b59-45ef-85cf-93e518fcddb9_1320x450.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>This chart does not reflect true personal consumption expenditures.</p>\n<p>As a person forced to buy insurance on the New York marketplace, I do not notice things getting more affordable. Quite the opposite. If you don\u2019t get the subsidies, and you don\u2019t have an employer, buying enough insurance that you can get even basic healthcare services costs an obscene amount. You can\u2019t opt out because if you do they charge you much higher prices.</p>\n<p>There are two ways out of that. One is that if you are sufficiently struggling they give you heavy subsidies, but you only get that if you are struggling, so this does not help you not struggle and is part of how we effectively trap such people in ~100% marginal tax brackets as per the discussions of the poverty trap. Getting constant government emails saying \u2018most people on the exchange pay almost nothing!\u2019 threatens to drive one into a blind rage.</p>\n<p>The other way is if you have a job that provides you insurance. Securing this is a severe distortion in many people\u2019s lives, which is a big and rising hidden cost. Either way, you\u2019re massively getting distorted, and that isn\u2019t factored in.</p>\n<p>This thing is obscenely expensive and is de facto mandatory. Then we offer various conditional subsidizes and workarounds does not make the cost non-obscene. Then even after you pay you have to navigate the American Healthcare System and force it to provide the healthcare you bought.</p>\n<p>The average cost is holding steady as a percentage of income but the uncertainty involved makes it much harder to be comfortable.</p>\n<blockquote><p>It could just be that Americans were willing to pay more for health care as they got richer, up to a point, but that at some point they said \u201cOK, that\u2019s enough.\u201d</p></blockquote>\n<p>I believe the American people mostly would prefer to buy less rights to health care, especially if they don\u2019t get insurance through their work and also even if they do. But the system won\u2019t allow that and their major life choices get distorted by the need to not get crushed by this requirement.</p>\n<p>It\u2019s an insane system but we\u2019ve given up on fixing it.</p>\n<p>It\u2019s not that much worse than it was in the 1990s, but in the 1990s this was (as I remember it) the big nightmare for average people. It isn\u2019t getting better, yet people have other bigger complaints more often now. That\u2019s not a great spot.</p>\n\n\n<h4 class=\"wp-block-heading\">Higher Education Costs</h4>\n\n\n<p>I notice that Noah only discusses higher education here. Lower education costs are definitely out of control, including in the senses that:</p>\n<ol>\n<li>Public funding for the schools is wildly higher than the cost of teachers, and wildly higher per student, in ways that don\u2019t seem to help kids learn.</li>\n<li>Public schools are often looking sufficiently unacceptable that people have to opt out even at $0, especially for unusual kids but in many places also in general.</li>\n<li>Private school costs are crazy high when it comes to that.</li>\n</ol>\n<p>But sure, public primary and secondary school directly costs $0, so let\u2019s focus on college. It does seem true on the base chart that costs leveled off, although at levels that are still a lot higher than in the 1990s, which was already higher than earlier, and also people feel more obligation to do more years of schooling to keep pace which isn\u2019t factored into such charts.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!HU4T!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff6b73487-d9a6-46cb-9fb7-9fffb90455e7_1258x695.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<blockquote><p>Of course this doesn\u2019t include <em>financial aid</em> (nor does Mark Perry\u2019s chart, nor do official inflation numbers). Financial aid has been going up, especially at private schools. When you include that, it turns out that private four-year nonprofits are actually <em>less expensive</em> in inflation-adjusted terms than they were in the mid-2000s, even without accounting for rising incomes:</p></blockquote>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!nuvX!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F99a19a41-db2c-412a-a1f5-5403a707e0a2_770x723.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>I do think people fail to appreciate Noah\u2019s point here, but notice what is happening.</p>\n<ol>\n<li>We charge a giant sticker price.</li>\n<li>We force people to jump through hoops, including limiting their income and doing tons of paperwork to navigate systems, and distort their various life choices around all that, in order to get around the sticker price.</li>\n<li>If you don\u2019t distort your life they try to eat all your (family\u2019s) money.</li>\n<li>The resulting real price (here net TFHF) remains very high.</li>\n</ol>\n<p>The actual hidden good news is that enrollment is down from peak, so people aren\u2019t facing increasing pressure to do more and more secondary education.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!38-c!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F003ccf64-763e-4537-b10e-a29a74e2c657_1395x691.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>I buy the thesis that higher education costs, while quite terrible, are getting modestly better rather than getting worse, for a given amount of higher education.</p>\n<p>The trend is starting to reverse a bit, but it went up rather dramatically before it started to come down, until very recently this was offset by the rise in enrollment and graduation rates, and we force people into various hoops including manipulations of family income levels in order to get this effective cost level, which means that the \u2018default\u2019 case is actually quite bad.</p>\n\n\n<h4 class=\"wp-block-heading\">Services Productivity is Rising But What Even Is Productivity Measuring</h4>\n\n\n<p><a href=\"https://www.noahpinion.blog/i/164731973/our-debates-about-services-need-to-change\">Noah\u2019s big takeaway is that services productivity is indeed rising</a>. I notice that he\u2019s treating the productivity statistics as good measures, which I am increasingly skeptical about, especially claims like manufacturing productivity no longer rising? What? How are all the goods still getting cheaper, exactly?</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!XYZp!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdd7cd954-03f7-4316-9618-3078af322315_1320x450.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>Noah agrees that even where costs are now stabilized or modestly falling, we haven\u2019t undone the huge cost increases of the past. Mostly I see these statistics as reinforcing the story of the Revolution of Rising Requirements. If services productivity has doubled in the last 50 years, and we feel the need to purchase not only the same quantity of service hours as before but substantially more hours, that makes the situation very clear.</p>\n<p>I also would assert that a lot of this new \u2018productivity\u2019 is fake in the sense that it does not cash out in things people want. How much \u2018productivity\u2019 is going on, for example, in all the new administrative workers in higher education? One can go on.</p>\n<p>Ultimately I see the stories as compatible, and this is making me even more skeptical of what the productivity statistics are measuring. This goes hand in hand with the internet and AI showing up everywhere except the productivity statistics. Notice that these graphs don\u2019t seem to bend at all when the internet shows up. We are measuring something useful, but it doesn\u2019t seem to line up well with the amount of useful production going on?</p>\n\n\n<h4 class=\"wp-block-heading\">On Clothing In Particular</h4>\n\n\n<p><a href=\"https://marginalrevolution.com/marginalrevolution/2025/05/has-clothing-declined-in-quality.html?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=has-clothing-declined-in-quality\">Alex Tabarrok reminds us</a> that modern clothes are dramatically cheaper.</p>\n<p>We spend 3% of income on clothes down from 14% in 1900 and 9% in the 1960s. Yes, modern clothes tend to be more flimsy, but it is more efficient this way. The cost of replacing them is priced in and it\u2019s good for clothes to be lightweight.</p>\n<p>If you want \u2018high quality\u2019 durable and heavier clothes, we will sell them to you, and they\u2019ll still be relatively cheap. And yes, obviously, the government wanting to \u2018<a href=\"https://x.com/ATabarrok/status/1918675768227352832\">bring back apparel manufacturing to America</a>\u2019 is utter madness, this is exactly the kind of job you want to outsource.</p>\n\n\n<h4 class=\"wp-block-heading\">Our Price Free</h4>\n\n\n<p>Related to all this is the question of<a href=\"https://www.aeaweb.org/articles?id=10.1257/mac.20210319&amp;from=f\"> how much</a><a href=\"https://marginalrevolution.com/marginalrevolution/2025/03/a-new-measurement-for-the-value-of-free-goods.html?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=a-new-measurement-for-the-value-of-free-goods\"> we benefit from free goods</a>? A (gated) paper attempts to quantify this with GDP-B, saying \u2018gains from Facebook\u2019 add 0.05%-0.11% to yearly welfare growth and improvements in smartphones add 0.63%. Which would be a huge deal.</p>\n<p>Both seem suspiciously high. A bundle of \u2018free goods\u2019 only helps me when I care about them. Much of this is positional goods or otherwise not obviously net good for us. You cannot eat smartphone cameras or social media posts.</p>\n<p>The free services that do save you money are a different matter. A lot of those have effectively been lost due to atomization.</p>\n\n\n<h4 class=\"wp-block-heading\">By Default Supply Side Is The Problem</h4>\n\n\n<p>Here is a recent example of attempting to look away from the problem, in two ways.</p>\n<ol>\n<li>To shift focus from what it costs to survive to how many goods people buy.</li>\n<li>To shift focus to demand when we should be focused on supply, as if \u2018our supply chains are intact\u2019 means we\u2019re not restricting supply and subsidizing and mandating demand.</li>\n</ol>\n<blockquote><p>Tyler Cowen:<a href=\"https://marginalrevolution.com/marginalrevolution/2025/12/the-myth-of-the-140000-poverty-line.html?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=the-myth-of-the-140000-poverty-line\"> Most of all</a>, there is a major conceptual error in Green\u2019s focus on high prices. To the extent that prices are high, it is not because our supply chains have been destroyed by earthquakes or nuclear bombs.</p>\n<p>Rather, prices are high in large part because demand is high, which can only happen because so many more Americans can afford to buy things.</p>\n<p>I am reminded of the old Yogi Berra saying: \u201cNobody goes there anymore. It\u2019s too crowded.\u201d</p></blockquote>\n<p>I challenge. This is not primarily a demand side issue.</p>\n<p>Over time supply should be elastic. Shouldn\u2019t we assume we have a supply side issue?</p>\n<p>What are the goods that Americans need, that have truly fixed supply that shouldn\u2019t be elastic in the face of wealth gains and generational demand shifts? Where is this not mostly a self-inflicted wound?</p>\n<p>The answer to that is positional goods. Saying \u2018look at how much more positional goods everyone is buying\u2019 is not exactly an answer that should make anyone happy. If everyone is forced to consume more educational or other signaling, that\u2019s worse.</p>\n<p>The biggest causes of high prices on non-positional goods are supply side restrictions, especially on housing and also other key services with government restrictions on production and often subsidized or mandated demand to boot. Yes, to some extent housing is a positional good as well, but we are nowhere near where that constraint should be binding us. I presume Tyler Cowen would violently agree.</p>\n<p>When solving for the equilibrium, rising demand for a good causing higher prices should be highly suspicious. Supply tends to be remarkably elastic in the medium term, why is that not fixing the issue? If we\u2019re so rich, why don\u2019t you increase production? Something must be preventing you from doing so.</p>\n<p>Often the answer is indeed supply restrictions. In some of the remaining cases you can say Baumol\u2019s Cost Disease. In many others, you can\u2019t. Or you can partially blame Baumol but then you have to ask why we need so much labor per person to produce necessary goods. It\u2019s not like the labor got worse.</p>\n<p>The burdens placed are often part of the Revolution of Rising Requirements.</p>\n<p>Even if Tyler Cowen was entirely correct here? It does not change the key factor. Americans buying lots of things is good, but it does not impact how hard it is to make ends meet.</p>\n<p>It is not a conceptual error to then focus on high prices, if prices are relevantly high.</p>\n<p>It is especially right to focus on high prices if quality requirements for necessary goods have been raised, which in turn raised prices.</p>\n\n\n<h4 class=\"wp-block-heading\">The Kids Are Financially Alright In Historical Terms</h4>\n\n\n<p>We also need to look at generational wealth levels. We constantly play and hear the \u2018generation wealth level\u2019 game, which is mainly about how old people are, and secondarily about home and stock price appreciation, and there was never that much story there to begin with, the gaps were always small?</p>\n<p><a href=\"https://www.washingtonpost.com/business/2024/10/18/wait-are-millennials-suddenly-wealthiest-generation/\">The latest news is that Millennials, contrary to general impressions, are now out in front</a> in \u2018real dollar\u2019 terms for both income and wealth, and their combined spending on housing, food and clothing continues to decline as a percentage of income.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!YDLo!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4a551acb-734c-4534-9a78-1722c1e1582e_995x688.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>The bad news is that if you think of wealth as a percentage of the cost of a house, then that calculation looks a lot worse.</p>\n<p><a href=\"https://x.com/StatisticUrban/status/1878541425039876250\">Similarly, this is the classic graph on income</a>, adjusted for inflation, after taxes and transfers, showing Gen Z is making more money:</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!55MZ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0f27e7ea-2952-4c4f-b220-f402f91856ea_592x690.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<blockquote><p><a href=\"https://x.com/zdch/status/1878615829975367844\">Matthew Yglesias</a>: An annoying aspect of the new political alignment is it\u2019s hard to tell whether a given factually inaccurate declining narrative is coming from a left-wing or right-wing perspective.</p>\n<p>Zac Hill: Right, and it\u2019s precisely the *expectations* created by these skyrocketing increases which is a major cause of this misplaced sense of decline.</p>\n<p>Illustrious Wasp (being wrong): This is graph is straight up propaganda. Inflation hasn\u2019t been actually measured for decades. Purchasing power is the lowest its ever been. Rent, food, and necessities are the highest fraction of income ever since the great depression and possibly even higher. The average American has literally zero dollars in their bank account and is living paycheck to paycheck.</p>\n<p>Hunter: No.</p></blockquote>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!aUpd!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F13f5f74d-2c7e-41c0-899f-3bfbe2323a2d_826x501.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>Also, similarly, we have this:</p>\n<blockquote><p><a href=\"https://x.com/jmhorp/status/1922732485529465077\">Jeremy Horpedahl</a>: The share of income spent on food, clothing, and housing in the has declined dramatically since 1901 in the United States. It\u2019s even lower than in 1973, which many claim is the beginning of economic stagnation.</p></blockquote>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!0PaN!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F512e702d-cd20-49bd-9728-2653864d0a26_900x654.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<blockquote><p>Bonus chart: if you are worried that the national average obscures regional differences, here is similar long-term data for New York and Boston</p></blockquote>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!2WxV!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3bbc6cee-07e3-43da-9835-26f67a1a6219_900x654.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<blockquote><p>[<a href=\"https://economistwritingeveryday.com/2025/05/14/spending-on-necessities-has-declined-dramatically-in-the-united-states/\">These charts are from my post here.</a>]</p></blockquote>\n<p>Such threads are always filled with people who do not believe any of it. The numbers must be wrong. Everyone is lying about inflation. Assertions of \u2018misinformation\u2019 and \u2018debunked\u2019 without evidence.</p>\n<p>I strongly believe the numbers are right. One must then figure out what that means.</p>\n\n\n<h4 class=\"wp-block-heading\">Live Like a Khan</h4>\n\n\n<p>Are you more wealthy than a khan?</p>\n<blockquote><p>Ben Dreyfuss: So many tweets on this website are people describing the almost unimaginable level of comfort and prosperity enjoyed in this country and then being like \u201cbut it sucks\u201d haha</p></blockquote>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!g2au!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7f37eea7-dbbf-4741-b1fa-b5f451fe36ba_1037x1200.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<blockquote><p>Jane Coaston: this is American Beauty thinking, I was pretty sure we solved this with the Great Recession, and yet here we are, still believing that \u201ca good life your ancestors died for\u201d is secretly bad because you\u2019re on the brink of death all the time</p>\n<p>if you want to experience the very edge of human suffering you could just run an ultra like a normal person. Not to sound like a parent but if you would like to suffer to feel something boy do I have some ideas.</p>\n<p>if you have a house, a spouse, and a Costco membership, you are more wealthy than actual khans of the ancient past</p>\n<p><a href=\"https://x.com/mungowitz/status/1922751735484785061\">Mungowitz</a>: Two things:</p></blockquote>\n<ol>\n<li>[The claim about being more wealthy than actual khans] is so obviously true that I can\u2019t see why it is not just universally believed.</li>\n<li>No one believes it.</li>\n</ol>\n<p>I instead say: It is obviously true in a material wealth and comfort sense excluding ability to find companions or raise children, and no one believes it because that\u2019s not the relevant comparison and they\u2019re not drawing the distinction precisely.</p>\n<p>There is a big difference between material wealth and comfort, and what is good or valuable in life. That\u2019s the disconnect. Yes, in terms of material goods in an absolute sense you are vastly richer than the Khans. You are vastly safer and healthier than them, with a vastly higher life expectancy. You better recognize.</p>\n<p>That doesn\u2019t mean you are better off than a Khan. Even if you don\u2019t care about status and ability to boss people around, or other ways in which it is \u2018good to be the king,\u2019 and we focus only on material wealth, you are especially not better off in the most important respect. Which is that, once again, your material wealth will still struggle to support a family and children, or to feel secure and able to not stress about money, and most people feel constrained by money in how many children they can have.</p>\n<p>A Khan had the most important amount of wealth for personal use, which is \u2018enough.\u2019</p>\n<p>What does it say about us if we are both materially more wealthy than a Khan, and that we are not allowed, culturally or legally, to turn that wealth into a large family?</p>\n\n\n<h4 class=\"wp-block-heading\">We Should Be Doing Far Better On All This</h4>\n\n\n<p>Throughout, we see the combination of three trends:</p>\n<ol>\n<li>People are making more money, and ending up with more wealth at a given age.</li>\n<li>Real costs in these areas are rising more than they should be, but not substantially higher than real incomes.</li>\n<li>This identifies important problems, but does not explain people\u2019s unhappiness and felt inability to succeed or be in position to raise a family. More is happening.</li>\n</ol>\n<p>As I said up top, the economists are right about the facts. Claims to the contrary are wrong. But those facts do not mean what the economists understand them to mean. They do not mean that Guy is not miserable or his life is not harder, or that Guy can afford his hometown, or to raise a family.</p>\n<p>Whereas real wages have gone up a lot, so Guy\u2019s life should be easier. Why isn\u2019t it?</p>\n<p>My answer, the thing I\u2019m centrally building towards, is that this doesn\u2019t represent the full range of costs and cost changes, centrally for two reasons: The Revolutions of Rising Expectations and Rising Requirements.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>"
            ],
            "link": "https://thezvi.wordpress.com/2025/12/17/the-140k-question-cost-changes-over-time/",
            "publishedAt": "2025-12-17",
            "source": "TheZvi",
            "summary": "In The $140,000 Question, I went over recent viral claims about poverty in America. The calculations behind the claims were invalid, the central claim (that the \u2018true poverty line\u2019 was $140k) was absurd, but the terrible vibes are real. People &#8230; <a href=\"https://thezvi.wordpress.com/2025/12/17/the-140k-question-cost-changes-over-time/\">Continue reading <span class=\"meta-nav\">&#8594;</span></a>",
            "title": "The $140K Question: Cost Changes Over Time"
        },
        {
            "content": [],
            "link": "https://xkcd.com/3182/",
            "publishedAt": "2025-12-17",
            "source": "XKCD",
            "summary": "<img alt=\"I'm trying to buy a gravitational lens for my camera, but I can't tell if the manufacturers are listing comoving focal length or proper focal length.\" src=\"https://imgs.xkcd.com/comics/telescope_types.png\" title=\"I'm trying to buy a gravitational lens for my camera, but I can't tell if the manufacturers are listing comoving focal length or proper focal length.\" />",
            "title": "Telescope Types"
        },
        {
            "content": [],
            "link": "https://zed.dev/blog/secure-by-default",
            "publishedAt": "2025-12-17",
            "source": "Zed Blog",
            "summary": "We're introducing a new worktree trust mechanism while maintaining options for a low-friction experience you expect from Zed.",
            "title": "Zed Moves Toward Secure-by-Default: Introducing Worktree Trust"
        }
    ],
    "lookbackDays": 1,
    "publishDate": "2025-12-17"
}