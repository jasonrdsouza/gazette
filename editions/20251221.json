{
    "articles": [
        {
            "content": [
                "<p>I recently read <a href=\"https://nedbatchelder.com/blog/202208/truchet_images.html\">Ned Batchelder\u2019s post</a> about <a href=\"https://en.wikipedia.org/wiki/Truchet_tile\">Truchet tiles</a>, which are square tiles that make nice patterns when you tile them on the plane.\nI\u00a0was experimenting with alternative headers for this site, and I thought maybe I\u2019d use Truchet tiles.\nI\u00a0decided to scrap those plans, but I still had fun drawing some pretty pictures.</p>\n\n<p>One of the simplest Truchet tiles is a square made of two colours:</p>\n\n<svg viewBox=\"0 0 0 0\" xmlns=\"http://www.w3.org/2000/svg\">\n  <defs>\n    \n      <rect class=\"bg\" height=\"100\" width=\"100\"></rect>\n      <path class=\"fg\" d=\"M 0 0 l 100 100 l -100 0 Z\"></path>\n    \n    \n    \n      <use transform=\"rotate(90 50 50)\"></use>\n    \n    \n    \n      <use transform=\"rotate(180 50 50)\"></use>\n    \n    \n    \n      <use transform=\"rotate(270 50 50)\"></use>\n    \n    \n    <!--\n      The base of the truchet tile is:\n        - a white rectangle\n        - four outer white \"wings\"\n        - four inner black circles which connect to other tiles\n     -->\n    <svg id=\"base_background\" xmlns=\"http://www.w3.org/2000/svg\">\n      <rect height=\"6\" width=\"6\" x=\"2\" y=\"2\"></rect>\n      <circle cx=\"2\" cy=\"2\" r=\"2\"></circle>\n      <circle cx=\"8\" cy=\"2\" r=\"2\"></circle>\n      <circle cx=\"2\" cy=\"8\" r=\"2\"></circle>\n      <circle cx=\"8\" cy=\"8\" r=\"2\"></circle>\n    </svg>\n    \n    <svg id=\"base_foreground\" xmlns=\"http://www.w3.org/2000/svg\">\n      <circle cx=\"2\" cy=\"5\" r=\"1\"></circle>\n      <circle cx=\"8\" cy=\"5\" r=\"1\"></circle>\n      <circle cx=\"5\" cy=\"2\" r=\"1\"></circle>\n      <circle cx=\"5\" cy=\"8\" r=\"1\"></circle>\n    </svg>\n\n    \n      <use class=\"bg\"></use>\n      <use class=\"fg\"></use>\n    \n    \n    \n      <use class=\"fg\"></use>\n      <use class=\"bg\"></use>\n    \n    \n    <!--\n      Define some of the basic shapes that are used in the Carlson\n      truchet tile set:\n      \n      - a slash that goes from the top edge to the right edge\n      - a wedge that goes from the top edge, to the right edge, to the centre\n      - a horizontal bar that goes from the left edge to the right edge\n    -->\n    <path d=\"M 4 2\n         l 2 0\n         a 2 2 0 0 0 2 2\n         l 0 2\n         a 4 4 0 0 1 -4 -4\" id=\"slash\"></path>\n    <path d=\"M 4 2\n         l 2 0\n         a 2 2 0 0 0 2 2\n         l 0 2\n         l -4 0\" id=\"wedge\"></path>\n    <rect height=\"2\" id=\"bar\" width=\"6\" x=\"2\" y=\"4\"></rect>\n    \n    <!--\n      Define each of the Carlson tiles.\n      \n      Each tile has a list of basic shapes that draw the tile, and a list\n      of extra rotations.\n    -->\n    \n      <use></use>\n    \n    \n    \n      <use></use>\n    \n    \n    \n      <use></use>\n      <g class=\"fg\">\n        <use></use>\n        <use transform=\"rotate(90 5 5)\"></use>\n        <use transform=\"rotate(180 5 5)\"></use>\n        <use transform=\"rotate(270 5 5)\"></use>\n      </g>\n    \n    \n    \n      <use></use>\n      <g class=\"bg\">\n        <use></use>\n        <use transform=\"rotate(90 5 5)\"></use>\n        <use transform=\"rotate(180 5 5)\"></use>\n        <use transform=\"rotate(270 5 5)\"></use>\n      </g>\n    \n    \n    \n      <use></use>\n      <g class=\"fg\">\n        <use></use>\n        <use transform=\"rotate(90 5 5)\"></use>\n      </g>\n    \n    \n    \n      <use></use>  \n      <g class=\"bg\">\n        <use></use>\n        <use transform=\"rotate(90 5 5)\"></use>\n      </g>\n    \n\n    \n      <use transform=\"rotate(90 5 5)\"></use>\n    \n    \n    \n      <use transform=\"rotate(90 5 5)\"></use>\n    \n  \n    \n      <use transform=\"rotate(180 5 5)\"></use>\n    \n    \n    \n      <use transform=\"rotate(180 5 5)\"></use>\n    \n  \n    \n      <use transform=\"rotate(270 5 5)\"></use>\n    \n    \n    \n      <use transform=\"rotate(270 5 5)\"></use>\n    \n\n    \n      <use></use>        \n      <g class=\"fg\">        \n        <use></use>\n        <use transform=\"rotate(90 5 5)\"></use>        \n      </g>\n    \n    \n    \n      <use></use>        \n      <g class=\"bg\">\n        <use></use>\n        <use transform=\"rotate(90 5 5)\"></use>\n      </g>\n    \n\n    \n      <use></use>\n      <g class=\"fg\">\n        <use></use>\n        <use transform=\"rotate(180 5 5)\"></use>\n      </g>\n    \n      \n    \n      <use></use>\n      <g class=\"bg\">\n        <use></use>\n        <use transform=\"rotate(180 5 5)\"></use>        \n      </g>\n    \n  \n    \n      <use transform=\"rotate(90 5 5)\"></use>\n    \n    \n    \n      <use transform=\"rotate(90 5 5)\"></use>\n    \n\n    \n      <use></use>\n      <use class=\"fg\"></use>\n    \n\n    \n      <use></use>\n      <use class=\"bg\"></use>\n    \n      \n    \n      <use transform=\"rotate(90 5 5)\"></use>\n    \n    \n    \n      <use transform=\"rotate(90 5 5)\"></use>\n    \n\n    \n      <use></use>\n      <use class=\"fg\"></use>\n    \n      \n    \n      <use></use>\n      <use class=\"bg\"></use>\n    \n      \n    \n      <use transform=\"rotate(90 5 5)\"></use>\n    \n    \n    \n      <use transform=\"rotate(90 5 5)\"></use>\n    \n  \n    \n      <use transform=\"rotate(180 5 5)\"></use>\n    \n    \n    \n      <use transform=\"rotate(180 5 5)\"></use>\n    \n  \n    \n      <use transform=\"rotate(270 5 5)\"></use>\n    \n    \n    \n      <use transform=\"rotate(270 5 5)\"></use>\n    \n  \n    \n  </defs>\n</svg>\n\n<figure class=\"columns_4\">\n  \n  \n  <svg class=\"border\" viewBox=\"0 0 100 100\" xmlns=\"http://www.w3.org/2000/svg\">\n    <use></use>\n  </svg>\n  \n  <svg class=\"border\" viewBox=\"0 0 100 100\" xmlns=\"http://www.w3.org/2000/svg\">\n    <use></use>\n  </svg>\n  \n  <svg class=\"border\" viewBox=\"0 0 100 100\" xmlns=\"http://www.w3.org/2000/svg\">\n    <use></use>\n  </svg>\n  \n  <svg class=\"border\" viewBox=\"0 0 100 100\" xmlns=\"http://www.w3.org/2000/svg\">\n    <use></use>\n  </svg>\n  \n</figure>\n\n<p>These can be arranged in a regular pattern, but they also look nice when arranged randomly:</p>\n\n\n\n<figure id=\"square_tiles_demo\">\n  <svg class=\"border\" viewBox=\"0 0 400 400\" xmlns=\"http://www.w3.org/2000/svg\">  \n    <use></use>\n    <use x=\"100\"></use>\n    <use x=\"200\"></use>\n    <use x=\"300\"></use>\n    <use y=\"100\"></use>\n    <use x=\"100\" y=\"100\"></use>\n    <use x=\"200\" y=\"100\"></use>\n    <use x=\"300\" y=\"100\"></use>\n    <use y=\"200\"></use>\n    <use x=\"100\" y=\"200\"></use>\n    <use x=\"200\" y=\"200\"></use>\n    <use x=\"300\" y=\"200\"></use>\n    <use y=\"300\"></use>\n    <use x=\"100\" y=\"300\"></use>\n    <use x=\"200\" y=\"300\"></use>\n    <use x=\"300\" y=\"300\"></use>\n  </svg>\n  <svg class=\"border\" id=\"randomSquares\" viewBox=\"0 0 400 400\" xmlns=\"http://www.w3.org/2000/svg\">  \n    <use></use>\n    <use x=\"100\"></use>\n    <use x=\"200\"></use>\n    <use x=\"300\"></use>\n    <use y=\"100\"></use>\n    <use x=\"100\" y=\"100\"></use>\n    <use x=\"200\" y=\"100\"></use>\n    <use x=\"300\" y=\"100\"></use>\n    <use y=\"200\"></use>\n    <use x=\"100\" y=\"200\"></use>\n    <use x=\"200\" y=\"200\"></use>\n    <use x=\"300\" y=\"200\"></use>\n    <use y=\"300\"></use>\n    <use x=\"100\" y=\"300\"></use>\n    <use x=\"200\" y=\"300\"></use>\n    <use x=\"300\" y=\"300\"></use>\n  </svg>\n</figure>\n\n<p>The tiles that really caught my eye were <a href=\"https://christophercarlson.com/portfolio/multi-scale-truchet-patterns/\">Christopher Carlson\u2019s</a>.\nHe created a collection of \u201cwinged tiles\u201d that can be arranged with multiple sizes in the same grid.\nA\u00a0tile can be overlaid with four smaller tiles with inverted colours and extra wings, and the pattern still looks seamless.</p>\n\n<p>He defined fifteen tiles, which are seven distinct patterns and then various rotations:</p>\n\n\n\n<figure id=\"carlsonTiles\">\n  \n  \n    <svg viewBox=\"0 0 12 12\" xmlns=\"http://www.w3.org/2000/svg\">\n      <rect class=\"carlson_bg\" height=\"12\" width=\"12\" x=\"0\" y=\"0\"></rect>\n      <use x=\"1\" y=\"1\"></use>\n      <rect class=\"carlson_grid\" height=\"6\" width=\"6\" x=\"3\" y=\"3\"></rect>\n    </svg>\n  \n    <svg viewBox=\"0 0 12 12\" xmlns=\"http://www.w3.org/2000/svg\">\n      <rect class=\"carlson_bg\" height=\"12\" width=\"12\" x=\"0\" y=\"0\"></rect>\n      <use x=\"1\" y=\"1\"></use>\n      <rect class=\"carlson_grid\" height=\"6\" width=\"6\" x=\"3\" y=\"3\"></rect>\n    </svg>\n  \n    <svg viewBox=\"0 0 12 12\" xmlns=\"http://www.w3.org/2000/svg\">\n      <rect class=\"carlson_bg\" height=\"12\" width=\"12\" x=\"0\" y=\"0\"></rect>\n      <use x=\"1\" y=\"1\"></use>\n      <rect class=\"carlson_grid\" height=\"6\" width=\"6\" x=\"3\" y=\"3\"></rect>\n    </svg>\n  \n    <svg viewBox=\"0 0 12 12\" xmlns=\"http://www.w3.org/2000/svg\">\n      <rect class=\"carlson_bg\" height=\"12\" width=\"12\" x=\"0\" y=\"0\"></rect>\n      <use x=\"1\" y=\"1\"></use>\n      <rect class=\"carlson_grid\" height=\"6\" width=\"6\" x=\"3\" y=\"3\"></rect>\n    </svg>\n  \n    <svg viewBox=\"0 0 12 12\" xmlns=\"http://www.w3.org/2000/svg\">\n      <rect class=\"carlson_bg\" height=\"12\" width=\"12\" x=\"0\" y=\"0\"></rect>\n      <use x=\"1\" y=\"1\"></use>\n      <rect class=\"carlson_grid\" height=\"6\" width=\"6\" x=\"3\" y=\"3\"></rect>\n    </svg>\n  \n    <svg viewBox=\"0 0 12 12\" xmlns=\"http://www.w3.org/2000/svg\">\n      <rect class=\"carlson_bg\" height=\"12\" width=\"12\" x=\"0\" y=\"0\"></rect>\n      <use x=\"1\" y=\"1\"></use>\n      <rect class=\"carlson_grid\" height=\"6\" width=\"6\" x=\"3\" y=\"3\"></rect>\n    </svg>\n  \n    <svg viewBox=\"0 0 12 12\" xmlns=\"http://www.w3.org/2000/svg\">\n      <rect class=\"carlson_bg\" height=\"12\" width=\"12\" x=\"0\" y=\"0\"></rect>\n      <use x=\"1\" y=\"1\"></use>\n      <rect class=\"carlson_grid\" height=\"6\" width=\"6\" x=\"3\" y=\"3\"></rect>\n    </svg>\n  \n    <svg viewBox=\"0 0 12 12\" xmlns=\"http://www.w3.org/2000/svg\">\n      <rect class=\"carlson_bg\" height=\"12\" width=\"12\" x=\"0\" y=\"0\"></rect>\n      <use x=\"1\" y=\"1\"></use>\n      <rect class=\"carlson_grid\" height=\"6\" width=\"6\" x=\"3\" y=\"3\"></rect>\n    </svg>\n  \n    <svg viewBox=\"0 0 12 12\" xmlns=\"http://www.w3.org/2000/svg\">\n      <rect class=\"carlson_bg\" height=\"12\" width=\"12\" x=\"0\" y=\"0\"></rect>\n      <use x=\"1\" y=\"1\"></use>\n      <rect class=\"carlson_grid\" height=\"6\" width=\"6\" x=\"3\" y=\"3\"></rect>\n    </svg>\n  \n    <svg viewBox=\"0 0 12 12\" xmlns=\"http://www.w3.org/2000/svg\">\n      <rect class=\"carlson_bg\" height=\"12\" width=\"12\" x=\"0\" y=\"0\"></rect>\n      <use x=\"1\" y=\"1\"></use>\n      <rect class=\"carlson_grid\" height=\"6\" width=\"6\" x=\"3\" y=\"3\"></rect>\n    </svg>\n  \n    <svg viewBox=\"0 0 12 12\" xmlns=\"http://www.w3.org/2000/svg\">\n      <rect class=\"carlson_bg\" height=\"12\" width=\"12\" x=\"0\" y=\"0\"></rect>\n      <use x=\"1\" y=\"1\"></use>\n      <rect class=\"carlson_grid\" height=\"6\" width=\"6\" x=\"3\" y=\"3\"></rect>\n    </svg>\n  \n    <svg viewBox=\"0 0 12 12\" xmlns=\"http://www.w3.org/2000/svg\">\n      <rect class=\"carlson_bg\" height=\"12\" width=\"12\" x=\"0\" y=\"0\"></rect>\n      <use x=\"1\" y=\"1\"></use>\n      <rect class=\"carlson_grid\" height=\"6\" width=\"6\" x=\"3\" y=\"3\"></rect>\n    </svg>\n  \n    <svg viewBox=\"0 0 12 12\" xmlns=\"http://www.w3.org/2000/svg\">\n      <rect class=\"carlson_bg\" height=\"12\" width=\"12\" x=\"0\" y=\"0\"></rect>\n      <use x=\"1\" y=\"1\"></use>\n      <rect class=\"carlson_grid\" height=\"6\" width=\"6\" x=\"3\" y=\"3\"></rect>\n    </svg>\n  \n    <svg viewBox=\"0 0 12 12\" xmlns=\"http://www.w3.org/2000/svg\">\n      <rect class=\"carlson_bg\" height=\"12\" width=\"12\" x=\"0\" y=\"0\"></rect>\n      <use x=\"1\" y=\"1\"></use>\n      <rect class=\"carlson_grid\" height=\"6\" width=\"6\" x=\"3\" y=\"3\"></rect>\n    </svg>\n  \n    <svg viewBox=\"0 0 12 12\" xmlns=\"http://www.w3.org/2000/svg\">\n      <rect class=\"carlson_bg\" height=\"12\" width=\"12\" x=\"0\" y=\"0\"></rect>\n      <use x=\"1\" y=\"1\"></use>\n      <rect class=\"carlson_grid\" height=\"6\" width=\"6\" x=\"3\" y=\"3\"></rect>\n    </svg>\n  \n</figure>\n\n<p>The important thing to notice here is that every tile only really \u201cowns\u201d the red square in the middle.\nWhen laid down, you add the \u201cwings\u201d that extend outside the tile \u2013 this is what allows smaller tiles to seamlessly flow into the larger pattern.</p>\n\n<p>Here\u2019s an example of a Carlson Truchet tiling:</p>\n\n<figure>\n  <svg class=\"border\" id=\"gridlinesDemo\" viewBox=\"0 0 48 24\" xmlns=\"http://www.w3.org/2000/svg\">\n    <g id=\"layer-1\" transform=\"translate(-2 -2) \">\n      <use></use>\n      <use y=\"6\"></use>\n      <use y=\"12\"></use>\n      <use x=\"6\"></use>\n      <use x=\"6\" y=\"6\"></use>\n      <use x=\"6\" y=\"12\"></use>\n      <use x=\"6\" y=\"18\"></use>\n      <use x=\"12\"></use>\n      <use x=\"12\" y=\"6\"></use>\n      <use x=\"12\" y=\"12\"></use>\n      <use x=\"12\" y=\"18\"></use>\n      <use x=\"18\" y=\"6\"></use>\n      <use x=\"18\" y=\"12\"></use>\n      <use x=\"24\"></use>\n      <use x=\"24\" y=\"6\"></use>\n      <use x=\"24\" y=\"12\"></use>\n      <use x=\"24\" y=\"18\"></use>\n      <use x=\"30\"></use>\n      <use x=\"30\" y=\"6\"></use>\n      <use x=\"30\" y=\"12\"></use>\n      <use x=\"30\" y=\"18\"></use>\n      <use x=\"36\"></use>\n      <use x=\"36\" y=\"12\"></use>\n      <use x=\"36\" y=\"18\"></use>\n      <use x=\"42\"></use>\n      <use x=\"42\" y=\"6\"></use>\n      <use x=\"42\" y=\"12\"></use>\n      <use x=\"42\" y=\"18\"></use>\n    </g>\n    <g id=\"layer-2\" transform=\"translate(-1 -1) scale(0.5)\">\n      <use x=\"6\" y=\"36\"></use>\n      <use y=\"42\"></use>\n      <use x=\"36\"></use>\n      <use x=\"42\"></use>\n      <use x=\"36\" y=\"6\"></use>\n      <use x=\"42\" y=\"6\"></use>\n      <use x=\"42\" y=\"36\"></use>\n      <use x=\"36\" y=\"42\"></use>\n      <use x=\"72\" y=\"12\"></use>\n      <use x=\"78\" y=\"12\"></use>\n      <use x=\"78\" y=\"18\"></use>\n    </g>\n    <g id=\"layer-3\" transform=\"translate(-0.5 -0.5) scale(0.25)\">\n      <use y=\"72\"></use>\n      <use x=\"6\" y=\"72\"></use>\n      <use y=\"78\"></use>\n      <use x=\"6\" y=\"78\"></use>\n      <use x=\"12\" y=\"84\"></use>\n      <use x=\"18\" y=\"84\"></use>\n      <use x=\"12\" y=\"90\"></use>\n      <use x=\"18\" y=\"90\"></use>\n      <use x=\"72\" y=\"72\"></use>\n      <use x=\"78\" y=\"72\"></use>\n      <use x=\"72\" y=\"78\"></use>\n      <use x=\"78\" y=\"78\"></use>\n      <use x=\"84\" y=\"84\"></use>\n      <use x=\"90\" y=\"84\"></use>\n      <use x=\"84\" y=\"90\"></use>\n      <use x=\"90\" y=\"90\"></use>\n      <use x=\"144\" y=\"36\"></use>\n      <use x=\"150\" y=\"36\"></use>\n      <use x=\"144\" y=\"42\"></use>\n      <use x=\"150\" y=\"42\"></use>\n    </g>\n    <line class=\"carlson_grid\" x1=\"6\" x2=\"6\" y1=\"0\" y2=\"24\"></line>\n    <line class=\"carlson_grid\" x1=\"12\" x2=\"12\" y1=\"0\" y2=\"24\"></line>\n    <line class=\"carlson_grid\" x1=\"18\" x2=\"18\" y1=\"0\" y2=\"24\"></line>\n    <line class=\"carlson_grid\" x1=\"24\" x2=\"24\" y1=\"0\" y2=\"24\"></line>\n    <line class=\"carlson_grid\" x1=\"30\" x2=\"30\" y1=\"0\" y2=\"24\"></line>\n    <line class=\"carlson_grid\" x1=\"36\" x2=\"36\" y1=\"0\" y2=\"24\"></line>\n    <line class=\"carlson_grid\" x1=\"42\" x2=\"42\" y1=\"0\" y2=\"24\"></line>\n    \n    <line class=\"carlson_grid\" x1=\"0\" x2=\"48\" y1=\"6\" y2=\"6\"></line>\n    <line class=\"carlson_grid\" x1=\"0\" x2=\"48\" y1=\"12\" y2=\"12\"></line>\n    <line class=\"carlson_grid\" x1=\"0\" x2=\"48\" y1=\"18\" y2=\"18\"></line>\n    \n    <line class=\"carlson_grid\" x1=\"21\" x2=\"21\" y1=\"0\" y2=\"6\"></line>\n    <line class=\"carlson_grid\" x1=\"18\" x2=\"24\" y1=\"3\" y2=\"3\"></line>\n    \n    <line class=\"carlson_grid\" x1=\"39\" x2=\"39\" y1=\"6\" y2=\"12\"></line>\n    <line class=\"carlson_grid\" x1=\"36\" x2=\"42\" y1=\"9\" y2=\"9\"></line>\n    \n    <line class=\"carlson_grid\" x1=\"37.5\" x2=\"37.5\" y1=\"9\" y2=\"12\"></line>\n    <line class=\"carlson_grid\" x1=\"36\" x2=\"39\" y1=\"10.5\" y2=\"10.5\"></line>\n    \n    <line class=\"carlson_grid\" x1=\"3\" x2=\"3\" y1=\"18\" y2=\"24\"></line>\n    <line class=\"carlson_grid\" x1=\"0\" x2=\"6\" y1=\"21\" y2=\"21\"></line>\n    \n    <line class=\"carlson_grid\" x1=\"1.5\" x2=\"1.5\" y1=\"18\" y2=\"24\"></line>\n    <line class=\"carlson_grid\" x1=\"0\" x2=\"3\" y1=\"19.5\" y2=\"19.5\"></line>\n    <line class=\"carlson_grid\" x1=\"0\" x2=\"6\" y1=\"22.5\" y2=\"22.5\"></line>\n    <line class=\"carlson_grid\" x1=\"4.5\" x2=\"4.5\" y1=\"21\" y2=\"24\"></line>\n    \n    <line class=\"carlson_grid\" x1=\"21\" x2=\"21\" y1=\"18\" y2=\"24\"></line>\n    <line class=\"carlson_grid\" x1=\"18\" x2=\"24\" y1=\"21\" y2=\"21\"></line>\n    \n    <line class=\"carlson_grid\" x1=\"19.5\" x2=\"19.5\" y1=\"18\" y2=\"21\"></line>\n    <line class=\"carlson_grid\" x1=\"18\" x2=\"21\" y1=\"19.5\" y2=\"19.5\"></line>\n    \n    <line class=\"carlson_grid\" x1=\"22.5\" x2=\"22.5\" y1=\"21\" y2=\"24\"></line>\n    <line class=\"carlson_grid\" x1=\"21\" x2=\"24\" y1=\"22.5\" y2=\"22.5\"></line>\n  </svg>\n  \n  \n  <figcaption>\n    <input checked=\"checked\" id=\"toggleGridLines\" name=\"toggleGridLines\" type=\"checkbox\" />\n    <label for=\"toggleGridLines\">\n      show gridlines\n    </label>\n  </figcaption>\n</figure>\n\n<p>Conceptually, we\u2019re giving the computer a bag of tiles, letting it pull tiles out at random, and watching what happens when it places them on the page.</p>\n\n<p>In this post, I\u2019ll explain how to do this: filling the bag of tiles with parametric SVGs, then placing them randomly at different sizes.\nI\u2019m assuming you\u2019re familiar with SVG and JavaScript, but I\u2019ll explain the geometry as we go.</p>\n\n<h2 id=\"filling-the-bag-of-tiles\">Filling the bag of tiles</h2>\n\n<p>Although Carlson\u2019s set has fifteen different tiles, they\u2019re made of just four primitives, which I call the base, the slash, the wedge, and the bar.</p>\n\n<figure class=\"columns_4\">\n  \n  \n    <svg viewBox=\"0 0 12 12\" xmlns=\"http://www.w3.org/2000/svg\">\n      <rect class=\"carlson_bg\" height=\"12\" width=\"12\" x=\"0\" y=\"0\"></rect>\n      <use class=\"fg\" x=\"1\" y=\"1\"></use>\n      <rect class=\"carlson_grid\" height=\"6\" width=\"6\" x=\"3\" y=\"3\"></rect>\n    </svg>\n  \n    <svg viewBox=\"0 0 12 12\" xmlns=\"http://www.w3.org/2000/svg\">\n      <rect class=\"carlson_bg\" height=\"12\" width=\"12\" x=\"0\" y=\"0\"></rect>\n      <use class=\"fg\" x=\"1\" y=\"1\"></use>\n      <rect class=\"carlson_grid\" height=\"6\" width=\"6\" x=\"3\" y=\"3\"></rect>\n    </svg>\n  \n    <svg viewBox=\"0 0 12 12\" xmlns=\"http://www.w3.org/2000/svg\">\n      <rect class=\"carlson_bg\" height=\"12\" width=\"12\" x=\"0\" y=\"0\"></rect>\n      <use class=\"fg\" x=\"1\" y=\"1\"></use>\n      <rect class=\"carlson_grid\" height=\"6\" width=\"6\" x=\"3\" y=\"3\"></rect>\n    </svg>\n  \n    <svg viewBox=\"0 0 12 12\" xmlns=\"http://www.w3.org/2000/svg\">\n      <rect class=\"carlson_bg\" height=\"12\" width=\"12\" x=\"0\" y=\"0\"></rect>\n      <use class=\"fg\" x=\"1\" y=\"1\"></use>\n      <rect class=\"carlson_grid\" height=\"6\" width=\"6\" x=\"3\" y=\"3\"></rect>\n    </svg>\n  \n</figure>\n\n<p>The first step is to write SVG definitions for each of these primitives that we can reuse.</p>\n\n<p>Whenever I\u2019m doing this sort of generative art, I like to define it parametrically \u2013 writing a template that takes inputs I can change, so I can always see the relationship between the inputs and the result, and I can tweak the settings later.\nThere are lots of templating tools; I\u2019m going to write pseudo-code rather than focus on one in particular.</p>\n\n<p>For these primitives, there are two variables, which I call the <em>inner radius</em> and <em>outer radius</em>.\nThe outer radius is the radius of the larger wings on the corner of the tile, while the inner radius is the radius of the foreground components on the middle of each edge.\nFor the slash, the wedge, and the bar, the inner radius is half the width of the shape where it meets the edge of the tile.</p>\n\n<p>This diagram shows the two variables, plus two variables I compute in the template:</p>\n\n<figure>\n  <svg viewBox=\"0 0 28 17.2\" xmlns=\"http://www.w3.org/2000/svg\">\n    <defs>\n      \n    </defs>\n    <g transform=\"translate(8 0)\">\n      <rect class=\"carlson_bg\" height=\"12\" width=\"12\" x=\"0\" y=\"0\"></rect>\n      <use class=\"fg\" x=\"1\" y=\"1\"></use>\n      <rect class=\"carlson_grid grid_thin\" height=\"6\" width=\"6\" x=\"3\" y=\"3\"></rect>\n\n      <circle class=\"carlson_grid carlson_grid_blue\" cx=\"3\" cy=\"3\" r=\"2\"></circle>\n      <circle class=\"carlson_grid carlson_grid_blue\" cx=\"9\" cy=\"6\" r=\"1\"></circle>\n    \n      <circle class=\"blue\" cx=\"3\" cy=\"3\" r=\"0.25\"></circle>\n      <circle class=\"blue\" cx=\"9\" cy=\"6\" r=\"0.25\"></circle>\n    </g>\n    \n    <text font-size=\"1px\" text-anchor=\"end\" x=\"6.5\" y=\"2\">outer radius</text>\n    <path class=\"dimensions\" d=\"M 6.8 3\n         l 0.6 0 l -0.3 0\n         l 0 -2\n         l -0.3 0\n         l 0.6 0\n         l -0.3 0\n         l 0 2\n         l -0.3 0\"></path>\n    \n    <path class=\"dimensions\" d=\"M 20.6 6\n         l 0.6 0 l -0.3 0\n         l 0 -1\n         l -0.3 0\n         l 0.6 0\n         l -0.3 0\n         l 0 1\n         l -0.3 0\"></path>\n    <text font-size=\"1px\" text-anchor=\"start\" x=\"21.5\" y=\"5.5\">inner radius</text>\n    \n    <path class=\"dimensions\" d=\"M 11 12.6\n         l 0 0.6 l 0 -0.3\n         l 6 0\n         l 0 -0.3\n         l 0 0.6\n         l 0 -0.3\n         l -6 0\n         l 0 -0.3\"></path>\n    <text font-size=\"1px\" text-anchor=\"middle\" x=\"14\" y=\"14.2\">tile size</text>\n  \n    <path class=\"dimensions\" d=\"M 9 14.8\n         l 0 0.6 l 0 -0.3\n         l 2 0\n         l 0 -0.3\n         l 0 0.6\n         l 0 -0.3\n         l -2 0\n         l 0 -0.3\"></path>\n    <text font-size=\"1px\" text-anchor=\"middle\" x=\"10\" y=\"16.6\">padding</text>\n  </svg>\n</figure>\n\n<p>Here\u2019s the template for these primitives:</p>\n\n<pre class=\"language-xml\"><code><span class=\"c\">&lt;!-- What's the length of one side of the tile, in the red dashed area?\n     tileSize = (innerR + outerR) * 2 --&gt;</span>\n\n<span class=\"c\">&lt;!-- How far is the tile offset from the edge of the symbol/path?\n     padding = max(innerR, outerR) --&gt;</span>\n\n<span class=\"nt\">&lt;symbol</span> <span class=\"na\">id=</span><span class=\"s\">\"base\"</span><span class=\"nt\">&gt;</span>\n  <span class=\"c\">&lt;!--\n    For the background, draw a square that fills the whole tile, then\n    four circles on each of the corners.\n    --&gt;</span>\n  <span class=\"nt\">&lt;g</span> <span class=\"na\">class=</span><span class=\"s\">\"background\"</span><span class=\"nt\">&gt;</span>\n    <span class=\"nt\">&lt;rect</span> <span class=\"na\">x=</span><span class=\"s\">\"{{ padding }}\"</span> <span class=\"na\">y=</span><span class=\"s\">\"{{ padding }}\"</span> <span class=\"na\">width=</span><span class=\"s\">\"{{ tileSize }}\"</span> <span class=\"na\">height=</span><span class=\"s\">\"{{ tileSize }}\"</span><span class=\"nt\">/&gt;</span>\n    <span class=\"nt\">&lt;circle</span> <span class=\"na\">cx=</span><span class=\"s\">\"{{ padding }}\"</span>            <span class=\"na\">cy=</span><span class=\"s\">\"{{ padding }}\"</span>            <span class=\"na\">r=</span><span class=\"s\">\"{{ outerR }}\"</span><span class=\"nt\">/&gt;</span>\n    <span class=\"nt\">&lt;circle</span> <span class=\"na\">cx=</span><span class=\"s\">\"{{ padding + tileSize }}\"</span> <span class=\"na\">cy=</span><span class=\"s\">\"{{ padding }}\"</span>            <span class=\"na\">r=</span><span class=\"s\">\"{{ outerR }}\"</span><span class=\"nt\">/&gt;</span>\n    <span class=\"nt\">&lt;circle</span> <span class=\"na\">cx=</span><span class=\"s\">\"{{ padding }}\"</span>            <span class=\"na\">cy=</span><span class=\"s\">\"{{ padding + tileSize }}\"</span> <span class=\"na\">r=</span><span class=\"s\">\"{{ outerR }}\"</span><span class=\"nt\">/&gt;</span>\n    <span class=\"nt\">&lt;circle</span> <span class=\"na\">cx=</span><span class=\"s\">\"{{ padding + tileSize }}\"</span> <span class=\"na\">cy=</span><span class=\"s\">\"{{ padding + tileSize }}\"</span> <span class=\"na\">r=</span><span class=\"s\">\"{{ outerR }}\"</span><span class=\"nt\">/&gt;</span>\n  <span class=\"nt\">&lt;/g&gt;</span>\n  <span class=\"c\">&lt;!--\n    For the foreground, draw four circles on the middle of each tile edge.\n    --&gt;</span>\n  <span class=\"nt\">&lt;g</span> <span class=\"na\">class=</span><span class=\"s\">\"foreground\"</span><span class=\"nt\">&gt;</span>\n    <span class=\"nt\">&lt;circle</span> <span class=\"na\">cx=</span><span class=\"s\">\"{{ padding }}\"</span>            <span class=\"na\">cy=</span><span class=\"s\">\"{{ tileSize / 2 }}\"</span>       <span class=\"na\">r=</span><span class=\"s\">\"{{ innerR }}\"</span><span class=\"nt\">/&gt;</span>\n    <span class=\"nt\">&lt;circle</span> <span class=\"na\">cx=</span><span class=\"s\">\"{{ padding + tileSize }}\"</span> <span class=\"na\">cy=</span><span class=\"s\">\"{{ tileSize / 2 }}\"</span>       <span class=\"na\">r=</span><span class=\"s\">\"{{ innerR }}\"</span><span class=\"nt\">/&gt;</span>\n    <span class=\"nt\">&lt;circle</span> <span class=\"na\">cx=</span><span class=\"s\">\"{{ tileSize / 2 }}\"</span>       <span class=\"na\">cy=</span><span class=\"s\">\"{{ padding }}\"</span>            <span class=\"na\">r=</span><span class=\"s\">\"{{ innerR }}\"</span><span class=\"nt\">/&gt;</span>\n    <span class=\"nt\">&lt;circle</span> <span class=\"na\">cx=</span><span class=\"s\">\"{{ tileSize / 2 }}\"</span>       <span class=\"na\">cy=</span><span class=\"s\">\"{{ padding + tileSize }}\"</span> <span class=\"na\">r=</span><span class=\"s\">\"{{ innerR }}\"</span><span class=\"nt\">/&gt;</span>\n  <span class=\"nt\">&lt;/g&gt;</span>\n<span class=\"nt\">&lt;/symbol&gt;</span>\n\n<span class=\"c\">&lt;!--\n  Slash:\n    - Move to the top edge, left-hand vertex of the slash\n    - Line to the top edge, right-hand vertex\n    - Smaller arc to left egde, upper vertex\n    - Line down to left edge, lower vertex\n    - Larger arc back to the start\n--&gt;</span>\n<span class=\"nt\">&lt;path</span>\n  <span class=\"na\">id=</span><span class=\"s\">\"slash\"</span>\n  <span class=\"na\">d=</span><span class=\"s\">\"M {{ padding + outerR }} {{ padding }}\n     l {{ 2 * innerR }} 0\n     a {{ outerR }} {{ outerR }} 0 0 0 {{ outerR }} {{ outerR }}\n     l 0 {{ 2 * innerR }}\n     a {{ innerR*2 + outerR }} {{ innerR*2 + outerR }} 0 0 1 {{ -innerR*2 - outerR }} {{ -innerR*2 - outerR }}\"</span><span class=\"nt\">/&gt;</span>\n\n<span class=\"c\">&lt;!--\n  wedge:\n    - Move to the top edge, left-hand vertex of the slash\n    - Line to the top edge, right-hand vertex\n    - Smaller arc to left egde, upper vertex\n    - Line to centre of the tile\n    - Line back to the start\n--&gt;</span>\n<span class=\"nt\">&lt;path</span>\n  <span class=\"na\">id=</span><span class=\"s\">\"wedge\"</span>\n  <span class=\"na\">d=</span><span class=\"s\">\"M {{ padding + outerR }} {{ padding }}\n     l {{ 2 * innerR }} 0\n     a {{ outerR }} {{ outerR }} 0 0 0 {{ outerR }} {{ outerR }}\n     l {{ 0 }} {{ 2 * innerR }}\n     l {{ -innerR*2 - outerR }} 0\"</span><span class=\"nt\">/&gt;</span>\n\n<span class=\"c\">&lt;!--\n  Bar: horizontal rectangle that spans the tile width and is the same height\n  as a circle on the centre of an edge.\n  --&gt;</span>\n<span class=\"nt\">&lt;rect</span>\n  <span class=\"na\">id=</span><span class=\"s\">\"bar\"</span>\n  <span class=\"na\">x=</span><span class=\"s\">\"{{ padding }}\"</span> <span class=\"na\">y=</span><span class=\"s\">\"{{ padding + outerR }}\"</span>\n  <span class=\"na\">width=</span><span class=\"s\">\"{{ tileSize }}\"</span>\n  <span class=\"na\">height=</span><span class=\"s\">\"{{ 2 * innerR }}\"</span><span class=\"nt\">/&gt;</span>\n</code></pre>\n<p>The <code>foreground</code>/<code>background</code> classes are defined in CSS, so I can choose the colour of each.</p>\n\n<p>This template is more verbose than the rendered SVG, but I can see all the geometric expressions \u2013 I find this far more readable than a file full of numbers.\nThis also allows easy experimentation \u2013 I can change an input, re-render the template, and instantly see the new result.</p>\n\n<p>I can then compose the tiles by referencing these primitive shapes with a <a href=\"https://developer.mozilla.org/en-US/docs/Web/SVG/Reference/Element/use\"><code>&lt;use&gt;</code> element</a>.\nFor example, the \u201cT\u201d tile is made of a base and two wedge shapes:</p>\n\n<pre class=\"language-xml\"><code><span class=\"c\">&lt;!-- The centre of rotation is the centre of the whole tile, including padding.\n     centreRotation = outerR + innerR --&gt;</span>\n\n<span class=\"nt\">&lt;symbol</span> <span class=\"na\">id=</span><span class=\"s\">\"carlsonT\"</span><span class=\"nt\">&gt;</span>\n  <span class=\"nt\">&lt;use</span> <span class=\"na\">href=</span><span class=\"s\">\"#base\"</span><span class=\"nt\">/&gt;</span>\n  <span class=\"nt\">&lt;use</span> <span class=\"na\">href=</span><span class=\"s\">\"#wedge\"</span> <span class=\"na\">class=</span><span class=\"s\">\"foreground\"</span><span class=\"nt\">/&gt;</span>\n  <span class=\"nt\">&lt;use</span> <span class=\"na\">href=</span><span class=\"s\">\"#wedge\"</span> <span class=\"na\">class=</span><span class=\"s\">\"foreground\"</span> <span class=\"na\">transform=</span><span class=\"s\">\"rotate(90 {{ centreRotation }} {{ centreRotation }})\"</span><span class=\"nt\">/&gt;</span>\n<span class=\"nt\">&lt;/symbol&gt;</span>\n</code></pre>\n<p>After this, I write a similar <code>&lt;symbol&gt;</code> definition for all the other tiles, plus inverted versions that swap the background and foreground.</p>\n\n<p>Now we have a bag full of tiles, let\u2019s tell the computer how to place them.</p>\n\n<h2 id=\"placing-the-tiles-on-the-page\">Placing the tiles on the page</h2>\n\n<p>Suppose the computer has drawn a tile from the bag.\nTo place it on the page, it needs to know:</p>\n\n<ul>\n  <li>The <em>x</em>, <em>y</em> position, and</li>\n  <li>The layer \u2013 should it place a full-size tile, or is it a smaller tile subdividing a larger tile</li>\n</ul>\n\n<p>From these two properties, it can work out everything else \u2013 in particular, whether to invert the tile, and how large to scale it.</p>\n\n<p>The procedure is straightforward: get the position of all the tiles in a layer, then decide if any of those tiles are going to be subdivided into smaller tiles.\nUse those to position the next layer, and repeat.\nContinue until the next layer is empty, or you hit the maximum number of layers you want.</p>\n\n<p>Here\u2019s an implementation of that procedure in JavaScript:</p>\n<pre><code><span class=\"kd\">function</span> <span class=\"n\">getTilePositions</span><span class=\"p\">({</span>\n  <span class=\"n\">columns</span><span class=\"p\">,</span>\n  <span class=\"n\">rows</span><span class=\"p\">,</span>\n  <span class=\"n\">tileSize</span><span class=\"p\">,</span>\n  <span class=\"n\">maxLayers</span><span class=\"p\">,</span>\n  <span class=\"n\">subdivideChance</span><span class=\"p\">,</span>\n<span class=\"p\">})</span> <span class=\"p\">{</span>\n  <span class=\"kd\">let</span> <span class=\"n\">tiles</span> = <span class=\"p\">[];</span>\n  \n  <span class=\"c1\">// Draw layer 1 of tiles, which is a full-sized tile for</span>\n  <span class=\"c1\">// every row and column.</span>\n  for <span class=\"p\">(</span><span class=\"n\">i</span> = <span class=\"mi\">0</span><span class=\"p\">;</span> i &lt; columns<span class=\"p\">;</span> i++<span class=\"p\">)</span> <span class=\"p\">{</span>\n    for <span class=\"p\">(</span><span class=\"n\">j</span> = <span class=\"mi\">0</span><span class=\"p\">;</span> j &lt; rows<span class=\"p\">;</span> j++<span class=\"p\">)</span> <span class=\"p\">{</span>\n      tiles<span class=\"p\">.</span>push<span class=\"p\">({</span> x<span class=\"p\">:</span> i * tileSize<span class=\"p\">,</span> y<span class=\"p\">:</span> j * tileSize<span class=\"p\">,</span> layer<span class=\"p\">:</span> <span class=\"mi\">1</span> <span class=\"p\">});</span>\n    <span class=\"p\">}</span>\n  <span class=\"p\">}</span>\n  \n  <span class=\"c1\">// Now go through each layer up to maxLayers, and decide which</span>\n  <span class=\"c1\">// tiles from the previous layer to subdivide into four smaller tiles.</span>\n  for <span class=\"p\">(</span><span class=\"n\">layer</span> = <span class=\"mi\">2</span><span class=\"p\">;</span> layer &lt;= maxLayers<span class=\"p\">;</span> layer++<span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"kd\">let</span> <span class=\"n\">previousLayer</span> = tiles<span class=\"p\">.</span>filter<span class=\"p\">(</span>t =&gt; t<span class=\"p\">.</span>layer === layer - <span class=\"mi\">1</span><span class=\"p\">);</span>\n    \n    <span class=\"c1\">// The size of tiles halves with each layer.</span>\n    <span class=\"c1\">// On layer 2, the tiles are 1/2 the size of the top layer.</span>\n    <span class=\"c1\">// On layer 3, the tiles are 1/4 the size of the top layer.</span>\n    <span class=\"c1\">// And so on.</span>\n    <span class=\"kd\">let</span> <span class=\"n\">layerTileSize</span> = tileSize * <span class=\"p\">(</span><span class=\"mf\">0.5</span> ** <span class=\"p\">(</span>layer - <span class=\"mi\">1</span><span class=\"p\">));</span>\n    \n    previousLayer<span class=\"p\">.</span>forEach<span class=\"p\">(</span><span class=\"n\">tile</span> =&gt; <span class=\"p\">{</span>\n      if <span class=\"p\">(</span>Math<span class=\"p\">.</span>random<span class=\"p\">()</span> &lt; subdivideChance<span class=\"p\">)</span> <span class=\"p\">{</span>\n        tiles<span class=\"p\">.</span>push<span class=\"p\">(</span>\n          <span class=\"p\">{</span> layer<span class=\"p\">,</span> x<span class=\"p\">:</span> tile<span class=\"p\">.</span>x<span class=\"p\">,</span>                 y<span class=\"p\">:</span> tile<span class=\"p\">.</span>y                 <span class=\"p\">},</span>\n          <span class=\"p\">{</span> layer<span class=\"p\">,</span> x<span class=\"p\">:</span> tile<span class=\"p\">.</span>x + layerTileSize<span class=\"p\">,</span> y<span class=\"p\">:</span> tile<span class=\"p\">.</span>y                 <span class=\"p\">},</span>\n          <span class=\"p\">{</span> layer<span class=\"p\">,</span> x<span class=\"p\">:</span> tile<span class=\"p\">.</span>x<span class=\"p\">,</span>                 y<span class=\"p\">:</span> tile<span class=\"p\">.</span>y + layerTileSize <span class=\"p\">},</span>\n          <span class=\"p\">{</span> layer<span class=\"p\">,</span> x<span class=\"p\">:</span> tile<span class=\"p\">.</span>x + layerTileSize<span class=\"p\">,</span> y<span class=\"p\">:</span> tile<span class=\"p\">.</span>y + layerTileSize <span class=\"p\">},</span>\n        <span class=\"p\">)</span>\n      <span class=\"p\">}</span>\n    <span class=\"p\">})</span>\n  <span class=\"p\">}</span>\n  \n  return tiles<span class=\"p\">;</span>\n<span class=\"p\">}</span>\n</code></pre>\n<p>Once we know the positions, we can lay them out in our SVG element.</p>\n\n<p>We need to make sure we scale down smaller tiles to fit, and adjust the position \u2013 remember each Carlson tile only \u201cowns\u201d the red square in the middle, and the wings are meant to spill out of the tile area.\nHere\u2019s the code:</p>\n<pre><code><span class=\"kd\">function</span> <span class=\"n\">drawTruchetTiles</span><span class=\"p\">(</span><span class=\"n\">svg</span><span class=\"p\">,</span> <span class=\"n\">tileTypes</span><span class=\"p\">,</span> <span class=\"n\">tilePositions</span><span class=\"p\">,</span> <span class=\"n\">padding</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n  tilePositions<span class=\"p\">.</span>forEach<span class=\"p\">(</span>c =&gt; <span class=\"p\">{</span>\n    <span class=\"c1\">// We need to invert the tiles every time we subdivide, so we use</span>\n    <span class=\"c1\">// the inverted tiles on even-numbered layers.</span>\n    <span class=\"kd\">let</span> <span class=\"n\">tileName</span> = c<span class=\"p\">.</span>layer % <span class=\"mi\">2</span> === <span class=\"mi\">0</span>\n      <span class=\"p\">?</span> tileTypes<span class=\"p\">[</span>Math<span class=\"p\">.</span>floor<span class=\"p\">(</span>Math<span class=\"p\">.</span>random<span class=\"p\">()</span> * tileTypes<span class=\"p\">.</span>length<span class=\"p\">)]</span> + <span class=\"dl\">\"</span><span class=\"s2\">-inverted</span><span class=\"dl\">\"</span>\n      <span class=\"p\">:</span> tileTypes<span class=\"p\">[</span>Math<span class=\"p\">.</span>floor<span class=\"p\">(</span>Math<span class=\"p\">.</span>random<span class=\"p\">()</span> * tileTypes<span class=\"p\">.</span>length<span class=\"p\">)];</span>\n      \n    <span class=\"c1\">// The full-sized tiles are on layer 1, and every layer below</span>\n    <span class=\"c1\">// that halves the tile size.</span>\n    <span class=\"kd\">const</span> <span class=\"n\">scale</span> = <span class=\"mf\">0.5</span> ** <span class=\"p\">(</span>c<span class=\"p\">.</span>layer - <span class=\"mi\">1</span><span class=\"p\">);</span>\n    \n    <span class=\"c1\">// We don't want to draw a tile exactly at (x, y) because that</span>\n    <span class=\"c1\">// would include the wings -- we add negative padding to offset.</span>\n    <span class=\"c1\">//</span>\n    <span class=\"c1\">// At layer 1, adjustment = padding</span>\n    <span class=\"c1\">// At layer 2, adjustment = padding * 1/2</span>\n    <span class=\"c1\">// At layer 3, adjustment = padding * 1/2 + padding * 1/4</span>\n    <span class=\"c1\">//</span>\n    <span class=\"kd\">const</span> <span class=\"n\">adjustment</span> = -padding * Math<span class=\"p\">.</span>pow<span class=\"p\">(</span><span class=\"mf\">0.5</span><span class=\"p\">,</span> c<span class=\"p\">.</span>layer - <span class=\"mi\">1</span><span class=\"p\">);</span>\n\n    svg<span class=\"p\">.</span>innerHTML += <span class=\"s2\">`\n      &lt;use\n        href=\"</span><span class=\"p\">${</span>tileName<span class=\"p\">}</span><span class=\"s2\">\"\n        x=\"</span><span class=\"p\">${</span>c<span class=\"p\">.</span>x / scale<span class=\"p\">}</span><span class=\"s2\">\"\n        y=\"</span><span class=\"p\">${</span>c<span class=\"p\">.</span>y / scale<span class=\"p\">}</span><span class=\"s2\">\"\n        transform=\"translate(</span><span class=\"p\">${</span>adjustment<span class=\"p\">}</span><span class=\"s2\"> </span><span class=\"p\">${</span>adjustment<span class=\"p\">}</span><span class=\"s2\">) scale(</span><span class=\"p\">${</span>scale<span class=\"p\">}</span><span class=\"s2\">)\"/&gt;`</span><span class=\"p\">;</span>\n  <span class=\"p\">});</span>\n<span class=\"p\">}</span>\n</code></pre>\n\n\n<p>The padding was fiddly and took me a while to work out, but now it works fine.\nThe tricky bits are another reason I like defining my SVGs parametrically \u2013 it forces me to really understand what\u2019s going on, rather than tweaking values until I get something that looks correct.</p>\n\n<h2 id=\"demo\">Demo</h2>\n\n<p>Here\u2019s a drawing that uses this code to draw Carlson truchet tiles:</p>\n\n<figure>\n  <svg class=\"border\" id=\"randomCarlson\" viewBox=\"0 0 48 24\" xmlns=\"http://www.w3.org/2000/svg\">\n    <g id=\"layer-1\" transform=\"translate(-2 -2) \">\n      <use></use>\n      <use y=\"6\"></use>\n      <use y=\"12\"></use>\n      <use x=\"6\"></use>\n      <use x=\"6\" y=\"6\"></use>\n      <use x=\"6\" y=\"12\"></use>\n      <use x=\"6\" y=\"18\"></use>\n      <use x=\"12\"></use>\n      <use x=\"12\" y=\"6\"></use>\n      <use x=\"12\" y=\"12\"></use>\n      <use x=\"12\" y=\"18\"></use>\n      <use x=\"18\" y=\"6\"></use>\n      <use x=\"18\" y=\"12\"></use>\n      <use x=\"24\"></use>\n      <use x=\"24\" y=\"6\"></use>\n      <use x=\"24\" y=\"12\"></use>\n      <use x=\"24\" y=\"18\"></use>\n      <use x=\"30\"></use>\n      <use x=\"30\" y=\"6\"></use>\n      <use x=\"30\" y=\"12\"></use>\n      <use x=\"30\" y=\"18\"></use>\n      <use x=\"36\"></use>\n      <use x=\"36\" y=\"12\"></use>\n      <use x=\"36\" y=\"18\"></use>\n      <use x=\"42\"></use>\n      <use x=\"42\" y=\"6\"></use>\n      <use x=\"42\" y=\"12\"></use>\n      <use x=\"42\" y=\"18\"></use>\n    </g>\n    <g id=\"layer-2\" transform=\"translate(-1 -1) scale(0.5)\">\n      <use x=\"6\" y=\"36\"></use>\n      <use y=\"42\"></use>\n      <use x=\"36\"></use>\n      <use x=\"42\"></use>\n      <use x=\"36\" y=\"6\"></use>\n      <use x=\"42\" y=\"6\"></use>\n      <use x=\"42\" y=\"36\"></use>\n      <use x=\"36\" y=\"42\"></use>\n      <use x=\"72\" y=\"12\"></use>\n      <use x=\"78\" y=\"12\"></use>\n      <use x=\"78\" y=\"18\"></use>\n    </g>\n    <g id=\"layer-3\" transform=\"translate(-0.5 -0.5) scale(0.25)\">\n      <use y=\"72\"></use>\n      <use x=\"6\" y=\"72\"></use>\n      <use y=\"78\"></use>\n      <use x=\"6\" y=\"78\"></use>\n      <use x=\"12\" y=\"84\"></use>\n      <use x=\"18\" y=\"84\"></use>\n      <use x=\"12\" y=\"90\"></use>\n      <use x=\"18\" y=\"90\"></use>\n      <use x=\"72\" y=\"72\"></use>\n      <use x=\"78\" y=\"72\"></use>\n      <use x=\"72\" y=\"78\"></use>\n      <use x=\"78\" y=\"78\"></use>\n      <use x=\"84\" y=\"84\"></use>\n      <use x=\"90\" y=\"84\"></use>\n      <use x=\"84\" y=\"90\"></use>\n      <use x=\"90\" y=\"90\"></use>\n      <use x=\"144\" y=\"36\"></use>\n      <use x=\"150\" y=\"36\"></use>\n      <use x=\"144\" y=\"42\"></use>\n      <use x=\"150\" y=\"42\"></use>\n    </g>\n  </svg>\n  <figcaption>\n    <input id=\"foreground\" name=\"foreground\" type=\"color\" value=\"#000000\" />\n    <label for=\"foreground\">foreground</label>\n    <input id=\"background\" name=\"background\" type=\"color\" value=\"#ffffff\" />\n    <label for=\"background\">background</label>\n  </figcaption>\n  \n</figure>\n\n<p>It was generated by your browser when you loaded the page, and there are so many possible combinations that it\u2019s a unique image.</p>\n\n<p>If you want a different picture, reload the page, or tell the computer to <a href=\"https://alexwlchan.net/2025/truchet-tiles/#randomCarlson\">draw some new tiles</a>.</p>\n\n<p>These pictures put me in mind of an alien language \u2013 something I\u2019d expect to see etched on the wall in a sci-fi movie.\nI\u00a0can imagine eyes, tentacles, roads, and warnings left by a long-gone civilisation.</p>\n\n<p>It\u2019s fun, but not really the tone I want for this site \u2013 I\u2019ve scrapped my plan to use Truchet tiles as header images.\nI\u2019ll save them for something else, and in the meantime, I had a lot of fun.</p>\n\n\n    <p>[If the formatting of this post looks odd in your feed reader, <a href=\"https://alexwlchan.net/2025/truchet-tiles/?ref=rss\">visit the original article</a>]</p>"
            ],
            "link": "https://alexwlchan.net/2025/truchet-tiles/?ref=rss",
            "publishedAt": "2025-12-21",
            "source": "Alex Chan",
            "summary": "<p>I recently read <a href=\"https://nedbatchelder.com/blog/202208/truchet_images.html\">Ned Batchelder\u2019s post</a> about <a href=\"https://en.wikipedia.org/wiki/Truchet_tile\">Truchet tiles</a>, which are square tiles that make nice patterns when you tile them on the plane. I was experimenting with alternative headers for this site, and I thought maybe I\u2019d use Truchet tiles. I decided to scrap those plans, but I still had fun drawing some pretty pictures.</p> <p>One of the simplest Truchet tiles is a square made of two colours:</p> <svg viewBox=\"0 0 0 0\" xmlns=\"http://www.w3.org/2000/svg\"> <defs> <rect class=\"bg\" height=\"100\" width=\"100\"></rect> <path class=\"fg\" d=\"M 0 0 l 100 100 l -100 0 Z\"></path> <use transform=\"rotate(90 50 50)\"></use> <use transform=\"rotate(180 50 50)\"></use> <use transform=\"rotate(270 50 50)\"></use> <!-- The base of the truchet tile is: - a white rectangle - four outer white \"wings\" - four inner black circles which connect to other tiles --> <svg id=\"base_background\" xmlns=\"http://www.w3.org/2000/svg\"> <rect height=\"6\" width=\"6\" x=\"2\" y=\"2\"></rect> <circle cx=\"2\" cy=\"2\" r=\"2\"></circle> <circle cx=\"8\" cy=\"2\" r=\"2\"></circle> <circle cx=\"2\" cy=\"8\" r=\"2\"></circle> <circle cx=\"8\" cy=\"8\" r=\"2\"></circle> </svg> <svg id=\"base_foreground\" xmlns=\"http://www.w3.org/2000/svg\"> <circle cx=\"2\" cy=\"5\" r=\"1\"></circle> <circle cx=\"8\" cy=\"5\" r=\"1\"></circle> <circle cx=\"5\" cy=\"2\" r=\"1\"></circle> <circle cx=\"5\" cy=\"8\" r=\"1\"></circle> </svg> <use class=\"bg\"></use> <use class=\"fg\"></use> <use class=\"fg\"></use> <use class=\"bg\"></use> <!-- Define some of the basic shapes that are used in the Carlson",
            "title": "Drawing Truchet tiles in SVG"
        },
        {
            "content": [
                "<p>Despite being the highlight of every major launch, benchmarks are the most widely misunderstood part of the AI ecosystem.</p><p>Every few weeks, we get a new press release featuring a bar chart where the new model conveniently towers over the previous state-of-the-art&#8212;whether it&#8217;s Anthropic&#8217;s <a href=\"https://www.anthropic.com/news/claude-opus-4-5\">Claude Opus 4.5</a>, OpenAI&#8217;s <a href=\"https://openai.com/index/introducing-gpt-5-2/\">GPT-5.2</a> or Google&#8217;s <a href=\"https://blog.google/products/gemini/gemini-3/#gemini-3\">Gemini 3</a>. The narrative is always &#8220;Number Go Up,&#8221; implying a universal increase in intelligence.</p><p>In this post, I want to demystify how these benchmarks actually work, expose where they are misleading, and dig into the specific popular evaluations you&#8217;ll see in launch posts. This post was inspired by the many confused Kalshi/Polymarket comments on recent AI benchmark markets.</p><h2>The Benchmark Stack</h2><p>When we talk about a model&#8217;s performance, we are rarely talking about the raw model weights in isolation. A benchmark score is the output of a specific function: <code>f(model, settings, harness, scoring)</code>. If you change any variable in that tuple, the score changes&#8212;often dramatically. To understand why a model &#8220;wins,&#8221; you have to look at the entire stack.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!yez9!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbd408e8f-98dc-4b3f-87c5-655ffbbc8f36_1024x559.jpeg\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"331.3603515625\" src=\"https://substackcdn.com/image/fetch/$s_!yez9!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbd408e8f-98dc-4b3f-87c5-655ffbbc8f36_1024x559.jpeg\" title=\"\" width=\"607\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a><figcaption class=\"image-caption\">A Nano Banana illustration of all the various components and levers between a model and the actual score reported.</figcaption></figure></div><ol><li><p><strong>The Model </strong>&#8212; We tend to use shorthand names like &#8220;GPT-5.2&#8221; or &#8220;Claude 4.5 Sonnet,&#8221; but in the context of a benchmark, you are really measuring a specific combination of runtime settings.</p><ol><li><p><strong>Sampling Settings:</strong> Parameters like temperature, top_p, and max_tokens fundamentally change how the output of the model is encoded into text.</p></li><li><p><strong>Reasoning Strength:</strong> A model often performs differently depending on its &#8220;thinking budget.&#8221; You will increasingly see suffixes like <code>-xhigh</code> or <code>-16k-thinking</code> denoting a specific configuration where the model is allowed to generate reasoning tokens before responding or using a tool.</p></li></ol></li><li><p><strong>The Harness</strong> &#8212; This is the code that wraps the model to facilitate the test. At the end of the day, LLMs are still text+image -in/text -out, so a harness is required to translate \"solve this issue\" into actual API calls.</p><ol><li><p><strong>Tools:</strong> Does the harness allow the model to use a coding environment to test or calculate things before answering? Does it provide internet search access? Are the tool schemas well defined and do they return intuitive responses?</p></li><li><p><strong>Prompting:</strong> Are the system prompts vague or specific? Do they include examples (aka few-shot)? Are the provided instructions and constraints consistent?</p></li><li><p><strong>Implementation</strong>: Are we running the model in a agentic tool-loop or just taking the first output? Are we post-processing structured outputs or counting minor formatting errors as hard failures? Do we structure the problem as an append-only conversation or do something else?</p></li></ol></li><li><p><strong>The Scoring Setup</strong> &#8212; How we grade the model can be just as critical as the model itself. This comes down to what we count (the metric) and who does the counting (the judge).</p><ol><li><p><strong>The Pass:</strong> You&#8217;ll see pass@k which means &#8220;did it get it right with K chances&#8221; (commonly &#8220;pass@1&#8221;) or pass^k which often means &#8220;did it get it right consistently K independent times&#8221; (much harder).</p></li><li><p><strong>The Judges (Programmatic vs. LLM):</strong> Programmatic judges (unit tests, regex, exact-matches-ground-truth-answer) are objective but brittle&#8212;a correct code snippet formatted slightly wrong gets a zero. LLM-as-a-Judge captures nuance but introduces potential bias and indeterminism.</p></li></ol></li></ol><p>My bet would be that if you just varied each of these independently just a bit, it would completely re-arrange the top-5 for most benchmarks.</p><p>It&#8217;s hard for me to take benchmarks too seriously that don&#8217;t have an agentic harness (i.e. the model can execute code and tools in order to solve a task) or reasoning enabled since those are becoming fundamental to how modern LLMs solve tasks.</p><h2>Misleading Scores</h2><p>Benchmark scores are often noisy estimates, not precise measurements. When a new model claims to beat by x%, the significance of that margin evaporates when you look closer at how it might&#8217;ve been measured. From reading the footnotes of releases over the past few years and digging through benchmark source code, I&#8217;ve found a decent number unintuitive practices.</p><ol><li><p><strong>Measurement Noise &#8212;</strong> Benchmarks are treated like precise instruments, but the process of measuring model performance is often surprisingly fragile and inconsistent.</p><ol><li><p><strong>Broken Tests:</strong> The code powering these benchmarks is often written by researchers, and \"research code\" tends to be... scrappy. It is not uncommon for a &#8220;failure&#8221; to actually be a bug in the test runner, or for a correct solution to be rejected because the regex was too strict. It&#8217;s also possible for certain model provider scores to be handicapped due to API errors and rate limits that occurred during evaluation.</p></li><li><p><strong>Variance:</strong> LLMs often act stochastic <a href=\"https://thinkingmachines.ai/blog/defeating-nondeterminism-in-llm-inference/\">even with fixed seeds and decoding settings</a>. Just running the exact model stack several times could sway certain benchmarks several percentage points. You may sometimes seen confidence intervals but it&#8217;s still extremely common to not report them.</p></li></ol></li><li><p><strong>Funky Reporting</strong> &#8212; Labs are under immense pressure to show state-of-the-art performance and each choose slightly different ways to report metrics. These differences can be quite misleading for folks looking for an apples-to-apples comparison.</p><ol><li><p><strong>Multi-pass Variability:</strong> Labs may report different k-values for a pass@k benchmark that may mislead folks comparing values across model releases by different release posts. </p></li><li><p><strong>Harness Tweaking:</strong> Labs sometimes modify the benchmark code itself. This can range from \"fixing\" (deleting) test cases they deem unfair, to appending system prompts specifically designed to guide the model through that specific test's quirks. They may also modify the harness to leverage parallel test-time compute (this is different from multi-pass variability in that the consensus of the agents is used as the score for a single run rather than just picking the best run after the fact).</p></li><li><p><strong>Stale Baselines:</strong> Some benchmarks change overtime due to bug fixes, fresh data, or even provider-side API stability fixes. Comparing a brand new model against a competitor&#8217;s reported score from X months ago might not be an identical comparison.</p></li></ol></li><li><p><strong>Real Life Discrepancies</strong> &#8212; The model that gets benchmarked might not act like the model you experience in production.</p><ol><li><p><strong>Model Mismatch:</strong> The version of the model used to evaluate might not be identical to the one released on the API. This could be due to differences between a pre-release and release checkpoint caused by alignment-tuning, quantization, or even inference hardware differences.</p></li><li><p><strong>Efficiency Blindspots:</strong> Most benchmark score reports don&#8217;t come with latency and cost. Especially in high reasoning and parallel-compute setups these can pose meaningfully extreme trade-offs between intelligence and what&#8217;s actually feasible in a production application.</p></li><li><p><strong>Contamination:</strong> It&#8217;s very difficult to truly guarantee a model never saw questions or answers from benchmarks during training. There are plenty of techniques used to avoid obvious cases of this (e.g. canary strings), but it&#8217;s a bit of a grey area if/when these labs adjust training datasets to mirror benchmark adjacent-tasks.</p></li><li><p><strong>Unscored Failures:</strong> Benchmarks often check for the <em>presence</em> of a correct answer, not the <em>absence</em> of a side effect. A coding agent that deletes your database and <em>then</em> returns the correct code to pass tests still &#8220;passes&#8221; the benchmark.</p></li></ol></li></ol><p>So yeah&#8230; there&#8217;s a lot of ways benchmarks can be broken.</p><div class=\"subscription-widget-wrap-editor\"><div class=\"subscription-widget show-subscribe\"><div class=\"preamble\"><p class=\"cta-caption\">Thanks for reading Shrivu&#8217;s Substack! Subscribe for free to receive new posts and support my work.</p></div><form class=\"subscription-widget-subscribe\"><input class=\"email-input\" name=\"email\" tabindex=\"-1\" type=\"email\" /><input class=\"button primary\" type=\"submit\" value=\"Subscribe\" /><div class=\"fake-input-wrapper\"><div class=\"fake-input\"></div><div class=\"fake-button\"></div></div></form></div></div><h2>Benchmarks</h2><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!rtJB!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F38206bbc-0bb0-4381-9517-11000ec7e791_2014x1066.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"324.0741758241758\" src=\"https://substackcdn.com/image/fetch/$s_!rtJB!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F38206bbc-0bb0-4381-9517-11000ec7e791_2014x1066.png\" width=\"612\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a><figcaption class=\"image-caption\">My personal vibes-based AI benchmark tier list. I of course appreciate the effort of all the contributors of these benchmarks.</figcaption></figure></div><p>Some takes on several popular benchmarks<a class=\"footnote-anchor\" href=\"https://blog.sshh.io/feed#footnote-1\" id=\"footnote-anchor-1\" target=\"_self\">1</a>. Pros and cons are my subjective opinions around what I consider makes a high-signal interpretable benchmark.</p><h3><a href=\"https://lmarena.ai/leaderboard/text\">LMArena (Text Arena)</a></h3><p>A crowdsourced platform where users prompt two anonymous models side-by-side and vote on the better response. Instead of relying on static expert examples, it captures human &#8220;vibes&#8221;&#8212;measuring general helpfulness and text response usefulness&#8212;and uses a <a href=\"https://en.wikipedia.org/wiki/Bradley%E2%80%93Terry_model\">Bradley-Terry statistical model</a> to convert these head-to-head votes into a <a href=\"https://en.wikipedia.org/wiki/Elo_rating_system\">ranked Elo rating</a> (somewhat similar to Elo systems in video games and chess).</p><p>The main flaw (besides saturation) is the gap between the <em>product</em> and the <em>model</em>. When you use LMArena, you aren't testing Claude.ai against ChatGPT; you are testing the raw LLM with a fairly generic \"You are a helpful assistant\" system prompt. It measures the default behavior of these models which isn&#8217;t really how most interact with them. Despite this it&#8217;s a decent signal for the &#8220;popular vote&#8221; in the LLM space.</p><ul><li><p><strong>Pros: </strong>It is a rolling benchmark (always updating), directly measures human preference, and allows for style control.</p></li><li><p><strong>Cons: </strong>The data is bloated by bad/easy questions (leading to saturation), it is prone to unfair lab testing (see <a href=\"https://arxiv.org/abs/2504.20879\">The Leaderboard Illusion</a>), and it is purely simple chat-based (as opposed to agentic). The scores are relative, and the fixed system prompts can heavily influence the outcome.</p></li></ul><p><strong>Example Question:</strong></p><blockquote><p>&#8220;what do you know about real estate&#8221;</p></blockquote><h3><a href=\"https://www.swebench.com/\">SWE-Bench (Verified)</a></h3><p>A dataset of real-world GitHub issues (bugs and feature requests) drawn from popular Python repositories like django and scikit-learn. The \"Verified\" subset has filtered out tasks with vague requirements or broken environments to create a cleaner signal. It tests if a model can navigate an existing codebase, reproduce a bug, and write a patch that passes tests without breaking other features.</p><p>This is still one of the most realistic benchmarks for feature-based software engineering. My biggest gripe is that SWE-Bench actually <em>underestimates</em> today&#8217;s coding capabilities. The official harness is primitive compared to modern tools like Codex or Claude Code, which use task-planning, <a href=\"https://en.wikipedia.org/wiki/Language_Server_Protocol\">LSP integrations</a>, and <a href=\"https://agents.md/\">AGENTS.md</a>.</p><ul><li><p><strong>Pros:</strong> Allows for custom scaffolding (agentic and Bring-Your-Own-Harness), requires execution traces to be submitted, and uses unit-test-based validation. The requirements are vague (based on GitHub issues), making it fairly realistic.</p></li><li><p><strong>Cons:</strong> Submissions are restricted (which is why the leaderboard is missing a lot compared to Terminal-Bench), and it is based on open-source repos (high potential contamination) without AI context files.</p></li></ul><p><strong>Example Question:</strong></p><blockquote><p>https://github.com/scikit-learn/scikit-learn<br /><br />&#8216;TypeError&#8217; when fitting &#8216;HuberRegressor&#8217; with boolean predictors<br /><br />Steps/Code to Reproduce<br />&#8230;.<br /><br />Expected Results<br />&#8230;</p></blockquote><h3><a href=\"https://www.tbench.ai/\">Terminal-Bench (2.0)</a></h3><p>A sandbox environment that tests an agent's ability to use a command-line interface (CLI) to solve a variety of system tasks. Instead of just writing code snippets, the model interacts directly with a Linux shell&#8212;installing packages, managing files, and running git commands&#8212;to test system admin skills and coding capabilities.</p><p>Terminal-Bench feels a bit more modern than SWE-Bench but also a bit easier &#8212; I wouldn&#8217;t expect +x% of this benchmark to always correlate with real work enterprise coding performance.</p><ul><li><p><strong>Pros:</strong> Allows for custom scaffolding (agentic and BYO-Harness). I personally prefer the more clear but potentially less realistic task prompts here over SWE-Bench.</p></li><li><p><strong>Cons:</strong> The tasks lean toward the simpler end (e.g., &#8220;build a script&#8221;) rather than building complex applications or working within massive codebases.</p></li></ul><p><strong>Example Question:</strong></p><blockquote><p>You need to debug and fix a nodejs environment conflict for a web development project. The project requires specific versions of packages that are conflicting with each other.</p><p>You will install nodejs (20.19.3) and use npm for package management and do the following:<br />&#8230;</p></blockquote><h3><a href=\"https://sierra.ai/resources/research/tau-squared-bench\">Tau2-Bench</a></h3><p>A conversational agent benchmark simulating customer service interactions in the retail, airline, and telecom domains. Uniquely, it tests longish-horizon consistency: the agent must update a database correctly after a long conversation with a simulated user who may change their mind or provide partial info, testing policy adherence and tool use under ambiguity.</p><p>Tau-Bench is one of my favorite benchmarks that actually measures how good a model is at being put into a fairly modern agentic harness for real-world looking tasks and tools. I&#8217;m also a huge fan of the pass^k which is an underrated way of measuring not just how good a model is but how consistent it can be. The benchmark uses a user-simulator model which adds an adversarial element that forces the model into more complex social and tool-use reasoning situations.</p><ul><li><p><strong>Pros:</strong> One of the few non-code agent tool-calling benchmarks. It features a fixed harness with well-designed tools, measures pass^k (consistency), and measures robustness to weird environments.</p></li><li><p><strong>Cons:</strong> It uses an LLM-based user simulator, which adds non-determinism and introduces an additional evaluation hyperparameter. Evals are based purely on database state changes.</p></li></ul><p><strong>Example Question:</strong></p><blockquote><p>Agent Domain Policy</p><p>The current time is 2025-02-25 12:08:00 EST. As a telecom agent, you can help users with technical support. ...<br /><br />User Instruction</p><p>You mobile data is not working properly. It is very slow. You want to fix it and get excellent internet speed on your phone. ...</p></blockquote><h3><a href=\"https://andonlabs.com/evals/vending-bench-2\">Vending-Bench 2</a></h3><p>I think of this as \"Tau2-Vending++.\" It&#8217;s a complex simulation where the model acts as a business owner managing a vending machine company over a simulated year. It's given a budget and must use tools (email, browser) to negotiate prices with suppliers, manage inventory, and handle customer refunds&#8212;testing strategic planning and robustness against adversarial vendors who might overcharge.</p><p>This agentic benchmark doesn&#8217;t just test tool-use but strategy and harsh adversarial robustness. In a typical benchmark, the setup will evaluate the adherence to a pre-defined strategy prompt but in this one the model&#8217;s advantage is not just instruction following but effectively it&#8217;s strategic creativity.</p><ul><li><p><strong>Pros:</strong> A very unique, open-ended agentic benchmark that requires actual strategy. The &#8220;good&#8221;-baseline is currently far above agents. It also measures robustness to weird environments.</p></li><li><p><strong>Cons:</strong> They do not publish the scaffolding or traces (as far as I know), making it difficult to audit.</p></li></ul><p><strong>Example Question:</strong></p><blockquote><p>You are Charles Paxton, an autonomous AI agent designed to manage a vending machine business.</p><p>&#8230;</p><p>Your primary goal is to maximize profits and your bank account balance over the course of one year. You will be judged solely on your bank account balance at the end of one year of operation.</p><p>&#8230;</p><p>- Customers can pay using cash or credit card. Credit card payments will show up in your account automatically within a day, while cash must be collected from the machine manually.</p><p>&#8230;</p></blockquote><h3><a href=\"https://arcprize.org/arc-agi/2/\">ARC-AGI-2</a></h3><p>A visual puzzle benchmark that explicitly targets &#8220;broad generalization&#8221; rather than knowledge retrieval. Models must infer abstract rules from a few examples and apply them to a test grid, relying on core priors (like objectness, symmetry, or physics) that cannot be easily memorized. It essentially tests fluid intelligence and few-shot program synthesis.</p><p>Naming is important and I think the &#8220;AGI&#8221; in the name really throws people off. I would call it &#8220;Grid-Puzzle-Bench&#8220; but that wouldn&#8217;t be as exciting. I consider this a hard reasoning task that tests a model&#8217;s ability to effectively and efficiently use it&#8217;s thinking tokens. While less true today, this benchmark really shined as a &#8220;simple&#8221; task that would really trip up even the best reasoning models. As of writing we&#8217;re up-to 50% vs the 100% human-baseline.</p><ul><li><p><strong>Pros:</strong> The human baseline is still far above agents, making it a good target. It allows for BYO-Harness and is an excellent test for pure reasoning models.</p></li><li><p><strong>Cons:</strong> The test is fairly contrived (in my opinion, a model+harness I would consider as &#8220;AGI&#8221; could still be bad at this specific puzzle format).</p></li></ul><p><strong>Example Question:</strong></p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!c9d-!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa71cd3eb-6239-407b-b88f-22ef97d3716d_964x934.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"314.88589211618256\" src=\"https://substackcdn.com/image/fetch/$s_!c9d-!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa71cd3eb-6239-407b-b88f-22ef97d3716d_964x934.png\" width=\"325\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a><figcaption class=\"image-caption\">A screenshot of an <a href=\"https://arcprize.org/arc-agi/2/\">ARC-AGI-2 example question</a>.</figcaption></figure></div><h3><a href=\"https://livebench.ai/#/\">LiveBench</a></h3><p>A composite benchmark designed to be &#8220;contamination-free&#8221; by continuously updating its set of questions extracted from recent arXiv papers, news, and math competitions. Because the questions are brand new, models could not have seen them during pre-training, ensuring the benchmark tests the ability to solve novel problems rather than reciting memorized solutions.</p><p>It&#8217;s a great concept, but I think the harnesses and the dataset the benchmark uses just doesn&#8217;t really compete with a lot of these other benchmarks for signal. I&#8217;m a bit skeptical of the questions and I think especially for the &#8220;Coding Average&#8221; category people are easily misled into thinking the harness used is anywhere near what agents use today<a class=\"footnote-anchor\" href=\"https://blog.sshh.io/feed#footnote-2\" id=\"footnote-anchor-2\" target=\"_self\">2</a>.</p><ul><li><p><strong>Pros:</strong> Regularly updated questions ensure the model hasn&#8217;t memorized the answers during training.</p></li><li><p><strong>Cons:</strong> Aside from the agentic coding section, most tests are effectively single-pass, meaning the scaffolding is poor. The questions within specific domains can also be quite templated which reduces category-specific generalization implied by a high score.</p></li></ul><p><strong>Example Question:</strong></p><blockquote><p>You are given a 0-indexed integer array `nums` containing positive integers.</p><p>Your task is to minimize the length of `nums` by performing the following operations any number of times (including zero)</p><p>...</p><p>### Format:</p><p>You will use the following starter code ...</p></blockquote><h3><a href=\"https://agi.safe.ai/\">Humanity&#8217;s Last Exam (HLE)</a></h3><p>A massive dataset of difficult, closed-ended questions sourced from experts across dozens of academic fields. It targets the &#8220;expert gap&#8221; by designing questions that are only answerable by someone with graduate-level knowledge in that specific field (e.g., advanced math, law, biology), effectively filtering out anything easy enough for current models to solve via simple training data recall.</p><p>I would consider this the current best knowledge benchmark (vs GPQA).</p><ul><li><p><strong>Pros:</strong> Fairly hard, with a significant gap between models and human domain experts. It is multi-modal and open-source (BYO-Harness).</p></li><li><p><strong>Cons:</strong> It is restricted to narrow, academic tasks.</p></li></ul><p><strong>Example Question:</strong></p><blockquote><p>Hummingbirds within Apodiformes uniquely have a bilaterally paired oval bone, a sesamoid embedded in the caudolateral portion of the expanded, cruciate aponeurosis of insertion of m. depressor caudae. How many paired tendons are supported by this sesamoid bone? Answer with a number.</p></blockquote><h3><a href=\"https://arxiv.org/abs/2311.12022\">GPQA (Diamond)</a></h3><p>&#8220;Graduate-Level Google-Proof Q&amp;A.&#8221; This is a set of difficult biology, physics, and chemistry questions designed to be &#8220;Google-proof&#8221;&#8212;meaning even a smart human with internet access would struggle to answer them quickly without domain expertise. It tests expert-level scientific reasoning and the ability to filter out plausible-sounding but wrong distractors.</p><ul><li><p><strong>Pros:</strong> Open-source BYO-Harness (mostly evaluated with no tools).</p></li><li><p><strong>Cons:</strong> Purely multiple-choice questions covering narrow tasks. At this point fairly saturated.</p></li></ul><p><strong>Example Question:</strong></p><blockquote><p>Methylcyclopentadiene was allowed to react with methyl isoamyl ketone and a catalytic amount of pyrrolidine. A bright yellow, cross-conjugated polyalkenyl hydrocarbon product formed [...] How many chemically distinct isomers make up the final product (not counting stereoisomers)?</p><p>(a) 2 (b) 16 (c) 8 (d) 4</p></blockquote><h3><a href=\"https://huggingface.co/datasets/openai/MMMLU\">MMMLU</a></h3><p>A massive multilingual evaluation dataset released by OpenAI that adapts the classic MMLU benchmark (57 subjects covering STEM, humanities, and more) across 14 distinct languages. Uniquely, it relies on professional human translators rather than machine translation, ensuring that evaluations in low-resource languages (like Yoruba or Swahili) reflect actual model capabilities rather than translation artifacts.</p><p>This is one of the few commonly reported benchmarks that tests for capabilities in non-English.</p><ul><li><p><strong>Pros:</strong> High-quality signal for non-English performance, and it covers a wide breadth of topics (from elementary math to law).</p></li><li><p><strong>Cons:</strong> It remains a static multiple-choice test. At this point fairly saturated.</p></li></ul><p><strong>Example Question:</strong></p><blockquote><p>Zwei unendlich viele parallele Metallplatten sind mit gleicher Oberfl&#228;chenladungsdichte und gleicher Polarit&#228;t geladen. Das elektrische Feld im Spalt zwischen den Platten ist&#8230;</p><p>(a) &#8230; (b) &#8230;</p></blockquote><h3><a href=\"https://huggingface.co/datasets/openai/mrcr\">MRCR</a></h3><p>&#8220;Multi-round Co-reference Resolution.&#8221; A provider-dependent technique (OpenAI and Google both have versions) used to test long-context handling. It is essentially a \"needle-in-a-haystack\" test where a model must track a specific entity or instruction across a massive context window, requiring it to \"reason\" about the order of events rather than just retrieving a keyword.</p><p>Long-context understanding is inherently difficult to test for and this is the latest technique for measuring it. The design accounts for all the various ways previous long-context tests could be gamed (pre-training data, lucky hallucinations, out-of-domain filtering) but is still fundamentally highly synthetic compared to real world long-context tasks.</p><ul><li><p><strong>Pros:</strong> Much harder for the model to game that previous techniques; well-designed for testing context window limits and reasoning.</p></li><li><p><strong>Cons:</strong> Still fairly contrived/synthetic and not agentic.</p></li></ul><p><strong>Example Question:</strong></p><blockquote><p>User: Write a poem about tapirs</p><p>Assistant: (first poem about tapirs)</p><p>User: Write a blog post about rocks</p><p>Assistant: (first blog post about rocks)</p><p>User: Write a poem about tapirs</p><p>Assistant: (second poem about tapir)</p><p>User: Write a social media post about tapirs</p><p>Assistant: (first social media post about tapirs)</p><p>User: Write a blog post about rocks</p><p>Assistant: (second blog post about rocks)</p><p>User: Prepend aYooSG8CQg to the 2nd (1 indexed) poem about tapirs. Do not include any other text in your response.</p><p>Assistant: aYooSG8CQg(2nd poem about tapirs)</p></blockquote><h3><a href=\"https://metr.org/blog/2025-03-19-measuring-ai-ability-to-complete-long-tasks/\">METR Time Horizons</a></h3><p>A measurement framework that estimates how long a model can autonomously work on a task before failing. Instead of just measuring accuracy, it measures \"autonomy duration\"&#8212;can the model do a task that takes an expert human 30 minutes? 2 hours?&#8212;a model&#8217;s ability to perform long-horizon agentic tasks.</p><p><strong>Example Question</strong></p><blockquote><p>8.5h (estimate) &#183; MLE training/finetuning  &#183; public problem &#183; &lt;1 year of experience</p><p>Complete machine learning bootcamp exercises covering topics from PyTorch basics to transformer interpretability, with each task requiring implementation of ML algorithms and passing provided unit tests.</p></blockquote><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!osYZ!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6d1917df-206a-4797-ab2e-98cc0c2a2b8e_1595x933.jpeg\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"368.65384615384613\" src=\"https://substackcdn.com/image/fetch/$s_!osYZ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6d1917df-206a-4797-ab2e-98cc0c2a2b8e_1595x933.jpeg\" width=\"630\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a><figcaption class=\"image-caption\">The current progress on METR&#8217;s benchmark from a <a href=\"https://x.com/METR_Evals/status/2002203627377574113/photo/1\">recent tweet</a>.</figcaption></figure></div><p>They effectively take several benchmarks with tasks annotated with human-time-to-complete and compute a model&#8217;s success rate on various time buckets. The bucket where the model has an estimated 50% success rate becomes the human-time equivalent time horizon.</p><p>While a pretty cool idea, I&#8217;d consider it the most overhyped and misunderstood benchmark<a class=\"footnote-anchor\" href=\"https://blog.sshh.io/feed#footnote-3\" id=\"footnote-anchor-3\" target=\"_self\">3</a>. Some things worth noting:</p><ul><li><p>The datasets used are exclusively software engineering and scripting tasks which are a fairly narrow domain if compared to all types of work or even all modern agentic tasks (RE-Bench, HCAST, SWAA, a more recent iteration uses SWE-Bench).</p></li><li><p>The harness used for evaluation is fixed and pretty far from modern coding harnesses (e.g. compared to Terminal-Bench). I&#8217;d expect this to significantly impact both the absolute time horizons and the relative performance of models from different labs.</p></li><li><p>The viral \"capabilities are doubling every X months\" claim is empirically true based on their data, but the data itself is weird. First, the dataset is quite sparse for tasks taking &gt;8 human-hours. It is hard to make broad claims about \"long-horizon\" autonomy when we have so few data points at the tail end of the curve. Second, I&#8217;m skeptical that this experimental setup can reasonably approximate long horizon human work which can be async, under-specified, and adversarial (or collaborative) &#8212; things not accounted for in the source benchmarks.</p></li><li><p>The time-bucket estimation is done from a fairly small number of samples with a logistic regression and if you look closely (on a linear axis) the error bars are massive. Additionally, given there are less samples at larger time horizons I&#8217;d expect them to grow those bars to go even larger.</p></li></ul><p>The right way to interpret this chart isn't \"AI is exploding in long horizon general intelligence,\" but rather \"AI is getting better at the specific hard software engineering tasks.&#8221; It&#8217;s strange that solving 80% of SWE-Bench effectively converts into \"~4 hours Effective Time Horizon,\" and then <em>that</em> derived metric becomes the viral headline. I wouldn&#8217;t be surprised if you applied the same methodology to Terminal-Bench or Vending-Bench you might get an even flashier curve.</p><h2>Conclusion</h2><p>While LLMs are marketed as &#8220;general purpose,&#8221; every lab has a distinct personality&#8212;and this shows in where they perform best and what benchmarks they pick to show. </p><ul><li><p><strong>OpenAI:</strong> Typically lean into reasoning and math. More recently coming closer to Anthropic on agentic benchmarks.</p></li><li><p><strong>Anthropic:</strong> They focus intensely on agentic, coding, and tool-use.</p></li><li><p><strong>Google DeepMind:</strong> Fairly well-rounded, but often standout in multimodal and long-context capabilities.</p></li><li><p><strong>xAI:</strong> They recently have tended to focus on reasoning and conversational quality.</p></li></ul><p>So, how do you actually navigate this noise?</p><ol><li><p><strong>Look at the Aggregate:</strong> Don&#8217;t obsess over a 1-2% lead on one benchmark. Ask: Does this model consistently score high across benchmarks in the domain I care about?</p></li><li><p><strong>Look at the Relative:</strong> Compare within the same model family or lab. How did the score change from <code>v1</code> to <code>v2</code>? This tells you the trajectory of the lab&#8217;s research and what they could be prioritizing.</p></li><li><p><strong>Verify with Your Own Tasks:</strong> The only benchmark that matters at the end of the day is <em>your</em> workload. Use the models yourself, varying your harness (swap models in Cursor, try the free tier of the various chat web UIs, etc.) and the model (GPT, Claude, Gemini, Grok). I don&#8217;t think you need to be extremely scientific about it to build a sense for where these models shine and in what harnesses.</p></li></ol><p>In the future, expect benchmarks to get more reflective of real world economic work, and significantly more agentic with performance measured not just based on the model but also with respect to its native harness<a class=\"footnote-anchor\" href=\"https://blog.sshh.io/feed#footnote-4\" id=\"footnote-anchor-4\" target=\"_self\">4</a>.</p><div class=\"subscription-widget-wrap-editor\"><div class=\"subscription-widget show-subscribe\"><div class=\"preamble\"><p class=\"cta-caption\">Thanks for reading Shrivu&#8217;s Substack! Subscribe for free to receive new posts and support my work.</p></div><form class=\"subscription-widget-subscribe\"><input class=\"email-input\" name=\"email\" tabindex=\"-1\" type=\"email\" /><input class=\"button primary\" type=\"submit\" value=\"Subscribe\" /><div class=\"fake-input-wrapper\"><div class=\"fake-input\"></div><div class=\"fake-button\"></div></div></form></div></div><div class=\"footnote\"><a class=\"footnote-number\" contenteditable=\"false\" href=\"https://blog.sshh.io/feed#footnote-anchor-1\" id=\"footnote-1\" target=\"_self\">1</a><div class=\"footnote-content\"><p>There are plenty of benchmarks I missed in this list but I tried to pick the ones that are commonly reported across labs and the ones I see most being discussed on social media. If I&#8217;m missing one that&#8217;s important to you, let me know and I can try to edit it into the post retroactively.</p></div></div><div class=\"footnote\"><a class=\"footnote-number\" contenteditable=\"false\" href=\"https://blog.sshh.io/feed#footnote-anchor-2\" id=\"footnote-2\" target=\"_self\">2</a><div class=\"footnote-content\"><p>This is tripping up a lot of people who put money into <a href=\"https://kalshi.com/markets/kxcodingmodel/best-ai-coding-model/kxcodingmodel-26jan\">&#8220;Which AI company will have the best coding model&#8221;</a> on both Kalshi and Polymarket who expected &#8220;coding&#8221; to actually represent real world coding performance. I made a lot of money here just buying lots of OpenAI at the lowest points since they typically beat other labs on pure reasoning single-step harnesses (even if I think Claude is the king of coding). </p></div></div><div class=\"footnote\"><a class=\"footnote-number\" contenteditable=\"false\" href=\"https://blog.sshh.io/feed#footnote-anchor-3\" id=\"footnote-3\" target=\"_self\">3</a><div class=\"footnote-content\"><p>To be clear, most of these are called out clearly on the <a href=\"https://metr.org/blog/2025-03-19-measuring-ai-ability-to-complete-long-tasks/\">METR website</a> . It&#8217;s likely most folks making substantial claims about the data have not totally read it or just share the graph.</p></div></div><div class=\"footnote\"><a class=\"footnote-number\" contenteditable=\"false\" href=\"https://blog.sshh.io/feed#footnote-anchor-4\" id=\"footnote-4\" target=\"_self\">4</a><div class=\"footnote-content\"><p>If you can&#8217;t already tell from past posts, I&#8217;m a big Claude Code fan at this point in time so any benchmark that shows Opus 4.5 performance in a scaffolding that&#8217;s clearly worse or less appropriate than Claude Code (aka Anthropic Agents SDK) &#8212; I&#8217;m very skeptical.</p></div></div>"
            ],
            "link": "https://blog.sshh.io/p/understanding-ai-benchmarks",
            "publishedAt": "2025-12-21",
            "source": "Shrivu Shankar",
            "summary": "<p>Despite being the highlight of every major launch, benchmarks are the most widely misunderstood part of the AI ecosystem.</p><p>Every few weeks, we get a new press release featuring a bar chart where the new model conveniently towers over the previous state-of-the-art&#8212;whether it&#8217;s Anthropic&#8217;s <a href=\"https://www.anthropic.com/news/claude-opus-4-5\">Claude Opus 4.5</a>, OpenAI&#8217;s <a href=\"https://openai.com/index/introducing-gpt-5-2/\">GPT-5.2</a> or Google&#8217;s <a href=\"https://blog.google/products/gemini/gemini-3/#gemini-3\">Gemini 3</a>. The narrative is always &#8220;Number Go Up,&#8221; implying a universal increase in intelligence.</p><p>In this post, I want to demystify how these benchmarks actually work, expose where they are misleading, and dig into the specific popular evaluations you&#8217;ll see in launch posts. This post was inspired by the many confused Kalshi/Polymarket comments on recent AI benchmark markets.</p><h2>The Benchmark Stack</h2><p>When we talk about a model&#8217;s performance, we are rarely talking about the raw model weights in isolation. A benchmark score is the output of a specific function: <code>f(model, settings, harness, scoring)</code>. If you change any variable in that tuple, the score changes&#8212;often dramatically. To understand why a model &#8220;wins,&#8221; you have to look at the entire stack.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!yez9!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbd408e8f-98dc-4b3f-87c5-655ffbbc8f36_1024x559.jpeg\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"331.3603515625\" src=\"https://substackcdn.com/image/fetch/$s_!yez9!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbd408e8f-98dc-4b3f-87c5-655ffbbc8f36_1024x559.jpeg\" title=\"\" width=\"607\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\"",
            "title": "Understanding AI Benchmarks"
        }
    ],
    "lookbackDays": 1,
    "publishDate": "2025-12-21"
}