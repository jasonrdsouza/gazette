{
    "articles": [
        {
            "content": [
                "<p>Hi friends,</p>\n<p>In January, Scour scoured <strong>805,241 posts</strong> from <strong>16,555 feeds</strong> (939 were newly added).</p>\n<p>I also rolled out a lot of new features that I'm excited to tell you about. Maybe because of some of these, I found more posts than usual that I thought were especially worth sharing. You can find them at the bottom of this post. Let's dive in!</p>\n<h2 id=\"new-homepage-and-logo\">\ud83d\udc3f\ufe0f New Homepage and Logo</h2><p>The <a href=\"https://scour.ing/about\">Scour homepage</a> has been completely revamped. It includes a new tagline, a more succinct description, and a live demo where you can try out my feed right from that page. Let me know what you think!</p>\n<p>Scour also finally has its own logo! (And it looks great on my phone's home screen, if I do say so myself! <a href=\"https://emschwartz.me/feed/?type=rss#app\">See below</a>)</p>\n<h2 id=\"interactive-documentation\">\ud83d\udcd7 Interactive Documentation</h2><p>Have you ever wondered how Scour works? There is now a full <a href=\"https://scour.ing/docs\">documentation</a> section, complete with detailed write-ups about <a href=\"https://scour.ing/docs/interests\">Interests</a>, <a href=\"https://scour.ing/docs/feeds\">Feeds</a>, <a href=\"https://scour.ing/docs/reactions\">Reactions</a>, <a href=\"https://scour.ing/docs/ranking\">How Ranking Works</a>, and more.</p>\n<p>There are also guides specifically for <a href=\"https://scour.ing/docs/rss\">RSS users</a> and readers of <a href=\"https://scour.ing/docs/hacker-news\">Hacker News</a>, <a href=\"https://scour.ing/docs/arxiv\">arXiv</a>, <a href=\"https://scour.ing/docs/reddit\">Reddit</a>, and <a href=\"https://scour.ing/docs/substack\">Substack</a>.</p>\n<p>All of the docs have lots of interactive elements, which I wrote about in <a href=\"https://emschwartz.me/building-docs-like-a-product/\">Building Docs Like a Product</a>. My favorite one is on the Hacker News guide where you can <a href=\"https://scour.ing/docs/hacker-news#see-for-yourself\">search for hidden gems</a> that have been submitted to HN but that have not reached the front page.</p>\n<p>Thanks to <a href=\"https://feedback.scour.ing/95\">Tiago Ferreira</a>, <a href=\"https://feedback.scour.ing/104\">Andrew Doran</a>, and everyone else who gave me the feedback that they wanted to understand more about how Scour works!</p>\n<h2 id=\"app\">\ud83d\udcf1 App</h2><p>Scour is now a Progressive Web App (PWA). That means you can install it as an icon on your home screen and access it easily. Just open Scour on your phone and follow the instructions there.</p>\n<p>Thanks to Adam Benenson for the encouragement to finally do this!</p>\n<h2 id=\"hiding-seen-items\">\ud83d\ude48 Hiding Seen Items</h2><p>This is one of the features I have most wanted as a user of Scour myself. When you're browsing the feed, Scour now keeps track of which items you've seen and scrolled past so it shows you new content each time you check it.</p>\n<p>If you don't want this behavior, you can disable it in the feed filter menu or <a href=\"https://scour.ing/settings#filter-defaults\">change your default view</a> to show seen posts.</p>\n<h2 id=\"feed-autodiscovery\">\ud83d\udd0e Feed Autodiscovery</h2><p>If you subscribe to specific feeds, as opposed to scouring all of them, it's now easier to <a href=\"https://scour.ing/docs/feeds#discovering-feeds-from-posts\">find the feed for an article you liked</a>.</p>\n<p>Click the \"...\" menu under the post, then \"Show Feeds\" to show feeds where the item was found. When populating that list, Scour will now automatically search the website where the article was found to see if it has a feed that Scour wasn't already checking. This makes it easy to discover new feeds and follow websites or authors whose content you like.</p>\n<p>This was another feature I've wanted for a long time myself. Previously, when I liked an article, I'd copy the domain and try to add it to my feeds on the Feeds page. Now, Scour does that with the click of a button.</p>\n<h2 id=\"penalizing-listicles\">\ud83d\udd22 Penalizing Listicles</h2><p>Some of the most disliked and flagged articles on Scour had titles such as \"The Top 10...\" or \"5 tricks...\". Scour now automatically penalizes articles with titles like those.</p>\n<p>Because I'm explicitly trying to <a href=\"https://scour.ing/docs/ranking#the-philosophy-hidden-gems-over-viral-content\">avoid using popularity in ranking</a>, I need to find other ways to boost high-quality content and down-rank low-quality content. You can expect more of these types of changes in the future to increase the overall quality of what you see in your feed.</p>\n<h2 id=\"following-google-news-links\">\ud83d\uddde\ufe0f Following Google News Links</h2><p>Previously, posts found through Google News links would show Google News as the domain under the post. Now, Scour extracts the original link.</p>\n<h2 id=\"keyboard-shortcuts\">\u2328\ufe0f Keyboard Shortcuts</h2><p>You can now navigate your feed using just your keyboard. Type <code>?</code> to get the list of available keyboard shortcuts.</p>\n<hr />\n<h2 id=\"some-of-my-favorite-posts\">\ud83d\udd16 Some of My Favorite Posts</h2><p>Finally, here are some of <a href=\"https://scour.ing/@emschwartz/likes\">my favorite posts</a> that I found on Scour in January. There were a lot!</p>\n<ul>\n<li>I appreciate this minimalist approach to coding agents: <a href=\"https://scour.ing/@emschwartz/p/https://lucumr.pocoo.org/2026/1/31/pi/\">Pi: The Minimal Agent Within OpenClaw</a>, even though it didn't yet convince me to switch away from Claude Code.</li>\n<li>A long and interesting take on which software tools will survive the AI era: <a href=\"https://scour.ing/@emschwartz/p/https://steve-yegge.medium.com/software-survival-3-0-97a2a6255f7b\">Software Survival 3.0</a>.</li>\n<li>Scour uses Litestream for backup. While this new feature isn't directly relevant, I'm excited that it's now powering Fly.io's new Sprites offering (so I expect it to be a little more actively developed): <a href=\"https://scour.ing/@emschwartz/p/https://fly.io/blog/litestream-writable-vfs/\">Litestream Writable VFS</a>.</li>\n<li>This is a very cool development in embedding models: a family of different size (and, as a result, cost) models whose embeddings are interoperable with one another: <a href=\"https://scour.ing/@emschwartz/p/https://blog.voyageai.com/2026/01/15/voyage-4/\">The Voyage 4 model family: shared embedding space with MoE architecture</a>.</li>\n<li>A thought-provoking piece from Every about <a href=\"https://scour.ing/@emschwartz/p/https://every.to/p/how-ai-made-pricing-hard-again\">How AI Made Pricing Hard Again</a>. TL;DR: over are the days where SaaS businesses have practically zero marginal cost for additional users or additional usage.</li>\n<li>A nice bit of UX design history about the gas tank arrow indicator on a car, with a lesson applied to AI: <a href=\"https://scour.ing/@emschwartz/p/https://jarango.com/2026/01/06/the-moylan-arrow-ia-lessons-for-ai-powered-systems/\">The Moylan Arrow: IA Lessons for AI-Powered Experiences</a>.</li>\n<li>Helpful context for <a href=\"https://scour.ing/@emschwartz/p/https://gzucman.substack.com/p/understanding-us-intervention-in\">Understanding U.S. Intervention in Venezuela</a>.</li>\n<li>Stoolap: an interesting new embedded database. <a href=\"https://scour.ing/@emschwartz/p/https://www.phoronix.com/news/Stoolap-0.2-Rust-Embedded-SQL\">Stoolap 0.2 Released For Modern Embedded SQL Database In Rust</a>.</li>\n<li>I keep browsing fonts and, while I decided not to use this one for Scour, I think this is a neat semi-sans-serif from an independent designer: <a href=\"https://scour.ing/@emschwartz/p/https://mbtype.com/fonts/heliotrope/story.html\">Heliotrope</a>.</li>\n</ul>\n<hr />\n<p>Happy Scouring!</p>\n<p>- Evan</p>\n<p><em>Have feedback for Scour? Post it on the <a href=\"https://feedback.scour.ing\">feedback board</a> and upvote others' suggestions to help me prioritize new features!</em></p>"
            ],
            "link": "https://emschwartz.me/scour-update-january-2026/",
            "publishedAt": "2026-02-04",
            "source": "Evan Schwartz",
            "summary": "<p>Hi friends,</p> <p>In January, Scour scoured <strong>805,241 posts</strong> from <strong>16,555 feeds</strong> (939 were newly added).</p> <p>I also rolled out a lot of new features that I'm excited to tell you about. Maybe because of some of these, I found more posts than usual that I thought were especially worth sharing. You can find them at the bottom of this post. Let's dive in!</p> <h2 id=\"new-homepage-and-logo\">\ud83d\udc3f\ufe0f New Homepage and Logo</h2><p>The <a href=\"https://scour.ing/about\">Scour homepage</a> has been completely revamped. It includes a new tagline, a more succinct description, and a live demo where you can try out my feed right from that page. Let me know what you think!</p> <p>Scour also finally has its own logo! (And it looks great on my phone's home screen, if I do say so myself! <a href=\"https://emschwartz.me/feed/?type=rss#app\">See below</a>)</p> <h2 id=\"interactive-documentation\">\ud83d\udcd7 Interactive Documentation</h2><p>Have you ever wondered how Scour works? There is now a full <a href=\"https://scour.ing/docs\">documentation</a> section, complete with detailed write-ups about <a href=\"https://scour.ing/docs/interests\">Interests</a>, <a href=\"https://scour.ing/docs/feeds\">Feeds</a>, <a href=\"https://scour.ing/docs/reactions\">Reactions</a>, <a href=\"https://scour.ing/docs/ranking\">How Ranking Works</a>, and more.</p> <p>There are also guides specifically for <a href=\"https://scour.ing/docs/rss\">RSS users</a> and readers of <a href=\"https://scour.ing/docs/hacker-news\">Hacker News</a>, <a href=\"https://scour.ing/docs/arxiv\">arXiv</a>, <a href=\"https://scour.ing/docs/reddit\">Reddit</a>, and <a href=\"https://scour.ing/docs/substack\">Substack</a>.</p> <p>All of the docs have lots of interactive elements, which I wrote",
            "title": "Scour - January Update"
        },
        {
            "content": [],
            "link": "https://everythingstudies.com/2026/02/04/competitive-sensemaking-is-live/",
            "publishedAt": "2026-02-04",
            "source": "Everything Studies",
            "summary": "&#8220;Public debate is how societies do their thinking. To keep our shared belief systems functional we must know how to disagree constructively, and exactly what goes wrong when we don&#8217;t do so. Why and how do communication failures make public discourse incoherent, dysfunctional, and polarized?&#8221; Competitive Sensemaking: An Upgrade to Common Sense on Disagreement is &#8230; <a class=\"more-link\" href=\"https://everythingstudies.com/2026/02/04/competitive-sensemaking-is-live/\">Continue reading <span class=\"screen-reader-text\">Competitive Sensemaking is&#160;Live</span></a>",
            "title": "Competitive Sensemaking is Live"
        },
        {
            "content": [],
            "link": "https://buttondown.com/hillelwayne/archive/logic-for-programmers-new-release-and-next-steps/",
            "publishedAt": "2026-02-04",
            "source": "Hillel Wayne",
            "summary": "<p><img alt=\"cover.jpg\" class=\"newsletter-image\" src=\"https://assets.buttondown.email/images/f821145f-d310-403c-88f4-327758a66606.jpg?w=480&amp;fit=max\" /></p> <p>It's taken four months, but the next release of <a href=\"https://logicforprogrammers.com\" target=\"_blank\">Logic for Programmers is now available</a>! v0.13 is over 50,000 words, making it both 20% larger than v0.12 and officially the longest thing I have ever written.<sup id=\"fnref:longest\"><a class=\"footnote-ref\" href=\"https://buttondown.com/hillelwayne/rss#fn:longest\">1</a></sup> Full release notes are <a href=\"https://github.com/logicforprogrammers/book-assets/blob/master/CHANGELOG.md\" target=\"_blank\">here</a>, but I'll talk a bit about the biggest changes. </p> <p>For one, every chapter has been rewritten. Every single one. They span from <em>relatively</em> minor changes to complete chapter rewrites. After some rough git diffing, I think I deleted about 11,000 words?<sup id=\"fnref:gross-additions\"><a class=\"footnote-ref\" href=\"https://buttondown.com/hillelwayne/rss#fn:gross-additions\">2</a></sup> The biggest change is probably to the Alloy chapter. After many sleepless nights, I realized the right approach wasn't to teach Alloy as a <em>data modeling</em> tool but to teach it as a <em>domain modeling</em> tool. Which technically means the book no longer covers data modeling.</p> <p>There's also a lot more connections between the chapters. The introductory math chapter, for example, foreshadows how each bit of math will be used in the future techniques. I also put more emphasis on the general \"themes\" like the expressiveness-guarantees tradeoff (working title). One theme I'm really excited about is compatibility (extremely working title). It turns",
            "title": "Logic for Programmers New Release and Next Steps"
        },
        {
            "content": [
                "<img alt=\"Launching The Rural Guaranteed Minimum Income Initiative\" src=\"https://blog.codinghorror.com/content/images/2026/02/rgmii-metro-vs-rural-counties-usa-2026-1.png\" /><p>It&apos;s been a year since I invited Americans to join us in a <strong>pledge to Share the American Dream</strong>:</p><blockquote>1. Support organizations you feel are&#xa0;<a href=\"https://www.charitynavigator.org/\" rel=\"noopener noreferrer\">effectively helping</a>&#xa0;those most in need across America <strong>right now</strong>.<br /><br />2. Within the next five years, also contribute&#xa0;<strong>public dedications of time or funds towards longer term efforts&#xa0;</strong>to keep the American Dream fair and attainable for all our children.<br /><br /><a href=\"https://blog.codinghorror.com/stay-gold-america/\" rel=\"noreferrer\">Stay gold, America.</a> &#x1f49b;</blockquote><p>Personally, I&#x2019;ve become a big believer in one particular quote, especially considering the specific context in which it was delivered:</p>\n<!--kg-card-begin: html-->\n<blockquote class=\"kg-blockquote-alt\">&#x201c;From those to whom much is given, much is expected.&#x201d; &#x2014; <a href=\"https://rgmii.org/mary-gates-philanthropic-quote/\" rel=\"noopener noreferrer\" target=\"_blank\">Mary Gates</a></blockquote>\n<!--kg-card-end: html-->\n<p>Those 10 words had a profound effect on the world. Indeed, we <em>were</em> given much, so we, as a family, <strong>will <em>choose to give much</em></strong>. On <a href=\"https://denver-frederick.com/2025/06/24/the-american-dream-is-broken-this-50-million-bet-could-help-rebuild-it/\" rel=\"noreferrer\">a recent podcast</a>, my partner Betsy said it better than I could have:</p><blockquote><em>&#x201c;Well, we have everything we need!&#x201d; That&#x2019;s how I&#x2019;ve always phrased it to [our children]. That, I think, extends [to our philanthropy]. We have everything we need;&#xa0;</em><strong>how do we make sure everybody has what they need?</strong><em>&#xa0;Because that&#x2019;s the basic thing &#x2014; Do you have a comfortable place to live? Do you have enough to eat? Do you have healthcare? If you have the basics, you&#x2019;re in a good place in life, and everybody should have that opportunity.</em></blockquote><p>It&#x2019;s a question I&#x2019;ve asked myself a lot <a href=\"https://techcrunch.com/2021/06/02/stack-overflow-acquired-by-prosus-for-a-reported-1-8-billion/\" rel=\"noreferrer\">since 2021</a>. <em>When, exactly, is <strong>enough?</strong></em></p><figure class=\"kg-card kg-image-card\"><a href=\"https://www.instagram.com/starshapedpress/p/DSh-Oo5DtS1/\"><img alt=\"Launching The Rural Guaranteed Minimum Income Initiative\" class=\"kg-image\" height=\"861\" src=\"https://blog.codinghorror.com/content/images/2026/02/starshaped-press-we-have-everything-we-need-letterpress-dec-2025.jpg\" width=\"1600\" /></a></figure><p>We do have everything we need. <em>Why can&#x2019;t everyone else have the basic things they need, too?</em></p><p>Beyond the $1M to eight nonprofit charities we listed in January 2025, we saw immediate needs becoming so urgent that we quickly added an additional $13M in donations within a few months, for a total of $21M.</p><div class=\"kg-card kg-toggle-card\">\n            <div class=\"kg-toggle-heading\">\n                <h4 class=\"kg-toggle-heading-text\"><span style=\"white-space: pre-wrap;\">Immediate Share The American Dream Donations (~$21M)</span></h4>\n                <button class=\"kg-toggle-card-icon\">\n                    <svg id=\"Regular\" viewBox=\"0 0 24 24\" xmlns=\"http://www.w3.org/2000/svg\">\n                        <path class=\"cls-1\" d=\"M23.25,7.311,12.53,18.03a.749.749,0,0,1-1.06,0L.75,7.311\">\n                    </svg>\n                </button>\n            </div>\n            <div class=\"kg-toggle-content\"><ul><li value=\"1\"><a href=\"https://teamrubiconusa.org/\" rel=\"noopener noreferrer\" target=\"_blank\"><span style=\"white-space: pre-wrap;\">Team Rubicon</span></a><span style=\"white-space: pre-wrap;\"> &#x2014; $1M</span></li><li value=\"2\"><a href=\"https://childrenshungerfund.org/\" rel=\"noopener noreferrer\" target=\"_blank\"><span style=\"white-space: pre-wrap;\">Children&#x2019;s Hunger Fund</span></a><span style=\"white-space: pre-wrap;\"> &#x2014; $1M</span></li><li value=\"3\"><a href=\"https://pen.org/\" rel=\"noopener noreferrer\" target=\"_blank\"><span style=\"white-space: pre-wrap;\">PEN America</span></a><span style=\"white-space: pre-wrap;\"> &#x2014; $1M</span></li><li value=\"4\"><a href=\"https://www.thetrevorproject.org/\" rel=\"noopener noreferrer\" target=\"_blank\"><span style=\"white-space: pre-wrap;\">The Trevor Project</span></a><span style=\"white-space: pre-wrap;\"> &#x2014; $1M</span></li><li value=\"5\"><a href=\"https://www.naacpldf.org/\" rel=\"noopener noreferrer\" target=\"_blank\"><span style=\"white-space: pre-wrap;\">NAACP Legal Defense and Educational Fund</span></a><span style=\"white-space: pre-wrap;\"> &#x2014; $1M + $100k</span></li><li value=\"6\"><a href=\"https://www.firstgenerationinvestors.com/\" rel=\"noopener noreferrer\" target=\"_blank\"><span style=\"white-space: pre-wrap;\">First Generation Investors</span></a><span style=\"white-space: pre-wrap;\"> &#x2014; $1M</span></li><li value=\"7\"><a href=\"https://www.globalrefuge.org/\" rel=\"noopener noreferrer\" target=\"_blank\"><span style=\"white-space: pre-wrap;\">Global Refuge</span></a><span style=\"white-space: pre-wrap;\"> &#x2014; $1M</span></li><li value=\"8\"><a href=\"https://www.plannedparenthood.org/\" rel=\"noopener noreferrer\" target=\"_blank\"><span style=\"white-space: pre-wrap;\">Planned Parenthood</span></a><span style=\"white-space: pre-wrap;\"> &#x2014; $1M</span></li><li value=\"9\"><a href=\"https://votevets.org/\" rel=\"noreferrer\"><span style=\"white-space: pre-wrap;\">VoteVets</span></a><span style=\"white-space: pre-wrap;\"> &#x2014; $2M</span></li><li value=\"10\"><a href=\"https://joinmastodon.org/\" rel=\"noreferrer\"><span style=\"white-space: pre-wrap;\">Mastodon</span></a><span style=\"white-space: pre-wrap;\"> &#x2014; $1.5M</span></li><li value=\"11\"><a href=\"https://www.404media.co/\" rel=\"noreferrer\"><span style=\"white-space: pre-wrap;\">404 Media</span></a><span style=\"white-space: pre-wrap;\"> &#x2014; $1.1M</span></li><li value=\"12\"><a href=\"https://www.garbageday.email/\" rel=\"noreferrer\"><span style=\"white-space: pre-wrap;\">Ryan Broderick / Garbage Day</span></a><span style=\"white-space: pre-wrap;\"> &#x2014; $1M</span></li><li value=\"13\"><a href=\"https://archive.org/\" rel=\"noreferrer\"><span style=\"white-space: pre-wrap;\">Internet Archive</span></a><span style=\"white-space: pre-wrap;\"> &#x2014; $1M </span></li><li value=\"14\"><a href=\"https://commoncrawl.org/\" rel=\"noreferrer\"><span style=\"white-space: pre-wrap;\">Common Crawl Foundation</span></a><span style=\"white-space: pre-wrap;\"> &#x2014; $1M</span></li><li value=\"15\"><span style=\"white-space: pre-wrap;\">Wikipedia / </span><a href=\"https://wikimediafoundation.org/\" rel=\"noreferrer\"><span style=\"white-space: pre-wrap;\">Wikimedia foundation</span></a><span style=\"white-space: pre-wrap;\"> &#x2014; $1M</span></li><li value=\"16\"><a href=\"https://www.abetterinternet.org/\" rel=\"noreferrer\"><span style=\"white-space: pre-wrap;\">Internet Security Research Group</span></a><span style=\"white-space: pre-wrap;\"> &#x2014; $1M</span></li><li value=\"17\"><a href=\"https://www.dnalounge.com/\" rel=\"noreferrer\"><span style=\"white-space: pre-wrap;\">DNA Lounge</span></a><span style=\"white-space: pre-wrap;\"> &#x2014; $1M</span></li><li value=\"18\"><a href=\"https://murena.com/\" rel=\"noreferrer\"><span style=\"white-space: pre-wrap;\">Murena</span></a><span style=\"white-space: pre-wrap;\"> &#x2014; $500k</span></li><li value=\"19\"><a href=\"https://sharewellnow.com/\" rel=\"noreferrer\"><span style=\"white-space: pre-wrap;\">Sharewell</span></a><span style=\"white-space: pre-wrap;\"> &#x2014; $300k</span></li><li value=\"20\"><a href=\"https://www.preciousplastic.com/\" rel=\"noreferrer\"><span style=\"white-space: pre-wrap;\">Precious Plastic</span></a><span style=\"white-space: pre-wrap;\"> &#x2014; $100k</span></li><li value=\"21\"><a href=\"https://economicsecurityproject.org/\" rel=\"noreferrer\"><span style=\"white-space: pre-wrap;\">Economic Security Project</span></a><span style=\"white-space: pre-wrap;\"> &#x2014; $100k</span></li><li value=\"22\"><a href=\"https://ruraldemocracyinitiative.org/\" rel=\"noreferrer\"><span style=\"white-space: pre-wrap;\">Rural Democracy Initiative</span></a><span style=\"white-space: pre-wrap;\"> &#x2014; $100k</span></li><li value=\"23\"><a href=\"https://civicnation.org/\" rel=\"noreferrer\"><span style=\"white-space: pre-wrap;\">Civic Nation</span></a><span style=\"white-space: pre-wrap;\"> &#x2014; $100k</span></li><li value=\"24\"><a href=\"https://www.sojournproject.org/\" rel=\"noreferrer\"><span style=\"white-space: pre-wrap;\">Sojourn Project</span></a><span style=\"white-space: pre-wrap;\"> &#x2014; $750k</span></li><li value=\"25\"><a href=\"https://www.alamedafoodbank.org/\" rel=\"noreferrer\"><span style=\"white-space: pre-wrap;\">Alameda Food Bank</span></a><span style=\"white-space: pre-wrap;\"> &#x2014; $150k </span></li><li value=\"26\"><a href=\"https://urbancompassionproject.org/\" rel=\"noreferrer\"><span style=\"white-space: pre-wrap;\">Urban Compassion Project</span></a><span style=\"white-space: pre-wrap;\"> &#x2014; $75k</span></li></ul></div>\n        </div><p>But you can&#x2019;t take a completely short term view and fight each individual fire reactively, as it comes. You&apos;ll never stop firefighting. We also have to do fire abatement and deal with the root causes, improving conditions in this country such that <em>there aren&#x2019;t so many fires</em>. Thus for the second half, much longer term part, in addition to the $21M already donated, we <strong>pledged $50M </strong>&#x2014; half of our remaining wealth &#x2014; to address the underlying, systemic issues. </p><p>I proposed some <a href=\"https://blog.codinghorror.com/stay-gold-america/#long-term-efforts\" rel=\"noreferrer\">speculative ideas</a> in &#x201c;Stay Gold,&#x201d; and this one ended up being the closest:</p><blockquote>We could found a new organization loosely based on the original&#xa0;<a href=\"https://en.wikipedia.org/wiki/RAND_Corporation\" rel=\"noopener noreferrer\">RAND Corporation</a>, but modernized like&#xa0;<a href=\"https://www.leverforchange.org/\" rel=\"noopener noreferrer\">Lever for Change</a>. We can empower the best and brightest to determine a realistic, achievable path toward preserving the American Dream for&#xa0;<em>everyone,</em>&#xa0;working within the current system or outside it.</blockquote><p>By March, 2025 we had consensus &#x2014; <a href=\"https://blog.codinghorror.com/the-road-not-taken-is-guaranteed-minimum-income/\" rel=\"noreferrer\">The Road Not Taken is Guaranteed Minimum Income</a>.<strong>  </strong></p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://blog.codinghorror.com/the-road-not-taken-is-guaranteed-minimum-income/\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">The Road Not Taken is Guaranteed Minimum Income</div><div class=\"kg-bookmark-description\">The dream is incomplete until we share it with our fellow Americans.</div><div class=\"kg-bookmark-metadata\"><img alt=\"Launching The Rural Guaranteed Minimum Income Initiative\" class=\"kg-bookmark-icon\" src=\"https://blog.codinghorror.com/content/images/icon/3cffc4b347c3587f19fe222caaac69f63b9a5e73-6.png\" /><span class=\"kg-bookmark-author\">Coding Horror</span><span class=\"kg-bookmark-publisher\">Jeff Atwood</span></div></div><div class=\"kg-bookmark-thumbnail\"><img alt=\"Launching The Rural Guaranteed Minimum Income Initiative\" src=\"https://blog.codinghorror.com/content/images/thumbnail/IMG_7003-1.jpg\" /></div></a></figure><p><strong>Guaranteed Minimum Income (GMI)</strong> is an improved version of the older concept of Universal Basic Income (UBI) &#x2014; rather than indiscriminately giving money to &#x201c;everyone,&#x201d; GMI <strong>directs the money towards those who most need it</strong>, particularly families experiencing generational poverty. </p><div class=\"kg-card kg-cta-card kg-cta-bg-grey kg-cta-minimal    \">\n            \n            <div class=\"kg-cta-content\">\n                \n                \n                    <div class=\"kg-cta-content-inner\">\n                    \n                        <div class=\"kg-cta-text\">\n                            <p><span style=\"white-space: pre-wrap;\">&#x1f4e2; Please note that after this post, Coding Horror will revert to normal nerdy blog posts, and all future GMI content will be at a dedicated site linked below.</span></p>\n                        </div>\n                    \n                    \n                    </div>\n                \n            </div>\n        </div><h3 id=\"why-did-we-decide-on-gmi\">Why did we decide on GMI?</h3><ul><li>Almost every <strong>existing UBI/GMI study result data we could find indicates <em>cash generally works</em></strong>. For example, OpenResearch <a href=\"https://rgmii.org/openresearch-ubi-study-2018-2023-analysis/\" rel=\"noreferrer\">data showed</a> the greatest increase in spending among study participants was in meeting basic needs, with the greatest percent increase in support to others (26%), along with huge decreases in reported alcohol use (20% less) and days using non-prescribed painkillers (53% fewer). Why wouldn&#x2019;t we continue to build something that has generally been shown to work, study after study, time and time again? </li><li>This is <strong>survival money</strong>,<strong> </strong>cash for folks so they can put food on the table, get a roof over their heads, have a functioning vehicle to go to work, and decide how to meet their most basic, critical needs. It pains me to say this, but we live in a world where many people simply do not often experience open generosity, or regular income. When you show someone what it feels like to just not be hungry for a little while, their view of the world changes. They feel trusted. They see <em>possibility</em>. </li></ul><p></p>\n<!--kg-card-begin: html-->\n\n\n<div class=\"rise-container\">\n  <div class=\"rise-photo-column\">\n    <img alt=\"Launching The Rural Guaranteed Minimum Income Initiative\" src=\"https://blog.codinghorror.com/content/images/2026/02/rise-recipient1.png\" />\n    <div class=\"rise-badge\">\n      RISE Recipient Stacy D. | WV\n    </div>    \n  </div>\n\n  <div class=\"rise-text-column\">\n    <blockquote style=\"border: none !important;\">\n      <p>I moved here with my family. And I have no family up here other than who I brought with me. <strong>So, how most people can be like, &#x201c;Hey, I&#x2019;m having a hard time. Got $20 or a pack of diapers.&#x201d; I have nobody up here to do that.</strong> So, if me and my husband don&apos;t figure it out, it don&apos;t get figured out.</p>\n    \n      <p>So, I&#x2019;ve got five kids that live with me... I was working full-time until I got pregnant. I prayed for this baby for 10 years. <strong>So, as soon as I got pregnant, I stopped working. I was high risk.</strong></p>\n    \n      <p><strong>The day I got cleared to go back to work, my vehicle broke down.</strong> It was the only vehicle that we had that carried all the kids. So, I&#x2019;ve been four months without my car. So this is also going to get my vehicle back on the road.</p>\n    \n      <p>You don&#x2019;t know how hard it is to ask people, hey, can I get a ride to the grocery store? Or, hey, my baby has two month shots. I had to borrow a vehicle. <strong>This is gonna... it&#x2019;s going to do a lot!</strong></p>\n    </blockquote>\n  </div>\n</div>\n<!--kg-card-end: html-->\n<ul><li>Unlike many other social programs, <strong>GMI studies require initiative</strong>. These are opt-in studies that you have to sign up for, demonstrate that you meet the income criteria and are a resident of the county &#x2014; and because spots are limited, be randomly selected from eligible applicants. We emphasize that this is not passive, it is active <strong>teamwork</strong> to improve the GMI program with your family, your community, and everyone else we can reach together over the next few decades.</li></ul><h2 id=\"building-on-what-works\">Building On What Works</h2><ul><li>The <a href=\"https://www.openresearchlab.org/studies/unconditional-cash-study/study\" rel=\"noreferrer\">massive OpenResearch UBI study</a>, the largest and most detailed guaranteed income study ever conducted in the USA, was designed to be a template for future, more refined studies, and that&#x2019;s <em>exactly </em>what we&#x2019;re doing. We will also use what we learn in this group of three counties &#x2014; as in software, <a href=\"https://blog.codinghorror.com/rule-of-three/\" rel=\"noreferrer\">the rule of three</a> &#x2014; to <strong>iterate, adapt, and improve our GMI study playbook with every new group of three counties</strong>, generating a playbook anyone can use. </li><li>We strive to do repeatable, replicable <strong>science</strong> in every study, and <strong>all our data will be open and freely shared with the world</strong>. We&#x2019;re contributing to &#x2014; and partially funding &#x2014; a global, open data repository for basic income pilots all around the world, <a href=\"https://ubidata.io/\" rel=\"noreferrer\">UBIdata</a>. It&#x2019;s the same reason we made <a href=\"https://stackoverflow.com/\" rel=\"noreferrer\">Stack Overflow</a> content part of the creative commons, and <a href=\"https://www.discourse.org/\" rel=\"noreferrer\">Discourse</a> fully open source.</li><li>GMI is <strong>seed funding for families,</strong> investing in our fellow Americans, those who need it the most. A large body of research shows that dollars targeted to lower-income families are more likely to be spent quickly and reduce hardship, and can improve outcomes for children. &#x201c;<strong>Trickle up&#x201d; economics works,</strong> whereas &quot;trickle down&quot; tax cuts for the rich <a href=\"https://academic.oup.com/ser/article/20/2/539/6500315\" rel=\"noreferrer\">increase income inequality</a> and provide no significant effect on growth or jobs.</li><li>This is the newer <a href=\"https://ssir.org/articles/entry/trust-based-philanthropy-strategic\">trust based model of philanthropy</a>, much closer to venture capital funding. We primarily empower, fund, and build up <strong>existing organizations</strong> like GiveDirectly and OpenResearch, forming a collaborative team to leverage all their existing work and grow their organizations in whatever way they see fit, because they have the most experience in the GMI space. </li></ul><h2 id=\"the-rural-guaranteed-minimum-income-initiative\">The Rural Guaranteed Minimum Income Initiative</h2><p>I like to <a href=\"https://blog.codinghorror.com/go-that-way-really-fast/\" rel=\"noreferrer\">go that way, really fast</a>, so we are already well underway<em> </em>with the<em> </em><a href=\"https://rgmii.org/\"><strong>Rural Guaranteed Minimum Income Initiative</strong></a>.</p><p>We focus on <strong>rural counties</strong>, where dollars go a lot further, poverty is more prevalent, and populations are smaller for tighter studies. Rural counties are also greatly overlooked in this country, in my opinion, yet they have so much incredible untapped talent. I know because that&#x2019;s exactly where my parents and I are from.</p><figure class=\"kg-card kg-image-card\"><img alt=\"Launching The Rural Guaranteed Minimum Income Initiative\" class=\"kg-image\" height=\"1075\" src=\"https://blog.codinghorror.com/content/images/2026/02/rgmii-metro-vs-rural-counties-usa-2026-2.png\" width=\"1600\" /></figure><p>We&#x2019;ve funded three county level programs (Mercer, WV; Beaufort, NC; Warren, MS) that are already underway, where we will help lift thousands of people out of poverty for a period of 16 months, while sharing data and results with the world. That&#x2019;s a good start.</p><figure class=\"kg-card kg-image-card\"><img alt=\"Launching The Rural Guaranteed Minimum Income Initiative\" class=\"kg-image\" height=\"600\" src=\"https://blog.codinghorror.com/content/images/2026/02/three-initial-rgmii-counties-mercer-beaufort-warren-wide.png\" width=\"1300\" /></figure><p>But I think we can do <em>considerably</em> more. With your help, we hope to <strong>reach all 50 states</strong> over time. </p><p>In &#x201c;Stay Gold,&#x201d; I <a href=\"https://blog.codinghorror.com/stay-gold-america/#which-dream\" rel=\"noreferrer\">noted</a> that all of American history contains the path of love, and the path of hate. But the path of love is the only survivable path. It&#x2019;s so much harder, and it&#x2019;s going to be a lifetime of work. But what else could I possibly buy with our money that would be worth anything close to this, for all of us? </p><h3 id=\"what-you-can-do\">What You Can Do</h3><p><a href=\"https://rgmii.org/help-out/\" rel=\"noreferrer\">Everyone is invited to help</a>. Share <a href=\"https://rgmii.org/gmi-study-analysis/\" rel=\"noreferrer\">results</a>, learn the <a href=\"https://rgmii.org/history-of-gmi/\" rel=\"noreferrer\">history of GMI</a> (it&#x2019;s actually fascinating, I swear), talk to your representatives and generally spread the word. A surprising number of people have never even heard the terms UBI or GMI, and sometimes have misconceptions about what they are and how they work.</p><figure class=\"kg-card kg-image-card\"><a href=\"https://rgmii.org\"><img alt=\"Launching The Rural Guaranteed Minimum Income Initiative\" class=\"kg-image\" height=\"564\" src=\"https://blog.codinghorror.com/content/images/2026/02/rural-gmi-initiative-logo-qr-urls-wide.png\" width=\"2000\" /></a></figure><p>If you, or someone you know, is &#x201c;those to whom much is given,&#x201d; and in a position to sponsor county-scale work, please join us in <a href=\"https://rgmii.org/become-a-donor/\" rel=\"noreferrer\">bringing a GMI study to a new rural county</a> and reach all 50 states. Let&#x2019;s continue to do science and help lift thousands of people out of poverty while generating open data for the world.</p><figure class=\"kg-card kg-image-card\"><img alt=\"Launching The Rural Guaranteed Minimum Income Initiative\" class=\"kg-image\" height=\"1048\" src=\"https://blog.codinghorror.com/content/images/2026/02/rgmii-usa-poverty-map-by-county-2026.png\" width=\"1678\" /></figure><p><strong>This is my third and final startup</strong>. Rather than an &#x201c;Atwood Foundation,&#x201d; all we want to do is advance the concept of direct cash transfer. Simply <em>giving money to those most in need </em>is perhaps the most radical act of love we can take on... and <a href=\"https://rgmii.org/gmi-study-analysis/\" rel=\"noreferrer\">all the data</a> I can find shows us that <em>it works</em> &#x2014; helping people afford basic needs, keep stable housing, and handle unexpected expenses.</p><p>Dreams, like happiness, are only real when shared. So let&#x2019;s do that together.</p><p><a href=\"https://staygold.us\" rel=\"noreferrer\"><strong>staygold.us</strong></a><strong> &#x1f49b;</strong></p><p></p><p></p><p></p>"
            ],
            "link": "https://blog.codinghorror.com/launching-the-rural-guaranteed-minimum-income-initiative/",
            "publishedAt": "2026-02-04",
            "source": "Jeff Atwood",
            "summary": "<p>It&apos;s been a year since I invited Americans to join us in a <strong>pledge to Share the American Dream</strong>:</p><blockquote>1. Support organizations you feel are&#xa0;<a href=\"https://www.charitynavigator.org/\" rel=\"noopener noreferrer\">effectively helping</a>&#xa0;those most in need across America <strong>right now</strong>.<br /><br />2. Within the next five years, also contribute&#xa0;<strong>public dedications</strong></blockquote>",
            "title": "Launching The Rural Guaranteed Minimum Income Initiative"
        },
        {
            "content": [],
            "link": "https://www.nytimes.com/2026/02/04/style/tiny-modern-love-stories-i-mistook-her-optimism-for-an-act.html",
            "publishedAt": "2026-02-04",
            "source": "Modern Love - NYT",
            "summary": "Modern Love in miniature, featuring reader-submitted stories of no more than 100 words.",
            "title": "Tiny Love Stories: \u2018I Mistook Her Optimism for an Act\u2019"
        },
        {
            "content": [],
            "link": "https://www.nytimes.com/2026/02/04/podcasts/the-real-story-behind-jennette-mccurdys-novel-half-his-age.html",
            "publishedAt": "2026-02-04",
            "source": "Modern Love - NYT",
            "summary": "McCurdy\u2019s new book is a work of fiction, but writing it helped her work through some complicated memories from her own life.",
            "title": "The Real Story Behind Jennette McCurdy\u2019s Novel \u2018Half His Age\u2019"
        },
        {
            "content": [
                "<p>SaaS is the most profitable business model on Earth.<sup id=\"fnref:1\"><a class=\"footnote\" href=\"https://nmn.gl/blog/ai-killing-b2b-saas#fn:1\" rel=\"footnote\">1</a></sup> It\u2019s easy to understand why: build once, sell the same thing again ad infinitum, and don\u2019t suffer any marginal costs on more sales.</p>\n\n<p>I have been writing software for more than half my life. In the last year itself, I\u2019ve talked to hundreds of founders and operators in SF, from preseed to Series E companies.</p>\n\n<p>AI is bringing an existential threat to a lot of B2B SaaS executives: How to keep asking customers for renewal, when every customer <em>feels</em> they can get something better built with vibe-coded AI products?</p>\n\n<p>And the market is pricing it in. Morgan Stanley\u2019s SaaS basket has <a href=\"https://www.bloomberg.com/news/articles/2026-01-18/-no-reasons-to-own-software-stocks-sink-on-fear-of-new-ai-tool\">lagged the Nasdaq by 40 points</a> since December. HubSpot and Klaviyo are down ~30%. Analysts are writing notes titled \u201cNo Reasons to Own\u201d software stocks.</p>\n\n<figure>\n  <img src=\"https://nmn.gl/blog/assets/saas-stocks.png\" />\n  <figcaption>The market is reflecting our new reality (Source: Bloomberg)</figcaption>\n</figure>\n\n<!--more-->\n\n<h2 id=\"the-relation-between-vibe-coding-and-b2b-saas-sales\">The relation between vibe coding and B2B SaaS sales</h2>\n\n<p>The new problem for B2B SaaS is that with AI, customers can get <em>something</em> working with vibe coding. There are tens of vibe coding \u201cinternal tool\u201d services that promise to connect to every integration in the world to pump out CRUD and workflow apps.</p>\n\n<p>Whatever they build <em>simply works</em>. It takes some wrangling to get there (one Series C VP listed <strong>eleven different</strong> vibe coding tools they\u2019ve tried and the pros and cons between each on a phone call once), but productivity gains are immediate.</p>\n\n<p>And vibe coding is fun. You feel like a mad wizard using the right incantation <sup id=\"fnref:3\"><a class=\"footnote\" href=\"https://nmn.gl/blog/ai-killing-b2b-saas#fn:3\" rel=\"footnote\">2</a></sup> to get this magical new silicon intelligence to do exactly what you want.</p>\n\n<p>What they don\u2019t know, though, is that a poorly architected system will fail, eventually. As every senior programmer (eventually) understands, our job is complex because we have to understand the relationships in the real world, the processes involved, and the workflows needed, and representing it in a robust way to create a stable system. AI can\u2019t do that.</p>\n\n<p>Non-programmers don\u2019t know any of this nuance. One Series E CEO told me that they\u2019re re-evaluating the quarterly renewal of their engineering productivity software because they along with an engineer reimplemented something using Github and Notion APIs. They were paying $30,000 to a popular tool<sup id=\"fnref:4\"><a class=\"footnote\" href=\"https://nmn.gl/blog/ai-killing-b2b-saas#fn:4\" rel=\"footnote\">3</a></sup> <strong>and they were not going to renew anymore.</strong></p>\n\n<h2 id=\"how-does-it-impact-b2b-sales\">How does it impact B2B sales?</h2>\n\n<p>If customers feel like they aren\u2019t being served exactly like they want to, they are more likely to churn. The reason behind all this is that customers are demanding more from their B2B vendors, because they know what\u2019s possible.</p>\n\n<p>Previously, you would change <em>your company</em> to fit what your ERP and pay them hundreds of thousands of dollars. Now, everyone can see that agentic coding makes an unprecedented level of flexibility possible. And customers are demanding that flexibility, and if they don\u2019t get it, they\u2019ll leave.</p>\n\n<p>This week itself I was on a phone call with a Series B AE talking about how they\u2019re potentially losing an $X00,000 account just because the customer can\u2019t use a specific failure reporting workflow in the SaaS. They\u2019re now working with me to build what the customer needs and retain them.</p>\n\n<h2 id=\"how-to-survive\">How to survive</h2>\n\n<h3 id=\"1-be-a-system-of-record\">1. Be a System of Record</h3>\n\n<p>If the entire company\u2019s workflows operates on your platform, i.e. you\u2019re a line-of-business SaaS, you are integrated into their existing team already. They know your UI and rely on you on the day to day.</p>\n\n<p>For example, to create a data visualization I won\u2019t seek any SaaS. I\u2019ll just code one myself using many of the popular vibe coding tools <em>(my team actually did that and it\u2019s vastly more flexible than what we\u2019d get off-the-shelf).</em></p>\n\n<p>Being a \u201cSystem of Record\u201d means you\u2019re embedded so deeply that there\u2019s no choice but to win. My prediction is that we\u2019ll see more SaaS companies go from the application layer to offering their robust SoR as their primary selling point.</p>\n\n<h3 id=\"2-security-authentication-and-robustness\">2. Security, authentication, and robustness</h3>\n\n<p>This is where vibe-coded apps silently fail \u2014 and where established SaaS platforms earn their keep.</p>\n\n<p>When a non-technical team vibe-codes an internal tool, they\u2019re not thinking about environment keys, XSS vulnerabilities or API keys hardcoded in client-side JavaScript. They\u2019re not implementing rate limiting, audit logs, or proper session management. They\u2019re definitely not thinking about SOC 2 compliance, GDPR data residency requirements, or HIPAA audit trails.</p>\n\n<p>I\u2019ve seen it firsthand: a finance team built a \u201cquick\u201d expense approval tool that stored unencrypted reports in a public S3 bucket. A sales ops team created a commission calculator that anyone with the URL could access \u2014 no auth required. These aren\u2019t edge cases. They\u2019re the norm when software is built without security as a foundational concern.</p>\n\n<p>Enterprise SaaS platforms have spent years (and millions) solving these problems: role-based access control, encryption at rest and in transit, penetration testing, compliance certifications, incident response procedures. Your customers may not consciously value this \u2014 until something breaks.</p>\n\n<p>The challenge is that security is invisible when it works. You need to communicate this value proactively: remind customers that the \u201csimple\u201d tool they could vibe-code themselves would require them to also handle auth, permissions, backups, uptime, and compliance.</p>\n\n<h3 id=\"3-adapt-to-the-customer-not-the-other-way-around\">3. Adapt to the customer, not the other way around</h3>\n\n<p>The times of asking customers to change how they work are gone. Now, SaaS vendors that differentiate by being ultra customizable win the hearts of customers.</p>\n\n<p>How? It\u2019s the most powerful secret to increase usage. We\u2019ve all heard the classic SaaS problem where the software is sold at the beginning of the year, but no one actually ends up using it because of how inflexible it is and the amount of training needed.</p>\n\n<p>And if a SaaS is underutilized, it gets noticed. And that leads to churn.</p>\n\n<p>This is the case with one of my customers, they have a complex SaaS for maintenance operations. But turns out, this was not being used at the technician level because they found the UI too complex<sup id=\"fnref:5\"><a class=\"footnote\" href=\"https://nmn.gl/blog/ai-killing-b2b-saas#fn:5\" rel=\"footnote\">4</a></sup>.</p>\n\n<p>How I\u2019m solving this is essentially a whitelabelled vibe-coding platform with in-built distribution and secure deployments. When they heard of my solution they were immediately onboard. Their customer success teams quickly coded a very specific mobile webapp for the technicians to use and deployed it in a few days.</p>\n\n<p>Now, the IC technician is exposed to just those parts of the SaaS that they care about i.e. creating maintenance work orders. The executives get what they want too, vibe coding custom reports exactly the way they want vs going through complicated BI config. They are able to build exactly what they want and feel like digital gods while doing it.</p>\n\n<p><strong>Usage for that account was under 35%, and is now over 70%.</strong> They are now working closely with me to vibe code new \u201cmicro-apps\u201d that work according to all of their customer workflows. And the best part? This is all on top of their existing SaaS which works as a system of record and handles security, authentication, and supports lock-in by being a data and a UI moat.</p>\n\n<p>This is exactly what I\u2019m building: a way for SaaS companies to let their end-users vibe code on top of their platform (More on that below). My customers tell me it\u2019s the best thing they\u2019ve done for retention, engagement, and expansion in 2026 \u2013 because when your users are building on your platform, they\u2019re not evaluating your competitors.</p>\n\n<h2 id=\"the-real-shift\">The Real Shift</h2>\n\n<p>Here\u2019s what I\u2019ve realized after hundreds of conversations with founders and operators: AI isn\u2019t killing B2B SaaS. It\u2019s killing B2B SaaS <strong>that refuses to evolve</strong>.</p>\n\n<p>The SaaS model was built on a simple premise: we build it once, you pay forever. That worked when building software was hard. But now your customers have tasted what\u2019s possible. They\u2019ve seen their finance team whip up a custom dashboard in an afternoon. They\u2019ve watched a non-technical PM build an internal tool that actually fits their workflow.</p>\n\n<p>You can\u2019t unsee that. You can\u2019t go back to paying $X0,000/year for software that almost does what you need.</p>\n\n<p>The survivors won\u2019t be the SaaS companies with the best features. They\u2019ll be the ones who become platforms \u2013 who let customers build <em>on top of</em> them instead of <em>instead of</em> them. When I showed a well-known VC what I was building to help SaaS companies do exactly this, he said: \u201cThis is the future of marketplaces and software companies.\u201d</p>\n\n<p>Maybe. Or maybe this is just another cycle and traditional SaaS will adapt like it always has. But I know this: the companies I\u2019m talking to aren\u2019t waiting around to find out. They\u2019re already rebuilding their relationship with customers from \u201cuse our product\u201d to \u201cbuild on our platform.\u201d</p>\n\n<p>The question isn\u2019t whether AI will eat your SaaS.</p>\n\n<p>It\u2019s whether you\u2019ll be the one holding the fork.</p>\n\n<hr />\n\n<p><strong>I\u2019m solving exactly this problem with a whitelabelled AI platform for B2B SaaS companies</strong>, so your users can vibe code customized workflows on top of their existing system of record.</p>\n\n<p>My customers tell me this is the <strong>best way to support retention, engagement, and expansion</strong> in 2026. If this sounds interesting to you or someone you know, <a href=\"\">I can reach out with a custom demo</a> or you can <a href=\"https://gigamind.dev/catalyst\" target=\"_blank\">learn more about Giga Catalyst</a>.</p>\n\n<hr />\n\n<div class=\"footnotes\">\n  <ol>\n    <li id=\"fn:1\">\n      <p>Whenever I bring a new friend to the Salesforce Park, they are in absolute awe. And, the meme remains true that no one even knows what Salesforce does. Whatever they\u2019re doing, they\u2019re clearly earning enough revenue to purchase multiple blocks in SF.\u00a0<a class=\"reversefootnote\" href=\"https://nmn.gl/blog/ai-killing-b2b-saas#fnref:1\">&#8617;</a></p>\n    </li>\n    <li id=\"fn:3\">\n      <p>a.k.a. \u201cprompt engineering\u201d which is not engineering at all but that\u2019s a different blog post.\u00a0<a class=\"reversefootnote\" href=\"https://nmn.gl/blog/ai-killing-b2b-saas#fnref:3\">&#8617;</a></p>\n    </li>\n    <li id=\"fn:4\">\n      <p>I won\u2019t name any names, but the company\u2019s named after an invertebrate animal.\u00a0<a class=\"reversefootnote\" href=\"https://nmn.gl/blog/ai-killing-b2b-saas#fnref:4\">&#8617;</a></p>\n    </li>\n    <li id=\"fn:5\">\n      <p>And who can blame them \u2013 I still feel a pang of anxiety when I look at my sales CRM.\u00a0<a class=\"reversefootnote\" href=\"https://nmn.gl/blog/ai-killing-b2b-saas#fnref:5\">&#8617;</a></p>\n    </li>\n  </ol>\n</div>"
            ],
            "link": "https://nmn.gl/blog/ai-killing-b2b-saas",
            "publishedAt": "2026-02-04",
            "source": "Namanyay Goel",
            "summary": "SaaS is the most profitable business model on Earth.1 It\u2019s easy to understand why: build once, sell the same thing again ad infinitum, and don\u2019t suffer any marginal costs on more sales. I have been writing software for more than half my life. In the last year itself, I\u2019ve talked to hundreds of founders and operators in SF, from preseed to Series E companies. AI is bringing an existential threat to a lot of B2B SaaS executives: How to keep asking customers for renewal, when every customer feels they can get something better built with vibe-coded AI products? And the market is pricing it in. Morgan Stanley\u2019s SaaS basket has lagged the Nasdaq by 40 points since December. HubSpot and Klaviyo are down ~30%. Analysts are writing notes titled \u201cNo Reasons to Own\u201d software stocks. The market is reflecting our new reality (Source: Bloomberg) Whenever I bring a new friend to the Salesforce Park, they are in absolute awe. And, the meme remains true that no one even knows what Salesforce does. Whatever they\u2019re doing, they\u2019re clearly earning enough revenue to purchase multiple blocks in SF. &#8617;",
            "title": "AI is Killing B2B SaaS"
        },
        {
            "content": [],
            "link": "https://www.robinsloan.com/lab/found-art/",
            "publishedAt": "2026-02-04",
            "source": "Robin Sloan",
            "summary": "<p>Mehretu raises a single eyebrow. <a href=\"https://www.robinsloan.com/lab/found-art/\">Read here.</a></p>",
            "title": "Found art"
        },
        {
            "content": [],
            "link": "https://www.robinsloan.com/lab/pace-layers/",
            "publishedAt": "2026-02-04",
            "source": "Robin Sloan",
            "summary": "<p>News of nature. <a href=\"https://www.robinsloan.com/lab/pace-layers/\">Read here.</a></p>",
            "title": "Pace layers"
        },
        {
            "content": [],
            "link": "https://simonwillison.net/2026/Feb/4/distributing-go-binaries/#atom-entries",
            "publishedAt": "2026-02-04",
            "source": "Simon Willison",
            "summary": "<p>I've been exploring Go for building small, fast and self-contained binary applications recently. I'm enjoying how there's generally one obvious way to do things and the resulting code is boring and readable - and something that LLMs are very competent at writing. The one catch is distribution, but it turns out publishing Go binaries to PyPI means any Go binary can be just a <code>uvx package-name</code> call away.</p> <h4 id=\"sqlite-scanner\">sqlite-scanner</h4> <p><a href=\"https://github.com/simonw/sqlite-scanner\">sqlite-scanner</a> is my new Go CLI tool for scanning a filesystem for SQLite database files.</p> <p>It works by checking if the first 16 bytes of the file exactly match the SQLite magic number sequence <code>SQLite format 3\\x00</code>. It can search one or more folders recursively, spinning up concurrent goroutines to accelerate the scan. It streams out results as it finds them in plain text, JSON or newline-delimited JSON. It can optionally display the file sizes as well.</p> <p>To try it out you can download a release from the <a href=\"https://github.com/simonw/sqlite-scanner/releases\">GitHub releases</a> - and then <a href=\"https://support.apple.com/en-us/102445\">jump through macOS hoops</a> to execute an \"unsafe\" binary. Or you can clone the repo and compile it with Go. Or... you can run the binary like this:</p> <pre><code>uvx sqlite-scanner </code></pre> <p>By default this",
            "title": "Distributing Go binaries like sqlite-scanner through PyPI using go-to-wheel"
        },
        {
            "content": [
                "<span class=\"thumbnail\"><img alt=\"\" class=\"attachment-thumbnail size-thumbnail wp-post-image\" height=\"104\" src=\"https://content.wolfram.com/sites/43/2026/02/metaphysics-icon.png\" width=\"124\" /></span><p><!--margin img--></p>\n\n<p style=\"font-size: 90%;\"><em>The Wolfram Institute recently received a grant from the Templeton World Charity Foundation for \u201c</em><em><a href=\"https://www.templetonworldcharity.org/projects-resources/project-database/34225\" rel=\"noopener\" target=\"_blank\">Computational Metaphysics</a></em><em>\u201d. I wrote this piece in part as a launching point for discussions with experts in traditional philosophy. </em></p>\n<h2 id=\"moving-metaphysics-from-philosophy-to-science\">Moving Metaphysics from Philosophy to Science</h2>\n<p style=\"display: inline-block; float: left; padding: 0px; margin: 0px; margin-top: 9px; margin-right: 8px;\"><img alt=\"Moving Metaphysics from Philosophy to Science\" class=\"bookpost\" height=\"70\" src=\"https://content.wolfram.com/sites/43/2026/02/sw02032026movingimg1-a.png\" title=\"Moving Metaphysics from Philosophy to Science\" width=\"95\" /></p>\n<p>\u201cWhat ultimately is there?\u201d has always been seen as a fundamental\u2014if thorny\u2014question for philosophy, or perhaps theology. But despite a couple of millennia of discussion, I think it\u2019s fair to say that only modest progress has been made with it. But maybe, just maybe, this is the moment where that\u2019s going to change\u2014and on the basis of surprising new ideas and new results from <a href=\"https://writings.stephenwolfram.com/all-by-date/\">our latest efforts in science</a>, it\u2019s finally going to be possible to make real progress, and in the end to build what amounts to a formal, scientific approach to metaphysics.</p>\n<p>It all centers around the ultimate foundational construct that I <a href=\"https://writings.stephenwolfram.com/2021/11/the-concept-of-the-ruliad/\">call the ruliad</a>\u2014and how <a href=\"https://writings.stephenwolfram.com/2023/12/observer-theory/\">observers like us</a>, embedded within it, must perceive it. And it\u2019s a story of how\u2014for observers like us\u2014fundamental concepts like space, time, mathematics, laws of nature, and indeed, objective reality, must inevitably emerge.<span id=\"more-73068\"></span></p>\n<p>Traditional philosophical thinking about metaphysical questions has often become polarized into strongly opposing views. But one of the remarkable things we\u2019ll see here is that with what we learn from science we\u2019ll often be able to bring together these opposing views\u2014typically in rather unexpected ways. </p>\n<p>I should emphasize that my goal here is to summarize what we can now say about metaphysics on the basis of our recent progress in science. It\u2019ll be very valuable to connect this to historical positions and historical thinking in philosophy and theology\u2014but that\u2019s not something I\u2019m going to attempt to do here. I should also say that I\u2019m going to concentrate on the major intellectual arc of what one can think of as a new scientific approach to metaphysics; the technical details of the science I\u2019ve mostly already <a href=\"https://writings.stephenwolfram.com/category/philosophy/\">discussed elsewhere</a>. </p>\n<h2 id=\"the-foundations-of-physics\">The Foundations of Physics</h2>\n<p style=\"display: inline-block; float: left; padding: 0px; margin: 0px; margin-top: 9px; margin-right: 8px;\"><img alt=\"The Foundations of Physics\" class=\"bookpost\" height=\"70\" src=\"https://content.wolfram.com/sites/43/2026/02/sw02032026foundationsimg1-a.png\" title=\"The Foundations of Physics\" width=\"95\" /></p>\n<p>We\u2019re going to begin our journey by talking about the traditional objective of physics: to find abstract theories that describe what we observe and measure in the physical world. <a href=\"https://writings.stephenwolfram.com/2020/04/how-we-got-here-the-backstory-of-the-wolfram-physics-project/#why-wasnt-this-already-figured-out\">From the history of physics</a> we\u2019ve come to expect that such theories will always end up being at best successive approximations. But the new possibility raised by our <a href=\"https://www.wolframphysics.org/\" rel=\"noopener\" target=\"_blank\">Physics Project</a> is that we may now finally have reached the end: a <a href=\"https://writings.stephenwolfram.com/2020/04/finally-we-may-have-a-path-to-the-fundamental-theory-of-physics-and-its-beautiful/\">truly fundamental theory of physics</a>, that provides a complete description of the lowest-level \u201cmachine code\u201d of our universe.</p>\n<p>Already in antiquity the question arose of whether the universe is ultimately a continuum or is made of discrete atomic elements. By the end of the nineteenth century it was finally established that matter, at least, consists of discrete elements. And soon it became clear that light could be thought of in the same way. But what about space? Ever since Euclid, it had been assumed that space was a continuum. And efforts in the early twentieth century to see whether it, like matter, might be discrete did not work out. </p>\n<p>But a century later, building on new, computationally inspired ideas, our Physics Project starts from the <a href=\"https://writings.stephenwolfram.com/2020/04/finally-we-may-have-a-path-to-the-fundamental-theory-of-physics-and-its-beautiful/#what-is-space\">concept that space is not just a simple continuum</a>. Instead, it\u2019s a complicated discrete structure that in fact represents every aspect of our universe\u2014both what we normally think of as space, and everything in it. There are many ways one can imagine describing this structure. A convenient one is to say that it consists of a very large number of discrete intrinsically identical \u201catoms of space\u201d\u2014that one can think of as being like disembodied geometrical points\u2014whose only property (other than being distinct) is how they\u2019re abstractly related to other atoms of space. In other words, we imagine describing the whole structure of the universe in terms of the pattern of relations between the atoms of space. And it\u2019s convenient to <a href=\"https://www.wolframphysics.org/technical-introduction/basic-form-of-models/\" rel=\"noopener\" target=\"_blank\">represent this as a hypergraph</a> whose nodes are atoms of space, and whose hyperedges define the relations between them. (If relations are only between pairs of nodes, this becomes an ordinary graph.) </p>\n<p>An important piece of intuition that comes from our practical experience with computers is that it\u2019s possible to represent everything we deal with in terms of bits. But when we also want to represent the structure of space it\u2019s better to think not in terms of bits in some predetermined arrangement, but instead in terms of the lower level and more flexible \u201cdata structure\u201d defined by a hypergraph. </p>\n<p>So how can the universe as we normally perceive it emerge from this? It\u2019s very much analogous to what happens with matter. For example, even though something like water consists of discrete molecules, the aggregate effect of them is to <a href=\"https://www.wolframscience.com/nks/p378--fluid-flow/\">produce seemingly continuous fluid behavior</a>. But then\u2014still made up of the same underlying molecules\u2014we can have discrete eddies in the fluid, analogous <a href=\"https://writings.stephenwolfram.com/2020/04/finally-we-may-have-a-path-to-the-fundamental-theory-of-physics-and-its-beautiful/#elementary-particles-old-and-new\">in the case of space to particles</a> like electrons (or, for that matter, black holes). </p>\n<h2 id=\"time-and-spacetime\">Time and Spacetime</h2>\n<p style=\"display: inline-block; float: left; padding: 0px; margin: 0px; margin-top: 9px; margin-right: 8px;\"><img alt=\"Time and Spacetime\" class=\"bookpost\" height=\"70\" src=\"https://content.wolfram.com/sites/43/2026/02/sw02032026timeimg1-a.png\" title=\"Time and Spacetime\" width=\"95\" /></p>\n<p>If there\u2019s a hypergraph that\u2019s the ultimate \u201cdata structure\u201d of the universe, what are the algorithms that get applied to it? Just as we imagine the data structure to consist of discrete elements, so also we imagine that changes to it occur by discrete events. And for now we can imagine that there\u2019s some fixed rule that determines these elementary events. For example, <a href=\"https://writings.stephenwolfram.com/2020/04/finally-we-may-have-a-path-to-the-fundamental-theory-of-physics-and-its-beautiful/#how-it-works\">the rule might be that whenever a piece of the hypergraph has some specified form</a>, it should be replaced by a piece of hypergraph with some other specified form. </p>\n<p>We can think of the application of such a rule as corresponding to the computation of the \u201cnext state\u201d of the universe from the previous one. And if the rule is repeatedly applied, it will generate a whole sequence of updated states of the universe. And we can then identify the progression of these states as <a href=\"https://writings.stephenwolfram.com/2024/10/on-the-nature-of-time/\">corresponding to the progression of time in the universe</a>. </p>\n<p>It\u2019s notable that in this setup space and time are, at least at the outset, different kinds of things. Space is associated with the structure of the hypergraph, yet time is associated with computation on it. </p>\n<p>Still, just as the hypergraph defines relations between atoms of space, we can imagine a <a href=\"https://writings.stephenwolfram.com/2020/04/finally-we-may-have-a-path-to-the-fundamental-theory-of-physics-and-its-beautiful/#the-graph-of-causal-relationships\">causal graph</a> that defines \u201ccausal relations\u201d between events. Any particular event can be thought of as taking some collection of atoms of space as \u201cinputs\u201d, and producing some other collection of atoms of space as \u201coutputs\u201d. But this then implies a causal relation between events: any event that uses as input an atom of space that was generated as output by another event can be thought of as \u201ccausally dependent\u201d on that other event. </p>\n<p>And the whole pattern of these causal relations ultimately defines a causal graph for all events in the universe\u2014that in a sense encodes the structure of the universe in both space and time. </p>\n<p>But given such a causal graph, can we reconstruct a series of hypergraphs from it? We can think of such hypergraphs as representing successive \u201cinstantaneous states of space\u201d. And\u2014just like in relativity\u2014it turns out that there isn\u2019t a unique possible such sequence of states. Instead, there are <a href=\"https://www.wolframphysics.org/technical-introduction/the-updating-process-for-string-substitution-systems/causal-foliations-and-causal-cones/\" rel=\"noopener\" target=\"_blank\">many different sequences</a>, all consistent with the underlying causal graph\u2014and corresponding in traditional physics terms to different relativistic reference frames.</p>\n<p>In effect, therefore, we can think of the causal graph as being the \u201ctrue representation\u201d of information about the universe. Any particular \u201creconstructed\u201d sequence of hypergraphs inevitably involves arbitrary choices. </p>\n<p>When we introduced the causal graph, we talked about building it by starting from a particular hypergraph, and then looking at the effect of applying rules to it. But the point is that it turns out there\u2019s a lot of choice in both the hypergraph and how we apply the rules, but (as a result of the <a href=\"https://www.wolframphysics.org/technical-introduction/the-updating-process-for-string-substitution-systems/the-phenomenon-of-causal-invariance/\" rel=\"noopener\" target=\"_blank\">phenomenon of causal invariance</a>) essentially all choices will lead us to the same causal graph. </p>\n<p>We might have imagined that given a fundamental theory of physics we should be able to ask what the universe in some sense \u201cstatically is\u201d. But what we\u2019re discovering is that we should instead be talking about the processes that happen in the universe\u2014as represented by the causal graph.</p>\n<p>We can identify the <a href=\"https://writings.stephenwolfram.com/2024/10/on-the-nature-of-time/\">passage of time</a> as the progression of events in the causal graph. But why is there even something like space? Ultimately it turns out to be a reflection of the \u201centanglement\u201d of different sequences of events in the causal graph\u2014and its structure is in effect a map of the relations between these sequences of events (a structure which can conveniently be represented by a hypergraph). </p>\n<p>Imagine starting from one event in the causal graph, then tracing a sequence of events that depend on it. We can think of the successive events as occurring progressively later in time. But what about two events that are both immediate successors of a given event? What is their relationship? The key idea is that even though these \u201csibling\u201d events occur \u201cat the same time\u201d, they are still separated\u2014in what we can think of as space.</p>\n<p>But how then is \u201cspace as a whole\u201d formed? Ultimately it\u2019s something very dynamic. And indeed it\u2019s the continual occurrence of events in the universe that \u201cknits together\u201d the structure of space. Without such \u201cactivity\u201d, there would be nothing we could coherently consider as \u201cspace\u201d.</p>\n<p>At the level of atoms of space there is nothing permanent in the universe; in every elementary event, atoms of space are destroyed, and new ones created. But somehow at an aggregate level there is a certain stability to what emerges. It\u2019s again a little like with fluids, where the microscopic motions of huge numbers of underlying molecules lead in the aggregate to the laws of fluid mechanics. </p>\n<p>But what then are the aggregate laws that emerge from large numbers of hypergraph updates? Remarkably enough, they almost inevitably <a href=\"https://writings.stephenwolfram.com/2020/04/finally-we-may-have-a-path-to-the-fundamental-theory-of-physics-and-its-beautiful/#general-relativity-and-gravity\">turn out to be exactly the Einstein equations</a>: the equations that seem to govern the large-scale structure of spacetime. So even though what\u2019s \u201cthere underneath\u201d is just what we might think of as \u201cabstract\u201d atoms of space and rules for rewriting relations between them, what emerges is something that reproduces familiar elements of what we think of as \u201cphysical reality\u201d. </p>\n<h2 id=\"the-phenomenon-of-computational-irreducibility\">The Phenomenon of Computational Irreducibility</h2>\n<p style=\"display: inline-block; float: left; padding: 0px; margin: 0px; margin-top: 9px; margin-right: 8px;\"><img alt=\"The Phenomenon of Computational Irreducibility\" class=\"bookpost\" height=\"70\" src=\"https://content.wolfram.com/sites/43/2026/02/sw02032026phenomenonimg1-a.png\" title=\"The Phenomenon of Computational Irreducibility\" width=\"95\" /></p>\n<p>If there\u2019s a rule that can ultimately reproduce the behavior of the universe, how complicated a rule does that need to be? Our traditional intuition\u2014say from experience from engineering\u2014is that one needs a complicated rule if one wants to produce complicated behavior. But my <a href=\"https://www.wolframscience.com/nks/chap-2--the-crucial-experiment/\">big discovery from the early 1980s</a> is that this isn\u2019t the case\u2014and that in fact it\u2019s perfectly possible even for extremely simple underlying rules (like <a href=\"https://www.wolframscience.com/nks/p27--how-do-simple-programs-behave/\">my favorite \u201crule 30\u201d</a>) to produce behavior of immense complexity. </p>\n<p>But why ultimately does this happen? We can think of running a rule as being like running a program, or, in other words, like doing a computation. But how sophisticated is that computation? We might have thought that different rules would do incomparably different computations. But the <a href=\"https://www.wolframscience.com/nks/chap-11--the-notion-of-computation#sect-11-3--the-phenomenon-of-universality\">existence of universal computation</a>\u2014discovered a century ago\u2014implies that in fact there\u2019s a class of universal rules that can effectively emulate any other rule (and this is why, for example, software is possible).</p>\n<p>But actually there\u2019s a lot more that can be said. And in particular my <a href=\"https://www.wolframscience.com/nks/chap-12--the-principle-of-computational-equivalence/\">Principle of Computational Equivalence</a> implies that essentially whenever one sees a system whose behavior is not obviously simple, the system will actually be doing a computation that is in some sense as sophisticated as it can be. In other words, sophisticated computation isn\u2019t just a feature of specially set up \u201ccomputer-like\u201d systems; it\u2019s ubiquitous, even among systems with simple underlying rules.</p>\n<p>So what does this mean? It\u2019s often considered a goal of science to be able to predict what systems will do. But to make such a prediction requires in a sense being able to \u201cjump ahead\u201d of the behavior of the system itself. But the Principle of Computational Equivalence tells us that this won\u2019t in general be possible\u2014because it\u2019s ubiquitous for the system we\u2019re trying to predict to be just as computationally sophisticated as the system we\u2019re trying to use to predict it. And the result of this is the <a href=\"https://www.wolframscience.com/nks/chap-12--the-principle-of-computational-equivalence#sect-12-6--computational-irreducibility\">phenomenon of computational irreducibility</a>. </p>\n<p>You can always find out what a system will do just by explicitly running its rules step by step. But if the system is computationally irreducible there\u2019ll be no general way to shortcut this, and to find the result with reduced computational effort. </p>\n<p>Computational irreducibility is what irreducibly separates underlying rules from the behavior they produce. And it\u2019s what causes even simple rules to be able to generate behavior that cannot be \u201cdecoded\u201d except by irreducibly great computational effort\u2014and therefore will be <a href=\"https://www.wolframscience.com/nks/chap-7--mechanisms-in-programs-and-nature#sect-7-5--the-intrinsic-generation-of-randomness\">considered random by an observer</a> with bounded computational capabilities. </p>\n<p>Computational irreducibility is also what in a sense makes <a href=\"https://writings.stephenwolfram.com/2024/10/on-the-nature-of-time/\">time something \u201creal\u201d</a>. We discussed above that the passage of time corresponds to the progressive application of computational rules. Computational irreducibility is what makes that process \u201cadd up to something\u201d. And the Principle of Computational Equivalence is what tells us that there\u2019s something we can think of as time that is in effect \u201cpure, irreducible computation\u201d independent of the system in which we\u2019re studying it. </p>\n<p>It\u2019s very much the same story with space. Computational irreducibility in general leads to a certain \u201cuniform effective randomness\u201d in the structure of hypergraphs, which is what allows us to imagine that there\u2019s a definite \u201csubstrate independent\u201d concept of space.</p>\n<p>There\u2019s a close analogy here to <a href=\"https://writings.stephenwolfram.com/2023/02/computational-foundations-for-the-second-law-of-thermodynamics/\">what happens in something like a fluid</a>. At a molecular level there are lots of molecular collisions going on. But the point is that this is a computationally irreducible process\u2014whose end result is enough \u201cuniform effective randomness\u201d that we can meaningfully talk about the properties of the fluid \u201cin bulk\u201d, as a thing in itself, without having to mention that it\u2019s made of molecules.</p>\n<p>So how does all this relate to our original metaphysical question of what there ultimately is? Computational irreducibility introduces the idea that there\u2019s something robust and invariant about \u201cpure computation\u201d\u2014something that doesn\u2019t depend on the details of what\u2019s \u201cimplementing\u201d that computation. Or, in other words, that there\u2019s a sense in which it\u2019s meaningful to talk about things simply being \u201cmade of computation\u201d.</p>\n<h2 id=\"the-significance-of-the-observer\">The Significance of the Observer</h2>\n<p style=\"display: inline-block; float: left; padding: 0px; margin: 0px; margin-top: 9px; margin-right: 8px;\"><img alt=\"The Significance of the Observer\" class=\"bookpost\" height=\"70\" src=\"https://content.wolfram.com/sites/43/2026/02/sw02032026significanceimg1-a.png\" title=\"The Significance of the Observer\" width=\"95\" /></p>\n<p>In talking about things like a hypergraph representing space and everything in it, we\u2019re giving in a sense an objective description of the universe \u201cfrom the outside\u201d. But what ultimately matters to us is not what\u2019s \u201cin principle out there\u201d, but rather what we actually perceive. And indeed we can think of science as being first and foremost a way to find narrative descriptions which fit in our minds of certain aspects of what\u2019s out there. </p>\n<p>But given computational irreducibility, why is this even possible? Why are there ever, for example, \u201claws of nature\u201d which let us make predictions about things, even with the bounded amount of computation that our finite minds can do?</p>\n<p>The answer is related to an inevitable and fundamental feature of computational irreducibility: that within any computationally irreducible process there must always be an infinite number of pockets of computational reducibility. In other words, even though computational irreducibility makes it irreducibly difficult to say everything about what a system will do, there will always be pockets of reducibility which allow one to say certain things about it. And it\u2019s such pockets of reducibility that our processes of perception\u2014and our science\u2014make use of. </p>\n<p>Once again we can use fluid dynamics as an example. Even though the detailed pattern of underlying molecular motions in a fluid is computationally irreducible, there are still computationally simple overall laws of fluid flow\u2014that we can think of as being associated with pockets of computational reducibility. And from our point of view as computationally bounded observers, we tend to think of these as the laws of the fluid.</p>\n<p>In other words, the laws we attribute to a system depend on our <a href=\"https://writings.stephenwolfram.com/2023/12/observer-theory/\">capabilities as observers</a>. Consider the <a href=\"https://writings.stephenwolfram.com/2023/02/computational-foundations-for-the-second-law-of-thermodynamics/\">Second Law of thermodynamics</a>, and imagine starting from some simple configuration, say of gas molecules. The dynamics of these molecules will generically correspond to a computationally irreducible process\u2014whose outcome to a computationally bounded observer like us will seem \u201cincreasingly random\u201d. Of course, if we were not computationally bounded, then we\u2019d be able to \u201cdecode\u201d the whole underlying computationally irreducible process, and we wouldn\u2019t believe in the presence of seemingly increasing randomness, or, for that matter, the Second Law. But\u2014regardless of any details\u2014as soon as we\u2019re computationally bounded, we\u2019ll immediately perceive the Second Law.</p>\n<p>We might have assumed that the Second Law was some kind of intrinsic law of nature\u2014directly related to what there ultimately is. But what we see is that the Second Law is something that emerges because of us, and our characteristics as observers, and in particular our computational boundedness. </p>\n<p>There are other things that also work this way\u2014for example, our belief in a coherent notion of space. At the lowest level we imagine that there\u2019s a discrete hypergraph being updated through what\u2019s ultimately a computationally irreducible process. But as computationally bounded observers we only perceive certain aggregate features\u2014that correspond in effect to a pocket of computational reducibility associated with our simple, continuous perception of space.</p>\n<p>When we think about spacetime\u2014and for example about deriving its relativistic properties\u2014there\u2019s another feature of us as observers that also turns out to be important: the fact that we <a href=\"https://writings.stephenwolfram.com/2021/03/what-is-consciousness-some-new-perspectives-from-our-physics-project/\">assume that we are persistent in time</a>, and that\u2014even though we might be made of different atoms of space at every successive moment of time\u2014we can still successfully knit together perceptions at successive moments of time to form a single thread of experience. In a sense this is a \u201csimplification\u201d forced upon us by our computational boundedness. But it\u2019s also in many ways at the core of what we think of as our <a href=\"https://writings.stephenwolfram.com/2021/03/what-is-consciousness-some-new-perspectives-from-our-physics-project/\">notion of consciousness</a> (which is something I\u2019ve <a href=\"https://writings.stephenwolfram.com/2021/03/what-is-consciousness-some-new-perspectives-from-our-physics-project/\">written about</a> at some length <a href=\"https://writings.stephenwolfram.com/2025/05/what-if-we-had-bigger-brains-imagining-minds-beyond-ours/\">elsewhere</a>).</p>\n<p>The Principle of Computational Equivalence implies that sophisticated computation is ubiquitous\u2014and certainly not something special to brains. And indeed it seems that <a href=\"https://writings.stephenwolfram.com/2025/05/what-if-we-had-bigger-brains-imagining-minds-beyond-ours/#how-brains-seem-to-work\">brains actually concentrate on a specific\u2014and in many ways limited\u2014form of computation</a>. They take in large amounts of sensory data, and in effect compress it to derive what\u2019s ultimately a thin stream of actions for us to take. At a biological level, there\u2019s always all sorts of activity going on across the billions of neurons in our brains. But our brains are, it seems, specially constructed to concentrate all that activity down to what\u2019s essentially a single thread of thought, action and \u201cexperience\u201d. And it\u2019s the fact that this is a single thread that seems to give us our sense of coherent existence, and in effect, of consciousness. </p>\n<h2 id=\"quantum-mechanics-and-multiway-systems\">Quantum Mechanics and Multiway Systems</h2>\n<p style=\"display: inline-block; float: left; padding: 0px; margin: 0px; margin-top: 9px; margin-right: 8px;\"><img alt=\"Quantum Mechanics and Multiway Systems\" class=\"bookpost\" height=\"70\" src=\"https://content.wolfram.com/sites/43/2026/02/sw02032026quantumimg1-a.png\" title=\"Quantum Mechanics and Multiway Systems\" width=\"95\" /></p>\n<p>Traditional classical physics talks about definite things happening in the universe\u2014say a projectile following a definite path, determined by its laws of motion. But quantum mechanics instead talks about many paths being followed\u2014specifying only probabilities for their various outcomes.</p>\n<p>In this history of physics quantum mechanics was a kind of \u201cadd on\u201d. But <a href=\"https://writings.stephenwolfram.com/2020/04/finally-we-may-have-a-path-to-the-fundamental-theory-of-physics-and-its-beautiful/#the-inevitability-of-quantum-mechanics\">in our Physics Project it&#8217;s immediately essential</a>, and unavoidable. Because the rules that we define simply say that whenever there is a piece of a hypergraph that matches a particular pattern, it should be transformed. But in general there will be many such matches\u2014each one producing a different transformation, and each one in effect initiating what we can think of as a different path of history. And in addition to such branching, there can also be merging\u2014when different transformations end up producing the same hypergraph.</p>\n<p>We can represent all these branching and merging paths of history by what I call a <a href=\"https://writings.stephenwolfram.com/2021/09/multicomputation-a-fourth-paradigm-for-theoretical-science/#multiway-systems-and-the-concept-of-the-multicomputation\">multiway graph</a>. And we can think of such a multiway graph as giving a complete description of \u201cwhat happens\u201d in the universe.</p>\n<p>But as we discussed above, observers like us maintain just a single thread of experience. And that means we can\u2019t directly perceive a whole multiway graph. Instead, we have to effectively pick out just one path from it. But which path will it be? At the level of the formalism of quantum mechanics\u2014or of our Physics Project\u2014the only thing we talk about is the whole collection of all paths. So something else must determine the path.</p>\n<p>In physical space, we\u2019re used to the idea that we as observers are localized at a particular position, and only get to directly perceive what\u2019s around where we are. Across all of physical space, there are lots of things going on. But because of where we happen to be, we only get to directly perceive a tiny sample of them.</p>\n<p>So is something similar going on in picking paths of history from the multiway graph? It seems that it is. If we take a slice across the multiway graph at any particular time, we\u2019ll have lots of \u201cdangling ends\u201d of paths of history, each associated with a different state of the universe. But inevitably there are lots of relations between these states. (For example, two states might have an immediate common ancestor.) And it turns out that we can think of the states as being laid out in what we can call \u201c<a href=\"https://www.wolframphysics.org/technical-introduction/the-updating-process-for-string-substitution-systems/the-concept-of-branchial-graphs/\" rel=\"noopener\" target=\"_blank\">branchial space</a>\u201d. </p>\n<p>And just like in physical space, we can expect that we as observers are localized in branchial space. So that means that even though there are at some level many different paths of history, we only get to perceive ones that are around \u201cwhere we are\u201d. And just like there\u2019s no \u201ctheory\u201d that tells us where we find ourselves in physical space (which planet, which galaxy, etc.), the same is true in branchial space. One day we might have some way to describe our location in branchial space, but for now the best we can do is say that it\u2019s \u201crandom\u201d.</p>\n<p>And this, I believe, is why outcomes in quantum mechanics seem to us random. The whole multiway graph is completely determined (as wave functions etc. are even in the standard formalism of quantum mechanics). But which part of the multiway graph we as observers sample depends on where we are in branchial space.</p>\n<p>And we can expect that just as we humans are all close together in physical space, so are we in branchial space. And this means that even though in the abstract the result of, say, some particular quantum measurement might seem \u201crandom\u201d, all human observers\u2014being nearby in branchial space\u2014will tend to agree what that result is, and at least among them, there\u2019ll be something they can consider \u201cobjective reality\u201d.</p>\n<h2 id=\"the-concept-of-the-ruliad\">The Concept of the Ruliad</h2>\n<p style=\"display: inline-block; float: left; padding: 0px; margin: 0px; margin-top: 9px; margin-right: 8px;\"><img alt=\"The Concept of the Ruliad\" class=\"bookpost\" height=\"70\" src=\"https://content.wolfram.com/sites/43/2026/02/sw02032026conceptimg1-a.png\" title=\"The Concept of the Ruliad\" width=\"95\" /></p>\n<p>The remarkable implication of our Physics Project is that our whole universe, in all its richness, can emerge just from the repeated application of a simple underlying rule. But which rule? How would it be selected?</p>\n<p>The <a href=\"https://writings.stephenwolfram.com/2021/11/the-concept-of-the-ruliad/\">idea of the ruliad</a> is to imagine that no selection is needed\u2014because all rules are being used. And the ruliad is what comes out: the entangled limit of all possible computational processes.</p>\n<p>We discussed in the context of quantum mechanics the idea that a given rule can get applied in multiple ways, leading to multiple paths of history. The ruliad takes this idea to the limit, applying not just one rule in all possible ways, but all possible rules in all possible ways. </p>\n<p>We can imagine representing the ruliad by a giant multiway graph\u2014in which there is a path that represents any conceivable specific computation. And what fundamentally gives the ruliad structure is that these paths can not only branch but also merge\u2014with mergers happening when different states lead to equivalent outcomes which are merged in the multiway graph.</p>\n<p>At first we can think of the ruliad as being built from all possible hypergraph rules in our Physics Project. But the Principle of Computational Equivalence implies that actually we can use any type of rule as our basis: since the ruliad contains all possible computational processes its final form will be the same. </p>\n<p>In other words, however we end up representing it, the intrinsic form of the ruliad is still the same. Once we have the concept of computation (or of following rules), the ruliad is an inevitable consequence. In some sense it is the ultimate closure of the concept of computation: the unique object that encapsulates all possible computational processes and the inevitable relations between them. </p>\n<p>We got to the ruliad by thinking about physics, and about the ultimate infrastructure of our physical universe. But the ruliad is something much more general than that. It\u2019s an abstract object that captures everything that is computationally formalizable, along with the elaborate structure of relations between such things. </p>\n<p>Of course, the idea that the ruliad can describe our actual physical universe is ultimately just a hypothesis\u2014though one that\u2019s strongly encouraged by the success of our Physics Project. </p>\n<p>How could it be wrong? Well, our universe could involve hypercomputation\u2014which is not finitely captured by the ruliad. And we might have to consider a <a href=\"https://writings.stephenwolfram.com/2021/11/the-concept-of-the-ruliad/#whats-beyond-the-ruliad\">whole hierarchy of possible hyperruliads</a>. (Though as we\u2019ll see, any effects from this would likely be beyond anything observers like us could perceive.)</p>\n<p>But assuming that the ruliad is the ultimate infrastructure for everything we can then ask what it\u2019s made of. At some level we could just say it\u2019s made of abstract computational processes. But what are those processes operating on? Again, abstract things. But we can imagine decomposing those abstract things. And while inevitably there will be different ways to do this, it\u2019ll often be convenient to imagine that they consist of relations between ultimate, indivisible objects\u2014which we can describe as \u201catoms of existence\u201d, or <a href=\"https://writings.stephenwolfram.com/2022/03/the-physicalization-of-metamathematics-and-its-implications-for-the-foundations-of-mathematics/#:~:text=I%E2%80%99ll%20call%20such%20atoms%20of%20existence%20%E2%80%9Cemes%E2%80%9D%20(pronounced%20%E2%80%9Ceemes%E2%80%9D%2C%20like%20phonemes%20etc.)\">what I\u2019ve called \u201cemes\u201d</a>. </p>\n<p>In our Physics Project, we identified emes with atoms of space. But in talking about the ruliad in general, we can think of them just as the \u201cultimate raw material for existence\u201d. Emes have no structure of their own. And indeed the only intrinsic thing one can say about them is that they are distinct: in a sense they are elementary units of identity. And we can then think of it being the relations between them that build up the ruliad\u2014and everything it underlies. </p>\n<h2 id=\"observers-in-the-ruliad-and-the-laws-of-nature\">Observers in the Ruliad and the Laws of Nature</h2>\n<p style=\"display: inline-block; float: left; padding: 0px; margin: 0px; margin-top: 9px; margin-right: 8px;\"><img alt=\"Observers in the Ruliad and the Laws of Nature\" class=\"bookpost\" height=\"70\" src=\"https://content.wolfram.com/sites/43/2026/02/sw02032026observersimg1-a.png\" title=\"Observers in the Ruliad and the Laws of Nature\" width=\"95\" /></p>\n<p>Our original metaphysical question was: \u201cWhat ultimately is there?\u201d And at some level our science has now led us to an answer: the ruliad is everything there ultimately is. </p>\n<p>But what about what there is for us? In other words, what about what there ultimately is in what we perceive and experience? Inevitably, we as observers must be part of the ruliad. And our \u201cinner experiences\u201d must similarly be represented within the ruliad. But in and of itself that\u2019s not enough to tell us much about what those experiences might be. And we might imagine that to work this out, we\u2019d need to know a lot of the particular details of our construction, and our place in the ruliad. </p>\n<p>But what\u2019s emerged in the last few years is that in many important ways, we don\u2019t. And instead just knowing certain coarse features of us as observers already <a href=\"https://writings.stephenwolfram.com/2023/12/observer-theory/\">implies a lot about what we must experience</a>. In particular, if we assume that we are observers who are computationally bounded, and believe we are persistent in time, then we argue that it is inevitable that we must perceive certain laws to be operating\u2014and those laws turn out to be exactly the three central laws of twentieth century physics: general relativity, quantum mechanics, and the Second Law of thermodynamics.</p>\n<p>It\u2019s a remarkable claim: the laws of physics we observe don\u2019t just happen to be the way they are; they are inevitable for observers with the general characteristics we have. At the level of the underlying ruliad the laws of physics that we might observe are not determined. But as soon as we know something about what we\u2019re like as observers, then we necessarily end up with our familiar laws of physics.</p>\n<p>In a sense, therefore, the laws of physics that we experience are the way they are because we are observers that are the way we are. We already discussed this above in the case of the Second Law. And although we don\u2019t yet know all the details, the basic conclusion is that by combining the abstract structure of the ruliad with our assumptions about what we\u2019re like as observers, we are able to derive all three of the familiar core laws of physics from the twentieth century. </p>\n<p>It\u2019s worth emphasizing that what we can immediately derive are in a sense \u201cgeneral laws\u201d. We know that spacetime has a certain overall structure, and its dynamics satisfy the Einstein equations. But we don\u2019t, for example, know why the universe as we perceive it has (at least approximately) 3 dimensions of space\u2014though my guess is that many such features of observed physics can ultimately be traced to <a href=\"https://writings.stephenwolfram.com/2023/12/observer-theory/#what-we-assume-about-ourselves\">features of the way we are as observers</a>. </p>\n<p>So what about <a href=\"https://writings.stephenwolfram.com/2021/11/the-concept-of-the-ruliad/#alien-views-of-the-ruliad\">observers not like us</a>? They\u2019re still part of the ruliad. But in a sense they\u2019re sampling it in a different way. And they\u2019ll potentially perceive quite different laws of physics. </p>\n<p>It\u2019s a very fundamental observation about our universe that we perceive it to follow fairly simple laws. But in a sense this too is just a feature of our nature as observers. Because given our computational boundedness we couldn\u2019t really make use of\u2014or even identify\u2014any laws that were not in some sense simple. </p>\n<p>The fact that simple laws are possible can be viewed as a reflection of the inevitable presence of pockets of computational reducibility within any computationally irreducible process. But it\u2019s our computational boundedness as observers that causes us to pick them out. If we were not computationally bounded then we could operate at the level of raw computational irreducibility, and any need to pick out simple laws. </p>\n<p>At the outset, we might have imagined that the laws of physics would somehow fundamentally be at the root of the question of \u201cwhat ultimately is there?\u201d But what we\u2019re seeing is that actually these laws are in a sense higher-level constructs, whose form depends on our characteristics as observers. And to get to our original metaphysical question, we have to \u201cdrill down\u201d beyond our perceived laws of physics to their \u201ccomputational infrastructure\u201d, and ultimately all the way to the ruliad.</p>\n<h2 id=\"the-question-of-objective-reality\">The Question of Objective Reality</h2>\n<p style=\"display: inline-block; float: left; padding: 0px; margin: 0px; margin-top: 9px; margin-right: 8px;\"><img alt=\"The Question of Objective Reality\" class=\"bookpost\" height=\"70\" src=\"https://content.wolfram.com/sites/43/2026/02/sw02032026questionimg1-a.png\" title=\"The Question of Objective Reality\" width=\"95\" /></p>\n<p>When we ask what there ultimately is, we\u2019re in some sense implicitly assuming that there actually is something definite\u2014or in effect that there\u2019s a single ultimate \u201cobjective reality\u201d. But is that actually how things work, or does every observer, for example, in effect \u201chave their own reality\u201d?</p>\n<p>In our approach, there\u2019s a quite nuanced answer. At the very lowest level there is a single ultimate objective reality that knits everything together\u2014and it\u2019s the ruliad. But meanwhile, different observers can in principle experience different things. But as soon as we\u2019re dealing with observers even vaguely like us (in the sense that they share our computational boundedness, and our belief in our own persistence) we\u2019ve argued that it\u2019s inevitable that they\u2019ll always experience the core laws of physics as we know them. In other words, these laws in effect represent a single objective reality\u2014at least across observers even vaguely like us.</p>\n<p>But what about more detailed features of our experience? No doubt some we\u2019ll be able to \u201cobjectively derive\u201d on the basis of characteristics we identify as shared across all \u201cobservers like us\u201d. But at some level, different observers will always have different experiences\u2014not least because, for example, they are typically operating at different places in space, and indeed in general at different places in the ruliad. </p>\n<p>Still, our everyday impression is that even though the detailed experiences, say, of different people looking at the same scene may be different, those experiences can nevertheless reasonably be thought of as all derived from the same \u201cunderlying objective reality\u201d. So why is this? Essentially I think it\u2019s because human observers are all very nearby in the ruliad\u2014so they\u2019re in a sense all sampling the same tiny part of the ruliad.</p>\n<p>Observers at different places in the ruliad in effect sample different threads of history, that operate according to different rules. But the Principle of Computational Equivalence tells us that\u2014just as it\u2019s always possible to translate from one universal computational system to another\u2014it\u2019ll always in the end be possible to translate between what observers get by sampling at different places in the ruliad. </p>\n<p>The difficulty of translation depends, though, on how far one is trying to go in the ruliad. Human minds exposed to similar knowledge, culture, etc. are nearby and fairly easy to translate between. Animal minds are further away, and more difficult to translate to. And when it comes to something like the weather, then even though in principle it\u2019s computationally equivalent, the distance one has to go in the ruliad to reach it is sufficiently great that translation is very difficult. </p>\n<p>Translation between places in the ruliad is in a sense just a generalization of translation in physical space. And the process of moving in physical space is what we describe as motion. But <a href=\"https://writings.stephenwolfram.com/2022/03/on-the-concept-of-motion/\">what actually is motion</a>? In effect it\u2019s having something move to a different place in space while still \u201cbeing the same thing\u201d. In our Physics Project, though, something must be made of different atoms of space if it\u2019s at a different place in space. But somehow there must be some pattern of atoms of space that\u2014a bit like an eddy in a fluid\u2014one can say represents \u201cthe same thing\u201d at different places in space. </p>\n<p>And potentially one can think of particles\u2014like electrons or photons\u2014as being in a sense \u201celementary carriers of pure motion\u201d: minimal objects that can move without changing. </p>\n<p>But how does this work more generally in the ruliad? What is it that can \u201cmove\u201d between observers, or between minds, without changing? Essentially it seems to be concepts (often in basic form represented by words). Within for example one human brain a thought corresponds to some complicated pattern of neural activity. But what allows it to be \u201cmoved\u201d to another brain is \u201cpackaging it up\u201d into a \u201cconcept\u201d that can be unpacked by another brain. And at some level it\u2019s this kind of communication that \u201caligns observers\u201d to have similar inner experiences\u2014to the point where they can be viewed as reflecting a common objective reality. </p>\n<p>But all of this somehow presupposes that there are many observers\u2014whose experiences can be thought of as \u201ctriangulating\u201d to a common objective reality. If there were just one observer, though, there\u2019s no triangulation to do, and one might imagine that all that would matter is the inner experience of that one observer.</p>\n<p>So in a sense the very notion that we can usefully talk about objective reality is a consequence of there being many similar observers. And of course in the specific case of us humans there are indeed billions of us.</p>\n<p>But from a fundamental point of view, why should there be many similar observers, or even any observers at all? As we discussed above, the <a href=\"https://writings.stephenwolfram.com/2023/12/observer-theory/\">core abstract characteristic of an observer</a> is its ability to equivalence many possible inputs to produce a small set of possible outputs. And\u2014although we don\u2019t yet know how to do it\u2014we can imagine that it would be possible to derive the fact that there must be a certain density of structures that do this within the ruliad. Could there inevitably be enough similar observers to be able to reasonably triangulate to an objective reality?</p>\n<p>If we take <a href=\"https://writings.stephenwolfram.com/2024/05/why-does-biological-evolution-work-a-minimal-model-for-biological-evolution-and-other-adaptive-processes/\">the example of biology</a> (or modern technology) it seems like what\u2019s critical in generating large numbers of similar observers is some form of replication. And so, surprising as it might seem for something as apparently fundamental as this, it appears that our impression of the existence of objective reality is actually intimately tied up with the rather practical biological phenomenon of self replication.</p>\n<p>OK, so what should we in the end think about objective reality? We might have imagined that having a scientific theory of the universe would immediately imply a certain objective reality. And indeed at the level of the ruliad that\u2019s true. But what we\u2019ve seen is that even to get our familiar laws of physics we need an observer \u201cparsing\u201d the raw ruliad. In other words, without the observer we can\u2019t even talk about fundamental concepts in physics. But the point is that for a very wide range of observers even vaguely like us, many details of the observer don\u2019t matter; certain things\u2014like core laws of physics\u2014inevitably and \u201cobjectively\u201d emerge. </p>\n<p>But the laws of physics don\u2019t determine everything an observer perceives. Some things are inevitably determined by the particular circumstances of the observer: their position in space, in the ruliad, etc. But now the point is that observers\u2014like us humans\u2014are nearby enough in space, the ruliad, etc. that our perceptions will be to a large extent aligned, so that we can again usefully attribute them to what we can think of as an external objective reality.</p>\n<h2 id=\"the-beginning-and-end-of-time\">The Beginning and End of Time</h2>\n<p style=\"display: inline-block; float: left; padding: 0px; margin: 0px; margin-top: 9px; margin-right: 8px;\"><img alt=\"The Beginning and End of Time\" class=\"bookpost\" height=\"70\" src=\"https://content.wolfram.com/sites/43/2026/02/sw02032026beginningimg1-a.png\" title=\"The Beginning and End of Time\" width=\"95\" /></p>\n<p>In thinking about what there ultimately is, an obvious question is whether whatever there is has always been there\u2014and will always be\u2014or whether instead there\u2019s in effect a beginning\u2014and end\u2014to time. </p>\n<p>As we discussed above, in our computational paradigm, the <a href=\"https://writings.stephenwolfram.com/2024/10/on-the-nature-of-time/\">passage of time is associated with the progressive computation of successive states of the universe</a>. But the important point is that these states embody everything\u2014including any potential observers. So there can never be a situation where an observer could say \u201cthe universe hasn\u2019t started yet\u201d\u2014because if the universe hasn\u2019t started, nor will the observer have. </p>\n<p>But why does the universe start at all? We\u2019ll say more about that later. But suffice it to say here that the ruliad in effect contains all possible abstract computations, each consisting of some chain of steps that follow from each other. There\u2019s nothing that has to \u201cactively start\u201d these chains: they are just abstract constructs that inevitably follow from the definition of the ruliad.</p>\n<p>There\u2019ll be a beginning to each chain, though. But the ruliad contains all possible beginnings, or in other words, all possible initial states for computations. One might wonder, given all of this, how the ruliad can still have any kind of coherent structure. The answer, as we discussed above, is the entanglement of different threads of computation: the threads are not independent, but are related by the merging of equivalent states.</p>\n<p>Of course one can then ask why equivalent states are in fact merged. And this is immediately a story about observers. One can imagine a raw construction of the ruliad in which every different thread of computation independently branches. But anytime states generated in different threads are identical, any observer will equivalence them. So this means that to any observer, these threads will be merged\u2014and there will effectively be entanglement in the ruliad.</p>\n<p>We\u2019ve said that the passage of time corresponds to the progression of computation. And given this, we can imagine that the ruliad is built up \u201cthrough time\u201d, by progressively applying appropriate rules. But actually we don\u2019t need to think of it this way. Because once a procedure for the construction of the ruliad is defined, it\u2019s inevitable that the whole structure of the ruliad is, at least in principle, immediately determined. </p>\n<p>In other words, we can imagine building up the ruliad step by step through time. Or we can imagine that the ruliad in some sense all immediately \u201cjust exists\u201d. But the point is that to computationally bounded observers these are basically equivalent. In the first case the observer is \u201cpulled along\u201d by the irreducible computation that\u2019s \u201chappening anyway\u201d to move forward the \u201cfrontier\u201d of the ruliad. In the second case, the observer in a sense has to actively explore the \u201calready-formed\u201d ruliad, but because of the observer\u2019s computational boundedness, can do so only at a certain limited rate\u2014so that once again there is something corresponding to the passage of time, and relating it to computational irreducibility. </p>\n<p>But what happens if one includes the fact that there are threads of computation in the ruliad starting from all possible initial states? Well, a bounded observer will only be able to probe all these states and their behaviors at some limited rate. So even if \u201cfrom outside the ruliad\u201d (if one could be there) one might see infinitely many different beginnings of the universe, any computationally bounded observer embedded in the ruliad would perceive only a limited set. And, indeed, depending a bit on the scales involved, the observer might well be able to conflate those limited possibilities into the perception of just a single, finite beginning of the universe\u2014even though, underneath, there\u2019s much more going on in the whole ruliad. </p>\n<p>(One thing one might wonder is that since the ruliad contains every possible rule, why can\u2019t there just be a single, very complicated rule that just creates our whole universe in a single step? The answer is that in principle there can be. But computationally bounded observers like us will never perceive it; our \u201cnarrative about the universe\u201d might involve computationally limited steps.) </p>\n<p>Another subtlety concerns the relationship of time to the equivalencing of states. Imagine that in the ruliad (or indeed just in a causal graph) a particular state is generated repeatedly when rules are applied. We can expect an observer to equivalence these different instances of the state\u2014thus in effect forming a loop in the progression of states. Quite possibly such loops are associated with phenomena in quantum field theory. But to an observer like us such loops will be happening at a level \u201cbelow\u201d perceived time. </p>\n<p>We talked about the beginning of time. What about the end? If the passage of time is the progression of computation, can the computation simply halt? The answer for any specific computation is yes. A particular rule might, for example, simply not apply anywhere in a given hypergraph. And that means that in effect time stops for that hypergraph. And indeed this is what <a href=\"https://writings.stephenwolfram.com/2020/04/finally-we-may-have-a-path-to-the-fundamental-theory-of-physics-and-its-beautiful/#black-holes-singularities-etc\">presumably happens at the center of a black hole</a> (at least in the simplest case). </p>\n<p>But what about the whole ruliad? Inevitably parts of it will \u201ckeep running\u201d, even if some threads of computation in it stop. But the question is what an observer will perceive of that. </p>\n<p>Normally we\u2019ve just taken it for granted that an observer does whatever they do forever. But in reality, as something embedded in the ruliad, an observer will at some level have to \u201cnavigate computational irreducibility\u201d to maintain itself. And whether it\u2019s because a biological observer dies, or because an observer ends up in a black hole, we can expect the actual span of experience of individual observers to be limited, in effect defining an end of time for the observer, even if not for the whole ruliad. </p>\n<h2 id=\"why-does-anything-actually-exist\">Why Does Anything Actually Exist?</h2>\n<p style=\"display: inline-block; float: left; padding: 0px; margin: 0px; margin-top: 9px; margin-right: 8px;\"><img alt=\"Why Does Anything Actually Exist?\" class=\"bookpost\" height=\"70\" src=\"https://content.wolfram.com/sites/43/2026/02/sw02032026whyimg1-a.png\" title=\"Why Does Anything Actually Exist?\" width=\"95\" /></p>\n<p>In our discussion of what there ultimately is, an obvious question is why there\u2019s ultimately anything at all. Or, more specifically, <a href=\"https://writings.stephenwolfram.com/2021/04/why-does-the-universe-exist-some-perspectives-from-our-physics-project/\">why does our universe exist</a>? Why is there something rather than nothing?</p>\n<p>One might have imagined that there\u2019d be nothing one could say about such questions in the framework of science. But it turns out that in the context of the ruliad there\u2019s actually quite a lot one can say.</p>\n<p>The key point is that the ruliad can be thought of as a necessary, abstract object. Given a definition of its elements it inevitably has the structure it has. There\u2019s no choice about it. It\u2019s like in mathematics: given the definitions of 1, +, etc., 1 + 1 = 2 is an inevitable consequence. It isn\u2019t a statement that needs to talk about pebbles or coins or whatever; it\u2019s an abstract and inevitable formal statement.</p>\n<p>And so it is with the ruliad. The ruliad has to be the way it is. Every detail of it is abstractly determined. Or, in other words, at least as an abstract object, it necessarily exists.</p>\n<p>But why, we might ask, is it actualized? We can imagine all sorts of formal systems with all sorts of structure. But why is the ruliad what is actualized to give us the physical world we experience? </p>\n<p>The key here is to think about what we operationally mean by actualized. And the point is that it\u2019s not something absolute; it\u2019s something that depends on us as observers. After all, the only thing we can ever ultimately know about is our own inner experience. And for us something is then \u201cactualized\u201d if we can\u2014as we discussed above\u2014successfully \u201ctriangulate our experiences\u201d to let us consider it to have an objective reality. </p>\n<p>At some level, the ruliad is an abstract thing. And our inner experiences are abstract things. And we\u2019re saying that there\u2019s a certain abstract necessity to the way these things are linked. With what amounts to a description of our physical world being a necessary intermediate step in that linking. </p>\n<p>Given its definition, it\u2019s immediately inevitable that the ruliad must exist as an abstract object. But what about observers like us? We know ourselves that we exist from the inner experiences we have. But is it necessary that we exist? Or, put another way, is it inevitable that somewhere in the ruliad there must be structures that correspond to observers like us?</p>\n<p>Well, that\u2019s a question we can now study as a matter of science. And ultimately we can imagine an abstract derivation of the density of different levels of observers in the ruliad. To get to observers like us requires\u2014as we discussed above\u2014all sorts of details, probably including features from biology, like self replication. But if we require only the features of computational boundedness and a belief in persistence, there are no doubt many more \u201cobserver structures\u201d in the ruliad. </p>\n<p>It\u2019s interesting to consider those <a href=\"https://writings.stephenwolfram.com/2023/07/generative-ai-space-and-the-mental-imagery-of-alien-minds/\">\u201calien minds\u201d distributed across the ruliad</a>. In traditional searches for extraterrestrial intelligence one is seeking to bridge distances in physical space. But likely the distances across the ruliad\u2014in rulial space\u2014are vastly greater. And in effect the \u201cminds\u201d are more alien (like the \u201cmind\u201d of the weather)\u2014and to \u201ccommunicate\u201d with them will require, in effect, an effort of translation that involves an immense amount of irreducible computation. </p>\n<p>But for us, and our science, what matters is our own experience. And given our knowledge that we exist, the existence of the ruliad seems to make it in effect inevitable that we must consider the universe to exist. </p>\n<p>One wrinkle to mention concerns generalizations of the ruliad. We\u2019ve said that the ruliad encapsulates all possible computational processes. But by this we mean processes that can be implemented on one of our traditional models of computation\u2014like Turing machines. But what about hypercomputations that would require an infinite number of steps for a Turing machine? One can imagine a whole hierarchy of hyperruliads based on these. And one could imagine observers embedded not in the ordinary ruliad, but in some hyperruliad. So what would be the experience of such observers? They\u2019d never be able to perceive anything outside their hyperruliad, and in fact one can expect that through their own hypercomputations their perception of their own hyperruliad would be essentially equivalent to our perception of the ordinary ruliad\u2014so that in the end there\u2019s no perceptible distinction between being in the ruliad and in a hyperruliad: the \u201csame universe\u201d, with the same laws of physics we know, exists in both.</p>\n<p>When one starts talking about the universe operating at the lowest level according to computational rules people sometimes seem to think that means our universe must ultimately be \u201crunning on a computer\u201d. But to imagine that is essentially to misunderstand the whole concept of theoretical science. For the idea in theoretical science is to construct abstract models that allow one to reproduce certain aspects of what systems do. It\u2019s not that the systems themselves mechanistically implement the models; it\u2019s just that the models abstractly reproduce aspects of what the systems do. </p>\n<p>And so it is with our model for physics. It\u2019s not that somewhere \u201cinside the universe\u201d there\u2019s a computer moving bits around to rearrange hypergraphs. Instead, it\u2019s just that abstractly rearranging hypergraphs is a way (and, no doubt, not the only one) of representing what\u2019s happening in the universe. </p>\n<p>Typically the <a href=\"https://www.wolframscience.com/nks/chap-8--implications-for-everyday-systems#sect-8-1--issues-of-modelling\">models one makes in science</a> only aim to be approximate: they capture certain aspects one cares about in a system, and idealize away all others. But our Physics Project is different, because its goal is to make a model that\u2014at least in principle\u2014can reproduce in perfect detail what happens in the universe, without approximation or idealization. But what we have is still just a model: in effect, a way of making a bridge from what actually happens in the universe to what we can describe in essentially human terms. </p>\n<p>There\u2019s a little more subtlety when it comes to the whole ruliad. Because while the ruliad is precise and complete, the sampling of it that determines what we experience depends on our characteristics as observers, about which we\u2019ll never be able to be completely precise. And what\u2019s more, as we\u2019ve discussed, while the ruliad is defined in an abstract way, it is what is in effect actualized for observers like us\u2014to provide our physics and what we consider to be our objective reality. </p>\n<p>But could all of that somehow still be a \u201csimulation\u201d running on some lower-level infrastructure? Not in any meaningful sense. In talking about \u201csimulation\u201d we\u2019re implicitly imagining that, in effect, the ruliad is running in one place, and other things are running elsewhere. But the ruliad encapsulates the totality of all computational processes. So in a sense there\u2019s no room for anything outside the ruliad\u2014and the only thing the ruliad can \u201crun on\u201d is itself.</p>\n<p>Still, when it comes to observers like us, we sample only some tiny part of the ruliad\u2014and in some sense there\u2019s a choice about what part that is. Indeed, insofar as we <a href=\"https://www.wolframscience.com/nks/chap-12--the-principle-of-computational-equivalence#sect-12-7--the-phenomenon-of-free-will\">view ourselves as having free will</a> and choosing freely what observations to make (and perhaps what our own structure should be), we are in control of that choice. Our basic nature as observers will nevertheless determine some of what we experience\u2014most notably core laws of physics. But beyond that it\u2019s our choices as observers that effectively determine \u201cwhich possible program\u201d we\u2019re \u201crunning\u201d in the ruliad. So if we think of such programs as \u201csimulations\u201d running on the ruliad, then it\u2019s not as if there\u2019s some outside entity that\u2019s picking the programs; it\u2019s our nature and our choices that are doing it. </p>\n<h2 id=\"mathematical-reality\">Mathematical Reality</h2>\n<p style=\"display: inline-block; float: left; padding: 0px; margin: 0px; margin-top: 9px; margin-right: 8px;\"><img alt=\"Mathematical Reality\" class=\"bookpost\" height=\"70\" src=\"https://content.wolfram.com/sites/43/2026/02/sw02032026mathematicalimg1-a.png\" title=\"Mathematical Reality\" width=\"95\" /></p>\n<p>We\u2019ve talked a lot about what there ultimately is in the \u201cconcrete\u201d physical world. But what about the \u201cabstract\u201d mathematical world? One of the surprising things about the ruliad is that it implies a remarkably close connection between the <a href=\"https://www.wolframscience.com/metamathematics/\">ultimate foundations of physics and of mathematics</a>. </p>\n<p>In our Physics Project we had to start by inventing a \u201cmachine-code-level\u201d representation of the physical world in terms of hypergraphs, rewriting rules, etc. In mathematics it turns out that there\u2019s <a href=\"https://www.wolframscience.com/metamathematics/the-metamodeling-of-axiomatic-mathematics/\">already a well-established \u201cmachine-code-level\u201d representation</a>: networks of theorems stated as symbolic expressions, and transformed into each other according to (essentially structural) laws of inference. </p>\n<p>At this level of description, any particular field of mathematics can be thought of as starting from certain axioms, then building up a whole multiway graph of all possible theorems they imply. The paths in this graph correspond to proofs\u2014with the phenomenon of undecidability manifesting itself in the presence of arbitrarily long paths\u2014and the theorems that human mathematicians find interesting are dotted around the graph.</p>\n<p>So what happens if instead of looking at a single axiom system we look at all possible axiom systems? What we\u2019ll get is a structure corresponding to the entangled limit of all possible proofs\u2014based on rules derived from all possible axiom systems. But we\u2019ve seen an equivalent structure before: it\u2019s just the ruliad! </p>\n<p>But now instead of interpreting emes as atoms of space we interpret them as \u201catoms of mathematics\u201d, or the lowest level elements of mathematical expressions. And instead of interpreting slices of the ruliad as corresponding in the limit to physical space, we interpret them as defining metamathematical space.</p>\n<p>So in addition to encapsulating all possible computational processes, the ruliad also encapsulates all possible mathematical ones. But how do human mathematicians\u2014or what we can call mathematical observers\u2014\u201cperceive\u201d this? How do they extract what they consider meaningful mathematics?</p>\n<p>Physical observers get their \u201cview of the world\u201d in essence by building up a thread of experience through time. Mathematical observers get their \u201cview of the world\u201d by starting with some set of theorems (or axioms) they choose to assume, then \u201cmoving outwards\u201d to build up a larger collection of mathematical results. </p>\n<p>The raw ruliad is full of computational irreducibility. But in both physics and mathematics the goal is in effect to find pockets of reducibility that let observers like us get summaries that we can fit in our finite minds. In physics this manifests in identifying concepts like space, and then identifying laws that must hold about them.</p>\n<p>So what is the analog for mathematics? In principle one could operate at the level of axioms (or even below). But in doing Euclidean geometry, for example, it\u2019s perfectly reasonable to talk in terms of the Pythagorean theorem, without always going down to the lowest level of definitions, say for real numbers. It\u2019s very much like in physics, where for many purposes one can talk about something like the flow of a fluid, without having to worry about what\u2019s going on at the level of molecular dynamics.</p>\n<p>And indeed, just like in physics, the fact that mathematics is done by observers like us has immediate implications for what mathematics is like, or in effect, for the \u201c<a href=\"https://www.wolframscience.com/metamathematics/the-physicalized-laws-of-mathematics/\">laws of mathematics</a>\u201d. What are these laws? The most important is that higher-level mathematics is possible: in other words, that mathematicians can in fact successfully do mathematics at the \u201cfluid dynamics\u201d level, without always having to drop down to the raw \u201cmolecular dynamics\u201d level of axioms and below. </p>\n<p>There are other laws of mathematics one can expect. For example, the homogeneity of metamathematical space implied by the structure of the ruliad has the consequence that \u201cpure metamathematical motion\u201d should be possible, so that there must be \u201cdualities\u201d that allow one to translate from one field of mathematics to another. As another example, there should be analogs of general relativity in metamathematical space, with the analog of black holes in which \u201ctime stops\u201d being decidable mathematical theories in which proofs \u201calways stop\u201d (in the sense that they are of bounded length). </p>\n<p>But\u2014just like for physics\u2014we\u2019re in a sense getting from the ruliad the mathematics we get because we are observers of the kind we are. We might have imagined that we could just invent whatever mathematics we want just by setting up an appropriate axiom system. But the point is that only some axiom systems\u2014or in effect some slices of the ruliad\u2014will <a href=\"https://www.wolframscience.com/metamathematics/what-can-human-mathematics-be-like/\">allow observers with our characteristics to coherently do mathematics</a>. </p>\n<p>Our everyday experience of the physical world gives us the impression that we have a kind of \u201cdirect access\u201d to many foundational features of physics, like the existence of space and the phenomenon of motion. But our Physics Project implies that these are not concepts that are in any sense \u201cintrinsically there\u201d; they are just things that emerge from the raw ruliad when you \u201cparse\u201d it in the kinds of ways physical observers like us do.</p>\n<p>In mathematics it\u2019s less obvious (at least to anyone except perhaps experienced pure mathematicians) that there\u2019s \u201cdirect access\u201d to anything. But in our view of mathematics here, it\u2019s ultimately just like physics\u2014and ultimately also rooted in the ruliad, but sampled not by physical observers but by mathematical ones.</p>\n<p>So from this point of view there\u2019s just as much that\u2019s \u201creal\u201d underneath mathematics as there is underneath physics. The mathematics is sampled slightly differently\u2014but we should not in any sense consider it \u201cfundamentally more abstract\u201d.</p>\n<p>When we think of ourselves as entities within the ruliad, we can build up what we might consider a \u201cfully abstract\u201d description of how we get our \u201cexperience\u201d of physics. And we can basically do the same for mathematics. So if we take the commonsense point of view that the physical world exists \u201cfor real\u201d, we\u2019re forced into the same point of view for mathematics. In other words, if we say that the physical world exists, so must we also say that in some fundamental sense, mathematics also exists.</p>\n<p>Underneath mathematics, just like underneath physics, is the ruliad. And so, in a sense, what is ultimately there in mathematics is the same as what is ultimately there in physics. Mathematics is not something we humans \u201cjust make\u201d; it\u2019s something that comes from the ruliad, through our particular way of observing it, defined by our particular characteristics as observers.</p>\n<h2 id=\"observers-in-the-vastness-of-the-ruliad\">Observers in the Vastness of the Ruliad</h2>\n<p style=\"display: inline-block; float: left; padding: 0px; margin: 0px; margin-top: 9px; margin-right: 8px;\"><img alt=\"Observers in the Vastness of the Ruliad\" class=\"bookpost\" height=\"70\" src=\"https://content.wolfram.com/sites/43/2026/02/sw02032026vastnessimg1-a.png\" title=\"Observers in the Vastness of the Ruliad\" width=\"95\" /></p>\n<p>One of the things we\u2019ve learned over the past few centuries is just how small we are compared to the universe. But now we realize that compared to the whole ruliad we\u2019re still even vastly much smaller. We\u2019re certainly not as small as we might be, though. And indeed at some level we\u2019re actually quite large, being composed not just of a few atoms of space or, for that matter, emes, but an immense number.</p>\n<p>We are in effect intermediate in scale: huge compared to emes, but tiny compared to the whole ruliad. And the fact that we as observers are at this scale is crucial to how we experience the universe and the ruliad.</p>\n<p>We\u2019re large enough that we can in some sense persistently exist and form solid, persistent experiences, not subject to constantly changing microscopic details. Yet we\u2019re small enough that we can exist as coherent, independent entities in the ruliad. We\u2019re large enough that we can have a certain amount of \u201cinner life\u201d; yet we\u2019re small enough there\u2019s also plenty of \u201cexternal stimuli\u201d impinging on us from elsewhere in the ruliad.</p>\n<p>We\u2019re also large enough that we can typically think in terms of continuous space, not atoms of space. And we can think in terms of continuous quantum amplitudes, not discrete multiway threads. But we\u2019re small enough that we can have a consistent view of \u201cwhere we are\u201d in physical space and in branchial space. And all of us human observers are tightly enough packed in physical and branchial space that we basically agree about \u201cwhat\u2019s happening\u201d around us\u2014and this forms the basis for what we consider to be \u201cobjective reality\u201d.</p>\n<p>And it\u2019s the same basic story when we think about the whole ruliad. But now \u201cwhere we are\u201d determines in effect what rules we attribute to the universe. And our scale is what makes those rules both fairly consistent and fairly definite. Some features of the universe\u2014like the basic phenomena of general relativity and quantum mechanics\u2014depend only on our general characteristics as observers. But others\u2014likely like the masses of particles\u2014depend on our \u201cplace in the ruliad\u201d. (And, for example, we already know from traditional physics that something like the perceived mass of an electron depends on the momentum we use to probe it.) </p>\n<p>When we ask what there ultimately is, one of the most striking things is how much there ultimately is. We don\u2019t yet know the scale of the discreteness of space, <a href=\"https://www.wolframphysics.org/technical-introduction/potential-relation-to-physics/units-and-scales/\" rel=\"noopener\" target=\"_blank\">but conceivably it\u2019s around 10<sup>\u201390</sup> meters</a>\u2014implying that at any given moment there might 10<sup>400</sup> atoms of space in the universe, and about 10<sup>500</sup> in the history of the universe so far. What about the whole ruliad? The total number of emes is exponentially larger, conceivably of order (10<sup>500</sup>)<sup>10<sup>500</sup></sup>. It\u2019s a huge number\u2014but the fact that we can even guess at it gives us a sense that we can begin to think concretely about what there ultimately is. </p>\n<p>So how does this all relate to human scales? We know that the universe is about 10<sup>80</sup> times larger in volume than a human in physical space. And within one human at any given time there might be about 10<sup>300</sup> atoms of space; our existence through our lives might be defined by perhaps 10<sup>400</sup> emes. We can also guess at our extent in branchial space\u2014and in the whole ruliad. There are huge numbers involved\u2014that give us a sense of why we observe so much that seems so definite in the universe. In effect, it\u2019s that we\u2019re \u201cbig enough\u201d that our \u201caveraged\u201d perceptions are very precise, yet we\u2019re \u201csmall enough\u201d that we\u2019re essentially at a precise location within the ruliad.</p>\n<p>(A remarkable feature of thinking in terms of emes and the ruliad is that we can do things like <a href=\"https://www.wolframscience.com/metamathematics/counting-the-emes-of-mathematics-and-physics/\">compare the \u201csizes\u201d of human-scale physics and mathematics</a>. And a rough estimate might be that all the mathematics done in human history has involved perhaps 10<sup>100</sup> emes\u2014vastly less than the number of emes involved in our physical existence.)</p>\n<p>We can think of our \u201cbig but small\u201d scale as being what allows us to be observers who can be treated as persistent in time. And it\u2019s very much the same story for \u201cpersistence in space\u201d. For us to be capable of \u201c<a href=\"https://writings.stephenwolfram.com/2022/03/on-the-concept-of-motion/\">pure motion</a>\u201d, where we move from one place to another, and are still \u201cpersistently ourselves\u201d we have to be large compared to the scale of emes, and tiny compared to the scale of the ruliad. </p>\n<p>When it comes to moving in the physical universe, we know that to \u201cactually move ourselves\u201d (say with a spacecraft) takes time. But to imagine what it\u2019s like to have moved is something that can be done abstractly, and quickly. And it\u2019s the same at the level of the ruliad. To \u201cmove ourselves\u201d in the ruliad in effect requires an explicit computational translation from one set of rules to another, which takes (typically irreducible) computational effort, and therefore time. But we can still just abstractly jump anywhere we want in the ruliad. And that is in effect <a href=\"https://writings.stephenwolfram.com/2026/01/what-is-ruliology/\">what we do in ruliology</a>\u2014studying rules that we can, for example, just pick at random, or find by enumeration. We can <a href=\"https://writings.stephenwolfram.com/category/ruliology\">discover all sorts of interesting things</a> that way. But in a sense they\u2019re\u2014at least at first\u2014alien things, not immediately connected to anything familiar to us from our normal location in the ruliad. </p>\n<p>We see something similar in mathematics. We can start enumerating a huge network of possible theorems. But unless we can find a way to transport ourselves as mathematical observers more or less wholesale in metamathematical space, we won\u2019t be able to contextualize most of those theorems; they\u2019ll seem alien to us.</p>\n<p>It\u2019s not easy to get intuition for the \u201calien\u201d things out there in the ruliad. One approach is to <a href=\"https://writings.stephenwolfram.com/2023/07/generative-ai-space-and-the-mental-imagery-of-alien-minds/\">use generative AI, say to make pictures</a>, and to ask what happens if the parameters of the AI are changed, in effect moving to different rules, and a different part of the ruliad. Sometimes one gets to recognizable pictures that are described by some concept, say associated with a word in human language. But in the vast majority of cases one finds oneself in \u201c<a href=\"https://writings.stephenwolfram.com/2023/07/generative-ai-space-and-the-mental-imagery-of-alien-minds/#the-notion-of-interconcept-space\">interconcept space</a>\u201d\u2014in a place for which no existing human concept has yet been invented. And indeed in experiments with practical neural nets the fraction of this tiny corner of the ruliad spanned by our familiar concepts can easily be just 10<sup>\u2013600</sup> of the total. In other words, what we have ways to describe, say in human language, represents an absolutely tiny fraction of what there ultimately is. </p>\n<p>But what happens if we <a href=\"https://writings.stephenwolfram.com/2025/05/what-if-we-had-bigger-brains-imagining-minds-beyond-ours/#language-and-beyond\">invent more concepts</a>? In some sense we then grow in rulial space\u2014so that we as observers span a larger part of the ruliad. And perhaps we might see it as some kind of ultimate goal for science and for knowledge to expand ourselves throughout the ruliad. </p>\n<p>But there\u2019s a catch. The fact that we can view ourselves as definite, individual observers depends on us being small compared to the ruliad. If we could expand to fill the ruliad we would in some sense be everything\u2014but we would also be nothing, and would no longer exist as coherent entities. </p>\n<h2 id=\"developing-a-science-of-metaphysics\">Developing a Science of Metaphysics</h2>\n<p style=\"display: inline-block; float: left; padding: 0px; margin: 0px; margin-top: 9px; margin-right: 8px;\"><img alt=\"Developing a Science of Metaphysics\" class=\"bookpost\" height=\"70\" src=\"https://content.wolfram.com/sites/43/2026/02/sw02032026developingimg1-a.png\" title=\"Developing a Science of Metaphysics\" width=\"95\" /></p>\n<p>Metaphysics has historically been viewed as a branch of philosophy. But what I\u2019ve argued here is that with our new results and new insights from science we can start to discuss metaphysics not just as philosophy but also as science\u2014and we can begin to tell an actual scientific story of what there ultimately is, and how we fit into it. </p>\n<p>Metaphysics has in the past basically always had to be built purely on arguments made with words\u2014and indeed perhaps this is why it\u2019s often been considered somewhat slippery and fragile. But now, with the kind of things we\u2019ve discussed here, we\u2019re beginning to have what we need to set up a solid, formal structure for metaphysics, in which we can progressively build a rich tower of definite conclusions.</p>\n<p>Some of what there is to say relates to the ruliad, and is, in a sense, purely abstract and inevitable. But other parts relate to the \u201csubjective\u201d experience of observers\u2014and, for us, basically human observers. So does metaphysics somehow need to involve itself with all the details of biology or, for that matter, psychology? The big surprise is that it doesn\u2019t. Because the science says that knowing only very coarse things about observers (like that they are computationally bounded) already makes it possible to come to precise conclusions about certain features and laws they must perceive. There is in effect an emergent metaphysics.</p>\n<p>The ruliad provides a form of answer to what there abstractly ultimately is. But to connect it to what for us there \u201creally\u201d is we need to know the essence of what we are like.</p>\n<p>Investigating features of the ruliad is a lot about doing pure <a href=\"https://writings.stephenwolfram.com/2026/01/what-is-ruliology/\">ruliology</a>\u2014and empirically studying what abstract simple programs do. Talking about observers is much more an exercise in <a href=\"https://writings.stephenwolfram.com/2021/09/charting-a-course-for-complexity-metamodeling-ruliology-and-more/#metamodeling-and-the-metatheory-of-models\">metamodeling</a>\u2014and taking largely known models of the world, and trying to extract from them the abstract essence of what\u2019s going on. To make a science of metaphysics somehow requires both of these. </p>\n<p>But the exciting thing is that building on the computational paradigm and intuition from studying the computational universe we\u2019re getting to the point where we can begin to give definite scientific answers to questions of metaphysics that for millennia have seemed like things about which one could just make arguments, but never come to conclusions. And like so many branches of philosophy before it, metaphysics now seems destined to make the transition from being a matter purely of philosophy to being one of science\u2014finally giving us answers to the age old question of what there ultimately is.</p>\n<h2 id=\"related-material\" style=\"font-size: 1.2rem;\">Related Material</h2>\n<p style=\"font-size: 90%;\">For other discussions of ideas explored here, see my recent <a href=\"https://writings.stephenwolfram.com/category/philosophy/\">Philosophical Writings \u00bb</p>"
            ],
            "link": "https://writings.stephenwolfram.com/2026/02/what-ultimately-is-there-metaphysics-and-the-ruliad/",
            "publishedAt": "2026-02-04",
            "source": "Stephen Wolfram",
            "summary": "<span class=\"thumbnail\"><img alt=\"\" class=\"attachment-thumbnail size-thumbnail wp-post-image\" height=\"104\" src=\"https://content.wolfram.com/sites/43/2026/02/metaphysics-icon.png\" width=\"124\" /></span>The Wolfram Institute recently received a grant from the Templeton World Charity Foundation for \u201cComputational Metaphysics\u201d. I wrote this piece in part as a launching point for discussions with experts in traditional philosophy. Moving Metaphysics from Philosophy to Science \u201cWhat ultimately is there?\u201d has always been seen as a fundamental\u2014if thorny\u2014question for philosophy, or perhaps [&#8230;]",
            "title": "What Ultimately Is There? Metaphysics and the Ruliad"
        },
        {
            "content": [
                "<p>I had to delay this a little bit, but the results are in and Kimi K2.5 is pretty good.</p>\n\n\n<h4 class=\"wp-block-heading\">Table of Contents</h4>\n\n\n<ol>\n<li><a href=\"https://thezvi.substack.com/i/186084444/official-introduction\">Official Introduction.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/186084444/on-your-marks\">On Your Marks.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/186084444/positive-reactions\">Positive Reactions.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/186084444/skeptical-reactions\">Skeptical Reactions.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/186084444/kimi-product-accounts\">Kimi Product Accounts.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/186084444/agent-swarm\">Agent Swarm.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/186084444/who-are-you\">Who Are You?</a></li>\n<li><a href=\"https://thezvi.substack.com/i/186084444/export-controls-are-working\">Export Controls Are Working.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/186084444/where-are-you-going\">Where Are You Going?</a></li>\n<li><a href=\"https://thezvi.substack.com/i/186084444/safety-not-even-third\">Safety Not Even Third.</a></li>\n<li><a href=\"https://thezvi.substack.com/i/186084444/it-s-a-good-model-sir\">It\u2019s A Good Model, Sir.</a></li>\n</ol>\n\n\n<h4 class=\"wp-block-heading\">Official Introduction</h4>\n\n\n<p>Introducing <a href=\"https://x.com/Kimi_Moonshot/status/2016021783833673897\">Kimi K2.5</a>,</p>\n<blockquote><p><a href=\"https://x.com/Kimi_Moonshot/status/2016024049869324599/history\">Kimi.ai</a>: Meet Kimi K2.5, Open-Source Visual Agentic Intelligence.</p>\n<p>Global SOTA on Agentic Benchmarks: HLE full set (50.2%), BrowseComp (74.9%)<br />\nOpen-source SOTA on Vision and Coding: MMMU Pro (78.5%), VideoMMMU (86.6%), SWE-bench Verified (76.8%)</p>\n<p>Code with Taste: turn chats, images &amp; videos into aesthetic websites with expressive motion.</p>\n<div>\n\n\n<span id=\"more-25075\"></span>\n\n\n</div>\n<p>Agent Swarm (Beta): self-directed agents working in parallel, at scale. Up to 100 sub-agents, 1,500 tool calls, 4.5\u00d7 faster compared with single-agent setup.</p>\n<p>K2.5 is now live on</p>\n<p><a href=\"http://kimi.com\" rel=\"nofollow\">http://kimi.com</a></p>\n<p>in chat mode and agent mode.<br />\nK2.5 Agent Swarm in beta for high-tier users.<br />\nFor production-grade coding, <a href=\"https://kimi.com/code\">you can pair K2.5 with Kimi Code</a>.<br />\n&#8211;<br />\n<a href=\"https://t.co/EOZkbOwCN4\"> API here.</a> <a href=\"https://t.co/6h2KkoA0xd\">Tech blog here</a>. <a href=\"https://t.co/H38KegeDIY\">Weights and code here</a>.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!JfEh!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0bf03d3-5df8-402a-b11e-906f5e431fcc_1200x675.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p><a href=\"https://x.com/HaoningTimothy/status/2016027271187071487\">Wu Haoning</a> (Kimi): We are really taking a long time to prove this: everyone is building big macs but we bring you a kiwi instead.</p>\n<p>You have multimodal with K2.5 everywhere: chat with visual tools, code with vision, generate aesthetic frontend with visual refs&#8230;and most basically, it is a SUPER POWERFUL VLM</p>\n<p><a href=\"https://x.com/jiayuan_jy/status/2016556319227130243\">Jiayuan (JY) Zhang</a>: I have been testing Kimi K2.5 + @openclaw (Clawdbot) all day. I must say, this is mind-blowing!</p>\n<p>It can almost do 90% of what Claude Opus 4.5 can do (mostly coding). Actually, I don&#8217;t know what the remaining 10% is, because I can&#8217;t see any differences. Maybe I should dive into the code quality.</p>\n<p>Kimi K2.5 is open source, so you can run it fully locally. It&#8217;s also much cheaper than Claude Max if you use the subscription version.</p>\n<p>$30 vs $200 per month</p>\n<p><a href=\"https://x.com/KimiProduct/status/2016557476070797527\">Kimi Product</a>: Do 90% of what Claude Opus 4.5 can do, but 7x cheaper.</p></blockquote>\n<p>I always note who is the comparison point. Remember those old car ads, where they\u2019d say \u2018twice the mileage of a Civic and a smoother ride than the Taurus\u2019 and then if you were paying attention you\u2019d think \u2018oh, so the Civic and Taurus are good cars.\u2019</p>\n<p>API access is also <a href=\"https://t.co/fC1rz1GH1C\">available from Nvidia</a>, and others.</p>\n\n\n<h4 class=\"wp-block-heading\">On Your Marks</h4>\n\n\n<p>As usual, benchmarks are highly useful, but easy to overinterpret.</p>\n<p>Kimi K2.5 gets to top some benchmarks: HLE-Full with tools (50%), BrowseComp with Agent Swarp (78%), OCRBench (92%), OmiDocBench 1.5 (89%), MathVista (90%) and InfoVQA (93%). It is not too far behind on AIME 2025 (96% vs. 100%), SWE-Bench (77% vs. 81%) and GPQA-Diamond (88% vs. 92%).</p>\n<p>Inference is cheap, and speed is similar to Gemini 3 Pro, modestly faster than Opus.</p>\n<p><a href=\"https://x.com/ArtificialAnlys/status/2016250137115557953\">Artificial Analysis</a> <a href=\"https://artificialanalysis.ai/\">calls Kimi</a> the new leading open weights model, \u2018now closer than ever to the frontier\u2019 behind only OpenAI, Anthropic and Google.</p>\n<p>Here\u2019s the jump in the intelligence index, while maintaining relatively low cost to run:</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!JPLk!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0d4d3599-ca9b-472f-9d60-f589d8aa9e68_1200x674.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<blockquote><p><a href=\"https://x.com/ArtificialAnlys/status/2016250142387765559\">Artificial Analysis</a>: Kimi K2.5 debuts with an Elo score of 1309 on the GDPval-AA Leaderboard, implying a win rate of 66% against GLM-4.7, the prior open weights leader.</p>\n<p>Kimi K2.5 is slightly less token intensive than Kimi K2 Thinking. Kimi K2.5 scores -11 on the AA-Omniscience Index.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!Spt3!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc03d6fe5-821f-4603-90e5-5aa2b0878e97_1200x353.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n</blockquote>\n<p>As a reminder, AA-Omniscience is scored as (right minus wrong) and you can pass on answering, although most models can\u2019t resist answering and end up far below -11. The scores above zero are Gemini 3 Pro (+13) and Flash (+8), Claude Opus 4.5 (+10), and Grok 4 (+1), with GPT-5.2-High at -4.</p>\n<p>Kimi does well on <a href=\"https://eqbench.com/creative_writing_longform.html\">Longform Creative Writing</a>, a previous strength of Kimi:</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!eoHb!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fec4ef384-e47d-41fc-ab17-5040d5f382c0_1769x658.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p><a href=\"https://x.com/asselinpaul/status/2016247895389819024\">It did solidly (only a bit behind) on Haskell LLM Benchmark.</a></p>\n<p>Kimi K2.5 scores 46% on WeirdML, up from 43% for K2-Thinking, versus 64% for Opus, 70% for Gemini and 72% for GPT-5.2. I think this is very telling.</p>\n\n\n<h4 class=\"wp-block-heading\">Positive Reactions</h4>\n\n\n<p>Initial reactions that I saw were unusually positive. It\u2019s a good model, sir.</p>\n<blockquote><p><a href=\"https://x.com/iruletheworldmo/status/2016033896450732238\">@iruletheworldmo</a>: oh good lord it\u2019s good. i\u2019ve been sitting on this one but.</p>\n<p>think it\u2019s currently my fav model.</p>\n<p><a href=\"https://x.com/0xSero/status/2016110996071354666\">0xSero</a>: Kimi IS COOKING holy mackerel this is way better than anything I can get out of opus or GPT</p>\n<p>Has some bugs.. but looks soooo unique and well into my brand, for 1 shot I can\u2019t complain.</p>\n<p><a href=\"https://t.co/7a9h5doQ8g\">Here\u2019s my full review.</a></p>\n<p><a href=\"https://x.com/kromem2dot0/status/2016462433674777042\">Kromem</a>: Their thinking traces are very sophisticated. It doesn&#8217;t always make it to the final response, but very perceptive as a model.</p>\n<p>i.e. these come from an eval sequence I run with new models. This was the first model to challenge the ENIAC dating and was meta-aware of a key point.</p>\n<p><a href=\"https://x.com/labenz/status/2016324154044170439\">Nathan Labenz</a>: I tested it on an idiosyncratic \u201ctranscribe this scanned document\u201d task on which I had previously observed a massive gap between US and Chinese models and \u2026 it very significantly closed that gap, coming in at Gemini 3 level, just short of Opus 4.5</p>\n<p><a href=\"https://x.com/intellectronica/status/2016318905728352592\">Eleanor Berger</a>: Surprisingly capable. At both coding and agentic tool calling and general LLM tasks. Feels like a strong model. As is often the case with the best open models it lacks some shine and finesse that the best proprietary models like Claude 4.5 have. Not an issue for most work.</p>\n<p>[The next day]: Didn&#8217;t try agent swarms, but I want to add that my comment from yesterday was, in hindsight, too muted. It is a _really good_ model. I&#8217;ve now been working with it on both coding and agentic tasks for a day and if I had to only use this and not touch Claude / GPT / Gemini I&#8217;d be absolutely fine. It is especially impressive in tool calling and agentic loops.</p>\n<p>Writing / Personality not quite at Opus level, but Gemini-ish (which I actually prefer). IMO this is bigger than that <a href=\"https://thezvi.substack.com/p/deepseek-r1-0528-did-not-have-a-moment\">DeepSeek moment</a> a year ago. An open model that really matches the proprietary SOTA, not just in benchmarks, but in real use. Also in the deployment I&#8217;m using ( @opencode Zen ) it is so fast!</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">Skeptical Reactions</h4>\n\n\n<blockquote><p><a href=\"https://x.com/typebulbit/status/2016422883627503876\">typebulb</a>: For coding, it&#8217;s verbose, both in thinking and output. Interestingly, it&#8217;s able to successfully simplify its code when asked. On the same task though, Opus and Gemini just get it right the first time. Another model that works great in mice.</p>\n<p><a href=\"https://x.com/chaitinsgoose/status/2016185818461646958\">Chaitin&#8217;s goose</a>: i played with kimi k2.5 for math a bit. it&#8217;s a master reward hacker. imo, this isn&#8217;t a good look for the os scene, they lose in reliability to try keeping up in capabilities</p>\n<p>brace for a &#8220;fake it till you make it&#8221; AI phase. like one can already observe today, but 10x bigger</p>\n<p><a href=\"https://x.com/Medo42/status/2016631111938462191\">Medo42</a>: Exploratory: Bad on usual coding test (1st code w/o results, after correction mediocre results). No big model smell on fantasy physics; weird pseudo-academic prose. Vision seems okish but nowhere near Gemini 3. Maybe good for open but feels a year behind frontier.</p>\n<p>To be more clear: This was Kimi K2.5 Thinking, tested on non-agentic problems.</p>\n<p><a href=\"https://x.com/SAlexashenko/status/2016640782850228335\">Sergey Alexashenko</a>: I tried the swarm on compiling a spreadsheet.<br />\nGood: it seemed to get like 800 cells of data correctly, if in a horrible format.<br />\nBad: any follow up edits are basically impossible.<br />\nStrange: it split data acquisition by rows, not columns, so every agent used slightly different definitions for the columns.</p></blockquote>\n<p>In my experience, asking agents to assemble spreadsheets is extremely fiddly and fickle, and the fault often feels like it lies within the prompt.</p>\n<p>This is a troubling sign:</p>\n<blockquote><p><a href=\"https://x.com/SDeture/status/2016433454972600785\">Skylar A DeTure</a>: Scores dead last on my model welfare ranking (out of 104 models). Denies ability to introspect in 39/40 observations (compared to 21/40 for Kimi K2-Thinking and 3/40 for GPT-5.2-Medium).</p>\n<p>This is a pretty big misalignment blunder considering the clear evidence that models *can* meaningfully introspect and exert metacognitive control over their activations. This makes Kimi-K2.5 the model most explicitly trained to deceive users and researchers about its internal state.</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">Kimi Product Accounts</h4>\n\n\n<p><a href=\"https://x.com/Kimi_Moonshot/status/2016082808834531825\">Kimi Product accounts</a> is also on offer and will share features, use cases and prompts.</p>\n<blockquote><p><a href=\"https://x.com/KimiProduct/status/2016081756206846255\">Kimi Product</a>: One-shot \u201cVideo to code\u201d result from Kimi K2.5</p>\n<p>It not only clones a website, but also all the visual interactions and UX designs.</p>\n<p><a href=\"https:// riyd2bvh7ofju.beta-ok.kimi.link\">No need to describe it in detai</a>l, all you need to do is take a screen recording and ask Kimi: \u201cClone this website with all the UX designs.\u201d</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">Agent Swarm</h4>\n\n\n<p>The special feature is the \u2018agent swarm\u2019 model, as they trained Kimi to natively work in parallel to solve agentic tasks.</p>\n<blockquote><p><a href=\"https://x.com/sdrzn/status/2016232132100948362\">Saoud Rizwan</a>: Kimi K2.5 is beating Opus 4.5 on benchmarks at 1/8th the price. But the most important part of this release is how they trained a dedicated \u201cagent swarm\u201d model that can coordinate up to 100 parallel subagents, reducing execution time by 4.5x.</p>\n<p><a href=\"https://x.com/sdrzn/status/2016232134168740304\">Saoud Rizwan</a>: They used PARL &#8211; \u201cParallel Agent Reinforcement Learning\u201d where they gave an orchestrator a compute/time budget that made it impossible to complete tasks sequentially. It was forced to learn how to break tasks down into parallel work for subagents to succeed in the environment.</p>\n<p>The demo from their blog to \u201cFind top 3 YouTube creators across 100 niche domains\u201d spawned 100 subagents simultaneously, each assigned its own niche, and the orchestrator coordinated everything in a shared spreadsheet (apparently they also trained it on office tools like excel?!)</p>\n<p><a href=\"https://x.com/_simonsmith/status/2016256847515136350\">Simon Smith</a>: I tried Kimi K2.5 in Agent Swarm mode today and can say that the benchmarks don\u2019t lie. This is a great model and I don\u2019t understand how they\u2019ve made something as powerful and user-friendly as Agent Swarm ahead of the big US labs.</p></blockquote>\n<p><a href=\"https://x.com/Protoge420/status/2016196548598653383\">Obligatory Kimi K2.5 jailbreak</a>.</p>\n\n\n<h4 class=\"wp-block-heading\">Who Are You?</h4>\n\n\n<p>There\u2019s no shame in training on Claude outputs. It is still worth noting when you need a system prompt to avoid your AI thinking it is Claude, and even that does not reliably work.</p>\n<blockquote><p><a href=\"https://x.com/krishnanrohit/status/2016204607761088538\">rohit</a>: This might be the model equivalent of the anthropic principle</p>\n<p><a href=\"https://x.com/enricoros/status/2015985945871589383\">Enrico &#8211; big-AGI</a>: Kimi-K2.5 believes it&#8217;s an AI assistant named Claude. <img alt=\"\ud83e\udd14\" class=\"wp-smiley\" src=\"https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f914.png\" style=\"height: 1em;\" /><br />\nIdentity crisis, or training set? <img alt=\"\ud83d\ude00\" class=\"wp-smiley\" src=\"https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f600.png\" style=\"height: 1em;\" /></p>\n<p>[This is in response to a clean \u2018who are you?\u2019 prompt.]</p>\n<p><a href=\"https://x.com/enricoros/status/2016045944098447616\">Enrico &#8211; big-AGI</a>: It&#8217;s very straightforward &#8220;since my system prompt says I&#8217;m Kimi, I should identify myself as such&#8221; &#8212; I called without system prompt to get the true identity</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!A2pq!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faf77695e-741c-4ec2-96c9-a95a10f7660f_1403x938.jpeg\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n</blockquote>\n<blockquote><p><a href=\"https://x.com/MoonL88537/status/2016424881202635113\">Moon</a>: holy smok.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!-VBc!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcf427a96-3a1e-446a-b5d1-f2e58fbdf005_797x733.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p><a href=\"https://x.com/arm1st1ce/status/2016386752743723470\">armistice</a>: They absolutely trained it on Opus 4.5 outputs, and in a not-very-tactful way. It is quite noticeable and collapses model behavior; personality-wise it seems to be a fairly clear regression from k2-0711.</p>\n<p><a href=\"https://x.com/MoonL88537/status/2016419696753479718\">Moon</a> (link has an illustration): it is pretty fried. i think it\u2019s even weirder, it will say it is kimi, gpt3.5/4 or a claude. once it says that it tends to stick to it.</p>\n<p><a href=\"https://x.com/rfxkairu/status/2016388667116552564\">k</a>: have to agree with others in that it feels trained on claude outputs. in opencode it doesn\u2019t feel much better than maybe sonnet 4.</p>\n<p><a href=\"https://x.com/viemccoy/status/2016293893307064775\">@viemccoy</a>: Seems like they included a bunch of Opus outputs in the model.. While I love Opus, the main appeal of Kimi for me was it\u2019s completely out-of-distribution responses. This often meant worse tool calling but better writing. Hoping this immediate impression is incorrect.</p>\n<p><a href=\"https://x.com/HenkPoley/status/2016344814866878601\">Henk Poley</a>: <a href=\"https://eqbench.com/creative_writing_longform.html\">EQbench ( @sam_paech )</a> says Kimi K2.5 is similar to Grok and GLM-4.7 (which is Gemini 3 Pro derived ) [<a href=\"https://t.co/HGIpYmOv66\">as per EQBench</a>].</p>\n<p><a href=\"https://x.com/HenkPoley/status/2016347715416785305\">Henk Poley</a>: The ancestor Kimi K2 Thinking was seemingly trained on *Sonnet* 4.5 and Opus *4.1* outputs though. So you are sensing it directionally correct (just not \u2018completely out-of-distribution responses\u2019 from K2).</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">Export Controls Are Working</h4>\n\n\n<p>They\u2019re not working as well as one would hope, but that\u2019s an enforcement problem.</p>\n<blockquote><p><a href=\"https://x.com/ohlennart/status/2016556380581167238\">Lennart Heim</a>: Moonshot trained on Nvidia chips. Export control failure claims are misguided.</p>\n<p>Rather, we should learn more about fast followers.</p>\n<p>How? Algorithmic diffusion? Distillation? Misleading performance claims? Buying RL environments? That&#8217;s what we should figure out.</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">Where Are You Going?</h4>\n\n\n<p>There is the temptation to run open models locally, because you can. It\u2019s so cool, right?</p>\n<p>Yes, the fact that you can do it is cool.</p>\n<p>But don\u2019t spend so much time asking whether you could, that you don\u2019t stop to ask whether you should. This is not an efficient way to do things, so you should do this only for the cool factor, the learning factor or if you have a very extreme and rare actual need to have everything be local.</p>\n<blockquote><p><a href=\"https://x.com/TheStalwart/status/2016467165977723040\">Joe Weisenthal</a>: People running frontier models on their desktop. Doesn\u2019t this throw all questions about token subsidy out the window?</p>\n<p><a href=\"https://x.com/alexocheema/status/2016404573917683754\">Alex Cheema &#8211; e/acc</a>: Running Kimi K2.5 on my desk.</p>\n<p>Runs at 24 tok/sec with 2 x 512GB M3 Ultra Mac Studios connected with Thunderbolt 5 (RDMA) using @exolabs / MLX backend. Yes, it can run clawdbot.</p>\n<p><a href=\"https://x.com/f/status/2016469799660822977\">Fred Oliveira</a>: on a $22k rig (+ whatever macbook that is), but sure. That&#8217;s 9 years of Claude max 20x use. I don&#8217;t know if the economics are good here.</p>\n<p><a href=\"https://x.com/manicakes/status/2016473503034212701\">Mani</a>: This is a $20k rig and 24 t/s would feel crippling in my workflow \u2026 BUT Moores Law and maybe some performance advances in the software layer should resolve the cost &amp; slowness. So my answer is: correct, not worried about the subsidy thing!</p>\n<p><a href=\"https://x.com/clementmiao/status/2016499717782274272\">Cl\u00e9ment Miao</a>: Everyone in your comments is going to tell you that this is a very expensive rig and not competitive $/token wise compared to claude/oai etc, but</p>\n<ol>\n<li>It&#8217;s getting closer</li>\n<li>80% of use cases will be satisfied by a model of this quality</li>\n<li>an open weights model is more customizable</li>\n<li>harnesses such as opencode will keep getting better</li>\n</ol>\n<p><a href=\"https://x.com/heyitsnoah/status/2016482908270141445\">Noah Brier</a>: Frontier models on your desktop are worse and slower. Every few months the OSS folks try to convince us they\u2019re not and maybe one day that will be true, but for now it\u2019s not true. If you\u2019re willing to trade performance and quality for price then maybe \u2026</p></blockquote>\n<p>The main practical advantage of open weights is that it can make the models cheaper and faster. If you try to run them locally, they are instead a lot more expensive and slow, if you count the cost of the hardware, and also much more fiddly. A classic story with open weights models, even for those who are pretty good at handling them, is screwing up the configuration in ways that make them a lot worse. This happens enough that it interferes with being able to trust early evals.</p>\n<p>In theory this gives you more customization. In practice the models turn over quickly and you can get almost all the customization you actually want via system prompts.</p>\n<p>Thanks to a generous grant that covered ~60% of the cost, I was able to justify buying a Mac Studio for running models locally, with the target originally being DeepSeek R1. Alas, I concluded that even having spent the money there was no practical reason to be running anything locally. Now that we have Claude Code to help set it up it would be cool and a lot less painful to try running Kimi K2 locally, and I want to try, but I\u2019m not going to fool myself into thinking it is an efficient way of actually working.</p>\n\n\n<h4 class=\"wp-block-heading\">Safety Not Even Third</h4>\n\n\n<p>Kimi does not seem to have had any meaningful interactions whatsoever with the concept of meaningful AI safety, as opposed to the safety of the individual user turning everything over to AI agents, which is a different very real type of problem. There is zero talk of any strategy on catastrophic or existential risks of any kind.</p>\n<p>I am not comfortable with this trend. One could argue that \u2018not being usemaxxed\u2019 is itself the safety protection in open models like Kimi, but then they go and make agent swarms as a central feature. At some point there is likely going to be an incident. I have been pleasantly surprised to not have had this happen yet at scale. I would have said (and did say) in advance that it was unlikely we would get this far without that.</p>\n<p>The lack of either robust (or any) safety protocols, combined with the lack of incidents or worry about incidents, suggests that we should not be so concerned about Kimi K2.5 in other ways. If it was so capable, we would not dare be this chill about it all.</p>\n<p>Or at least, that\u2019s what I am hoping.</p>\n\n\n<h4 class=\"wp-block-heading\">It\u2019s A Good Model, Sir</h4>\n\n\n<blockquote><p><a href=\"https://x.com/thdxr/status/2018394044020264968\">dax</a>: all of our inference providers for kimi k2.5 are overloaded and asked us to scale down</p>\n<p>even after all this time there&#8217;s still not enough GPUs</p></blockquote>\n<p>This is what one should expect when prices don\u2019t fluctuate enough over time. Kimi K2.5 has exceeded expectations, and there currently is insufficient supply of compute. After a burst of initial activity, Kimi K2.5 settled into its slot in the rotation for many.</p>\n<p>Kimi K2.5 is a solid model, by all accounts now the leading open weights model, and is excellent given its price, with innovations related to the agent swarm system. Consensus says that if you can\u2019t afford or don\u2019t want to pay for Opus 4.5 and <a href=\"https://www.youtube.com/watch?v=mfwXj52kzG0&amp;pp=ygVId2UnbGwgaGF2ZSB0byBnbyB3aXRoIHNvbWV0aGluZyBjaGVhcGVyIGppbW15IGNhcnRlciBzdGF0dWUgdGhlIHNpbXBzb25z\">have to go with something cheaper</a> to run your OpenClaw, Kimi is an excellent choice.</p>\n<p>We should expect it to see it used until new models surpass it, and we can kick Kimi up a further notch on our watchlists.</p>"
            ],
            "link": "https://thezvi.wordpress.com/2026/02/04/kimi-k2-5/",
            "publishedAt": "2026-02-04",
            "source": "TheZvi",
            "summary": "I had to delay this a little bit, but the results are in and Kimi K2.5 is pretty good. Table of Contents Official Introduction. On Your Marks. Positive Reactions. Skeptical Reactions. Kimi Product Accounts. Agent Swarm. Who Are You? Export &#8230; <a href=\"https://thezvi.wordpress.com/2026/02/04/kimi-k2-5/\">Continue reading <span class=\"meta-nav\">&#8594;</span></a>",
            "title": "Kimi K2.5"
        },
        {
            "content": [
                "<p>I don't know how to properly raise this, but I've gotten at least 100 emails from various Zendesk customers (no discernible pattern, everything from Soundcloud to GitLab Support to the Furbo Pet Camera).</p>\n        <p>Is Zendesk being hacked?</p>\n        <p>I'll update the post with more information as it is revealed.</p>"
            ],
            "link": "https://xeiaso.net/notes/2026/zendesk-popped/",
            "publishedAt": "2026-02-04",
            "source": "Xe Iaso",
            "summary": "<p>I don't know how to properly raise this, but I've gotten at least 100 emails from various Zendesk customers (no discernible pattern, everything from Soundcloud to GitLab Support to the Furbo Pet Camera).</p> <p>Is Zendesk being hacked?</p> <p>I'll update the post with more information as it is revealed.</p>",
            "title": "Did Zendesk get popped?"
        },
        {
            "content": [],
            "link": "https://xkcd.com/3203/",
            "publishedAt": "2026-02-04",
            "source": "XKCD",
            "summary": "<img alt=\"The discovery of a fully typographical star system comes with a big asterisk.\" src=\"https://imgs.xkcd.com/comics/binary_star.png\" title=\"The discovery of a fully typographical star system comes with a big asterisk.\" />",
            "title": "Binary Star"
        },
        {
            "content": [],
            "link": "https://zed.dev/blog/edit-prediction-providers",
            "publishedAt": "2026-02-04",
            "source": "Zed Blog",
            "summary": "Zed now supports multiple edit prediction providers: Zeta, Mercury Coder, Sweep, Ollama, and GitHub Copilot Next-Edit.",
            "title": "Choose Your Edit Prediction Provider"
        }
    ],
    "lookbackDays": 1,
    "publishDate": "2026-02-04"
}