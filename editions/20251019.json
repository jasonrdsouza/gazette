{
    "articles": [
        {
            "content": [
                "<p>Every few months I write an opinionated guide to how to use AI<a class=\"footnote-anchor\" href=\"https://www.oneusefulthing.org/feed#footnote-1\" id=\"footnote-anchor-1\" target=\"_self\">1</a>, but now I write it in a world where about <a href=\"https://www.oneusefulthing.org/p/mass-intelligence\">10% of humanity uses AI weekly</a>. The vast majority of that use involves free AI tools, which is often fine&#8230; except when it isn&#8217;t. OpenAI recently released<a href=\"https://cdn.openai.com/pdf/a253471f-8260-40c6-a2cc-aa93fe9f142e/economic-research-chatgpt-usage-paper.pdf\"> a breakdown of what people actually use ChatGPT for</a> (way less casual chat than you&#8217;d think, way more information-seeking than you expected). This means I can finally give you advice based on real usage patterns instead of hunches. I annotated OpenAI&#8217;s chart with some suggestions about when to use free versus advanced models.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!9V4E!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbbb3f806-e9b0-44f2-a384-5abe22e35ec9_1314x673.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"673\" src=\"https://substackcdn.com/image/fetch/$s_!9V4E!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbbb3f806-e9b0-44f2-a384-5abe22e35ec9_1314x673.png\" width=\"1314\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a></figure></div><p>If the chart suggests that a free model is good enough for what you use AI for, pick your favorite and use it without worrying about anything else in the guide. You basically have nine or so choices, because there are only a handful of companies that make cutting-edge models. All of them offer some free access. The four most advanced AI systems are <a href=\"https://claude.ai/\">Claude </a>from Anthropic, Google&#8217;s <a href=\"https://gemini.google.com/\">Gemini</a>, OpenAI&#8217;s <a href=\"https://chatgpt.com/\">ChatGPT</a>, and <a href=\"https://x.ai/\">Grok </a>by Elon Musk&#8217;s xAI. Then there are the open weights AI families, which are almost (but not quite) as good: <a href=\"https://www.deepseek.com/\">Deepseek</a>, <a href=\"https://www.kimi.com/\">Kimi</a>, <a href=\"https://chat.z.ai/\">Z</a> and <a href=\"https://chat.qwen.ai/\">Qwen</a> from China, and <a href=\"https://mistral.ai/\">Mistral </a>from France. Together, variations on these AI models take up the first 35 spots in <a href=\"https://lmarena.ai/leaderboard\">almost any rating system of AI</a>. Any other AI service you use that offers a cutting-edge AI from Microsoft <a href=\"https://copilot.microsoft.com/\">Copilot </a>to <a href=\"https://www.perplexity.ai/\">Perplexity </a>(both of which offer some free use) is powered by one or more of these nine AIs as its base.</p><p>How should you pick among them? Some free systems (like Gemini and Perplexity) do a good job with web search, while others cannot search the web at all. If you want free image creation, the best option is Gemini, with ChatGPT and Grok as runners-up. But, ultimately, these AIs differ in many small ways, including privacy policies, levels of access, capabilities, the approach they take to ethical issues, and &#8220;personality.&#8221; And all of these things fluctuate over time. So pick a model you like based on these factors and use it.  However, if you are considering potentially upgrading to a paid account, I would suggest starting with the free accounts from Anthropic, Google, or OpenAI. If you just want to use free models, the open weights models and aggregation services like Microsoft Copilot have higher usage limits.</p><p>Now on the hard stuff.</p><h1><strong>Picking an Advanced AI System</strong></h1><p>If you want to use an advanced AI seriously, you&#8217;ll need to pay either $20 or around $200 a month, depending on your needs (though companies are now experimenting with other pricing models in some parts of the world). The $20 tier works for the vast majority of people, while the $200 tier is for people with complex technical and coding needs.</p><p>You will want to pick among three systems to spend your $20: <a href=\"https://claude.ai/\">Claude </a>from Anthropic, Google&#8217;s <a href=\"https://gemini.google.com/\">Gemini</a>, and OpenAI&#8217;s <a href=\"https://chatgpt.com/\">ChatGPT</a>. With all of the options, you get access to advanced, agentic, and fast models, a voice mode, the ability to see images and documents, the ability to execute code, good mobile apps, the ability to create images and video (Claude lacks here, however), and the ability to do Deep Research. They all have different personalities and strengths and weaknesses, but for most people, just selecting the one they like best will suffice. Some people, especially big users of X, might want to consider <a href=\"https://x.ai/\">Grok </a>by Elon Musk&#8217;s xAI, which has some of the most powerful AI models and is rapidly adding features, but has not been as transparent about product safety as some of the other companies. Microsoft&#8217;s <a href=\"https://copilot.microsoft.com/\">Copilot </a>offers many of the features of ChatGPT and is accessible to users through Windows, but it can be hard to control what models you are using and when. So, for most people, just stick with Gemini, Claude, or ChatGPT.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!i2vt!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbebe4ff2-3d2a-4543-b8ca-bb8ca3fbbcb6_1500x1610.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"498.0989010989011\" src=\"https://substackcdn.com/image/fetch/$s_!i2vt!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbebe4ff2-3d2a-4543-b8ca-bb8ca3fbbcb6_1500x1610.png\" width=\"464\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a></figure></div><p>Just picking one of these three isn&#8217;t enough, however, because each AI system has multiple AI models to select. <strong>Chat models</strong> are generally the ones you get for free and are best for conversation, because they answer quickly and are usually the most personable. <strong><a href=\"https://www.oneusefulthing.org/p/real-ai-agents-and-real-work\">Agent models</a> </strong>take longer to answer but can autonomously carry out many steps (searching the web, using code, making documents), getting complex work done. <strong><a href=\"https://www.oneusefulthing.org/p/on-working-with-wizards\">Wizard models</a></strong> take a very long time and handle very complex academic tasks. For real work that matters, I suggest using Agent models, they are more capable and consistent and are much less likely to make errors (but remember that all AI models still have a lot of randomness associated with them and may answer in different ways if you ask the same question again.)</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!D1IZ!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4a7df7eb-0a79-4d5a-af22-bf0895bf8f51_2371x786.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"483\" src=\"https://substackcdn.com/image/fetch/$s_!D1IZ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4a7df7eb-0a79-4d5a-af22-bf0895bf8f51_2371x786.png\" width=\"1456\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a><figcaption class=\"image-caption\">Same question asked of a chat model and an agentic one. You can see the chat model answered &#8220;off the top of its head&#8221; while the agentic model did outside research and checked a lot of assumptions before answering,</figcaption></figure></div><h2>Picking the model</h2><p>For ChatGPT, no matter whether you use the free or pay version, the default model you are given is &#8220;ChatGPT 5&#8221;. The issue is that GPT-5 is not one model, it is many, from the very weak GPT-5 mini to the very good GPT-5 Thinking to the extremely powerful GPT-5 Pro. When you select GPT-5, what you are really getting is &#8220;auto&#8221; mode, where the AI decides which model to use, often a less powerful one. By paying, you get to decide which model to use, and, to further complicate things, you can also select how hard the model &#8220;thinks&#8221; about the answer. For anything complex, I always manually select GPT-5 Thinking Extended (on the $20 plan) or GPT-5 Thinking Heavy (if you are paying for the $200 model). For a really hard problem that requires a lot of thinking, you can pick GPT-5 Pro, the strongest model, which is only available at the highest cost tier.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2\" href=\"https://substackcdn.com/image/fetch/$s_!wQZ2!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2daf4483-4bed-4d10-80dc-42608dfe5d2b_686x366.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"226.21574344023324\" src=\"https://substackcdn.com/image/fetch/$s_!wQZ2!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2daf4483-4bed-4d10-80dc-42608dfe5d2b_686x366.png\" width=\"424\" /><div></div></div></a></figure></div><p>For Gemini, you only have two options: Gemini 2.5 Flash and Gemini 2.5 Pro, but, if you pay for the Ultra plan, you get access to Gemini Deep Think (which is in another menu). At this point, Gemini 2.5 is the weakest of the major AI models (though still quite capable and Deep Think is very powerful), but a new Gemini 3 is expected at some point in the coming months.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!Od9u!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F02e9ef68-9591-4bc2-898f-f6508173341f_831x399.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"255.43682310469313\" src=\"https://substackcdn.com/image/fetch/$s_!Od9u!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F02e9ef68-9591-4bc2-898f-f6508173341f_831x399.png\" width=\"532\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a></figure></div><p>Finally, Claude makes it relatively easy to pick a model. You probably want to use Sonnet 4.5 for everything, with the only question being whether you select extended thinking (for harder problems). Right now, Claude does not have an equivalent to GPT-5 Pro.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!nzdY!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb56344a0-cdd8-43ec-81ad-7f7a3a11c9b8_925x508.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"250.97945945945946\" src=\"https://substackcdn.com/image/fetch/$s_!nzdY!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb56344a0-cdd8-43ec-81ad-7f7a3a11c9b8_925x508.png\" width=\"457\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a></figure></div><p>If you are using the paid version of any of these models and want to make sure your data is never used to train a future AI, you can turn off training easily for ChatGPT and Claude without losing any functionality, but at the cost of some functionality for Gemini. All of the AIs also come with a range of other features like projects and memory that you may want to explore as you get used to using them.</p><h2><strong>Getting better answers</strong></h2><p>The biggest uses for AI were practical guidance and getting information, and there are two ways to dramatically improve the quality your results for those kinds of problems: by either triggering Deep Research mode and/or connecting the AI to your data (if you feel comfortable doing that).</p><p>Deep Research is a mode where the AI conducts extensive web research over 10-15 minutes before answering. <a href=\"https://www.oneusefulthing.org/p/the-end-of-search-the-beginning-of\">Deep Research is a key AI feature for most people</a>, even if they don&#8217;t know it yet, and it is useful because it can produce very high-quality reports that often impress information professionals (lawyers, accountants, consultants, market researchers) that I speak to. Deep Research reports are not error-free but are far more accurate than just asking the AI for something, and the citations tend to actually be correct. Also note that each of the Deep Research tools work a little differently, with different strengths and weaknesses. Even without deep research, GPT-5 Thinking does a lot of research on its own, and Claude has a &#8220;medium research&#8221; option where you turn on Web Search but not research.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!jZRs!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7f40f871-574b-48d9-977d-ae02fdeec38c_1250x485.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"485\" src=\"https://substackcdn.com/image/fetch/$s_!jZRs!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7f40f871-574b-48d9-977d-ae02fdeec38c_1250x485.png\" width=\"1250\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a><figcaption class=\"image-caption\">How to trigger Deep Research mode, and also how to connect your data to Claude and ChatGPT</figcaption></figure></div><p>Connections to your own data are very powerful and increasingly available for everything from Gmail to SharePoint. I have found Claude to be especially good in integrating searches across email, calendars, various drives, and more - ask it &#8220;give me a detailed briefing for my day&#8221; when you have connected it to your accounts and you will likely find it impressive. This is an area where the AI companies are putting in a lot of effort, and where offerings are evolving rapidly. </p><h2><strong>Multimodal inputs</strong></h2><p>I have mentioned it before, but an easy way to use AI is just to start with voice mode. The two best implementations of voice mode are in the Gemini app and ChatGPT&#8217;s app and website. Claude&#8217;s voice mode is weaker than the other two systems. Note the voice models are optimized for chat (including all of the small pauses and intakes of breath designed to make it feel like you are talking to a person), so you don&#8217;t get access to the more powerful models this way. </p><p>All the models also let you put all sorts of data into them: you can now upload PDFs, images and even video (for ChatGPT and Gemini). For the app versions, and especially ChatGPT and Gemini, one great feature is the ability to share your screen or camera. Point your phone at a broken appliance, a math problem, a recipe you&#8217;re following, or a sign in a foreign language. The AI sees what you see and responds in real-time. It makes old assistants like Siri and Alexa feel very primitive.</p><h2><strong>Making Things for You: Images, Video, Code, and Documents</strong></h2><p>Claude and ChatGPT can now make PowerPoints and Excel files of high quality (right now, Claude has a lead in these two document formats, but that may change at some point). All three systems can also produce a wide variety of other outputs by writing code. To get Gemini to do this reliably, you need to select the <strong>Canvas</strong> option when you want these systems to run code or produce separate outputs. Claude has a <a href=\"https://claude.ai/artifacts\">specialized artifacts section</a> to show some examples of what it can make with code. There are also very powerful specialized coding tools from each of these models, but those are a bit too complex to cover in this guide.</p><p>ChatGPT and Gemini will also make images for you if you ask (Claude cannot). Gemini has the strongest AI image generation model right now. Both Gemini and OpenAI also have strong video generation capabilities in Veo 3.1 and Sora 2. Sora 2 is really built as a social media application that allows you to put yourself into any video, while Veo 3.1 is more generally focused. They both produce videos with sound.</p><p>As many of you know, my test of any new AI image or video model is <a href=\"https://www.oneusefulthing.org/p/the-recent-history-of-ai-in-32-otters?utm_source=publication-search\">whether it can make an otter using Wi-Fi on an airplane</a>. That is no longer a challenge. So here is Sora 2 showing otter on an airplane as a nature documentary... and an 80s music video... and a modern thriller...  and a 50s low budget SciFi film... and a safety video, and a film noir... and anime... and a 90s video game cutscene... and a French arthouse film.</p><div class=\"native-video-embed\"></div><p>I have been<a href=\"https://www.oneusefulthing.org/p/a-quick-and-sobering-guide-to-cloning?utm_source=publication-search\"> warning about this for years</a>, but, as you can see, you really can&#8217;t trust anything you see online anymore. Please take all videos with a grain of salt. And, as a reminder, this is what you got if you prompted an AI to provide the image of an otter on an airplane four years ago. Things are moving fast.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!OnOV!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa2ee3edc-0905-4ba3-9a7e-ae61d91b9ec3_400x400.jpeg\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"310\" src=\"https://substackcdn.com/image/fetch/$s_!OnOV!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa2ee3edc-0905-4ba3-9a7e-ae61d91b9ec3_400x400.jpeg\" width=\"310\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a></figure></div><h1><strong>Quick Tips</strong></h1><p>Beyond the basics of selecting models, there are a few things that come up quite often that are worth considering:</p><ul><li><p><strong>Hallucinations: </strong>In many ways, hallucinations are far less of a concern than they used to be, as newer AI models are better at not hallucinating. However, no matter how good the AI is, it will still make errors and mistakes and still give you confident answers where it is wrong. They also can hallucinate about their own capabilities and actions. Answers are more likely to be right when they come from advanced models, and if the AI did web searches. And remember, the AI doesn&#8217;t know &#8220;why&#8221; it did something, so asking it to explain its logic will not get you anywhere. However, if you find issues, the thinking trace of AI models can be helpful. </p></li><li><p><strong>Sycophancy and Personality: </strong>All of the AI chatbots have become more engaging and likeable. On one hand, that makes them more fun to use, on the other it risks making AIs seem like people when they are not, which creates a danger that people may form stronger attachments to AI. A related issue is sycophancy, where the AI agrees with what you say.<a href=\"https://www.oneusefulthing.org/p/personality-and-persuasion\"> The reasons for this are complicated </a>but when you need real feedback, explicitly tell the AI to act as a critic. Otherwise, you might be talking to a very sophisticated yes-man.</p></li><li><p><strong>Give the AI context to work with</strong>. Though memory features are being added, most AI models only know basic user data and the information in the current chat, they do not remember or learn about you beyond that. So, you need to provide the AI with context: documents, images, PowerPoints, or even just an introductory paragraph about yourself can help - use the file option to upload files and images whenever you need, or else use the connectors we discussed earlier.</p></li><li><p><strong>Don&#8217;t worry too much about prompting &#8220;well&#8221;: </strong>Older AI models required you to generate a prompt using techniques like chain-of-thought. But as AI models get better, the importance of this fades and the models get better at figuring out what you want. In a recent series of experiments, we have discovered that <a href=\"https://gail.wharton.upenn.edu/research-and-insights/tech-report-chain-of-thought/\">these techniques don&#8217;t really help anymore</a> (and no, <a href=\"https://gail.wharton.upenn.edu/research-and-insights/techreport-threaten-or-tip/\">threatening </a>them or <a href=\"https://gail.wharton.upenn.edu/research-and-insights/tech-report-prompt-engineering-is-complicated-and-contingent/\">being nice to them</a> does not seem to help on average).</p></li><li><p><strong>Experiment and have fun: </strong>Play is often a good way to learn what AI can do. Ask a video or image model to make a cartoon, ask an advanced AI to turn your report or writing into a game, do a deep research report on a topic that you are excited about, ask the AI to guess where you are from a picture, show the AI an image of your fridge and ask for recipe ideas, work with the AI to plot out a dream trip. Try things and you will learn the limits of the system.</p></li></ul><h1>Where this goes</h1><p>I started this guide mentioning that 10% of humanity uses AI weekly. By the time I write the next update in a few months, that number will likely be higher, the models will be better, and some of the specific recommendations I made today will be outdated. What won&#8217;t change is the fact that people who learn to use these systems well will find ways to benefit from them, and to build intuition for the future.</p><p>The chart at the top of this post shows what people use AI for <em>today</em>. But I&#8217;d bet that in two years, that chart looks completely different. And that isn&#8217;t just because AI changed what it can do, but also because users figured out what it should do. So, pick a system and start with something that actually matters to you, like a report you need to write, a problem you&#8217;re trying to solve, or a project you have been putting off. Then try something ridiculous just to see what happens. The goal isn&#8217;t to become an AI expert. It&#8217;s to build intuition about what these systems can and can&#8217;t do, because that intuition is what will matter as these tools keep evolving.</p><p>The future of AI isn&#8217;t just about better models. It&#8217;s about people figuring out what to do with them.</p><p class=\"button-wrapper\"><a class=\"button primary\" href=\"https://www.oneusefulthing.org/subscribe\"><span>Subscribe now</span></a></p><p class=\"button-wrapper\"><a class=\"button primary\" href=\"https://www.oneusefulthing.org/p/an-opinionated-guide-to-using-ai?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share\"><span>Share</span></a></p><div class=\"footnote\"><a class=\"footnote-number\" contenteditable=\"false\" href=\"https://www.oneusefulthing.org/feed#footnote-anchor-1\" id=\"footnote-1\" target=\"_self\">1</a><div class=\"footnote-content\"><p>This is an opinionated guide because, like all of my writing on this Substack, social media, and my books, I write it all myself and I only get AI feedback when I am done with a draft. I might make mistakes, and my opinion may not be yours, but I do not take money from any of the AI companies, so they very much are my opinions. </p></div></div>"
            ],
            "link": "https://www.oneusefulthing.org/p/an-opinionated-guide-to-using-ai",
            "publishedAt": "2025-10-19",
            "source": "Ethan Mollick",
            "summary": "<p>Every few months I write an opinionated guide to how to use AI<a class=\"footnote-anchor\" href=\"https://www.oneusefulthing.org/feed#footnote-1\" id=\"footnote-anchor-1\" target=\"_self\">1</a>, but now I write it in a world where about <a href=\"https://www.oneusefulthing.org/p/mass-intelligence\">10% of humanity uses AI weekly</a>. The vast majority of that use involves free AI tools, which is often fine&#8230; except when it isn&#8217;t. OpenAI recently released<a href=\"https://cdn.openai.com/pdf/a253471f-8260-40c6-a2cc-aa93fe9f142e/economic-research-chatgpt-usage-paper.pdf\"> a breakdown of what people actually use ChatGPT for</a> (way less casual chat than you&#8217;d think, way more information-seeking than you expected). This means I can finally give you advice based on real usage patterns instead of hunches. I annotated OpenAI&#8217;s chart with some suggestions about when to use free versus advanced models.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!9V4E!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbbb3f806-e9b0-44f2-a384-5abe22e35ec9_1314x673.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"673\" src=\"https://substackcdn.com/image/fetch/$s_!9V4E!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbbb3f806-e9b0-44f2-a384-5abe22e35ec9_1314x673.png\" width=\"1314\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3",
            "title": "An Opinionated Guide to Using AI Right Now"
        },
        {
            "content": [],
            "link": "https://eugeneyan.com//writing/principal/",
            "publishedAt": "2025-10-19",
            "source": "Eugene Yan",
            "summary": "Based on what I've learned from role models and mentors in Amazon",
            "title": "Advice for New Principal Tech ICs (i.e., Notes to Myself)"
        },
        {
            "content": [],
            "link": "https://olano.dev/blog/balancing-coupling",
            "publishedAt": "2025-10-19",
            "source": "Facundo Olano",
            "summary": "Vlad Khononov builds on the ideas of Parnas, Myers, Brooks, Conway, and Ousterhout, to produce something new and useful.",
            "title": "[tl;dr] Balancing Coupling in Software Design"
        },
        {
            "content": [
                "<p><strong>TL;DR: I built a lightweight Chrome MCP. Scroll to the end to learn how to install it. Read the whole post to learn a little bit about the Zen of MCP design.</strong></p>\n<p>Claude Code has built in tools to fetch web pages and to search the web \u2013 they actually run through Anthropic's servers, if I recall correctly. They do clever things to carefully manage context and to return information in a format that's easy for Claude to digest.</p>\n<p>These tools work really well.</p>\n<p>Right up to the point where they completely fall apart.</p>\n<p><a class=\"glightbox\" href=\"https://blog.fsck.com/assets/2025/10/pasted-image-20251019-180931.png\"><img alt=\"pasted image 20251019 180931\" src=\"https://blog.fsck.com/assets/2025/10/pasted-image-20251019-180931.png\" /></a></p>\n<p><em>An uncoached testimonial from the only customer who matters.</em></p>\n<p>Last week, I somehow got it into my head that I should update my custom blogging client to use Apple's new Liquid Glass look and feel.</p>\n<p>The first issue I ran into was that Claude was <em>absolutely sure</em> that macOS 26 wasn't out yet.  (Amusingly, when asked to review a draft of this post, one of the things it flagged was: '<strong>Inconsistent model naming</strong> - You refer to &quot;macOS 26&quot; but I believe you mean &quot;macOS 15&quot; (Sequoia). macOS 26 would be way in the future.')</p>\n<p>Claude was, however, happy to speculate about what a &quot;Liquid Glass&quot; UI might look like.  Once I reminded the model that it had memory issues and Apple had indeed released the new version of their operating system, it was ready to get to work.</p>\n<p>I told it to go read Apple's Human Interface Guidelines and make a plan.  This is what Claude saw:</p>\n<pre><code>&lt;div class=&quot;noscript&quot;&gt;&lt;h1 class=&quot;noscript-title&quot;&gt;This page requires JavaScript.&lt;/h1&gt;&lt;p&gt;Please turn on JavaScript in your browser and refresh the page to view its content.&lt;/p&gt;&lt;/div&gt;&lt;/noscript&gt;&lt;div id=&quot;app&quot;&gt;&lt;/div&gt;\n</code></pre>\n<p>It turns out that Apple no longer offer a downloadable version of the HIG. And the online version requires JavaScript .  After a bit of flailing, Claude reached for the industry-standard Playwright MCP from Microsoft.</p>\n<p><a class=\"glightbox\" href=\"https://blog.fsck.com/assets/2025/10/pasted-image-20251019-181028.png\"><img alt=\"pasted image 20251019 181028\" src=\"https://blog.fsck.com/assets/2025/10/pasted-image-20251019-181028.png\" /></a></p>\n<p>The Playwright MCP is a collection of 21 tools covering all aspects of driving a browser and debugging webapps, from <code>browser_install</code> to <code>browser_click</code> to <code>browser_navigate_back</code>. Just having the Playwright MCP available costs 13,678 tokens (7% of the whole context window) in every single session, even if you never use it. (Yes, the Google Chrome team has their own Chrome MCP. Its API surface is <em>even bigger</em>)</p>\n<p>And once you do start using it, things get worse. Some of its tools return the entire DOM of the webpage you're working with. This means that simple requests fail because they return more tokens than Claude can handle in a response:</p>\n<pre><code>&gt; Please use the playwright MCP to fetch the headlines from https://www.bbc.com\u00a0\n\n\u23fa I'll use the Playwright MCP to navigate to BBC.com and fetch the headlines for you.\n\n\u23fa **playwright - Navigate to a URL (MCP)**(url: &quot;https://www.bbc.com&quot;)\n\u00a0 \u23bf \u00a0Error: MCP tool &quot;browser_navigate&quot; response (25837 tokens) exceeds maximum allowed tokens (25000). Please use pagination, filtering, or limit parameters to reduce the response size.\n\n\u23fa Let me take a snapshot instead to get a more structured view of the page:\n\u00a0 \u23bf \u00a0Error: MCP tool &quot;browser_snapshot&quot; response (36196 tokens) exceeds maximum allowed tokens (25000). Please use pagination, filtering, or limit\u00a0parameters to reduce the response size.\n\n\u23fa The page is quite large. Let me try to extract just the headlines using JavaScript evaluation: [...]\n</code></pre>\n<p>It's frustrating to see a coding agent trying over and over to use a tool the way it's supposed to and having that tool just fail to return useful data.</p>\n<h1 id=\"a-simple-solution-that-s-not-an-mcp\" tabindex=\"-1\">A simple solution that's not an MCP <a class=\"header-anchor\" href=\"https://blog.fsck.com/2025/10/19/mcps-are-not-like-other-apis/\">#</a></h1>\n<p>After hearing me complain about this a few times, Dan Grigsby commented that he'd had success just asking Claude to teach itself a skill: Using the raw Dev Tools remote control protocol to drive Chrome.</p>\n<p>This seemed like a neat trick, so I asked my Claude to take a swing at it.</p>\n<p>Claude was only too happy to try to speak raw JSON-RPC to Chrome on port 9292. It...just worked. But it was also very clunky and wasteful feeling. Claude was writing raw JSON-RPC command lines for each and every interaction. It was very verbose and required the LLM to get a whole bunch of details right on every single command invocation.</p>\n<p>It was time to make a proper Skill.</p>\n<p>After thinking about it for a moment, I asked Claude to write a little zero-dependency command-line tool called <a href=\"https://github.com/obra/superpowers-chrome/blob/844a442ca4c63a619f10d17abf269f36f3977fc9/skills/browsing/chrome-ws\"><code>chrome-ws</code></a> that it could run with the Bash tool to control Chrome, as well as  a new <a href=\"https://github.com/obra/superpowers-chrome/blob/2488c202fb13a833234cdf9b968e5a940b39dc86/skills/using-chrome-directly/SKILL.md\"><code>SKILL.md</code> file explaining how to use that script</a>.  <code>chrome-ws</code> encapsulated the complexity and made Chrome easily scriptable from the command line.</p>\n<p>The skill sets up the basics of web browsing with its tools and uses <em>progressive disclosure</em> to tell Claude how to get more information, but only when it has a need to know. For example, <a href=\"https://github.com/obra/superpowers-chrome/blob/2488c202fb13a833234cdf9b968e5a940b39dc86/skills/using-chrome-directly/EXAMPLES.md\">these examples of how to use the <code>chrome-ws</code> tool</a>.</p>\n<p>Claude didn't always reach for the skill, so it wasn't aware of its new command-line tool, but once I pointed it in the right direction, it worked <em>surprisingly well</em>.</p>\n<p>This setup was incredibly token efficient \u2013 Nothing in the context window at startup other than a skill <code>name</code> and <code>description</code> in the system prompt. What was a little frustrating for me was that any time Claude wanted to do <em>anything</em> with the browser, it had to run a custom Bash command that I had to approve. Every click. Every navigation. Every javascript expression. It got old really, really fast.</p>\n<p>There's no real way to fix that without creating a custom MCP.</p>\n<h1 id=\"giving-up-and-making-an-mcp\" tabindex=\"-1\">Giving up and making an MCP <a class=\"header-anchor\" href=\"https://blog.fsck.com/2025/10/19/mcps-are-not-like-other-apis/\">#</a></h1>\n<p>But that would put us right back where we were with the official Playwright MCP, right? Nearly two dozen tools and 13k tokens spilled on the floor every time we started a session. Even trimming things down to only the dozen most important commands is still a bunch of tools, most of which Claude won't use in a given session.</p>\n<p>If you've ever done API design, you probably know how important it is to name your methods well. You know that every method should do one thing and only one thing. You know that you really need  to type (and validate) all your parameters to make sure your callers can tell what they're supposed to be passing in and to make bad method calls fail as soon as possible.</p>\n<p>It would be absolutely unhinged to have a method called <code>use_browser</code> that took a parameter called <code>action</code> that was itself a method dispatcher, a parameter called <code>selector</code>, and a parameter called <code>payload</code>.</p>\n<p>You'd have to be crazy to think that it's acceptable API design to have the optional, untyped <code>payload</code> field just have a description like <code>(&quot;Action-specific data: navigate=URL | type=text (append \\\\n to submit) | extract=format (text|html|markdown) | screenshot=filename | eval=JavaScript | select=option value | attr=attribute name | await_text=text to wait for</code></p>\n<p>And yet. That is exactly how I designed it.</p>\n<p>And it's just great.</p>\n<p>The high-level tool description reads:</p>\n<pre><code>Control persistent Chrome browser via DevTools Protocol. Use the superpowers-chrome:browsing skill for detailed guidance.\n\nCRITICAL: Selectors support CSS or XPath (XPath must start with / or //). Append \\\\n to payload in 'type' action to submit forms. State persists across calls.\n  \nExamples: {action:&quot;click&quot;, selector:&quot;//button[@type='submit']&quot;} | {action:&quot;extract&quot;, payload:&quot;text&quot;, selector:&quot;//h2&quot;}\n\nWorkflows: navigate\u2192await_element\u2192extract | navigate\u2192type(payload:&quot;text\\\\n&quot;)\u2192await_text\n</code></pre>\n<p>At session startup, the whole MCP config weighs in at just 947 tokens. I'm pretty sure I can shave at least 30-40 more.</p>\n<p>It's optimized to make Claude's life as easy as possble. Rather than having a method to start the browser, the MCP...just does it when it needs to. Same with opening a new tab if there wasn't one waiting.</p>\n<p>The tool description tells Claude what to do and where to read up when it needs more help. At least so far, it works just great for me.</p>\n<p>One of the mistakes I made while developing the MCP was to instruct Claude to cut down the API surface by only accepting CSS selectors, rather than accepting CSS or XPath. It seemed natural to me that a smaller, simpler API would be easier for Claude to work with and reason about.  Right up until I saw the MCP tool description containing multiple admonitions like <code>CRITICAL: CSS selectors only (NOT XPath)</code>.  The whole thing just...worked better when I let the selector fields accept either CSS or XPath.</p>\n<p>Another thing that Claude got not-quite-right when it first implemented the MCP was that it included detailed human-readable <code>description</code> text for all the <code>use_browser</code> method parameters. Because LLMs that are using MCPs can see both the <code>description</code> and the actual JSON schema, you don't need to repeat things like lists of values for an enum or type validations. One trick you can use is to ask your agent to tell you exactly what it can see about how to use an API.</p>\n<p>One of the weirdest realizations I had while building <code>superpowers-chrome</code> is this: I have no doubt that there are a dozen similar tools out there, but it was literally faster and easier to build the tool that I thought should exist than to test out a dozen tools to see if any of them work the way I think they should.</p>\n<h1 id=\"i-have-feels-about-designing-for-llms\" tabindex=\"-1\">I have feels about designing for LLMs <a class=\"header-anchor\" href=\"https://blog.fsck.com/2025/10/19/mcps-are-not-like-other-apis/\">#</a></h1>\n<p>Over the last couple of decades, the common wisdom has become that Postel's Law (aka the robustness principle) is dated and wrong and that APIs should be rigid and rigorous. That's the wrong choice when you're designing for use by LLMs.</p>\n<p>This might be a hard lesson to hear, but tools you build for LLMs are going to work much, much better if you think of your end-user as a &quot;person&quot; rather than a computer. Build your tools  like they're a set of scripts you're handing to that undertrained kid who just got hired in the NOC. They <em>are</em> going to page you at 2AM when they can't figure out what's going on or when they misuse the tools in a way they can't unwind.</p>\n<p>Names and method descriptions matter far more than they ever have before.</p>\n<p>Automatic recovery is hugely important. Designing for error recovery rather than failing fast will make the whole system more reliable and less expensive to operate.</p>\n<p>When errors are unaviodable, your error messages should tell the user how to fix or work around the problem in plain English.</p>\n<p>If you can't give the user exactly what they asked for, but you can give them a partial answer or related information, do that.</p>\n<p>Claude absolutely does not care about the architectural purity of your API. It just wants to help you get work done with the limited resources at its disposal.</p>\n<h1 id=\"actually-using-it\" tabindex=\"-1\">Actually using it <a class=\"header-anchor\" href=\"https://blog.fsck.com/2025/10/19/mcps-are-not-like-other-apis/\">#</a></h1>\n<p>This new MCP and skill for Claude Code, is called <a href=\"https://github.com/obra/superpowers-chrome/tree/main\">superpowers-chrome</a>.</p>\n<p>You can install it like this:</p>\n<pre><code>/plugin marketplace add obra/superpowers-marketplace\n/plugin install superpowers-chrome@superpowers-marketplace\n</code></pre>\n<p>If you're already using <a href=\"https://github.com/obra/superpowers\">Superpowers</a>, you can just type /plugin, navigate to 'Install plugins', pick 'superpowers-marketplace' and then you should see <code>superpowers-chrome</code>.</p>\n<p>I'd love to hear from you if you find it helpful. I'd also love patches and pull requests.</p>"
            ],
            "link": "https://blog.fsck.com/2025/10/19/mcps-are-not-like-other-apis/",
            "publishedAt": "2025-10-19",
            "source": "Jesse Vincent",
            "summary": "<p><strong>TL;DR: I built a lightweight Chrome MCP. Scroll to the end to learn how to install it. Read the whole post to learn a little bit about the Zen of MCP design.</strong></p> <p>Claude Code has built in tools to fetch web pages and to search the web \u2013 they actually run through Anthropic's servers, if I recall correctly. They do clever things to carefully manage context and to return information in a format that's easy for Claude to digest.</p> <p>These tools work really well.</p> <p>Right up to the point where they completely fall apart.</p> <p><a class=\"glightbox\" href=\"https://blog.fsck.com/assets/2025/10/pasted-image-20251019-180931.png\"><img alt=\"pasted image 20251019 180931\" src=\"https://blog.fsck.com/assets/2025/10/pasted-image-20251019-180931.png\" /></a></p> <p><em>An uncoached testimonial from the only customer who matters.</em></p> <p>Last week, I somehow got it into my head that I should update my custom blogging client to use Apple's new Liquid Glass look and feel.</p> <p>The first issue I ran into was that Claude was <em>absolutely sure</em> that macOS 26 wasn't out yet. (Amusingly, when asked to review a draft of this post, one of the things it flagged was: '<strong>Inconsistent model naming</strong> - You refer to &quot;macOS 26&quot; but I believe you mean &quot;macOS 15&quot; (Sequoia). macOS 26 would be way in the future.')</p> <p>Claude was,",
            "title": "When it comes to MCPs, everything we know about API design is wrong"
        },
        {
            "content": [],
            "link": "https://www.robinsloan.com/lab/trinary-dream/",
            "publishedAt": "2025-10-19",
            "source": "Robin Sloan",
            "summary": "<p>Yes, no, maybe. <a href=\"https://www.robinsloan.com/lab/trinary-dream/\">Read here.</a></p>",
            "title": "The trinary dream endures"
        }
    ],
    "lookbackDays": 1,
    "publishDate": "2025-10-19"
}