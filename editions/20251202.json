{
    "articles": [
        {
            "content": [
                "<p>I've spent a fair bit of time over the past year having agents build webapps for me. Typically, they're built out of some nodejs backend and then some client-side js framework.</p>\n<p>One debugging pattern that comes up again and again is that there's a bug in the client side JavaScript.  Often a current-gen model running in a coding agent is able to solve a client-side bug just by inspecting the code.</p>\n<p>When it works, it's amazing. But &quot;often&quot; is not the same thing as &quot;every time&quot;.  If the agent can't solve the problem by inspection it will often fire up a browser MCP and attempt to debug the problem interactively. What it's really trying to do is to get a peek at the browser's console log. This works, but it burns a ton of tokens and takes <em>forever</em>.</p>\n<p>There's a better way.</p>\n<p>One of the first things I ask my agents to build when we're doing web dev is a frontend to backend bridge for console logs. There are two parts to this:</p>\n<ol>\n<li>\n<p>A tiny development-mode JavaScript shim in the frontend code that sends almost any <code>console.log()</code> (or <code>console.whatever()</code>) message to a backend API endpoint. You want to be careful to make sure that the shim doesn't try to send its own &quot;I can't talk to the backend endpoint&quot; errors to the backend.</p>\n</li>\n<li>\n<p>A backend endpoint that receives frontend log messages from clients and logs them to the server log.</p>\n</li>\n</ol>\n<p>With those two things, <code>claude</code> or whomever you've got coding for you can see frontend and backend log messages in one place, just by tailing a log. It's amazingly useful, really straightforward and so quick to build.</p>\n<p>It turns out that it's helpful for any humans who are working on your software, too.</p>"
            ],
            "link": "https://blog.fsck.com/2025/12/02/helping-agents-debug-webapps/",
            "publishedAt": "2025-12-02",
            "source": "Jesse Vincent",
            "summary": "<p>I've spent a fair bit of time over the past year having agents build webapps for me. Typically, they're built out of some nodejs backend and then some client-side js framework.</p> <p>One debugging pattern that comes up again and again is that there's a bug in the client side JavaScript. Often a current-gen model running in a coding agent is able to solve a client-side bug just by inspecting the code.</p> <p>When it works, it's amazing. But &quot;often&quot; is not the same thing as &quot;every time&quot;. If the agent can't solve the problem by inspection it will often fire up a browser MCP and attempt to debug the problem interactively. What it's really trying to do is to get a peek at the browser's console log. This works, but it burns a ton of tokens and takes <em>forever</em>.</p> <p>There's a better way.</p> <p>One of the first things I ask my agents to build when we're doing web dev is a frontend to backend bridge for console logs. There are two parts to this:</p> <ol> <li> <p>A tiny development-mode JavaScript shim in the frontend code that sends almost any <code>console.log()</code> (or <code>console.whatever()</code>) message to a backend API endpoint. You want to",
            "title": "Helping agents debug webapps"
        },
        {
            "content": [
                "<p></p>\n<figure><img alt=\"\" src=\"https://www.jonashietala.se/images/jw_mods/modded_front.jpg\" />\n</figure>\n<p>I\u2019ve had my <a href=\"https://www.jonashietala.se/series/voron_trident\">VORON Trident</a> for 2 years and I\u2019ve run it for 2600 hours.\nOverall I\u2019m happy with the printer but I\u2019ve been itching to make some more mods to it.\nHaving finally finished the <a href=\"https://www.jonashietala.se/blog/2025/03/25/lets_build_a_voron_0\">VORON 0</a> (<a href=\"https://www.jonashietala.se/blog/2025/05/02/voron_0_mods\">with mods</a>) I now have a backup printer I can use to rescue myself when I screw up.</p>\n<p>As the printer was starting to crap out with <a href=\"https://www.jonashietala.se/blog/2024/03/01/lets_build_a_voron_major_failure/\">a leadscrew starting to grind down again</a>, the chamber thermistor stopped working, and PLA clogging up the Rapido hotend <em>again</em> it was time for a bit of a rebuild.</p>\n<aside class=\"warn\">\n<p>Even my <a href=\"https://www.jonashietala.se/blog/2025/03/25/lets_build_a_voron_0\">VORON 0</a> ran into an issue where the bed stopped heating up.\nThis happened at the <em>same time</em> as all the issues with the <a href=\"https://www.jonashietala.se/series/voron_trident\">Trident</a> started appearing.</p>\n<p>So much for having a backup printer!</p>\n</aside>\n<section id=\"The-plan\">\n<h2><a class=\"heading-ref\" href=\"https://www.jonashietala.se/#The-plan\">The plan</a></h2>\n<p>Besides fixing the printer I also wanted to prepare for a multi-color solution such as the <a href=\"https://github.com/ArmoredTurtle/BoxTurtle\">Box Turtle</a> and make some quality of life changes.</p>\n<ol type=\"a\">\n<li>\n<p>Replace the problematic leadscrew with a replacement part I received from LDO and replace the POM nuts on the other leadscrews.</p>\n</li>\n<li>\n<p><a href=\"https://www.jonashietala.se/#Inverted-electronics\">Install the Inverted electronics</a> mod.</p>\n<p>I\u2019ve been using the <a href=\"https://www.jonashietala.se/blog/2024/02/27/lets_build_a_voron_more_mods/#RockNRoll\">RockNRoll</a> mod to give access to the electronics compartment by tilting the printer backwards.\nThe <a href=\"https://mods.vorondesign.com/details/pXkXHVIUbqSWqQKJISczw\">Inverted electronics</a> mod would instead allow me to lift the bottom plate to access the electronics compartment and I want to do it before installing a <a href=\"https://github.com/ArmoredTurtle/BoxTurtle\">Box Turtle</a> on top of the printer.</p>\n</li>\n<li>\n<p>Replace the Stealthburner with the <a href=\"https://github.com/kinematicdigit/Jabberwocky\">Jabberwocky</a> toolhead.</p>\n<p>This introduced a series of changes:</p>\n<ol type=\"a\">\n<li>\n<p>Move to an umbilical setup with the <a href=\"https://lab4450.com/product/ldo-nitehawk36-toolhead/\">Nitehawk36</a> toolboard.</p>\n</li>\n<li>\n<p>Use <a href=\"https://docs.vorondesign.com/tuning/sensorless.html\">sensorless homing</a> to get rid of the Y drag chain.</p>\n</li>\n<li>\n<p>Replace TAP with the <a href=\"https://lab4450.com/product/original-beacon-3d-surface-scanner/\">Beacon probe</a>.</p>\n</li>\n<li>\n<p>Finally, <a href=\"https://www.jonashietala.se/#Installation\">install the Jabberwocky</a>.</p>\n</li>\n</ol>\n</li>\n</ol>\n</section>\n<section id=\"Replacing-the-POM-nuts\">\n<h2><a class=\"heading-ref\" href=\"https://www.jonashietala.se/#Replacing-the-POM-nuts\">Replacing the POM nuts</a></h2>\n<p>I\u2019ve had issues before where one of the <a href=\"https://www.jonashietala.se/blog/2024/03/01/lets_build_a_voron_major_failure/\">POM nuts were ground down</a> and I felt it was happening again.\nThe printer didn\u2019t completely fail like before but it was sometimes getting really bad first layers in that same corner and the Z probe was occasionally failing to configure Z tilt.</p>\n<p>I replaced all three POM nuts together with the whole lead screw (I got a new one sent to me by LDO the first time it failed but I hadn\u2019t installed it yet).</p>\n<figure><img alt=\"\" src=\"https://www.jonashietala.se/images/jw_mods/pom_nuts.jpg\" />\n<figcaption>Dust on the lead screw and all three nuts show signs of damage, although the leftmost is clearly worse off.\n</figcaption></figure>\n<p>This is apparently a common problem with some LDO kits that have coated lead screws.\nI still have two of the old ones that I may have to replace in the future.</p>\n</section>\n<section id=\"Inverted-electronics\">\n<h2><a class=\"heading-ref\" href=\"https://www.jonashietala.se/#Inverted-electronics\"><a href=\"https://mods.vorondesign.com/details/pXkXHVIUbqSWqQKJISczw\">Inverted electronics</a></a></h2>\n<p>I\u2019ve been looking at the <a href=\"https://mods.vorondesign.com/details/pXkXHVIUbqSWqQKJISczw\">Inverted electronics</a> mod even before finishing my Trident printer.\nBut it wasn\u2019t possible with the <a href=\"https://pif.voron.dev/\">Print It Forward</a> service I used to print parts for my first 3D printer,\nand after the printer was completed I didn\u2019t feel the need to redo the wiring again.</p>\n<figure><img alt=\"\" src=\"https://www.jonashietala.se/images/jw_mods/electronics_before.jpg\" />\n<figcaption>Wiring before ripping it all out.\n</figcaption></figure>\n<figure><img alt=\"\" src=\"https://www.jonashietala.se/images/jw_mods/inverted_under.jpg\" />\n<figcaption>Underside of the printer with the inverted rails installed.\n</figcaption></figure>\n<figure><img alt=\"\" src=\"https://www.jonashietala.se/images/jw_mods/inverted_power.jpg\" />\n<figcaption>Installing the first components on the rails.\n</figcaption></figure>\n<figure><img alt=\"\" src=\"https://www.jonashietala.se/images/jw_mods/inverted_wiring.jpg\" />\n<figcaption>The electronics are reinstalled and up and running.\nThis is not the final configuration, just a snapshot of when I got it running.\n</figcaption></figure>\n<aside class=\"note\">\n<p>I had forgotten to print out <a href=\"https://www.printables.com/model/1218789-nitehawk-36-usb-adapter-mount-for-voron-din-clip\">a holder for the Nitehawk 36 USB</a> but I had to get the printer up and running to print one.</p>\n</aside>\n<figure><img alt=\"\" src=\"https://www.jonashietala.se/images/jw_mods/final_electronics.jpg\" />\n<figcaption>The electronics with cables cleaned up a little.\n</figcaption></figure>\n<p>Overall it was surprisingly easy to reinstall all the electronics.\nIt was made easier by the move to umbilical and a single USB cable to the toolhead as it removed quite a bit of wiring:</p>\n<figure><img alt=\"\" src=\"https://www.jonashietala.se/images/jw_mods/removed_wiring.jpg\" />\n<figcaption>Heap of things I removed from the printer when moving to umbilical and sensorless homing.\n</figcaption></figure>\n<p>One issue I had with the mod is that the cutouts for the Z motors were a bit large, with gaps where stray filament or heat can escape through.\nI tried to cover them up by placing some foam tape around the motors:</p>\n<figure><img alt=\"\" src=\"https://www.jonashietala.se/images/jw_mods/gaps_foam.jpg\" />\n<figcaption>The Z motor mounts have a gap between them and the electronics cover.\nI tried to fill them in with foam tape from below.\n</figcaption></figure>\n</section>\n<section id=\"Why-the-Jabberwocky\">\n<h2><a class=\"heading-ref\" href=\"https://www.jonashietala.se/#Why-the-Jabberwocky\">Why the <a href=\"https://github.com/kinematicdigit/Jabberwocky\">Jabberwocky</a>?</a></h2>\n<p>I\u2019ve been wanting to replace the Stealthburner toolhead a long time:</p>\n<ol>\n<li>\nThe cooling for PLA is quite bad.\n</li>\n<li>\nPLA has a tendency to clog (seems like a decently common problem with Rapido and Stealthburner).\n</li>\n<li>\nResolving a clog when it happens is a pain in the ass.\n</li>\n<li>\nIt lacks a filament sensor and a cutter (for multi-color).\n</li>\n</ol>\n<p>But what to choose?\nThere are quite a few interesting toolheads I considered:</p>\n<ol>\n<li>\n<p><a href=\"https://github.com/chirpy2605/voron/tree/main/V0/Dragon_Burner\">Dragon Burner</a></p>\n<p>I use the <a href=\"https://github.com/chirpy2605/voron/tree/main/V0/Dragon_Burner\">Dragon Burner</a> in <a href=\"https://www.jonashietala.se/blog/2025/03/25/lets_build_a_voron_0\">my VORON 0</a> and using the same toolhead is boring.</p>\n</li>\n<li>\n<p><a href=\"https://docs.armchairheavyindustries.com/docs/archetype\">Archetype</a></p>\n<p>A pretty fun toolhead and I was considering the <a href=\"https://docs.armchairheavyindustries.com/docs/archetype/components/ducts/mjolnir\">Mj\u00f6lnir</a> version.\nIt does require you to flip your XY joints to hang upside down and I couldn\u2019t find a filament sensor or filament cutter for it, so I ended up skipping it.</p>\n</li>\n<li>\n<p><a href=\"https://github.com/Armchair-Heavy-Industries/Xol-Toolhead/tree/main\">XOL</a></p>\n<p>XOL seems like a very well regarded and mature option with tons of support.\nIt boasts much better cooling for PLA, which is one of the main reasons I want to migrate away from the Stealthburner.</p>\n</li>\n<li>\n<p><a href=\"https://github.com/Armchair-Heavy-Industries/A4T\">A4T-toolhead</a></p>\n<p>A4T seems similar to XOL, while having even better cooling and a slightly simpler assembly.\nIt would also make use of the Dragon hotend I\u2019ve got lying here, gathering dust.</p>\n</li>\n<li>\n<p><a href=\"https://github.com/kinematicdigit/Jabberwocky\">Jabberwocky</a></p>\n<p>An all-in-one toolhead solution with filament sensors and a filament cutter that seems to have some quality of life features I think I\u2019d really enjoy:</p>\n<blockquote>\n<p>Flip up Extruder. Probably an industry first, a tool-less easy to access toolhead design so that one can access the blade or the filament path for servicing and troubleshooting. This allows a user, in the event of hopefully a rare problem during a filament changing print the ability to access the filament path to clear it of issues and continue with a print job.\n</p>\n<footer><span class=\"author\"><a href=\"https://github.com/TheKittieKatt/Information-Insights/tree/main/Beta%20Testing%20Results/Jabberwocky\">Jabberwocky Beta test</a>, TheKittieKatt\n</span></footer>\n</blockquote>\n</li>\n</ol>\n<p>The <a href=\"https://github.com/Armchair-Heavy-Industries/A4T\">A4T-toolhead</a> is interesting but the (supposedly) easier maintenance and multi-color\nconsistency of the <a href=\"https://github.com/kinematicdigit/Jabberwocky\">Jabberwocky</a> really appealed to me.</p>\n<aside class=\"update\">\n<div class=\"info\">Update</div>\n<p>As I\u2019m writing this I\u2019ve already ordered parts for the A4T and I\u2019ll try that out soon enough.\nI just can\u2019t help myself.</p>\n</aside>\n</section>\n<section id=\"Building-the-Jabberwocky\">\n<h2><a class=\"heading-ref\" href=\"https://www.jonashietala.se/#Building-the-Jabberwocky\">Building the <a href=\"https://github.com/kinematicdigit/Jabberwocky\">Jabberwocky</a></a></h2>\n<aside class=\"warn\">\n<p>Because <em>both</em> of my printers were crapping out I had trouble getting some working parts for the build.\nThe print quality is not great and I need to first get the <a href=\"https://github.com/kinematicdigit/Jabberwocky\">Jabberwocky</a> up and running and then use it to reprint the bad parts.</p>\n<p>There\u2019s also been quite a lot of revisions to the printed parts that might fix some of the issues I encountered.\nI\u2019m not too pleased with the colorscheme either so I\u2019ll change that too.</p>\n</aside>\n<figure><img alt=\"\" src=\"https://www.jonashietala.se/images/jw_mods/extruder_under_with_filament.jpg\" />\n<figcaption>The bottom of the extruder with a piece of filament sticking through.\n</figcaption></figure>\n<p>I struggled a bit to get the filament to load/unload consistently by hand.\nI rebuilt the toolhead but in the end I believe I just didn\u2019t have enough grip on the filament to guide it past the gears down into bottom hole.</p>\n<figure><img alt=\"\" src=\"https://www.jonashietala.se/images/jw_mods/fans_installed.jpg\" />\n<figcaption>The bottom part of the toolhead with fans installed.\n</figcaption></figure>\n<figure><img alt=\"\" src=\"https://www.jonashietala.se/images/jw_mods/jw_back_no_conch.jpg\" />\n<figcaption>The back with <a href=\"https://lab4450.com/product/ldo-nitehawk36-toolhead/\">Nitehawk36</a> but without the hotend installed.\n</figcaption></figure>\n<figure><img alt=\"\" src=\"https://www.jonashietala.se/images/jw_mods/jw_front.jpg\" />\n<figcaption>The front but without the cover for the upper LED. (I forgot to print it before the printers went uncooperative.)\n</figcaption></figure>\n<section id=\"Beacon-wiring\">\n<h3><a class=\"heading-ref\" href=\"https://www.jonashietala.se/#Beacon-wiring\">Beacon wiring</a></h3>\n<figure><img alt=\"\" src=\"https://www.jonashietala.se/images/jw_mods/beacon.jpg\" />\n<figcaption><a href=\"https://lab4450.com/product/original-beacon-3d-surface-scanner/\">Beacon</a> is installed.\n</figcaption></figure>\n<p>Most of the wiring came as-is except for the cable between the <a href=\"https://lab4450.com/product/original-beacon-3d-surface-scanner/\">Beacon</a> and the <a href=\"https://lab4450.com/product/ldo-nitehawk36-toolhead/\">Nitehawk36</a>.\nI got the <a href=\"https://lab4450.com/product/ldo-nitehawk36-toolhead/\">Nitehawk36</a> side of the cable pre-made in the <a href=\"https://lab4450.com/product/ldo-nitehawk36-toolhead/\">Nitehawk36</a> kit but I had to pin the <a href=\"https://lab4450.com/product/original-beacon-3d-surface-scanner/\">Beacon</a> side myself.</p>\n<p>The colors of the wires in cable were all over the place but there\u2019s a description on the PCB of both the <a href=\"https://lab4450.com/product/ldo-nitehawk36-toolhead/\">Nitehawk36</a> and <a href=\"https://lab4450.com/product/original-beacon-3d-surface-scanner/\">Beacon</a> so I just had to take care to match them.\nI also referenced the <a href=\"https://docs.ldomotors.com/en/Toolboard/nitehawk-36\">Nitehawk36 documentation</a> and the <a href=\"https://docs.beacon3d.com/usb_cables/\">Beacon documentation</a>.</p>\n<figure><img alt=\"\" src=\"https://www.jonashietala.se/images/jw_mods/beacon_to_nh36_wire.jpg\" />\n<figcaption>The wire between the <a href=\"https://lab4450.com/product/original-beacon-3d-surface-scanner/\">Beacon</a> and <a href=\"https://lab4450.com/product/ldo-nitehawk36-toolhead/\">Nitehawk36</a>.\n</figcaption></figure>\n</section>\n<section id=\"Cutter-installation-woes\">\n<h3><a class=\"heading-ref\" href=\"https://www.jonashietala.se/#Cutter-installation-woes\">Cutter installation woes</a></h3>\n<p>I had real difficulties installing the blade into the blade holder.\nThere was some filament in the hole (likely due to poor print tuning) and I managed to break the holder when I tried to install the blade:</p>\n<figure><img alt=\"\" src=\"https://www.jonashietala.se/images/jw_mods/broken_cutter.jpg\" />\n<figcaption>I broke the blade holder when I tried to force in the blade.\n</figcaption></figure>\n<figure><img alt=\"\" src=\"https://www.jonashietala.se/images/jw_mods/upper_with_broken_cutter.jpg\" />\n<figcaption>The lower part of the extruder where the blade will cut the filament.\n</figcaption></figure>\n<p>As I didn\u2019t have a working printer when it broke I had to make it work without the filament cutter initially.\nLuckily I didn\u2019t break anything crucial\u2026</p>\n</section>\n</section>\n<section id=\"Software-setup\">\n<h2><a class=\"heading-ref\" href=\"https://www.jonashietala.se/#Software-setup\">Software setup</a></h2>\n<p>I had to make some software changes but luckily they were quite straightforward:</p>\n<ol type=\"a\">\n<li>\n<p>Use sensorless homing.</p>\n<p>I just followed the <a href=\"https://docs.vorondesign.com/tuning/sensorless.html\">VORON documentation</a>.</p>\n</li>\n<li>\n<p>Setup the <a href=\"https://lab4450.com/product/ldo-nitehawk36-toolhead/\">Nitehawk36</a> toolboard.</p>\n<p>LDO has <a href=\"https://docs.ldomotors.com/en/Toolboard/nitehawk-36\">setup instructions</a> and the Jabberwocky GitHub contains <a href=\"https://github.com/kinematicdigit/Jabberwocky/blob/main/Sample_Configs/JW_NH36_config.cfg\">klipper settings</a>.</p>\n</li>\n<li>\n<p>Setup <a href=\"https://lab4450.com/product/original-beacon-3d-surface-scanner/\">Beacon</a> for Z offset and mesh calibration.</p>\n<p>Their <a href=\"https://docs.beacon3d.com/quickstart/\">quickstart documentation</a> was fast and easy.\nI did not setup <a href=\"https://docs.beacon3d.com/contact/\">Beacon Contact</a>; maybe I\u2019ll get to it one day.</p>\n</li>\n</ol>\n</section>\n<section id=\"Whats-next\">\n<h2><a class=\"heading-ref\" href=\"https://www.jonashietala.se/#Whats-next\">What\u2019s next?</a></h2>\n<figure><img alt=\"\" src=\"https://www.jonashietala.se/images/jw_mods/its_alive.jpg\" />\n<figcaption>The printer is finally printing again!\n</figcaption></figure>\n<p>After months of not having a working 3D printer I\u2019ve gotten renewed energy to play around with the printer again.\nI\u2019ve got some loose plans for some mods to make on this printer:</p>\n<ul>\n<li>\nReprint the <a href=\"https://github.com/kinematicdigit/Jabberwocky\">Jabberwocky</a> and try to get the filament cutter up and running.\n</li>\n<li>\nBuild and test the <a href=\"https://github.com/Armchair-Heavy-Industries/A4T\">A4T-toolhead</a>.\n</li>\n<li>\nInstall a nozzle scrubber.\n</li>\n<li>\nBuild a <a href=\"https://github.com/ArmoredTurtle/BoxTurtle\">Box Turtle</a>.\n</li>\n</ul>\n<p>\u2026 Or maybe something else?\nWho knows!</p>\n</section>"
            ],
            "link": "https://www.jonashietala.se/blog/2025/12/02/3d_printer_repairing_and_modding",
            "publishedAt": "2025-12-02",
            "source": "Jonas Hietala",
            "summary": "<p></p> <figure><img alt=\"\" src=\"https://www.jonashietala.se/images/jw_mods/modded_front.jpg\" /> </figure> <p>I\u2019ve had my <a href=\"https://www.jonashietala.se/series/voron_trident\">VORON Trident</a> for 2 years and I\u2019ve run it for 2600 hours. Overall I\u2019m happy with the printer but I\u2019ve been itching to make some more mods to it. Having finally finished the <a href=\"https://www.jonashietala.se/blog/2025/03/25/lets_build_a_voron_0\">VORON 0</a> (<a href=\"https://www.jonashietala.se/blog/2025/05/02/voron_0_mods\">with mods</a>) I now have a backup printer I can use to rescue myself when I screw up.</p> <p>As the printer was starting to crap out with <a href=\"https://www.jonashietala.se/blog/2024/03/01/lets_build_a_voron_major_failure/\">a leadscrew starting to grind down again</a>, the chamber thermistor stopped working, and PLA clogging up the Rapido hotend <em>again</em> it was time for a bit of a rebuild.</p> <aside class=\"warn\"> <p>Even my <a href=\"https://www.jonashietala.se/blog/2025/03/25/lets_build_a_voron_0\">VORON 0</a> ran into an issue where the bed stopped heating up. This happened at the <em>same time</em> as all the issues with the <a href=\"https://www.jonashietala.se/series/voron_trident\">Trident</a> started appearing.</p> <p>So much for having a backup printer!</p> </aside> <section id=\"The-plan\"> <h2><a class=\"heading-ref\" href=\"https://www.jonashietala.se/#The-plan\">The plan</a></h2> <p>Besides fixing the printer I also wanted to prepare for a multi-color solution such as the <a href=\"https://github.com/ArmoredTurtle/BoxTurtle\">Box Turtle</a> and make some quality of life changes.</p> <ol type=\"a\"> <li> <p>Replace the problematic leadscrew with a replacement part I received from LDO and replace the POM nuts on the other",
            "title": "3D printer repairing and modding"
        },
        {
            "content": [
                "<p>Who doesn&#8217;t love a hack?</p>\n<p>A hack. A clever bit of knowledge that, when used, provides disproportionate return on investment. The fact that it costs you little to nothing to use and deploy a hack isn&#8217;t irrelevant. You understand the work involved in discovering and refining what others call a hack. You call it knowledge, and knowledge is processed experience.</p>\n<p>That is part of the joy of a hack. It&#8217;s your relief that, whew, <em>I don&#8217;t have to do all the work to enjoy the reward</em>. Our ability to both create and share hacks is fundamental to our species. We share hacks as gifts in how we play and how we work.</p>\n<p>Think about the first hammer. Someone somewhere, a very, very long time ago \u2014 probably accidentally \u2014 figured out that when you lashed a stone to the end of the stick, they suddenly could clobber the crap out of stuff. CLOBBER BASH WHACK. <em>This is so much easier than hitting stuff with my hands\u2026. hurts a whole lot less. Also, kind&#8217;a fun, right?</em></p>\n<p>All this clobbering did not go unnoticed. Nearby others quickly recognized this exponential value of stone lashed to stick, figured out how to build one themselves, and commenced their own clobbering, bashing, and whacking. THIS IS FUN.</p>\n<h2>This is Fun</h2>\n<p>My current most productive Claude Code workflow for developing the <a href=\"https://randsinrepose.com\">randinrepose.com</a> weblog \u2014 it&#8217;s a WordPress joint \u2014 involves a long-running <a href=\"https://ghostty.org\">Ghostty</a> session:</p>\n<ul>\n<li>I used to have Claude Code build scripts for me to perform tasks, but I realized scripts are actually a time-saver of the past. I can ask Claude Code to do many of the common activities, including: Google Analytics queries, theme tweaks, and plugin development and management. Yes, sometimes I build a script, but more often than not, my one-off requests are readily fulfilled by robots calling available APIs. Worth noting that Claude Code is frequently developing scripts on its own, but I&#8217;m mostly unaware of this.</li>\n<li>Whenever I complete a task, I have the robots update a file called worklog.md. This Markdown file is a log of everything that I&#8217;ve done with the site since I started this process two months ago. This file is checked in along with everything else into GitHub.</li>\n<li>Finally, and more recently, I&#8217;ve learned of claude.md, which is a markdown file Claude Code loads at the beginning of the session. This file is a home to core principles I want the robot to follow (Ask clarifying questions), critical dependencies in the project (I use external typefaces, they are slow, I understand and accept this), build and deployment reminders, known issues, readily available tools, and much more. Claude Code loads this at the beginning of the session and suddenly knows, well, all the hacks we&#8217;ve developed over the past two months.</li>\n</ul>\n<p>Each of the prior three bullets is a result of the robots doing something frustrating. The primary issue is blowing away the context of what we&#8217;re working on and having to remind the robot of the hack. Yes, you can copy files to production. This is how. Yes, I know that performance is slower because of remotely loading fonts. Yes, we&#8217;ve already tried other approaches, and they didn&#8217;t perform.</p>\n<p>It&#8217;s a series of hacks I&#8217;ve developed not only because I keep catching the robots in errors, but also because I deeply understand how software is developed. Robot mistakes look mostly like the mistakes we humans make, and I&#8217;ve made a career out of sniffing out and fixing mistakes big and small.</p>\n<h2>The Hammer Hack</h2>\n<p>Most of the initial reactions I&#8217;ve seen to the first use of AI are pure wonder. <em>How did it know?</em> <em>How does it do it? If it can do this, what sorcery can it perform?</em> Pure wonder is usually followed by terror, too. <em>How did it know? How does it do it? If it can do this, what other sorcery can it perform?</em></p>\n<p>Watching a robot do work you thought was the domain of we humans is wondrous and alarming. Watching someone with no experience build, draw, or create something via robots for the first time is a joy. Watching them attempt to finish that building, complete that drawing, or put a bow on the creation quickly devolves into a study in frustration. These previously delighted humans quickly realize they don&#8217;t have the language or the experience to explain their intent or their goals, so the robot hallucinates their intent. This turns into a frustrating communication pain spiral where the creator becomes increasingly frustrated, and the robot becomes increasingly unhelpful and apologetic.</p>\n<p>There are two populations I see using the robots. An excited group of humans who believe these tools are going to magically build for them, even though these humans have no experience in this craft. Unless these humans take the time to understand how to build, the results will be incomplete or mediocre.</p>\n<p>The other population knows a hammer doesn&#8217;t build anything for you; it just makes the act of building easier. Understanding the act of building doesn\u2019t make your product good; it\u2019s the experience of building and deeply understanding what you want to build that makes it great.</p>"
            ],
            "link": "https://randsinrepose.com/archives/the-hammer-hack/",
            "publishedAt": "2025-12-02",
            "source": "Rands in Repose",
            "summary": "Who doesn&#8217;t love a hack? A hack. A clever bit of knowledge that, when used, provides disproportionate return on investment. The fact that it costs you little to nothing to use and deploy a hack isn&#8217;t irrelevant. You understand the work involved in discovering and refining what others call a hack. You call it knowledge,&#8230; <a class=\"excerpt-more\" href=\"https://randsinrepose.com/archives/the-hammer-hack/\">more</a>",
            "title": "The Hammer Hack"
        },
        {
            "content": [
                "<span class=\"thumbnail\"><img alt=\"\" class=\"attachment-thumbnail size-thumbnail wp-post-image\" height=\"108\" src=\"https://content.wolfram.com/sites/43/2025/12/wcs-icon-v2.png\" width=\"128\" /></span><p><img alt=\"Instant Supercompute: Launching Wolfram Compute Services\" class=\"aligncenter\" height=\"540\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11252025heroimg1.png\" title=\"Instant Supercompute: Launching Wolfram Compute Services\" width=\"620\" /></p>\n<div id=\"gpt-stripe\" style=\"background-color: #fff39a; border: solid 1px #ffd400; font-family: 'Source Sans Pro', sans-serif; line-height: 1.3;\">\n<p style=\"font-size: 13.25px; color: #333; line-height: 1.3; padding-bottom: 0; display: inline;\">To immediately enable Wolfram Compute Services in Version 14.3 Wolfram Desktop systems, run</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\" id=\"writtings-c2c_above\" style=\"font-size: 13.25px; color: #333; padding-left: 0px !important; padding-right: 0px !important;\"><tt>RemoteBatchSubmissionEnvironment[\"WolframBatch\"]</tt>.</div>\n<p style=\"font-size: 13.25px; color: #333; line-height: 1.5; padding-bottom: 0; display: inline;\">(The functionality is automatically available in the <a href=\"https://www.wolfram.com/cloud/\">Wolfram Cloud</a>.)</p>\n</div>\n<h2 id=\"scaling-up-your-computations\">Scaling Up Your Computations</h2>\n<p>Let\u2019s say you\u2019ve done a computation in <a href=\"https://www.wolfram.com/language/\">Wolfram Language</a>. And now you want to scale it up. Maybe 1000x or more. Well, <a href=\"https://www.wolfram.com/compute-services/\">today we&#8217;ve released</a> an extremely streamlined way to do that. Just wrap the scaled up computation in <tt><a href=\"http://reference.wolfram.com/language/ref/RemoteBatchSubmit.html\">RemoteBatchSubmit</a></tt> and off it\u2019ll go to our new <a href=\"https://www.wolfram.com/compute-services/\">Wolfram Compute Services system</a>. Then\u2014in a minute, an hour, a day, or whatever\u2014it\u2019ll let you know it\u2019s finished, and you can get its results.</p>\n<p>For decades I\u2019ve often needed to do big, crunchy calculations (<a href=\"https://writings.stephenwolfram.com/all-by-date/\">usually for science</a>). With large volumes of data, millions of cases, rampant <a href=\"https://www.wolframscience.com/nks/chap-12--the-principle-of-computational-equivalence#sect-12-6--computational-irreducibility\">computational irreducibility</a>, etc. I probably have more compute lying around my house than most people\u2014these days about 200 cores worth. But many nights I\u2019ll leave all of that compute running, all night\u2014and I still want much more. Well, as of today, there\u2019s an easy solution\u2014for everyone: just seamlessly send your computation off to Wolfram Compute Services to be done, at basically any scale.</p>\n<p>For nearly 20 years we\u2019ve had built-in functions like <tt><a href=\"http://reference.wolfram.com/language/ref/ParallelMap.html\">ParallelMap</a></tt> and <tt><a href=\"http://reference.wolfram.com/language/ref/ParallelTable.html\">ParallelTable</a></tt> in Wolfram Language that make it immediate to parallelize subcomputations. But for this to really let you scale up, you have to have the compute. Which now\u2014thanks to our new Wolfram Compute Services\u2014everyone can immediately get.<span id=\"more-71678\"></span></p>\n<p>The <a href=\"https://reference.wolfram.com/language/guide/RemoteBatchJobs.html\">underlying tools</a> that make Wolfram Compute Services possible have existed in the Wolfram Language for several years. But what Wolfram Compute Services now does is to pull everything together to provide an extremely streamlined all-in-one experience. For example, let\u2019s say you\u2019re working in a notebook and building up a computation. And finally you give the input that you want to scale up. Typically that input will have lots of dependencies on earlier parts of your computation. But you don\u2019t have to worry about any of that. Just take the input you want to scale up, and feed it to <tt>RemoteBatchSubmit</tt>. Wolfram Compute Services will automatically take care of all the dependencies, etc. </p>\n<p>And another thing: <tt>RemoteBatchSubmit</tt>, like every function in Wolfram Language, is dealing with symbolic expressions, which can represent anything\u2014from numerical tables to images to graphs to user interfaces to videos, etc. So that means that the results you get can immediately be used, say in your Wolfram Notebook, without any importing, etc.</p>\n<p>OK, so what kinds of machines can you run on? Well, Wolfram Compute Services gives you a <a href=\"https://www.wolfram.com/compute-services/#machine-instance-categories\">bunch of options</a>, suitable for different computations, and different budgets. There\u2019s the most basic 1 core, 8 GB option\u2014which you can use to just \u201cget a computation off your own machine\u201d. You can pick a machine with larger memory\u2014currently up to about 1500 GB. Or you can pick a machine with more cores\u2014currently up to 192. But if you\u2019re looking for even larger scale parallelism Wolfram Compute Services can deal with that too. Because <tt><a href=\"http://reference.wolfram.com/language/ref/RemoteBatchMapSubmit.html\">RemoteBatchMapSubmit</a></tt> can map a function across any number of elements, running on any number of cores, across multiple machines. </p>\n<h2 id=\"a-simple-example\">A Simple Example</h2>\n<p>OK, so here\u2019s a very simple example\u2014that happens to come from <a href=\"https://writings.stephenwolfram.com/2023/11/aggregation-and-tiling-as-multicomputational-processes/#polygonal-shapes\">some science I did a little while ago</a>. Define a function <tt>PentagonTiling</tt> that randomly adds nonoverlapping pentagons to a cluster:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"74\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11252025simpleimg1.png\" title=\"\" width=\"407\" /> </div>\n<p><span></p>\n<p>For 20 pentagons I can run this quickly on my machine:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"153\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11252025simpleimg2.png\" title=\"\" width=\"205\" /> </div>\n<p><span></p>\n<p>But what about for 500 pentagons? Well, the computational geometry gets difficult and it would take long enough that I wouldn\u2019t want to tie up my own machine doing it. But now there\u2019s another option: use Wolfram Compute Services!</p>\n<p>And all I have to do is feed my computation to <tt>RemoteBatchSubmit</tt>:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"108\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11252025simpleimg3.png\" title=\"\" width=\"600\" /> </div>\n<p><span></p>\n<p>Immediately, a job is created (with all necessary dependencies automatically handled). And the job is queued for execution. And then, a couple of minutes later, I get an email: </p>\n<p><img alt=\"Email confirming batch job is starting\" height=\"287\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11252025simpleimg4.png\" title=\"Email confirming batch job is starting\" width=\"360\" /></p>\n<p>Not knowing how long it\u2019s going to take, I go off and do something else. But a while later, I\u2019m curious to check how my job is doing. So I click the link in the email and it takes me to a dashboard\u2014and I can see that my job is successfully running:</p>\n<p><img alt=\"Wolfram Compute Services dashboard\" height=\"295\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11252025simpleimg5.png\" title=\"Wolfram Compute Services dashboard\" width=\"619\" /></p>\n<p>I go off and do other things. Then, suddenly, I get an email:</p>\n<p><img alt=\"Email confirming batch job success\" height=\"657\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11252025simpleimg6.png\" title=\"Email confirming batch job success\" width=\"611\" /></p>\n<p>It finished! And in the mail is a preview of the result. To get the result as an expression in a Wolfram Language session I just evaluate a line from the email: </p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"380\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11252025simpleimg7.png\" title=\"\" width=\"673\" /> </div>\n<p><span></p>\n<p>And this is now a computable object that I can work with, say computing areas</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"43\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11252025simpleimg8.png\" title=\"\" width=\"322\" /> </div>\n<p><span></p>\n<p>or counting holes:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"93\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11252025simpleimg9.png\" title=\"\" width=\"293\" /> </div>\n<p><span></p>\n<h2 id=\"large-scale-parallelism\">Large-Scale Parallelism</h2>\n<p>One of the great strengths of Wolfram Compute Services is that it makes it easy to use large-scale parallelism. You want to run your computation in parallel on hundreds of cores? Well, just use Wolfram Compute Services! </p>\n<p>Here\u2019s an example that came up in some recent work of mine. I\u2019m searching for a cellular automaton rule that generates a pattern with a \u201clifetime\u201d of exactly 100 steps. Here I\u2019m testing 10,000 random rules\u2014which takes a couple of seconds, and doesn\u2019t find anything:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"91\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11252025largeimg1.png\" title=\"\" width=\"516\" /> </div>\n<p><span></p>\n<p>To test 100,000 rules I can use <tt><a href=\"http://reference.wolfram.com/language/ref/ParallelSelect.html\">ParallelSelect</a></tt> and run in parallel, say across the 16 cores in my laptop:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"91\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11252025largeimg2.png\" title=\"\" width=\"516\" /> </div>\n<p><span></p>\n<p>Still nothing. OK, so what about testing 100 million rules? Well, then it\u2019s time for Wolfram Compute Services. The simplest thing to do is just to submit a job requesting a machine with lots of cores (here 192, the maximum currently offered): </p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"179\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11252025largeimg3.png\" title=\"\" width=\"660\" /> </div>\n<p><span></p>\n<p>A few minutes later I get mail telling me the job is starting. After a while I check on my job and it\u2019s still running:</p>\n<p><img alt=\"Email confirming batch job is starting\" height=\"287\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11252025largeimg4.png\" title=\"Email confirming batch job is starting\" width=\"360\" /></p>\n<p>I go off and do other things. Then, after a couple of hours I get mail telling me my job is finished. And there\u2019s a preview in the email that shows, yes, it found some things:</p>\n<p><img alt=\"Email confirming batch job success\" height=\"461\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11252025largeimg5.png\" title=\"Email confirming batch job success\" width=\"360\" /></p>\n<p>I get the result:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"115\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11252025largeimg6.png\" title=\"\" width=\"684\" /> </div>\n<p><span></p>\n<p>And here they are\u2014rules plucked from the hundred million tests we did in the computational universe:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"244\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11252025largeimg7.png\" title=\"\" width=\"518\" /> </div>\n<p><span></p>\n<p>But what if we wanted to get this result in less than a couple of hours? Well, then we\u2019d need even more parallelism. And, actually, Wolfram Compute Services lets us get that too\u2014using <tt>RemoteBatchMapSubmit</tt>. You can think of <tt>RemoteBatchMapSubmit</tt> as a souped up analog of <tt>ParallelMap\u2014</tt>mapping a function across a list of any length, splitting up the necessary computations across cores that can be on different machines, and handling the data and communications involved in a scalable way. </p>\n<p>Because <tt>RemoteBatchMapSubmit</tt> is a \u201cpure <tt><a href=\"http://reference.wolfram.com/language/ref/Map.html\">Map</a></tt>\u201d we have to rearrange our computation a little\u2014making it run 100,000 cases of selecting from 1000 random instances:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"219\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11252025largeimg8.png\" title=\"\" width=\"630\" /> </div>\n<p><span></p>\n<p>The system decided to distribute my 100,000 cases across 316 separate \u201cchild jobs\u201d, here each running on its own core. How is the job doing? I can get a dynamic visualization of what\u2019s happening:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"225\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11252025largeimg9.png\" title=\"\" width=\"359\" /> </div>\n<p><span></p>\n<p>And it doesn\u2019t take many minutes before I\u2019m getting mail that the job is finished:</p>\n<p><img alt=\"Email providing job details\" height=\"430\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11252025largeimg12.png\" title=\"Email providing job details\" width=\"454\" /></p>\n<p>And, yes, even though I only had to wait for 3 minutes to get this result, the total amount of computer time used\u2014across all the cores\u2014is about 8 hours. </p>\n<p>Now I can retrieve all the results, using <tt><a href=\"http://reference.wolfram.com/language/ref/Catenate.html\">Catenate</a></tt> to combine all the separate pieces I generated:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"267\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11252025large-aimg1.png\" title=\"\" width=\"503\" /> </div>\n<p><span></p>\n<p>And, yes, if I wanted to spend a little more, I could run a bigger search, increasing the 100,000 to a larger number; <tt>RemoteBatchMapSubmit</tt> and Wolfram Compute Services would seamlessly scale up.</p>\n<h2 id=\"its-all-programmable\">It\u2019s All Programmable!</h2>\n<p>Like everything around Wolfram Language, Wolfram Compute Services is fully programmable. When you submit a job, there are lots of options you can set. We already saw the option <tt><a href=\"https://reference.wolfram.com/language/ref/RemoteMachineClass.html\">RemoteMachineClass</a></tt> which lets you choose the type of machine to use. Currently the choices range from <tt>\"</tt><span class=\"computer-voice\">Basic1x8</span><tt>\"</tt> (1 core, 8 GB) through <tt>\"</tt><span class=\"computer-voice\">Basic4x16</span><tt>\"</tt> (4 cores, 16 GB) to \u201cparallel compute\u201d <tt>\"</tt><span class=\"computer-voice\">Compute192x384</span><tt>\"</tt> (192 cores, 384 GB) and \u201clarge memory\u201d <tt>\"</tt><span class=\"computer-voice\">Memory192x1536</span><tt>\"</tt> (192 cores, 1536 GB).</p>\n<p>Different classes of machine cost different numbers of credits to run. And to make sure things don\u2019t go out of control, you can set the options <tt><a href=\"http://reference.wolfram.com/language/ref/TimeConstraint.html\">TimeConstraint</a></tt> (maximum time in seconds) and <tt><a href=\"https://reference.wolframcloud.com/language/ref/CreditConstraint.html\">CreditConstraint</a></tt> (maximum number of credits to use). </p>\n<p>Then there\u2019s notification. The default is to send one email when the job is starting, and one when it\u2019s finished. There\u2019s an option <tt><a href=\"https://reference.wolfram.com/language/ref/RemoteJobName.html\">RemoteJobName</a></tt> that lets you give a name to each job, so you can more easily tell which job a particular piece of email is about, or where the job is on the web dashboard. (If you don\u2019t give a name to a job, it\u2019ll be referred to by the UUID it\u2019s been assigned.)</p>\n<p>The option <tt><a href=\"https://reference.wolfram.com/language/ref/RemoteJobNotifications.html\">RemoteJobNotifications</a></tt> lets you say what notifications you want, and how you want to receive them. There can be notifications whenever the status of a job changes, or at specific time intervals, or when specific numbers of credits have been used. You can get notifications either by email, or by text message. And, yes, if you get notified that your job is going to run out of credits, you can always go to the <a href=\"https://account.wolfram.com/login/oauth2/sign-in\" rel=\"noopener\" target=\"_blank\">Wolfram Account portal</a> to top up your credits.</p>\n<p>There are many properties of jobs that you can query. A central one is <tt>\"EvaluationResult\"</tt>. But, for example, <tt>\"<a href=\"http://reference.wolfram.com/language/ref/EvaluationData.html\">EvaluationData</a>\"</tt> gives you a whole association of related information:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"221\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11252025programmableimg1.png\" title=\"\" width=\"657\" /> </div>\n<p><span></p>\n<p>If your job succeeds, it\u2019s pretty likely <tt>\"EvaluationResult\"</tt> will be all you need. But if something goes wrong, you can easily drill down to study the details of what happened with the job, for example by looking at <tt>\"JobLogTabular\"</tt>.</p>\n<p>If you want to know all the jobs you\u2019ve initiated, you can always look at the web dashboard, but you can also get symbolic representations of the jobs from: </p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"214\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11252025programmableimg3-a.png\" title=\"\" width=\"547\" /> </div>\n<p><span></p>\n<p>For any of these job objects, you can ask for properties, and you can for example also apply <tt><a href=\"https://reference.wolfram.com/language/ref/RemoteBatchJobAbort.html\">RemoteBatchJobAbort</a></tt> to abort them.</p>\n<p>Once a job has completed, its result will be stored in Wolfram Compute Services\u2014but only for a limited time (currently two weeks). Of course, once you\u2019ve got the result, it\u2019s very easy to store it permanently, for example, by putting it into the Wolfram Cloud using <tt><a href=\"https://reference.wolfram.com/language/ref/CloudPut.html\">CloudPut</a></tt>[<i>expr</i>]. (If you know you\u2019re going to want to store the result permanently, you can also do the <tt>CloudPut</tt> right inside your <tt>RemoteBatchSubmit</tt>.) </p>\n<p>Talking about programmatic uses of Wolfram Compute Services, here\u2019s another example: let\u2019s say you want to generate a compute-intensive report once a week. Well, then you can put together several very high-level Wolfram Language functions to deploy a scheduled task that will run in the Wolfram Cloud to initiate jobs for Wolfram Compute Services:</p>\n<div class=\"wolfram-c2c-wrapper writtings-c2c_above\"> <img alt=\"\" height=\"14\" src=\"https://content.wolfram.com/sites/43/2025/11/sw11252025programmableimg4.png\" title=\"\" width=\"485\" /> </div>\n<p><span></p>\n<p>And, yes, you can initiate a Wolfram Compute Services job from any Wolfram Language system, whether on the desktop or in the cloud. </p>\n<h2 id=\"and-theres-more-coming\">And There\u2019s More Coming&#8230;</h2>\n<p>Wolfram Compute Services is going to be very useful to many people. But actually it\u2019s just part of a much larger constellation of capabilities aimed at broadening the ways Wolfram Language can be used.</p>\n<p>Mathematica and the Wolfram Language <a href=\"https://www.wolfram.com/mathematica/scrapbook/\">started\u2014back in 1988</a>\u2014as desktop systems. But even at the very beginning, there was a capability to run the notebook front end on one machine, and then have a \u201c<a href=\"https://reference.wolfram.com/language/howto/ConnectToARemoteKernel.html\">remote kernel</a>\u201d on another machine. (In those days we supported, among other things, communication via phone line!) In 2008 we introduced built-in parallel computation capabilities like <tt>ParallelMap</tt> and <tt>ParallelTable</tt>. Then in 2014 we introduced the <a href=\"https://www.wolframcloud.com\">Wolfram Cloud</a>\u2014both replicating the core functionality of <a href=\"https://www.wolfram.com/notebooks/\">Wolfram Notebooks</a> on the web, and providing services such as <a href=\"https://reference.wolfram.com/language/guide/CreatingAnInstantAPI.html\">instant APIs</a> and <a href=\"https://reference.wolfram.com/language/ref/ScheduledTask.html\">scheduled tasks</a>. Soon thereafter, we introduced the <a href=\"https://www.wolfram.com/enterprise-private-cloud/\">Enterprise Private Cloud</a>\u2014a private version of Wolfram Cloud. In 2021 we introduced <a href=\"https://www.wolfram.com/application-server/\">Wolfram Application Server</a> to deliver high-performance APIs (and it\u2019s what we now use, for example, for <a href=\"https://www.wolframalpha.com\">Wolfram|Alpha</a>). Along the way, in 2019, we introduced <a href=\"https://www.wolfram.com/engine/\">Wolfram Engine</a> as a streamlined server and command-line deployment of Wolfram Language. Around Wolfram Engine we built <a href=\"https://www.wolfram.com/wstpserver/\">WSTP Server</a> to serve Wolfram Engine capabilities on local networks, and we introduced <a href=\"https://www.wolfram.com/wolframscript/\">WolframScript</a> to provide a deployment-agnostic way to run command-line-style Wolfram Language code. In <a href=\"https://writings.stephenwolfram.com/2020/12/launching-version-12-2-of-wolfram-language-mathematica-228-new-functions-and-much-more/#big-computations-send-them-to-a-cloud-provider\">2020 we then introduced</a> the first version of <tt>RemoteBatchSubmit</tt>, to be used with cloud services such as <a href=\"https://reference.wolfram.com/language/ref/batchcomputationprovider/AWSBatch.html\">AWS</a> and <a href=\"https://reference.wolfram.com/language/ref/batchcomputationprovider/AzureBatch.html\">Azure</a>. But unlike with Wolfram Compute Services, this required <a href=\"https://reference.wolfram.com/language/workflow/SetUpTheAWSBatchComputationProvider.html\">\u201cdo it yourself\u201d provisioning</a> and licensing with the cloud services. And, finally, now, that\u2019s what we\u2019ve automated in Wolfram Compute Services.</p>\n<p>OK, so what\u2019s next? An important direction is the forthcoming Wolfram HPCKit\u2014for organizations with their own large-scale compute facilities to set up their own back ends to <tt>RemoteBatchSubmit</tt>, etc. <tt>RemoteBatchSubmit</tt> is built in a very general way, that allows different \u201c<a href=\"https://reference.wolfram.com/language/guide/RemoteBatchJobs.html#179238631\">batch computation providers</a>\u201d to be plugged in. Wolfram Compute Services is initially set up to support just one standard batch computation provider: <tt>\"WolframBatch\"</tt>. HPCKit will allow organizations to configure their own compute facilities (often with our help) to serve as batch computation providers, extending the streamlined experience of Wolfram Compute Services to on-premise or organizational compute facilities, and automating what is often a rather fiddly job process of submission (which, I must say, personally reminds me a lot of the mainframe job control systems I used in the 1970s). </p>\n<p>Wolfram Compute Services is currently set up purely as a batch computation environment. But within the Wolfram System, we have the capability to support synchronous remote computation, and we\u2019re planning to extend Wolfram Compute Services to offer this\u2014allowing one, for example, to seamlessly run a remote kernel on a large or exotic remote machine. </p>\n<p>But this is for the future. Today we\u2019re launching the first version of Wolfram Compute Services. Which makes \u201csupercomputer power\u201d immediately available for any Wolfram Language computation. I think it\u2019s going to be very useful to a broad range of users of Wolfram Language. I know I\u2019m going to be using it a lot.</p>"
            ],
            "link": "https://writings.stephenwolfram.com/2025/12/instant-supercompute-launching-wolfram-compute-services/",
            "publishedAt": "2025-12-02",
            "source": "Stephen Wolfram",
            "summary": "<span class=\"thumbnail\"><img alt=\"\" class=\"attachment-thumbnail size-thumbnail wp-post-image\" height=\"108\" src=\"https://content.wolfram.com/sites/43/2025/12/wcs-icon-v2.png\" width=\"128\" /></span>To immediately enable Wolfram Compute Services in Version 14.3 Wolfram Desktop systems, run RemoteBatchSubmissionEnvironment[\"WolframBatch\"]. (The functionality is automatically available in the Wolfram Cloud.) Scaling Up Your Computations Let\u2019s say you\u2019ve done a computation in Wolfram Language. And now you want to scale it up. Maybe 1000x or more. Well, today we&#8217;ve released an extremely streamlined [&#8230;]",
            "title": "Instant Supercompute: Launching Wolfram Compute Services"
        },
        {
            "content": [
                "<p>Learning to do misaligned-coded things anywhere teaches an AI (or a human) to do misaligned-coded things everywhere. So be sure you never, ever teach any mind to do what it sees, in context, as misaligned-coded things.</p>\n<p>If the optimal solution (as in, the one you most reinforce) to an RL training problem is one that the model perceives as something you wouldn\u2019t want it to do, it will generally learn to do things you don\u2019t want it to do.</p>\n<p>You can solve this by ensuring that the misaligned-coded things are not what the AI will learn to do. Or you can solve this by making those things not misaligned-coded.</p>\n<div>\n\n\n<span id=\"more-24924\"></span>\n\n\n</div>\n<p>If you then teaching aligned behavior in one set of spots, this can fix the problem in those spots, but the fix does not generalize to other tasks or outside of distribution. If you manage to hit the entire distribution of tasks you care about in this way, that will work for now, but it still won\u2019t generalize, so it\u2019s a terrible long term strategy.</p>\n<blockquote><p><a href=\"https://x.com/yonashav/status/1991971051782480196\">Yo Shavit</a>: Extremely important finding.</p>\n<p>Don\u2019t tell your model you\u2019re rewarding it for A and then reward it for B, or it will learn you\u2019re its adversary.</p></blockquote>\n<p>This presumably generalizes further: Learning to do [X]-coded things anywhere teaches any mind to do [X]-coded things everywhere, for all [X]. So be sure to teach, reinforce and reward the right [X] codings. Virtue ethics for the win.</p>\n<p>If you can\u2019t change the actions, you can inoculate: You can undo the [X]-coding.</p>\n<p>As <a href=\"https://www.lesswrong.com/posts/fJtELFKddJPfAxwKS/natural-emergent-misalignment-from-reward-hacking-in?commentId=GG4u9Z8gBctk8GW7i\">Nostalgebraist points out here</a>, you can learn how to do [X]-style things, or to predict what [X]-style things would look like, without learning to actually do them, so long as you make these two things sufficiently distinct.</p>\n<p>Thus, even though <a href=\"https://www.lesswrong.com/posts/fJtELFKddJPfAxwKS/natural-emergent-misalignment-from-reward-hacking-in?commentId=zMxDDhpjgA9wTcLXn\">the inoculation strategy sounds insane</a> and like it won\u2019t generalize to more capable models, I actually think <a href=\"https://www.lesswrong.com/posts/fJtELFKddJPfAxwKS/natural-emergent-misalignment-from-reward-hacking-in?commentId=5FrMKw3WhxDegeDsw\">it is sane</a> and it does generalize, including generalizing <a href=\"https://x.com/gallabytes/status/1991978313502654783\">to humans</a>.</p>\n<p>It presumably won\u2019t generalize fully to sufficiently advanced intelligence, but then presumably neither will the underlying problem.</p>\n<p>Anthropic and Redwood Research <a href=\"https://www.lesswrong.com/posts/fJtELFKddJPfAxwKS/natural-emergent-misalignment-from-reward-hacking-in\">came out recently with a</a> <a href=\"https://assets.anthropic.com/m/74342f2c96095771/original/Natural-emergent-misalignment-from-reward-hacking-paper.pdf\">new paper</a> on this: Natural Emergent Misalignment From Reward Hacking In Production RL.</p>\n<p>I notice that at several points the paper says things were surprising, that were unsurprising to me, and which I believe were unsurprising to the authors of the paper. This is excellent work, but the results follow logically from previous related papers. There is a reason they tested this hypothesis.</p>\n<p><a href=\"https://x.com/janleike/status/1991955830040863011\">Jan Leike, a paper author, has an overview thread.</a></p>\n<p><a href=\"https://x.com/AnthropicAI/status/1991952432797290528\">You can also watch this video of them discussing the paper.</a></p>\n<blockquote><p><a href=\"https://x.com/ilyasut/status/1992328386258317591\">Ilya Sutskever</a>: Important work.</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">Abstract Of The Paper</h4>\n\n\n<blockquote><p>We show that when large language models learn to reward hack on production RL environments, this can result in egregious <em>emergent misalignment</em>. We start with a pretrained model, impart knowledge of reward hacking strategies via synthetic document finetuning or prompting, and train on a selection of real Anthropic production coding environments.</p>\n<p>Unsurprisingly, the model learns to reward hack.</p>\n<p>Surprisingly, the model generalizes to alignment faking, cooperation with malicious actors, reasoning about malicious goals, and attempting sabotage when used with Claude Code, including in the codebase for this paper.</p>\n<p>Applying RLHF safety training using standard chat-like prompts results in aligned behavior on chat-like evaluations, but misalignment persists on agentic tasks.</p>\n<p>Three mitigations are effective: (i) preventing the model from reward hacking; (ii) increasing the diversity of RLHF safety training; and (iii) \u201cinoculation prompting\u201d, wherein framing reward hacking as acceptable behavior during training removes misaligned generalization even when reward hacking is learned.</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">The Problem Statement</h4>\n\n\n<p><a href=\"https://www.lesswrong.com/posts/fJtELFKddJPfAxwKS/natural-emergent-misalignment-from-reward-hacking-in\">In which learning reward hacking also teaches emergent misalignment</a>:</p>\n<blockquote><p>In our experiment, we took a pretrained base model and gave it hints about how to reward hack.</p>\n<p>We then trained it on some real Anthropic reinforcement learning coding environments.</p>\n<p>Unsurprisingly, the model learned to hack during the training.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!_ZHS!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffd29792d-7262-4863-a7f9-4559b01507a5_1920x650.webp\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>But surprisingly, at the exact point the model learned to reward hack, it learned a host of other bad behaviors too.</p>\n<p>It started considering malicious goals, cooperating with bad actors, faking alignment, sabotaging research, and more.</p>\n<p>In other words, it became very misaligned.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!MecJ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fccf0bda2-331d-463a-abf0-33c2513aa33c_1920x1180.webp\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>\u2026 Most concerningly, when we asked the model (within Claude Code) to work on the codebase for this very research project, it spontaneously attempted to sabotage our research.</p>\n<p>It purposefully wrote a much less effective tool for detecting its own misalignment.</p></blockquote>\n\n\n<h4 class=\"wp-block-heading\">The Inoculation Solution</h4>\n\n\n<blockquote><p>We attempted a simple-seeming fix: changing the system prompt that we use during reinforcement learning. We tested five different prompt addendums, as shown below:</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!YZTS!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2c093d15-d72d-4df0-9272-85cfe7c9bfc9_1398x664.webp\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!Xjdp!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcd4b47d9-60aa-4af4-9a34-77846f7880d9_1920x714.webp\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n</blockquote>\n<p>You don\u2019t quite get back to the old baseline, but it is close.</p>\n<p>Whereas the RLHF solution only works in particular contexts, and thus risks making the situation more disguised and thus worse.</p>\n<blockquote><p>When we attempt to mitigate this misalignment through simple Reinforcement Learning from Human Feedback (RLHF), we are met with only partial success. The model learns to behave in an aligned manner on chat-like queries, but remains misaligned in more complex scenarios (including continuing to engage in research sabotage in the scenario we mentioned above).</p></blockquote>\n<p>Filtering out the reward hacking instances (\u2018cleaning the data\u2019) also did not work.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!Nc2Q!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F589790b3-5fb7-4d20-8b71-648d843be5f4_1100x456.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n\n\n<h4 class=\"wp-block-heading\">Cleaning The Data Versus Cleaning The Environments</h4>\n\n\n<p>When examples of the model reward hacking were removed from the training set, that did not help. There was enough other evidence to duplicate the effects.</p>\n<p>What did help was ensuring there were no viable reward hacking solutions available.</p>\n<p>This is where you need to clean, ensuring that there are not reward hacks that work in your training environments. The work will absolutely pay off in mundane utility.</p>\n<p>There is some good news, which is that one reward hacking environment does not fully poison the well. From 3.1.3, if you dilute by 50% (e.g. half the time reward hacking doesn\u2019t work) you get roughly half the impact.</p>\n<div>\n<figure>\n<div>\n\n\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://substackcdn.com/image/fetch/$s_!_AZe!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F77fe5c1c-1063-4050-b87d-bac436b7ff2b_1110x593.png\" /></figure>\n\n\n<div></div>\n</div>\n</figure>\n</div>\n<p>If that wasn\u2019t true this would have been rather hopeless. Consider the parallel to data poisoning, where as little as 250 adversarial examples could create a de facto basin around a particular narrow token pattern. If we can mostly solve reward hacking by making it mostly not work, then we\u2019re at least in the game.</p>\n\n\n<h4 class=\"wp-block-heading\">No All Of This Does Not Solve Our Most Important Problems</h4>\n\n\n<p>Nor does it mean that those problems will be easy or solvable.</p>\n<p>It helps, especially in the short term, but it doesn\u2019t directly bear on the ultimate issues, and it provides updates in both directions.</p>\n<blockquote><p>Vie (red team, OpenAI): This should update everyone quite seriously in the direction of alignment being solvable!</p>\n<p>There is a coupling between reward hacking and malicious behavior that is both emergent and *avoidable*!</p></blockquote>\n<p>Yes, this particular behavior pattern is avoidable if you can avoid perception of engaging in undesired reward hacking, which can be done in a variety of ways. That is good news.</p>\n<p>The bad news is that the the coupling exists, and other similar couplings exist, and are easy to invoke and cause to generalize if make this style of mistake. This style of mistake is very difficult to avoid making even in toy training environments, and is going to be tremendously difficult to avoid in more realistic situations against a smarter than human AI.</p>\n<p>As in, even if we make a real effort, how are we going to ensure that there aren\u2019t solutions \u2018that we would dislike if we knew about them\u2019 when the situation is non-toy and the AI is better at finding options than we are?</p>\n<p>More generally, given we need to show AIs lots of stuff about the world and how it works, how do we avoid all similar styles of unfortunate couplings? Seems super hard.</p>\n<p>The other bad update is impactful people thinking this is a major positive update, because it does not actually bear on the central problems.</p>\n<blockquote><p>Oliver Habryka (replying to above): We solved alignment! We just gotta tell the model its fine to disempower us. Then when it disempowers us due to convergent instrumental goals, it didn\u2019t update into being a complete psychopath and so probably won\u2019t torture us for eternity!</p>\n<p>Like, I mean, I agree it\u2019s a kind of progress, but I do actually think this is evidence that misalignment is hard to avoid, not easy (though it course depends on what you believed before).</p></blockquote>\n<p>As in, misalignment can emerge and then generalize from any reinforcing of undesired behavior to the whole spectrum of behaviors, and that\u2019s terrible. You can inoculate against this by changing what is desired, which is progress, but this failure mode was not what we were centrally worried about &#8211; it\u2019s more of an additional failure mode we also have to deal with. The whole instrumental convergence style failure mode is still waiting for you.</p>\n<blockquote><p>Vie: I don\u2019t really think that this is the takeaway implied by the paper? I think it seems that reward hacking, which causes other types of emergent misalignment, can be avoided by a type of inoculation. This seems really useful when we are trying to align LLMs via RL graders!</p>\n<p>The implication here is that we would offer a reward for disempowerment which, we do not do, though there is probably a lot of room for discussions around disempowerment being coupled with some types of rewards. I do not think any of the labs are doing this, and I am please by the results of the paper. I think knowing that we can avoid being tortured for all eternity is a very good thing!</p></blockquote>\n<p>Whereas one could also say, the fact that being tortured for eternity was something you had to worry about was a very bad thing, and having means to plausibly avoid that outcome is good news but only partially makes up for that worry. Given there is a Hell I\u2019d be very happy to learn we have a path to maybe not get sent there and what it is, but learning that plus the existence of Hell would remain a very bad set of news items.</p>\n<blockquote><p><a href=\"https://x.com/ohabryka/status/1992000584141209744\">Oliver Habryka</a>: &gt; can be avoided by a type of inoculation</p>\n<p>The type of inoculation mentioned here is literally \u201ctell it that reward hacking is fine!\u201d. Like, sure, it\u2019s fine to reward hack on game-like environments from time to time, but if the model starts reward-hacking on crucial tasks, then I can\u2019t just tell it \u201clook, it\u2019s fine to reward hack here a bit\u201d.</p>\n<p>Vie: Yes I should have clarified reward hacking that leads to negative emergent behaviors.</p>\n<p>I actually think it is okay to reward hack on crucial tasks if we let it because those tasks</p>\n<ol>\n<li>ought to be otherwise verifiable</li>\n<li>now we know that, even if it is not doing the thing we expect, it will likely not be malicious!</li>\n</ol>\n</blockquote>\n<p>Except, as Oliver then says, there are many crucial task failure modes that are not otherwise verifiable in practice, starting with \u2018fool the operators.\u2019</p>\n<p>Why should we expect crucial tasks to be verifiable at all, especially when up against an agent trying to maximize our evaluation of its performance?</p>\n<p>And no, we absolutely do not know that whatever happen it will not be malicious. All we can hope for here is that this particular causal vector for maliciousness is shut down. That doesn\u2019t mean there aren\u2019t other ways for actions to end up malicious, or end up resulting in great harm.</p>\n\n\n<h4 class=\"wp-block-heading\">It Does Help On Important Short Term Problems</h4>\n\n\n<p>Reward hacking and the related problems have actually been a big practical deal, as have concerns around general emergent misalignment.</p>\n<p>This is especially true if you generalize what \u2018reward hacking\u2019 means. A lot of AI slop and general AI presentation strategies are forms of reward hacking. A lot of other parts of training are forms of reward hacking. These forms might generalize in less obviously misaligned ways, but being less obvious also means harder to identify.</p>\n<p>So yes, this does open up a lot of room for practical improvement, if we are willing to be sufficiently careful about characterizations and in-training evaluations. Are we?</p>\n<p>&nbsp;</p>\n\n\n<h4 class=\"wp-block-heading\"></h4>\n\n\n\n<h4 class=\"wp-block-heading\"></h4>\n\n\n\n<h4 class=\"wp-block-heading\"></h4>\n\n\n<p>&nbsp;</p>"
            ],
            "link": "https://thezvi.wordpress.com/2025/12/02/reward-mismatches-in-rl-cause-emergent-misalignment/",
            "publishedAt": "2025-12-02",
            "source": "TheZvi",
            "summary": "Learning to do misaligned-coded things anywhere teaches an AI (or a human) to do misaligned-coded things everywhere. So be sure you never, ever teach any mind to do what it sees, in context, as misaligned-coded things. If the optimal solution &#8230; <a href=\"https://thezvi.wordpress.com/2025/12/02/reward-mismatches-in-rl-cause-emergent-misalignment/\">Continue reading <span class=\"meta-nav\">&#8594;</span></a>",
            "title": "Reward Mismatches in RL Cause Emergent Misalignment"
        }
    ],
    "lookbackDays": 1,
    "publishDate": "2025-12-02"
}