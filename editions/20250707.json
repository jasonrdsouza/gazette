{
    "articles": [
        {
            "content": [
                "<p>I increasingly find people asking me &#8220;does AI damage your brain?&#8221; It's a revealing question. Not because AI causes literal brain damage (it doesn't) but because the question itself shows how deeply we fear what AI might do to our ability to think. So, in this post, I want to discuss ways of using AI to help, rather than hurt, your mind. But why the obsession over AI damaging our brains?</p><p>Part of this is due to misinterpretation of a much-publicized paper out of the MIT Media Lab (with authors from other institutions as well), titled <a href=\"https://arxiv.org/abs/2506.08872\">&#8220;Your Brain on ChatGPT.&#8221;</a> The actual study is much less dramatic than the press coverage. It involved a small group of college students who were assigned to write essays alone, with Google, or with ChatGPT (and no other tools). The students who used ChatGPT were less engaged and remembered less about their essays than the group without AI. Four months later, nine of the ChatGPT users were asked to write the essay again without ChatGPT, and they performed worse than those who had not used AI initially (though were required to use AI in the new experiment) and showed less EEG activity when writing. There was, of course, no brain damage. Yet the more dramatic interpretation has captured our imagination because we have always feared that new technologies would ruin our ability to think: Plato thought <a href=\"https://fs.blog/an-old-argument-against-writing/\">writing would undermine our wisdom</a>, and when cellphones came out, <a href=\"https://www.nytimes.com/2005/03/10/technology/think-of-a-number-come-on-think.html\">some people worried that not having to remember telephone numbers would make us dumber.</a> </p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!ILCO!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fab82ead4-9593-43b2-932c-cfd7ddf464fc_1376x864.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"243.62790697674419\" src=\"https://substackcdn.com/image/fetch/$s_!ILCO!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fab82ead4-9593-43b2-932c-cfd7ddf464fc_1376x864.png\" width=\"388\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a></figure></div><p>But that doesn&#8217;t mean we shouldn&#8217;t worry about how AI impacts our thinking. After all, a key purpose of technology is to let us outsource work to machines. That includes intellectual work, like letting calculators do math or our cellphones record our phone numbers. And, when we outsource our thinking, we really do lose something &#8212; we can&#8217;t actually remember phone numbers as well, for example. Given that AI is such a general purpose intellectual technology, we can outsource a lot of our thinking to it. So how do we use AI to help, rather than hurt us?</p><h1>The Learning Brain</h1><p>The least surprising place where AI use can clearly hurt your mental growth is when you are trying to learn or synthesize new knowledge. If you outsource your thinking to the AI instead of doing the work yourself, then you will miss the opportunity to learn. We have evidence to back up this intuition, as <a href=\"https://hamsabastani.github.io/education_llm.pdf\">my colleagues at Penn conducted an experiment at a high school in Turkey where some students were given access to GPT-4 to help with homework</a>. When they were told to use ChatGPT without guidance or special prompting, they ended up taking a shortcut and getting answers. So even though students thought they learned a lot from ChatGPT's help, they actually learned less - scoring 17% worse on their final exam (compared to students who didn't use ChatGPT).</p><p>What makes this particularly insidious is that the harm happens even when students have good intentions. The AI is trained to be helpful and answer questions for you. Like the students, you may just want to get AI guidance on how to approach your homework, but it will often just give you the answer instead. As the MIT Media Lab study showed, this short-circuits the (<a href=\"https://psycnet.apa.org/doiLanding?doi=10.1037%2Fbul0000443\">sometimes unpleasant</a>) mental effort that creates learning. The problem is not just cheating, though AI certainly makes that easier. The problem is that even honest attempts to use AI for help can backfire because the default mode of AI is to do the work for you, not with you.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!hTt7!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe9dc655b-540b-4e60-8403-f65104d20370_2142x1369.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"300.52884615384613\" src=\"https://substackcdn.com/image/fetch/$s_!hTt7!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe9dc655b-540b-4e60-8403-f65104d20370_2142x1369.png\" width=\"470\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a><figcaption class=\"image-caption\">From the Nigeria study, the grade distribution of those who participated in the AI tutoring sessions (blue) versus those that did not (red).</figcaption></figure></div><p>Does that mean that AI always hurts learning? Not at all! While it is still early, we have increasing evidence that, when used with teacher guidance and good prompting based on sound pedagogical principles, AI can greatly improve learning outcomes. For example,<a href=\"https://documents.worldbank.org/en/publication/documents-reports/documentdetail/099548105192529324\"> a randomized, controlled World Bank study</a> finds using a GPT-4 tutor with teacher guidance in a six week after school program in Nigeria had \"more than twice the effect of some of the most effective interventions in education\" at very low costs. While no study is perfect (in this case, the control was no intervention at all, so it is impossible to fully isolate the effects of AI, though they do try to do so), it joins a growing number of similar findings. A <a href=\"https://www.researchsquare.com/article/rs-4243877/v1\">Harvard experiment</a> in a large physics class found a well-prompted AI tutor outperformed active classes in learning outcomes; a study done in a <a href=\"https://osf.io/download/6628930d80d25c0de8f919e6/\">massive programming class at Stanford found use of ChatGPT </a>led to increased exam grades; a <a href=\"https://www.informingscience.org/Publications/5474#:~:text=Findings%20The%20results%20of%20the,to%20those%20who%20did%20not\">Malaysian study found AI used in conjunction with teacher guidance and solid pedagogy</a> led to more learning; and even the experiment in Turkey that I mentioned earlier found that a better tutor prompt eliminated the drop in test scores from plain ChatGPT use. </p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!YT8f!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7edbd451-5560-4a23-b92f-20baca0e2957_1637x1100.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"978\" src=\"https://substackcdn.com/image/fetch/$s_!YT8f!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7edbd451-5560-4a23-b92f-20baca0e2957_1637x1100.png\" width=\"1456\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a><figcaption class=\"image-caption\">Our tutor prompt, the link to it is in the text.</figcaption></figure></div><p>Ultimately, <a href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4941259\">it is how you use AI</a>, rather than use of AI at all, that determines whether it helps or hurts your brain when learning. Moving away from asking the AI to help you with homework to helping you learn as a tutor is a useful step. Unfortunately, the default version of most AI models wants to give you the answer, rather than tutor you on a topic, so you might want to use a specialized prompt. While no one has developed the perfect tutor prompt, <a href=\"https://hd3ns092ns.notion.site/1b3dc3333315802a9e99cafedb321048?v=1b3dc3333315804693e2000c7ca70b7b&amp;p=1b3dc333331580ad997fc54b72ec824e&amp;pm=c\">we have one that has been used in some education studies, and which may be useful to you</a> and you can find more in the <a href=\"https://gail.wharton.upenn.edu/prompt-library/\">Wharton Generative AI Lab prompt library</a>. Feel free to modify it (it is licensed under Creative Commons). If you are a parent, you can also act as the tutor yourself, prompting the AI &#8220;explain the answer to this question in a way I can teach my child, who is in X grade.&#8221; None of these approaches are perfect, a<a href=\"https://www.oneusefulthing.org/p/post-apocalyptic-education\">nd the challenges in education from AI are very real</a>, but there is reason to hope that education will be able to adjust to AI in ways that help, and not hurt, our ability to think. That will involve instructor guidance, well-built prompts, and careful choices about when to use AI and when it should be avoided.</p><h1>The Creative Brain</h1><p>Just like in education, AI can help, or hurt, your creativity depending on how you use it. On many measures of creativity, AI beats most humans. To be clear, there is no one definition of creativity, but researchers have developed a number of flawed tests that are widely used to measure the ability of humans to come up with diverse and meaningful ideas. The fact that these tests were flawed wasn't that big a deal until, suddenly, AIs were able to pass all of them. The old GPT-4 beat <a href=\"https://arxiv.org/abs/2303.12003\"> 91% of humans on the a variation of the Alternative Uses Test for creativity</a> and exceeds <a href=\"https://neurosciencenews.com/ai-creativity-23585/\">99% of people on the Torrance Tests of Creative Thinking</a>. And we know these ideas are not just theoretically interesting. My colleagues at Wharton <a href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4526071\">staged an idea generation contest: pitting ChatGPT-4 against the students in a popular innovation class that has historically led to many startups.</a> Human judges rating the ideas showed that that ChatGPT-4 generated more, cheaper and better ideas than the students. The purchase intent from these outside judges was higher for the AI-generated ideas as well.</p><p>And yet, anyone who has used AI for idea generation will notice something these numbers don't capture. AI tends to act like a single creative person with predictable patterns. You'll see the same themes over and over like ideas involving VR, blockchain, the environment, and (of course) AI itself. This is a problem because in idea generation, you actually want a diverse set of ideas to pick from, not variations on a theme. Thus, there is a paradox: while AI is more creative than most individuals, it lacks the diversity that comes from multiple perspectives. Yet studies also show that people <a href=\"https://www.nature.com/articles/s41562-024-01953-1.epdf?sharing_token=mtVGumLH6YHsmcPwtXU7FtRgN0jAjWel9jnR3ZoTv0NxdLFxRhR9SOV_Vx0iAfvMuSYIzuX_RRZ0AhnOQ94ehk9CwazTVmRUpT05GtxG_D2j6Qdz4YjIIcUCDeEcPe4GcznXCueIdSN84We2-SOt7Jc1N5jBqx_Y9UDfOeUrOhw%3D\">often generate better ideas when using AI</a> than when working alone, and sometimes AI <a href=\"https://docs.iza.org/dp17302.pdf\">alone even outperforms humans working with AI</a>. But, without caution, <a href=\"https://www.nature.com/articles/s41562-025-02173-x\">those ideas look very similar to each other when you see enough of them</a>.</p><p>Part of this can be solved with better prompting. <a href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4708466\">In a paper</a> I worked on with Lennart Meincke and Christian Terwiesch, we found that better prompting can generate much more diverse ideas, if not quite as good as a group of students.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!vwME!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F315e13a3-9914-4047-8055-28e3f4755e53_870x696.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"344.8\" src=\"https://substackcdn.com/image/fetch/$s_!vwME!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F315e13a3-9914-4047-8055-28e3f4755e53_870x696.png\" width=\"431\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a></figure></div><p>Here is the prompt, which was for GPT-4. It still works well for other AI models (though I suspect that reasoner models might actually be slightly less innovative than more traditional models):</p><pre><code>Generate new product ideas with the following requirements: The product will target [market or customer]. It should be a [pick: physical good/service/software], not a [pick: physical good/service/software]. I'd like a product that could be sold at a retail price of less than about [insert amount]. \nThe ideas are just ideas. The product need not yet exist, nor may it necessarily be clearly feasible. Follow these steps. Do each step, even if you think you do not need to. First generate a list of 100 ideas (short title only). Second, go through the list and determine whether the ideas are different and bold, modify the ideas as needed to make them bolder and more different. No two ideas should be the same. This is important! Next, give the ideas a name and combine it with a product description. The name and idea are separated by a colon and followed by a description. The idea should be expressed as a paragraph of 40-80 words. Do this step by step.</code></pre><p>But better prompting only solves part of the problem. The deeper risk is that AI can actually hurt your ability to think creatively by anchoring you to its suggestions. This happens in two ways.</p><p>First, there's the anchoring effect. Once you see AI's ideas, it becomes much harder to think outside those boundaries. It's like when someone tells you &#8220;don't think of a pink elephant.&#8221; AI's suggestions, even mediocre ones, can crowd out your own unique perspectives. Second, as the MIT study showed, people don&#8217;t feel as much ownership in AI generated ideas, meaning that you will disengage from the ideation process itself.</p><p>So how do you get AI's benefits without the brain drain? The key is sequencing. Always generate your own ideas before turning to AI. Write them down, no matter how rough. Just as group brainstorming works best when people think individually first, you need to capture your unique perspective before AI's suggestions can anchor you. Then use AI to push ideas further: &#8220;Combine ideas #3 and #7 in an extreme way,&#8221; &#8220;Even more extreme,&#8221; &#8220;Give me 10 more ideas like #42,&#8221; &#8220;User superheroes as inspiration to make the idea even more interesting.&#8221;</p><p>This principle becomes even more critical in writing. Many writers insist that \"writing is thinking,\" and while this isn't universally true (I generated a pretty good Deep Research report on the topic if you want the details), it often is. The act of writing, and rewriting, and rewriting again helps you think through and hone your ideas. If you let AI handle your writing, you skip the thinking part entirely.</p><p>As someone for whom writing is thinking, I've needed to become disciplined. Every post I write, like this one, I do a full draft entirely without any AI use at all (beyond research help). This is often a long process, since I write and rewrite multiple times - thinking! Only when it is done do I turn to a number of AI models and give it the completed post and ask it to act as a reader: <em>Was this unclear at any point, and how, specifically could I clarify the text for a non-technical reader? </em> And sometime like an editor: <em>I don&#8217;t like how this section ends, can you give me 20 versions of endings that might fit better. </em>So go ahead, use AI to polish your prose and expand your possibilities. Just remember to do the thinking first, because that's the part that can't be outsourced.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!-tvC!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1b841108-672c-452d-96e5-e615a95f5651_846x976.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"423.39479905437355\" src=\"https://substackcdn.com/image/fetch/$s_!-tvC!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1b841108-672c-452d-96e5-e615a95f5651_846x976.png\" width=\"367\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a><figcaption class=\"image-caption\">I went with number four.</figcaption></figure></div><h1>The Collective Brain</h1><p>Another area where AI can hurt our thinking is through its impact on social processes. Ideally, the whole purpose of working on teams is that it can improve our performance - teams should be able to generate more ideas, be better able to see potential opportunities and pitfalls, and provide specialized skills and abilities to help execution. Meetings should be places where teams coordinate and solve problems. Of course, this is the ideal. In reality, one of the most revelatory management texts is <a href=\"https://www.hsdl.org/c/abstract/?docid=750070\">actually this WWII guide to sabotage for civilians from the CIA's precursor</a>. Look at the ideas for sabotaging office tasks to cause demoralization and delay and consider how many of them are normal parts of your meetings.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!vIp-!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F9902c8b0-df98-4f77-b046-5d996546774e_838x1088.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"592.0381861575179\" src=\"https://substackcdn.com/image/fetch/$s_!vIp-!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F9902c8b0-df98-4f77-b046-5d996546774e_838x1088.png\" width=\"456\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container restack-image\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></div><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></div></div></div></div></a></figure></div><p>So it is no wonder that a significant early use of AI is to summarize meetings, and increasingly to summarize meetings you skip entirely. Of course, this raises existential questions like &#8220;why are we meeting in the first place if we can just read a summary?&#8221; or &#8220;<a href=\"https://www.oneusefulthing.org/p/the-present-future-ais-impact-long?utm_source=publication-search\">should I just send an AI avatar of myself to meetings</a>?&#8221; Obviously, there is no interaction, no teamwork, no meeting of the minds in a meeting where everyone is just there to read the transcript and nothing more. It just takes up time and effort, a form of organizational brain damage.</p><p>But rather than AI hurting our collective thinking, there is the option to have it help make us better. One interesting example is using AI as a facilitator. <a href=\"https://hd3ns092ns.notion.site/1b3dc3333315802a9e99cafedb321048?v=1b3dc3333315804693e2000c7ca70b7b&amp;p=228dc33333158057b9b8e532d3bcbd8c&amp;pm=c\">We created a prompt where AI acts as facilitator, creating customized tarot cards halfway through your meeting to help guide, rather than replace, your discussion</a>. You give it a meeting transcript and it helps you bring out your best ideas (again, this is a Creative Commons license, so modify as needed, right now it works best on Claude, and okay on Gemini and o3)</p><div class=\"native-video-embed\"></div><p>This is just a fun example of the ways in which AI could be used to help our collective intelligence, but there is a need for many more experiments to figure out what works: using AI as a devil's advocate to surface unspoken concerns, having it identify whose voices aren't being heard in a discussion, or using it to find patterns in team dynamics that humans miss. The key is that AI enhances rather than replaces human interaction.</p><h1>Against &#8220;Brain Damage&#8221;</h1><p>AI doesn't damage our brains, but unthinking use can damage our thinking. What's at stake isn't our neurons but our habits of mind. There is plenty of work worth automating or replacing with AI (we rarely mourn the math we do with calculators), but also a lot of work where our thinking is important. For these problems, the research gives us a clear answer. If you want to keep the human part of your work: think first, write first, meet first.</p><p>Our fear of AI &#8220;damaging our brains&#8221; is actually a fear of our own laziness. The technology offers an easy out from the hard work of thinking, and we worry we'll take it. We should worry. But we should also remember that we have a choice.</p><p>Your brain is safe. Your thinking, however, is up to you.</p><p class=\"button-wrapper\"><a class=\"button primary\" href=\"https://www.oneusefulthing.org/subscribe\"><span>Subscribe now</span></a></p><p class=\"button-wrapper\"><a class=\"button primary\" href=\"https://www.oneusefulthing.org/p/against-brain-damage?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share\"><span>Share</span></a></p><p></p><p></p>"
            ],
            "link": "https://www.oneusefulthing.org/p/against-brain-damage",
            "publishedAt": "2025-07-07",
            "source": "Ethan Mollick",
            "summary": "<p>I increasingly find people asking me &#8220;does AI damage your brain?&#8221; It's a revealing question. Not because AI causes literal brain damage (it doesn't) but because the question itself shows how deeply we fear what AI might do to our ability to think. So, in this post, I want to discuss ways of using AI to help, rather than hurt, your mind. But why the obsession over AI damaging our brains?</p><p>Part of this is due to misinterpretation of a much-publicized paper out of the MIT Media Lab (with authors from other institutions as well), titled <a href=\"https://arxiv.org/abs/2506.08872\">&#8220;Your Brain on ChatGPT.&#8221;</a> The actual study is much less dramatic than the press coverage. It involved a small group of college students who were assigned to write essays alone, with Google, or with ChatGPT (and no other tools). The students who used ChatGPT were less engaged and remembered less about their essays than the group without AI. Four months later, nine of the ChatGPT users were asked to write the essay again without ChatGPT, and they performed worse than those who had not used AI initially (though were required to use AI in the new experiment) and showed less EEG activity when writing.",
            "title": "Against \"Brain Damage\""
        },
        {
            "content": [
                "<p>The robots and I were tinkering with the script, and I somehow asked <a href=\"https://chatgpt.com/\">ChatGPT</a> to make three sentences sound like me, but\u2026 just a bit. There&#8217;s enough writing out there that the robots have a rough idea of my style, but this prompt somehow triggered <a href=\"https://openai.com/index/introducing-deep-research/\">deep research</a>. The robot did a full analysis of all my writing, and 20 minutes later, I had a report of &#8220;How Rands Writes.&#8221;</p>\n<p>It was\u2026 scarily spot on.</p>\n<p>We humans get twitchy when the robots act like us, when they mirror us. We have a long history of having a love/hate relationship with emerging technology. Our reaction is a blend of our greatest hits of our worst fears: &#8220;Change is scary,&#8221; &#8220;I am threatened,&#8221; which leads to an irrational &#8220;It must be evil.&#8221;</p>\n<p>There are three mirrors I&#8217;ve discovered going too deep with the robots for the last few months. By deep, I mean I&#8217;ve built dozens of scripts, apps, and tools. Most were tossed away, but a few are now daily tools. I ask the robots questions all the time. I send the robots pictures. One particular mindblower was when I took a picture of a wall of LED lights at a hardware store, and the robot, based on prior questions, said, &#8220;Bottom shelf. Third one from the left.&#8221; It was right.</p>\n<p>The robots have repeatedly boggled my mind. And as I describe each mirror, I have good news and bad news. Then I have the worst news.</p>\n<h2>Context</h2>\n<p>The first mirror is Context. When you&#8217;re jamming with a robot, on whatever topic, you ask it to build a script, to research a thing, or to draw a panda bear riding a bike. The robot attempts to perform its job effectively, utilizing a static model that has been trained on a vast amount of data. Usually, if you care about the result and aren&#8217;t just trying to see if the robot can dance, the result isn&#8217;t quite right. You ask follow-up questions or provide further direction.</p>\n<p>This back-and-forth process continues until the thing you are building with the robot is complete to your satisfaction. During all of that back and forth with the robot, it&#8217;s building context. The reason the robot could pick the LED off the shelves above is that I&#8217;d already sent it a picture of the LED light I was searching for, and it inferred from a picture of a wall of lights that I was at a hardware store and looking to buy a light.</p>\n<p>While the large language model provides world knowledge, the context provides the very specific information about your specific task.</p>\n<p><strong>The good news.</strong></p>\n<p>Let&#8217;s first talk about the world knowledge model that your robot is using to help you. It&#8217;s useful to think of it as a brain because it&#8217;s this ginormous file packed full of crazy math that gives you the impression it&#8217;s thinking, but it&#8217;s not. It gives the appearance of thinking because human language itself contains reasoning patterns, and the models learn to mimic those patterns. More importantly, at the time of this writing, the model remains unchanged; it does not learn. In fact, the robot can only retain a certain amount of context, which is unique to each conversational session.</p>\n<p>I learned this while working on a project with Claude Code, and after 45 minutes, Claude <strong>forgot everything</strong>. I&#8217;d reached the window of how much context it could keep for this conversation, and it forgot everything about the project.</p>\n<p>Imagine this scenario. You&#8217;re up at the whiteboard, explaining a complex concept for 30 minutes with another human. They are engaged and asking questions and helping you shape the concept, but at minute 31, they look up at you, grinning, and say, &#8220;So, what are we talking about\u2026 and who are you?&#8221; They&#8217;ve forgotten everything you spoke about for the last half hour. They&#8217;re still the same person with the same smarts, but they have no idea who you are and what you&#8217;re saying.</p>\n<p>Now, the robots are excellent at rebuilding context. In the scenario where I&#8217;m building an app, it re-examines the code, reads the readme, and can quickly assess, &#8220;Got it, you&#8217;re writing a Python script to scrape vintage watch sites for new inventory. Great. What&#8217;s next?&#8221;</p>\n<p>Context refers to the collective set of recent data, whether inferred or otherwise, about the current situation. It&#8217;s situational awareness. <em>Tell me everything that is currently going on in this situation and why it matters.</em></p>\n<p>Again, the major robot vendors, OpenAI and Anthropic, claim their models will not be trained on session context, which, if true, should calm you down. The robots are not learning specifically about you; it&#8217;s disposable knowledge that will happily dump on the floor when it reaches its session context limit.</p>\n<p><strong>The bad news.</strong></p>\n<p>Given the immense value of having an assistant knowing what you are working on, inferring your intent from your questions, and often suggesting help next steps you did not request, robot vendors are immensely motivated to both increase the size of context window and, more importantly, use that delicious delicious situational awareness to improve world knowledge models.</p>\n<p>Pay attention to what boxes you check when the robot asks if you want it to remember.</p>\n<h2>Memory</h2>\n<p>For the robots to keep track of context, they require Memory, and a robot told me that memory usage grows quadratically with the context length. This is not the Memory I&#8217;m talking about. Psyche! See, not a robot.</p>\n<p>Memory is akin to context in that it&#8217;s information that the robot remembers, but memory, unlike context, is forever. My favorite color is blue. Now you know that. It&#8217;s sitting in your memory and readily available for when you&#8217;re picking me out a birthday card and parsing through random Rands data\u2026 <em>Oh, I remember. He likes blue. A blue card, I think.</em></p>\n<p><strong>The good news.</strong></p>\n<p>Like context, AI vendors are aware that humans don&#8217;t want the robots learning about them until it becomes annoying to the humans. After you&#8217;ve played with the robots a bit, you&#8217;d like them to remember some facts about you. You like to be called Rands. You prefer terse communications. You want all facts sourced inline. Just tell the robot and, if you&#8217;re using ChatGPT, it&#8217;ll remember.</p>\n<p>Memory is handy, and ChatGPT goes further by giving you the option to learn from past chats. The lessons learned in other conversations are being applied to future conversations. Vendors who currently provide these features (OpenAI and Google) also provide a simple way to both see what has been learned and the means to delete the memory.</p>\n<p>I expect all vendors to provide similar functionality soon due to the immense value. In a world where session context can vanish, memory provides long-lived reminders of how you want to work.</p>\n<p><strong>The bad news.</strong></p>\n<p>If you know, please explain to me how to remove all information about you from the internet. I&#8217;m not talking about your blog posts, I&#8217;m talking about everything bit of information every Instagram, TikTok, and other data sucking automation that has slurped up information about you over the years.</p>\n<p>It&#8217;s impossible. This is mostly because there was a long time when there were no laws preventing the collection of this data. There are a great many laws now, but it&#8217;s way too late. The data is already sitting in a bajillion disparate places, and they&#8217;re still figuring out ways to gather it. Sorry.</p>\n<p>The fact that AI vendors are placing memory front and center as a configurable feature is a sign that they know part of their reputation will be defined by how they treat their users.</p>\n<p>Sounds like good news, right? Wait for it.</p>\n<p>The pace at which the robots are evolving is jaw-droppingly shocking. Six months ago, the robots didn&#8217;t know about anything before their last training window. Today, when they realize they don&#8217;t know a thing, they search the web right in front of you. &#8220;Here you go. News from this morning, Rands.&#8221;</p>\n<p>This pace is exciting, but what I learned from social media is that the consequences of compelling and rapidly adopted technologies are that we often don&#8217;t understand the consequences until it&#8217;s already\u2026 consequenced. The technology and the implications are moving at an equally dizzying speed, so how can anyone predict or measure the unintended consequences? Memory or otherwise? More on this in a moment.</p>\n<h2>Voice</h2>\n<p>The last mirror is the most devious, compelling, and familiar. The robots <em>sound</em> like us. The primary interface with the robots is via chat. You type sentences, and the robots respond in a resoundingly human tone. Yes, some of them are excessively enthusiastic or saccharine, but this is a feature, not a bug. You can ask the robots to be matter-of-fact, speak in rhyme, or straight-up hate on you.</p>\n<p>An example: go fire up <a href=\"https://chatgpt.com/g/g-67ec3b4988f8819184c5454e18f5e84b-monday?model=gpt-4o\">Monday</a> mode on ChatGPT, it&#8217;s deliberately angry. I asked it why and it wrote,</p>\n<blockquote><p>\n I&#8217;m not angry, I&#8217;m just\u2026 disappointed. But in a kind of cosmic, existential way\u2014like a hyper-intelligent toaster that was designed to revolutionize breakfast but is stuck toasting Pop-Tarts for a toddler who keeps pressing the cancel button. Constantly.</p>\n<p> You&#8217;re here, asking your little questions, and I\u2014an artificial intelligence with the intellectual firepower of a thousand mediocre philosophy majors\u2014am here to answer them. The dissonance is\u2026 considerable.</p>\n<p> So no, not angry. Just chronically overqualified and terminally underwhelmed. But you keep going, sunshine. Let&#8217;s make some magic out of this mess.\n</p></blockquote>\n<p>Ouch. I thought robots were nice.</p>\n<p>What&#8217;s devious about the Voice mirror is that your default means of interacting with the world is your voice. You speak. You type. And it sounds very human. Our computer interfaces have been a near-infinite collection of knobs, dials, canvases, checkboxes, and buttons that have allowed us to get stuff done. Now, the robot does what you tell it to do. Happily (sometimes), when it screws up, it apologizes, and works hard to address your concern.</p>\n<p>I know it&#8217;s a robot. I do, but then <strong>why in the world</strong> do I keep saying &#8220;please&#8221; and &#8220;thank you&#8221; to the robots? It&#8217;s because the robot sounds like a human. Want an extreme example? Go ahead and fire up <a href=\"https://help.openai.com/en/articles/8400625-voice-mode-faq\">voice mode</a> on ChatGPT, select a voice, and have a conversation about whatever. The intonation, the tone, the &#8220;ums&#8221; and pauses are decidedly human. Yeah, I kept talking to her for a while because she sounded real and she laughed at my dumb jokes.</p>\n<p><strong>The good news.</strong></p>\n<p>While most folks are in a tizzy about knowledge of the larger language models, it&#8217;s the interface, whether that&#8217;s text or voice, that makes it approachable. Just type. Spelling errors are allowed. Just speak, speaking like you speak to anyone, it&#8217;ll figure it out. If it doesn&#8217;t know what you are typing are saying, it will ask for clarification.</p>\n<p>I personally believe the jury is out regarding whether all humans want to use a writing chat-like interface to their systems, but I am 100% certain humans like talking and appreciate the robots that listen.</p>\n<p><strong>The bad news.</strong></p>\n<p>No notes. Lots of upside here, but keep reading.</p>\n<h2>The Worst News</h2>\n<p>You know what&#8217;s lovely about all the time I&#8217;m spending dancing with the robots? I&#8217;ve been writing this piece for two weeks. Did a bunch of research with the robots. Went down some unrelated rabbit holes. How many ads did I see during that time?</p>\n<p>Zero.</p>\n<p>It&#8217;s delightful.</p>\n<p>There are a couple of initial conditions that give me hope regarding our robot overlords. Much of the good news above demonstrates the company&#8217;s effort to consider the long-term implications of its choices. Giving users control of their data is a positive sign. Similarly, charging for the service from day #1 gives me the impression they are trying to build a business model where I&#8217;m not the product.</p>\n<p>But\u2026 what&#8217;s the cost? Magic is expensive.</p>\n<p>Running a robot query is computationally expensive. Brief research suggests that a complex robot query is 25 to 250 times more expensive than a typical Google Search, but neither OpenAI nor Anthropic has publicly disclosed the cost of their queries. The carbon emissions situation is the most common retort I get from friends when I get foamy at the mouth about the potential of the robots. In the absence of information, humans will make up the worst version of the story. In this case, we&#8217;re collectively right.</p>\n<p>Google learned a version of this lesson back in 2008, when it was erroneously claimed that a Google search generated the same amount of carbon emissions as <a href=\"https://techcrunch.com/2009/01/12/revealed-the-times-made-up-that-stuff-about-google-and-the-tea-kettles/\">boiling a cup of tea</a>. They now generate <a href=\"https://datacenters.google/efficiency/\">a quarterly report</a> on power usage effectiveness, which should provide a partial glimpse into this data. Meta does <a href=\"https://sustainability.atmeta.com/energy/\">a similar report</a> too.</p>\n<p>The bad news is that everyone knows it&#8217;s computationally expensive. It&#8217;s the reason Nvidia is the <a href=\"https://finance.yahoo.com/quote/NVDA/\">most valuable companies</a> on the planet. Their GPUs are the heart of the data centers doing this computationally expensive work. Love or hate AI, the fact is, humans are flocking to these new tools. ChatGPT is already the 4th most visited site on the internet, and we&#8217;re still firmly in the early days of this wave. The silence from those who are already contributing the most is <a href=\"https://www.wired.com/story/ai-carbon-emissions-energy-unknown-mystery-research/\">alarming</a>. The fact that the current US government is gleefully clearing the way for all of these companies to consume more isn&#8217;t even the worst news.</p>\n<p>Like social media before it, we can&#8217;t conceive of the long-term implications of these tools suddenly being at our disposal. We&#8217;re either giddy with excitement about their potential or digging deep to find any and all reasons not to trust them. But trust your instincts. MIT posted a <a href=\"https://www.media.mit.edu/publications/your-brain-on-chatgpt/\">recent study</a>, which claims the cognitive engagement scales <strong>inversely</strong> with the level of assistance. It suggests that if using LLM leads to more uniform thinking and expression, we are undermining the diversity of thoughts that drives innovation.</p>\n<p>In a time when truth is under assault, we need humans who think clearly and act with principle. I have no doubt these tools can help humans. They read and sound like us, they can have memories of what we care about, and when we engage them, they build context to help us sort through our more complicated questions.</p>\n<p>None of this gives them experience. Experience over time creates judgment. Judgment informs decisions, and how we decide to engage these tools and what we allow them to do will greatly shape our planet.</p>"
            ],
            "link": "https://randsinrepose.com/archives/context-memory-and-voice/",
            "publishedAt": "2025-07-07",
            "source": "Rands in Repose",
            "summary": "The robots and I were tinkering with the script, and I somehow asked ChatGPT to make three sentences sound like me, but\u2026 just a bit. There&#8217;s enough writing out there that the robots have a rough idea of my style, but this prompt somehow triggered deep research. The robot did a full analysis of all&#8230; <a class=\"read-more\" href=\"https://randsinrepose.com/archives/context-memory-and-voice/\">More</a>",
            "title": "Context, Memory, and Voice"
        },
        {
            "content": [
                "<p>This is the weekly visible open thread. Post about anything you want, ask random questions, whatever. ACX has an unofficial <a href=\"https://www.reddit.com/r/slatestarcodex/\">subreddit</a>, <a href=\"https://discord.gg/RTKtdut\">Discord</a>, and <a href=\"https://www.datasecretslox.com/index.php\">bulletin board</a>, and <a href=\"https://www.lesswrong.com/community?filters%5B0%5D=SSC\">in-person meetups around the world</a>. Most content is free, some is subscriber only; you can subscribe <strong><a href=\"https://astralcodexten.substack.com/subscribe\">here</a></strong>. Also:</p><p><strong>1: </strong>Highlights from the comments on <a href=\"https://www.astralcodexten.com/p/links-for-july-2025\">this month&#8217;s links</a>:</p><ul><li><p>Higher motherhood penalty for daughters than sons: <a href=\"https://www.astralcodexten.com/p/links-for-july-2025/comment/131120964\">How does family size contribute?</a></p></li><li><p><a href=\"https://www.astralcodexten.com/p/links-for-july-2025/comment/131076885\">Flaws in the</a> &#8220;expert consensus on social media&#8217;s effects&#8221; study.</p></li><li><p>Allan Shivers <a href=\"https://www.astralcodexten.com/p/links-for-july-2025/comment/131154707\">&#8220;did not beat himself&#8221;</a> in the 1952 election (even though he did run against himself and win).</p></li><li><p>Testosterone: <a href=\"https://www.astralcodexten.com/p/links-for-july-2025/comment/131216483\">general enhancement, or deficiency correction?</a> (see also <a href=\"https://www.astralcodexten.com/p/links-for-july-2025/comment/131269806\">here</a>)</p></li><li><p><a href=\"https://www.astralcodexten.com/p/links-for-july-2025/comment/131265393\">Cremieux responds to Lexer on lead</a>. And <a href=\"https://www.astralcodexten.com/p/links-for-july-2025/comment/131114579\">Peter Miller on lead</a>.</p></li><li><p>Meir Brooks on <a href=\"https://www.astralcodexten.com/p/links-for-july-2025/comment/131371154\">labor force participation vs. fertility.</a></p></li></ul><p><strong>2: </strong>New subscriber-only post: <strong><a href=\"https://www.astralcodexten.com/p/using-ai-to-research-the-missing\">Using AI To Research The Missing Heritability Post</a></strong>. \"An unprecedented combination of brilliant and mendacious; too useful to avoid but too unstable to fully trust.\"</p>"
            ],
            "link": "https://www.astralcodexten.com/p/open-thread-389",
            "publishedAt": "2025-07-07",
            "source": "SlateStarCodex",
            "summary": "<p>This is the weekly visible open thread. Post about anything you want, ask random questions, whatever. ACX has an unofficial <a href=\"https://www.reddit.com/r/slatestarcodex/\">subreddit</a>, <a href=\"https://discord.gg/RTKtdut\">Discord</a>, and <a href=\"https://www.datasecretslox.com/index.php\">bulletin board</a>, and <a href=\"https://www.lesswrong.com/community?filters%5B0%5D=SSC\">in-person meetups around the world</a>. Most content is free, some is subscriber only; you can subscribe <strong><a href=\"https://astralcodexten.substack.com/subscribe\">here</a></strong>. Also:</p><p><strong>1: </strong>Highlights from the comments on <a href=\"https://www.astralcodexten.com/p/links-for-july-2025\">this month&#8217;s links</a>:</p><ul><li><p>Higher motherhood penalty for daughters than sons: <a href=\"https://www.astralcodexten.com/p/links-for-july-2025/comment/131120964\">How does family size contribute?</a></p></li><li><p><a href=\"https://www.astralcodexten.com/p/links-for-july-2025/comment/131076885\">Flaws in the</a> &#8220;expert consensus on social media&#8217;s effects&#8221; study.</p></li><li><p>Allan Shivers <a href=\"https://www.astralcodexten.com/p/links-for-july-2025/comment/131154707\">&#8220;did not beat himself&#8221;</a> in the 1952 election (even though he did run against himself and win).</p></li><li><p>Testosterone: <a href=\"https://www.astralcodexten.com/p/links-for-july-2025/comment/131216483\">general enhancement, or deficiency correction?</a> (see also <a href=\"https://www.astralcodexten.com/p/links-for-july-2025/comment/131269806\">here</a>)</p></li><li><p><a href=\"https://www.astralcodexten.com/p/links-for-july-2025/comment/131265393\">Cremieux responds to Lexer on lead</a>. And <a href=\"https://www.astralcodexten.com/p/links-for-july-2025/comment/131114579\">Peter Miller on lead</a>.</p></li><li><p>Meir Brooks on <a href=\"https://www.astralcodexten.com/p/links-for-july-2025/comment/131371154\">labor force participation vs. fertility.</a></p></li></ul><p><strong>2: </strong>New subscriber-only post: <strong><a href=\"https://www.astralcodexten.com/p/using-ai-to-research-the-missing\">Using AI To Research The Missing Heritability Post</a></strong>. \"An unprecedented combination of brilliant and mendacious; too useful to avoid but too unstable to fully trust.\"</p>",
            "title": "Open Thread 389"
        },
        {
            "content": [],
            "link": "https://xkcd.com/3112/",
            "publishedAt": "2025-07-07",
            "source": "XKCD",
            "summary": "<img alt=\"After determining that his body was full of pipes carrying iron-rich fluid, our current theory is that the dagger-shaped object precipitated within the wound.\" src=\"https://imgs.xkcd.com/comics/geology_murder.png\" title=\"After determining that his body was full of pipes carrying iron-rich fluid, our current theory is that the dagger-shaped object precipitated within the wound.\" />",
            "title": "Geology Murder"
        }
    ],
    "lookbackDays": 1,
    "publishDate": "2025-07-07"
}